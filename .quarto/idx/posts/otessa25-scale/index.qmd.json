{"title":"OTESSA25","markdown":{"yaml":{"title":"OTESSA25","author":"Colin Madland<sup>1</sup>, Valerie Irvine<sup>1</sup>, Christopher DeLuca<sup>2</sup>, and Okan Bulut<sup>3</sup>","institute":"<sup>1</sup>University of Victoria, <sup>2</sup>Queens University, <sup>3</sup>University of Alberta","date":"2025-06-05","format":{"revealjs":{"multiplex":true,"incremental":true,"theme":"night"}},"logo":"otessa-logo-CS6.png","footer":"Special thanks to BCcampus"},"headingText":"Developing the Technology-integrated Assessment Scale","containsRefs":true,"markdown":"\n\n\n## Acknowledgements\n\nOur team is spread across most of the country and we each live and work on land that has been cared for by Indigenous people for millenia. We each acknowledge that our abundant lives were made possible because of the displacement of the original stewards of the land.\n\n::: {.notes}\n\n:::\n\n# Background\n\n## OTESSA24\n\n### [Evolving our understanding of technology-integrated assessment: A review of the literature and development of a new framework](https://cmadland.github.io/slides/posts/deck-otessa24)\n\n\n## Two Papers\n\n- Madland, C., Irvine, V., DeLuca, C., & Bulut, O. (2024b). Technology-Integrated Assessment: A Literature Review. *The Open/Technology in Education, Society, and Scholarship Association Journal, 4*(1), 1–48. <https://doi.org/10.18357/otessaj.2024.4.1.57>\n\n- Madland, C., Irvine, V., DeLuca, C., & Bulut, O. (2024a). Developing the Technology-Integrated Assessment Framework. *The Open/Technology in Education, Society, and Scholarship Association Journal, 4*(1), 1–19. <https://doi.org/10.18357/otessaj.2024.4.1.63>\n\n\n\n# Technology-integrated Assessment Framework (TIAF)\n\n## 4 Components\n\n::: r-vstack\n::: {data-id=\"box1\" auto-animate-delay=\"0\" style=\"background: #5EC962; width: 50px; height: 50px; border-radius: 30px; margin: 10px;\" title=\"Assessment Design\"}\n:::\nAssessment Design\n\n::: {data-id=\"box2\" auto-animate-delay=\"0.1\" style=\"background: #21918C; width: 50px; height: 50px; border-radius: 30px; margin: 10px;\" title=\"Technology Acceptance\"}\n:::\nTechnology Acceptance\n\n::: {data-id=\"box3\" auto-animate-delay=\"0.2\" style=\"background: #3B528B; width: 50px; height: 50px; border-radius: 30px; margin: 10px;\" title=\"Duty of Care\"}\n:::\nDuty of Care\n\n::: {data-id=\"box4\" auto-animate-delay=\"0.3\" style=\"background: #440154; width: 50px; height: 50px; border-radius: 30px; margin: 10px;\" title=\"Purposes of Assessment\"}\n:::\nPurposes of Assessment\n:::\n\n##  {auto-animate=\"true\" auto-animate-easing=\"ease-in-out\"}\n\n::: r-hstack\n::: {data-id=\"box1\" auto-animate-delay=\"0\" style=\"background: #5EC962; width: 50px; height: 50px; border-radius: 30px; margin: 10px;\" title=\"Assessment Design\"}\n:::\n\n::: {data-id=\"box2\" auto-animate-delay=\"0.1\" style=\"background: #21918C; width: 50px; height: 50px; border-radius: 30px; margin: 10px;\" title=\"Technology Acceptance\"}\n:::\n\n::: {data-id=\"box3\" auto-animate-delay=\"0.2\" style=\"background: #3B528B; width: 50px; height: 50px; border-radius: 30px; margin: 10px;\" title=\"Duty of Care\"}\n:::\n\n::: {data-id=\"box4\" auto-animate-delay=\"0.3\" style=\"background: #440154; width: 50px; height: 50px; border-radius: 30px; margin: 10px;\" title=\"Purposes of Assessment\"}\n:::\n:::\n\n##  {auto-animate=\"true\" auto-animate-easing=\"ease-in-out\"}\n\n::: r-stack\n::: {data-id=\"box1\" style=\"background: #5EC962; width: 600px; height: 600px; border-radius: 300px;\" title=\"Assessment Design\"}\n:::\n\n::: {data-id=\"box2\" style=\"background: #21918C; width: 450px; height: 450px; border-radius: 300px;\" title=\"Technology Acceptance\"}\n:::\n\n::: {data-id=\"box3\" style=\"background: #3B528B; width: 300px; height: 300px; border-radius: 300px;\" title=\"Duty of Care\"}\n:::\n\n::: {data-id=\"box4\" style=\"background: #440154; width: 150px; height: 150px; border-radius: 300px;\" title=\"Purposes of Assessment\"}\n:::\n:::\n\n## \n\n![Full Model](tiaf-q-full.drawio.png)\n\n## Alt-View\n```{mermaid}\nflowchart TD\nclassDef purpose fill:#440154,color:#fff,stroke:#440154,stroke-width:4px\nclassDef duty fill:#3B528B,color:#fff,stroke:#3B528B,stroke-width:4px\nclassDef accept fill:#21918c,color:#fff,stroke:#21918c,stroke-width:4px\nclassDef design fill:#5EC962,color:#000,stroke:#5EC962,stroke-width:4px\n  A[Technology-Integrated Assessment] --- B(Assessment Purpose)\n  A(Technology-Integrated Assessment) --- C(Duty of Care)\n  A(Technology-Integrated Assessment) --- D(Technology Acceptance)\n  A(Technology-Integrated Assessment) --- E(Assessment Design)\n  B --- F([Assessment of Learning]) --- G([Assessment for Learning]) --- H([Assessment as Learning])\n  C --- I([Bias]) --- J([Inclusion]) --- K([Relationships]) --- L([Ethical EdTech])\n  D --- M([Performance Expectancy]) --- N([Effort Expectancy]) --- O([Social Influence]) --- P([Facilitating Conditions])\n  E --- Q([Measurement Theory]) --- R([Academic Integrity]) --- S([Relevance]) --- T([Reciprocity])\n  class B,F,G,H purpose\n  class C,I,J,K,L duty\n  class D,M,N,O,P accept\n  class E,Q,R,S,T design\n\n```\n\n## Differentiation\n\n- 5Rs of Indigenous Education\n  - Respect\n  - Relevance\n  - Reciprocity\n  - Responsibility\n  - Relationship\n\n---\n\n## Differentiation\n\n- Duty of Care\n  - Bias\n  - Inclusion\n  - Relationships\n  - Ethical EdTech\n\n---\n\n## Differentiation\n\n- Technology Acceptance\n  - Performance Expectancy\n  - Effort Expectancy\n  - Social Influence\n  - Facilitating Conditions\n\n---\n\n# Analysis\n\n---\n\n## Exploratory Factor Analysis\n\n- specify constructs\n- identify parameters\n- generate and refine items\n- content validity\n\n---\n\n# [Table of Specifications](https://cmadland.github.io/slides/posts/otessa25-specs/)\n\n---\n\n# [Parameters](https://cmadland.github.io/slides/posts/otessa25-specs/#parameters-rough-sample)\n\n::: {.callout}\nNote: Archived /WIP/\n\n:::\n---\n\n# Draft Questions\n\n## Part B: Scenario-Based Questions {.unnumbered}\n\nYou will be presented with five scenarios in this section. Each scenario has 15 actions. For each action, please identify how likely you are to do each of the following as part of your overall response to the scenario (1=highly unlikely; 2=unlikely; 3=somewhat unlikely; 4=somewhat likely; 5=likely; 6=highly likely).\n\nPlease interpret the scenario in relation to your current teaching context; if you teach across contexts, select one context and keep this context in mind when completing the entire survey. There are no right or wrong answers. We are interested in your honest responses to the scenarios. If you do not understand the statement, select 'Don't Know.'\n\n### Large Enrolment Course {.unnumbered}\n\nYou are teaching a large enrollment course. The students will be submitting bi-weekly assignments, a midterm exam, and a culminating assignment all designed to support their learning and submitted in the institurional LMS. (ACAI-HE)\n\nHow might the following influence your decision whether or not to use technology in this situation? (1=Much less likely to use technology - 6 = Much more likely to use technology)\n\n| Primary Construct | Secondary Construct | Description |\n| --- | --- | --- |\n|Technology Acceptance | Performance Expectancy | You have confidence that the technology will work as expected. | | | Effort Expectancy | The technology will require more time to set up and use than not using technology. | | | Social Influences | A trusted colleague has told you that you should use the technology. | | | Facilitating Conditions | You are confident that you will be able to get technical support in a timely manner. |\n\nPresuming you decide to use technology, how likely are you to take the following actions in this situation?\n\n| Primary Construct | Secondary Construct | Description |\n| --- | --- | --- |\n|Assessment Purpose | Assessment of learning | Grade each bi-weekly assignment. | | | Assessment for learning | Read a subset of bi-weekly assignments, identify and share performance trends with the whole class. | | | Assessment as learning | Ask students to self-assess their bi-weekly assignments using evaluative criteria. | | Duty of Care | Bias | Examine assessment results to ensure subgroups are not assigned systematically higher or lower grades | | | Inclusion | Avoid software that may make it difficult for equity-deserving populations to participate. | | | Relationship | Organize learners into learning pods of 3-5 for peer support and learning. | | | Ethical EdTech | Ensure that software used in class does not contribute to learner anxiety. | | Assessment Design | Academic Integrity | Use automated software to check for academic misconduct. | | | Measurement Theory | Examine assessment data to ensure content and construct validity. | | | Relevance | Ensure that assessment strategies are relevant to learners' contexts. | | | Reciprocity | Use learning pods to engage in peer-review and feedback. |\n\n```{=html}\n<!--\n1. Purpose\n  1. Assessment of learning\n     1. Grade each bi-weekly assignment.\n  2. Assessment for learning\n     1. Read a subset of bi-weekly assignments, identify and share performance trends with the whole class.\n  3. Assessment as learning\n     1. Ask students to self-assess their bi-weekly assignments using evaluative criteria.\n2. Human-centred assessment\n  1. Future activities\n     1. Ensure that learners respond to assignments in the context of their future career goals.\n  2. Future self\n     1. Provide opportunities for learners to choose from 3-4 different ways to represent their learning in relation to outcomes and their future goals.\n  3. Community\n     1. Organize learners into learning pods of 3-5 for peer support and learning.\n3. Fairness\n  1. Potential harms\n     1. Avoid software that may make it difficult for equity-deserving populations to participate.\n  2. Academic Integrity\n     1. Use automated software to check for academic misconduct.\n4. Assessment Design\n  1. Measurement Theory\n     1. Examine assessment data to ensure consistency.\n  2. Feedback Design\n     1. Use learning pods to engage in peer-review and feedback.\n5. Technology\n  1. Instructor Workload\n     1. Maximize instructor effort through the implementation of relevant technology.\n  2. Digital Literacy\n     1. Ensure that all stakeholders are able tounderstand and use required technologies safely, ethically, and effectively.\n  3. Modality\n     1. Enable access to synchronous and asynchronous participation.\n\n-->\n```\n### Generative Artificial Intelligence (GenAI) {.unnumbered}\n\nAn assignment in your course requires learners to write a 2000 word essay and your department has requested that each instructor develop an assessment strategy in light of generative AI tools (ChatGPT, Google Bard).\n\nHow might the following influence your decision whether or not to use technology in this situation? (1=Much less likely to use technology - 6 = Much More likely to use technology)\n\n```{=html}\n<!--\n//todo #269\n-->\n```\n| Primary Construct | Secondary Construct | Description |\n| --- | --- | --- |\n|Technology Acceptance | Performance Expectancy | You have confidence that the technology will work as expected. | | | Effort Expectancy | It is too much work to try to limit the use of generative AI tools, so you allow its use under certain conditions. | | | Social Influences | A trusted colleague has told you that you won't be able to detect AI generated content. | | | Facilitating Conditions | You are confident that you will be able to get support for developing assessment tasks that discourage or prevent the use of generative AI. |\n\nPresuming you decide to use technology, how likely are you to take the following actions in this situation?\n\n| Primary Construct | Secondary Construct | Description |\n| --- | --- | --- |\n|Assessment Purpose | Assessment of learning | Implement a ban on all GenAI tools. | | | Assessment for learning | Allow learners to use GenAI to generate ideas with proper citations and informed consent. | | | Assessment as learning | Collaborate with learners to evaluate the quality of GenAI outputs and the ethics of their use. | | Duty of Care | Bias | Examine assessment results to ensure that learners who used genAI did not score significantly higher or lower than those who did not. | | | Inclusion | Confirm that all learners know how to access and use a genAI tool to assist them. | | | Relationship | Encourage cooperative approaches to learning in learning pods. | | | Ethical EdTech | Provide learners with training on using 'local-only' generative AI tools that they can use to assist their work. | | Assessment Design | Academic Integrity | Require learners to submit papers through software that claims to detect plagiarism and AI-generated writing. | | | Measurement Theory | Examine assessment data to ensure there are no significant grade differences between learners who used generative AI and those who did not. | | | Relevance | Since learners will use generative AI in their careers, ensure that they know how to construct helpful prompts. | | | Reciprocity | Experiment with learners to learn about the capabilities and limitations of generative AI. |\n\n```{=html}\n<!--\n1. Purpose\n  1. Assessment of learning\n     1. Implement a ban on all GenAI tools.\n  2. Assessment for learning\n     1. Allow learners to use GenAI to generate ideas with proper citations and informed consent.\n  3. Assessment as learning\n     1. Collaborate with learners to evaluate the quality of GenAI outputs and the ethics of their use.\n2. Human-centred assessment\n  1. Future activities\n     1. Reflect with learners on the implications of GenAI in their future careers.\n  2. Future self\n     1. Encourage thoughtful engagment with the personal impacts of GenAI on individual learners.\n  3. Community\n     1. Encourage cooperative approaches to learning in learning pods. \n3. Fairness\n  1. Potential harms\n     1. Ensure learners understand the human and environmental costs of GenAI tools.\n  2. Academic Integrity\n     1. Require learners to submit appers through software that claims to detect plagiarism and AI-generated writing. \n4. Assessment Design\n  1. Measurement Theory\n     1. Use genAI to help you evaluate learners' papers.\n  2. Feedback Design\n     1. Require learning pods to evaluate the quality of their work against both human-written and AI-generated samples.\n5. Technology\n  1. Instructor Workload\n     1. Use AI tools to provide feedback on learner products.\n  2. Digital Literacy\n     1. Encourage the use of AI-powered tools to assist the process of writing the paper, rather than creating the final product.\n  3. Modality\n     1. Require evidence of interactions in learning pods to make the learning process more visible.\n\n-->\n```\n### Plagiarism Detection and Remote Proctoring {.unnumbered}\n\nYou teach a course with multiple sections taught by various instructors. Your department head has noticed that you are the only instructor who does not use plagiarism detection software (Turnitin) or remote proctoring (Proctorio, or ProctorU)\n\nHow might the following influence your decision whether or not to use technology in this situation? (1=Much less likely to use technology - 6 = Much More likely to use technology)\n\n| Primary Construct | Secondary Construct | Description |\n| --- | --- | --- |\n|Technology Acceptance | Performance Expectancy | You learn that surveillance tools have a high error rate. | | | Effort Expectancy | You learn that instructors who use surveillance technologies spend less time grading than you do. | | | Social Influences | A trusted colleague has sent you an article on the privacy concerns related to surveillance technologies. | | | Facilitating Conditions | You are confident that you will be able to get support for developing assessment tasks that discourage or prevent academically dishonest assignment submissions. |\n\nPresuming you decide to use technology, how likely are you to take the following actions in this situation?\n\n| Primary Construct | Secondary Construct | Description |\n| --- | --- | --- |\n|Assessment Purpose | Assessment of learning | Implement the use of tools that claim to detect plagiarism or cheating on exams. | | | Assessment for learning | Advocate for department standards that prioritize feedback processes over technology-centric policing of academic misconduct. | | | Assessment as learning | Encourage learners to develop workflows that document and make the process of their learning visible. | | Duty of Care | Bias | Evaluate with learners the equity implications of using technology-centric policing of academic misconduct. | | | Inclusion | Decline to use technology to police academic misconduct due to concerns about unequal access to appropriate learning resources or tools. | | | Relationship | Encourage learning pods to review each others' work for quality and compliance to standards of academic writing. | | | Ethical EdTech | Only use technology tools that protect learner anonymity. | | Assessment Design | Academic Integrity | Structure your course to minimize the likelihood of academic misconduct. | | | Measurement Theory | Examine assessment data to ensure that measures to promote academic honesty do not introduce construct irrelevant variance. | | | Relevance | Ensure that assessment tasks are relevant to learners' contexts and community as a strategy to reduce academic dishonesty. | | | Reciprocity | Host a conversation with learners to discuss the importance of academic honesty for the entire higher education community. |\n\n```{=html}\n<!--\n1. Purpose\n  1. Assessment of learning\n     1. Implement the use of tools that claim to detect plagiarism or cheating on exams.\n  2. Assessment for learning\n     1. Advocate for department standards that prioritize feedback processes over technology-centric policing of academic misconduct.\n  3. Assessment as learning\n       1. Encourage learners to develop workflows that document and make the process of their learning visible.\n2. Human-centred assessment\n    1. Future activities\n       1. Discuss with learners how they can protect themselves from accusations of academic misconduct.\n    2. Future self\n       1. Have learners consider the implications of relying on digital algorithms to determine ethical behaviour.\n    3. Community\n       1. Encourage learning pods to review each others' work for quality and compliance to standards of academic writing.\n3. Fairness\n    1. Potential harms\n       1. Evaluate with learners the privacy and equity implications of using technology-centric policing of academic misconduct.\n    2. Academic Integrity\n       1. Structure your course to minimize the likelihood of academic misconduct.\n4. Assessment Design\n    1. Measurement Theory\n       1. Ensure proper alignment between course outcomes, learning activities, and assessment tasks.\n    2. Feedback Design\n       1. Ensure learners receive ample formative feedback during the process of the course.\n5. Technology\n    1. Instructor Workload\n       1. Use technology tools to reduce the time required to detect academic misconduct.\n    2. Digital Literacy\n       1. Provide professional development resources for your colleagues regarding the implictions of technology-centric policing of academic misconduct.\n    3. Modality\n       1. Create multiple avenues for access to your course to ease pressure on learners who have difficulty attending on-campus.\n-->\n```\n### Orientations to Assessment and Grading {.unnumbered}\n\nThere are expectations in your department that grades should be distributed across the grading scale. However, your class averages are consistently lower than your colleagues’. Your course assessment scheme includes two term exams and one final exam. (ACAI-HE)\n\nHow might the following influence your decision whether or not to use technology in this situation? (1=Much less likely to use technology - 6 = Much More likely to use technology)\n\n```{=html}\n<!--\n//todo #268\n-->\n```\n| Primary Construct | Secondary Construct | Description |\n| --- | --- | --- |\n|Technology Acceptance | Performance Expectancy | You learn about an assessment method that uses technology to increase the accuracy of your grades. | | | Effort Expectancy | You learn about an assessment method that will require you to learn how to use a new technology tool. | | | Social Influences | A trusted colleague shares how they used technology to prepare their learners for an exam. | | | Facilitating Conditions | There are help resources built in to a technology-integrated assessment tool. |\n\nPresuming you decide to use technology, how likely are you to take the following actions in this situation?\n\n| Primary Construct | Secondary Construct | Description |\n| --- | --- | --- |\n|Assessment Purpose | Assessment of learning | Provide students with additional graded assessments to chunk learning into smaller units. | | | Assessment for learning | Provide students with additional opportunities to check their understanding throughout the course (e.g., ungraded quizzes, exit slips). | | | Assessment as learning | Provide self-assessment opportunities to help students recognize and address gaps in their learning. | | Duty of Care | Bias | Analyze test results for evidence of differential results between identifiable groups (ethnicity, gender). | | | Inclusion | Provide learners with multiple options for demonstrating their achievement in relation to the learning outcomes. | | | Relationship | Implement double-attempt tests where learners first complete the test alone, and then work through the test with their learning pod. | | | Ethical EdTech | Ensure that any technology you use in your assessment allows learners to export their work in a usable format. | | Assessment Design | Academic Integrity | Reduce learners' test anxiety by allowing them to prepare and use note cards during exams. | | | Measurement Theory | Use technology to adjust grades upwards to match other sections. | | | Relevance | Ensure that items on your exams are standardized across sections to increase reliability. | | | Reciprocity | Ensure learners complete assessment tasks individually and without external assistance. |\n\n```{=html}\n<!--\n1. Purpose\n    1. Assessment of learning\n       1. Provide students with additional graded assessments to chunk learning into smaller units.\n    2. Assessment for learning\n       1. Provide students with additional opportunities to check their understanding throughout the course (e.g., ungraded quizzes, exit slips).\n    3. Assessment as learning\n       1. Provide self-assessment opportunities to help students recognize and address gaps in their learning.\n2. Human-centred assessment\n    1. Future activities\n       1. Collaborate with learners to devise alternate methods of assessing their progress and learning in relation to the outcomes.\n    2. Future self\n       1. Meet with each learner for assessment conversations to better understand their contexts and gaps in understanding. \n    3. Community\n       1. Implement double-attempt tests where learners first  complete the test alone, and then work through the test with their learning pod.\n3. Fairness\n     1. Potential harms\n        1. Analyze test results for evidence of differential results between identifiable groups (ethnicity, gender).\n     2. Academic Integrity\n        1. Reduce learners' test anxiety by allowing them to prepare and use notecards during exams.\n4. Assessment Design\n     1. Measurement Theory\n        1. Scale your grades so that they are more in line with your colleagues'.\n     2. Feedback Design\n        1. Provide more opportunities for learners to receive and respond to feedback.\n5. Technology\n     1. Instructor Workload\n        1. Implement automated feedback quizzes to help learners prepare for exams.\n     2. Digital Literacy\n        1. Ensure that any digital technologies you use are not causing lower performance.\n     3. Modality\n        1. Provide an asynchronous backchannel for learners to use for support.\n\n-->\n```\n### Multi-access Collaboration {.unnumbered}\n\n{==Likely drop this. ==}{\\>\\>\\<\\<} You teach a course which requires collaboration between learners. Some learners are able to attend class on campus, others can attend synchronously from off-campus, and still others can only attend asynchronously. About half of the remote learners live internationally.\n\n| Primary Construct | Secondary Construct | Description |\n| --- | --- | --- |\n|Assessment Purpose | Assessment of learning | Grade each bi-weekly assignment. | | | Assessment for learning | Read a subset of bi-weekly assignments, identify and share performance trends with the whole class. | | | Assessment as learning | Ask students to self-assess their bi-weekly assignments using evaluative criteria. | | Duty of Care | Bias | Examine assessment results to ensure subgroups are not assigned systematically higher or lower grades | | | Inclusion | Avoid software that may make it difficult for equity-deserving populations to participate. | | | Relationship | Ensure that learning pods consist of people from all modalities (synchronous and asynchronous). | | | Ethical EdTech | | | Technology Acceptance | Performance Expectancy | | | | Effort Expectancy | | | | Social Influences | | | | Facilitating Conditions | | | Assessment Design | Academic Integrity | Use automated software to check for academic misconduct. | | | Measurement Theory | Examine assessment data to ensure content and construct validity. | | | Relevance | | | | Reciprocity | |\n\n```{=html}\n<!--\n\n1. Purpose\n    1. Assessment of learning\n       1. Ensure that all learners complete the same assessment tasks under the same conditions.\n    2. Assessment for learning\n       1. Meet with learning pods to identify gaps in understanding and how to improve.\n    3. Assessment as learning\n       1. Ensure learning pods are identifying their own gaps in understanding.\n2. Human-centred assessment\n    1. Future activities\n       1. Ensure learners have opportunity to learn collaboration skills in a remote team.\n    2. Future self\n       1. Have students reflect on the importance of international collaborations.\n    3. Community\n       1. Ensure that learning pods consist of people from all modalities (synchronous and asynchronous).\n3. Fairness\n    1. Potential harms\n       1. Provide alternative assignment structures for learners who are unable to engage with digital tools.\n    2. Academic Integrity\n       1. Provide resources to empower learning pods to ensure that their work is representative of their level of ability or knowledge.\n4. Assessment Design\n    1. Measurement Theory\n       1. Ensure that all assignments and tasks are aligned with course learning outcomes.\n    2. Feedback Design\n       1. Provide clear rubrics to allow learning pods to evaluate their own progress towards learning outcomes. \n5. Technology\n    1. Instructor Workload\n       1. Have learners engage in peer-review prior to presenting their final draft.\n    2. Digital Literacy\n       1. Ensure that learners feel competent in using the technology required to connect with temporally or geographically remote peers.\n    3. Modality\n       1. Enact reasonably flexible policies around due dates to account for different modalities of participation.\n\n-->\n```\n29. Below are a number of statements about assessment. Please indicate your level of agreement with each statement (1=strongly disagree; 2=disagree; 3=somewhat disagree; 4=somewhat agree; 5=agree; 6=strongly agree). There are no right or wrong answers. We are interested in your honest opinions about assessment. If you do not understand the statement, select 'Don't Know.'\n\n|                                                                                                                                     | Strongly disagree | Disagree | Somewhat disagree | Somewhat agree | Agree | Strongly agree | Don't know |\n\n|--\\>--\\>--\\>|--\\>--\\>--\\>|--\\>--\\>--\\>|--\\>--\\>--\\>|--\\>--\\>--\\>|--\\>--\\>--\\>|--\\>--\\>--\\>|--\\>--\\>--\\>| | The primary purpose of assessment is to assign a grade to student work. | | | | | | | | | Assessment should be used to determine if students have met program standards. | | | | | | | | | Feedback from assessment improves student learning. | | | | | | | | | By using assessment, instructors can track the progress of students. | | | | | | | | | Students should use assessment to evaluate their own work. | | | | | | | | | Students are able to provide accurate and useful feedback to each other. | | | | | | | | | Instructors have the skills and knowledge to construct good assessments. | | | | | | | | | For good assessment, instructors need extensive knowledge of the subject matter. | | | | | | | | | Assessment involves judging a student’s performance in relation to a set of goals/standards/criteria. | | | | | | | | | The results of assessment should inform future teaching. | | | | | | | | | Assessment results should be used to provide evidence of student progress for administrative purposes. | | | | | | | | | Assessment is useful when reporting a student's achievement/progress to department heads and administration. | | | | | | | | | An important component of assessment is preparing students for large-scale tests (e.g., certification, licensing, MCAT, LSAT, GRE). | | | | | | | | | All students should achieve a minimum score on a standardized entrance exam as part of admission to higher education. | | | | | | | | | All assessments should be adapted for students with identified accommodation needs. | | | | | | | | | Students with exceptionalities should be provided with different assessments than other students. | | | | | | | | | Instructors should offer choice in their assessments based on students’ learning needs. | | | | | | | | | Assessment helps instructors identify individual students’ learning needs. | | | | | | | | | Assessment results provide reliable information. | | | | | | | | | Assessment involves instructors making judgements about how well a student is learning in relation to other students. | | | | | | | | | Assessment results are a good indicator of the quality of a program. | | | | | | | | | Assessment results reflect the quality of teaching. | | | | | | | | | Assessment is an imprecise process. | | | | | | | | | Observing students is a valid form of assessment. | | | | | | | | | Assessment is of little use to instructors on a day-to-day basis. | | | | | | | | | Assessment interrupts students’ learning. | | | | | | | | | Assessment is a stressful activity for students. | | | | | | | | | Assessment takes time away from teaching. | | | | | | | | | Instructors use too many assessments. | | | | | | | | | Assessment is a positive force for improving classroom culture. | | | | | | | | | Assessments motivate students to do their best. | | | | | | | | | Assessment is a positive experience for students. | | | | | | | |\n\n```{=html}\n<!--\n## Possible Orientations {-}\n\n### Tool-centred {-}\n\n- focus on using tools for efficient administration of assessments of learning\n\n### Human-centred {-}\n\n- focus on amplifying human capabilities and characteristics\n- concerned with ethical technologies and ethical use of technologies\n\n### Compliance-centred {-}\n\n-->\n```\n\n## Funding and Support\n\nThis  research  was supported by the  BCcampus  Research  Fellows  Program, which provides B.C. post-secondary educators and students with funding to conduct small-scale research on teaching and learning, as well as explore evidence-based teaching practices that focus on student success and learning.\n\n## References {.unnumbered}\n\n::: {#refs}\n:::\n\n\n\n<!--\n## Consolidating\n::: r-hstack\n::: {data-id=\"box1\" auto-animate-delay=\"0\" style=\"background: #5EC962; width: 200px; height: 150px; border-radius: 30px; margin: 10px; font-color: #ffffff;\" title=\"Workload;\"}\n:::\nWorkload\n\n::: {data-id=\"box2\" auto-animate-delay=\"0.1\" style=\"background: #21918C; width: 200px; height: 150px; border-radius: 30px; margin: 10px;\" title=\"Efficiency;\"}\n:::\nEfficiency\n:::\n\n## Consolidating {auto-animate=\"true\" auto-animate-easing=\"ease-in-out\"}\n\n::: r-hstack\n::: {data-id=\"box1\" auto-animate-delay=\"0\" style=\"background: #5EC962; width: 200px; height: 150px; border-radius: 30px; margin: 10px; font-color: #ffffff;\" title=\"Technology Acceptance;\"}\n\n:::\n\n::: {data-id=\"box2\" auto-animate-delay=\"0.1\" style=\"background: #21918C; width: 200px; height: 150px; border-radius: 30px; margin: 10px;\"}\n\n:::\n:::\n\n\n##  {auto-animate=\"true\" auto-animate-easing=\"ease-in-out\"}\n\n::: r-stack\n::: {data-id=\"box1\" style=\"background: #ffffff; width: 200px; height: 150px; border-radius: 30px; margin: 10px;\"}\n:::\n\n::: {data-id=\"box2\" auto-animate-delay=\"0.1\" style=\"background: #21918C; width: 200px; height: 150px; border-radius: 30px; margin: 10px;\" title=\"Technology Acceptance\"}\n\n:::\n:::\n\n## test\n::: r-hstack\n::: {data-id=\"box1\" auto-animate-delay=\"0\" style=\"background: #21918C; width: 200px; height: 150px; border-radius: 30px; margin: 10px; font-color: #ffffff;\" title=\"Technology Acceptance\"}\n:::\n:::\nTechnology Acceptance\n\n-->\n","srcMarkdownNoYaml":"\n\n## Developing the Technology-integrated Assessment Scale\n\n## Acknowledgements\n\nOur team is spread across most of the country and we each live and work on land that has been cared for by Indigenous people for millenia. We each acknowledge that our abundant lives were made possible because of the displacement of the original stewards of the land.\n\n::: {.notes}\n\n:::\n\n# Background\n\n## OTESSA24\n\n### [Evolving our understanding of technology-integrated assessment: A review of the literature and development of a new framework](https://cmadland.github.io/slides/posts/deck-otessa24)\n\n\n## Two Papers\n\n- Madland, C., Irvine, V., DeLuca, C., & Bulut, O. (2024b). Technology-Integrated Assessment: A Literature Review. *The Open/Technology in Education, Society, and Scholarship Association Journal, 4*(1), 1–48. <https://doi.org/10.18357/otessaj.2024.4.1.57>\n\n- Madland, C., Irvine, V., DeLuca, C., & Bulut, O. (2024a). Developing the Technology-Integrated Assessment Framework. *The Open/Technology in Education, Society, and Scholarship Association Journal, 4*(1), 1–19. <https://doi.org/10.18357/otessaj.2024.4.1.63>\n\n\n\n# Technology-integrated Assessment Framework (TIAF)\n\n## 4 Components\n\n::: r-vstack\n::: {data-id=\"box1\" auto-animate-delay=\"0\" style=\"background: #5EC962; width: 50px; height: 50px; border-radius: 30px; margin: 10px;\" title=\"Assessment Design\"}\n:::\nAssessment Design\n\n::: {data-id=\"box2\" auto-animate-delay=\"0.1\" style=\"background: #21918C; width: 50px; height: 50px; border-radius: 30px; margin: 10px;\" title=\"Technology Acceptance\"}\n:::\nTechnology Acceptance\n\n::: {data-id=\"box3\" auto-animate-delay=\"0.2\" style=\"background: #3B528B; width: 50px; height: 50px; border-radius: 30px; margin: 10px;\" title=\"Duty of Care\"}\n:::\nDuty of Care\n\n::: {data-id=\"box4\" auto-animate-delay=\"0.3\" style=\"background: #440154; width: 50px; height: 50px; border-radius: 30px; margin: 10px;\" title=\"Purposes of Assessment\"}\n:::\nPurposes of Assessment\n:::\n\n##  {auto-animate=\"true\" auto-animate-easing=\"ease-in-out\"}\n\n::: r-hstack\n::: {data-id=\"box1\" auto-animate-delay=\"0\" style=\"background: #5EC962; width: 50px; height: 50px; border-radius: 30px; margin: 10px;\" title=\"Assessment Design\"}\n:::\n\n::: {data-id=\"box2\" auto-animate-delay=\"0.1\" style=\"background: #21918C; width: 50px; height: 50px; border-radius: 30px; margin: 10px;\" title=\"Technology Acceptance\"}\n:::\n\n::: {data-id=\"box3\" auto-animate-delay=\"0.2\" style=\"background: #3B528B; width: 50px; height: 50px; border-radius: 30px; margin: 10px;\" title=\"Duty of Care\"}\n:::\n\n::: {data-id=\"box4\" auto-animate-delay=\"0.3\" style=\"background: #440154; width: 50px; height: 50px; border-radius: 30px; margin: 10px;\" title=\"Purposes of Assessment\"}\n:::\n:::\n\n##  {auto-animate=\"true\" auto-animate-easing=\"ease-in-out\"}\n\n::: r-stack\n::: {data-id=\"box1\" style=\"background: #5EC962; width: 600px; height: 600px; border-radius: 300px;\" title=\"Assessment Design\"}\n:::\n\n::: {data-id=\"box2\" style=\"background: #21918C; width: 450px; height: 450px; border-radius: 300px;\" title=\"Technology Acceptance\"}\n:::\n\n::: {data-id=\"box3\" style=\"background: #3B528B; width: 300px; height: 300px; border-radius: 300px;\" title=\"Duty of Care\"}\n:::\n\n::: {data-id=\"box4\" style=\"background: #440154; width: 150px; height: 150px; border-radius: 300px;\" title=\"Purposes of Assessment\"}\n:::\n:::\n\n## \n\n![Full Model](tiaf-q-full.drawio.png)\n\n## Alt-View\n```{mermaid}\nflowchart TD\nclassDef purpose fill:#440154,color:#fff,stroke:#440154,stroke-width:4px\nclassDef duty fill:#3B528B,color:#fff,stroke:#3B528B,stroke-width:4px\nclassDef accept fill:#21918c,color:#fff,stroke:#21918c,stroke-width:4px\nclassDef design fill:#5EC962,color:#000,stroke:#5EC962,stroke-width:4px\n  A[Technology-Integrated Assessment] --- B(Assessment Purpose)\n  A(Technology-Integrated Assessment) --- C(Duty of Care)\n  A(Technology-Integrated Assessment) --- D(Technology Acceptance)\n  A(Technology-Integrated Assessment) --- E(Assessment Design)\n  B --- F([Assessment of Learning]) --- G([Assessment for Learning]) --- H([Assessment as Learning])\n  C --- I([Bias]) --- J([Inclusion]) --- K([Relationships]) --- L([Ethical EdTech])\n  D --- M([Performance Expectancy]) --- N([Effort Expectancy]) --- O([Social Influence]) --- P([Facilitating Conditions])\n  E --- Q([Measurement Theory]) --- R([Academic Integrity]) --- S([Relevance]) --- T([Reciprocity])\n  class B,F,G,H purpose\n  class C,I,J,K,L duty\n  class D,M,N,O,P accept\n  class E,Q,R,S,T design\n\n```\n\n## Differentiation\n\n- 5Rs of Indigenous Education\n  - Respect\n  - Relevance\n  - Reciprocity\n  - Responsibility\n  - Relationship\n\n---\n\n## Differentiation\n\n- Duty of Care\n  - Bias\n  - Inclusion\n  - Relationships\n  - Ethical EdTech\n\n---\n\n## Differentiation\n\n- Technology Acceptance\n  - Performance Expectancy\n  - Effort Expectancy\n  - Social Influence\n  - Facilitating Conditions\n\n---\n\n# Analysis\n\n---\n\n## Exploratory Factor Analysis\n\n- specify constructs\n- identify parameters\n- generate and refine items\n- content validity\n\n---\n\n# [Table of Specifications](https://cmadland.github.io/slides/posts/otessa25-specs/)\n\n---\n\n# [Parameters](https://cmadland.github.io/slides/posts/otessa25-specs/#parameters-rough-sample)\n\n::: {.callout}\nNote: Archived /WIP/\n\n:::\n---\n\n# Draft Questions\n\n## Part B: Scenario-Based Questions {.unnumbered}\n\nYou will be presented with five scenarios in this section. Each scenario has 15 actions. For each action, please identify how likely you are to do each of the following as part of your overall response to the scenario (1=highly unlikely; 2=unlikely; 3=somewhat unlikely; 4=somewhat likely; 5=likely; 6=highly likely).\n\nPlease interpret the scenario in relation to your current teaching context; if you teach across contexts, select one context and keep this context in mind when completing the entire survey. There are no right or wrong answers. We are interested in your honest responses to the scenarios. If you do not understand the statement, select 'Don't Know.'\n\n### Large Enrolment Course {.unnumbered}\n\nYou are teaching a large enrollment course. The students will be submitting bi-weekly assignments, a midterm exam, and a culminating assignment all designed to support their learning and submitted in the institurional LMS. (ACAI-HE)\n\nHow might the following influence your decision whether or not to use technology in this situation? (1=Much less likely to use technology - 6 = Much more likely to use technology)\n\n| Primary Construct | Secondary Construct | Description |\n| --- | --- | --- |\n|Technology Acceptance | Performance Expectancy | You have confidence that the technology will work as expected. | | | Effort Expectancy | The technology will require more time to set up and use than not using technology. | | | Social Influences | A trusted colleague has told you that you should use the technology. | | | Facilitating Conditions | You are confident that you will be able to get technical support in a timely manner. |\n\nPresuming you decide to use technology, how likely are you to take the following actions in this situation?\n\n| Primary Construct | Secondary Construct | Description |\n| --- | --- | --- |\n|Assessment Purpose | Assessment of learning | Grade each bi-weekly assignment. | | | Assessment for learning | Read a subset of bi-weekly assignments, identify and share performance trends with the whole class. | | | Assessment as learning | Ask students to self-assess their bi-weekly assignments using evaluative criteria. | | Duty of Care | Bias | Examine assessment results to ensure subgroups are not assigned systematically higher or lower grades | | | Inclusion | Avoid software that may make it difficult for equity-deserving populations to participate. | | | Relationship | Organize learners into learning pods of 3-5 for peer support and learning. | | | Ethical EdTech | Ensure that software used in class does not contribute to learner anxiety. | | Assessment Design | Academic Integrity | Use automated software to check for academic misconduct. | | | Measurement Theory | Examine assessment data to ensure content and construct validity. | | | Relevance | Ensure that assessment strategies are relevant to learners' contexts. | | | Reciprocity | Use learning pods to engage in peer-review and feedback. |\n\n```{=html}\n<!--\n1. Purpose\n  1. Assessment of learning\n     1. Grade each bi-weekly assignment.\n  2. Assessment for learning\n     1. Read a subset of bi-weekly assignments, identify and share performance trends with the whole class.\n  3. Assessment as learning\n     1. Ask students to self-assess their bi-weekly assignments using evaluative criteria.\n2. Human-centred assessment\n  1. Future activities\n     1. Ensure that learners respond to assignments in the context of their future career goals.\n  2. Future self\n     1. Provide opportunities for learners to choose from 3-4 different ways to represent their learning in relation to outcomes and their future goals.\n  3. Community\n     1. Organize learners into learning pods of 3-5 for peer support and learning.\n3. Fairness\n  1. Potential harms\n     1. Avoid software that may make it difficult for equity-deserving populations to participate.\n  2. Academic Integrity\n     1. Use automated software to check for academic misconduct.\n4. Assessment Design\n  1. Measurement Theory\n     1. Examine assessment data to ensure consistency.\n  2. Feedback Design\n     1. Use learning pods to engage in peer-review and feedback.\n5. Technology\n  1. Instructor Workload\n     1. Maximize instructor effort through the implementation of relevant technology.\n  2. Digital Literacy\n     1. Ensure that all stakeholders are able tounderstand and use required technologies safely, ethically, and effectively.\n  3. Modality\n     1. Enable access to synchronous and asynchronous participation.\n\n-->\n```\n### Generative Artificial Intelligence (GenAI) {.unnumbered}\n\nAn assignment in your course requires learners to write a 2000 word essay and your department has requested that each instructor develop an assessment strategy in light of generative AI tools (ChatGPT, Google Bard).\n\nHow might the following influence your decision whether or not to use technology in this situation? (1=Much less likely to use technology - 6 = Much More likely to use technology)\n\n```{=html}\n<!--\n//todo #269\n-->\n```\n| Primary Construct | Secondary Construct | Description |\n| --- | --- | --- |\n|Technology Acceptance | Performance Expectancy | You have confidence that the technology will work as expected. | | | Effort Expectancy | It is too much work to try to limit the use of generative AI tools, so you allow its use under certain conditions. | | | Social Influences | A trusted colleague has told you that you won't be able to detect AI generated content. | | | Facilitating Conditions | You are confident that you will be able to get support for developing assessment tasks that discourage or prevent the use of generative AI. |\n\nPresuming you decide to use technology, how likely are you to take the following actions in this situation?\n\n| Primary Construct | Secondary Construct | Description |\n| --- | --- | --- |\n|Assessment Purpose | Assessment of learning | Implement a ban on all GenAI tools. | | | Assessment for learning | Allow learners to use GenAI to generate ideas with proper citations and informed consent. | | | Assessment as learning | Collaborate with learners to evaluate the quality of GenAI outputs and the ethics of their use. | | Duty of Care | Bias | Examine assessment results to ensure that learners who used genAI did not score significantly higher or lower than those who did not. | | | Inclusion | Confirm that all learners know how to access and use a genAI tool to assist them. | | | Relationship | Encourage cooperative approaches to learning in learning pods. | | | Ethical EdTech | Provide learners with training on using 'local-only' generative AI tools that they can use to assist their work. | | Assessment Design | Academic Integrity | Require learners to submit papers through software that claims to detect plagiarism and AI-generated writing. | | | Measurement Theory | Examine assessment data to ensure there are no significant grade differences between learners who used generative AI and those who did not. | | | Relevance | Since learners will use generative AI in their careers, ensure that they know how to construct helpful prompts. | | | Reciprocity | Experiment with learners to learn about the capabilities and limitations of generative AI. |\n\n```{=html}\n<!--\n1. Purpose\n  1. Assessment of learning\n     1. Implement a ban on all GenAI tools.\n  2. Assessment for learning\n     1. Allow learners to use GenAI to generate ideas with proper citations and informed consent.\n  3. Assessment as learning\n     1. Collaborate with learners to evaluate the quality of GenAI outputs and the ethics of their use.\n2. Human-centred assessment\n  1. Future activities\n     1. Reflect with learners on the implications of GenAI in their future careers.\n  2. Future self\n     1. Encourage thoughtful engagment with the personal impacts of GenAI on individual learners.\n  3. Community\n     1. Encourage cooperative approaches to learning in learning pods. \n3. Fairness\n  1. Potential harms\n     1. Ensure learners understand the human and environmental costs of GenAI tools.\n  2. Academic Integrity\n     1. Require learners to submit appers through software that claims to detect plagiarism and AI-generated writing. \n4. Assessment Design\n  1. Measurement Theory\n     1. Use genAI to help you evaluate learners' papers.\n  2. Feedback Design\n     1. Require learning pods to evaluate the quality of their work against both human-written and AI-generated samples.\n5. Technology\n  1. Instructor Workload\n     1. Use AI tools to provide feedback on learner products.\n  2. Digital Literacy\n     1. Encourage the use of AI-powered tools to assist the process of writing the paper, rather than creating the final product.\n  3. Modality\n     1. Require evidence of interactions in learning pods to make the learning process more visible.\n\n-->\n```\n### Plagiarism Detection and Remote Proctoring {.unnumbered}\n\nYou teach a course with multiple sections taught by various instructors. Your department head has noticed that you are the only instructor who does not use plagiarism detection software (Turnitin) or remote proctoring (Proctorio, or ProctorU)\n\nHow might the following influence your decision whether or not to use technology in this situation? (1=Much less likely to use technology - 6 = Much More likely to use technology)\n\n| Primary Construct | Secondary Construct | Description |\n| --- | --- | --- |\n|Technology Acceptance | Performance Expectancy | You learn that surveillance tools have a high error rate. | | | Effort Expectancy | You learn that instructors who use surveillance technologies spend less time grading than you do. | | | Social Influences | A trusted colleague has sent you an article on the privacy concerns related to surveillance technologies. | | | Facilitating Conditions | You are confident that you will be able to get support for developing assessment tasks that discourage or prevent academically dishonest assignment submissions. |\n\nPresuming you decide to use technology, how likely are you to take the following actions in this situation?\n\n| Primary Construct | Secondary Construct | Description |\n| --- | --- | --- |\n|Assessment Purpose | Assessment of learning | Implement the use of tools that claim to detect plagiarism or cheating on exams. | | | Assessment for learning | Advocate for department standards that prioritize feedback processes over technology-centric policing of academic misconduct. | | | Assessment as learning | Encourage learners to develop workflows that document and make the process of their learning visible. | | Duty of Care | Bias | Evaluate with learners the equity implications of using technology-centric policing of academic misconduct. | | | Inclusion | Decline to use technology to police academic misconduct due to concerns about unequal access to appropriate learning resources or tools. | | | Relationship | Encourage learning pods to review each others' work for quality and compliance to standards of academic writing. | | | Ethical EdTech | Only use technology tools that protect learner anonymity. | | Assessment Design | Academic Integrity | Structure your course to minimize the likelihood of academic misconduct. | | | Measurement Theory | Examine assessment data to ensure that measures to promote academic honesty do not introduce construct irrelevant variance. | | | Relevance | Ensure that assessment tasks are relevant to learners' contexts and community as a strategy to reduce academic dishonesty. | | | Reciprocity | Host a conversation with learners to discuss the importance of academic honesty for the entire higher education community. |\n\n```{=html}\n<!--\n1. Purpose\n  1. Assessment of learning\n     1. Implement the use of tools that claim to detect plagiarism or cheating on exams.\n  2. Assessment for learning\n     1. Advocate for department standards that prioritize feedback processes over technology-centric policing of academic misconduct.\n  3. Assessment as learning\n       1. Encourage learners to develop workflows that document and make the process of their learning visible.\n2. Human-centred assessment\n    1. Future activities\n       1. Discuss with learners how they can protect themselves from accusations of academic misconduct.\n    2. Future self\n       1. Have learners consider the implications of relying on digital algorithms to determine ethical behaviour.\n    3. Community\n       1. Encourage learning pods to review each others' work for quality and compliance to standards of academic writing.\n3. Fairness\n    1. Potential harms\n       1. Evaluate with learners the privacy and equity implications of using technology-centric policing of academic misconduct.\n    2. Academic Integrity\n       1. Structure your course to minimize the likelihood of academic misconduct.\n4. Assessment Design\n    1. Measurement Theory\n       1. Ensure proper alignment between course outcomes, learning activities, and assessment tasks.\n    2. Feedback Design\n       1. Ensure learners receive ample formative feedback during the process of the course.\n5. Technology\n    1. Instructor Workload\n       1. Use technology tools to reduce the time required to detect academic misconduct.\n    2. Digital Literacy\n       1. Provide professional development resources for your colleagues regarding the implictions of technology-centric policing of academic misconduct.\n    3. Modality\n       1. Create multiple avenues for access to your course to ease pressure on learners who have difficulty attending on-campus.\n-->\n```\n### Orientations to Assessment and Grading {.unnumbered}\n\nThere are expectations in your department that grades should be distributed across the grading scale. However, your class averages are consistently lower than your colleagues’. Your course assessment scheme includes two term exams and one final exam. (ACAI-HE)\n\nHow might the following influence your decision whether or not to use technology in this situation? (1=Much less likely to use technology - 6 = Much More likely to use technology)\n\n```{=html}\n<!--\n//todo #268\n-->\n```\n| Primary Construct | Secondary Construct | Description |\n| --- | --- | --- |\n|Technology Acceptance | Performance Expectancy | You learn about an assessment method that uses technology to increase the accuracy of your grades. | | | Effort Expectancy | You learn about an assessment method that will require you to learn how to use a new technology tool. | | | Social Influences | A trusted colleague shares how they used technology to prepare their learners for an exam. | | | Facilitating Conditions | There are help resources built in to a technology-integrated assessment tool. |\n\nPresuming you decide to use technology, how likely are you to take the following actions in this situation?\n\n| Primary Construct | Secondary Construct | Description |\n| --- | --- | --- |\n|Assessment Purpose | Assessment of learning | Provide students with additional graded assessments to chunk learning into smaller units. | | | Assessment for learning | Provide students with additional opportunities to check their understanding throughout the course (e.g., ungraded quizzes, exit slips). | | | Assessment as learning | Provide self-assessment opportunities to help students recognize and address gaps in their learning. | | Duty of Care | Bias | Analyze test results for evidence of differential results between identifiable groups (ethnicity, gender). | | | Inclusion | Provide learners with multiple options for demonstrating their achievement in relation to the learning outcomes. | | | Relationship | Implement double-attempt tests where learners first complete the test alone, and then work through the test with their learning pod. | | | Ethical EdTech | Ensure that any technology you use in your assessment allows learners to export their work in a usable format. | | Assessment Design | Academic Integrity | Reduce learners' test anxiety by allowing them to prepare and use note cards during exams. | | | Measurement Theory | Use technology to adjust grades upwards to match other sections. | | | Relevance | Ensure that items on your exams are standardized across sections to increase reliability. | | | Reciprocity | Ensure learners complete assessment tasks individually and without external assistance. |\n\n```{=html}\n<!--\n1. Purpose\n    1. Assessment of learning\n       1. Provide students with additional graded assessments to chunk learning into smaller units.\n    2. Assessment for learning\n       1. Provide students with additional opportunities to check their understanding throughout the course (e.g., ungraded quizzes, exit slips).\n    3. Assessment as learning\n       1. Provide self-assessment opportunities to help students recognize and address gaps in their learning.\n2. Human-centred assessment\n    1. Future activities\n       1. Collaborate with learners to devise alternate methods of assessing their progress and learning in relation to the outcomes.\n    2. Future self\n       1. Meet with each learner for assessment conversations to better understand their contexts and gaps in understanding. \n    3. Community\n       1. Implement double-attempt tests where learners first  complete the test alone, and then work through the test with their learning pod.\n3. Fairness\n     1. Potential harms\n        1. Analyze test results for evidence of differential results between identifiable groups (ethnicity, gender).\n     2. Academic Integrity\n        1. Reduce learners' test anxiety by allowing them to prepare and use notecards during exams.\n4. Assessment Design\n     1. Measurement Theory\n        1. Scale your grades so that they are more in line with your colleagues'.\n     2. Feedback Design\n        1. Provide more opportunities for learners to receive and respond to feedback.\n5. Technology\n     1. Instructor Workload\n        1. Implement automated feedback quizzes to help learners prepare for exams.\n     2. Digital Literacy\n        1. Ensure that any digital technologies you use are not causing lower performance.\n     3. Modality\n        1. Provide an asynchronous backchannel for learners to use for support.\n\n-->\n```\n### Multi-access Collaboration {.unnumbered}\n\n{==Likely drop this. ==}{\\>\\>\\<\\<} You teach a course which requires collaboration between learners. Some learners are able to attend class on campus, others can attend synchronously from off-campus, and still others can only attend asynchronously. About half of the remote learners live internationally.\n\n| Primary Construct | Secondary Construct | Description |\n| --- | --- | --- |\n|Assessment Purpose | Assessment of learning | Grade each bi-weekly assignment. | | | Assessment for learning | Read a subset of bi-weekly assignments, identify and share performance trends with the whole class. | | | Assessment as learning | Ask students to self-assess their bi-weekly assignments using evaluative criteria. | | Duty of Care | Bias | Examine assessment results to ensure subgroups are not assigned systematically higher or lower grades | | | Inclusion | Avoid software that may make it difficult for equity-deserving populations to participate. | | | Relationship | Ensure that learning pods consist of people from all modalities (synchronous and asynchronous). | | | Ethical EdTech | | | Technology Acceptance | Performance Expectancy | | | | Effort Expectancy | | | | Social Influences | | | | Facilitating Conditions | | | Assessment Design | Academic Integrity | Use automated software to check for academic misconduct. | | | Measurement Theory | Examine assessment data to ensure content and construct validity. | | | Relevance | | | | Reciprocity | |\n\n```{=html}\n<!--\n\n1. Purpose\n    1. Assessment of learning\n       1. Ensure that all learners complete the same assessment tasks under the same conditions.\n    2. Assessment for learning\n       1. Meet with learning pods to identify gaps in understanding and how to improve.\n    3. Assessment as learning\n       1. Ensure learning pods are identifying their own gaps in understanding.\n2. Human-centred assessment\n    1. Future activities\n       1. Ensure learners have opportunity to learn collaboration skills in a remote team.\n    2. Future self\n       1. Have students reflect on the importance of international collaborations.\n    3. Community\n       1. Ensure that learning pods consist of people from all modalities (synchronous and asynchronous).\n3. Fairness\n    1. Potential harms\n       1. Provide alternative assignment structures for learners who are unable to engage with digital tools.\n    2. Academic Integrity\n       1. Provide resources to empower learning pods to ensure that their work is representative of their level of ability or knowledge.\n4. Assessment Design\n    1. Measurement Theory\n       1. Ensure that all assignments and tasks are aligned with course learning outcomes.\n    2. Feedback Design\n       1. Provide clear rubrics to allow learning pods to evaluate their own progress towards learning outcomes. \n5. Technology\n    1. Instructor Workload\n       1. Have learners engage in peer-review prior to presenting their final draft.\n    2. Digital Literacy\n       1. Ensure that learners feel competent in using the technology required to connect with temporally or geographically remote peers.\n    3. Modality\n       1. Enact reasonably flexible policies around due dates to account for different modalities of participation.\n\n-->\n```\n29. Below are a number of statements about assessment. Please indicate your level of agreement with each statement (1=strongly disagree; 2=disagree; 3=somewhat disagree; 4=somewhat agree; 5=agree; 6=strongly agree). There are no right or wrong answers. We are interested in your honest opinions about assessment. If you do not understand the statement, select 'Don't Know.'\n\n|                                                                                                                                     | Strongly disagree | Disagree | Somewhat disagree | Somewhat agree | Agree | Strongly agree | Don't know |\n\n|--\\>--\\>--\\>|--\\>--\\>--\\>|--\\>--\\>--\\>|--\\>--\\>--\\>|--\\>--\\>--\\>|--\\>--\\>--\\>|--\\>--\\>--\\>|--\\>--\\>--\\>| | The primary purpose of assessment is to assign a grade to student work. | | | | | | | | | Assessment should be used to determine if students have met program standards. | | | | | | | | | Feedback from assessment improves student learning. | | | | | | | | | By using assessment, instructors can track the progress of students. | | | | | | | | | Students should use assessment to evaluate their own work. | | | | | | | | | Students are able to provide accurate and useful feedback to each other. | | | | | | | | | Instructors have the skills and knowledge to construct good assessments. | | | | | | | | | For good assessment, instructors need extensive knowledge of the subject matter. | | | | | | | | | Assessment involves judging a student’s performance in relation to a set of goals/standards/criteria. | | | | | | | | | The results of assessment should inform future teaching. | | | | | | | | | Assessment results should be used to provide evidence of student progress for administrative purposes. | | | | | | | | | Assessment is useful when reporting a student's achievement/progress to department heads and administration. | | | | | | | | | An important component of assessment is preparing students for large-scale tests (e.g., certification, licensing, MCAT, LSAT, GRE). | | | | | | | | | All students should achieve a minimum score on a standardized entrance exam as part of admission to higher education. | | | | | | | | | All assessments should be adapted for students with identified accommodation needs. | | | | | | | | | Students with exceptionalities should be provided with different assessments than other students. | | | | | | | | | Instructors should offer choice in their assessments based on students’ learning needs. | | | | | | | | | Assessment helps instructors identify individual students’ learning needs. | | | | | | | | | Assessment results provide reliable information. | | | | | | | | | Assessment involves instructors making judgements about how well a student is learning in relation to other students. | | | | | | | | | Assessment results are a good indicator of the quality of a program. | | | | | | | | | Assessment results reflect the quality of teaching. | | | | | | | | | Assessment is an imprecise process. | | | | | | | | | Observing students is a valid form of assessment. | | | | | | | | | Assessment is of little use to instructors on a day-to-day basis. | | | | | | | | | Assessment interrupts students’ learning. | | | | | | | | | Assessment is a stressful activity for students. | | | | | | | | | Assessment takes time away from teaching. | | | | | | | | | Instructors use too many assessments. | | | | | | | | | Assessment is a positive force for improving classroom culture. | | | | | | | | | Assessments motivate students to do their best. | | | | | | | | | Assessment is a positive experience for students. | | | | | | | |\n\n```{=html}\n<!--\n## Possible Orientations {-}\n\n### Tool-centred {-}\n\n- focus on using tools for efficient administration of assessments of learning\n\n### Human-centred {-}\n\n- focus on amplifying human capabilities and characteristics\n- concerned with ethical technologies and ethical use of technologies\n\n### Compliance-centred {-}\n\n-->\n```\n\n## Funding and Support\n\nThis  research  was supported by the  BCcampus  Research  Fellows  Program, which provides B.C. post-secondary educators and students with funding to conduct small-scale research on teaching and learning, as well as explore evidence-based teaching practices that focus on student success and learning.\n\n## References {.unnumbered}\n\n::: {#refs}\n:::\n\n\n\n<!--\n## Consolidating\n::: r-hstack\n::: {data-id=\"box1\" auto-animate-delay=\"0\" style=\"background: #5EC962; width: 200px; height: 150px; border-radius: 30px; margin: 10px; font-color: #ffffff;\" title=\"Workload;\"}\n:::\nWorkload\n\n::: {data-id=\"box2\" auto-animate-delay=\"0.1\" style=\"background: #21918C; width: 200px; height: 150px; border-radius: 30px; margin: 10px;\" title=\"Efficiency;\"}\n:::\nEfficiency\n:::\n\n## Consolidating {auto-animate=\"true\" auto-animate-easing=\"ease-in-out\"}\n\n::: r-hstack\n::: {data-id=\"box1\" auto-animate-delay=\"0\" style=\"background: #5EC962; width: 200px; height: 150px; border-radius: 30px; margin: 10px; font-color: #ffffff;\" title=\"Technology Acceptance;\"}\n\n:::\n\n::: {data-id=\"box2\" auto-animate-delay=\"0.1\" style=\"background: #21918C; width: 200px; height: 150px; border-radius: 30px; margin: 10px;\"}\n\n:::\n:::\n\n\n##  {auto-animate=\"true\" auto-animate-easing=\"ease-in-out\"}\n\n::: r-stack\n::: {data-id=\"box1\" style=\"background: #ffffff; width: 200px; height: 150px; border-radius: 30px; margin: 10px;\"}\n:::\n\n::: {data-id=\"box2\" auto-animate-delay=\"0.1\" style=\"background: #21918C; width: 200px; height: 150px; border-radius: 30px; margin: 10px;\" title=\"Technology Acceptance\"}\n\n:::\n:::\n\n## test\n::: r-hstack\n::: {data-id=\"box1\" auto-animate-delay=\"0\" style=\"background: #21918C; width: 200px; height: 150px; border-radius: 30px; margin: 10px; font-color: #ffffff;\" title=\"Technology Acceptance\"}\n:::\n:::\nTechnology Acceptance\n\n-->\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","incremental":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.6.8","auto-stretch":true,"bibliography":["../../refs.bib"],"csl":"../../apa.csl","title-block-banner":true,"title":"OTESSA25","author":"Colin Madland<sup>1</sup>, Valerie Irvine<sup>1</sup>, Christopher DeLuca<sup>2</sup>, and Okan Bulut<sup>3</sup>","institute":"<sup>1</sup>University of Victoria, <sup>2</sup>Queens University, <sup>3</sup>University of Alberta","date":"2025-06-05","logo":"otessa-logo-CS6.png","footer":"Special thanks to BCcampus","multiplex":true,"theme":"night"}}},"projectFormats":["html"]}