@misc{@zoomColinmadlandHeyColin2020,
  type = {Tweet},
  title = {@colinmadland {{Hey Colin}}, We'd like to Get to the Bottom of This. {{Would}} You and Your Colleague Be Willing to Meet with Our Virtual Background Engineers to Try to Replicate This Issue? {{Please DM}} Us so We Can Set a Time. {{Thank}} You!},
  author = {{Zoom [@Zoom]}},
  year = {2020},
  month = sep,
  journal = {Twitter},
  urldate = {2022-10-17},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/82MAHGWF/1307405523667484672.html}
}

@article{0194a88ebcee00f4109ad0edb399385d3b718527,
  title = {{{AN INVESTIGATION OF TEACHER EDUCATIONAL MEASUREMENT LITERACY}}},
  author = {Gotch, Chad},
  year = {2012},
  abstract = {Thesis (Ph.D.), Department of Educational Leadership and Counseling Psychology, Washington State University},
  keywords = {No DOI found}
}

@misc{100OurFault,
  title = {`100\% Our Fault': {{Twitter}} Apologizes for `Racist' Photo-Cropping Algorithm as {{Team Woke}} Scores Another Touchdown},
  shorttitle = {`100\% Our Fault'},
  journal = {RT International},
  urldate = {2020-09-22},
  abstract = {A senior Twitter engineer has expressed contrition after a viral thread accused the platform's photo-cropping algorithm of preferring white faces over black ones, in the latest example of `the woke' eating their own.},
  chapter = {World News},
  howpublished = {https://www.rt.com/news/501202-twitter-racist-algorithm-photo-crop/},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/AUVJ3V6R/501202-twitter-racist-algorithm-photo-crop.html}
}

@article{11c2f81298dab9bb716bc57beeb00276da961837,
  title = {Teaching to Assess: {{An}} Evaluation of Assessment Education for Secondary Teacher Candidates},
  author = {Frederking, Daniel M},
  year = {2018},
  doi = {10/gh5k67},
  abstract = {Semantic Scholar extracted view of "Teaching to Assess: An Evaluation of Assessment Education for Secondary Teacher Candidates" by Daniel M Frederking}
}

@article{1231f512970c5db5360eb3fe304be4908e2a4ada,
  title = {Language Assessment Literacy},
  author = {{Inbar-Lourie}, Ofra},
  year = {2012},
  doi = {10/gh5k6r},
  abstract = {Language assessment literacy forms the knowledge base needed to conduct language assessment procedures, that is, to design, administer, interpret, utilize, and report language assessment data for different purposes. The term is derived from the generic assessment literacy concept which refers to the knowledge and skills required for performing assessment-related actions (Stiggins, 1991; Webb, 2002). Language assessment literacy encompasses not only familiarity with tools and procedures for evaluating students' language abilities, but additional components, particularly the ability to render apt feedback so as to effectively direct learners toward setting and reaching future learning targets. Furthermore, assessment literate professionals are also aware of the ethical aspects involved in the assessment process and of the possible ramifications of putting assessment-based decisions into practice, hence consequential validity (Messick, 1989). Keywords: assessment for learning; assessment literacy; classroom assessment; formative assessment; language assessment culture}
}

@article{1eacc72fb0e7e73d1cbbcc2ba71e679e818c6670,
  title = {Language Assessment Training in {{Hong Kong}}: {{Implications}} for Language Assessment Literacy},
  author = {Lam, R.},
  year = {2015},
  journal = {Language Testing},
  volume = {32},
  pages = {169--197},
  doi = {10/gh5k65},
  abstract = {Despite the call for using assessment to promote effective learning, most language teachers remain underprepared to conduct classroom-based formative assessment and interpret the summative assessment information for improving instruction as well as learning. Drawing upon a survey of programme and government documents, interviews, student assessment tasks, and teaching evaluation, this paper aims to explore the overall language assessment training landscape in five Hong Kong teacher education institutions against the backdrop of assessment reforms in primary/secondary school contexts. It specifically attempts to investigate the extent to which two assessment courses may facilitate and/or inhibit the development of pre-service teachers' language assessment literacy in one teacher education institution. Findings indicate that language assessment training in Hong Kong remains inadequate and selected language assessment courses are still unable to bridge the theory-practice gap within the assessment reform context. Implications and recommendations for promoting language assessment literacy are discussed.}
}

@article{1f7ee6278c37702f26e3c3dc35ec22490c74e611,
  title = {Language Assessment Literacy: {{Implications}} for Language Teachers},
  author = {Giraldo, Frank},
  year = {2018},
  journal = {Profile Issues in Teachers' Professional Development},
  volume = {20},
  pages = {179--195},
  doi = {10/gh5k68},
  abstract = {Recently, the applied linguistics field has examined the knowledge, skills, and principles needed for assessment, defined as language assessment literacy. Two major issues in language assessment literacy have been addressed but not fully resolved---what exactly language assessment literacy is and how it differs among stakeholders (e.g., students and teachers). This reflective article reviews assessment literacy from general education experts and language education scholars and shows how the meaning of language assessment literacy has expanded. To add to the discussion of this construct, the article focuses on the specific language assessment literacy for language teachers and proposes a core list of assessment knowledge, skills, and principles for these stakeholders.}
}

@misc{2012ParisOER,
  title = {2012 {{Paris OER Declaration}}},
  urldate = {2018-11-05},
  howpublished = {http://www.unesco.org/new/fileadmin/MULTIMEDIA/HQ/CI/WPFD2009/English\_Declaration.html},
  keywords = {oer,social justice},
  file = {/Users/colin.madland/Zotero/storage/HABPAWK6/English_Declaration.html}
}

@article{36c0130c653fec3cec3b401e0ab868468eb7880d,
  title = {Assessment Literacy of Foreign Language Teachers: {{Findings}} of a European Study},
  author = {Vogt, Karin and Tsagari, Dina},
  year = {2014},
  journal = {Language Assessment Quarterly},
  volume = {11},
  pages = {374--402},
  doi = {10/gh5k7f},
  abstract = {Training of pre- and in-service teachers constitutes one of the most important aspects in the quality assurance of language testing and assessment (LTA). For instance, foreign language (FL) teachers have to deal with standardised tests as well as their own classroom-based assessment procedures. This means they need the necessary expertise that can be provided by training measures. To gauge the current level of FL teachers in LTA literacy and identify their training needs in this area, data from seven European countries were collected in a mixed-methods study that used questionnaires (n = 853) and qualitative data from teacher interviews (n = 63) in selected countries across Europe. Despite the small differences across countries, the results show that only certain elements of teachers' LTA expertise are developed. To compensate for insufficient training, teachers seem to learn about LTA on the job or use teaching materials for their assessment purposes. Teachers overall express a need to receive training across the range of LTA features identified in the study with varying priorities, depending on their local educational contexts.}
}

@article{43009d969ed6f100c16d7d12053a4b847694471b,
  title = {Assessment Literacy for the Language Classroom},
  author = {Fulcher, G.},
  year = {2012},
  journal = {Language Assessment Quarterly},
  volume = {9},
  pages = {113--132},
  doi = {10/gh5k6t},
  abstract = {Language testing has seen unprecedented expansion during the first part of the 21st century. As a result there is an increasing need for the language testing profession to consider more precisely what it means by ``assessment literacy'' and to articulate its role in the creation of new pedagogic materials and programs in language testing and assessment to meet the changing needs of teachers and other stakeholders for a new age. This article describes a research project in which a survey instrument was developed, piloted, and delivered on the Internet to elicit the assessment training needs of language teachers. The results were used to inform the design of new teaching materials and the further development of online resources that could be used to support program delivery. The project makes two significant contributions. First, it provides new empirically derived content for the concept of assessment literacy within which to frame materials development and teaching. Second, it uncovered methodological problems with existing survey techniques that may have impacted upon earlier studies, and solutions to these problems are suggested.}
}

@misc{479LittleWar2018,
  title = {479: {{Little War}} on the {{Prairie}}},
  shorttitle = {479},
  year = {2018},
  month = apr,
  journal = {This American Life},
  urldate = {2019-12-11},
  howpublished = {https://www.thisamericanlife.org/479/transcript},
  file = {/Users/colin.madland/Zotero/storage/9WLX2S6S/transcript.html}
}

@article{4b47fc6992d9e1a4d4d17eb63cb0fad95fee3db2,
  title = {University English Teacher Assessment Literacy: {{A}} Survey-Test Report from China},
  author = {Xu, Y. and Brown, Gavin T. L.},
  year = {2017},
  abstract = {Assessment literacy (AL) is central to the quality of education because competencies in assessing student learning lead to informed decisions. While the AL of university English teachers in China is particularly crucial as they teach the largest group of adult English language learners in the world, it has regrettably remained largely unexplored. The present study subjected an adapted version of the Teacher Assessment Literacy Questionnaire to rigorous psychometric property analyses, and used it to investigate the AL level of Chinese university English teachers (N=891) and the effects of their demographic characteristics on AL performance. Findings reveal a basic level of AL in certain dimensions with limited influence from demographic characteristics. Discussions are centered around validation of the AL instrument, causes for limited AL competence, and key factors that have impacted AL. This study concludes with a reflection of constructing contextually-grounded AL measures and implications for principles, policy and practice of teacher assessment education.},
  keywords = {No DOI found}
}

@article{5052b70aa6d4f96b2706a769454677a412bf5390,
  title = {A Study into Language Assessment Literacy of Preservice English as a Foreign Language Teachers in Turkish Context},
  author = {Sariyildiz, Gamze},
  year = {2018},
  abstract = {Bu arastirma Turkiye'deki bir devlet universitesindeki Ingilizce ogretmen adaylarinin dil degerlendirme okuryazarligini incelemeyi amaclamaktadir. Calisma ayrica Ingilizce ogretmen adaylarinin ogretmen yetistirme programlarinda degerlendirmenin teorisi ve uygulamasi uzerine aldiklari egitimin ne olcude olduguna iliskin goruslerini ve dil degerlendirmesinde ek egitimi ihtiyac olarak gorup gormediklerini bulmayi amaclamaktadir. Bu arastirmanin bir diger amaci da, Ingilizce ogretmen adaylarinin okul deneyimi dersini yabanci dil ogretiminde olcme ve degerlendirme dersine bagli olarak nasil degerlendirdikleridir. Bu amaclar dogrultusunda, bu calismada hem nicel arastirma (anket) hem de nitel arastirma (mulakat) yontemlerinin kullanildigi karma yontemler arastirmasi kullanilmistir. Arastirmanin nicel kismina Orta Dogu Teknik Universitesi'nin Ingiliz Dili Egitimi Anabilim Dali'nda 4.sinifta olan toplam 101 ogretmen adayi, nitel kismina ise 25 kisi katilmistir. Nicel veriler siklik, yuzdeler ve ortalama deger gibi betimsel istatistik yontemi kullanilarak analiz edilmistir. Yari yapilandirilmis gorusmelerden elde edilen nitel verilerin secici kodlama ile analizi yapilmistir. Bulgular, Ingilizce ogretmen adaylarinin dil olcme ve degerlendirmenin farkli alanlarinda aldiklari egitimi yeterli bulmadiklarini ve bu alanlarda ek egitime ihtiyac duyduklarini gostermistir. Mulakat sonuclari, katilimcilarin dil olcme ve degerlendirmedeki teorik bilgilerini ogretmenlik uygulamasinda pratige donusturme firsati bulamadigini ve degerlendirmenin teorisinin ve uygulamasinin okul deneyimi dersinde cok islenmedigini gostermistir. Ayrica, sonuclar katilimcilarin yabanci dil ogretiminde olcme ve degerlendirme dersinin oneminin ve bu dersin onlarin profesyonel gelisimlerine ve dil ogretmenleri olarak gelecekteki uygulamalarina katkilarinin farkinda olduklarini ortaya cikarmistir.},
  keywords = {No DOI found}
}

@article{56ae01467ed63c228a7547f11cf9fc2f1eb94271,
  title = {A Rubric to Track the Development of Secondary Pre-Service and Novice Teachers' Summative Assessment Literacy},
  author = {Edwards, Frances},
  year = {2017},
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {24},
  pages = {205--227},
  doi = {10/gh5k66},
  abstract = {Abstract Teachers require specialised assessment knowledge and skills in order to effectively assess student learning. These knowledge and skills develop over time through ongoing teacher learning and experiences. The first part of this paper presents a Summative Assessment Literacy Rubric (SALRubric) constructed to track the development of secondary science teachers' summative assessment literacy. The analytic rubric consists of 10 dimensions spread across three categories drawn from the literature and context-specific empirical evidence: knowledge of assessment, understanding the context for assessment, and recognising the impact of assessment. The second part of this paper applies the SALRubric in a case study to explore the development of summative assessment literacy of New Zealand secondary science pre-service and novice teachers. An increasing sophistication in these teachers' summative assessment literacy was evident over 20 months albeit in a nuanced manner for individual teachers. The rubric was a very useful tool for evaluating and documenting shifts in teachers' summative assessment literacy over time. Implications of the use of SALRubric are discussed in terms of summative assessment literacy practice and development.}
}

@article{928861c3b03f4f65664a39f04d9803c3560c0baa,
  title = {Classroom Assessment Literacy for {{L2}} Writing Teachers},
  author = {Lee, Icy},
  year = {2017},
  doi = {10/gh5k6x},
  abstract = {The turn of the twenty-first century has witnessed ``a phenomenal increase in the testing and assessment responsibilities placed upon language teachers'' (Fulcher 2012, p. 113), and as a result, teachers' assessment literacy has been a cause for concern and an important topic for discussion and research (Popham 2008; Vogt and Tsagari 2014). More than two decades ago, US assessment scholar Rick Stiggins sounded an alarm about teachers' inabilities to conduct effective language assessment; he wrote: ``we are a nation of assessment illiterates'' (Stiggins 1991, p. 535). In the same decade, the UK assessment for learning reform (Black and Wiliam 1998) also triggered considerable interest in teacher assessment literacy. Since then, there has been an increasing realization throughout the world that teacher assessment literacy is underdeveloped (Jin 2010; Popham 2011; Volante and Fazio 2007) and that it warrants urgent attention on teachers' professional development programs.}
}

@article{a4ada7d709365e1e873fb0c80b7e537bcb8637ab,
  title = {The Current State of Assessment Education},
  author = {DeLuca, Christopher and Bellara, Aarti P.},
  year = {2013},
  journal = {Journal of Teacher Education},
  volume = {64},
  pages = {356--372},
  doi = {10/f45j4x},
  abstract = {In response to the existing accountability movement in the United States, a plethora of educational policies and standards have emerged at various levels to promote teacher assessment competency, with a focus on preservice assessment education. However, despite these policies and standards, research has shown that beginning teachers continue to maintain low competency levels in assessment. Limited assessment education that is potentially misaligned to assessment standards and classroom practices has been identified as one factor contributing to a lack of assessment competency. Accordingly, the purpose of this study was to analyze the alignment between teacher education accreditation policies, professional standards for teacher assessment practice, and preservice assessment course curriculum. Through a curriculum alignment methodology involving two policy documents, two professional standards documents, and syllabi from 10 Florida-based, Council for Accreditation of Teacher Education--certified teacher education programs, the results of this study serve to identify points of alignment and misalignment across policies, standards, and curricula. The study concludes with a discussion on the current state of assessment education with implications for enhancing teacher preparation in this area and future research on assessment education.}
}

@article{abdekhodaeeWikisGroupWork2017,
  title = {Wikis for Group Work: {{Encouraging}} Transparency, Benchmarking, and Feedback},
  author = {Abdekhodaee, A and Chase, {\relax AM} and Ross, B},
  year = {2017},
  journal = {Australasian Journal Of Educational Technology},
  volume = {33},
  number = {5},
  pages = {15--31},
  issn = {1449-3098},
  doi = {10.14742/ajet.2829},
  abstract = {Technology is recognised as playing a part in the changing landscape in higher education; altering delivery modes and providing flexible opportunities for learning. Research into the use of wikis has shown that they provide many opportunities for student learning and the development of twenty-first century skills, however, there has been limited success in their use for collaboration. In this exploratory research, we report on a group wiki project in an engineering management unit at an Australian university. A wiki was introduced to replace the existing group report assessment to add transparency to the task. Each group had their own wiki and students were required to provide feedback to other group wikis which enabled transparency of students' report development and group progress. The research aim was to investigate student perceptions of using a wiki. Students found the wikis helpful for benchmarking their activity against their peers. Students stated that peer feedback had improved their work; however, much of the feedback given by peers was too brief to be constructive, and provided too late to be useful in guiding their work. This paper will be of interest to academics interested in using wikis in their teaching to develop feedback, transparency, and benchmarking.},
  langid = {english},
  keywords = {ASSESSING COLLABORATION,ENGAGEMENT,HIGHER-EDUCATION,SUPPORT,TECHNOLOGY,UNIVERSITY-STUDENTS},
  file = {/Users/colin.madland/Zotero/storage/G9I8MMNW/abdekhodaeeWikisGroupWork2017.pdf}
}

@article{abdullahEvaluatingPreServiceTeaching2020,
  title = {Evaluating {{Pre-Service Teaching Practice}} for {{Online}} and {{Distance Education Students}} in {{Pakistan}}},
  author = {Abdullah, Nauman Ahmed and Mirza, Munawar Sultana},
  year = {2020},
  month = apr,
  journal = {International Review of Research in Open and Distributed Learning},
  volume = {21},
  number = {2},
  pages = {81--97},
  publisher = {{International Review of Research in Open and Distributed Learning}},
  issn = {1492-3831},
  doi = {10.19173/irrodl.v21i2.4606},
  abstract = {In addition to conventional modes, teacher education programs in Pakistan are also offered through online and distance education. Teaching practice is a significant component of pre-service teacher education programs. Assessing the quality of teaching practice for pre-service student teachers is important, as these modules train the prospective teachers for their professional teaching careers. Virtual University of Pakistan (VU), an online university, offers pre-service teacher education programs. This research is an investigation into the learning opportunities and practices of VU student teachers in their teaching practice modules. Students enrolled in different teacher education programs served as the population of this study. Those in the fall 2018 semester who were enrolled in teaching practice modules were selected as a sample. Data sources included lesson plans prepared, lessons delivered, administrative and co-curricular duties performed by the students, as well as evaluation reports by supervisors, cooperating teachers, and school principals. There were improvements in the student teachers' lesson plan formation and their overall learning. Data obtained through personal visits by VU faculty was used to verify and assess actual classroom teaching. Lack of regular attendance and punctuality by student teachers was observed as a result. Internal review of the VU system as it relates to the teaching practice modules was conducted to address any shortcomings in the course(s), its procedures, and its controls. Recommendations for improving the system, such as grading the modules, peer-assessment, and orientation workshops for student teachers are provided, as well as suggestions for developments in the teaching practice modules themselves.},
  keywords = {Attendance,Distance Education,Educational Technology,Foreign Countries,Lesson Plans,Online Courses,Pakistan,Preservice Teacher Education,Preservice Teachers,Skill Development,Student Attitudes,Student Evaluation,Teaching Methods,Technology Uses in Education},
  file = {/Users/colin.madland/Zotero/storage/3KZGTTSC/abdullahEvaluatingPreServiceTeaching2020.pdf}
}

@article{abelloClassroomMotivationalClimate2021,
  title = {Classroom {{Motivational Climate}} in {{Higher Education}}: {{Validation}} of a {{Model}} for {{Assessment}}},
  author = {Abello, Diana and {Alonso-Tapia}, Jes{\'u}s and Panadero, Ernesto},
  year = {2021},
  journal = {International Journal of Instruction},
  volume = {14},
  number = {2},
  pages = {685--702},
  issn = {ISSN-1694-609X},
  doi = {10/gjj8fr},
  abstract = {This study aims to adapt and validate the Classroom Motivational Climate Questionnaire and Attribution of Motivational Changes to the Teacher Questionnaire, for their administration in Higher Education and thus having adequate instruments to assess motivational climate and student preferences in this educational level. Data from 624 university students were analyzed through a Confirmatory Factor Analysis based on the original models proposed for each questionnaire. Then, a cross-validation analysis was performed for each questionnaire between two random sub-samples. Subsequently, a Path Analysis was conducted on both instruments to measure predictive validity on performance. A multigroup analysis was also conducted with two categories of students: those in their initial studies (basic) and those in practice-oriented studies (in-depth). The results confirm the factor structure for both questionnaires with configurations slightly different from those found in previous studies with high school samples. The Classroom Motivational Climate Questionnaire was found to influence performance and to identify differences in student's motivational profile depending to the year of their study.},
  langid = {english},
  keywords = {Classroom Environment,Foreign Countries,Goal Orientation,Mastery Learning,Performance Factors,Questionnaires,Student Motivation,Undergraduate Students,Validity}
}

@misc{AboriginalPopulationProfile,
  title = {Aboriginal {{Population Profile}}, 2016 {{Census}} - {{British Columbia}} [{{Province}}]},
  urldate = {2019-02-14},
  howpublished = {https://www12.statcan.gc.ca/census-recensement/2016/dp-pd/abpopprof/details/Page.cfm?Lang=E\&Geo1=PR\&Code1=59\&Data=Count\&SearchText=British\%20Columbia\&SearchType=Begins\&B1=All\&C1=All\&GeoLevel=PR\&GeoCode=59\&SEX\_ID=1\&AGE\_ID=1\&RESGEO\_ID=1},
  file = {/Users/colin.madland/Zotero/storage/FSXNMQ59/Page.html}
}

@misc{AboriginalWaysKnowing2017,
  title = {Aboriginal {{Ways}} of {{Knowing}} and {{Being}}},
  year = {2017},
  publisher = {BCTF},
  urldate = {2018-11-19}
}

@misc{abrahartRejectionLegalDuty2023,
  title = {Rejection of Legal Duty of Care Marks a Bad Day for Students' Rights},
  author = {Abrahart, Robert},
  year = {2023},
  month = jun,
  journal = {Wonkhe},
  urldate = {2023-10-19},
  abstract = {Campaigner Robert Abrahart expresses his disappointment in the government's decision not to pursue a statutory duty of care for universities},
  langid = {british},
  file = {/Users/colin.madland/Zotero/storage/HT85S9TL/RejectionLegalDuty.pdf;/Users/colin.madland/Zotero/storage/KW8XQH5B/rejection-of-legal-duty-of-care-marks-a-bad-day-for-students-rights.html}
}

@article{abramiInteractionDistanceEducation2011,
  title = {Interaction in Distance Education and Online Learning: Using Evidence and Theory to Improve Practice},
  shorttitle = {Interaction in Distance Education and Online Learning: Using Evidence and Theory to Improve Practice},
  author = {Abrami, Philip and Bernard, Robert and Bures, Eva and Borokhovski, Eugene and Tamim, Rana},
  year = {2011},
  journal = {Journal of Computing in Higher Education},
  volume = {23},
  pages = {82--103},
  issn = {1042-1726},
  doi = {10.1007/s12528-011-9043-x},
  abstract = {In a recent meta-analysis of distance and online learning, Bernard et al. ( 2009 ) quantitatively verified the importance of three types of interaction: among students, between the instructor and students, and between students and course content. In this paper we explore these findings further, discuss methodological issues in research and suggest how these results may foster instructional improvement. We highlight several evidence-based approaches that may be useful in the next generation of distance and online learning. These include principles and applications stemming from the theories of self-regulation and multimedia learning, research-based motivational principles and collaborative learning principles. We also discuss the pedagogical challenges inherent in distance and online learning that need to be considered in instructional design and software development.},
  annotation = {2}
}

@article{abramovichUnderstandingDigitalBadges2016,
  title = {Understanding Digital Badges in Higher Education through Assessment},
  author = {Abramovich, Samuel},
  year = {2016},
  journal = {On the Horizon},
  volume = {24},
  number = {1},
  pages = {126--131},
  publisher = {Emerald Group Publishing Limited},
  address = {BINGLEY},
  issn = {1074-8121},
  doi = {10.1108/OTH-08-2015-0044},
  abstract = {Purpose -- The purpose of this paper is to provide an argument why digital badges in higher education should be used as an assessment tool and not only as a credentialing mechanism. Design/methodology/approach -- This paper unpacks the use of digital badges in videogames and explains how it aligns with quality assessment practices. Several research studies are provided as examples of this alignment. Findings -- Because different people have different reactions to different badges, some people will likely be best served by badges that are designed to be assessments. Originality/value -- The meta-analysis in this paper helps to shift current thinking on the use of digital badges in higher education away from a framework that only considers badges as credentials. Digital badges that are designed as assessments can be educative for learners who would otherwise not benefit from its use.},
  keywords = {Computer & video games,Design,Education,Education & Educational Research,Educational technology,Gamification,Global & comparative education,Higher education,Learning,Online instruction,Professional development,Social Sciences,Students}
}

@article{abramsImplementingClassroomAssessment2018,
  title = {Implementing a Classroom Assessment Technique to Improve Student Engagement, Communication, and Performance in an Introductory Animal Science Laboratory Course},
  author = {Abrams, A and Nold, R and Gonda, M},
  year = {2018},
  journal = {Journal of animal science},
  volume = {96},
  pages = {498--498},
  publisher = {Oxford University Press},
  address = {Champaign},
  issn = {0021-8812},
  abstract = {We hypothesized that the use of classroom assessment techniques would improve final exam grades and promote student engagement, communication, and retention of material among college students. A classroom assessment tool was administered weekly to students in an introductory level animal science laboratory course. Of the six laboratory sections (n = 27 per lab section), three sections were randomly selected to complete assessments at the conclusion of each laboratory period. Based on the assessment responses, feedback was provided at the beginning of the next week's laboratory period to clarify material that students had expressed difficulty understanding. Data were collected on student perception of classroom engagement, communication, and learning abilities through a Likert scale survey administered at the end of the semester. Final exam grades and survey responses from students (n = 161) enrolled in this class were compared to evaluate the effect of assessments on student grades and student's perception of learning. Final exam grades were compared between treatment and control groups using a Students t-test and Likert scale survey questions using a Chi-Squared test. Surveys administered to the lab sections that participated in the assessment activity included additional questions to evaluate assessment effectiveness. No differences (P {$>$} 0.05) between groups were observed for final exam grades or student's confidence of their ability for short or long-term retention of the material. Weekly feedback provided to students based on assessment responses had a greater impact on perceived learning ability (P = 0.014) and classroom engagement (P = 0.01) than completing the assessment without this feedback. Utilizing assessment techniques to provide directed feedback may positively impact student engagement and learning in the classroom, although enhanced perceived learning was not associated with final exam grades.},
  keywords = {Animal behavior,Animal sciences,Assessments,Classrooms,Feedback,Learning,Multiple DOI,Perception,Polls & surveys,Retention,Statistical tests,Students}
}

@incollection{absolonPuttingOurselvesForward2005,
  title = {Putting {{Ourselves}} Forward: {{Location}} in {{Aboriginal Research}}},
  booktitle = {Research as {{Resistance}}: {{Critical}}, {{Indigenous}}, and {{Anti-Oppressive Approaches}}},
  author = {Absolon, Kathy and Willett, Cam},
  editor = {Brown, Leslie and Strega, Susan},
  year = {2005},
  publisher = {Canadian Scholar's Press, Inc. [CSPI]},
  address = {Toronto},
  isbn = {978-1-55130-275-1},
  langid = {english},
  keywords = {Indians of North America--Research--Canada,Oppression (Psychology)--Research,Research--Methodology,SOCIAL SCIENCE / Ethnic Studies / American / Native American Studies},
  file = {/Users/colin.madland/Zotero/storage/SXKBED8R/absolonPuttingOurselvesForward2005.pdf}
}

@article{abu-ayyashImpactIntegratingTechnology2019,
  title = {The Impact of Integrating Technology into Students' Presentations on Peer Evaluation in Higher Education},
  author = {{Abu-Ayyash}, Emad A. S. and Hill, Christopher},
  year = {2019},
  journal = {Education and information technologies},
  volume = {24},
  number = {6},
  pages = {3745--3765},
  publisher = {Springer US},
  address = {New York},
  issn = {1360-2357},
  doi = {10.1007/s10639-019-09936-w},
  abstract = {This study investigated the impact of technology in presentations on students' perception of quality. Students peer reviewed presentations and two external raters evaluated the presentations based on a rubric adapted from Savory ( 2009 ). Students reviewed activity using two assessment instruments: a seven-point attitudinal scale and a 1--5 ranking scale. The study utilized a mixed-methods, embedded QUAN:qual design, where statistical analysis of Pearson Correlation coefficient was paired with qualitative description to discuss the data gathered. The findings showed that students' scores on the attitudinal scale and their holistic rankings correlated positively with the degree of technology employed in the presentations. The greater the integration of technology in a presentation, the higher the peer rating. However, the external raters' evaluations did not generally accord with the student-raters'.},
  keywords = {Analysis,College Students,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Correlation,Education,Education & Educational Research,Education Higher,Educational Technology,Higher education,Information Systems Applications (incl.Internet),Pedagogy,Peer Evaluation,Public Speaking,Social Sciences,Student Evaluation,Students,Teacher evaluations,Technology Integration,Technology Uses in Education,User Interfaces and Human Computer Interaction}
}

@misc{AcademicHonesty,
  title = {Academic {{Honesty}}},
  journal = {PLNU CTL},
  urldate = {2020-04-10},
  howpublished = {https://ctlpointloma.org/academic-honesty},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/4KEEFVT4/academic-honesty.html}
}

@article{acosta-gonzagaRoleAttitudinalFactors2018,
  ids = {acosta-gonzagaRoleAttitudinalFactors2018a},
  title = {The Role of Attitudinal Factors in Mathematical On-Line Assessments: A Study of Undergraduate {{STEM}} Students},
  author = {{Acosta-Gonzaga}, Elizabeth and Walet, Niels R.},
  year = {2018},
  journal = {Assessment and evaluation in higher education},
  volume = {43},
  number = {5},
  pages = {710--726},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0260-2938},
  doi = {10.1080/02602938.2017.1401976},
  abstract = {This study explores student attitudes to the use of substantive on-line assessments that require mathematical answers. Since there is limited guidance available for their use in a university setting, our goal is to learn what are the important aspects in student acceptance of e-assessments that support learning of mathematical subjects in higher education. To that end we analyse the effects of a variety of attitudinal factors towards such assessments amongst a cross-section of first year students in an English university, using a detailed questionnaire. These students were all previously exposed to on-line assessments containing substantial mathematical work, including testing of and feedback on the algebraic structure of their answers, based on identifiable misconceptions underlying these answers. Since students received highly tailored feedback, the expectation was that the usefulness of this feedback would be the key driver in their usage of educational technology. The results indeed suggest that students find on-line feedback more enjoyable and useful than conventional feedback, but enjoyment and attitude are the two most important factors.},
  keywords = {College students,Computer Assisted Testing,Education & Educational Research,Educational evaluation,Educational Technology,English language,Evaluation Methods,Feedback,Feedback (Response),Foreign Countries,Higher education,Learning,Mathematics education,mathematics teaching,Mathematics Tests,Measurement,Online assessments,online formative feedback,Questionnaires,Social Sciences,STEM Education,Structural Equation Models,Student Attitudes,technology enhanced learning,Technology Uses in Education,Undergraduate Students,University students},
  file = {/Users/colin.madland/Zotero/storage/KNJU2ZWS/acosta-gonzagaRoleAttitudinalFactors2018.pdf}
}

@article{adachiAcademicsPerceptionsBenefits2018,
  title = {Academics' Perceptions of the Benefits and Challenges of Self and Peer Assessment in Higher Education},
  author = {Adachi, Chie and Tai, Joanna Hong-Meng and Dawson, Phillip},
  year = {2018},
  month = feb,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {43},
  number = {2},
  pages = {294--306},
  issn = {0260-2938, 1469-297X},
  doi = {10/gfz39x},
  urldate = {2021-07-03},
  langid = {english}
}

@article{adachiFrameworkDesigningImplementing2018,
  title = {A Framework for Designing, Implementing, Communicating and Researching Peer Assessment},
  author = {Adachi, Chie and Tai, Joanna and Dawson, Phillip},
  year = {2018},
  month = apr,
  journal = {Higher Education Research \& Development},
  volume = {37},
  number = {3},
  pages = {453--467},
  issn = {0729-4360, 1469-8366},
  doi = {10/ghzq6d},
  urldate = {2021-07-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/7JJSCP3L/adachiFrameworkDesigningImplementing2018.pdf}
}

@article{adamaCOVID19AlternativeAssessments2023,
  title = {{{COVID-19}} and Alternative Assessments in Higher Education: Implications for Academic Integrity among Nursing and Social Science Students},
  author = {Adama, Esther Abena and Graf, Amanda and {Adusei-Asante}, Kwadwo and {Afrifa-Yamoah}, Ebenezer},
  year = {2023},
  journal = {International journal for educational integrity},
  volume = {19},
  number = {1},
  pages = {1--19},
  publisher = {Springer Nature Singapore},
  address = {Singapore},
  issn = {1833-2595},
  doi = {10.1007/s40979-023-00129-0},
  abstract = {Background COVID-19 and its associated restrictions called for innovations in higher education teaching and learning space with many universities resorting to online teaching and alternative assessments. However, little has been done to understand the academic integrity implications in alternative online and non-invigilated assessments. Aim This study explored the perceptions of higher education students regarding academic integrity in alternative assessments. Methods Cross-sectional mixed method design following the parallel convergent approach was utilised in this study. A convenience sample of 380 undergraduate and postgraduate nursing and social science students completed an online survey on academic integrity behaviours associated with alternative assessments. Results High risk (31.7\%) of academic misconduct was perceived among young people (18-24\,years old). Collusion was common among nursing students (24.5\%) and cheating likely to occur in assessments with longer duration---between 2 and 4\,hours (18.8\%) and between 1 and 2\,weeks (46\%). Qualitative data resulted in 274 findings and three themes--- (i) impossible to cheat; (ii) easy to cheat and (iii) understanding the consequence of cheating. Suggestions for preserving academic integrity in alternative assessments were also made from the qualitative data. Conclusion Like other forms of traditional assessments, alternative assessments have increased risk of breach of academic integrity; however, with the right strategies, they could serve as effective means of assessing learning outcomes.},
  keywords = {Academic misconduct,Assessments,Cheating behaviours,Education,Ethics,Higher Education,International and Comparative Education,Original,Original Article,Tertiary students,Universityeducation},
  file = {/Users/colin.madland/Zotero/storage/GCJEJEZG/adamaCOVID19AlternativeAssessments2023.pdf}
}

@incollection{adamsAutoethnography2017,
  title = {Autoethnography},
  booktitle = {The {{International Encyclopedia}} of {{Communication Research Methods}}},
  author = {Adams, Tony E. and Ellis, Carolyn and Jones, Stacy Holman},
  editor = {Matthes, J{\"o}rg and Davis, Christine S. and Potter, Robert F.},
  year = {2017},
  month = aug,
  edition = {1},
  pages = {1--11},
  publisher = {Wiley},
  doi = {10.1002/9781118901731.iecrm0011},
  urldate = {2023-11-13},
  abstract = {The authors describe the history of autoethnography, particularly within the communication discipline; discuss key characteristics of autoethnography and identify the purposes of doing autoethnographic research; and provide three examples of doing and writing autoethnography.},
  isbn = {978-1-118-90176-2 978-1-118-90173-1},
  langid = {english}
}

@book{adamsHandbookAutoethnography2021,
  title = {Handbook of Autoethnography},
  editor = {Adams, Tony E. and Holman Jones, Stacy Linn and Ellis, Carolyn},
  year = {2021},
  edition = {Second edition},
  publisher = {Routledge},
  address = {New York, NY},
  abstract = {"The second edition of this seminal text in the field of autoethnography considers the development and establishing of a fast-moving discipline since the publication of the first edition. Seven of the original handbook chapters are revised; the rest are original contributions and exemplars from some of the most established scholars in the field. A substantially revised structure makes the thematic organisation easier to follow. Combining established scholarship with innovative new contributions, Handbook of Autoethnography will be of interest to all those teaching and studying graduate and undergraduate courses in autoethnography and qualitative research"--},
  isbn = {978-1-138-36311-3 978-1-138-36312-0},
  lccn = {GN307.7 .H65 2021},
  keywords = {Authorship,Ethnology,Methodology,Research},
  file = {/Users/colin.madland/Zotero/storage/V47WAQM8/adamsHandbookAutoethnography2021.pdf}
}

@misc{adamUbuntuWhoProvocation,
  title = {Ubuntu for Who? -- {{Provocation}} for {{Wikimania Workshop}} 2018 by {{Taskeen Adam}}},
  shorttitle = {Ubuntu for Who?},
  author = {Adam, Taskeen},
  urldate = {2018-10-21},
  abstract = {A provocation for the workshop at Wikimania 2018 "Ubuntu for who? Equity by Free Knowledge?" by Taskeen Adam Ubuntu for who? Openness is often described as something that is inherently good and desirable. In the latest discussions on open education, discussions have focused on the need to include the marginalised into the open world. However,{\dots}},
  langid = {english},
  keywords = {indigenous,open},
  file = {/Users/colin.madland/Zotero/storage/G662X53F/ubuntu-for-who-provocation-for-wikimania-workshop-2018-by-taskeen-adam.html}
}

@incollection{adanirAssessmentTypesMethods2021,
  title = {Assessment {{Types}} and {{Methods}} in {{Distance Learning}}},
  booktitle = {Handbook of {{Research}} on {{Determining}} the {{Reliability}} of {{Online Assessment}} and {{Distance Learning}}:},
  author = {Adanir, Gulgan Afacan},
  editor = {Moura, Ana S. and Reis, Pedro and Cordeiro, M. Nat{\'a}lia D. S. and {Ord{\'o}{\~n}ez de Pablos}, Patricia},
  year = {2021},
  series = {Advances in {{Mobile}} and {{Distance Learning}}},
  publisher = {IGI Global},
  doi = {10.4018/978-1-7998-4769-4},
  urldate = {2021-07-03},
  isbn = {978-1-7998-4769-4 978-1-7998-4770-0},
  file = {/Users/colin.madland/Zotero/storage/M4BWZZHN/adanirAssessmentTypesMethods2021.pdf}
}

@article{adanirLearnersPerceptionsOnline2020,
  title = {Learners' {{Perceptions}} of {{Online Exams}}: {{A Comparative Study}} in {{Turkey}} and {{Kyrgyzstan}}},
  author = {Adanir, G{\"u}lg{\"u}n Afacan and Ismailova, Rita and Omuraliev, Asan and Muhametjanova, Gulshat},
  year = {2020},
  month = sep,
  journal = {International Review of Research in Open and Distributed Learning},
  volume = {21},
  number = {3},
  pages = {1--17},
  issn = {1492-3831},
  abstract = {As online learning is becoming very popular in formal educational settings and in individual development, online exams are starting to be recognized as one of the more efficient assessment methods. Online exams are effective in either blended or traditional forms of learning, and, when appropriately used, bring benefits to both learners and the learning process. However, learners' perceptions of online exams in developing countries have not been widely studied despite the potential of such research for contributing to more effective use of online exams in these countries. Thus, this study served two purposes. First, it aimed to investigate students' perceptions of online exams at a state university in Turkey, and at a state university in Kyrgyzstan. Second, the study compared the results. Structured as a mixed study, the research was conducted during the 2018-2019 fall term. The participants were 370 undergraduate students taking first-year courses online. Quantitative data considered learners' perception scores gathered via a survey, whereas qualitative data considered learners' opinions in response to an open-ended question. According to the quantitative analysis, learners' perceptions differed according to gender, major, and prior online course experience variables. In addition, Turkish and Kyrgyz learners differed in that Turkish learners found online exams less stressful and more reliable and fairer than traditional paper-based exams when compared with their Kyrgyz counterparts. The qualitative analysis provided important results for future planning in both institutions.},
  keywords = {Cheating,Computer Assisted Testing,Computer Literacy,Developing Nations,Foreign Countries,Gender Differences,Kyrgyzstan,Majors (Students),No DOI found,Online Courses,Public Colleges,Required Courses,Student Attitudes,Student Experience,Test Anxiety,Test Format,Turkey,Undergraduate Students}
}

@article{adapaIntegratingTeachingResources2015,
  title = {Integrating Teaching Resources and Assessment Tasks to Enhance Student Experience},
  author = {Adapa, Sujana},
  year = {2015},
  journal = {International Journal of Learning, Teaching and Educational Research},
  doi = {null},
  abstract = {This research paper outlines the importance of integrating the teaching resources with the assessment tasks and continuous feedback in creating unique overall student experience through effective student engagement and interactive student learning. These activities are undertaken in two undergraduate Services marketing and Strategic marketing unit offerings in the off campus teaching mode in a regional Australian university. The resultant impact on the overall student satisfaction, academic performance, retention and attrition rates has been studied. Results observed indicate that the student engagement increased across the behavioural, emotional and cognitive dimensions and also students' focused on deeper learning through the integration of technology enables teaching resources and authentic assessment tasks. Continuous feedback provided by the academic staff member acted as a feed forward element that gauged students' deep interest in the unit offerings. Key words : Student experience, Student engagement, Student learning, Interactive resources, Authentic assessment, Feedback},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@article{adapaIntegratingTeachingResources2015a,
  title = {Integrating Teaching Resources and Assessment Tasks to Enhance Student Experience},
  author = {Adapa, Sujana},
  year = {2015},
  journal = {International Journal of Learning, Teaching and Educational Research},
  doi = {null},
  abstract = {This research paper outlines the importance of integrating the teaching resources with the assessment tasks and continuous feedback in creating unique overall student experience through effective student engagement and interactive student learning. These activities are undertaken in two undergraduate Services marketing and Strategic marketing unit offerings in the off campus teaching mode in a regional Australian university. The resultant impact on the overall student satisfaction, academic performance, retention and attrition rates has been studied. Results observed indicate that the student engagement increased across the behavioural, emotional and cognitive dimensions and also students' focused on deeper learning through the integration of technology enables teaching resources and authentic assessment tasks. Continuous feedback provided by the academic staff member acted as a feed forward element that gauged students' deep interest in the unit offerings. Key words : Student experience, Student engagement, Student learning, Interactive resources, Authentic assessment, Feedback},
  pmcid = {null},
  pmid = {null}
}

@article{adedoyinIssuesAssessmentPractices2018,
  title = {Issues in Assessment Practices at Botswana Private Tertiary Institutions as Perceived by Undergraduate Students},
  author = {Adedoyin, Omobola O. and Chisiyanwa, Lemogang},
  year = {2018},
  journal = {Asian Journal of Education and e-Learning},
  doi = {10.24203/ajeel.v6i1.5242},
  abstract = {This study investigated undergraduate students' perceptions on the issues pertaining to assessment practices at Botswana Private Tertiary Institutions. The purpose of the study was to investigate their perceptions on the issues relating to assessment practices. A survey research design was used for the study. A close- ended questionnaire, with four point Likert scale was developed regarding the issues on assessment practices and administered to a randomly selected five hundred (500) undergraduates from five (5) randomly selected tertiary institutions of higher Education in Botswana. Out of which four hundred and thirty six (436) undergraduate tertiary students responded to the questionnaire and their responses were coded, analysed using descriptive statistics (frequency distributions, mean, standard deviation of responses), exploratory factor analysis, independent t-test and analysis of variance (ANOVA). Results revealed eight (8) main issues of assessment practices as perceived by Botswana Private Tertiary undergraduate students which were as follows: Limited assessment strategies used by lecturers; Inadequate feedback; Non-challenging quality of test items; Assessment to be structured for teaching and learning; Assessment by lecturers not fair and valid; Assessment items focuses more on low order cognitive questions; Timing of assessments not strategic; Marking of assessments by lecturers not consistent. The study further determined if gender and the different tertiary institutions had a significant influence on the undergraduate students' perceived issues on assessment practices at the different private tertiary universities. It was found that that gender and university of study had significant influence on students' perceptions with regard to some issues on assessment practices. Based on the findings, all these issues perceived by the undergraduate students would inform institutions of higher education in Botswana tertiary institutions. Recommendations and way forward were suggested to improve the assessment practices at Botswana private tertiary institutions.},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@article{adieConstructionTeacherExpert2019,
  title = {The Construction of the Teacher as Expert Assessor},
  author = {Adie, Lenore and Stobart, Gordon and Cumming, Joy},
  year = {2019},
  journal = {Asia-pacific Journal of Teacher Education},
  doi = {10/gmgbpr},
  abstract = {ABSTRACTProfessional standards are increasingly being used internationally as the basis of teacher performance and as a mechanism to progress teacher quality. Concurrently, teacher assessment practices continue to be highlighted in many countries as an area in need of further professional development. In this paper, we analyse the assessment focus within the Australian Professional Standards for Teachers (APSTs), as an example of one nation's articulation of the expected performance and development of assessment literacies across a teaching career. Through a conceptual framework of proficiency progression based on the work of researchers such as Dreyfus and Dreyfus, we employ text analysis and a visualisation methodology to explore meanings and patterns in Standard 5: Assess, provide feedback and report on student learning. Using diagrammatic representations, we show the relationships between terms in the APST statements and how progression of expertise is constructed. The analysis identifies the areas of...}
}

@article{adiguzelExaminingWebBasedPeer2017,
  title = {Examining a {{Web-Based Peer Feedback System}} in an {{Introductory Computer Literacy Course}}},
  author = {Adiguzel, T and Varank, I and Erkoc, {\relax MF} and Buyukimdat, {\relax MK}},
  year = {2017},
  journal = {Eurasia Journal Of Mathematics Science And Technology Education},
  volume = {13},
  number = {1},
  pages = {237--251},
  issn = {1305-8215},
  doi = {10.12973/eurasia.2017.00614a},
  abstract = {This study focused on formative use of peer feedback in an online system that was used in basic computer literacy for word processing assignment-related purposes. Specifically, the effect of quantity, modality and satisfaction of peer feedback provided through the online system on students' performance, self-efficacy, and technology acceptance was investigated. Participants were 32 freshmen elementary and Turkish education pre-service teachers who were enrolled in two sections of the mandatory Computer I course in a public university in Turkey in the fall semester of 2013. Groups of students who submitted their assignments and received feedback in varying quantity and two different forms (text or text and video together) did not differ respectively in terms of students' performance test scores as well as self-efficacy and technology acceptance ratings. Students' feedback satisfaction ratings were significantly correlated only with their technology acceptance scores. All results were interpreted with the support of peer feedback content in both text and video formats to clarify the details and contribute more to the literature.},
  langid = {english},
  keywords = {ENHANCE,peer assessment,peer feedback,QUALITY,self-efficacy,STUDENTS PERFORMANCE,TECHNOLOGY,technology acceptance,USER ACCEPTANCE,VIDEO FEEDBACK,word processing},
  file = {/Users/colin.madland/Zotero/storage/RH7LKLHM/adiguzelExaminingWebBasedPeer2017.pdf}
}

@article{adnanAssessmentMultinationalOnline2017,
  title = {Assessment of a {{Multinational Online Faculty Development Program}} on {{Online Teaching}}: {{Reflections}} of {{Candidate E-Tutors}}},
  author = {Adnan, Muge and Kalelioglu, Filiz and Gulbahar, Yasemin},
  year = {2017},
  journal = {Turkish Online Journal of Distance Education},
  volume = {18},
  number = {1},
  pages = {22--38},
  issn = {EISSN-1302-6488},
  doi = {10/ggmt8d},
  abstract = {Teaching online requires different skills, roles and competencies for online instructors compared to teaching in traditional learning environments. Universities should offer ongoing support in various forms to help academic staff through their online journey. This paper provides insights into a multinational faculty development program for teaching online, elaborating on results of expectancy and satisfaction surveys. From a local program to a subproject within the Swiss National Science Foundation Project Scopes, e-Tutor aimed at expanding competencies in online lecturing and providing OER material for training colleagues. Designed in the form of a descriptive case study, this research was conducted with 34 attendees of e-Tutor. Data was collected using an e-learning readiness and expectancy questionnaire, and open-ended questions after the program to measure satisfaction. Descriptive statistics were used to analyze the survey data and content analysis for open-ended data. Participants considered e-Tutor a well-planned and targeted program with good theoretical and practical balance. Duration of such courses, opportunities for adaptation to real-life situations, and localization of the content are areas to be explored further. For future studies, it would also be interesting to see whether participants can apply their newly acquired knowledge and skills to create efficient online learning environments.},
  langid = {english},
  keywords = {Case Studies,College Faculty,Electronic Learning,Faculty Development,Foreign Countries,International Programs,Learning Readiness,Program Evaluation,Questionnaires}
}

@misc{AdvancingReconciliationPostsecondary,
  title = {Advancing Reconciliation through Postsecondary Education},
  journal = {Universities Canada},
  urldate = {2018-11-30},
  abstract = {This op-ed was published in~Policy Options~on November 19, 2018 by Paul Davidson, president, Universities Canada and~Roberta Jamieson, CEO, Indspire Postsecondary education is the gateway for young people to access --- and create --- opportunities in our rapidly changing world. In Canada, we believe everyone should have the tools and support they need to achieve their {\dots}},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/GVEBSPNI/advancing-reconciliation-through-postsecondary-education.html}
}

@article{adzimaExaminingOnlineCheating2020,
  title = {Examining {{Online Cheating}} in {{Higher Education Using Traditional Classroom Cheating}} as a {{Guide}}},
  author = {Adzima, Kerry},
  year = {2020},
  journal = {Electronic Journal of e-Learning},
  volume = {18},
  number = {6},
  pages = {476--493},
  issn = {EISSN-1479-4403},
  abstract = {Academic dishonesty in higher education is a perverse problem affecting institutions of learning in many countries across the globe. More alarmingly, numerous studies have pointed to increasing rates of cheating and plagiarism over the past few decades offering a wide array of explanations and theories for this trend. A relatively new feature of both higher education and the discussion of academic dishonesty involves the growing market for online education. Within the last decade, online education has become a permanent fixture increasing its reach in education markets throughout the world. The trend of online education is seen as bringing with it a new set of opportunities and challenges related to academic dishonesty. With high rates of cheating already a well-documented problem in the traditional (face-to-face) learning environment, it is important to analyze how online education factors into this scenario. The goal of this paper is to provide the reader with a critical analysis of the current literature on academic dishonesty in online education and to propose areas for future research where gaps in the literature exist.},
  langid = {english},
  keywords = {Cheating,College Students,Cultural Influences,Distance Education,Educational Environment,Educational Technology,Environmental Influences,Ethics,Higher Education,Incidence,Knowledge Level,Misconceptions,No DOI found,Online Courses,Plagiarism,Student Attitudes,Student Characteristics,Supervision,Teacher Attitudes}
}

@article{ae1ca4b9f888bf7f1ef676cde762c7b20c1e9cf3,
  title = {An Investigation of the Development of Pre-Service Teacher Assessment Literacy through Individualized Tutoring and Peer Debriefing.},
  author = {Odo, D.},
  year = {2016},
  journal = {Journal of Inquiry and Action in Education},
  volume = {7},
  pages = {31--61},
  abstract = {Many pre-service teachers lack deep understanding of assessment concepts and have low selfefficacy for using assessments but pre-service on-campus programs have been shown to support their assessment literacy development. Likewise, individualized tutoring has helped pre-service candidates improve instructional practice and peer debriefing has been found to help push their thinking. However, questions remain regarding the usefulness of these techniques to develop candidates' assessment literacy. The primary aim of this exploratory qualitative study was to describe pre-service teachers' perceptions of assessment literacy and the process of their assessment literacy development during a literacy assessment class containing an individualized tutoring component. Five teacher candidates in a literacy assessment and instruction course at a large urban university in the US engaged in individual semi-structured interviews and submitted written reflections and artifacts which were analyzed following the constant comparative and content analysis methods. Findings were that individualized tutoring allowed participants to apply the assessment techniques they were learning in class to determine their suitability with the diverse urban learners. Likewise, peer debriefing enabled them to share knowledge and ideas, offer mutual support and engage in collaborative problem solving to improve their tutoring. These findings support the conclusion that individualized tutoring and peer debriefing within a graduate class can be effective tools for deepening candidates' reflection, connecting theory to practice, and providing feedback on instructional technique to support their assessment literacy development.},
  keywords = {No DOI found}
}

@misc{AECTCodeProfessional2018,
  title = {{{AECT Code}} of {{Professional Ethics}} 2018},
  year = {2018},
  publisher = {AECT},
  urldate = {2024-10-09},
  file = {/Users/colin.madland/Zotero/storage/AECT_Code_of_EthicCurrent.pdf}
}

@article{AERAOpen2014,
  title = {{{AERA}} Open.},
  year = {2014},
  journal = {AERA open.},
  publisher = {American Educational Research Association},
  address = {Washington, DC},
  issn = {2332-8584},
  keywords = {Education,Education -- Research,Electronic journals,Fulltext,Internet Resources,Periodicals}
}

@book{aerastandards2014,
  title = {Standards for {{Educational}} and {{Psychological Testing}}},
  year = {2014},
  publisher = {American Educational Research Association},
  address = {Washington, D.C},
  collaborator = {American Educational Research Association and {National Council for Measurement in Education} and American Psychological Association},
  isbn = {978-0-935302-35-6},
  langid = {english},
  lccn = {LB1028 .A435 2011},
  keywords = {Education,Research},
  annotation = {OCLC: ocn826867074},
  file = {/Users/colin.madland/Zotero/storage/HZGAE63Q/aeraStandardsEducationalPsychological2014.pdf}
}

@misc{aestDigitalLearningAdvisory2022,
  title = {Digital {{Learning Advisory Committee Draft Recommendations}}},
  author = {AEST},
  year = {2022},
  publisher = {{BC Ministry of Advanced Education and Skills Training}},
  urldate = {2022-12-09},
  file = {/Users/colin.madland/Zotero/storage/46VA64EG/aestDigitalLearningAdvisory2022.pdf}
}

@misc{aftStandardsTeacherCompetence1990,
  title = {Standards for {{Teacher Competence}} in {{Educational Assessment}} of {{Students}}},
  author = {AFT and NCME and NEA},
  year = {1990},
  urldate = {2021-07-08},
  abstract = {The assessment competencies set forth in this monograph are knowledge and skills critical to a teacher's role as an educator. It is suggested that the seven standards described as essential for educational assessment of students be incorporated into future teacher training and certification programs. The standards require that teachers be skilled in the following competencies: (1) choosing assessment methods appropriate for instructional decisions; (2) developing assessment methods appropriate for instructional decisions; (3) administering, scoring, and interpreting the results of both externally produced and teacher-produced assessment methods; (4) using assessment results when making decisions about individual students, planning teaching, developing curriculum, and school improvement; (5) developing valid pupil grading procedures which use pupil assessments; (6) communicating assessment results to students, parents, other lay audiences, and other educators; and (7) recognizing unethical, illegal, and otherwise inappropriate assessment methods and uses of assessment information. (JD)},
  file = {/Users/colin.madland/Zotero/storage/YF4S9QFF/aftStandardsTeacherCompetence1990.pdf}
}

@article{agarwalExaminingTestingEffect2008,
  title = {Examining the Testing Effect with Open- and Closed-Book Tests},
  author = {Agarwal, Pooja K. and Karpicke, Jeffrey D. and Kang, Sean H. K. and Roediger, Henry L. and McDermott, Kathleen B.},
  year = {2008},
  month = nov,
  journal = {Applied Cognitive Psychology},
  volume = {22},
  number = {7},
  pages = {861--876},
  issn = {08884080, 10990720},
  doi = {10.1002/acp.1391},
  urldate = {2022-05-02},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/EKEQ387W/agarwalExaminingTestingEffect2008.pdf}
}

@article{agormedahOnlineLearningHigher2020,
  title = {Online {{Learning}} in {{Higher Education}} during {{COVID-19 Pandemic}}: {{A Case}} of {{Ghana}}},
  author = {Agormedah, Edmond Kwesi and Henaku, Eugene Adu and Ayite, Desire Mawuko Komla and Ansah, Enoch Apori},
  year = {2020},
  journal = {Journal of Educational Technology and Online Learning},
  volume = {3},
  number = {3},
  pages = {183--210},
  issn = {EISSN-2618-6586},
  abstract = {The COVID-19 pandemic has been a major concern across the globe affecting nation's socio-economic development including education. It has pushes many HEIs in world to move into remote learning as a substitute of in-person instruction. The study explored students' response to online learning in higher education in Ghana. The study was guided by three research questions. Descriptive survey design was adopted and online questionnaire was used to gather data from 467 students in a higher education of Ghana. The data was analysed using frequency and percentage. Overall, the study found that students had positive response to online learning. They knew of online learning and some of the platforms like UCC Moodle platform, Alison and Google classroom. They would also like to use other social media platforms. They would use smart phone and laptop for the online learning. However, they were not ready for online learning because they lacked formal orientation and training, perceived lack of constant access to internet connectivity and financial unpreparedness. Management of the university should provide resources to help students assess whether they are ready to take an online course and offer suggestions for preparation. Since internet accessibility is expensive in Ghana at the moment, management of the university should hold negotiations with Cellular operators for educational discount for distance students. Academic staff should provide instructional support through instructional activities that can help students in appraising their readiness, gaining the needed skills to learn online and consider using flexible approaches to teaching and deadlines to accommodate students with reliable Wi-Fi or broadband access challenges as well as emotional response to help student ensure smooth transition to emergency remote learning/teaching.},
  langid = {english},
  keywords = {Access to Computers,College Students,Costs,COVID-19,Distance Education,Foreign Countries,Handheld Devices,Higher Education,Integrated Learning Systems,Internet,Laptop Computers,No DOI found,Online Courses,Pandemics,Readiness,School Closing,Social Media,Student Attitudes,Technological Literacy,Telecommunications}
}

@misc{agoTwitterAlgorithmRacist,
  title = {Is {{Twitter}}'s Algorithm Racist?},
  author = {{\noopsort{ago}}a day {ago}, Georgia Coggan},
  journal = {Creative Bloq},
  urldate = {2020-09-22},
  abstract = {Social network's image preview function sparks experiment.},
  howpublished = {https://www.creativebloq.com/news/twitter-racist-algorithm},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/AU6ZPBHY/twitter-racist-algorithm.html}
}

@misc{AheadTomorrowStrategic,
  title = {Ahead of {{Tomorrow}} {\textbar} {{Strategic Plan}} 2023-30 {\textbar} {{University}} of {{Calgary}}},
  urldate = {2024-10-10},
  abstract = {UCalgary's 2023-30 Strategic Plan},
  howpublished = {https://ucalgary.ca/about/ahead-of-tomorrow},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/WKBEILIX/ahead-of-tomorrow.html}
}

@misc{AIAssessmentHigher2023,
  title = {{{AI}} and {{Assessment}} in {{Higher Education}}: {{Reflections}}},
  shorttitle = {{{AI}} and {{Assessment}} in {{Higher Education}}},
  year = {2023},
  month = feb,
  journal = {Lydia Arnold},
  urldate = {2023-02-16},
  abstract = {*Disclaimer -- this article was written with GTP, but not by GTP -- explanation within. There has been a great deal of buzz surrounding the emergence of AI services, with ChatGTP being on{\dots}},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/4LYJ8W9P/ai-and-assessment-in-higher-education-reflections.html}
}

@misc{AIInformationLiteracy,
  title = {{{AI}} and {{Information Literacy}}},
  urldate = {2023-09-22},
  howpublished = {https://umd.instructure.com/courses/1354089},
  file = {/Users/colin.madland/Zotero/storage/3UNVMXQE/1354089.html}
}

@article{aikenheadDecolonizingPanCanadianScience2006,
  title = {Towards Decolonizing the Pan-{{Canadian}} Science Framework},
  author = {Aikenhead, Glen S.},
  year = {2006},
  journal = {Canadian Journal of Science, Mathematics and Technology Education},
  volume = {6},
  number = {4},
  pages = {387--399},
  issn = {1492-6156},
  doi = {10.1080/14926150609556712},
  keywords = {Canada,Cultural relations,Cultural values,Education,Education policy,Engineering/Technology Education,Mathematics Education,Native North Americans,Native religions,Science Education}
}

@article{aikenheadEmergingDecolonizingScience2010,
  title = {An {{Emerging Decolonizing Science Education}} in {{Canada}}},
  author = {Aikenhead, Glen S. and Elliott, Dean},
  year = {2010},
  journal = {Canadian Journal of Science, Mathematics and Technology Education},
  volume = {10},
  number = {4},
  pages = {321--338},
  issn = {1492-6156},
  doi = {10.1080/14926156.2010.524967},
  abstract = {The article describes developments in science education since 2006 related to an agenda to decolonize the Pan-Canadian Science Framework by recognizing Indigenous knowledge as being foundational to understanding the physical world. Of particular interest is the Province of Saskatchewan's curriculum renewal that integrates Indigenous knowledge into school science, guided by continuous collaboration with Saskatchewan's Indigenous communities and with a textbook publisher to support a decolonizing, place-based, culturally responsive science instruction.;The article describes developments in science education since 2006 related to an agenda to decolonize the Pan-Canadian Science Framework by recognizing Indigenous knowledge as being foundational to understanding the physical world. Of particular interest is the Province of Saskatchewan's curriculum renewal that integrates Indigenous knowledge into school science, guided by continuous collaboration with Saskatchewan's Indigenous communities and with a textbook publisher to support a decolonizing, place-based, culturally responsive science instruction.L'article pr{\'e}sente les d{\'e}veloppements en enseignement des sciences depuis 2006, li{\'e}s {\`a} une volont{\'e} de d{\'e}coloniser le Cadre scientifique pancanadien gr{\^a}ce {\`a} la reconnaissance des savoirs autochtones comme fondements essentiels pour la compr{\'e}hension du monde physique. Soulignons en particulier le nouveau curriculum de la Saskatchewan, qui int{\`e}gre les savoirs autochtones {\`a} l'enseignement des sciences {\`a} l'{\'e}cole, et b{\'e}n{\'e}ficie d'une collaboration continue aussi bien avec les communaut{\'e}s autochtones de cette province qu'avec une maison d'{\'e}dition p{\'e}dagogique {\oe}uvrant en faveur d'un enseignement des sciences d{\'e}colonis{\'e}, ancr{\'e} dans le milieu et culturellement responsable.;},
  keywords = {Canadian culture,Collaboration,Curricula,Education,Engineering/Technology Education,Knowledge,Mathematics Education,Native North Americans,Saskatchewan Canada,Science Education,Teaching methods}
}

@article{ainiDigitalizationSmartStudent2020,
  title = {Digitalization of {{Smart Student Assessment Quality}} in {{Era}} 4.0},
  author = {Aini, Qurotul},
  year = {2020},
  month = apr,
  journal = {International Journal of Advanced Trends in Computer Science and Engineering},
  volume = {9},
  number = {1.2},
  pages = {257--265},
  issn = {22783091},
  doi = {10.30534/ijatcse/2020/3891.22020},
  urldate = {2022-11-05},
  abstract = {Era 4.0 has had a significant impact on information technology, especially in digitalization that has entered the field of education. The purpose of this study is to explore how from lecturers to department heads to understand and proficiency in digitizing student assessment in the 4.0 era. This study uses the SDLC waterfall method in building gamificationbased smart assessment. Researchers need to explore how to understand the concept of skills towards digitizing student assessments required to produce an effective and efficient system. The findings show that lecturers are able to see digitalization with broad and complex concepts including the pedagogical, technical, administrative and academic structures of the University. The role of the lecturer seems to play an essential and complex role due to digitization so that it impacts on the level of student motivation. However, time, human resources, as well as professional development, continue to influence in supporting the learning process of lecturers and students. This paper contributes to the digitization and quality of lecturers' smart assessment of students. The contribution shown for lecturers is trying to implement and be able to digitize in 4.0 era as a form of transformation in the field of education. The application of smart assessment helps the quality of lecturers' quality of input scores in students effectively and accurately so that it impacts on students knowing the value in real-time and becomes motivated by gamification.},
  file = {/Users/colin.madland/Zotero/storage/KVULSP82/ainiDigitalizationSmartStudent2020.pdf}
}

@misc{AINormalTechnology,
  title = {{{AI}} as {{Normal Technology}}},
  urldate = {2025-04-21},
  howpublished = {http://knightcolumbia.org/content/ai-as-normal-technology}
}

@misc{AINowInstitute,
  title = {{{AI Now Institute}}},
  urldate = {2020-09-23},
  abstract = {The AI Now Institute at New York University is an interdisciplinary research center dedicated to understanding the social implications of artificial intelligence.},
  howpublished = {/},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/ZZLTW6FX/ainowinstitute.org.html}
}

@misc{AISpreadingOld,
  title = {{{AI}} Is Spreading Old Stereotypes to New Languages and Cultures},
  urldate = {2025-05-08},
  howpublished = {https://link.condenast.com/view/6142243c6fdf8d47750a3614680fad9850dfdf3636057740/039522ba},
  file = {/Users/colin.madland/Zotero/storage/Y5GFFURV/039522ba.html}
}

@article{aithalStudentEvaluationReforms2016,
  title = {Student {{Evaluation And Reforms In Higher Education Institutions}}},
  author = {Aithal, Dr P S and Kumar, P M Suresh},
  year = {2016},
  journal = {International Journal of Multidisciplinary Research and Modern Education},
  volume = {2},
  number = {1},
  pages = {652--661},
  abstract = {Innovative evaluation process in higher education system is required to gauge the knowledge and skills acquired at various levels of the programmes. As part of imparting quality higher education for undergraduate and post graduate students, Srinivas Institute of Management Studies (SIMS) developed an education service model for integrated academic support. Backed by the presumption that evaluation is the essence of examination and examination is vital to assessment, the college has instituted a wide range of evaluation processes which runs parallel to curriculum delivery. In this paper, we have analysed the strategies followed by Srinivas Institute of Management Studies, which is affiliated to Mangalore University for ensuring transparency in evaluation and undertaking reforms to strengthen it. The paper discusses details on the major evaluation reforms of the university that the institution has adopted, and the reforms initiated by the institution on its own, details on some of the formative and summative evaluation approaches adopted to measure student achievement which have positively impacted the system, details on the significant improvements made in ensuring rigor and transparency in the internal assessment and weightages assigned, for the overall development of students. The graduate attributes specified by the college/affiliating university and the institutional effort to ensure the attainment of these by the students, and details of the mechanisms for redressal of grievances with reference to evaluation both at the college and University level are also analysed.},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/5M4NKRWF/aithalStudentEvaluationReforms2016.pdf}
}

@article{ajiAssessingStudentsOnline2022,
  title = {Assessing {{Students During Online Learning}}: {{A Case Study}} on a {{Linguistic Subject Teacher}}'s {{Experience}}},
  author = {Aji, Aulia Adilla and Basthomi, Yazid},
  year = {2022},
  journal = {Language circle (Semarang )},
  volume = {16},
  number = {2},
  pages = {264--273},
  issn = {1858-0157},
  doi = {10.15294/lc.v16i2.31643},
  abstract = {Online learning has caused major shifts, including the assessment process inside the English Language Teaching classroom. Through a series of in-depth interviews and thorough observations, this study explored a Linguistic Subject teacher's experience in implementing an online assessment using a Learning Media System (LMS) application called Microsoft Teams. The use of the Microsoft Teams Application helped to improve efficiency in uploading the files of students' assignments, correcting and giving feedback to their works. However, based on the interviews, some obstacles were found during the teaching, learning and evaluation process. These include network problems, shorter time of classes and massive collusion among students make the students' performance in doing their assignments do not always reflect their understanding and ability. While network problems and shorter face to face interaction often hinder the teaching and learning process as well as the assessment of students' active participation, the use of blended learning in the school required teachers to be more creative and assertive in the assessment process.},
  file = {/Users/colin.madland/Zotero/storage/F2QCBNQV/ajiAssessingStudentsOnline2022.pdf}
}

@book{ajjawiAssessmentInclusionHigher2022,
  title = {Assessment for {{Inclusion}} in {{Higher Education}}: {{Promoting Equity}} and {{Social Justice}} in {{Assessment}}},
  shorttitle = {Assessment for {{Inclusion}} in {{Higher Education}}},
  author = {Ajjawi, Rola and Tai, Joanna and Boud, David and Jorre De St Jorre, Trina},
  year = {2022},
  month = dec,
  edition = {1},
  publisher = {Routledge},
  address = {London},
  doi = {10.4324/9781003293101},
  urldate = {2023-09-03},
  isbn = {978-1-003-29310-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/HTXFSNDY/ajjawiAssessmentInclusionHigher2022.pdf}
}

@incollection{ajjawiConceptualisingEvaluativeJudgement2018,
  title = {Conceptualising Evaluative Judgement for Sustainable Assessment in Higher Education},
  booktitle = {Developing {{Evaluative Judgement}} in {{Higher Education}}},
  author = {Ajjawi, Rola and Tai, Joanna and Dawson, Phillip and Boud, David},
  editor = {Boud, David and Ajjawi, Rola and Dawson, Phillip and Tai, Joanna},
  year = {2018},
  month = apr,
  edition = {1},
  pages = {7--17},
  publisher = {Routledge},
  address = {Abingdon, Oxon ; New York, NY : Routledge, 2018.},
  doi = {10.4324/9781315109251-2},
  urldate = {2024-04-08},
  isbn = {978-1-315-10925-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/TQH8TSUQ/ajjawiConceptualisingEvaluativeJudgement2018.pdf}
}

@article{ajjawiPerformingStandardsCritical2021,
  title = {Performing Standards: {{A}} Critical Perspective on the Contemporary Use of Standards in Assessment},
  author = {Ajjawi, Rola and Bearman, Margaret and Boud, David},
  year = {2021},
  month = jul,
  journal = {Teaching in Higher Education},
  volume = {26},
  number = {5},
  pages = {728--741},
  publisher = {Taylor \& Francis},
  issn = {1356-2517},
  doi = {10.1080/13562517.2019.1678579},
  abstract = {This paper offers a critical and theoretical exploration of the contemporary use of standards in assessment in higher education. It outlines three discourses of assessment standards. Each perspective foregrounds particular realities and backgrounds others, and so influences practice in particular taken-for-granted ways. The assumptions of these perspectives are identified, and the advantages and disadvantages of each of the existing discourses discussed. The dominant perspective prompts educators to make standards `transparent' for students, inferring stability through a written explication. The sociocultural perspective highlights a tacit and more dynamic view of standards, suggesting that standards are built by expert consensus and students must learn to meet this community expectation. The sociomaterial perspective also infers a dynamic view, but one that is co-produced through social and material assemblages. Thinking about standards as performance, a dynamic and shifting human-material activity, encourages a focus on emergent activity in the design of standards, moderation and assessment. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {Academic standards,Educational Standards,Higher Education,Measurement,Performance,sociomaterial,student assessment,Student Attitudes,Teachers,Teaching Methods},
  file = {/Users/colin.madland/Zotero/storage/W2ZI358W/ajjawiPerformingStandardsCritical2021.pdf}
}

@incollection{ajjawiRepositioningAssessmentasPortrayalWhat2020,
  title = {Repositioning {{Assessment-as-Portrayal}}: {{What Can We Learn}} from {{Celebrity}} and {{Persona Studies}}?},
  shorttitle = {Repositioning {{Assessment-as-Portrayal}}},
  booktitle = {Re-Imagining {{University Assessment}} in a {{Digital World}}},
  author = {Ajjawi, Rola and Boud, David and Marshall, David},
  editor = {Bearman, Margaret and Dawson, Phillip and Ajjawi, Rola and Tai, Joanna and Boud, David},
  year = {2020},
  volume = {7},
  pages = {65--78},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-41956-1_6},
  urldate = {2022-03-19},
  isbn = {978-3-030-41955-4 978-3-030-41956-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/372TEJZR/ajjawiRepositioningAssessmentasPortrayalWhat2020.pdf}
}

@article{akatsukaPromotingCriticalThinking2020,
  title = {Promoting {{Critical Thinking Skills}} in an {{Online EFL Environment}}},
  author = {Akatsuka, Yuya},
  year = {2020},
  journal = {Journal of Pan-Pacific Association of Applied Linguistics},
  volume = {24},
  number = {2},
  pages = {95--113},
  issn = {ISSN-1345-8353},
  doi = {10/gmbv3z},
  abstract = {This study examined the effects of an approach that promotes EFL learners' critical thinking in an online EFL setting. Although recent studies have examined approaches to foster EFL learners' critical thinking, studies conducted in online settings are under-development. The participants were 31 Japanese undergraduate students enrolled in an online EFL course; their degree of critical thinking and resistance towards critical thinking were examined. First, the students' sense of classroom community was measured using the Rovai's Classroom Community Scale. Second, the frequency of using critical thinking in their English writing was observed adopting with Stapleton's rubric, and the resistance towards learning critical thinking was measured through a questionnaire. The results indicated that students could feel a sense of classroom community in online lessons as well as face-to-face settings, and improvements in critical thinking were found in students' writing regardless of the differences in their English proficiency level. A resistance towards tackling questions that required higher-order thinking was observed among low English proficiency level students compared to a face-to-face classroom setting. This study suggests that an online EFL course aiming to promote critical thinking reduce students' resistance offering both informal and formal interactive opportunities to answer questions involving higher-order thinking skills.},
  langid = {english},
  keywords = {Critical Thinking,English (Second Language),Foreign Countries,Language Proficiency,Online Courses,Outcomes of Education,Resistance (Psychology),Second Language Learning,Sense of Community,Thinking Skills,Undergraduate Students,Writing (Composition)}
}

@article{akbayTestDeliveryMedium2021,
  title = {Test {{Delivery Medium Matters}}: {{Cognitive Effort Exertion}} on {{Assessment}}},
  author = {Akbay, Tuncer and Akbay, Lokman and Erol, Osman},
  year = {2021},
  month = jan,
  journal = {Malaysian Online Journal of Educational Technology},
  volume = {9},
  number = {2},
  pages = {76--85},
  publisher = {Malaysian Online Journal of Educational Technology},
  issn = {2289-2990},
  doi = {10.52380/mojet.2021.9.2.273},
  abstract = {Integration of e-learning and computerized assessments into many levels of educational programs has been increasing as digital technology progresses. Due to a handful of prominent advantages of computer-based-testing (CBT), a rapid transition in test administration mode from paper-based-testing (PBT) to CBT has emerged. Recently, many national and international testing agencies have been offering an electronic version of some low- and high-stake tests along with their paper versions. In this study, we aim to examine test administration mode effect from a standpoint of cognitive effort exertion. To this end, the results of this experimental study suggest that the cognitive effort exertion rates of CBT and PBT examinees are different. More specifically, the study results suggest empirical evidence that examinees exert higher cognitive effort in a CBT in comparison to its PBT counterpart.},
  keywords = {Cognitive Ability,College Students,Comparative Analysis,Computer Assisted Testing,English (Second Language),Foreign Countries,High Stakes Tests,International Assessment,Language Tests,Majors (Students),Second Language Instruction,Second Language Learning,State Universities,Student Motivation,Test Format,Test Items,Testing,Turkey},
  file = {/Users/colin.madland/Zotero/storage/PZ3W945K/akbayTestDeliveryMedium2021.pdf}
}

@article{akcayViewsPreServiceElementary2021,
  title = {The {{Views}} of {{Pre-Service Elementary Teachers About Online}} and {{Traditional Peer Assessment}}},
  author = {Akcay, {\relax AO} and Guven, U and Karahan, E},
  year = {2021},
  journal = {International Journal of Assessment Tools in Education},
  volume = {8},
  number = {2},
  pages = {409--422},
  issn = {2148-7456},
  doi = {10.21449/ijate.762104},
  abstract = {The goal of this study is to compare traditional peer evaluation and online peer evaluation in order to identify which method is more effective in evaluating peers. Qualitative research method was used in this study to understand pre-service teachers' opinions on different peer evaluation techniques. The study was carried out in a state university in Turkey. The sample consisted of 58 second year pre-service teachers majoring in primary school teacher program who enrolled in "Instructional Technologies and Material Development" course. Pre-service teachers were divided into 11 groups, with five or six students in each group. Participation was voluntary and the students in each group actively participated in the traditional and online peer assessment activities. The analyses of the data were done via content analysis, by creating categories and then themes. The themes that emerged as a result of the analysis of the data collected within the study were (1) objectivity, (2) evaluation criteria, (3) interaction, and (4) attributes of the online evaluation platform. The study concluded that a combination of peer and instructor evaluation and even selfassessment can give a better validity and objectivity of assessment.},
  langid = {english},
  keywords = {Elementary Teacher Education,HIGHER-EDUCATION,Online peer assessment,SCIENCE,SELF-ASSESSMENT,Traditional peer-assessment},
  file = {/Users/colin.madland/Zotero/storage/4A2JYVB3/akcayViewsPreServiceElementary2021.pdf}
}

@article{akhtarAssessmentLiteracyProspective2021,
  title = {Assessment {{Literacy}} of {{Prospective Teachers}} in {{Distance Mode}} of {{Education}}: {{A Case Study}} of {{Allama Iqbal Open University}}, {{Islamabad}}},
  author = {Akhtar, Zarina and Hussain, Sajjad and Ahmad, Nasir},
  year = {2021},
  month = jun,
  journal = {Journal of Education and Educational Development},
  volume = {8},
  number = {1},
  pages = {218--234},
  publisher = {{Journal of Education and Educational Development}},
  issn = {2310-0869},
  abstract = {Pre-service teacher education comprises essential courses to prepare prospective teachers for effective classroom assessment practices. The study analyzes study material on students' assessment and assessment literacy of prospective teachers is investigated which require close attention of policy makers and practitioners for authentic assessment in classrooms. A sequential triangulation research design, using mix-method approaches, has been used for this research. All distance education students studying in B.Ed. and M.Ed. programs at Allama Iqbal Open University, Islamabad make the target population of the study. Through random sampling techniques, a sample of 344 prospective teachers and 18 teacher educators constitute the sample group. Results indicate that the study material satisfied the standards as stipulated in the National Professional Standards for Teachers in Pakistan; however, the assessment literacy of prospective teachers was found unsatisfactory. Furthermore, it was revealed that students' low motivation, low interaction between tutors and prospective teachers, and traditional approaches and beliefs were found to be the areas requiring urgent attention with regard to reforms in assessment. The presentation of study materials is found to be less engaging with no clearly specified road map for implementation in classrooms. Assessment practices by teacher educators included only summative approaches. Therefore, it is recommended that the study materials may be re-designed to ensure that it leads towards prospective teachers' assessment literacy.},
  keywords = {Alignment (Education),Assessment Literacy,Barriers,Distance Education,Ethics,Foreign Countries,Graduate Students,Instructional Effectiveness,Knowledge Level,No DOI found,Open Universities,Pakistan,Preservice Teacher Education,Preservice Teachers,Standards,Undergraduate Students}
}

@article{akilliSelectionScholarshipStudents2020,
  title = {Selection of {{Scholarship Students}} in {{Higher Education}} with {{VIKOR Method}}},
  author = {Akilli, Kubra and Ipekci Cetin, Emre},
  year = {2020},
  journal = {International Journal of Assessment Tools in Education},
  volume = {7},
  number = {3},
  pages = {379--391},
  issn = {EISSN-2148-7456},
  abstract = {Selection of students who will benefit from scholarships given in the university are usually done by formed commission. Due to limited number of scholarships offered, commission are obliged to choose the most appropriate students. In this selection process, it is important to make objective evaluation. The commission should mostly interview the applicants face to face. This situation causes time and labour loss and a stressful environment for both members of the commission and the students. An objective scoring system could solve the problems discussed above. In this study, 200 students who applied for the scholarship at Akdeniz University Faculty of Economics and Administrative Sciences to the scholarship were ranked. In this study, firstly the selection criteria of students for the scholarship was determined with the help of researchers and social aid service experts. Then, the weights of the criteria were calculated by the SWING method. These weights were used to rank the students who were eligible for the scholarship by using the VIKOR method. This method will make an objective evaluation and will accelerate the selection process.},
  langid = {english},
  keywords = {College Students,Evaluation Methods,Foreign Countries,No DOI found,Scholarships,Selection,Selection Criteria}
}

@article{akyarAssessmentNegotiationStyles2022,
  title = {Assessment of Negotiation Styles in Higher Education through a Game-Based Assessment Tool},
  author = {Akyar, {\"O}zg{\"u}r Ya{\c s}ar and Demirhan, G{\i}yasettin},
  year = {2022},
  journal = {Education and information technologies},
  volume = {27},
  number = {4},
  pages = {4987--5004},
  publisher = {Springer US},
  address = {New York},
  issn = {1360-2357},
  doi = {10.1007/s10639-021-10823-6},
  abstract = {The purpose of this concurrent mixed-method research is to examine the negotiation styles of candidate sports coaches in higher education by using a game-based assessment tool called ENACT game. The research was carried out with 3rd and 4th-degree university students who study in coaching education programs in Turkey. Students consist of 221 male (\%68,4) and 102 female (\%31,6). Furthermore, 12 volunteer students were interviewed as part of the qualitative part of the research. Results indicate that there is a positive significant relationship between conflict-handling styles and negotiations style only among integrating style and avoiding style. On the other hand, there is no significant relationship between the dominating, compromising, obliging styles of conflict handling and the dominating, compromising, and obliging styles of negotiation, respectively. Interviews with students revealed that negotiations in ENACT game-based assessment are very close to their real-life experience. Besides, it can be stated that discussing the aspects of the student's views on the goal achievement effort, relationship, and social skills according to the framework of the social interdependence can make significant contributions to further improvement of the ENACT game-based assessment tool.},
  keywords = {Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Education,Education & Educational Research,Education Higher,Educational Technology,Higher education,Information Systems Applications (incl.Internet),Negotiations,Pharmaceutical industry,Social Sciences,Students,User Interfaces and Human Computer Interaction}
}

@book{akyolEducationalCommunitiesInquiry2012,
  title = {Educational Communities of Inquiry: Theoretical Framework, Research, and Practice},
  author = {Akyol, Zehra and Garrison, Randy},
  year = {2012},
  month = sep,
  publisher = {Information Science Reference},
  address = {United States},
  isbn = {978-1-4666-2110-7}
}

@article{akyolUnderstandingCognitivePresence2011,
  title = {Understanding Cognitive Presence in an Online and Blended Community of Inquiry: {{Assessing}} Outcomes and Processes for Deep Approaches to Learning},
  author = {Akyol, Zehra and Garrison, D. Randy},
  year = {2011},
  month = mar,
  journal = {British Journal of Educational Technology},
  volume = {42},
  number = {2},
  pages = {233--250},
  issn = {1467-8535},
  doi = {10.1111/j.1467-8535.2009.01029.x},
  abstract = {This paper focuses on deep and meaningful learning approaches and outcomes associated with online and blended communities of inquiry. Applying mixed methodology for the research design, the study used transcript analysis, learning outcomes, perceived learning, satisfaction, and interviews to assess learning processes and outcomes. The findings for learning processes and outcomes indicated that students in both online and blended courses were able to reach high levels of cognitive presence and learning outcomes. The results suggest that cognitive presence in a community of inquiry is associated with perceived and actual learning outcomes. It is recommended that future research efforts focus on quantitative measures to establish links between cognitive presence and the quality of learning outcomes.}
}

@article{al-husbanCriticalThinkingSkills2020,
  title = {Critical {{Thinking Skills}} in {{Asynchronous Discussion Forums}}: {{A Case Study}}},
  author = {{Al-Husban}, Naima Ahmad},
  year = {2020},
  month = sep,
  journal = {International Journal of Technology in Education},
  volume = {3},
  number = {2},
  pages = {82--91},
  publisher = {International Journal of Technology in Education},
  issn = {2689-2758},
  doi = {10.46328/ijte.v3i2.22},
  abstract = {This study investigated critical thinking indicators of students' postings on the asynchronous online discussion forums on the learning management system (LMS) at Arab Open University (AOU), Jordan. The models used to diagnose nineteen students' postings were Garrisons' (2001) thinking skills and Newman (1995). Results revealed that participants' postings reflected the critical thinking indicators proposed by Newman like relevance and importance, but students need to enhance skills like justification, and critical assessment. According to Garrisons' model, participants could identify, and explore problems, but they need support to evaluate the problem and integrate solutions into their existing knowledge. The findings reveal that participants acquire essential critical thinking skills, but they need to focus on higher order skills. Further research should be conducted using different courses issues to impart the critical thinking indicators that students need in higher institutions. In addition, instructors should be trained on how to formulate online tasks that stimulate high level of thinking.},
  keywords = {Asynchronous Communication,College Students,Critical Thinking,Discussion Groups,Electronic Learning,English (Second Language),Foreign Countries,Integrated Learning Systems,Jordan,Second Language Instruction,Skill Development,Thinking Skills},
  file = {/Users/colin.madland/Zotero/storage/3I5KPPGB/al-husbanCriticalThinkingSkills2020.pdf}
}

@techreport{albertHowHandleAuthorship2009,
  title = {How to Handle Authorship Disputes: A Guide for New Researchers},
  shorttitle = {How to Handle Authorship Disputes},
  author = {Albert, Tim and Wager, Elizabeth},
  year = {2009},
  month = sep,
  institution = {Committee on Publication Ethics},
  doi = {10.24318/cope.2018.1.1},
  urldate = {2023-11-10},
  file = {/Users/colin.madland/Zotero/storage/URIMQUFJ/albertHowHandleAuthorship2009.pdf}
}

@article{albertoosterhofAssessingLearnersOnline2007,
  title = {Assessing {{Learners Online}}},
  author = {{Albert Oosterhof} and {Donald P. Ely}},
  year = {2007},
  abstract = {PART I. Establishing a Framework for Assessing Students 1. Historical Perspective 2. Measuring Knowledge 3. Gathering Evidence of Validity 4. Generalizing Observed Performance to Unobserved Performance PART II. Determining an Assessment Plan 5. Determining What to Assess 6. Determining How Assessments Will Be Interpreted and Used PART III. Producing and Administering Written Assessments 7. Creating Constructed-Response Items 8. Creating Fixed-Response Items 9. Administering Written Tests on the Web PART IV. Producing and Administering Performance Assessments 10. Considerations When Using Performance Assessments 11. Creating Online Performance Assessments 12. Managing Online Performance Assessments PART V. Assessing Online Interaction and Collaboration 13. Interaction and Collaboration Online 14. Managing Assessment of Interaction and Collaboration Glossary References Index}
}

@incollection{alexanderInformationManagementKnowledge2018,
  title = {Information {{Management Versus Knowledge Building}}: {{Implications}} for {{Learning}} and {{Assessment}} in {{Higher Education}}},
  booktitle = {Assessment of {{Learning Outcomes}} in {{Higher Education}}: {{Cross-National Comparisons}} and {{Perspectives}}},
  author = {Alexander, {\relax PA}},
  editor = {ZlatkinTroitschanskaia, O and Toepper, M and Pant, {\relax HA} and Lautenbach, C and Kuhn, C},
  year = {2018},
  pages = {43--56},
  doi = {10.1007/978-3-319-74338-7_3},
  abstract = {The goal of this paper is to consider two distinct orientations toward learning within the context of twenty-first-century higher education that have implications for assessment of outcomes internationally-information management and knowledge building. These two orientations are compared and contrasted along various dimensions, and potential contributors to the pervasiveness of the information management profile within the current generation of undergraduates are explored. With this background established, pertinent steps toward fostering more effective information management and enhancing knowledge building in higher education contexts are shared with specific attention to the role of assessment practices.},
  isbn = {2367-170X},
  langid = {english},
  keywords = {COGNITION,CRITICAL-ANALYTIC THINKING,ENGAGEMENT,EPISTEMIC BELIEFS,MODEL,TECHNOLOGY}
}

@article{alexanderluisortizocanaDecolonizingResearchEducation2017,
  title = {{Decolonizing Research in Education}},
  author = {{Alexander Luis Ortiz Oca{\~n}a}},
  year = {2017},
  journal = {Praxis},
  volume = {13},
  number = {1},
  pages = {93--104},
  issn = {1657-4915},
  doi = {10.21676/23897856.2112},
  abstract = {In this article is characterized the genesis of it turn decolonial and is valued the possibility of developing biopraxis pedagogical decolonial. It is suggested that the configuration of other forms of research: research decolonial. Proposes a classification of types of coloniality, introducing the notions of self-coloniality and interculturality decolonial, as basic concepts in the education Research. The reflections derived from this research are concentrated on two essential aspects: the configurations in the educational sciences and dialectical relations between reality, world and human knowledge.},
  langid = {spanish},
  keywords = {Biopraxis pedagogicas decoloniales,colonialidad,decolonialidad,interculturalidad decolonial,investigacion decolonial,perspectiva decolonial ciencias de la educacion}
}

@misc{AlexanderUniversityLethbridge2022,
  title = {Alexander v {{University}} of {{Lethbridge}}},
  year = {2022},
  month = jun,
  number = {2101-0086AC},
  urldate = {2023-10-05},
  file = {/Users/colin.madland/Zotero/storage/RNB5TD6J/AlexanderUniversityLethbridge2022.pdf;/Users/colin.madland/Zotero/storage/D357MB9I/2022abca228.html}
}

@article{alexiouExaminingSelfregulatedLearning2019,
  title = {Examining Self-Regulated Learning through a Social Networking {{ePortfolio}} in Higher Education},
  author = {Alexiou, A and Paraskeva, F},
  year = {2019},
  journal = {International Journal of Learning Technology},
  volume = {14},
  number = {2},
  pages = {162--192},
  issn = {1477-8386},
  doi = {10.1504/IJLT.2019.101849},
  abstract = {The use of social media applications can have negative effects on performance and as a result the need for interventions supporting learners to self-monitor, manage technology use and academic performance is pressing. The main focus of this research is the implementation of an ePortfolio through a course in higher education for empowering students to manage their academic path. An ePortfolio, as a dynamic social networking tool, was developed along the lines of self-regulated learning (SRL) with the aim of influencing student's self-regulatory capacity. To satisfy the purpose of the study a paired-samples t-test and correlations were employed to explore statistical differences on the levels of SRL processes. The findings reveal that there is a significant increase on the means across SRL processes. Future research needs to explore SRL effects on learning in the context of an ePortfolio using a set of assessment tools for capturing learning outcomes with greater precision.},
  langid = {english},
  keywords = {academic performance,ACADEMIC-PERFORMANCE,ACHIEVEMENT,ATTITUDES,CLASSROOM,EFFICACY,ePortfolio,higher education,MOTIVATED STRATEGIES,PORTFOLIOS,QUESTIONNAIRE,self-regulated learning,SRL,SRL models,SRL processes,TECHNOLOGY,undergraduate students,UNIVERSITY-STUDENTS}
}

@article{aliDesignCurriculumAssessment2018,
  title = {The {{Design}} of {{Curriculum}}, {{Assessment}} and {{Evaluation}} in {{Higher Education}} with {{Constructive Alignment}}},
  author = {Ali, Liaqat},
  year = {2018},
  journal = {Journal of Education and e-Learning Research},
  volume = {5},
  number = {1},
  pages = {72--78},
  issn = {ISSN-2518-0169},
  doi = {10/gmbv3g},
  abstract = {In higher education, the principle of constructive alignment for devising teaching, learning activities and assessment tasks is the underpinning concept in curriculum design and development to achieve intended learning outcomes. Student's deep learning is critical and it is the responsibility of the curriculum developer to make sure that synergy between formative and summative assessment is achieved. Also, the needs for special education must be addressed and diversity must be achieved through multiple channels throughout the process of learning, teaching and assessment. Constructive alignment is considered as a key element in education design. However, this requires time and effort in designing teaching and assessment. Due to the importance of constructive alignment, the research in this paper discusses issues relevant to the process of curriculum design and development with the emphasis on students with special needs. Conclusion is drawn based on the literature review.},
  langid = {english},
  keywords = {Alignment (Education),Curriculum Design,Curriculum Development,Curriculum Evaluation,Disabilities,Educational Assessment,Educational Legislation,Educational Objectives,Equal Education,Federal Legislation,Feedback (Response),Foreign Countries,Formative Evaluation,Higher Education,Special Education,Special Needs Students}
}

@article{aliOnlineRemoteLearning2020,
  title = {Online and {{Remote Learning}} in {{Higher Education Institutes}}: {{A Necessity}} in {{Light}} of {{COVID-19 Pandemic}}},
  author = {Ali, Wahab},
  year = {2020},
  journal = {Higher Education Studies},
  volume = {10},
  number = {3},
  pages = {16--25},
  issn = {ISSN-1925-4741},
  doi = {10/ghwrj3},
  abstract = {In light of the rising concerns about the spread of COVID-19 and calls to contain the Corona Virus, a growing number of tertiary institutions have shut down in regards to face-to-face classes globally. The Corona virus has revealed emerging vulnerabilities in education systems around the world. It is now clear that society needs flexible and resilient education systems as we face unpredictable futures. A meta-analysis methodology was adopted for this study and pertinent literature was visited to capture the essence of continued learning during these unprecedented times. Findings reveal that universities worldwide are moving more and more towards online learning or E- Learning. Findings also reveal that apart from resources, staff readiness, confidence, student accessibility and motivation play important function in ICT integrated learning. This exploratory paper proposes that staff members should use technology and technological gadgets to enhance learning especially during these exceptional times. Findings also propose online and remote learning as a necessity in times of lock downs and social distancing due to COVID-19 pandemic. It also provides a strong platform for further research.},
  langid = {english},
  keywords = {Access to Computers,Access to Education,Change Strategies,College Faculty,COVID-19,Disease Control,Distance Education,Educational Change,Educational Resources,Educational Technology,Electronic Learning,Foreign Countries,Higher Education,Online Courses,Pandemics,Politics of Education,School Closing,Teacher Competencies,Technology Integration,Telecommunications,World Problems}
}

@article{alkabiProposedArtificialIntelligence2023,
  title = {Proposed Artificial Intelligence Algorithm and Deep Learning Techniques for Development of Higher Education},
  author = {Al Ka'bi, Amin},
  year = {2023},
  journal = {International Journal of Intelligent Networks},
  volume = {4},
  pages = {68--73},
  issn = {26666030},
  doi = {10.1016/j.ijin.2023.03.002},
  urldate = {2023-09-23},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/SHRY8FIX/alkabiProposedArtificialIntelligence2023.pdf}
}

@article{alkharusiClassroomAssessmentTeacher2014,
  title = {Classroom {{Assessment}}: {{Teacher Practices}}, {{Student Perceptions}}, and {{Academic Self-Efficacy Beliefs}}},
  shorttitle = {Classroom {{Assessment}}},
  author = {Alkharusi, Hussain and Aldhafri, Said and Alnabhani, Hilal and Alkalbani, Muna},
  year = {2014},
  month = jun,
  journal = {Social Behavior and Personality: an international journal},
  volume = {42},
  number = {5},
  pages = {835--855},
  issn = {0301-2212},
  doi = {10/f6c65w},
  urldate = {2021-06-20},
  abstract = {We examined the effects of teachers' classroom assessment practices and students' perceptions of assessment tasks on students' academic self-efficacy beliefs as 1 dimension of student academic motivation. Participants (               N               = 1,457) were students sourced from 99 classrooms of public  secondary schools in Oman. Results of multilevel analysis showed that student academic self-efficacy beliefs were significantly and positively influenced by students' perceptions of the assessment tasks. Specifically, congruence with planned learning, authenticity, transparency, and diversity  all had significant positive influences on self-efficacy beliefs, as did frequent communication by the teacher about the assessment with students and teachers' frequent use of nonachievement grading factors. Implications are discussed for classroom practices and research related to classroom  assessment.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/WRHNJ8UB/alkharusiClassroomAssessmentTeacher2014.pdf}
}

@article{alkharusiEducationalAssessmentAttitudes2012,
  title = {Educational {{Assessment Attitudes}}, {{Competence}}, {{Knowledge}}, and {{Practices}}: {{An Exploratory Study}} of {{Muscat Teachers}} in the {{Sultanate}} of {{Oman}}},
  shorttitle = {Educational {{Assessment Attitudes}}, {{Competence}}, {{Knowledge}}, and {{Practices}}},
  author = {Alkharusi, Hussain and Aldhafri, Said and Alnabhani, Hilal and Alkalbani, Muna},
  year = {2012},
  month = oct,
  journal = {Journal of Education and Learning},
  volume = {1},
  number = {2},
  pages = {p217},
  issn = {1927-5269, 1927-5250},
  doi = {10/r7f},
  urldate = {2021-07-29},
  file = {/Users/colin.madland/Zotero/storage/E93A4DGN/alkharusiEducationalAssessmentAttitudes2012.pdf}
}

@article{allanMigrationTransformationSociomaterial2020,
  title = {Migration and {{Transformation}}: {{A Sociomaterial Analysis}} of {{Practitioners}}' {{Experiences}} with {{Online Exams}}},
  author = {Allan, Stuart},
  year = {2020},
  journal = {Research in Learning Technology},
  volume = {28},
  issn = {ISSN-2156-7069},
  doi = {10/gmbv3q},
  abstract = {Many institutions are making the move from pen and paper to online examinations, but the literature offers relatively few critical reflections on the ramifications of such a shift. This research presents evidence of the ways in which the social and human practices of online exams are deeply entangled with the material and technological, and cautions against the reinscribing of essentialist or instrumentalist assumptions about technology in assessment practices. Through semi-structured interviews with eight practitioners in Norway, the Netherlands, the UK and Ireland, it analyses the impact, dimensions and limitations of two main discourses: "migration," whereby exam technologies are assumed to be neutral instruments used independently by humans to realise their preordained intentions; and "transformation," whereby the essential and inalienable qualities of technologies can be released to 'transform' or 'enhance' assessment. Its findings indicate that: (1) exam technologies are neither inherently neutral nor essentially transformational; (2) implementation projects underpinned by the migration discourse can be much more complex and resource-intensive than anticipated; and (3) 'transformative' change may be value-laden and driven by assumptions. Given the complex and entangled nature of online exams, practitioners are encouraged to think creatively about how assessment strategies align with educational goals, to consider the limitations of current discourses and to analyse critically the relational and performative roles of digital technologies.},
  langid = {english},
  keywords = {Adoption (Ideas),College Faculty,Computer Assisted Testing,Educational Benefits,Educational Change,Evaluation Methods,Foreign Countries,Higher Education,Student Evaluation,Teacher Attitudes}
}

@article{allenAssessingImpactEfficacy2015,
  title = {Assessing the Impact and Efficacy of the Open-Access Chemwiki Textbook Project},
  author = {Allen, Gregory and {Guzman-Alvarez}, Alberto and Molinaro, Marco and Larsen, Delmar},
  year = {2015},
  journal = {Educause Quarterly},
  abstract = {Rapidly rising costs, including the cost of textbooks, impede access to higher education for many students, particularly among underserved and at-risk populations. The \textbf{STEMWiki Hyperlibrary }was initiated by the University of California, Davis, to \textbf{reduce this growing educational cost in the science, technology, engineering, and mathematics (STEM) fields}. The ChemWiki is the primary and most developed component of the Hyperlibrary project, which includes five other STEMWikis. When sufficiently developed, the Hyperlibrary will be leveraged as a platform for the dissemination of content and evaluation of emerging education technologies and pedagogies. Because the ChemWiki modules are hyperlinked both internally and externally to the modules within the other STEMWikis, students are exposed to a wide range of content at varying levels of difficulty, which allows for the simultaneous instruction of students with diverse backgrounds and performance.},
  keywords = {affordability,assessment and evaluation,digital content,learning objects,oer,open access,open educational resources,student success,student technology use}
}

@incollection{allyFoundationsEducationalTheory2008,
  title = {Foundations of {{Educational Theory}} for {{Online Learning}}},
  booktitle = {The {{Theory}} and {{Practice}} of {{Online Learning}}},
  author = {Ally, Mohamed},
  editor = {Anderson, Terry},
  year = {2008},
  edition = {2nd},
  pages = {15--44},
  publisher = {Athabasca University},
  address = {Athabasca}
}

@article{almaiahApplyingUTAUTModel2019,
  title = {Applying the {{UTAUT Model}} to {{Explain}} the {{Students}}' {{Acceptance}} of {{Mobile Learning System}} in {{Higher Education}}},
  author = {Almaiah, M. A. and Alamri, M. M. and {Al-Rahmi}, W.},
  year = {2019},
  journal = {IEEE Access},
  volume = {7},
  pages = {174673--174686},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2019.2957206},
  abstract = {Mobile learning applications have been growing in demand and popularity and have become a common phenomenon in modern educational systems, especially with the implementation of mobile learning projects. This study applies the Unified Theory of Acceptance and Use Technology (UTAUT) model to examine the effects of different factors that were identified from the literature on students' acceptance of mobile learning applications in higher education. The data was collected from a 697 university students responded to an online questionnaire. SEM method was used for data analysis. The results showed that perceived information quality, perceived compatibility, perceived trust, perceived awareness, and availability of resources, self-efficacy, and perceived security are the main motivators of students' acceptance of mobile learning system, and consequently success the implementation of mobile learning projects. Results from this study provide the necessary information as to how higher education institutions can enhance students' acceptance of mobile learning system in order to support the usage of mobile technologies in learning and teaching process. These results offer important implications for mobile learning acceptance and usage.},
  file = {/Users/colin.madland/Zotero/storage/GJSN6EBB/almaiahApplyingUTAUTModel2019.pdf}
}

@article{almossaAssessmentApproachesEnglish2022,
  title = {Assessment Approaches of {{English}} Language Teachers in the {{Saudi}} Higher Education Context},
  author = {Almossa, Samar Yakoob and Alzahrani, Sahar Matar},
  year = {2022},
  journal = {Language Testing in Asia},
  volume = {12},
  number = {1},
  pages = {10},
  issn = {2229-0443},
  doi = {10.1186/s40468-022-00160-x},
  urldate = {2022-05-29},
  abstract = {Abstract             Assessment approaches including assessment purposes, assessment processes, fairness, and measurement theory, and English teachers' professional development needs remain underexplored in the Middle East and North Africa regions. This study provided empirical evidence on English language teachers approaches in the Saudi higher education context. A survey was used to examine the teachers' current approaches to classroom assessment. A total of 287 subjects (191 women and 94 men) participated in the survey. The results revealed that both the male and female participants valued and endorsed assessments alike. However, female participants were found to value assessment purposes more than their male counterparts. Fairness in assessment approaches was the least valued item in teachers' identified assessment approaches. Experienced teachers who identified themselves as competent in their role valued assessment fairness and measurement theory more than novice teachers. The present work broadens our knowledge on teachers' assessment approaches in relation to gender, career stage, and academic position, which support interested researchers and policy-makers in decision-making regarding designing professional development programs.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/W7DHDI2V/almossaAssessmentApproachesEnglish2022.pdf}
}

@article{almossaAssessmentPracticesSaudi2022,
  title = {Assessment Practices in {{Saudi}} Higher Education during the {{COVID-19}} Pandemic},
  author = {Almossa, Samar Yakoob and Alzahrani, Sahar Matar},
  year = {2022},
  journal = {Humanities \& social sciences communications},
  volume = {9},
  number = {1},
  publisher = {SPRINGERNATURE},
  address = {LONDON},
  doi = {10.1057/s41599-021-01025-z},
  abstract = {This study determines the assessment practices used by teaching staff in Saudi universities, explores how these assessment practices have changed during the coronavirus disease 2019 pandemic, and investigates how teaching staffs' priorities and preferences for education on assessment during the pandemic were shaped. To support professional development, the study also aims to raise teaching staffs' awareness of assessment practices. Teaching staff in Saudi universities were invited to complete the Approaches to Classroom Inventory survey. The results showed that the most highly endorsed practices included giving feedback, linking assessments to learning objectives and learning outcomes, using scoring guides, and monitoring and revising assessment approaches. The least endorsed practices included mapping summative assessment to curriculum expectations, responding to the cultural and linguistic diversity of students, and accommodating students with special needs/exceptionalities in assessments. Further, during the pandemic, formative assessments were rarely used. Although faculty members from various colleges and fields of specialty showed similar patterns in endorsing assessment practices, they differed in their preferences and needs for assessment education.},
  langid = {english},
  keywords = {Arts & Humanities,Arts & Humanities - Other Topics,Humanities Multidisciplinary,Social Sciences,Social Sciences - Other Topics,Social Sciences Interdisciplinary}
}

@article{almossaLessonsMaintainingAssessment2022,
  title = {Lessons on Maintaining Assessment Integrity during {{COVID-19}}},
  author = {Almossa, Samar Yakoob and Alzahrani, Sahar Matar},
  year = {2022},
  journal = {International journal for educational integrity},
  volume = {18},
  number = {1},
  pages = {1--17},
  publisher = {Springer Nature Singapore},
  address = {Singapore},
  issn = {1833-2595},
  doi = {10.1007/s40979-022-00112-1},
  abstract = {In an era where conditions for education are rapidly changing globally, online assessment presents several opportunities as well as challenges in the higher education landscape. The forceful transition from face-to-face to online assessments, as part of the emergency implementation of online learning due to the COVID-19 pandemic, has affected teaching, learning, and assessment experiences worldwide. This study explores how faculty members in Saudi universities secured their online assessment during phase one of the COVID-19 pandemic. The research aims were: 1) identifying faculty assessment practices before the onset of COVID-19 and comparing these with practices during the pandemic, and 2) identifying the major challenges faced by the faculty members of the study in securing their online assessment to ensure that academic integrity and assessment standards remained intact. Data were collected from seven university professors through a self-reporting survey, followed by semi-structured interviews. The faculty members found the pandemic period to be the best time to change their assessment methods, and incorporate innovative ideas that conformed to both their own beliefs and students' needs. The factors that influenced the faculty's assessment alterations were their personal beliefs and learnings from others' experiences, in addition to the guidelines issued by Saudi Arabia's Ministry of Education. The results of this study have implications for the development of post-COVID-19 assessment practices and professional development priorities.},
  keywords = {Barriers,Beliefs,College Faculty,Computer Assisted Testing,COVID-19,Education,Educational Technology,Emergency online teaching,Ethics,Evaluation Methods,Foreign Countries,Higher Education,Integrity,International and Comparative Education,Online assessment,Online Courses,Online learning,Original,Original Article,Pandemics,Student Evaluation,Teacher Attitudes,Technology Uses in Education},
  file = {/Users/colin.madland/Zotero/storage/K56IGH2L/almossaLessonsMaintainingAssessment2022.pdf}
}

@article{almossaUniversityStudentsPerspectives2021,
  title = {University Students' Perspectives toward Learning and Assessment during {{COVID-19}}},
  author = {Almossa, Samar Yakoob},
  year = {2021},
  journal = {Education and information technologies},
  volume = {26},
  number = {6},
  pages = {7163--7181},
  publisher = {Springer US},
  address = {New York},
  issn = {1360-2357},
  doi = {10.1007/s10639-021-10554-8},
  abstract = {This article presents the findings of a study exploring students' reports of their engagement with online learning and assessment during the COVID-19 pandemic in Saudi higher education. Students shared perspectives on Twitter about their engagement, and research data was collected from their tweets posted between March and May 2020. A total of 124,810 tweets were analysed using MAXQDA quantitative and qualitative tools. The findings indicate that students' engagement with learning and assessment was affected by the challenges of the sudden shift in learning mode and alterations in assessment methods. Open communication between students and faculty are essential for ensuring shared understanding and acceptance. Additionally, departmental support and mediating between students and faculty members is necessary and should be a priority in cases where communication is lacking. Results are discussed in relation to current literature, research implications, and future directions.},
  keywords = {Assessment,College Students,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Coronaviruses,COVID-19,Distance learning,Education,Education & Educational Research,Educational Attitudes,Educational Change,Educational evaluation,Educational Technology,Electronic Learning,Epidemics,Evaluation Methods,Foreign Countries,Higher education,Information Systems Applications (incl.Internet),IT and the COVID-19 Pandemic,Learner Engagement,Learning,Online education,Saudi Arabia,Social Media,Social networks,Social Sciences,Student Attitudes,Student Evaluation,Student participation,Students engagement,User Interfaces and Human Computer Interaction},
  file = {/Users/colin.madland/Zotero/storage/TCJ9E2TQ/almossaUniversityStudentsPerspectives2021.pdf}
}

@article{almusharrafErroranalysisStudyEfl2022,
  title = {An Error-Analysis Study from an Efl Writing Context: {{Human}} and Automated Essay Scoring Approaches},
  author = {Almusharraf, Norah and Alotaibi, Hind},
  year = {2022},
  month = apr,
  journal = {Technology, Knowledge and Learning: Learning mathematics, science and the arts in the context of digital technologies},
  publisher = {Springer},
  issn = {2211-1662},
  doi = {10.1007/s10758-022-09592-z},
  abstract = {Evaluating written texts is believed to be a time-consuming process that can lack consistency and objectivity. Automated essay scoring (AES) can provide solutions to some of the limitations of human scoring. This research aimed to evaluate the performance of one AES system, Grammarly, in comparison to human raters. Both approaches' performances were analyzed quantitatively using Corder's (1974) error analysis approach to categorize the writing errors in a corpus of 197 essays written by English as a foreign language (EFL) learners. Pearson correlation coefficient and paired sample t-tests were conducted to analyze and compare errors detected by both approaches. According to the study's results, a moderate correlation between human raters and AES in terms of the total scores and the number of errors detected. Results also indicated that the total number of errors detected by AES is significantly higher than human raters and that the latter tend to give students higher scores. The findings encourage a more open attitude towards AES systems to support EFL writing teachers in assessing students' work. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {Automated essay scoring (AES),Correlation,EFL,Feedback,Human raters,No terms assigned,Writing}
}

@article{alonsoBarriersTeacherPerception2019,
  title = {Barriers in Teacher Perception about the Use of Technology for Evaluation in {{Higher Education}}},
  author = {Alonso, {\relax RR} and Plaza, {\relax IR} and Orfali, {\relax CH}},
  year = {2019},
  journal = {Digital Education Review},
  number = {35},
  pages = {170--185},
  issn = {2013-9144},
  abstract = {This article describes barriers in higher education teachers' perceptions facing changes when innovating in their evaluation practices by integrating information and communication technologies (ICT) in a Chilean university. Forming and evaluating in a competency-based approach involves challenges for the teaching staff and changes in their role that are accepted or resisted. The same happens in the face of innovation processes with information and communication technologies (ICT) integration in teaching practices. The primary results show a relationship between pedagogical beliefs and evaluation which is consistent with adoption and assessment of the digital tool used. In addition, it reveals the role of beliefs as secondary barriers to change in the face of teaching practices with the use of technology (Ertmer, Ottenbreit-Leftwich, Sadik, Sendurur, \& Sendurur, 2012). This study identifies the value of autonomy in student work and feedback as key beliefs in technology adoption.},
  langid = {english},
  keywords = {ADOPTION,Barriers,BELIEFS,CHALLENGES,evaluation of competences,evaluation tools,higher education,ICT,INTEGRATION,No DOI found,professional competences,RUBRICS,UNIVERSITY}
}

@article{alquraanMethodsAssessingStudents2012,
  title = {Methods of Assessing Students' Learning in Higher Education: {{An}} Analysis of {{Jordanian}} College and Grading System},
  shorttitle = {Methods of Assessing Students' Learning in Higher Education},
  author = {Alquraan, Mahmoud F.},
  year = {2012},
  month = jul,
  journal = {Education, Business and Society: Contemporary Middle Eastern Issues},
  volume = {5},
  number = {2},
  pages = {124--133},
  issn = {1753-7983},
  doi = {10/ghhbn7},
  urldate = {2020-10-30},
  langid = {english}
}

@article{alsabhanStudentCheatingDetection2023,
  title = {Student {{Cheating Detection}} in {{Higher Education}} by {{Implementing Machine Learning}} and {{LSTM Techniques}}},
  author = {Alsabhan, Waleed},
  year = {2023},
  journal = {Sensors (Basel, Switzerland)},
  volume = {23},
  number = {8},
  pages = {4149},
  publisher = {Mdpi},
  address = {BASEL},
  issn = {1424-8220},
  doi = {10.3390/s23084149},
  abstract = {Both paper-based and computerized exams have a high level of cheating. It is, therefore, desirable to be able to detect cheating accurately. Keeping the academic integrity of student evaluations intact is one of the biggest issues in online education. There is a substantial possibility of academic dishonesty during final exams since teachers are not directly monitoring students. We suggest a novel method in this study for identifying possible exam-cheating incidents using Machine Learning (ML) approaches. The 7WiseUp behavior dataset compiles data from surveys, sensor data, and institutional records to improve student well-being and academic performance. It offers information on academic achievement, student attendance, and behavior in general. In order to build models for predicting academic accomplishment, identifying at-risk students, and detecting problematic behavior, the dataset is designed for use in research on student behavior and performance. Our model approach surpassed all prior three-reference efforts with an accuracy of 90\% and used a long short-term memory (LSTM) technique with a dropout layer, dense layers, and an optimizer called Adam. Implementing a more intricate and optimized architecture and hyperparameters is credited with increased accuracy. In addition, the increased accuracy could have been caused by how we cleaned and prepared our data. More investigation and analysis are required to determine the precise elements that led to our model's superior performance.},
  keywords = {Academic achievement,Academic misconduct,Accuracy,Analysis,CAI,Cheating,Chemistry,Chemistry Analytical,Computer assisted instruction,Critical thinking,Datasets,Deep learning,Dishonesty,Education,Education Higher,Engineering,Engineering Electrical & Electronic,exploratory data analysis,Higher education,Instruments & Instrumentation,Literature reviews,Machine learning,Methods,Neural networks,Online education,online examination,Physical Sciences,Plagiarism,Science & Technology,Software,student assessment,student cheating detection,Students,Technology},
  file = {/Users/colin.madland/Zotero/storage/HQ6TVCMH/alsabhanStudentCheatingDetection2023.pdf}
}

@article{alsadoonStudentsPerceptionsEAssessment2017,
  title = {Students' {{Perceptions}} of {{E-Assessment}} at {{Saudi Electronic University}}},
  author = {Alsadoon, Hamadah},
  year = {2017},
  month = jan,
  journal = {Turkish Online Journal of Educational Technology - TOJET},
  volume = {16},
  number = {1},
  pages = {147--153},
  publisher = {Turkish Online Journal of Educational Technology - TOJET},
  issn = {2146-7242},
  abstract = {This study explored students' perceptions of E-assessment at Saudi Electronic University. The university recently implemented this mode of assessment in the learning management system it uses. Therefore it is important to examine the students' perceptions of this mode at the university level. The results were encouraging. Students had positive perceptions of e-assessment and valued its features such as immediate feedback and unbiased grading.},
  keywords = {College Students,Computer Assisted Testing,Educational Technology,Foreign Countries,Integrated Learning Systems,No DOI found,Online Surveys,Saudi Arabia,Student Attitudes,Teaching Methods,Technology Uses in Education,Virtual Universities}
}

@article{alsarieraAssessmentEvaluationDifferent2022,
  title = {Assessment and {{Evaluation}} of {{Different Machine Learning Algorithms}} for {{Predicting Student Performance}}},
  author = {Alsariera, Yazan A. and Baashar, Yahia and Alkawsi, Gamal and Mustafa, Abdulsalam and Alkahtani, Ammar Ahmed and Ali, Nor'ashikin},
  year = {2022},
  journal = {Computational intelligence and neuroscience},
  volume = {2022},
  pages = {4151487--11},
  publisher = {Hindawi},
  address = {LONDON},
  issn = {1687-5265},
  doi = {10.1155/2022/4151487},
  abstract = {Student performance is crucial to the success of tertiary institutions. Especially, academic achievement is one of the metrics used in rating top-quality universities. Despite the large volume of educational data, accurately predicting student performance becomes more challenging. The main reason for this is the limited research in various machine learning (ML) approaches. Accordingly, educators need to explore effective tools for modelling and assessing student performance while recognizing weaknesses to improve educational outcomes. The existing ML approaches and key features for predicting student performance were investigated in this work. Related studies published between 2015 and 2021 were identified through a systematic search of various online databases. Thirty-nine studies were selected and evaluated. The results showed that six ML models were mainly used: decision tree (DT), artificial neural networks (ANNs), support vector machine (SVM), K-nearest neighbor (KNN), linear regression (LinR), and Naive Bayes (NB). Our results also indicated that ANN outperformed other models and had higher accuracy levels. Furthermore, academic, demographic, internal assessment, and family/personal attributes were the most predominant input variables (e.g., predictive features) used for predicting student performance. Our analysis revealed an increasing number of research in this domain and a broad range of ML algorithms applied. At the same time, the extant body of evidence suggested that ML can be beneficial in identifying and improving various academic performance areas.},
  keywords = {Academic achievement,Algorithms,Artificial intelligence,Artificial neural networks,Bayesian analysis,Colleges & universities,Data mining,Datasets,Decision trees,Education,Information sources,Learning algorithms,Life Sciences & Biomedicine,Machine learning,Mathematical & Computational Biology,Neural networks,Neurosciences,Neurosciences & Neurology,Performance prediction,Review,Science & Technology,Students,Support vector machines,Teachers},
  file = {/Users/colin.madland/Zotero/storage/2LE5WZIM/alsarieraAssessmentEvaluationDifferent2022.pdf}
}

@article{alshamsiWhyGradedAssessment2021,
  title = {Why {{Graded Assessment}} for {{Undergraduates}} during the {{COVID-19 Lockdown}}? {{An Experience Introspection}}},
  author = {Alshamsi, Abdullatif and Zahavich, Alex and {El-Farra}, Samar},
  year = {2021},
  month = jan,
  journal = {IAFOR Journal of Education},
  volume = {9},
  number = {2},
  pages = {55--75},
  publisher = {IAFOR Journal of Education},
  issn = {2187-0594},
  doi = {10.22492/ije.9.2.04},
  abstract = {This paper presents a retrospective evaluation of the Higher Colleges of Technology's student assessments during the COVID-19 lockdown, reflecting the justified decision to deploy graded assessments during the lockdown for students to academically progress and/or graduate on time, while maintaining the quality and rigor of academic awards. The outcome-based evaluation of this paper is intended to provide lessons for any future situations of this significance and magnitude. While online education was the obvious response to the pandemic, the provision of assessments was not possible without risk. Taking a high-stakes decision that would affect the future of thousands of students, for years to come, involved complex steps of reasoning and justification. Addressing the role of graded assessment in supporting institutional accountability and transferability of students' achievements, student efficacy and informed pedagogy alterations were the main objectives. To meet those objectives, the Higher Colleges of Technology was able to deploy an off-campus student assessment model that builds upon three pillars of adjustments (assessment development and deployment; technology infrastructure; and governance resilience) to support students' learning, while mitigating vulnerabilities. The evaluation of student performance indicators and stakeholders' satisfaction rates revealed a successful deployment of off-campus assessment while maintaining the traditional conventions pertaining to evaluation of assessments.},
  keywords = {Academic Achievement,Computer Assisted Testing,COVID-19,Distance Education,Educational Indicators,Foreign Countries,Formative Evaluation,Outcome Based Education,Pandemics,Student Evaluation,Summative Evaluation,Undergraduate Students,United Arab Emirates},
  file = {/Users/colin.madland/Zotero/storage/EJVBPENY/alshamsiWhyGradedAssessment2021.pdf}
}

@article{altinayEvaluatingPeerLearning2017,
  title = {Evaluating Peer Learning and Assessment in Online Collaborative Learning Environments},
  author = {Alt{\i}nay, Zehra},
  year = {2017},
  journal = {Behaviour \& Information Technology},
  volume = {36},
  number = {3},
  pages = {312--320},
  publisher = {Taylor \& Francis},
  address = {ABINGDON},
  issn = {0144-929X},
  doi = {10/ggrgxd},
  abstract = {Transformation of learning and teaching in higher education now offers greater educational equality through enhanced access and collaboration within the framework of lifelong learning in the digital age. This study aims to evaluate online peer learning and assessment in the collaborative learning process in higher education practices. The study also investigates the impact of online peer learning on the development of skills within collaborative learning through the use of volunteered responses from learners concerning their experiences with and perceptions of online learning. Therefore, a quantitative approach is applied through the administration of a survey with 32 items that is distributed to 715 participants. According to the objective of the study, a set of inferential statistical analyses are performed. The theoretical framework of this study is the CHAT (cultural historical activity theory) which reconstructs the knowledge of learners through the application of the Adobe Connect program to demonstrate how learners can be collaborative and social with their peers in an online context. The results revealed that the collaborative online peer learning process in higher education encourages critical reflection and self-assessment. The study contributes to the understanding of the value of learner satisfaction in online collaborative learning environments through the experiences of learners.},
  keywords = {Collaboration,Collaborative learning,COMPUTER SCIENCE CYBERNETICS,critical reflection,Distance learning,Education,ERGONOMICS,Higher education,HIGHER-EDUCATION,Information technology,Lifelong learning,online education,open education practices,reconstruction of knowledge,Statistical analysis,STUDENTS},
  file = {/Users/colin.madland/Zotero/storage/R65CNZJ9/altinayEvaluatingPeerLearning2017.pdf}
}

@article{altowairikiOnlineCollaborativeLearning2021,
  ids = {altowairikiOnlineCollaborativeLearning2021a},
  title = {Online {{Collaborative Learning}}: {{Analyzing}} the {{Process}} through {{Living}} the {{Experience}}},
  author = {Altowairiki, Noha},
  year = {2021},
  month = jan,
  journal = {International Journal of Technology in Education},
  volume = {4},
  number = {3},
  pages = {413--427},
  publisher = {International Journal of Technology in Education},
  issn = {2689-2758},
  abstract = {Online collaborative learning is a complex process as it requires thoughtful and pedagogical considerations regarding the design, implementation, and assessment. To understand online collaborative learning, it is critical to involve stakeholders' perspectives of their lived experiences. A qualitative case study was selected to carry out the investigation. Two online graduate courses were purposefully involved in the study. Data were collected from semi-structured interviews and online observations of students and instructors. The collected data were analyzed using a constant comparative analysis method. The results revealed that multiple proactive supports (i.e., social, pedagogical, and technical support) play critical roles in fostering meaningful collaboration. Instructor presence is an essential factor that enables collaboration to occur as desired through setting the stage, modeling desired expectations, and guiding students to reach expected outcomes. Assessments also have an impact on students' level of engagement; therefore, incorporating both formative and summative assessments for both the product and the process of collaboration is recommended. The findings of this study have implications for online collaboration scaffolding and implementation to support online instructors.},
  keywords = {Canada,Cooperative Learning,Electronic Learning,Expectation,Facilitators (Individuals),Foreign Countries,Formative Evaluation,Graduate Students,Group Dynamics,No DOI found,Scaffolding (Teaching Technique),Sense of Community,Student Experience,Summative Evaluation,Teacher Role,Trust (Psychology)}
}

@article{alukoCriticalReviewStudent2020,
  ids = {alukoCriticalReviewStudent2020a},
  title = {A {{Critical Review}} of {{Student Assessment Practices}} in {{Distance Education}} in an {{Emerging Economy}}: {{Benchmarking Practices}} against {{Policy}}},
  author = {Aluko, Folake Ruth and Omidire, Margaret Funke},
  year = {2020},
  journal = {Africa education review},
  volume = {17},
  number = {5},
  pages = {76--94},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {1814-6627},
  doi = {10.1080/18146627.2021.1920842},
  abstract = {Higher education in emerging economies has taken advantage of several technology affordances for student assessment in the digital era. However, the use of educational technology remains an area of concern in this context because of unequal technology terrain. This issue is more difficult in distance education, where students live in and work in remote areas. Although distance education providers in emerging economies have started to adopt alternative student assessment strategies, their contexts often force them to continue using conventional assessment methods. Against this backdrop, through a pragmatic mode of inquiry, the authors describe a five-phase study in which they identified the student assessment elements in national quality criteria that are rooted in international standards. These elements were benchmarked against the practices at a higher institution, highlighting good practices and inherent challenges. The findings are discussed in light of the transactional distance theory (TDT), with possible implications for assessment in a digital era. Further research areas are highlighted.},
  keywords = {Assessment,Benchmarking,College Students,Developing Nations,Distance Education,Distance learning,Education,Education & Educational Research,Educational Quality,Educational Theories,Emerging markets,Evaluation Criteria,Evaluation Methods,Foreign Countries,Higher Education,International standards,Praxis,Quality criteria,Remote areas,Social Sciences,Student assessment,Student Evaluation,Students,Technology,Technology Uses in Education,Transactional distance theory},
  file = {/Users/colin.madland/Zotero/storage/N23GMRD4/alukoCriticalReviewStudent2020.pdf}
}

@article{alukoCriticalReviewStudent2020a,
  title = {A {{Critical Review}} of {{Student Assessment Practices}} in {{Distance Education}} in an {{Emerging Economy}}: {{Benchmarking Practices}} against {{Policy}}},
  author = {Aluko, Folake Ruth and Omidire, Margaret Funke},
  year = {2020},
  journal = {Africa education review},
  volume = {17},
  number = {5},
  pages = {76--94},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {1814-6627},
  doi = {10.1080/18146627.2021.1920842},
  abstract = {Higher education in emerging economies has taken advantage of several technology affordances for student assessment in the digital era. However, the use of educational technology remains an area of concern in this context because of unequal technology terrain. This issue is more difficult in distance education, where students live in and work in remote areas. Although distance education providers in emerging economies have started to adopt alternative student assessment strategies, their contexts often force them to continue using conventional assessment methods. Against this backdrop, through a pragmatic mode of inquiry, the authors describe a five-phase study in which they identified the student assessment elements in national quality criteria that are rooted in international standards. These elements were benchmarked against the practices at a higher institution, highlighting good practices and inherent challenges. The findings are discussed in light of the transactional distance theory (TDT), with possible implications for assessment in a digital era. Further research areas are highlighted.},
  keywords = {Assessment,Benchmarking,College Students,Developing Nations,Distance Education,Distance learning,Education,Education & Educational Research,Educational Quality,Educational Theories,Emerging markets,Evaluation Criteria,Evaluation Methods,Foreign Countries,Higher Education,International standards,Praxis,Quality criteria,Remote areas,Social Sciences,Student assessment,Student Evaluation,Students,Technology,Technology Uses in Education,Transactional distance theory}
}

@phdthesis{alvesballontedesquiPersonalityDeliberatePractice2019,
  title = {Personality, {{Deliberate Practice}}, and {{Expertise Development}} in {{Sport}}},
  author = {Alves Ball{\'o}n Tedesqui, Rafael},
  year = {2019},
  month = jan,
  urldate = {2022-02-05},
  abstract = {Conscientiousness-related personality traits are relevant predictors of many outcomes in achievement domains outside sport. They have also been associated with several outcomes in sport, however, their relative role on athletes' deliberate practice (DP) and other criteria of expertise development has not been investigated. The overall aim of this dissertation was to examine the role of conscientiousness-related traits on sport expertise development. It had six specific purposes: (a) to examine the structural validity of conscientiousness-related measures; (b) to understand whether athletes' DP amounts, skill level, and other criteria of expertise development could be predicted by these measures; (c) to identify the best personality predictor and combination of predictors that explained the maximal variance in different criteria of expertise development; (d) to examine whether grit facets predicted athletes' practice engagement across a demanding sport season; (e) to explore coaches' perspectives on the behavioural indicators of conscientious, gritty, and self-controlled athletes in training; and (f) to explore coaches' views about how these personality traits may impact athletes' quantity and quality of practice and development toward higher skill levels. The dissertation used a sequential explanatory mixed-methods design, wherein Phase 1 (Articles 1, 2, and 3) quantitatively pursued purposes (a) to (c), Phase 2 (Article 4) addressed (d), and Phase 3 (Article 5) qualitatively addressed (e) and (f). Article 1 tested the factor structure of the Brief Self-Control Scale in sport and showed distinct associations between self-control variables and (a) sport-specific practice amounts, (b) engagement in various practice contexts, and (c) threats to commitment to one's sport, in a diverse sport sample. Article 2 conducted factor analyses of the Grit Scale in sport and examined a full latent variable model showing associations between grit variables and several criteria of expertise development. In particular, perseverance of effort associated with athletes' weekly amounts of DP, engagement in different practice contexts, and skill level, while consistency of interests associated with athletes' commitment to their sport. Article 3 comprised two studies. In Study 1, path analyses were used to assess the role of conscientiousness on criteria of expertise development. At the broad level, conscientiousness predicted athletes' engagement in practice contexts and commitment to their sport; at the facet-level, achievement-striving was the best predictor of athletes' weekly DP and engagement in practice contexts. The systematic test of the role of self-control (Article 1), grit (Article 2), and conscientiousness (Article 3, Study1) for key criteria of expertise development culminated with Study 2 of Article 3, which reported comparative analyses of the predictive ability of self-control, grit, and conscientiousness facets---which had shown to be significant predictors when assessed separately---for the criterion measures of sport expertise. Study 2 showed that (a) perseverance of effort was the best predictor of athletes' weekly DP, engagement in mandatory practice, and the only predictor of higher skill level, (b) achievement-striving best predicted athletes' engagement in optional practice, and (c) consistency of interests best predicted athletes' commitment to their sport. Article 4 tested whether athletes' self-reported levels of grit (broad and facets) were longitudinally associated with their coach-reported practice engagement throughout one sport season. Perseverance of effort was the grit variable most related to indicators of practice engagement, the only variable related to overall practice engagement across three time points, and the only variable marginally associated with athletes' stability of practice engagement over time. Article 5 explored coaches' views about the behavioural indicators of athletes' conscientiousness, grit, and self-control in the daily training environment and how these traits impacted athletes' training and development. Coaches described (a) conscientious athletes as systematic and detail-oriented, highly considerate of others, and highly engaged in self-regulation; (b) gritty athletes as those who persevere despite adversity and work hard in practice; and (c) self-controlled athletes as those who control impulses, resist temptations, and delay gratification. Coaches believe grit, conscientiousness, and self-control play important roles on athletes' development toward higher skill levels, but results generally highlighted the preponderance of perseverance of effort. Potential mechanisms (e.g., conscientiousness---self-regulation---practice quality and conscientiousness---self-regulation---skill level) were highlighted to help explain the personality-expertise link found in Phases 1 and 2. This dissertation contributed to the literature on sport expertise by parsimoniously identifying conscientiousness-related personality traits that were associated with measures of athletes' practice quantity, quality, and stability, commitment to sport, and higher skill level. Although several facets (i.e., perseverance of effort, consistency of interests, achievement-striving, self-discipline, and dutifulness) showed associations with practice and performance-related outcomes, this dissertation generally highlighted the role of grit facets. In particular, while perseverance of effort was the best predictor of athletes' amounts of DP, the only grit variable associated with quality practice engagement over time, and the only predictor of higher skill level, consistency of interests was the best predictor of commitment variables. Furthermore, results based on coaches' descriptions (a) provided behavioural indicators of conscientiousness-related traits that serve as reference points for practitioners aiming to help athletes develop desirable traits, (b) suggested that gritty athletes `work hard' and conscientious athletes `work smart', and (c) proposed mechanisms to explain the personality-expertise link found in the quantitative studies. Taken together, the results of this dissertation suggest that the tendency to persevere despite adversity and mindfully use self-regulated processes seems to be a powerful predisposition for athletes' development toward expert levels of performance.},
  school = {University of Ottawa},
  keywords = {archived,conscientiousness,deliberate practice,expertise development,grit,personality,self-control},
  file = {/Users/colin.madland/Zotero/storage/5S6DTGAA/alvesballontedesquiPersonalityDeliberatePractice2019.pdf}
}

@article{alviTechnologyPedagogyAssessment2021,
  title = {Technology, {{Pedagogy}} \& {{Assessment}}: {{Challenges}} of {{COVID-19-Imposed E-Teaching}} of {{ESP}} to {{Saudi Female PY Students}}},
  author = {Alvi, Amatul Hafeez and Bilal, Syed Muhammad and Alvi, Aisha Abdul Rahim},
  year = {2021},
  month = apr,
  journal = {Arab World English Journal},
  pages = {334--353},
  publisher = {Arab World English Journal},
  issn = {2229-9327},
  abstract = {The Coronavirus Disease (COVID-19) triggered substantial shifts in the education systems worldwide as teaching and learning have had to shift from face-to-face to an entirely virtual model due to the closure of educational institutes. The present paper is a descriptive-analytical investigation of the challenges of the current pandemic-imposed E-teaching of English for Specific Purposes (ESP) courses to female preparatory (PY) year students at King Khalid University (KKU). It identifies teachers' and students' responses about the ongoing issues with E-teaching of ESP with to put practical solutions to them. The study is conducted at The University Center for Girls' Studies- Al-Samir Campus-Abha during the academic year 2020-2021. Twenty English Language instructors at the English Language Center (ELC) and eighty students of the preparatory year at the College of Medicine enrolled in Intensive English Course (Njl-019) participated in the study. It adopts mixed qualitative methodology with the teachers' semi-structured interview and students' questionnaire as tools to collect data, and descriptive analysis as a method to interpret data. The study finds out reciprocity of teachers' and students' responses in pinpointing the factors posing serious challenges in teaching and learning ESP courses as majorly related to technology, pedagogy, and Assessment. Considering these challenges, the study puts forth practical suggestions to promote virtual teaching and learning of ESP courses. The suggested solutions are hoped to help providing successful standards for virtual ESP teaching and learning as per the constraints of quality modern education.},
  keywords = {Barriers,College Faculty,College Students,COVID-19,Educational Technology,Electronic Learning,English (Second Language),English for Special Purposes,Females,Foreign Countries,No DOI found,Online Courses,Pandemics,Saudi Arabia,School Closing,Second Language Instruction,Student Attitudes,Teacher Attitudes},
  file = {/Users/colin.madland/Zotero/storage/79WGKIV7/alviTechnologyPedagogyAssessment2021.pdf}
}

@article{alwardImpactfulLeadershipTraits2019,
  title = {Impactful {{Leadership Traits}} of {{Virtual Leaders}} in {{Higher Education}}},
  author = {Alward, Erin and Phelps, Yvonne},
  year = {2019},
  journal = {Online Learning},
  volume = {23},
  number = {3},
  pages = {72--93},
  issn = {ISSN-2472-5749},
  abstract = {Universities are increasingly leveraging virtual teams into their organizational structure and strategic framework for many functions including academic administration and faculty leadership. One benefit of a virtual workforce is the ability to hire the most qualified individuals regardless of where they are physically located. As the virtual workforce expands, leaders may intuitively rely on traditional face-to-face approaches and strategies for employee oversight and motivation. These techniques may be ineffective or challenging to use in the virtual environment necessitating new approaches. Leaders of virtual teams need to understand the intricacies associated with these groups and be cognizant of factors that assist in creating cohesiveness, trust, and communication amongst virtual teams. This qualitative phenomenological study explores leaders' perceptions surrounding competencies needed to effectively lead virtual teams in online education. A decisive sampling method was used to identify 10 experienced academic leaders who supervise virtual teams. As a result of the interviews, seven major themes emerged: (a) training and development; (b) trust; (c) emotional intelligence; (d) communication/team building/technology; (e) employee recognition and motivation; (f) leadership styles; and (g) virtual leadership competencies unique to higher education. Based on these themes and further evaluation, the need for specific soft skills and robust technology emerged. Specifically, organizational success partially hinges on comprehensive training for virtual leaders, the significance of trust, emotional intelligence, and effective, respectful communication.},
  langid = {english},
  keywords = {Administrator Attitudes,College Faculty,Computer Mediated Communication,Emotional Intelligence,Employee Attitudes,Job Performance,Leadership Effectiveness,Leadership Qualities,Leadership Training,No DOI found,Private Colleges,Recognition (Achievement),Supervisors,Teamwork,Trust (Psychology),Work Environment}
}

@article{alyahyanPredictingAcademicSuccess2020,
  title = {Predicting Academic Success in Higher Education: Literature Review and Best Practices},
  author = {Alyahyan, Eyman and D{\"u}{\c s}teg{\"o}r, Dilek},
  year = {2020},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {17},
  number = {1},
  pages = {1--21},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-020-0177-7},
  abstract = {Student success plays a vital role in educational institutions, as it is often used as a metric for the institution's performance. Early detection of students at risk, along with preventive measures, can drastically improve their success. Lately, machine learning techniques have been extensively used for prediction purpose. While there is a plethora of success stories in the literature, these techniques are mainly accessible to ``computer science'', or more precisely, ``artificial intelligence'' literate educators. Indeed, the effective and efficient application of data mining methods entail many decisions, ranging from how to define student's success , through which student attributes to focus on , up to which machine learning method is more appropriate to the given problem . This study aims to provide a step-by-step set of guidelines for educators willing to apply data mining techniques to predict student success. For this, the literature has been reviewed, and the state-of-the-art has been compiled into a systematic process, where possible decisions and parameters are comprehensively covered and explained along with arguments. This study will provide to educators an easier access to data mining techniques, enabling all the potential of their application to the field of education.},
  keywords = {Academic achievement,Artificial intelligence,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Data mining,Decisions,Educational Technology,Guidelines,Higher Education,Humanities,Information Systems Applications (incl.Internet),Law,Literature reviews,Machine learning,Prediction,Predictions,Review,Review Article,State-of-the-art reviews,Statistics for Social Sciences,Student success,Success,Teachers},
  file = {/Users/colin.madland/Zotero/storage/4MM7DLY3/alyahyanPredictingAcademicSuccess2020.pdf}
}

@article{alzahraniEFLTeachersPerceptions2020,
  title = {{{EFL Teachers}}' {{Perceptions}} of the {{Effectiveness}} of {{Online Professional Development}} in {{Higher Education}} in {{Saudi Arabia}}},
  author = {Alzahrani, Fatimah Yousef and Althaqafi, Abeer Sultan},
  year = {2020},
  journal = {Higher Education Studies},
  volume = {10},
  number = {1},
  pages = {121--131},
  issn = {ISSN-1925-4741},
  doi = {10/gmbv2c},
  abstract = {This study aimed at examining EFL teachers' perceptions of the effectiveness of an OPD program provided by a Saudi University. The program lasted for almost one year, and consisted of different courses about teaching English language. An online questionnaire was sent to the teachers to examine their perceptions of the effectiveness of the program through examining teachers' perceptions of the significant features of the program, their learning in the program, and their use of the new knowledge and skills. Findings indicated limitations in teachers' positive perceptions of the features of the OPD courses, teachers' learning, and teachers' use of new skills and knowledge. Providers of OPD need to take into consideration teachers' needs and preferences, and the obstacles that might inhibit teachers' learning. Needs analysis might be helpful to discover their needs and preferences and solutions for the obstacles they face.},
  langid = {english},
  keywords = {Barriers,College Faculty,English (Second Language),Faculty Development,Foreign Countries,Language Teachers,Online Courses,Positive Attitudes,Preferences,Program Effectiveness,Second Language Instruction,Second Language Learning,Teacher Attitudes}
}

@incollection{amanteEAssessmentPortugueseHigher2019,
  title = {E-{{Assessment}} in {{Portuguese Higher Education}}: {{Framework}} and {{Perceptions}} of {{Teachers}} and {{Students}}.},
  shorttitle = {E-{{Assessment}} in {{Portuguese Higher Education}}},
  booktitle = {Handbook of Research on E-Assessment in Higher Education},
  author = {Amante, L{\'u}cia and Oliveira, Isolina Rosa and Gomes, Maria Jo{\~a}o},
  year = {2019},
  pages = {312--333},
  publisher = {IGI Global},
  file = {/Users/colin.madland/Zotero/storage/2DNDNLAI/amanteEAssessmentPortugueseHigher2019.pdf;/Users/colin.madland/Zotero/storage/PVMIMRE8/212288.html}
}

@article{amashaCombiningOnlineLearning2018,
  title = {Combining {{Online Learning}} \& {{Assessment}} in Synchronization Form},
  author = {Amasha, {\relax MA} and Abougalala, {\relax RA} and Reeves, {\relax AJ} and Alkhalaf, S},
  year = {2018},
  journal = {Education and Information Technologies},
  volume = {23},
  number = {6},
  pages = {2517--2529},
  issn = {1360-2357},
  doi = {10.1007/s10639-018-9728-0},
  abstract = {The main purpose of this study is to investigate the effects of integration of online learning and assessment in synchronization form (OLASF) on students' learning performance. The study seeks to evaluate how the synchronization content with immediate assessment can affect the knowledge performance of the students. An experimental design with digital formative assessment tools was used to fulfill the research purpose. Participants were 64 undergraduate students enrolled in is introduction to computer and programming (CSC 101) at Qassim University. The students from level five were divided into two-treatment groups: online learning \& assessment instruction in Synchronization form using Nearpod, and PowerPoint instruction with traditional form. The experiment was completed within 6 weeks. Formative assessment test was used to access students learning performance after class. Descriptive statistics and a t-test were used to analyze the data. Our findings revealed that the use of OLASF was an intrinsic motivation and could be a promising way of enhancing students' learning performance.},
  langid = {english},
  keywords = {ACHIEVEMENT,ACQUISITION,Assessment,CHAPTER QUIZZES,E-content,E-learning,EDUCATION,FORMATIVE ASSESSMENT,Learning performance,MODEL,MOTIVATION,Online learning,PERFORMANCE,Synchronization}
}

@book{ambroseHowLearningWorks2010,
  title = {How Learning Works: Seven Research-Based Principles for Smart Teaching},
  shorttitle = {How Learning Works},
  editor = {Ambrose, Susan A.},
  year = {2010},
  series = {The {{Jossey-Bass}} Higher and Adult Education Series},
  edition = {1st ed},
  publisher = {Jossey-Bass},
  address = {San Francisco, CA},
  isbn = {978-0-470-48410-4},
  lccn = {LB1025.3 .H68 2010},
  keywords = {Case studies,Educational innovations,Effective teaching,Learning Psychology of,School improvement programs},
  annotation = {OCLC: ocn468969206}
}

@article{aminTechnologyenabledAssessmentHealth2011,
  title = {Technology-Enabled Assessment of Health Professions Education: {{Consensus}} Statement and Recommendations from the {{Ottawa}} 2010 Conference},
  shorttitle = {Technology-Enabled Assessment of Health Professions Education},
  author = {Amin, Zubair and Boulet, John R. and Cook, David A. and Ellaway, Rachel and Fahal, Ahmad and Kneebone, Roger and Maley, Moira and Ostergaard, Doris and Ponnamperuma, Gominda and Wearn, Andy and Ziv, Amitai},
  year = {2011},
  month = may,
  journal = {Medical Teacher},
  volume = {33},
  number = {5},
  pages = {364--369},
  issn = {0142-159X, 1466-187X},
  doi = {10.3109/0142159X.2011.565832},
  urldate = {2023-04-19},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/E4X92QTR/aminTechnologyenabledAssessmentHealth2011.pdf}
}

@book{amrane-cooperOnlineDistanceEducation2023,
  title = {Online and {{Distance Education}} for a {{Connected World}}},
  editor = {{Amrane-Cooper}, Linda and Baume, David and Brown, Stephen and Hatzipanagos, Stylianos and Powell, Philip and Sherman, Sarah and Tait, Alan},
  year = {2023},
  month = mar,
  publisher = {UCL Press},
  doi = {10.14324/111.9781800084797},
  urldate = {2023-03-30},
  isbn = {978-1-80008-479-7},
  file = {/Users/colin.madland/Zotero/storage/FQWD9EAB/amrane-cooperOnlineDistanceEducation2023.pdf}
}

@article{amriSelfEfficacySaudiEnglish2021,
  title = {Self-{{Efficacy}} of {{Saudi English Majors}} after the {{Emergent Transition}} to {{Online Learning}} and {{Online Assessment}} during the {{COVID-19 Pandemic}}},
  author = {Amri, Zeineb and Alasmari, Nasser},
  year = {2021},
  journal = {International Journal of Higher Education},
  volume = {10},
  number = {3},
  pages = {127--137},
  issn = {ISSN-1927-6044},
  doi = {10/gmbvzg},
  abstract = {This research explores the sense of self-efficacy among Saudi English majors at Jeddah University during the COVID-19 pandemic, which forced all schools in Saudi Arabia to suspend face-to-face learning and, instead, use the online Blackboard platform. The study's objectives are to determine Blackboard's effect on Saudi learners' self-efficacy beliefs, identify factors influencing these beliefs in the online context, and determine the relationship between self-efficacy beliefs and academic performance. Phone interviews, an online questionnaire, and online performance tests served as data collection instruments. The results indicate that urgent Blackboard use negatively affected the subjects' self-efficacy beliefs, and there is a positive, significant relationship between academic performance and perceived self-efficacy. Among other factors, familiarity with Blackboard, technical competence, and a readiness to embrace technology strongly influenced the students' self-efficacy beliefs. This paper also presents implications and pedagogical recommendations drawn from the results.},
  langid = {english},
  keywords = {Academic Achievement,College Students,Computer Assisted Testing,Correlation,COVID-19,English (Second Language),Foreign Countries,Integrated Learning Systems,Majors (Students),Online Courses,Pandemics,Readiness,School Closing,Second Language Instruction,Self Efficacy,Technological Literacy}
}

@article{amriSelfEfficacySaudiEnglish2021a,
  title = {Self-{{Efficacy}} of {{Saudi English Majors}} after the {{Emergent Transition}} to {{Online Learning}} and {{Online Assessment}} during the {{COVID-19 Pandemic}}},
  author = {Amri, Zeineb and Alasmari, Nasser},
  year = {2021},
  month = jan,
  journal = {International Journal of Higher Education},
  volume = {10},
  number = {3},
  pages = {127--137},
  publisher = {International Journal of Higher Education},
  issn = {1927-6044},
  doi = {10.5430/ijhe.v10n3p127},
  abstract = {This research explores the sense of self-efficacy among Saudi English majors at Jeddah University during the COVID-19 pandemic, which forced all schools in Saudi Arabia to suspend face-to-face learning and, instead, use the online Blackboard platform. The study's objectives are to determine Blackboard's effect on Saudi learners' self-efficacy beliefs, identify factors influencing these beliefs in the online context, and determine the relationship between self-efficacy beliefs and academic performance. Phone interviews, an online questionnaire, and online performance tests served as data collection instruments. The results indicate that urgent Blackboard use negatively affected the subjects' self-efficacy beliefs, and there is a positive, significant relationship between academic performance and perceived self-efficacy. Among other factors, familiarity with Blackboard, technical competence, and a readiness to embrace technology strongly influenced the students' self-efficacy beliefs. This paper also presents implications and pedagogical recommendations drawn from the results.},
  keywords = {Academic Achievement,College Students,Computer Assisted Testing,Correlation,COVID-19,English (Second Language),Foreign Countries,Integrated Learning Systems,Majors (Students),Online Courses,Pandemics,Readiness,Saudi Arabia,School Closing,Second Language Instruction,Self Efficacy,Technological Literacy},
  file = {/Users/colin.madland/Zotero/storage/GCMCLH2F/amriSelfEfficacySaudiEnglish2021a.pdf}
}

@article{AnadoluUniversitesiEgitim2017,
  title = {Anadolu {{{\"U}niversitesi E{\u g}itim Fak{\"u}ltesi}} Dergisi.},
  year = {2017},
  journal = {Anadolu {\"U}niversitesi E{\u g}itim Fak{\"u}ltesi dergisi.},
  publisher = {Anadolu {\"U}niversitesi E{\u g}itim Fak{\"u}ltesi},
  address = {Eskisehir, Turkey},
  issn = {2602-2249},
  keywords = {Education -- Study and teaching,Periodicals,Teachers -- Training of}
}

@article{andersonAssessingTeachingPresence2001,
  title = {Assessing Teaching Presence in a Computer Conferencing Context},
  shorttitle = {Assessing Teaching Presence in a Computer Conferencing Context},
  author = {Anderson, Terry and Rourke, Liam and Garrison, D. Randy and Archer, Walter},
  year = {2001},
  journal = {Journal of the Asynchronous Learning Network},
  volume = {5},
  pages = {1--17},
  abstract = {This paper presents a tool developed for the purpose of assessing teaching presence in online courses that make use of computer conferencing, and preliminary results from the use of this tool. The method of analysis is based on Garrison, Anderson, and Archer's [1] model of critical thinking and practical inquiry in a computer conferencing context. The concept of teaching presence is constitutively defined as having three categories -- design and organization, facilitating discourse, and direct instruction. Indicators that we search for in the computer conference transcripts identify each category. Pilot testing of the instrument reveals interesting differences in the extent and type of teaching presence found in different graduate level online courses.},
  keywords = {CMC,Education,formal,formal education,instruction,Teaching},
  annotation = {2}
}

@article{andersonCriticalThinkingDistance1995,
  title = {Critical Thinking in Distance Education: {{Developing}} Critical Communities in an Audio Teleconference Context},
  shorttitle = {Critical Thinking in Distance Education: {{Developing}} Critical Communities in an Audio Teleconference Context},
  author = {Anderson, Terry D. and Garrison, D. R.},
  year = {1995},
  journal = {Higher Education},
  volume = {29},
  eprint = {3447843},
  eprinttype = {jstor},
  pages = {183--199},
  issn = {00181560},
  abstract = {Distance education has long been associated with independent study and delivery of prepackaged learning materials. These characteristics effectively deny distance education students the opportunity to participate in communities of inquiry and, perhaps, opportunities to develop their critical thinking skills. This paper reviews the theoretical impact of socially situated learning, critical thinking and their implications for distance education. It then presents the results from a study of learners' perceptions while enrolled in two different models of audio teleconferenced delivered, university courses. The study reports quantitative results from a mail survey of these students and the qualitative results from interviews and classroom observations. The impact of the instructional design used by the delivering institution resulted in two distinct models of audio teleconference delivery with significant qualitative and quantitative differences in student perception. The paper concludes that learning communities, which support the development of critical thinking skills, can be created at a distance and that they provide a mechanism for improving the quality of higher level distance education.},
  annotation = {2}
}

@inproceedings{andersonEmpoweringProfessionalOpenness2009,
  title = {Empowering {{Professional Openness}} through {{Groups}}, {{Networks}} and {{Collectives}}},
  shorttitle = {Empowering {{Professional Openness}} through {{Groups}}, {{Networks}} and {{Collectives}}},
  booktitle = {World {{Conference}} on {{E-Learning}} in {{Corporate}}, {{Government}}, {{Healthcare}}, and {{Higher Education}} 2009},
  author = {Anderson, Terry},
  year = {2009},
  publisher = {AACE},
  abstract = {In this session Terry overviews the affordances associated with the web and especially web 2.0 tools. By looking at the applications of groups, networks and collectives, he shows how we are provided with the capacity to expand and improve our professional and scholarly activities. he also notes the emergence of 'Openness" as a practice and ethic for more engaging and profitable professional activity.}
}

@article{andersonGettingMixRight2003,
  title = {Getting the Mix Right Again: {{An}} Updated and Theoretical Rationale for Interaction},
  shorttitle = {Getting the {{Mix Right Again}}: {{An Updated}} and {{Theoretical Rationale}} for {{Interaction}}},
  author = {Anderson, Terry},
  year = {2003},
  journal = {International Review of Research in Open and Distance Learning},
  volume = {4},
  number = {2},
  pages = {1--14},
  doi = {10.19173/irrodl.v4i2.149},
  abstract = {No topic raises more contentious debate among educators than the role of interaction as a crucial component of the education process. This debate is fueled by surface problems of definition and vested interests of professional educators, but is more deeply marked by epistemological assumptions relative to the role of humans and human interaction in education and learning. The seminal article by Daniel and Marquis (1979) challenged distance educators to get the mixture right between independent study and interactive learning strategies and activities. They quite rightly pointed out that these two primary forms of education have differing economic, pedagogical, and social characteristics, and that we are unlikely to find a {\quotesinglbase}{\"A}{\'u}perfect{\quotesinglbase}{\"A}{\`u} mix that meets all learner and institutional needs across all curricula and content. Nonetheless, hard decisions have to be made. Even more than in 1979, the development of newer, cost effective technologies and the nearly ubiquitous (in developed countries) Net-based telecommunications system is transforming, at least, the cost and access implications of getting the mix right. Further, developments in social cognitive based learning theories are providing increased evidence of the importance of collaborative activity as a component of all forms of education {\quotesinglbase}{\"A}{\`i} including those delivered at a distance. Finally, the context in which distance education is developed and delivered is changing in response to the capacity of the semantic Web (Berners-Lee, 1999) to support interaction, not only amongst humans, but also between and among autonomous agents and human beings. Thus, the landscape and challenges of {\quotesinglbase}{\"A}{\'u}getting the mix right{\quotesinglbase}{\"A}{\`u} have not lessened in the past 25 years, and, in fact, have become even more complicated. This paper attempts to provide a theoretical rationale and guide for instructional designers and teachers interested in developing distance education systems that are both effective and efficient in meeting diverse student learning needs.},
  file = {/Users/colin.madland/Zotero/storage/ML3UDXAD/andersonGettingMixRight2003.pdf}
}

@incollection{andersonIndependentLearningAutonomy2012,
  title = {Independent {{Learning}}: {{Autonomy}}, {{Control}}, and {{Meta-Cognition}}},
  booktitle = {Handbook of {{Distance Education}}},
  author = {Anderson, William},
  editor = {Moore, Michael Grahame},
  year = {2012},
  publisher = {Taylor \& Francis Group},
  address = {London, UNITED KINGDOM},
  isbn = {978-1-136-63557-1},
  keywords = {Distance education -- Handbooks,etc.,manuals},
  file = {/Users/colin.madland/Zotero/storage/GID5F8AZ/Anderson - 2012 - Independent Learning Autonomy, Control, and Meta-.pdf}
}

@incollection{andersonLearningNetworkedWorld1998,
  title = {Learning in a Networked World: {{New}} Roles and Responsibilities},
  booktitle = {Distance Learners in Higher Education: {{Institutional}} Responses for Quality Outcomes},
  author = {Anderson, Terry and Garrison, D. R.},
  editor = {Gibson, Chere},
  year = {1998},
  pages = {97--112},
  publisher = {Atwood},
  address = {Madison, WI}
}

@incollection{andersonModesInteractionDistance2003,
  title = {Modes of Interaction in Distance Education: {{Recent}} Developments and Research Questions},
  booktitle = {Handbook of Distance Education},
  author = {Anderson, Terry},
  editor = {Moore, Michael G. and Anderson, William G.},
  year = {2003},
  publisher = {L. Erlbaum Associates},
  address = {Mahwah, NJ},
  keywords = {Distance,Education,LEARNING,Online}
}

@book{andersonOnlineDistanceEducation2014,
  title = {Online Distance Education: Towards a Research Agenda},
  author = {Anderson, Olaf Zawacki-Richter {and} Terry and {eds}},
  year = {2014},
  month = oct,
  publisher = {Athabasca University Press},
  address = {Canada},
  isbn = {978-1-927356-62-3}
}

@book{andersonTeachingCrowdsLearning2014,
  title = {Teaching {{Crowds}}: {{Learning}} and {{Social Media}}},
  shorttitle = {Teaching {{Crowds}}},
  author = {Anderson, Terry and Dron, Jon},
  year = {2014},
  month = sep,
  publisher = {Athabasca University Press},
  doi = {10.15215/aupress/9781927356807.01},
  urldate = {2022-11-27},
  isbn = {978-1-927356-81-4},
  file = {/Users/colin.madland/Zotero/storage/MN9W9232/andersonTeachingCrowdsLearning2014.pdf}
}

@incollection{andersonTeachingOnlineLearning2008,
  title = {Teaching in an {{Online Learning Context}}},
  shorttitle = {Teaching in an {{Online Learning Context}}},
  booktitle = {The {{Theory}} and {{Practice}} of {{Online Learning}}},
  author = {Anderson, Terry},
  editor = {Anderson, Terry},
  year = {2008},
  edition = {2nd},
  pages = {343--365},
  publisher = {AU Press},
  address = {Athabasca},
  isbn = {978-1-897425-08-4}
}

@incollection{andersonTheoryOnlineLearning2004,
  title = {Toward a {{Theory}} of {{Online Learning}}},
  shorttitle = {Toward a {{Theory}} of {{Online Learning}}},
  booktitle = {Theory and {{Practice}} of {{Online Learning}}},
  author = {Anderson, Terry},
  editor = {Anderson, Terry and Elloumi, Fathi},
  year = {2004},
  publisher = {Athabasca University},
  address = {Athabasca}
}

@incollection{andersonTheoryOnlineLearning2008,
  title = {Towards a {{Theory}} of {{Online Learning}}},
  shorttitle = {Towards a {{Theory}} of {{Online Learning}}},
  booktitle = {The {{Theory}} and {{Practice}} of {{Online Learning}}},
  author = {Anderson, Terry},
  editor = {Anderson, Terry},
  year = {2008},
  edition = {2nd},
  pages = {45--74},
  publisher = {Athabasca University},
  address = {Athabasca}
}

@book{andersonTheoryPracticeOnline2008,
  title = {The {{Theory}} and {{Practice}} of {{Online Learning}}},
  shorttitle = {The {{Theory}} and {{Practice}} of {{Online Learning}}},
  author = {Anderson, Terry},
  year = {2008},
  edition = {2nd},
  publisher = {Athabasca University},
  address = {Athabasca},
  isbn = {978-1-897425-08-4},
  file = {/Users/colin.madland/Zotero/storage/RTMC9G2T/EndNote APA 6th Installation Instructions.pdf}
}

@inproceedings{andersonUpdatedTheoreticalRationale2002,
  title = {An Updated and Theoretical Rationale for Interaction},
  booktitle = {Instructional {{Technology Forum}}, {{Paper}} \#63},
  author = {Anderson, Terry},
  year = {2002},
  pages = {11}
}

@article{Andrade_2010,
  title = {Handbook of Formative Assessment},
  author = {Andrade, Heidi and Cizek, Gregory J.},
  year = {2010},
  journal = {null},
  doi = {10/ghhtsm},
  abstract = {Preface Section I. Foundations of Formative Assessment 1. An Introduction to Formative Assessment: History, Characteristics, and Challenges, Gregory J. Cizek 2. An Integrative Summary of the Research Literature and Implications for a New Theory of Formative Assessment, Dylan Wiliam 3. The Practical Implications of Educational Aims and Contexts for Formative Assessment, James McMillan Section II. Formative Assessment Methods and Practice 4. Peers as a Source of Formative Assessment, Keith J. Topping 5. Formative Assessment Applications of Culminating Demonstrations of Mastery, Jill Davidson and Jay Feldman 6. Students as the Definitive Source of Formative Assessment: Academic Self-Assessment and the Self-Regulation of Learning, Heidi L. Andrade 7. Formative Assessment: The Contribution of Benjamin S. Bloom, Thomas R. Guskey 8. Technology-Aided Formative Assessment of Learning: New Developments and Applications, Michael K. Russell 9. Formative Assessment, Motivation, and Science Learning, Maria Araceli Ruiz-Primo, Erin Marie Furtak, Carlos Ayala, Yue Yin, and Richard J. Shavelson 10. Research and Strategies for Adapting Formative Assessment for Students with Special Needs, Stephen N. Elliott, Ryan J. Kettler, Peter A. Beddow, and Alexander Kurz 11. Research and Recommendations for Formative Assessment with English Language Learners, Jamal Abedi 12. Moment-by-moment Formative Assessment of Second Language Development: ESOL Professionals at Work, Carla Meskill 13. Formative Assessment Practices that Maximize Learning for Students At-Risk, Gerunda B. Hughes 14. Essential Formative Assessment Competencies for Teachers and School Leaders, Rick Stiggins 15. Research on Characteristics of Effective Professional Development Programs for Enhancing Educators' Skills in Formative Assessment, M. Christina Schneider and Bruce Randel Section III: Challenges and Future Directions for Formative Assessment 16. Mixing It Up: Combining Sources of Classroom Achievement Information for Formative and Summative Purposes, Susan M. Brookhart 17. Psychometric Challenges and Opportunities in Implementing Formative Assessment, Walter D. Way, Robert P. Dolan, and Paul Nichols 18. Strategies and Policies for Incorporating Formative Assessment into Comprehensive and Balanced State Assessment Systems, Doug A. Rindone and Duncan MacQuarrie 19. Keeping the Focus, Expanding the Vision, Maintaining the Balance: Preserving and Enhancing Formative Assessment in Nebraska, Chris W. Gallagher 20. Summing Up and Moving Forward: Key Challenges and Future Directions for Research and Development in Formative Assessment, Heidi L. Andrade About the Authors Author Index Subject Index},
  mag_id = {600941897},
  pmcid = {null},
  pmid = {null},
  keywords = {guskey},
  file = {/Users/colin.madland/Zotero/storage/C9YSR398/Andrade_2010.pdf}
}

@article{andradeClassroomAssessmentCoregulation2020,
  title = {Classroom Assessment as the Co-Regulation of Learning},
  author = {Andrade, Heidi L. and Brookhart, Susan M.},
  year = {2020},
  month = jul,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {27},
  number = {4},
  pages = {350--372},
  issn = {0969-594X, 1465-329X},
  doi = {10.1080/0969594X.2019.1571992},
  urldate = {2022-09-14},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/HH9DJINH/andradeClassroomAssessmentCoregulation2020.pdf}
}

@article{andrejevicFacialRecognitionTechnology2020,
  title = {Facial Recognition Technology in Schools: Critical Questions and Concerns},
  shorttitle = {Facial Recognition Technology in Schools},
  author = {Andrejevic, Mark and Selwyn, Neil},
  year = {2020},
  month = apr,
  journal = {Learning, Media and Technology},
  volume = {45},
  number = {2},
  pages = {115--128},
  issn = {1743-9884, 1743-9892},
  doi = {10.1080/17439884.2020.1686014},
  urldate = {2022-03-20},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/WFQVFR5X/andrejevicFacialRecognitionTechnology2020.pdf}
}

@book{angeloClassroomAssessmentTechniques1993,
  title = {Classroom Assessment Techniques: A Handbook for College Teachers},
  shorttitle = {Classroom Assessment Techniques},
  author = {Angelo, Thomas A. and Cross, K. Patricia},
  year = {1993},
  series = {The {{Jossey-Bass}} Higher and Adult Education Series},
  edition = {2nd ed},
  publisher = {Jossey-Bass Publishers},
  address = {San Francisco},
  isbn = {978-1-55542-500-5},
  lccn = {LB2822.75 .A54 1993},
  keywords = {College students,College teaching,Educational evaluation,Handbooks manuals etc,Rating of Case studies,United States}
}

@article{annandIncentivizingProductionUse2017,
  title = {Incentivizing the {{Production}} and {{Use}} of {{Open Educational Resources}} in {{Higher Education Institutions}}},
  author = {Annand, David and Jensen, Tilly},
  year = {2017},
  month = jun,
  journal = {The International Review of Research in Open and Distributed Learning},
  volume = {18},
  number = {4},
  issn = {1492-3831},
  urldate = {2018-07-07},
  copyright = {Copyright (c) 2017 David Annand, Tilly Jensen},
  langid = {english},
  keywords = {behavioural economics,higher education,open education resources,post-secondary education},
  file = {/Users/colin.madland/Zotero/storage/VQ6Y7V32/annandIncentivizingProductionUse2017.pdf;/Users/colin.madland/Zotero/storage/UTRF2I4J/4226.html}
}

@article{annandSocialPresenceCommunity2011,
  title = {Social {{Presence}} within the {{Community}} of {{Inquiry Framework}}},
  shorttitle = {Social {{Presence}} within the {{Community}} of {{Inquiry Framework}}},
  author = {Annand, David},
  year = {2011},
  journal = {International Review of Research in Open and Distance Learning},
  volume = {12},
  pages = {40--56},
  abstract = {The role of social presence as defined by the community of inquiry (CoI) framework is critiqued through a review of recent literature. Evidence is presented that questions the actual extent of knowledge co-construction that occurs in most higher education settings and therefore challenges the framework's underlying assumption of the need for sustained, contiguous, two-way communication in higher-level online learning environments. The CoI framework has evolved from the description of a learning process within a social constructivist paradigm to an empirically testable construct in an objectivist paradigm. Related research results indicate that social presence does not impact cognitive presence in a meaningful way and that best teaching practices suggested by CoI-based studies are informed by objectivist, cognitively oriented learning theories. These suggest that higher-order cognition may be achieved through wide and varied combinations of learner--teacher, learner--content, and learner--learner interaction. Controlled studies can and should be undertaken to compare learning outcomes using sustained, contiguous, two-way communication to other learning models. To facilitate this, subcategories of social and teaching presences need to be revamped and analysis adjusted to separate processes that support explicitly group-based learning activities from those used by individual students.},
  keywords = {cohort-based,cohort-based learning,communities,communities of inquiry,constructivism,Distance,distance education,Education,individualized,individualized learning,inquiry,LEARNING,of,Online,Online learning,online pedagogy,Pedagogy},
  annotation = {5}
}

@article{AnnualReviewAnthropology2003,
  title = {Annual Review of Anthropology.},
  year = {2003},
  journal = {Annual review of anthropology.},
  issn = {0084-6570},
  langid = {english}
}

@misc{AnotherTerribleIdea,
  title = {Another {{Terrible Idea}} from {{Turnitin}} {\textbar} {{Inside Higher Ed}}},
  urldate = {2020-01-18},
  abstract = {A new way to surveil students. Yay!},
  howpublished = {https://www.insidehighered.com/blogs/just-visiting/another-terrible-idea-turnitin},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/J55LJSYG/AnotherTerribleIdea.pdf;/Users/colin.madland/Zotero/storage/X5Z3STF6/another-terrible-idea-turnitin.html}
}

@book{antoinePullingTogetherGuide2018,
  title = {Pulling {{Together}}: {{A Guide}} for {{Curriculum Developers}}},
  author = {Antoine, Asma-na-hi and Mason, Rachel and Mason, Roberta and Palahicky, Sophia and {Rodriguez de France}, Carmen},
  year = {2018},
  series = {Pulling {{Together}}: {{A}} Guide for {{Indigenization}} of Post-Secondary Institutions. {{A}} Professional Learning Series.},
  publisher = {BCcampus}
}

@article{anton-sanchoSelfAssessmentSoftSkills2021,
  title = {Self-{{Assessment}} of {{Soft Skills}} of {{University Teachers}} from {{Countries}} with a {{Low Level}} of {{Digital Competence}}},
  author = {{Anton-Sancho}, Alvaro and Vergara, Diego and {Fernandez-Arias}, Pablo},
  year = {2021},
  journal = {Electronics (Basel)},
  volume = {10},
  number = {20},
  pages = {2532},
  publisher = {Mdpi},
  address = {BASEL},
  issn = {2079-9292},
  doi = {10.3390/electronics10202532},
  abstract = {The lockdown of March and April 2020 as a consequence of the COVID-19 pandemic has forced relevant changes in the educational environment in a very short period of time, making it necessary to suspend in-person instruction and generating the need to implement virtual learning mechanisms. In a future post-COVID-19 hybrid educational model, it will be necessary for university teachers to acquire an optimal degree of digital competence, as a combination of different competencies, namely, (i) technical, (ii) digital, and (iii) soft. Soft skills have been shown to have a decisive influence on the development of digital competence. The aim of this study was to analyze the degree of acquisition of soft skills in Latin American university teachers whose countries are less digitally developed. For this purpose, the countries with the lowest Global Innovation Index (GII) were selected: (i) Panama; (ii) Peru; (iii) Argentina; (iv) El Salvador; (v) Ecuador; (vi) Paraguay; (vii) Honduras; and (viii) Bolivia. To achieve this objective, it was necessary to develop a questionnaire on the self-concept of soft skills, based on the soft skills included in the Bochum Inventory of Personality and Competences (BIP). Results obtained from statistical analysis of the data collected from a sample of 219 participants show that university teachers are sufficiently prepared, in terms of their soft skills, for the increase in digital competence required as a result of the COVID-19 crisis, despite the low level of digital development in their respective countries.},
  keywords = {21st century,Colleges & universities,Computer Science,Computer Science Information Systems,Coronaviruses,COVID-19,Critical thinking,digital competence,Education,Employers,Engineering,Engineering Electrical & Electronic,Higher education,Inequality,Low level,Personality,Physical Sciences,Physics,Physics Applied,Professionals,Questionnaires,Science & Technology,Self esteem,Self evaluation,Skills,Soft skills,Statistical analysis,Teachers,Teaching,Technology,University graduates,university teachers},
  file = {/Users/colin.madland/Zotero/storage/QLPVMW87/anton-sanchoSelfAssessmentSoftSkills2021.pdf}
}

@misc{AoIR2019Keynote,
  title = {{{AoIR}} 2019 {{Keynote}} -- {{AoIR}}},
  urldate = {2019-08-07},
  howpublished = {https://aoir.org/aoir2019/aoir2019program/},
  keywords = {indigenous,social},
  file = {/Users/colin.madland/Zotero/storage/P4W8JF5Y/aoir2019program.html}
}

@article{aparicioCulturalImpactsElearning2016,
  title = {Cultural Impacts on E-Learning Systems' Success},
  author = {Aparicio, Manuela and Bacao, Fernando and Oliveira, Tiago},
  year = {2016},
  month = oct,
  journal = {The Internet and Higher Education},
  volume = {31},
  pages = {58--70},
  issn = {10967516},
  doi = {10.1016/j.iheduc.2016.06.003},
  urldate = {2023-09-19},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/HFST4UHX/aparicioCulturalImpactsElearning2016.pdf}
}

@misc{ApparentRacialBias2020,
  title = {Apparent Racial Bias Found in {{Twitter}} Photo Algorithm},
  year = {2020},
  month = sep,
  journal = {VentureBeat},
  urldate = {2020-09-22},
  abstract = {Twitter's saliency detection algorithm appears to be prioritizing the faces of white people over Black people when displaying faces in people's timelines.},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/H8L97U92/apparent-racial-bias-found-in-twitter-photo-algorithm.html}
}

@article{appiahEassessmentHigherEducation2018,
  title = {E-Assessment in Higher Education: {{A}} Review.},
  shorttitle = {E-Assessment in Higher Education},
  author = {Appiah, Martin and Van Tonder, Fanus},
  year = {2018},
  journal = {International Journal of Business Management \& Economic Research},
  volume = {9},
  number = {6},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/457LUUTT/appiahEassessmentHigherEducation2018.pdf}
}

@article{appiahEAssessmentHigherEducation2018a,
  title = {E-{{Assessment}} in {{Higher Education}}: {{A Review}}},
  author = {Appiah, Dr. Martin},
  year = {2018},
  month = jan,
  abstract = {The improvement of technology and e-learning systems, has resulted in a high demand for ways and means of assessing students in such a system. Assessment is indeed a critical part of the teaching and learning process in any higher education institution. The aim of this study is to provide a discussion on e-assessment which focuses on concepts such as definitions of e-assessment; e-assessment delivery platforms, tasks that can be accessed through e-assessment; benefits and challenges of e-assessment and principles of e-assessment. It is concluded that e-assessment can be effective if the assessment is credible and lecturers make a concerted effort to create assessment that is authentic, consistent, transparent and practicable. Higher-order assessment tasks can also be assessed through e-assessment.},
  keywords = {No DOI found}
}

@incollection{appsChallengesDesigningOnline2020,
  title = {Challenges with {{Designing Online Assessment}} to {{Support Student Task Understanding}}},
  booktitle = {Re-Imagining {{University Assessment}} in a {{Digital World}}},
  author = {Apps, Tiffani and Beckman, Karley and Bennett, Sue},
  editor = {Bearman, Margaret and Dawson, Phillip and Ajjawi, Rola and Tai, Joanna and Boud, David},
  year = {2020},
  volume = {7},
  pages = {247--262},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-41956-1_17},
  urldate = {2022-03-19},
  isbn = {978-3-030-41955-4 978-3-030-41956-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/2W5VCJ3J/Apps2020_Chapter_ChallengesWithDesigningOnlineA.pdf}
}

@article{aquashFirstNationsWays2013,
  title = {First {{Nations Ways}} of {{Knowing}}: {{The Circle}} of {{Knowledge}}},
  author = {Aquash, Mark},
  year = {2013},
  journal = {First Nations Perspectives},
  volume = {5},
  number = {1},
  pages = {25--36},
  abstract = {The Circle of Knowledge (T-C-K) is a unique research project focused on documenting successful and effective pedagogical strategies that addresses fluency in Anishinaabe language through community initiatives, activities and an immersion school. Group teaching and learning, specifically, the precursor to cooperative learning called social interdependence theory is the theoretical framework. Action research was selected as the methodology as it was considered to be the least intrusive and provides a process for continuous improvement of the program. The challenges and successes to addressing fluency in the Anishinaabe language is a unique portrayal of life in this First Nation community. Currently, the pedagogical strategies utilised have dramatically increased the level of fluency for this First Nation community. Documentation of these teaching strategies have proven useful for the Walpole Island First Nation and it is anticipated that many Indigenous communities around the world may benefit from adapting these strategies as appropriate for their circumstances.}
}

@article{arasaratnam-smithCommunityOnlineHigher2017,
  title = {Community in {{Online Higher Education}}: {{Challenges}} and {{Opportunities}}},
  author = {{Arasaratnam-Smith}, Lily A. and Northcote, Maria},
  year = {2017},
  journal = {Electronic Journal of e-Learning},
  volume = {15},
  number = {2},
  pages = {188--198},
  issn = {EISSN-1479-4403},
  abstract = {Exploring the challenges and opportunities associated with the concepts of community and communication in online higher education, this paper reconsiders the intention to replicate face-to-face learning and teaching strategies in online learning environments. Rather than beginning with the assumption that face-to-face education is the prototype for quality, the authors appraise the online learning environment as a unique medium which, by its nature, necessitates unique communication, community-building, teaching and learning strategies. This paper proposes an in-depth analysis of the potential unique affordances associated with online learning contexts as existing in their own right. The concepts of community and communication are explored in relation to online Communities of Practice (CoPs). The nature of face-to-face and online learning contexts are considered, especially in the light of the possibility of redefining "face-to-face" within the online realm, in addition to physical learning contexts. The paper identifies unique ways in which online communication (in the context of learning) is different from face-to-face communication, and consequently four ways in which this can be an advantage for students; namely, there is a measure of social egalitarianism, emphasis on verbal/written proficiency, time for reasoned response, and social agency. The paper provides grounding for further research into strategies that forge rich online learning experiences and suggests an empirical study as a next step.},
  langid = {english},
  keywords = {Affordances,Asynchronous Communication,Communities of Practice,Computer Mediated Communication,Electronic Learning,Higher Education,No DOI found,Nonverbal Communication,Synchronous Communication}
}

@article{arbaughDevelopingCommunityInquiry2008,
  title = {Developing a Community of Inquiry Instrument: {{Testing}} a Measure of the {{Community}} of {{Inquiry}} Framework Using a Multi-Institutional Sample},
  author = {Arbaugh, J.B. and {Cleveland-Innes}, Martha and Diaz, Sebastian R. and Garrison, D. Randy and Ice, Philip and Richardson, Jennifer C. and Swan, Karen P.},
  year = {2008},
  journal = {Special Section of the AERA Education and World Wide Web Special Interest Group (EdWeb/SIG)},
  volume = {11},
  number = {3--4},
  pages = {133--136},
  issn = {1096-7516},
  doi = {10.1016/j.iheduc.2008.06.003},
  abstract = {This article reports on the multi-institutional development and validation of an instrument that attempts to operationalize Garrison, Anderson and Archer's Community of Inquiry (CoI) framework (2000). The results of the study suggest that the instrument is a valid, reliable, and efficient measure of the dimensions of social presence and cognitive presence, thereby providing additional support for the validity of the CoI as a framework for constructing effective online learning environments. While factor analysis supported the idea of teaching presence as a construct, it also suggested that the construct consisted of two factors---one related to course design and organization and the other related to instructor behavior during the course. The article concludes with a discussion of potential implications of further refinement of the CoI measures for researchers, designers, administrators, and instructors.},
  keywords = {Cognitive Presence,community of inquiry,Social Presence,Teaching Presence}
}

@misc{archibaldACDEAccordIndigenous,
  title = {{{ACDE Accord}} on {{Indigenous Education}}},
  author = {Archibald, Jo-ann and Lundy, John and Reynolds, Cecilia and Williams, Lorna}
}

@inbook{archibaldHandbookArtsQualitative2019,
  title = {Handbook of the {{Arts}} in {{Qualitative Research}}: {{Perspectives}}, {{Methodologies}}, {{Examples}}, and {{Issues}}},
  author = {Archibald, Jo-ann},
  year = {2019},
  publisher = {SAGE Publications, Inc.},
  address = {Thousand Oaks, California},
  doi = {10.4135/9781452226545},
  collaborator = {{pages 371-385}}
}

@article{arditoGenerativeAIDetection2024,
  title = {Generative {{AI}} Detection in Higher Education Assessments},
  author = {Ardito, Cesare Giulio},
  year = {2024},
  month = sep,
  journal = {New Directions for Teaching and Learning},
  pages = {tl.20624},
  issn = {0271-0633, 1536-0768},
  doi = {10.1002/tl.20624},
  urldate = {2024-11-05},
  abstract = {Abstract             This chapter presents a critical analysis of generative AI (GenAI) detection tools in higher education assessments. The rapid advancement and widespread adoption of GenAI, particularly in education, necessitates a reevaluation of traditional academic integrity mechanisms. I explore the effectiveness, vulnerabilities, and ethical implications of AI detection tools in the context of preserving academic integrity. My analysis synthesizes insights from various case studies, newspaper articles, and student testimonies to scrutinize the practical and philosophical challenges associated with AI detection. I argue that reliance on detection mechanisms is misaligned with the educational landscape, where AI plays an increasing role. I advocate for a strategic shift toward robust assessment methods and educational policies that embrace GenAI usage while ensuring academic integrity and authenticity in assessments.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/arditoGenerativeAIDetection2024.pdf}
}

@article{arellanodouglasMovingCriticalAssessment2020,
  title = {Moving from {{Critical Assessment}} to {{Assessment}} as {{Care}}},
  author = {Arellano Douglas, Veronica},
  year = {2020},
  journal = {Communications in Information Literacy},
  volume = {14},
  number = {1},
  issn = {19335954},
  doi = {10.15760/comminfolit.2020.14.1.4},
  urldate = {2022-05-07},
  file = {/Users/colin.madland/Zotero/storage/33PDU7FV/arellanodouglasMovingCriticalAssessment2020.pdf}
}

@article{arendCourseAssessmentPractives2019,
  title = {Course Assessment Practives and Student Learning Strategies in Online Courses},
  author = {Arend, Bridget},
  year = {2019},
  journal = {Online Learning},
  volume = {11},
  number = {4},
  issn = {2472-5730},
  doi = {10/gk349x},
  abstract = {Perhaps the most promising and understudied aspect of online education is course assessment. Course assessment is important because it has a strong impact on learning and is an indicator of the quality of learning occurring in a class. In the online environment, methods of assessment can be very different. However, the online education literature is currently lacking empirical data about the general status of assessment practices or how those practices relate to student learning. This article lays the groundwork for future studies by providing a description of formative and summative assessment and learning strategies in 60 online courses and suggesting some ways that assessment practices lead to different types of learning. In this study, instructors appear to follow effective practice by using multiple and alternativeassessment methods, dispersing grades over time, and providing timely and frequent feedback to students. Students report focusing on relatively more complex learning strategies, such as elaboration and critical thinking over rehearsal. However, online instructors need to ensure that assessments are used strategically and that feedback is productive and able to be acted upon by students.},
  keywords = {Course Assessment,Critical Thinking,Formative Assessment,Learning Strategies,Summative Assessment},
  file = {/Users/colin.madland/Zotero/storage/E2WMJEAL/arendCourseAssessmentPractives2019.pdf}
}

@incollection{arintoOEROEPGlobal2017,
  title = {{{OER}} and {{OEP}} in the {{Global South}}: {{Implications}} and Recommendations for Social Inclusion},
  shorttitle = {{{OER}} and {{OEP}} in the {{Global South}}},
  booktitle = {Adoption and {{Impact}} of {{OER}} in the {{Global South}}},
  author = {Arinto, Patricia and {Hodgkinson-Williams}, Cheryl and Trotter, Henry},
  year = {2017},
  month = dec,
  publisher = {African Minds, International Development Research Centre \& Research on Open Educational Resources for Development project},
  address = {Cape Town \& Ottawa},
  doi = {10.5281/zenodo.1094869},
  urldate = {2018-11-05},
  abstract = {The Research on Open Educational Resources for Development (ROER4D) project was undertaken to provide a better understanding of the uptake of Open Educational Resources (OER) and their impact on education in the Global South. The 18 sub-projects that comprise the larger project investigated the extent of OER adoption by educators and students; the factors influencing OER adoption; and the impact of OER adoption on access to educational resources, the quality of teaching and learning, and some of the costs of education provision in 21 countries in South America, Sub-Saharan Africa, and South and Southeast Asia. The findings of each of the sub-projects are discussed in the various chapters comprising this volume, and a meta-synthesis of these findings is presented in Chapter 2. Using a social realist lens, the meta-synthesis provides a comparative analysis of OER use, adaptation and creation across the research sites, and identifies the structural, cultural and agential factors that enable and constrain these Open Educational Practices (OEP). It points out disjunctures in adoption processes in the countries and institutions studied, and draws insights regarding the extent to which OER adoption can expand access to educational materials, enhance the quality of educational resources and educators' pedagogical perspectives and practices, and improve the affordability and sustainability of education in the Global South. This concluding chapter explores the implications of the main research findings presented in the meta-synthesis for the attainment of social inclusion, which lies at the heart of the Open Education movement. The Paris OER Declaration of 2012 explicitly calls upon states to ``[p]romote and use OER to {\dots} contribut[e] to social inclusion, gender equity and special needs education [and i]mprove both cost-efficiency and quality of teaching and learning outcomes'' (emphasis added). The Ljubljana OER Action Plan of 2017 likewise recognises that, ``[t]oward the realization of inclusive Knowledge Societies ... [OER] support quality education that is equitable, inclusive, open and participatory''. Understanding how OER, OEP and Open Education more generally, can help to achieve social inclusion is particularly critical in the Global South where increased demand, lack of resources and high costs limit the capacity of education systems to provide accessible, relevant, highquality and affordable education. This chapter aims to contribute to this understanding the potential of OER and their accompanying OEP through a critical exploration of the ROER4D findings in terms of whether and how OER adoption promotes equitable access, participatory education and empowerment of teachers and students, and thus helps to achieve social inclusion. The chapter begins with a brief overview of the relationship between OER and social inclusion, details the implications of ROER4D's findings as they pertain to social inclusion, and concludes with recommendations for advocacy, policy, practice and further research in OER and OEP in the Global South.},
  isbn = {978-1-55250-599-1},
  langid = {english},
  keywords = {access,adoption,development,Global South,OEP,OER,Open Education,Open Educational Practices,Open Educational Resources,recommendations,ROER4D,social inclusion},
  file = {/Users/colin.madland/Zotero/storage/ED4IC9J8/arintoOEROEPGlobal2017.pdf}
}

@article{arkseyScopingStudiesMethodological2005,
  title = {Scoping Studies: Towards a Methodological Framework},
  shorttitle = {Scoping Studies},
  author = {Arksey, Hilary and O'Malley, Lisa},
  year = {2005},
  month = feb,
  journal = {International Journal of Social Research Methodology},
  volume = {8},
  number = {1},
  pages = {19--32},
  issn = {1364-5579, 1464-5300},
  doi = {10.1080/1364557032000119616},
  urldate = {2023-04-24},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/ZLQJRALR/arkseyScopingStudiesMethodological2005.pdf}
}

@article{arnoldDawnDusk5th2018,
  title = {Dawn or Dusk of the 5th Age of Research in Educational Technology? {{A}} Literature Review on (e-)Leadership for Technology-Enhanced Learning in Higher Education (2013-2017)},
  shorttitle = {Dawn or Dusk of the 5th Age of Research in Educational Technology?},
  author = {Arnold, Deborah and Sangr{\`a}, Albert},
  year = {2018},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {15},
  number = {1},
  pages = {24},
  issn = {2365-9440},
  doi = {10.1186/s41239-018-0104-3},
  urldate = {2022-10-27},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/UHYHD3SX/arnoldDawnDusk5th2018.pdf}
}

@article{arnoldDawnDusk5th2018a,
  title = {Dawn or Dusk of the 5th Age of Research in Educational Technology? {{A}} Literature Review on (e-)Leadership for Technology-Enhanced Learning in Higher Education (2013-2017)},
  author = {Arnold, Deborah and Sangr{\`a}, Albert},
  year = {2018},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {15},
  number = {1},
  pages = {1--29},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-018-0104-3},
  abstract = {The aim of this article is to establish the extent to which the concept of e-leadership has taken off as a lens through which to study leadership for technology-enhanced learning (TEL) in higher education. Building on a previous study conducted in 2013, this article thus covers an exploratory review of the literature for the period 2103-2017. It analyses 49 articles which explore both the specific concept of e-leadership as well as other work dealing more generally with leadership and organisational change for TEL in higher education. The findings show that while none of the empirical studies identified in the literature refer explicitly to e-leadership, there are a number of interesting insights to be found in the theoretical articles. The results also highlight the widely different interpretations and applications of the concept of e-leadership and the consequent need for the definition to be refined. The paper concludes with recommendations for further multidisciplinary research at the intersection of the fields of educational technology and educational management, focusing on values, strategy, organisation and leadership interactions at meso level, the economy and public policy at macro level, and teaching and learning at the micro level, as well as for research in Leadership Development for TEL.},
  keywords = {change management,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,distributed leadership,e-leadership,Education,Educational Technology,Empirical analysis,Ensenanza (Superior),Ensenyament universitari,Higher Education,Humanities,Information Systems Applications (incl.Internet),Law,Leadership,Learning,Literature reviews,Multidisciplinary research,Online instruction,online learning,Professional development,Public policy,Review Article,Statistics for Social Sciences,Study and teaching (Higher),Technology,technology-enhanced learning,The universities of the future: educational and organizational challenges},
  file = {/Users/colin.madland/Zotero/storage/5DJBTSP7/arnoldDawnDusk5th2018a.pdf}
}

@article{arnoldItTimeStop,
  title = {Is It Time to Stop Talking about Authentic Assessment?},
  author = {Arnold, Lydia and Croxford, James},
  journal = {Teaching in Higher Education},
  pages = {1--9},
  publisher = {Routledge},
  issn = {1356-2517},
  doi = {10.1080/13562517.2024.2369143},
  abstract = {Authentic assessment is a widely discussed concept in higher education, but it has a problem: the concept has become so all-encompassing that its meaning is now unclear. The notion has been expanded and diluted. For example, adding social justice to the definition or positioning exams as authentic, adds to the contradictions inherent within in the term. We argue for a more critical stance regarding the existing claims related authentic assessment to ensure that the field remains evidence informed. From a position where we wholeheartedly believe in the aims and approaches of the authentic assessment movement, we conclude that for the sake of coherence and clarity, we should stop using the term ?authentic assessment? and instead turn our attention to focus on the component characteristics.}
}

@book{aromatarisJBIManualEvidence2020,
  title = {{{JBI Manual}} for {{Evidence Synthesis}}},
  editor = {Aromataris, Edoardo and Munn, Zachary},
  year = {2020},
  publisher = {JBI},
  doi = {10.46658/JBIMES-20-01},
  urldate = {2022-10-22},
  isbn = {978-0-6488488-0-6},
  file = {/Users/colin.madland/Zotero/storage/QATLK8CD/aromatarisJBIManualEvidence2020.pdf}
}

@article{arsenisEnhancingGraduateEmployability2022,
  title = {Enhancing Graduate Employability Skills and Student Engagement through Group Video Assessment},
  author = {Arsenis, P and Flores, M and Petropoulou, D},
  year = {2022},
  month = feb,
  journal = {Assessment \& Evaluation In Higher Education},
  volume = {47},
  number = {2},
  pages = {245--258},
  issn = {0260-2938},
  doi = {10.1080/02602938.2021.1897086},
  abstract = {Universities are under increasing pressure to equip graduates with a broader set of competencies, such as communication, teamwork and leadership skills, that go beyond subject-specific knowledge. This, alongside growing student numbers in higher education, creates pedagogic challenges, especially with regards to assessment design. Conventional assessment modalities, such as individual essay writing, are costly to scale up and poorly suited for the development of further desired competencies. To address these challenges in the context of a first-year economics module, we replaced a 1,000-word individual written assignment with a group video assignment, where students were required to work in small teams to create a three-minute video on a contemporary economic issue. Focus groups and module evaluation questionnaires were used to elicit students' perceptions of how the group video assessment contributed to their learning experience and skill development, how it compares with other modes of assessment, as well as suggestions for improved implementation. Our analysis generates insights on all these aspects. Students reported a preference for diversity in assessment methods, and found the video assignment to be a positive, engaging but also challenging experience, which provided the opportunity for collaboration and development of diverse skills.},
  langid = {english},
  keywords = {Assessment,employability skills,higher education,technology},
  file = {/Users/colin.madland/Zotero/storage/5YDKIF6Z/arsenisEnhancingGraduateEmployability2022.pdf}
}

@article{ashenafiPeerAssessmentHigherEducation2017,
  ids = {ashenafiPeerassessmentHigherEducation2017},
  title = {Peer-{{Assessment}} in {{Higher Education--Twenty-First Century Practices}}, {{Challenges}} and the {{Way Forward}}},
  author = {Ashenafi, Michael Mogessie},
  year = {2017},
  month = jan,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {42},
  number = {2},
  pages = {226--251},
  publisher = {Assessment \& Evaluation in Higher Education},
  address = {ABINGDON},
  issn = {0260-2938},
  doi = {10.1080/02602938.2015.1100711},
  abstract = {Peer assessment in higher education has been studied for decades. Despite the substantial amount of research carried out, peer assessment has yet to make significant advances. This review identifies themes of recent research and highlights the challenges that have hampered its advance. Most of these challenges arise from the manual nature of peer assessment practices, which prove intractable as the number of students involved increases. Practitioners of the discipline are urged to forge affiliations with closely related fields and other disciplines, such as computer science, in order to overcome these challenges.},
  keywords = {Action Research,Case Studies,College Faculty,College Students,Education & Educational Research,Educational Research,Evaluation Methods,Feedback (Response),formative assessment,Higher Education,Literature Reviews,Peer Evaluation,peer-assessment,Reliability,Search Strategies,Social Influences,Social Sciences,Student Attitudes,summative assessment,Teacher Attitudes,Teacher evaluations,Validity}
}

@article{ashmanEngagingFirstYear2022,
  title = {Engaging First Year Students in Assessment Rubrics: {{Three}} Personal Experiences},
  author = {Ashman, Katherine and Turner, Kristina and Martin, Dona},
  year = {2022},
  journal = {The Australian journal of teacher education},
  volume = {47},
  number = {2},
  pages = {14--28},
  publisher = {Edith Cowan University, School of Education},
  address = {Perth},
  issn = {1835-517X},
  doi = {10.14221/ajte.2022v47n2.2},
  abstract = {In a direct effort to build a greater understanding of higher education teaching and learning opportunities, this study shares the journey of three university lecturers working to ensure best practice outcomes from criterion-referenced assessment [CRA]. The work was built on a belief that our respective higher education undergraduate students did not fully value the design structure or feedback outcomes inherent in CRA. Using a collaborative autoethnographic lens we pooled experiences, outcomes, challenges, assumptions, and accounts of unconscious biases from across our different tertiary education schools and subjects. Our examination enriched our understanding, our teaching, and our student outcomes. In sharing our journey we offer three unique, yet jointly considered perspectives on using CRA to extend and enhance learning.},
  keywords = {Competency-based education,Criterion-referenced tests,Curricula,Education},
  file = {/Users/colin.madland/Zotero/storage/UF84CWB9/ashmanEngagingFirstYear2022.pdf}
}

@article{ashwinEducationalPurposesHigher2022,
  title = {The Educational Purposes of Higher Education: Changing Discussions of the Societal Outcomes of Educating Students},
  author = {Ashwin, Paul},
  year = {2022},
  month = oct,
  journal = {Higher Education},
  issn = {1573-174X},
  doi = {10.1007/s10734-022-00930-9},
  abstract = {In this article, I examine the educational purposes of higher education in terms of the societal outcomes of educating students through higher education. Based on an analysis of the first 80 volume of Higher Education, published from 1972 to 2020, I argue that discussions of societal educational purposes were dominated by authors from the Anglophone, global North and these authors were more likely to write as if the educational purposes under discussion were relevant to all higher education systems regardless of national context. This tendency increased over time. The overall models of the educational purposes in each contribution differed in terms of whether they focused on single, multiple, or differentiated sets of educational purposes. I argue that as higher education has become increasingly stratified, there has been less discussion of whether there are differences in the societal outcomes served by different forms of higher education. This is problematic because it obscures the potential differences in the educational purposes of higher education in different societies and the extent to which inequalities are perpetuated by differences in the forms of higher education to which students gain access. In order to address this, I argue there is a need to move away from a focus on the educational purposes of the institutional form of `the University' to focus on the educational purposes that are served by different configurations of higher education systems.},
  file = {/Users/colin.madland/Zotero/storage/I6WZ88JF/ashwinEducationalPurposesHigher2022.pdf}
}

@article{asmaAssessingUniversityStudents2019,
  title = {Assessing {{University Students}}' {{Physical Activity Levels}} in {{Terms}} of {{Different Variables}}},
  author = {Asma, Mehmet Bulent and Gencer, Yildirim G{\"o}khan},
  year = {2019},
  month = jan,
  journal = {International Journal of Progressive Education},
  volume = {15},
  number = {2},
  pages = {1--8},
  publisher = {International Journal of Progressive Education},
  issn = {1554-5210},
  doi = {10.29329/ijpe.2019.189.1},
  abstract = {This study aimed at assessing physical activity levels of university students who studied at Van Y{\"u}z{\"u}nc{\"u} Yil University in terms of different variables. 20 students who studied at School of Physical Education and Sports (SPES) (10 female students and 10 male students) and 20 students who studied at Education Faculty (EF) (10 female students and 10 male students) participated in the study voluntarily. The steps took during the day were measured by bio-electric impedance method and data about their nutrition, sleep, residence and internet use have been collected via information form and then this information was evaluated. Whether or not data followed a normal distribution was assessed and Non-Parametric Mann Whitney U Test was used for assessments. According to findings; average number of students' daily steps was 11,063{\textpm}2198 in male students while it was 10,308{\textpm}1829 in female students. There was no significant difference in terms of academic schools where the students attended (p{$>$}0.05) whereas there were significant differences in terms of sex variable among male students of SPES and EF as compared to female students in the parameters of BMI, body fat ratio and residence place (p{$<$}0.05). Besides, there were also significant differences in the number of weekly steps among students of both schools in terms of doing sports variable (p{$<$}0.05). However; no statistically significant differences were found in terms of students' internet use, daily sleep length, transportation to schools and number of weekly total steps (p{$<$}0.05). As a result, it was noted that physical activity levels of the female and male students were "active" according to literature criteria and average number of daily steps of those students who regularly did sports was high as expected.},
  keywords = {Athletics,Body Composition,Body Height,Body Weight,College Students,Computer Use,Foreign Countries,Gender Differences,Internet,Nutrition,Physical Activity Level,Physical Education,Place of Residence,Sleep,Transportation,Turkey},
  file = {/Users/colin.madland/Zotero/storage/A6URJ4FX/asmaAssessingUniversityStudents2019.pdf}
}

@misc{assemblyoffirstnationsFirstNationsControl2010,
  title = {First {{Nations Control}} of {{First Nations Education}}},
  author = {{Assembly of First Nations}},
  year = {2010},
  publisher = {Assembly of First Nations},
  abstract = {The Indian Control of Indian Education 1972 (ICIE 1972) policy articulated a statement of values which is as true today as it was at its inception. The National Indian Brotherhood (hereinafter Assembly of First Nations (AFN)) adopted the policy paper ``Indian Control of Indian Education'' in 1972 (Appendix I). The ICIE 1972 policy was affirmed by then Minister of Indian Affairs, Jean Chr{\'e}tien, in 1973. The full spirit and intent of the ICIE 1972 policy, however, has never been supported in a meaningful manner. Successive federal governments have consistently failed to provide the necessary support to fully implement the comprehensive First Nations learning environments and systems envisioned by First Nations that would lead to an overall improvement in learning outcomes.},
  file = {/Users/colin.madland/Zotero/storage/Q6V6FJWG/assemblyoffirstnationsFirstNationsControl2010.pdf}
}

@article{AssessmentEducationPrinciples1994,
  title = {Assessment in Education : Principles, Policy \& Practice.},
  year = {1994},
  journal = {Assessment in education : principles, policy \& practice.},
  publisher = {Carfax International Publishers},
  address = {Abingdon, Oxfordshire},
  issn = {1465-329X},
  keywords = {Education -- Evaluation,Education -- Evaluation -- Periodicals,Education -- Evaluation -- Periodiques,Educational tests and measurements,Educational tests and measurements -- Periodicals,Electronic journals,periodicals,Periodicals,Periodiques,Tests et mesures en education,Tests et mesures en education -- Periodiques}
}

@article{AssessmentEvaluationHigher1981,
  title = {Assessment and Evaluation in Higher Education ({{Online}})},
  year = {1981},
  journal = {Assessment and evaluation in higher education (Online)},
  publisher = {Carfax International Publishers},
  address = {Abingdon, Oxfordshire},
  issn = {1469-297X},
  keywords = {Academic Testing,Education Higher -- Evaluation,Electronic journals,Enseignement superieur -- Evaluation,Higher Education,Hoger onderwijs,Onderwijsevaluatie,Periodicals,Tests}
}

@misc{AssessmentFuturesCom2012,
  title = {{{AssessmentFutures}}.Com},
  year = {2012},
  month = sep,
  journal = {University of Technology Sydney},
  urldate = {2021-04-10},
  abstract = {Assessment FuturesMany students currently graduate without appropriate skills in assessment.Assessment serves many purposes, including:{$\bullet$} helping students improve their learning, and{$\bullet$} certifying their learning.This website is about an~important~additional purpose for assessment.It is about equipping students for the learning and assessing they will need to do~after~completing their course and the challenges they will face after graduation.},
  howpublished = {https://www.uts.edu.au/research-and-teaching/learning-and-teaching/assessment-futures/overview},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/YB3CKDUI/overview.html}
}

@misc{AssessmentLearningDigital,
  title = {Assessment, Learning and Digital Education {\textbar} {{MSc}} in {{Digital Education}}},
  urldate = {2021-04-07},
  howpublished = {https://digital.education.ed.ac.uk/course/assessment-learning-and-digital-education},
  file = {/Users/colin.madland/Zotero/storage/ZKWEF25R/assessment-learning-and-digital-education.html}
}

@article{AssessmentTestingApplied,
  title = {Assessment, {{Testing}} and {{Applied Measurement}}},
  series = {Frontiers in {{Education}}}
}

@article{astinWhatMattersCollege1993,
  title = {What Matters in College?},
  shorttitle = {What Matters in College?},
  author = {Astin, Alexander W.},
  year = {1993 Fall},
  journal = {Liberal Education},
  volume = {79},
  pages = {4},
  issn = {00241822},
  abstract = {Presents a study which focused primarily on student outcomes and how they are affected by college environments. Details of the study; Issues studied; Findings; Impact of student interaction; Peer group effects with regards to gender and race; Student-faculty interaction; Faculty responses to teaching; Implications for educational reform. INSET: Reflection and learning..},
  keywords = {College,COLLEGE environment,environment,EVALUATION},
  annotation = {4}
}

@article{ates-cobanogluTurkishStudentTeachers2021,
  title = {Do {{Turkish Student Teachers Feel Ready}} for {{Online Learning}} in {{Post-COVID Times}}? {{A Study}} of {{Online Learning Readiness}}},
  author = {{Ates-Cobanoglu}, Alev and Cobanoglu, Ilker},
  year = {2021},
  month = jul,
  journal = {Turkish Online Journal of Distance Education},
  volume = {22},
  number = {3},
  issn = {EISSN-1302-6488},
  abstract = {The purpose of this descriptive study is to investigate on-line learning readiness levels of student teachers according to several variables. By using purposive sampling method, the sample consisted of 270 (200 female and 70 male) student teachers in Turkey. Data collection tools include (i) Student Demographics Form with 18 items, (ii) On-line Learning Readiness Scale with 18 items and five factors. Statistically, the quantitative data were analyzed via ANOVA, t-test and ANCOVA. The findings suggest that mean of on-line learning readiness levels of student teachers is at good level. On-line learning readiness levels of student teachers are significantly different according to their departments [F(4,265)=3.450, p=0.09]. Namely, the mean scores for the students from Elementary Education and Pre-school Education departments were significantly higher than those from Social Science Education department. Besides, student teachers who has Internet access had higher on-line learning readiness scores (M= 67.27, SD=9.86) than did those without access (M= 60.14, SD=10.64), t(268)=3.16, p=0.002. There are also significant differences between student teachers' on-line learning readiness scores per their perceived information and communication technology use competency and departments after differences in accessibility to the Internet is controlled (p{$<$}0.001). As mentioned by International Society for Technology in Education in 2019 standards, on-line learning readiness needs to be considered in detail to assist learners in using digital media in 21st century for learning; teaching; gathering, producing, sharing information for educational purposes. In conclusion, it is suggested that practitioners should increase online, distance or blended (both on-line and face-to-face) learning experiences of their students who are prospective teachers of the 21st century learners. Therefore, it is strongly suggested contributing development of learning and teaching skills of student teachers by getting them more familiar with on-line learning environments especially in post-COVID times.},
  langid = {english},
  keywords = {Access to Computers,Blended Learning,COVID-19,Distance Education,Educational Technology,Foreign Countries,Intellectual Disciplines,Internet,No DOI found,Online Courses,Pandemics,Preservice Teachers,Readiness,Teacher Education Programs,Technological Literacy,Technology Uses in Education}
}

@unpublished{athabascauniversityNoOtherAthabasca2024,
  type = {Strategic {{Plan}}},
  title = {Like {{No Other}}: {{Athabasca University Strategic Plan}} (2024-2029)},
  author = {Athabasca University},
  year = {2024},
  address = {Athabasca},
  urldate = {2024-12-17}
}

@article{athertonUsingLearningAnalytics2017,
  title = {Using Learning Analytics to Assess Student Engagement and Academic Outcomes in Open Access Enabling Programmes},
  author = {Atherton, M and Shah, M and Vazquez, J and Griffiths, Z and Jackson, B and Burgess, C},
  year = {2017},
  journal = {Open Learning},
  volume = {32},
  number = {2},
  pages = {119--136},
  issn = {0268-0513},
  doi = {10.1080/02680513.2017.1309646},
  abstract = {Curriculum design, teaching methods, assessments and range of academic support need to be inclusive in Open Access Enabling courses. The findings of this study confirm a correlation between student access to online learning materials and a positive impact on grades in science courses. More specifically, students who frequently use the online learning system to access materials have better assessment and exam results.},
  langid = {english},
  keywords = {DISTANCE,enabling education,EQUITY,HIGHER-EDUCATION,LANGUAGE,learning analytics,learning technologies,MODEL,PREDICTORS,QUALITY-ASSURANCE,SCHOOL,science education,Student engagement}
}

@book{atwehActionResearchPractice2002,
  title = {Action {{Research}} in {{Practice}}: {{Partnership}} for {{Social Justice}} in {{Education}}},
  author = {Atweh, B. and Kemmis, S. and Weeks, P.},
  year = {2002},
  publisher = {Taylor \& Francis},
  isbn = {978-1-134-69492-1},
  file = {/Users/colin.madland/Zotero/storage/CYTEVXYR/atwehActionResearchPractice2002.pdf}
}

@article{augustusKnowledgeLiaisonsNegotiating2015,
  title = {Knowledge {{Liaisons}}: {{Negotiating Multiple Pedagogies}} in {{Global Indigenous Studies Courses}}},
  author = {Augustus, Camie},
  year = {2015},
  journal = {The Canadian Journal of Higher Education},
  volume = {45},
  number = {4},
  pages = {1--17},
  issn = {03161218},
  urldate = {2019-02-15},
  abstract = {Despite the implied importance of comparative Indigenous studies, little has been written about global Indigenous courses. There are two sets of literature wherein one might expect to find such a conversation. The first, literature on teaching globally, generally does not consider or include Indigenous issues (Rothwell, 2005; Stanley \& Plaza, 2002). Discussions of teaching globally tend to focus on "global awareness" as a socioeconomic problem, centring on students' abilities to situate their knowledge in global contexts (Gibson, Rimmington, \& Landwehr-Brown, 2008). What might be described as the "development" model considers topics like housing, the effects of transnational corporations, poverty, food security, and internal political crisis and conflict ([Peterson, Patti McGill], 2012). A corollary of this model takes an anti-capitalism stance, whereby globalization is invariably posited as a tool of exploitation (McLaren \& Farahmandpur, 2001). In both models, Indigenous peoples are viewed in the context of other disadvantaged or "develop- "develop- ing" populations in classrooms that seek to teach racial tolerance and cultural diversity (Fanghanel \& Cousin, 2012). Multiculturalism is thus taken to an international level to promote tolerance and dispel negative stereotypes. The emphasis is on teaching students to be responsible "global citizens" who are engaged in and aware of global issues and problems, especially those in African, Latin American, and South Asian countries. Violations against community well-being are thus posited in the context of modern human rights and environmental issues, not of continuing historical colonialism. Indigenous peoples become conflated with "the poor" or "victimized" (although indeed they are often both), in contrast to students as citizens of privileged, "developed" nations who are taught about their social responsibilities to "save" victimized peoples.}
}

@article{austinFutureFacultyDevelopment2013,
  title = {The {{Future}} of {{Faculty Development}}: {{Where Are We Going}}?},
  author = {Austin, Ann E. and Sorcinelli, Mary Deane},
  year = {2013},
  journal = {New Directions for Teaching and Learning},
  volume = {2013},
  number = {133},
  pages = {85--97}
}

@article{AustralasianJournalEducational2004,
  title = {Australasian Journal of Educational Technology ({{Online}})},
  year = {2004},
  journal = {Australasian journal of educational technology (Online)},
  publisher = {Australian Society for Educational Technology},
  issn = {1449-5554},
  keywords = {Conception pedagogique,Education,Educational technology,Electronic journals,Periodicals,Periodique electronique (Descripteur de forme),Ressource Internet (Descripteur de forme),Technologie educative,Telecommunication,Telecommunication in education}
}

@article{awang-hashimStrategizingInclusivityTeaching2019,
  title = {Strategizing {{Inclusivity}} in {{Teaching Diverse Learners}} in {{Higher Education}}},
  author = {{Awang-Hashim}, Rosna and Kaur, Amrita and Valdez, Nena P.},
  year = {2019},
  journal = {Malaysian Journal of Learning and Instruction},
  volume = {16},
  number = {1},
  pages = {105--128},
  issn = {ISSN-1675-8110},
  doi = {10/gmbv38},
  abstract = {Purpose: As the classrooms in higher education are growing increasingly diverse, it is imperative that higher education practitioners build a responsive learning environment for diverse learners to optimize their potential. Continuing professional development programmes (CPD) are central to such strategic approaches that equip educators with essential knowledge and skills to handle diversity related issues, achieve equity and increase student participation. Therefore, the present study aims to examine strategies used by higher education practitioners to address diversity and inclusion in teaching and learning. Methodology: Participants comprised nine academicians (six men and three women) who emerged from natural retention along the iterative cycles on community of practice (CoP) participation. This study adopted CoP as the theoretical lens and methodological tool to understand the strategies higher education practitioners have devised for their inclusive teaching and learning practices in response to diversity related challenges. The data was collected through a series of observations and reflective journals. Initially, thematic analysis techniques were used to reduce data into two categories--strategies and challenges. Later, according to prevalence and frequency counts, the strategies were analysed against the challenges reported and finally the strategies were reduced to major themes. Findings: Three major themes emerged which reported on the inclusive strategies conceived by the participants. The themes were inclusive/differentiated assessment which suggested that creating differentiated assessment that were inclusive in nature could provide equal opportunities for each and every student to participate. The second theme, motivation and goal strategies revealed that students were diverse in their goals for learning. Hence, a variety of motivational strategies such as including students' voice, providing them with a clear rationale for studying and fostering relatedness were deemed suitable to address these differences. The final theme, inclusive pedagogy suggested a variety of accommodation to be made in pedagogy such as integrating technology, adopting culturally responsive material and initiating collaborative learning to address students' differences. Significance: The findings have implications for faculty professional development, classroom teaching practices employing inclusive pedagogy in higher education institutions and the use of CoP as a framework for such developments.},
  langid = {english},
  keywords = {College Faculty,Communities of Practice,Cooperative Learning,Cultural Differences,Culturally Relevant Education,Educational Strategies,Faculty Development,Foreign Countries,Inclusion,Individual Differences,Individualized Instruction,Professional Continuing Education,Public Colleges,Student Diversity,Student Educational Objectives,Teacher Attitudes,Technology Integration}
}

@article{aydinEthicalIssuesEducational2024,
  title = {Ethical {{Issues}} in {{Educational Technology}}},
  author = {Ayd{\i}n, {\.I}nayet},
  year = {2024},
  month = jan,
  journal = {Kastamonu Education Journal},
  volume = {32},
  number = {1},
  pages = {138--158},
  publisher = {Kastamonu University},
  issn = {2147-9844},
  doi = {10.24106/kefdergi.1426735},
  urldate = {2024-01-01},
  abstract = {Purpose: The purpose of this study is to identify the ethical issues created by educational technology from the perspective of children and youth and to develop recommendations for addressing the ethical problems they face in educational technology based on ethical evaluations. Design/Methodology/Approach: This study utilizes the \&quot;Narrative Review\&quot; method. Findings: This study reveals scientific findings on the inequalities created among students by educational technology, its impact on the child\&\#039;s privacy, values, and world of meaning, its effects on students\&\#039; learning, cognitive functions, and creativity, its influence on students\&\#039; emotional development and human relationships, as well as the negative effects of virtual reality and gamification, and the impact of technology on children\&\#039;s fundamental academic and physical skills.Highlights: This research emphasizes the significant responsibilities that educational managers, decision-makers, policymakers, and teachers, especially those concerning \&quot;minors\&quot; under the age of 18, need to take on regarding the responsible, safe, and ethical use of technology in educational processes. The study delves into protecting children from potential harm and negative effects resulting from their use of educational technology.},
  copyright = {Y{\i}ld{\i}r{\i}m, H. (2018). A{\c c}{\i}k ve uzaktan {\"o}{\u g}renmede blokzincir teknolojisinin kullan{\i}m{\i}. [The use of blockchain technology in open and distance learning] A{\c c}{\i}k{\"o}{\u g}retim Uygulamalar{\i} ve Ara{\c s}t{\i}rmalar{\i} Dergisi, AUAd, 4(3), 142-153.},
  langid = {english},
  keywords = {Educatioanl technology,Ethical issues in educational technology,Ethics,Ethics in educational technology,Privacy and protection of children},
  file = {/Users/colin.madland/Zotero/storage/QVXJAFHM/_.pdf}
}

@misc{aydinOpenAIChatGPTGenerated2022,
  type = {{{SSRN Scholarly Paper}}},
  title = {{{OpenAI ChatGPT Generated Literature Review}}: {{Digital Twin}} in {{Healthcare}}},
  shorttitle = {{{OpenAI ChatGPT Generated Literature Review}}},
  author = {Ayd{\i}n, {\"O}mer and Karaarslan, Enis},
  year = {2022},
  month = dec,
  number = {4308687},
  address = {Rochester, NY},
  doi = {10.2139/ssrn.4308687},
  urldate = {2023-01-08},
  abstract = {Literature review articles are essential to summarise the related work in the selected field. However, covering all related studies takes too much time and effort. This study questions how Artificial Intelligence can be used in this process. We used ChatGPT to create a literature review article to show the stage of the OpenAI ChatGPT artificial intelligence application. As the subject, the applications of Digital Twin in the health field were chosen. Abstracts of the last three years (2020, 2021 and 2022) papers were obtained from the keyword "Digital twin in healthcare" search results on Google Scholar and paraphrased by ChatGPT. Later on, we asked ChatGPT questions. The results are promising; however, the paraphrased parts had significant matches when checked with the Ithenticate tool. This article is the first attempt to show the compilation and expression of knowledge will be accelerated with the help of artificial intelligence. We are still at the beginning of such advances. The future academic publishing process will require less human effort, which in turn will allow academics to focus on their studies. In future studies, we will monitor citations to this study to evaluate the academic validity of the content produced by the ChatGPT},
  langid = {english},
  keywords = {academic publishing,artificial intelligence,ChatGPT,ChatGPT revolution,Digital twin,Healthcare,OpenAI},
  file = {/Users/colin.madland/Zotero/storage/QSU92E3J/aydinOpenAIChatGPTGenerated2022.pdf}
}

@article{ayyoubUniversityStudentsEvaluation2021,
  title = {University {{Students}}' {{Evaluation}} of {{E-Assessment}} in {{Light}} of the {{Coronavirus Pandemic}}},
  author = {Ayyoub, Abed Alkarim and Jabali, Oqab},
  year = {2021},
  month = jan,
  journal = {Cypriot Journal of Educational Sciences},
  volume = {16},
  number = {4},
  pages = {1434--1449},
  publisher = {Cypriot Journal of Educational Sciences},
  issn = {1305-905X},
  doi = {10.18844/cjes.v16i4.5998},
  abstract = {Educational institutions strive to achieve their purposes mainly assessing students' performance and abilities; they might use traditional types of assessment or they may be forced to apply electronic assessment in certain situations such as those dictated by the current spread of COVID-19 Pandemic. The current study aims at providing insights into the ways and levels of university students' evaluation of the electronic assessment during the global health crisis whether this evaluation is affected by certain demographic variables or not. A 29-item online questionnaire was developed and conducted by the researchers to survey a large sample of university population. A large number of the students (n=582) responded to the survey. The study results show that the level of students' evaluation of e-assessment is moderate. The researchers also find that an interaction between gender and faculty may influence students' evaluation positively and negatively. The implications of the study suggest that educational institutions should consider all types of assessment mainly e-assessment to keep pace with all advancements and evade unexpected circumstances like pandemics.},
  keywords = {College Students,Computer Assisted Testing,COVID-19,Evaluation Methods,Foreign Countries,Gender Differences,Instructional Program Divisions,Intellectual Disciplines,Palestine,Pandemics,Student Attitudes,Student Evaluation},
  file = {/Users/colin.madland/Zotero/storage/RNUP98Z3/ayyoubUniversityStudentsEvaluation2021.pdf}
}

@book{azevedoHandbookResearchEassessment2019,
  title = {Handbook of Research on {{E-assessment}} in Higher Education},
  author = {Azevedo, Ana and Azevedo, Jose},
  year = {2019},
  publisher = {IGI Global},
  address = {Hershey, Pennsylvania},
  abstract = {"This book provides insights concerning the use of E-assessment in Higher Education. It also provides the opportunity for a reflection on this important issue, increasing the understanding of using E-assessment in the context of several different contexts, providing relevant academic work, empirical research findings, and an overview of this relevant field of study"-- Provided by publisher.},
  isbn = {1-5225-5937-X},
  keywords = {College students -- Rating of -- Data processing,Electronic books,Universities and colleges -- Examinations -- Data processing},
  file = {/Users/colin.madland/Zotero/storage/L3YJ9T9F/azevedoHandbookResearchEassessment2019.pdf}
}

@article{azevedoMathematicsLearningAssessment2022,
  title = {Mathematics Learning and Assessment Using {{MathE}} Platform: {{A}} Case Study},
  author = {Azevedo, Beatriz Flamia and Pereira, Ana I. and Fernandes, Florbela P. and Pacheco, M. Fatima},
  year = {2022},
  journal = {Education and information technologies},
  volume = {27},
  number = {2},
  pages = {1747--1769},
  publisher = {Springer US},
  address = {New York},
  issn = {1360-2357},
  doi = {10.1007/s10639-021-10669-y},
  abstract = {Universities are encouraging the implementation of innovative methodologies and teaching strategies to develop an interactive and appealing educational environment where students are the focus of the learning process. In such a personalised learning environment, an increase of the students' engagement and the improvement of the outcomes arise. MathE has been developed to help achieve this goal. Based on collaborative procedures, internet resources -- both pre-existing and freely available as well as resources specifically conceived by the project team -- and communities of practices, MathE intends to be a tool to nurture and stimulate the learning of Mathematics in higher education. This study introduces and describes the MathE platform, which is divided into three sections: Student's Assessment, Library and Community of Practice. An in-depth description of the Student's Assessment section is presented and an analysis of the results obtained from students, when using this feature of the platform, is also provided. After this, and based on the answers to an online survey, the impact of the MathE platform among students and teachers of eight countries is shown. Although the number of collected results is still scarce, it allows the recognition of a trend regarding the use of the material of the Student's Assessment section for autonomous study. The results indicate the platform is well organized, with a satisfactory amount and diversity of questions and good interconnection between the various parts. Nevertheless, both teachers and students indicate that more questions should be introduced. The overall opinion about the MathE platform is very favourable.},
  keywords = {Case studies,Collaborative learning,College students,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Distance learning,e-Learning,Education,Education & Educational Research,Education Higher,Educational evaluation,Educational Technology,Higher education,Information Systems Applications (incl.Internet),Learning strategies,Mathematics,Mathematics education,Social Sciences,Teachers,User Interfaces and Human Computer Interaction},
  file = {/Users/colin.madland/Zotero/storage/KQH4R2BH/azevedoMathematicsLearningAssessment2022.pdf}
}

@article{azevedoScaffoldingSelfregulatedLearning2005,
  title = {Scaffolding Self-Regulated Learning and Metacognition - Implications for the Design of Computer-Based Scaffolds},
  author = {Azevedo, Roger and Hadwin, Allyson F},
  year = {2005},
  month = nov,
  journal = {Instructional Science},
  volume = {33},
  number = {5-6},
  pages = {367--379},
  issn = {0020-4277},
  doi = {10.1007/s11251-005-1272-9},
  langid = {english},
  keywords = {Education}
}

@article{aziziFairnessAssessmentPractices2022,
  title = {Fairness in Assessment Practices in Online Education: {{Iranian University English}} Teachers' Perceptions},
  author = {Azizi, Zeinab},
  year = {2022},
  journal = {Language Testing in Asia},
  volume = {12},
  number = {1},
  pages = {1--17},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2229-0443},
  doi = {10.1186/s40468-022-00164-7},
  abstract = {Although fairness in assessment practices (APs) in traditional classes has gained noticeable attention in recent years, it has remained unexplored in online education (OE). Thus, this study explores Iranian university English teachers' perceptions of fair APs in OE. For this purpose, 21 university English teachers from Lorestan University and Ayatollah Borujerdi University, Iran, were selected using a purposive sampling method. They were invited to express their conceptions of fair APs by completing a reflective written statement questionnaire. The collected data were subjected to a thematic coding analysis. The results yielded three overarching categories: distributive justice (i.e., equality should be considered, equity is of paramount importance, and assessment practices should be tied with students' needs), procedural justice (i.e., voices of students should be heard, both consistency and flexibility are required, and assessment procedures should be transparent), and interactional justice (i.e., interpersonal justice is crucial and informational justice should be considered). The study concludes by proposing a range of implications for different testing stakeholders.},
  keywords = {Assessment,Assessment practices,Education,English as a second language instruction,English teachers,Fairness,Higher education,Language Education,Learning oriented Assessment (LOA): A Window for Fairness in Classroom Assessment?,Online education,Online instruction,Teacher attitudes,Testing and Evaluation,University English teachers},
  file = {/Users/colin.madland/Zotero/storage/8KLJEEET/aziziFairnessAssessmentPractices2022.pdf}
}

@article{aziziFairnessAssessmentPractices2022a,
  title = {Fairness in Assessment Practices in Online Education: {{Iranian University English}} Teachers' Perceptions},
  author = {Azizi, Zeinab},
  year = {2022},
  journal = {Language Testing in Asia},
  volume = {12},
  number = {1},
  pages = {1--17},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2229-0443},
  doi = {10.1186/s40468-022-00164-7},
  abstract = {Although fairness in assessment practices (APs) in traditional classes has gained noticeable attention in recent years, it has remained unexplored in online education (OE). Thus, this study explores Iranian university English teachers' perceptions of fair APs in OE. For this purpose, 21 university English teachers from Lorestan University and Ayatollah Borujerdi University, Iran, were selected using a purposive sampling method. They were invited to express their conceptions of fair APs by completing a reflective written statement questionnaire. The collected data were subjected to a thematic coding analysis. The results yielded three overarching categories: distributive justice (i.e., equality should be considered, equity is of paramount importance, and assessment practices should be tied with students' needs), procedural justice (i.e., voices of students should be heard, both consistency and flexibility are required, and assessment procedures should be transparent), and interactional justice (i.e., interpersonal justice is crucial and informational justice should be considered). The study concludes by proposing a range of implications for different testing stakeholders.},
  keywords = {Assessment,Assessment practices,Education,English as a second language instruction,English teachers,Fairness,Higher education,Language Education,Learning oriented Assessment (LOA): A Window for Fairness in Classroom Assessment?,Online education,Online instruction,Teacher attitudes,Testing and Evaluation,University English teachers},
  file = {/Users/colin.madland/Zotero/storage/SP6YZENL/aziziFairnessAssessmentPractices2022a.pdf}
}

@article{b7fa62850a8b1d4bd72f362f6fd49ca10ce420fe,
  title = {A Personal and Profound Approach to Building {{ESL}} Teachers' Assessment Literacy in the ``{{Transitional}} Space''},
  author = {{Willoughby-Knox}, Brie},
  year = {2019},
  doi = {10/gh5k7c},
  abstract = {null}
}

@article{b8f8fabea1ab6f92c60922141f509e2254ce22e1,
  title = {Language Assessment Literacy as Self-Awareness: {{Understanding}} the Role of Interpretation in Assessment and in Teacher Learning},
  author = {Scarino, Angela},
  year = {2013},
  journal = {Language Testing},
  volume = {30},
  pages = {309--327},
  doi = {10/gh5k7g},
  abstract = {The increasing influence of sociocultural theories of learning on assessment practices in second language education necessitates an expansion of the knowledge base that teacher-assessors need to develop (what teachers need to know) and related changes in the processes of language teacher education (how they learn and develop it). Teacher assessors need to acquire concepts from diverse assessment paradigms; they need to learn to use these concepts in developing, using and analysing assessment procedures and results; they need to exercise critical perspectives on their own assessment practices for particular purposes in diverse contexts, especially in seeking to do justice to all in education. In this paper I argue that, to develop language assessment literacy with the dual goals of transforming teacher assessment practices and developing teacher understanding of the phenomenon of assessment itself and themselves as assessors, it is necessary to reconsider both the knowledge base and the complex processes of language teacher education. I draw on projects I have conducted on developing and investigating teacher understanding and practices in second language assessment, to discuss the need to work with the often tacit preconceptions, beliefs, understandings and world-views about assessment that teacher-assessors bring to teacher professional learning programs and that inform their conceptualizations, interpretations, judgments and decisions in assessment. I discuss the need in developing language assessment literacy for processes that develop teacher-assessors' capability to explore and evaluate their own preconceptions so as to become aware of how they interpret their own assessment practices and their students' second language learning. Through these processes they develop a deeper understanding of the interpretive nature of assessment and their own self-awareness as assessors.}
}

@article{baartmanSelfevaluationAssessmentPrograms2011,
  title = {Self-Evaluation of Assessment Programs: {{A}} Cross-Case Analysis},
  shorttitle = {Self-Evaluation of Assessment Programs},
  author = {Baartman, Liesbeth K.J. and Prins, Frans J. and Kirschner, Paul A. and {\noopsort{vleuten}}{van der Vleuten}, Cees P.M.},
  year = {2011},
  month = aug,
  journal = {Evaluation and Program Planning},
  volume = {34},
  number = {3},
  pages = {206--216},
  issn = {01497189},
  doi = {10/bqn87p},
  urldate = {2020-12-21},
  langid = {english}
}

@article{babatundeAssessmentMethodsEntrepreneurship2021,
  title = {Assessment {{Methods}} in {{Entrepreneurship Education}}, {{Challenges}} and {{Opportunities}} in {{Developed}} and {{Developing Nations}}: {{A Comparative Study}} of {{Nigeria}} and {{England}}},
  author = {Babatunde, Simeon and {El-Gohary}, Hatem and Edwards, David},
  year = {2021},
  month = jan,
  journal = {Education \& Training},
  volume = {63},
  number = {7-8},
  pages = {1092--1113},
  publisher = {Education \& Training},
  issn = {0040-0912},
  abstract = {Purpose: With the growth of entrepreneurship education adoption in higher education institutions (HEIs), the importance of assessments as a tool to gauge and enhance learning is of utmost importance. The purpose of this paper is to examine the influence and appropriateness of current assessment methods for engineering and technology students in Nigerian and British HEIs. Design/methodology/approach: The study employs a qualitative research method with a case study approach to investigate the impact and suitability of assessment methods currently used within entrepreneurship education in Nigeria and England. Findings: The results reveal that lecturers across both countries believed that assessment methods currently in use were appropriate, but were not uniform in its influence on learning. However, students were unanimous in that most assessment methods currently used were not effective at enhancing their learning, not very appropriate, and were not a good judge of their work and effort. The results were used in building a framework to understand the importance of assessment methods in entrepreneurship education. Originality/value: In light of the inadequate literature, this paper covers an acute gap in the field. This will allow policymakers and different interested parties to reassess the development of suitable assessment methods to involve students as key stakeholders.},
  keywords = {College Students,Comparative Education,Developed Nations,Developing Nations,Engineering Education,Evaluation Methods,Foreign Countries,Nigeria,No DOI found,Student Evaluation,Technology Education,United Kingdom (England)}
}

@article{baboAssessmentMultipleChoiceQuestions2020,
  title = {E- {{Assessment}} with {{Multiple-Choice Questions}}: {{A}} 5 {{Year Study}} of {{Students}}' {{Opinions}} and {{Experience}}},
  author = {Babo, Rosalina and V. Babo, Lurdes and T Suhonen, Jarkko and Tukiainen, Markku},
  year = {2020},
  journal = {Journal of Information Technology Education: Innovations in Practice},
  volume = {19},
  pages = {001--029},
  issn = {2165-3151, 2165-316X},
  doi = {10/gmbvnn},
  urldate = {2021-07-27},
  abstract = {Aim/Purpose: The aim of this study is to understand student's opinions and perceptions about e-assessment when the assessment process was changed from the traditional computer assisted method to a multiple-choice Moodle based method. Background: In order to implement continuous assessment to a large number of students, several shifts are necessary, which implies as many different tests as the number of shifts required. Consequently, it is difficult to ensure homogeneity through the different tests and a huge amount of grading time is needed. These problems related to the traditional assessment based on computer assisted tests, lead to a re-design of the assessment resulting in the use of multiple-choice Moodle tests.  Methodology: A longitudinal, concurrent, mixed method study was implemented over a five-year period. A survey was developed and carried out by 815 undergraduate students who experienced the electronic multiple-choice questions (eMCQ) assessment in the courses of the IS department. Qualitative analyses included open-ended survey responses and interviews with repeating students in the first year. Contribution: This study provides a reflection tool on how to incorporate frequent moments of assessment in courses with a high number of students without overloading teachers with a huge workload. The research analysed the efficiency of assessing non-theoretical topics using eMCQ, while ensuring the homogeneity of assessment tests, which needs to be complemented with other assessment methods in order to assure that students develop and acquire the expected skills and competencies. Findings: The students involved in the study appreciate the online multiple-choice quiz assessment method and perceive it as fair but have a contradictory opinion regarding the preference of the assessment method, throughout the years. These changes in perception may be related to the improvement of the question bank and categorisation of questions according to difficulty level, which lead to the nullification of the `luck factor'. Other major findings are that although the online multiple-choice quizzes are used with success in the assessment of theoretical topics, the same is not in evidence regarding practical topics. Therefore, this assessment needs to be complemented with other methods in order to achieve the expected learning outcomes. Recommendations for Practitioners: In order to be able to evaluate the same expected learning outcomes in practical topics, particularly in technology and information systems subjects, the evaluator should complement the online multiple-choice quiz assessment with other approaches, such as a PBL method, homework assignments, and/or other tasks performed during the semester. Recommendation for Researchers: This study explores e-assessment with online multiple-choice quizzes in higher education. It provides a survey that can be applied in other institutions that are also using online multiple-choice quizzes to assess non-theorical topics. In order to better understand the students' opinions on the development of skills and competencies with online multiple-choice quizzes and on the other hand with classical computer assisted assessment, it would be necessary to add questions concerning these aspects. It would then be interesting to compare the findings of this study with the results from other institutions. Impact on Society: The increasing number of students in higher education has led to a raised use of e-assessment activities, since it can provide a fast and efficient manner to assess a high number of students. Therefore, this research provides meaningful insight of the stakeholders' perceptions of online multiple-choice quizzes about practical topics. Future Research: An interesting study, in the future, would be to obtain the opinions of a particular set of students on two tests, one of the tests using online multiple-choice quizzes and the other through a classical computer assisted assessment method. A natural extension of the present study is a comparative analysis regarding the grades obtained by students who performed one or another type of assessment (online multiple-choice quizzes vs. classical computer assisted assessment).},
  langid = {english},
  keywords = {e-assessment,EDUCATION,learning management system,Moodle quiz,multiple-choice question,PERCEPTIONS,SELF,SHORT-ANSWER,summative assessment,TESTS,TOOL},
  file = {/Users/colin.madland/Zotero/storage/Z2V9ISC3/baboAssessmentMultipleChoiceQuestions2020.pdf}
}

@article{baboolal-frankEmergencyRemoteLearning2021,
  title = {Emergency {{Remote Learning}} during the {{Pandemic}} from a {{South African Perspective}}},
  author = {{Baboolal-Frank}, Rashri},
  year = {2021},
  month = jan,
  journal = {International Journal for Educational Integrity},
  volume = {17},
  publisher = {International Journal for Educational Integrity},
  issn = {1833-2595},
  abstract = {The COVID-19 pandemic created a situation for the implementation of emergency remote learning. This meant that as a lecturer at a traditionalist University of contact sessions, the pandemic forced us to teach remotely through online methods of communication, using online lectures, narrated powerpoints, voice clips, podcasts, interviews and interactive videos. The assessments were conducted online from assignments to multiple choice questions, which forced the lecturers to think differently about the way the assessments were presented, in order to avoid easy access to answers found in a textbook and online. This meant that more application questions of theory to practice were assessed in a more challenging way to prevent cheating and collaboration with peers. Formal assessments completed during emergency remote learning, have become the past practice, as innovative methods have been adopted for learning and for assessment purposes in order to preserve the integrity and attainment of the degree through online modes of learning. The aim of the paper investigates and explores the methods of teaching, together with the results obtained from the students of 2019 and 2020 in their final year relating to two final year modules against the literature relating to learning processes and methodologies.},
  keywords = {Cheating,Computer Assisted Testing,COVID-19,Distance Education,Electronic Learning,Emergency Programs,Evaluation Methods,Foreign Countries,Higher Education,No DOI found,Pandemics,Prevention,South Africa,Teaching Methods}
}

@article{baderStudentsPerceptionsUse2021,
  title = {Students' Perceptions and Use of a New Digital Tool in Teacher Education},
  author = {Bader, M and Iversen, {\relax SH} and Burner, T},
  year = {2021},
  journal = {Nordic Journal Of Digital Literacy},
  volume = {16},
  number = {1},
  pages = {21--33},
  issn = {0809-6724},
  doi = {10.18261/issn.1891-943x-2021-01-03},
  abstract = {This article investigates how student teachers of English at two different teacher education institutions perceive and use a new digital tool, OneNote Class Notebook. The intervention study explores student responses to and use of a specific digital tool implemented for a specific pedagogical purpose, namely to enhance formative assessment. The data consist of 128 reflection notes written by 40 student teachers during a semester and a focus group interview with three of the students. The results show that the students' attitudes towards the new tool varied considerably. Both the attitudes and the reported use were overwhelmingly related to the perceived ease of use, rather than the learning-related potential of digital technology. On the other hand, the interview data show that at least some students are aware of the affordances provided by the digital tool for enhancing formative assessment. The article highlights that the transformational potential of digital artifacts rests on teachers and learners alike. The students need to be made aware of the pedagogical, and not just the practical, aspects of digital technology, and be willing to exploit it. The article concludes that more fundamental changes in students' working habits and their expectations of higher education may be required to truly harness the transformational power of digital technology.},
  langid = {english},
  keywords = {COMPETENCE,digital tools,FORMATIVE ASSESSMENT,higher education,student perceptions,teacher education},
  file = {/Users/colin.madland/Zotero/storage/6J5UNBIG/baderStudentsPerceptionsUse2021.pdf}
}

@article{badkeAIChallengesInformation2023,
  title = {{{AI Challenges}} to {{Information Literacy}}.},
  author = {Badke, William},
  year = {2023},
  month = apr,
  journal = {Computers in Libraries},
  volume = {43},
  number = {3},
  pages = {41--42},
  publisher = {Information Today Inc.},
  address = {Medford, New Jersey},
  issn = {1041-7915},
  abstract = {The article offers information about the implications of artificial intelligence generated content, specifically ChatGPT, from an information literacy perspective. It emphasizes the need for educators to acknowledge and address the existence of AI-generated content as it becomes increasingly accessible to students.},
  keywords = {Access to Information,Artificial Intelligence,Information Literacy,Information Resources,Neural Networks (Computer),No DOI found},
  file = {/Users/colin.madland/Zotero/storage/ACWPZKWX/badkeAIChallengesInformation2023.pdf}
}

@article{baggaleyFogOnlineLearning2016,
  title = {The Fog of Online Learning},
  author = {Baggaley, Jon and James, Sheila},
  year = {2016},
  month = jan,
  journal = {Distance Education},
  volume = {37},
  number = {1},
  pages = {121--129},
  issn = {0158-7919, 1475-0198},
  doi = {10.1080/01587919.2016.1153962},
  urldate = {2023-01-15},
  langid = {english}
}

@article{bagunaidAISARArtificialIntelligenceBased2022,
  title = {{{AISAR}}: {{Artificial Intelligence-Based Student Assessment}} and {{Recommendation System}} for {{E-Learning}} in {{Big Data}}},
  shorttitle = {{{AISAR}}},
  author = {Bagunaid, Wala and Chilamkurti, Naveen and Veeraraghavan, Prakash},
  year = {2022},
  month = aug,
  journal = {Sustainability},
  volume = {14},
  number = {17},
  pages = {10551},
  issn = {2071-1050},
  doi = {10.3390/su141710551},
  urldate = {2023-01-15},
  abstract = {Educational systems have advanced with the use of electronic learning (e-learning), which is a promising solution for long-distance learners. Students who engage in e-learning can access tests and exams online, making education more flexible and accessible. This work reports on the design of an e-learning system that makes recommendations to students to improve their learning. This artificial intelligence-based student assessment and recommendation (AISAR) system consists of score estimation, clustering, performance prediction, and recommendation. In addition, the importance of student authentication is recognised in situations in which students must authenticate themselves prior to using the e-learning system using their identity, password, and personal identification number. Individual scores are determined using a recurrent neural network (RNN) based on student engagement and examination scores. Then, a density-based spatial clustering algorithm (DBSCAN) using Mahalanobis distance clustering is implemented to group students based on their obtained score values. The constructed clusters are validated by estimating purity and entropy. Student performance is predicted using a threshold-based MapReduce (TMR) procedure from the score-based cluster. When predicting student performance, students are classified into two groups: average and poor, with the former being divided into below- and above-average students and the latter into poor and very poor students. This categorisation aims to provide useful recommendations for learning. A recommendation reinforcement learning algorithm, the rule-based state--action--reward--state--action (R-SARSA) algorithm, is incorporated for evaluation. Students were required to work on their subjects according to the provided recommendations. This e-learning recommendation system achieves better performance in terms of true-positives, false-positives, true-negatives, false-negatives, precision, recall, and accuracy.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/XSL38LLT/bagunaidAISARArtificialIntelligenceBased2022.pdf}
}

@book{bainSuperCourses2021,
  title = {Super {{Courses}}},
  author = {Bain, Ken},
  year = {2021},
  series = {The {{Future}} of {{Teaching}} and {{Learning}}},
  publisher = {Princeton University Press},
  doi = {10.1515/9780691216591},
  urldate = {2022-09-30},
  isbn = {978-0-691-21659-1},
  file = {/Users/colin.madland/Zotero/storage/B4RQ8CM2/bainSuperCourses2021.pdf}
}

@article{bairdAssessmentLearningFields2017,
  title = {Assessment and Learning: Fields Apart?},
  shorttitle = {Assessment and Learning},
  author = {Baird, Jo-Anne and Andrich, David and Hopfenbeck, Therese N. and Stobart, Gordon},
  year = {2017},
  month = jul,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {24},
  number = {3},
  pages = {317--350},
  issn = {0969-594X, 1465-329X},
  doi = {10/gf3brt},
  urldate = {2021-01-27},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/X6AMSHCA/bairdAssessmentLearningFields2017.pdf}
}

@techreport{bairdAssessmentLearningState2011,
  title = {Assessment and {{Learning}}: {{State}} of the {{Field Review}}},
  author = {Baird, Jo-Anne and Hopfenbeck, Therese N. and Newton, Paul and Stobart,, Gordon and {Steen-Utheim}, Anna T},
  year = {2011},
  number = {13/4697},
  pages = {174},
  institution = {Norwegian Knowledge Centre for Education},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/AQR8RURX/bairdAssessmentLearningState2011.pdf}
}

@incollection{bakerEducationalDataMining2016,
  title = {Educational Data Mining and Learning Analytics},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {Baker, Ryan S. and Martin, Taylor and Rossi, Lisa M.},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch16},
  pages = {379--396},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch16},
  abstract = {Summary In recent years, there has been increasing interest in using the methods of educational data mining (EDM) and learning analytics (LA) to study and measure learner cognition. In this chapter, we discuss how these types of methods can be used to measure complex cognition and meta-cognition in types of environments where inference can be challenging: exploratory and inquiry learning environments, complex games, and project-based learning. We give examples from a range of projects for the types of constructs that can be inferred using EDM/LA methods and how these measures compare to what can be obtained from more traditional methods. We conclude with a discussion of future discussion and potentials for these kinds of methods.},
  chapter = {16},
  isbn = {978-1-118-95658-8},
  keywords = {complex games,educational data mining,educational measurement,exploratory learning environments,inquiry learning environments,learning analytics}
}

@article{balasubramanianAssessmentModeImplementing2020,
  title = {Assessment {\`a} La {{Mode}}: {{Implementing}} an {{Adaptable Large-Scale Multivariant Online Deferred-Grade Exam}} for {{Virtual Learning}}},
  author = {Balasubramanian, Bhavani and DeSantis, Chris and Gulotta, Miriam},
  year = {2020},
  journal = {Journal of chemical education},
  volume = {97},
  number = {12},
  pages = {4297--4302},
  publisher = {{American Chemical Society and Division of Chemical Education, Inc}},
  address = {WASHINGTON},
  issn = {0021-9584},
  doi = {10.1021/acs.jchemed.0c00767},
  abstract = {The COVID pandemic forced many higher education institutions to pivot and switch to an online learning environment with minimal preparation. This transition was put in place during the middle of the spring semester, in March. During this transition, instructors had to quickly learn the tools of online teaching, navigate platforms like Webex and Zoom, and adapt their lectures to an online format. One of the biggest challenges during this transition was to administer common online exams to high enrollment undergraduate classes, such as general chemistry and organic chemistry, without compromising the integrity of the exam. The in-person chemistry common exam that is normally administered to students at New Jersey Institute of Technology (NJIT) had both multiple-choice and open-ended questions. In order to replicate this online, and to reduce the potential temptation to cheat, a robust multiple-choice and open-ended exam with multiple versions was required. Furthermore, this online exam had to be easily administered through our learning management system. What was developed included a blueprint for an online exam intended for large-scale distribution over multiple days with safeguards in place to protect the integrity of the examination. The exam employed deferred grading, a lockdown browser, multiple question variants, time controls, and controlled access to the completed exam to combat potential cheating. The exam resulted in average scores that were comparable to in-person exam scores from previous semesters, validating the proposed approach. In addition, polling results after administration of the exam showed strong student satisfaction with exam design and directions and student preference for webcam proctored exams.},
  keywords = {Access control,CAI,Chemistry,Chemistry Multidisciplinary,College Faculty,College students,Computer assisted instruction,Computer Assisted Testing,COVID-19,Education & Educational Research,Education Scientific Disciplines,Educational Technology,Electronic Learning,Higher Education,Higher education institutions,Integrated Learning Systems,Integrity,Learning environment,Multiple Choice Tests,Online Courses,Online instruction,Organic chemistry,Pandemics,Physical Sciences,Questions,Science & Technology,Science Instruction,Scores,Social Sciences,Student Evaluation,Teachers,Teaching methods,Undergraduate Students,Webcams},
  file = {/Users/colin.madland/Zotero/storage/IQ99IVQD/balasubramanianAssessmentModeImplementing2020.pdf}
}

@article{baldwinEvaluationInstrumentsGood2017,
  title = {Evaluation {{Instruments}} and {{Good Practices}} in {{Online Education}}},
  author = {Baldwin, Sally J. and Trespalacios, Jes{\'u}s},
  year = {2017},
  journal = {Online Learning},
  volume = {21},
  number = {2},
  issn = {ISSN-2472-5749},
  doi = {10/gmbv3s},
  abstract = {Chickering and Gamson's (1987) "Seven Principles for Good Practice in Undergraduate Education" offers extensively researched and validated tenets for best practices in higher education. After a review of the literature, twenty-eight evaluation instruments currently used to design and review online courses in higher education institutions were collected and divided into categories, based on geographical reach and the type of institution for which they were developed. This study investigates how evaluation instruments used in higher education assess the "Seven Principles for Good Practice in Undergraduate Education," and what other items are addressed in the evaluation of courses. Findings show that national and statewide evaluation instruments were less institute specific and more closely aligned to the principles of good practice, and that evaluation instruments often measure extraneous items (e.g., student services, navigation, resources, or institutional support). Additional findings and conclusions based on the analysis of the instruments are discussed.},
  langid = {english},
  keywords = {Best Practices,Cluster Grouping,Educational Principles,Evaluation Criteria,Evaluation Methods,Institutional Characteristics,Literature Reviews,Online Courses,Professional Development,Scoring Rubrics,Undergraduate Study}
}

@article{baleniOnlineFormativeAssessment2015,
  title = {Online Formative Assessment in Higher Education: {{Its}} Pros and Cons},
  author = {Baleni, Zwelijongile Gaylard},
  year = {2015},
  volume = {13},
  number = {4},
  pages = {9},
  abstract = {Online and blended learning have become common educational strategy in higher education. Lecturers have to re-theorise certain basic concerns of teaching, learning and assessment in non-traditional environments. These concerns include perceptions such as cogency and trustworthiness of assessment in online environments in relation to serving the intended purposes, as well as understanding how formative assessment operates within online learning environment. Of importance also is the issue of how formative assessment benefits both the student learning and teaching within pedagogical strategies in an online context. This paper's concern is how online formative assessment provides teaching and learning as well as how lecturers and students benefit from it. A mixed method questionnaire on formative assessment with a main focus on how formative assessment within online contexts operates was used to collect data from courses using Blackboard. Lecturers and students at a comprehensive university were the population. Various techniques for formative assessment linked with online tools such as discussion forums and objective tests were used. The benefits that were famous comprise improvement of student commitment, faster feedback, enhanced flexibility around time and place of taking the assessment task and importance in the procedure for students and lecturers also benefited with less marking time and saved on administrative costs. The crucial findings are that effective online formative assessment can nurture a student and assessment centred focus through formative feedback and enrich student commitment with valued learning experiences. Ongoing trustworthy assessment tasks and interactive formative feedback were identified as significant features that will deal with intimidations to rationality and trustworthiness within the milieu of online formative assessment.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/URRJID6Y/baleniOnlineFormativeAssessment2015.pdf}
}

@article{ballysinghTeachingAssessmentPreparing2018,
  title = {Teaching {{Assessment}}: {{Preparing}} Our {{Colleagues Through Graduate Education}}},
  author = {Ballysingh, Tracy Ar{\'a}mbula and Hern{\'a}ndez, Ignacio and Zerquera, Desiree},
  year = {2018},
  journal = {New Directions for Institutional Research},
  volume = {2018},
  number = {177},
  pages = {87--104},
  publisher = {Wiley Periodicals, Inc},
  address = {Tallahassee},
  issn = {0271-0579},
  doi = {10.1002/ir.20258},
  abstract = {Byline: Desiree Zerquera, Ignacio Hernandez, Juan G. Berumen, Tracy Arambula Ballysingh, Ignacio Hernandez, Desiree Zerquera This chapter provides a framework for grounding social justice principles at the center of learning in higher education program assessment and evaluation courses. Pedagogical reflections are drawn from the classroom experiences of three faculty of color who represent diverse institutional, programmatic, and geographic contexts. Their advanced framework incorporates theories of experiential learning, critical pedagogy, and problems of practice. It further explains how these notions might converge to foster a social justice-centered approach to graduate instruction of assessment and evaluation for higher education and student affairs. The authors incorporate excerpts from course syllabi and lesson plans to demonstrate how this framework better integrates social justice principles with the practice of assessment; two concepts commonly treated as separate pedagogical entities. This chapter will inform faculty in higher education and student affairs graduate programs, institutional researchers, and practitioners committed to advancing assessment practices that embrace social justice as a core value in higher education. Biographical information: Tracy Arambula Ballysingh, Ph.D. is an assistant professor in the Department of Leadership and Developmental Sciences at the University of Vermont. Ignacio Hernandez, Ph.D. is an associate professor in the Department of Educational Leadership and Program Director of the doctoral program in Educational Leadership at California State University, Fresno. Desiree Zerquera, Ph.D. is an assistant professor in the Department of Leadership Studies at the University of San Francisco.;This chapter provides a framework for grounding social justice principles at the center of learning in higher education program assessment and evaluation courses. Pedagogical reflections are drawn from the classroom experiences of three faculty of color who represent diverse institutional, programmatic, and geographic contexts. Their advanced framework incorporates theories of experiential learning, critical pedagogy, and problems of practice. It further explains how these notions might converge to foster a social justice-centered approach to graduate instruction of assessment and evaluation for higher education and student affairs. The authors incorporate excerpts from course syllabi and lesson plans to demonstrate how this framework better integrates social justice principles with the practice of assessment; two concepts commonly treated as separate pedagogical entities. This chapter will inform faculty in higher education and student affairs graduate programs, institutional researchers, and practitioners committed to advancing assessment practices that embrace social justice as a core value in higher education.;},
  langid = {english},
  keywords = {College Faculty,College teachers,Critical Thinking,Education,Evaluation Methods,Experiential Learning,Graduate Study,Higher Education,Minority Group Teachers,Pedagogy,Program Evaluation,Social Justice,Student Personnel Services,Teaching,Teaching Methods}
}

@article{balwantAlternativesConventionalOxford2021,
  ids = {balwantAlternativesConventionalOxford2021a},
  title = {Alternatives to the Conventional `{{Oxford}}' Tutorial Model: A Scoping Review},
  author = {Balwant, Paul Tristen and Doon, Roshnie},
  year = {2021},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {18},
  number = {1},
  pages = {1--24},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-021-00265-y},
  abstract = {In higher education, one commonly used teaching approach that is intended to develop deep learning is that of the `Oxford' tutorial---a personalized Socratic approach in which an instructor discusses course-related issues with a handful of students. Even though this conventional tutorial model is well supported in the literature, it may be neglected by research-driven academics and is expensive to operate. The latter issue has placed tutorials in the spotlight because higher education institutions are facing huge funding cuts worldwide. In light of these problems, a scoping review was conducted to explore financially viable alternatives to the Oxford tutorial for management education. Articles in highly ranked management education and development academic journals were collected by searching these catalogs and compiling a database of 48 articles published in four premier journals. These articles were reviewed by two independent raters in order to arrive at 8 alternatives to the Oxford tutorial model that can achieve similar objectives of said tutorials while reducing costs. These alternative tutorial models all involve the application of information communication technologies to tutorials and include peer instruction, simulations and games, online collaborative learning, syndicates, flipped classrooms, communication systems, tailored learning, and portfolios. Challenges and implementation guidelines are explained for each alternative tutorial model.},
  keywords = {Business Administration Education,Communications systems,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Cooperative Learning,Deep learning,Educational Technology,Electronic Learning,Flipped Classroom,Games,Higher Education,Higher education institutions,Humanities,Individualized Instruction,Information Systems Applications (incl.Internet),Information Technology,Law,Learning,Nontraditional Education,Pedagogy,Peer Teaching,Portfolios (Background Materials),Program Implementation,Questioning Techniques,Review Article,Scoping review,Simulation,Statistics for Social Sciences,Teaching,Teaching Methods,Tutorial,Tutorial Programs,Tutoring,Tutors},
  file = {/Users/colin.madland/Zotero/storage/QHJYWPBB/balwantAlternativesConventionalOxford2021.pdf}
}

@article{banathyDevelopingSystemsView1995,
  title = {Developing a {{Systems View}} of {{Education}}},
  author = {Banathy, Bela H},
  year = {1995},
  journal = {Educational Technology},
  number = {June},
  pages = {5},
  annotation = {MDDE603 Course Readings}
}

@incollection{banathySystemsInquiryIts1996,
  title = {Systems Inquiry and Its Application in Education},
  booktitle = {Handbook of Research for Educational Communications and Technology},
  author = {Banathy, Bela H and Jenlink, Patrick M},
  editor = {Jonassen, D. H.},
  year = {1996},
  pages = {37--57},
  publisher = {{Simon and Schuster}},
  annotation = {MDDE603 Course Readings}
}

@incollection{bandalosFactorAnalysisExploratory2019,
  title = {Factor {{Analysis}}: {{Exploratory}} and {{Confirmatory}}},
  booktitle = {The Reviewer's Guide to Quantitative Methods in the Social Sciences},
  author = {Bandalos, Deborah L. and Finney, Sara J.},
  editor = {Hancock, Gregory R. and Stapleton, Laura M. and Mueller, Ralph O.},
  year = {2019},
  edition = {Second Edition},
  publisher = {Routledge, Taylor \& Francis Group},
  address = {New York},
  abstract = {8Factor AnalysisExploratory and ConfirmatoryDeborah L. Bandalos and Sara J. FinneyFactor  analysis  is  a  method  of  modeling  the  covariation  among  a  set  of  observed  variables  as  a  function of one or more latent constructs. Here, we use the term construct to refer to an unobservable but  theoretically  defensible  entity,  such  as  intelligence,  self-efficacy,  or  creativity.  Such  constructs  are typically considered to be latent in the sense that they are not directly observable (see Bollen, 2002, for a more detailed discussion of latent constructs). The purpose of factor analysis is to assist researchers in identifying and/or understanding the nature of the latent constructs underlying the variables of interest. Technically, these descriptions exclude component analysis, which is a method for reducing the dimensionality of a set of observed variables through the creation of an optimum number of weighted composites. A major difference between factor and component analysis is that in the latter all of the variance is analyzed, whereas in factor analysis, only the shared (common) var-iance is analyzed. For this reason, factor analysis is sometimes referred to as common factor analysis. In many ways, however, component analysis is very similar to common factor analysis, and many of the desiderata for exploratory factor analysis presented here apply equally to component analy-sis. Given that the goal of component analysis is to explain as much observed variance as possible via the weighted composites and not, as in common factor analysis, to model the relations among variables as functions of underlying latent variables, those desiderata relating to the importance of theory for factor analysis do not necessarily apply to component analysis (see Widaman, 2007, for a detailed explanation of the conceptual and mathematical distinction between exploratory factor analysis and principal components analysis). This is because, although components may represent constructs, component analysis can still have utility as a data reduction method even if the compo-nents themselves are not interpreted. In such cases, the components do not provide an explanation for the variables' shared variance, but are instead used to represent that shared variance in the most parsimonious manner possible},
  isbn = {978-1-315-75564-9},
  lccn = {H62},
  keywords = {Research Methodology,Social sciences,Statistical methods},
  file = {/Users/colin.madland/Zotero/storage/XUHJEZF3/bandalosFactorAnalysisExploratory2019.pdf}
}

@article{banerjeeWhatLearningTools2021,
  title = {What {{Learning Tools Do Students Prefer}}? {{An Assessment}} of {{Undergraduate Business Courses}}},
  author = {Banerjee, Haimanti and Olson, Josephine E.},
  year = {2021},
  month = jan,
  journal = {Journal of Education for Business},
  volume = {96},
  number = {5},
  pages = {275--283},
  publisher = {Journal of Education for Business},
  issn = {0883-2323},
  doi = {10.1080/08832323.2020.1812490},
  abstract = {Universities strive to acquire resources to improve learning outcomes for students. This paper describes technology introduced in core undergraduate business classes and students' assessment of their value. Despite their widespread use, student enthusiasm for them was tepid. It also gauges student preferences for pedagogical methods and finds the preferred method was power point lectures, independent of the type of the course. Homework ranked second for quantitative classes, while in-class discussions ranked second for qualitative classes.},
  keywords = {Audience Response Systems,Business Administration Education,Classroom Communication,Core Curriculum,Course Evaluation,Homework,Integrated Learning Systems,Preferences,Student Attitudes,Teaching Methods,Technology Uses in Education,Undergraduate Students,Undergraduate Study,Visual Aids}
}

@article{baniasadiFairnessClassroomAssessment2023,
  title = {Fairness in {{Classroom Assessment}}: {{A Systematic Review}}},
  shorttitle = {Fairness in {{Classroom Assessment}}},
  author = {Baniasadi, Ali and Salehi, Keyvan and Khodaie, Ebrahim and Bagheri Noaparast, Khosrow and Izanloo, Balal},
  year = {2023},
  journal = {The Asia-Pacific Education Researcher},
  volume = {32},
  number = {1},
  pages = {91--109},
  issn = {0119-5646, 2243-7908},
  doi = {10.1007/s40299-021-00636-z},
  urldate = {2023-04-17},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/8LHEH4J7/s40299-021-00636-z (1).pdf}
}

@incollection{barabPracticeFieldsCommunities2000,
  title = {From {{Practice Fields}} to {{Communities}} of {{Practice}}},
  booktitle = {Theoretical Foundations of Learning Environments},
  author = {Barab, Sasha A and Duffy, Thomas M},
  editor = {Jonassen, David H. and Land, Susan M.},
  year = {2000},
  publisher = {Lawrence Erlbaum Associates},
  address = {Mahwah, New Jersey}
}

@article{barabPrinciplesSelfOrganizationLearning1999,
  title = {Principles of {{Self-Organization}}: {{Learning}} as {{Participation}} in {{Autocatakinetic Systems}}},
  shorttitle = {Principles of {{Self-Organization}}},
  author = {Barab, Sasha A. and {Cherkes-Julkowski}, Miriam and Swenson, Rod and Garrett, Steve and Shaw, Robert E. and Young, Michael},
  year = {1999},
  month = jul,
  journal = {Journal of the Learning Sciences},
  volume = {8},
  number = {3-4},
  pages = {349--390},
  issn = {1050-8406, 1532-7809},
  doi = {10.1080/10508406.1999.9672074},
  urldate = {2022-07-01},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/84S5445B/barabPrinciplesSelfOrganizationLearning1999.pdf}
}

@article{bardenWouldnBeAble2018,
  title = {"{{I}} Wouldn't Be Able to Graduate If It Wasn't for My Mobile Phone.' {{The}} Affordances of Mobile Devices in the Construction of Complex Academic Texts},
  author = {Barden, O and Bygroves, M},
  year = {2018},
  journal = {Innovations in Education and Teaching International},
  volume = {55},
  number = {5},
  pages = {521--531},
  issn = {1470-3297},
  doi = {10.1080/14703297.2017.1322996},
  abstract = {This is a case study of one student's mobile device use in HE. We draw on data generated by extended interviews to illustrate the learning practices and dispositions the student, now a co-author, evidenced with his smartphone and other devices whilst producing a third-year undergraduate assignment. We describe the process of assembling a complex academic text across multiple mobile internet-enabled devices. We aim to illuminate some contemporary mobile learning practices, and hence contribute to the discourse on pedagogy, assessment and mobile learning in HE. The paper is timely because although smartphones and internet access are near-ubiquitous in universities, there is relatively little extant research which reports in detail on the ways in which students actually use these technologies in their everyday learning and lives.},
  langid = {english},
  keywords = {assessment,learning,LITERACY,Mobility,smartphone,STUDENTS,technology,writing}
}

@incollection{barhamCreatingCultureAssessment2013,
  title = {Creating a {{Culture}} of {{Assessment}}},
  shorttitle = {Assessment in {{Practice}}},
  booktitle = {Assessment in {{Practice}}: {{A Companion Guide}} to the {{ASK Standards}}},
  author = {Barham, Jan Davis and Tschepikow, William Kyle and Seagraves, Beau},
  editor = {Timm, Dianne and Barham, Jan Davis and McKinney, Kristen and Knerr, Amanda},
  year = {2013},
  month = jan,
  abstract = {COLLEGES TODAY ARE ASKED TO PROVIDE GREATER PROOF that they are providing quality educational experiences to their students. There has been a growing need for student affairs to provide documentation that their areas also impact learning and student experience. However, many student affairs professionals are overwhelmed by the idea of assessment and are looking for examples of best practices in this area. Several years ago the American College Personnel Association's Commission Directorate for Assessment and Evaluation developed the Assessment Skills and Knowledge Standards for practitioners. This document provides examples of these standards in practice.},
  keywords = {No DOI found},
  annotation = {Chapter 8},
  file = {/Users/colin.madland/Zotero/storage/PFHIZXK3/barhamCreatingCultureAssessment2013.pdf;/Users/colin.madland/Zotero/storage/R7A6AHC3/33.html}
}

@book{barmanChildrenTeachersSchools2003,
  title = {Children, Teachers and Schools in the History of {{British Columbia}}},
  author = {Barman, Jean and Gleason, Mona},
  year = {2003},
  publisher = {Detselig Enterprises},
  address = {Calgary},
  abstract = {Grade level: 10, 11, 12, i, s, t.},
  isbn = {1-55059-251-3 978-1-55059-251-1},
  langid = {english}
}

@article{barnardMeasuringSelfregulationOnline2009,
  title = {Measuring Self-Regulation in Online and Blended Learning Environments},
  author = {Barnard, Lucy and Lan, William Y. and To, Yen M. and Paton, Valerie Osland and Lai, Shu-Ling},
  year = {2009},
  month = jan,
  journal = {The Internet and Higher Education},
  volume = {12},
  number = {1},
  pages = {1--6},
  issn = {1096-7516},
  doi = {10.1016/j.iheduc.2008.10.005},
  abstract = {In developing the Online Self-regulated Learning Questionnaire (OSLQ) to address the need for an instrument measuring self-regulation in the online learning environment, this study provides evidence toward the reliability and validity of the instrument. Data were collected from two samples of students. The first sample of students took coursework using an online course format while a second sample of students took coursework delivered via a blended or hybrid course format. Cronbach alpha ({$\alpha$}) and confirmatory factor analyses were performed to assess the psychometric properties of the OSLQ across both samples of students. Results indicate the OSLQ is an acceptable measure of self-regulation in the online and blended learning environments.},
  keywords = {Blended learning,Online learning,Self-regulation},
  file = {/Users/colin.madland/Zotero/storage/barnardMeasuringSelfregulationOnline2009.pdf}
}

@article{barnettUniversitiesEpistemologyDissolution2017,
  title = {Universities and {{Epistemology}}: {{From}} a {{Dissolution}} of {{Knowledge}} to the {{Emergence}} of a {{New Thinking}}},
  shorttitle = {Universities and {{Epistemology}}},
  author = {Barnett, Ronald and Bengtsen, S{\o}ren},
  year = {2017},
  month = mar,
  journal = {Education Sciences},
  volume = {7},
  number = {1},
  pages = {38},
  issn = {2227-7102},
  doi = {10.3390/educsci7010038},
  urldate = {2022-02-04},
  langid = {english},
  keywords = {archived},
  annotation = {https://web.archive.org/web/20180602025800/http://www.mdpi.com/2227-7102/7/1/38},
  file = {/Users/colin.madland/Zotero/storage/989LKGX6/barnettUniversitiesEpistemologyDissolution2017.pdf}
}

@book{barnettWillLearnBeing2007,
  ids = {barnettWillLearnBeing2007a,barnettWillLearnBeing2007b},
  title = {A {{Will}} to {{Learn}}: {{Being}} a {{Student}} in an {{Age}} of {{Uncertainty}}},
  author = {Barnett, Ronald},
  year = {2007},
  publisher = {McGraw-Hill Education},
  address = {Buckingham, UNITED KINGDOM},
  isbn = {978-0-335-23483-7},
  keywords = {Fiction.,Witches -- Fiction.},
  file = {/Users/colin.madland/Zotero/storage/4XWITK3U/barnettWillLearnBeing2007.pdf}
}

@article{barpiHackingHigherEducation2021,
  title = {Hacking {{Higher Education}}: {{Rethinking}} the {{EduHack Course}}},
  author = {Barpi, Fabrizio and Dalmazzo, Davide and De Blasio, Antonella and Vinci, Fiorella},
  year = {2021},
  journal = {Education Sciences},
  volume = {11},
  issn = {EISSN-2227-7102},
  doi = {10/gmbv3h},
  abstract = {The paper presents a report that discusses the experience of participation of the authors in the EduHack, an online course designed to train university teachers in the use of digital techniques and learning strategies. This study highlights two issues of great interest in pandemic times. The first one is the structure and the organization of the EduHack course with some suggestions related to its improvement; the second one is Drag\&Fly, the project idea of an e-learning web platform developed by the authors during the collaborative part of the course. The experience of participation to EduHack course has been analyzed by authors using concepts and categories of analysis widespread in the pragmatic theoretical tradition, enhancing the possibility of changing the teachers' approach to the design and the implementation of a higher education e-learning course.},
  keywords = {College Faculty,COVID-19,Distance Education,Educational Technology,Electronic Learning,Faculty Development,Foreign Countries,Higher Education,Learning Strategies,Online Courses,Pandemics,Training}
}

@article{barreiro-genEvaluatingEffectsMobile2020,
  title = {Evaluating the Effects of Mobile Applications on Course Assessment: {{A}} Quasi-Experiment on a Macroeconomics Course},
  author = {{Barreiro-Gen}, M},
  year = {2020},
  journal = {International Review of Economics Education},
  volume = {34},
  issn = {1477-3880},
  doi = {10.1016/j.iree.2020.100184},
  abstract = {Universities are facing the need to rethink their educational strategies, especially due to the emergence of new technologies, such as mobile applications, which have had great expectations. Previous studies have been focused on changes in student engagement from using mobile applications in the classroom, whereas there has been little research on the impact of mobile applications on student assessment. This research uses a quasi-experimental study to examine the relationship between student assessment and the use of a mobile application. Two groups of students (a control and an experimental group) were tested in the same academic semester with the same lecturer. Two analyses were carried out (t-test and difference-in-differences) to evaluate this relationship. Contrary to the general expectations, the results showed that there is no significant difference on assessment when comparing the two groups' scores. However, students showed a positive attitude in engaging with the mobile application. Although there has been an increase on the use of mobile applications in classrooms, they do not directly affect student scores. This research shows that mobile applications should be used as a complement to traditional education, and not as a substitute to it.},
  langid = {english},
  keywords = {Assessment,Course delivery,Higher education,Millennials,STUDENT,Student response systems,Teaching and learning,TECHNOLOGIES}
}

@article{barrettRejectingTestSurveillance2021,
  title = {Rejecting {{Test Surveillance}} in {{Higher Education}}},
  author = {Barrett, Lindsey},
  year = {2021},
  journal = {SSRN Electronic Journal},
  issn = {1556-5068},
  doi = {10.2139/ssrn.3871423},
  urldate = {2021-09-05},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/4YDSFZ5A/barrettRejectingTestSurveillance2021.pdf}
}

@article{barrettStructuralEquationModelling2007,
  title = {Structural Equation Modelling: {{Adjudging}} Model Fit},
  author = {Barrett, Paul},
  year = {2007},
  journal = {Personality and individual differences},
  volume = {42},
  number = {5},
  pages = {815--824},
  publisher = {Elsevier Ltd},
  issn = {0191-8869},
  doi = {10.1016/j.paid.2006.09.018},
  abstract = {For journal editors, reviewers, and readers of research articles, structural equation model (SEM) fit has recently become a confusing and contentious area of evaluative methodology. Proponents of two kinds of approaches to model fit can be identified: those who adhere strictly to the result from a null hypothesis significance test, and those who ignore this and instead index model fit as an approximation function. Both have principled reasons for their respective course of action. This paper argues that the chi-square exact-fit test is the only substantive test of fit for SEM, but, its sensitivity to discrepancies from expected values at increasing sample sizes can be highly problematic if those discrepancies are considered trivial from an explanatory-theory perspective. On the other hand, suitably scaled indices of approximate fit do not possess this sensitivity to sample size, but neither are they ``tests'' of model fit. The proposed solution to this dilemma is to consider the substantive ``consequences'' of accepting one explanatory model over another in terms of the predictive accuracy of theory-relevant-criteria. If there are none to be evaluated, then it is proposed that no scientifically worthwhile distinction between ``competing'' models can thus be made, which of course begs the question as to why such a SEM application was undertaken in the first place.},
  keywords = {Evaluation,Evaluative research,Model evaluation,Model fit,SEM,Structural equation modelling,Structural equation models},
  file = {/Users/colin.madland/Zotero/storage/84RXXQJC/barrettStructuralEquationModelling2007.pdf}
}

@article{bartlettTwoEyedSeeingOther2012,
  title = {Two-{{Eyed Seeing}} and Other Lessons Learned within a Co-Learning Journey of Bringing Together Indigenous and Mainstream Knowledges and Ways of Knowing},
  author = {Bartlett, Cheryl and Marshall, Murdena and Marshall, Albert},
  year = {2012},
  month = nov,
  journal = {Journal of Environmental Studies and Sciences},
  volume = {2},
  number = {4},
  pages = {331--340},
  issn = {2190-6491},
  doi = {10.1007/s13412-012-0086-8},
  abstract = {This is a process article for weaving indigenous and mainstream knowledges within science educational curricula and other science arenas, assuming participants include recognized holders of traditional ecological knowledge (we prefer ``Indigenous Knowledge'' or ``Traditional Knowledge'') and others with expertise in mainstream science. It is based on the ``Integrative Science'' undergraduate program created at Cape Breton University to bring together indigenous and mainstream sciences and ways of knowing, as well as related Integrative Science endeavors in science research, application, and outreach. A brief historical outline for that experiential journey is provided and eight ``Lessons Learned'' listed. The first, namely ``acknowledge that we need each other and must engage in a co-learning journey'' is explained as key for the success of weaving efforts. The second, namely ``be guided by Two-Eyed Seeing'', is considered the most profound because it is central to the whole of a co-learning journey and the article's discussion is focussed through it. The eighth lesson, ``develop an advisory council of willing, knowledgeable stakeholders'', is considered critical for sustaining success over the long-term given that institutional and community politics profoundly influence the resourcing and recruitment of any academic program and thus can help foster success, or sabotage it. The scope of relevance for Two-Eyed Seeing is broad and its uptake across Canada is sketched; the article also places it in the context of emerging theory for transdisciplinary research. The article concludes with thoughts on why ``Two-Eyed Seeing'' may seem to be desired or resisted as a label in different settings.Traditional Indian education is an expression of environmental education par excellence. It is an environmental education process that can have a profound meaning for the kind of modern education required to face the challenges of living in the world of the twenty-first century (Cajete (2010), p. 1128, emphasis as in original).As two-eyed seeing implies, people familiar with both knowledge systems can uniquely combine the two in various ways to meet a challenge or task at hand. In the context of environmental crises alone, a combination of both seems essential (Aikenhead and Michell (2011), p. 114).},
  keywords = {Cross-cultural education,Indigenous knowledge,Integrative Science,Traditional knowledge,Transdisciplinary,Two-eyed seeing},
  file = {/Users/colin.madland/Zotero/storage/F9ZSK7V5/bartlettTwoEyedSeeingOther2012.pdf}
}

@article{bartolomePersonalisationEducationalTechnology2018,
  title = {Personalisation in Educational Technology: The Absence of Underlying Pedagogies},
  author = {Bartolom{\'e}, Antonio and Casta{\~n}eda, Linda and Adell, Jordi},
  year = {2018},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {15},
  number = {1},
  pages = {1--17},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-018-0095-0},
  abstract = {Personalization is one of the recurring themes in education and has occupied a large amount of specialised literature, since its appearance in the 1960s. A systematic exploration of the literature of the last 55~years (1960--2015) is presented and is intended to analyse which educational perspective underlies the customized environments or experiences proposed in the educational technology that is addressed in the literature. It is important to understand that this analysis is a very relevant challenge, if we want to understand what pedagogical approaches have been continuously developed and how and why we should consider their future. The results show a complete centralisation of experiences in technological developments, the majority of them focussed in Higher Education, as well as a lack of an explicit pedagogical perspective in the experiences analysed, especially those with greater impact. It also shows a shortage of in-house pedagogical material -- developed in the light of this research, that evolves and makes an impact on the educational landscape.},
  keywords = {Active learning,Adaptive learning,Boolean,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Critical perspective,Education,Educational Technology,Empiricism,Higher Education,Humanities,Information Systems Applications (incl.Internet),Law,Literature review,Literature reviews,More than tools? Critical perspectives and alternative visions of technology in higher education,Pedagogy,Research Article,Statistics for Social Sciences},
  file = {/Users/colin.madland/Zotero/storage/QHQRHIT4/bartolomePersonalisationEducationalTechnology2018.pdf}
}

@book{bartolucciStatisticalAnalysisQuestionnaires2016,
  title = {Statistical Analysis of Questionnaires: A Unified Approach Based on {{R}} and {{Stata}}},
  shorttitle = {Statistical Analysis of Questionnaires},
  author = {Bartolucci, Francesco and Bacci, Silvia and Gnaldi, Michela},
  year = {2016},
  urldate = {2021-09-12},
  abstract = {'Statistical Analysis of Questionnaires: A Unified Approach Based on R and Stata' presents special statistical methods for analyzing data collected by questionnaires. The book takes an applied approach to testing and measurement tasks, mirroring the growing use of statistical methods and software in education, psychology, sociology, and other fields. It is suitable for graduate students in applied statistics and psychometrics and practitioners in education, health, and marketing. The book covers the foundations of classical test theory (CTT), test reliability, validity, and scaling as well as item response theory (IRT) fundamentals and IRT for dichotomous and polytomous items. The authors explore the latest IRT extensions, such as IRT models with covariates, multidimensional IRT models, IRT models for hierarchical and longitudinal data, and latent class IRT models. They also describe estimation methods and diagnostics, including graphical diagnostic tools, parametric and nonparametric tests, and differential item functioning. Stata and R software codes are included for each method. To enhance comprehension, the book employs real datasets in the examples and illustrates the software outputs in detail. The datasets are available on the authors' web page.--},
  isbn = {978-1-4665-6850-1 978-0-429-09525-2},
  langid = {english},
  annotation = {OCLC: 960706123},
  file = {/Users/colin.madland/Zotero/storage/BSGWSL46/bartolucciStatisticalAnalysisQuestionnaires2016.pdf}
}

@article{bartonInvestigatingAssessmentPractices2020,
  title = {Investigating the Assessment Practices within an {{Initial Teacher Education}} Program in an {{Australian}} University : {{Staff}} Perceptions and Practices},
  author = {Barton, Georgina and Baguley, Margaret and Kerby, Martin and MacDonald, Abbey},
  year = {2020},
  journal = {The Australian journal of teacher education},
  volume = {45},
  number = {3},
  pages = {34--47},
  publisher = {Edith Cowan Univ},
  address = {JOONDALUP},
  issn = {0313-5373},
  doi = {10.14221/ajte.2020v45n3.3},
  abstract = {Effective assessment design and subsequent assessment practices are essential for student success in the higher education sector. A plethora of research on assessment in higher education exists which tends to focus primarily on the student experience. This paper shares results from a 3 phased study that explored staff perceptions related to assessment practices in an undergraduate Initial Teacher Education program within an Australian metropolitan university. First, course learning objectives, activities and assessment items were mapped to identify the presence of constructive alignment. Second, staff were invited to complete a survey and a follow-up interview in relation to understanding of assessment knowledge and skills. Fink's Taxonomy of Significant Learning (2013) was used to analyse the qualitative data and findings suggest that staff are highly committed to quality assessment practices but often work in silos rather than teams. Additionally, a lack of professional development and learning was available at the school level, particularly for casual staff. Further research about assessment practices in higher education in relation to staff rather than student experience is warranted. [Author abstract]},
  keywords = {Academic staff attitudes,Classification,Constructive alignment,Education & Educational Research,Education Higher,Educational evaluation,Evaluation,Evaluation methods,Higher education,Methodology,Preservice teacher education,Professional development,Qualitative research,Secondary education,Social Sciences,Student assessment,Student teaching,Teachers,Training of},
  file = {/Users/colin.madland/Zotero/storage/M7U93ZRK/bartonInvestigatingAssessmentPractices2020.pdf}
}

@article{baseraLearnersPerceptionsAssessment2019,
  title = {Learners' {{Perceptions}} of {{Assessment Strategies}} in {{Higher Education}}},
  author = {Basera, Clay Hutama},
  year = {2019},
  journal = {Journal of Education and e-Learning Research},
  volume = {6},
  number = {2},
  pages = {76--81},
  issn = {ISSN-2518-0169},
  doi = {10/gmbvzq},
  abstract = {The study sought to establish learner perceptions about assessment strategies in higher education. This was against the backdrop of an emerging trend in the field of assessment that has resulted in different perceptions of learners with respect of their effectiveness in higher education learning. The study in particular endeavored to determine the perceptions of learners in relation to formative and summative assessment, as predominantly adopted assessment strategies in higher education. Forty six learners doing research methods were conveniently chosen to represent the target population and were served with self-administered questionnaires. The instrument used enabled the researcher to obtain quality data as respondents were given ample time to complete the questionnaire with limited pressure. The results were indicative of the fact that learners perceived formative assessment as a critical ingredient for effective learning in higher education. Formative assessment methods such as group presentations and other forms of collaborative learning were also perceived to be critical in higher education learning. Respondents also indicated that they perceived summative assessment as playing an augmenting role. Thus the two assessment approaches are perceived to be strategically important in enhancing effective learning in higher education.},
  langid = {english},
  keywords = {Educational Strategies,Evaluation Methods,Foreign Countries,Formative Evaluation,Higher Education,Outcomes of Education,Student Attitudes,Summative Evaluation}
}

@article{basilotta-gomez-pablosTeachersDigitalCompetencies2022,
  title = {Teachers' Digital Competencies in Higher Education: A Systematic Literature Review},
  author = {{Basilotta-G{\'o}mez-Pablos}, Ver{\'o}nica and Matarranz, Mar{\'i}a and {Casado-Aranda}, Luis-Alberto and Otto, Ana},
  year = {2022},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {19},
  number = {1},
  pages = {1--16},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-021-00312-8},
  abstract = {Digital competence has gained a strong prominence in the educational context, being one of the key competencies that teachers must master in today's society. Although most models and frameworks focus on the pre-university level, there is a growing interest in knowing the state of digital competencies of university teachers, that is, the set of knowledge, skills and attitudes necessary for a teacher to make effective use of technologies. The aim of this research is to present a systematic review of the literature in the Web of Science and Scopus, to identify, analyze and classify the published articles between 2000 and 2021 on digital competences, and thus find and improve the research being done on digital skills and future avenues of teachers in the university context. The SciMAT software is used in the analysis. The initial search reveals more than 343 articles in English, of which 152 are duplicates and 135 are not related to the topic of study. After this filtering, 56 articles are obtained and analyzed in depth. The results reveal a predominance of research that focuses on analyzing teachers' self-assessment and reflection of their digital competencies. Teachers recognize that they have a low or medium--low digital competence, as well as the absence of certain competencies, especially those related to the evaluation of educational practice. Despite the multiple studies that address this issue, it is necessary to continue improving research in this area, deepening the assessment of teachers' digital competencies and design, on this basis, more practical and personalized training programs that respond to the needs of teachers in the digital era.},
  keywords = {Bibliometric indicators,Bibliometrics,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Context,Core competencies,Digital competence,Digital literacy,Digitally Competent Future Teachers,Education,Educational Technology,Higher Education,Humanities,Information Systems Applications (incl.Internet),Law,Literature reviews,Review Article,Skills,Statistics for Social Sciences,Teacher professional competence,Teachers,University education},
  file = {/Users/colin.madland/Zotero/storage/BZJLRTYN/basilotta-gomez-pablosTeachersDigitalCompetencies2022.pdf}
}

@article{basoReducingCheatingOnline2023,
  title = {Reducing {{Cheating}} in {{Online Exams Through}} the {{Proctor Test Model}}},
  author = {Baso, Yusring Sanusi and Murtadho, Nurul and {-}, Syihabuddin and Maulani, Hikmah and Agussalim, Andi and {-}, Haeruddin and Fadlan, Ahmad and Ramadhan, Ilham},
  year = {2023},
  journal = {International journal of advanced computer science \& applications},
  volume = {14},
  number = {1},
  publisher = {{Science and Information (SAI) Organization Limited}},
  address = {West Yorkshire},
  issn = {2158-107X},
  doi = {10.14569/IJACSA.2023.0140139},
  abstract = {The World Health Organization (WHO) officially declared coronavirus (COVID-19) a pandemic on March 11, 2020. Educational institutions must change most face-to-face learning activities in class to online. This situation forces academic institutions to change the format of assessing student learning outcomes. Online exam surveillance applications utilizing cameras and other blocking browsers (proctors) are becoming popular. However, the appearance of the proctor model supervised exam system also raises controversy. The main discussion regarding this proctor system is the integrity of assessment and the capacity of students to adapt to this new method of supervision. The main question is whether students feel comfortable using the proctor system in exams and whether this system affects students' scores. To answer this question, we have analyzed the scores obtained from a trial of 152 scores of students learning Arabic at Hasanuddin University Makassar, Indonesia. The experiment involved three exam models: online format from home using the Sikola Learning Management System (Modality 1), online directly using the Proctor System in the Sikola Learning Management System (Modality 2), and a paper exam format in person under the supervision of a lecturer (Modality 3). The results show that students prefer Modality 1 (online at home with the Sikola LMS system). There is a statistical difference between the scores obtained by students from the three modalities analyzed. Student scores with modality 1 are higher than the other two modalities. On the other hand, there was no difference in scores between modalities 2 and 3. The online exam system (modality 2) can be applied to online exams in higher education institutions because it can reduce or even keep students from cheating.},
  keywords = {Colleges & universities,Coronaviruses,Format,Higher education institutions,Learning,Learning management systems,Questions,Students},
  file = {/Users/colin.madland/Zotero/storage/QWTC7EDN/basoReducingCheatingOnline2023.pdf}
}

@incollection{batesFrameworkSelectingUsing2003,
  title = {A Framework for Selecting and Using Technology},
  booktitle = {Effective Teaching with Technology in Higher Education},
  author = {Bates, A and Poole, G},
  year = {2003},
  pages = {75--105},
  publisher = {Jossey Bass},
  address = {San Francisco}
}

@book{batesTeachingDigitalAge2015,
  title = {Teaching in a Digital Age},
  author = {Bates, A. W},
  year = {2015},
  publisher = {BCcampus, BC Open Textbook Project},
  address = {Victoria},
  urldate = {2019-04-16},
  abstract = {"The book examines the underlying principles that guide effective teaching in an age when everyone, and in particular the students we are teaching, are using technology. A framework for making decisions about your teaching is provided, while understanding that every subject is different, and every instructor has something unique and special to bring to their teaching. The book enables teachers and instructors to help students develop the knowledge and skills they will need in a digital age: not so much the IT skills, but the thinking and attitudes to learning that will bring them success."--BC Campus website.},
  isbn = {978-0-9952692-0-0},
  langid = {english},
  annotation = {OCLC: 926273797}
}

@book{batesTeachingDigitalAge2019,
  title = {Teaching in a {{Digital Age}} -- {{Second Edition}}},
  author = {Bates, A. W.},
  year = {2019},
  publisher = {Tony Bates Associates Ltd.},
  address = {Vancouver, BC}
}

@article{battisteDecolonizingEducationCanadian2002,
  title = {Decolonizing {{Education}} in {{Canadian Universities}}: {{An Interdisciplinary}}, {{International}}, {{Indigenous Research Project}}},
  author = {Battiste, Marie and Bell, Lynne and Findlay, L. M.},
  year = {2002},
  journal = {Canadian Journal of Native Education},
  volume = {26},
  number = {2},
  pages = {82},
  issn = {0710-1481},
  abstract = {Despite several decades of work on educational equity in curriculum and research and bridging and access projects, Aboriginal peoples' achievements, knowledge, histories, and perspectives remain too often ignored, rejected, suppressed, marginalized, or underutilized in universities across Canada and beyond. Although promising to make postsecondary education accessible to Aboriginal peoples, universities express an Aboriginal agenda in mission statements, priorities, and projects that reaffirm Eurocentric and colonial encounters in the name of excellence, integration, and modernity. Addressing these challenges is the purpose of a research project undertaken by a team of investigators at the University of Saskatchewan, building on the theoretical foundations of postcolonial Indigenous consciousness emerging from Canadian Aboriginal scholars and from Aotearoa (New Zealand) in the scholarly work of Graham and Linda Smith. This article offers a process of animating postsecondary education that can generate methods and practices for the more thorough decolonization of research and policy development and the experience of Aboriginal students and teachers.;Aboriginal peoples' achievements, knowledge, histories, and perspectives are often ignored or marginalized in universities across Canada and beyond. An interdisciplinary Indigenous research project aims to address the deficit in public understanding and animate a truly postcolonial university, focusing on Elders' guidance, research ethics, educational materials, legitimacy of Indigenous knowledge, hiring of Indigenous faculty, networking, and the Indigenous renaissance in the visual arts. (Contains 40 references.) (SV);},
  keywords = {American Indian Education,Canada,Canada Natives,College Environment,Colleges & universities,Cultural Awareness,Curriculum development,Education,Educational change,Educational Needs,Equal Education,Eurocentrism,Foreign Countries,Higher Education,Indigenous Knowledge,Indigenous people,Interdisciplinary Approach,Native education,Postcolonialism,Research Projects,Universities,University level}
}

@book{battisteDecolonizingEducationNourishing2013,
  title = {Decolonizing Education: Nourishing the Learning Spirit},
  author = {Battiste, Marie Ann},
  year = {2013},
  publisher = {Purich Publishing Limited},
  address = {Saskatoon, SK, Canada},
  isbn = {978-1-895830-77-4 1-895830-77-X},
  lccn = {E96.2 .B355 2013},
  keywords = {Canad,Canada,Education,Education Government policy,Government policy,Indians of North America,Intellectual lif,Intellectual life,Native peoples},
  annotation = {OCLC: 856977069}
}

@techreport{battisteIndigenousKnowledgePedagogy2002,
  type = {Literature {{Review}}},
  title = {Indigenous Knowledge and Pedagogy in {{First Nations}} Education: {{A}} Literature Review with Recommendations.},
  author = {Battiste, Marie},
  year = {2002},
  pages = {1--69},
  address = {Ottawa, ON},
  institution = {{Indian and Northern Affairs Canada}},
  urldate = {2019-03-30}
}

@article{baumanConceptMapsActive2018,
  title = {Concept {{Maps}}: {{Active Learning Assessment Tool}} in a {{Strategic Management Capstone Class}}},
  author = {Bauman, Antonina},
  year = {2018},
  month = oct,
  journal = {College Teaching},
  volume = {66},
  number = {4},
  pages = {213--221},
  publisher = {Routledge},
  issn = {8756-7555},
  doi = {10.1080/87567555.2018.1501656},
  abstract = {AbstractTeaching a business program capstone class presents a double challenge, requiring the educator to integrate different functional areas of business and evaluate student learning. This paper discusses concept maps as an active learning assessment tool in teaching a strategic management capstone course. Concept maps are used to meaningfully depict knowledge and present illustrations of relationships between concepts in a particular course. This study reviews 54 individual and 19 group concept maps collected over three semesters. The analysis affirms that concept maps are a powerful pedagogical tool that requires students to reflect on the knowledge gained during a course.}
}

@article{baumeWhatHappeningWhen2004,
  title = {What Is Happening When We Assess, and How Can We Use Our Understanding of This to Improve Assessment?},
  author = {Baume, David and Yorke *, Mantz and Coffey, Martin},
  year = {2004},
  month = aug,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {29},
  number = {4},
  pages = {451--477},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602930310001689037},
  urldate = {2022-06-01},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/47WLL527/baumeWhatHappeningWhen2004.pdf}
}

@article{bayhanTechnologicalInnovationArchitecture2020,
  title = {Technological Innovation in Architecture and Engineering Education - an Investigation on Three Generations from {{Turkey}}},
  author = {Bayhan, Hasan Gokberk and Karaca, Ece},
  year = {2020},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {17},
  number = {1},
  pages = {1--22},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-020-00207-0},
  abstract = {The developments in technology have caused many radical changes in the curriculum of architecture and engineering (a/e) disciplines. At the same time, generations and their personal characteristics are in continuous change that is shaping newer education techniques. In this context, this study is aimed to compare the educational perceptions of generations X, Y and Z for the advancements in the curriculum. For this purpose, a literature review concerning the technological advancements in education and characteristics of X, Y, and Z generations are demonstrated. Then, a survey was conducted on 160 respondents to differ the perceptions between these generations while considering the respondents' educational and social-related features. Results of this study support that Information Technology (IT)-related education is insufficient for the upcoming generations who were born and grew in the digital age. Generation Y is the least satisfied with IT-related lectures and more affected by the movement of sustainability. The perceptions between the generations are found statistically different and solutions are offered for the upcoming generations. The outcomes of this study are expected to guide professionals in a/e education to better fulfill the expectations of the upcoming generations.},
  keywords = {Architecture,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Curricula,Distance learning,Education,Educational Technology,Engineering,Engineering education,Generation Z,Higher Education,Humanities,Information Systems Applications (incl.Internet),Information technology,Law,Literature reviews,Research Article,Statistics for Social Sciences,Turkey},
  file = {/Users/colin.madland/Zotero/storage/Z4G7LD7F/bayhanTechnologicalInnovationArchitecture2020.pdf}
}

@article{bayneOpenEducationNeed2015,
  title = {Open Education: The Need for a Critical Approach},
  author = {Bayne, Si{\^a}n and Knox, Jeremy and Ross, Jen},
  year = {2015},
  journal = {Learning, Media and Technology},
  volume = {40},
  number = {3},
  pages = {247--250},
  issn = {1743-9884},
  doi = {10.1080/17439884.2015.1065272}
}

@article{bayneWhatMatterTechnologyenhanced2015,
  title = {What's the Matter with `Technology-Enhanced Learning'?},
  author = {Bayne, Sian},
  year = {2015},
  month = jan,
  journal = {Learning, Media and Technology},
  volume = {40},
  number = {1},
  pages = {5--20},
  issn = {1743-9884, 1743-9892},
  doi = {10.1080/17439884.2014.915851},
  urldate = {2022-07-07},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/FAXJL4IU/bayneWhatMatterTechnologyenhanced2015.pdf}
}

@article{bayrakDevelopmentOnlineCourse2020,
  title = {Development of {{Online Course Satisfaction Scale}}},
  author = {Bayrak, Fatma and Tibi, Moanes H. and Altun, Arif},
  year = {2020},
  journal = {Turkish Online Journal of Distance Education},
  volume = {21},
  number = {4},
  pages = {110--123},
  issn = {EISSN-1302-6488},
  abstract = {Higher education institutions consider student satisfaction to be one of the main factors in determining the quality of their online learning. The purpose of this study was to develop a reliable, valid, and practical instrument to measure online students' satisfaction as well as to explore the psychometric and theoretical concerns surrounding the construct validity of existing satisfaction scales. The study was carried out in 2017-2018 fall and spring with participants consisting of freshmen who took the online course in a state university (N[subscript fall]=1585; N[subscript spring]=1206). In this study exploratory factor analysis (EFA) (Study 1-N[subscript EFA]=921) and confirmatory factor analysis (CFA) (Study 1-N[subscript CFA]=664; Study 1-N[subscript CFA]=1206) were performed to assess the construct validity of the scale's measures. As proof of validity, the effect of gender on satisfaction was examined, for which independent sample t-test was performed. For the criterion validity, the relationship between computer and internet self-efficacy and satisfaction scores of the learners was examined. The finalized version of satisfaction scale, consisting of eight items, demonstrated that the scale is suitable for general use. Suggestions for future researchers and practitioners are proposed.},
  langid = {english},
  keywords = {Attitude Measures,College Freshmen,Computer Literacy,Construct Validity,Electronic Learning,Foreign Countries,Gender Differences,No DOI found,Online Courses,Public Colleges,Self Efficacy,Student Satisfaction,Test Construction,Test Reliability}
}

@book{bazeleyIntegratingAnalysesMixed2018,
  ids = {bazeleyIntegratingAnalysesMixed2018a},
  title = {Integrating {{Analyses}} in {{Mixed Methods Research}}},
  author = {Bazeley, Patricia},
  year = {2018},
  publisher = {SAGE Publications Ltd},
  address = {1 Oliver's Yard,~55 City Road~London~EC1Y 1SP},
  doi = {10.4135/9781526417190},
  urldate = {2021-07-25},
  isbn = {978-1-4129-6186-8 978-1-5264-1719-0},
  file = {/Users/colin.madland/Zotero/storage/JNT3AAEG/bazeleyIntegratingAnalysesMixed2018.pdf}
}

@misc{BBCWorldService,
  title = {{{BBC World Service}} - 13 {{Minutes}} to the {{Moon}}},
  journal = {BBC},
  urldate = {2019-10-02},
  abstract = {How the first moon landing was saved. Theme music by Hans Zimmer},
  howpublished = {https://www.bbc.co.uk/programmes/w13xttx2},
  langid = {british},
  file = {/Users/colin.madland/Zotero/storage/LMUMXRQ7/w13xttx2.html}
}

@misc{BCIT,
  title = {{{BCIT}}},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/P9PZ5BLH/BCIT.pdf}
}

@misc{bcteacherscouncilProfessionalStandardsBC2019,
  title = {Professional {{Standards}} for {{BC Educators}}},
  author = {{BC Teachers' Council}},
  year = {2019},
  file = {/Users/colin.madland/Zotero/storage/VIFEPAKN/edu_standards.pdf}
}

@book{beanUsingSocialWork,
  title = {Using {{R}} for {{Social Work Research}}},
  author = {Bean, Jerry},
  urldate = {2022-05-09},
  abstract = {Our goal for this document is to illustrate the importance of good data analysis practices and how R and companion packages support these practices. We think the R system has many benefits for social work research. R has become the flagship computing environment for many areas of science and has great appeal because it is free and open-access. In addition, free tools like RStudio and R Markdown promote a replication commitment and open science philosophy important to our work.},
  file = {/Users/colin.madland/Zotero/storage/K4H7AC6E/using_r_for_social_work_research.html}
}

@article{bearmanDesigningAssessmentDigital2022,
  title = {Designing Assessment in a Digital World: An Organising Framework},
  author = {Bearman, M and Nieminen, {\relax JH} and Ajjawi, R},
  year = {2022},
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {48},
  number = {3},
  issn = {0260-2938},
  doi = {10.1080/02602938.2022.2069674},
  abstract = {E-assessment typically seeks to improve assessment designs through the use of innovative digital tools. However, the intersections between digital technologies and assessment can be seen as increasingly complex, particularly as the sociotechnical perspectives suggest assessment must be relevant to a digitally-mediated society. This paper presents an organising framework, which articulates this nuanced relationship between the digital and assessment design. It draws together literature from diverse domains, including educational technologies, assessment pedagogies and digital literacies. The framework describes three main purposes for designing the digital into assessment: 1) as a tool for improvement; 2) as a means to develop and credential digital literacies; and 3) as a means to develop and credential uniquely human capabilities. Within each purpose, it offers considerations for assessment and feedback design. In addition, it offers researchers analytical tools to understand the role of the digital in assessment. The framework seeks to connect assessment and feedback design to the digital world, and in so doing ensure that higher education will be relevant for graduates' digital futures.},
  langid = {english},
  keywords = {Assessment design,critical digital literacies,e-assessment,LEARNING ANALYTICS,LITERACY,sociotechnical,SUPPORT},
  file = {/Users/colin.madland/Zotero/storage/4HYP8KJ2/bearmanDesigningAssessmentDigital2022.pdf}
}

@article{bearmanDevelopingEvaluativeJudgement2024,
  title = {Developing Evaluative Judgement for a Time of Generative Artificial Intelligence},
  author = {Bearman, Margaret and Tai, Joanna and Dawson, Phillip and Boud, David and Ajjawi, Rola},
  year = {2024},
  month = apr,
  journal = {Assessment \& Evaluation in Higher Education},
  pages = {1--13},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2024.2335321},
  urldate = {2024-04-11},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/P5I5RSD8/bearmanDevelopingEvaluativeJudgement2024.pdf}
}

@incollection{bearmanDigitallyMediatedAssessment2020,
  title = {Digitally {{Mediated Assessment}} in {{Higher Education}}: {{Ethical}} and {{Social Impacts}}},
  shorttitle = {Digitally {{Mediated Assessment}} in {{Higher Education}}},
  booktitle = {Re-Imagining {{University Assessment}} in a {{Digital World}}},
  author = {Bearman, Margaret and Dawson, Phillip and Tai, Joanna},
  editor = {Bearman, Margaret and Dawson, Phillip and Ajjawi, Rola and Tai, Joanna and Boud, David},
  year = {2020},
  volume = {7},
  pages = {23--36},
  publisher = {Springer International Publishing},
  address = {Cham},
  urldate = {2022-03-19},
  isbn = {978-3-030-41955-4 978-3-030-41956-1},
  langid = {english},
  keywords = {archived},
  file = {/Users/colin.madland/Zotero/storage/6BBY9BEA/bearmanDigitallyMediatedAssessment2020.pdf}
}

@article{bearmanHowUniversityTeachers2017,
  title = {How University Teachers Design Assessments: A Cross-Disciplinary Study},
  shorttitle = {How University Teachers Design Assessments},
  author = {Bearman, Margaret and Dawson, Phillip and Bennett, Sue and Hall, Matt and Molloy, Elizabeth and Boud, David and Joughin, Gordon},
  year = {2017},
  month = jul,
  journal = {Higher Education},
  volume = {74},
  number = {1},
  pages = {49--64},
  issn = {0018-1560, 1573-174X},
  doi = {10/gbhr94},
  urldate = {2021-04-21},
  abstract = {There are dissonances between educators' aspirations for assessment design and actual assessment implementation in higher education. Understanding how assessment is designed `on the ground' can assist in resolving this tension. Thirty-three Australian university educators from a mix of disciplines and institutions were interviewed. A thematic analysis of the transcripts indicated that assessment design begins as a response to an impetus for change. The design process itself was shaped by environmental influences, which are the circumstances surrounding the assessment design, and professional influences, which are those factors that the educators themselves bring to the process. A range of activities or tasks were undertaken, including those which were essential to all assessment design; those more selective activities, which educators chose to optimise the assessment process in particular ways; and meta-design processes which educators used to dynamically respond to environmental influences. The qualitative description indicates the complex social nature of interwoven personal and environmental influences on assessment design and the value of an explicit and strategic ways of thinking within the constraints and affordances of a local environment. This suggests that focussing on relational forms of professional development that develop strategic approaches to assessment may be beneficial. The role of disciplinary approaches may be significant and remains an area for future research.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/BEXRKSFV/bearmanHowUniversityTeachers2017.pdf}
}

@incollection{bearmanNewDirectionsAssessment2020,
  title = {New {{Directions}} for {{Assessment}} in a {{Digital World}}},
  booktitle = {Re-Imagining {{University Assessment}} in a {{Digital World}}},
  author = {Bearman, Margaret and Boud, David and Ajjawi, Rola},
  editor = {Bearman, Margaret and Dawson, Phillip and Ajjawi, Rola and Tai, Joanna and Boud, David},
  year = {2020},
  volume = {7},
  pages = {7--18},
  publisher = {Springer International Publishing},
  address = {Cham},
  urldate = {2022-03-19},
  isbn = {978-3-030-41955-4 978-3-030-41956-1},
  langid = {english},
  keywords = {archived},
  file = {/Users/colin.madland/Zotero/storage/4Q7FGWWD/bearmanNewDirectionsAssessment2020.pdf}
}

@incollection{bearmanPreparingUniversityAssessment2020,
  title = {Preparing {{University Assessment}} for a {{World}} with {{AI}}: {{Tasks}} for {{Human Intelligence}}},
  shorttitle = {Preparing {{University Assessment}} for a {{World}} with {{AI}}},
  booktitle = {Re-Imagining {{University Assessment}} in a {{Digital World}}},
  author = {Bearman, Margaret and Luckin, Rosemary},
  editor = {Bearman, Margaret and Dawson, Phillip and Ajjawi, Rola and Tai, Joanna and Boud, David},
  year = {2020},
  volume = {7},
  pages = {49--63},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-41956-1_5; https://web.archive.org/web/20220319060042/https://link.springer.com/chapter/10.1007/978-3-030-41956-1_5},
  urldate = {2022-03-19},
  isbn = {978-3-030-41955-4 978-3-030-41956-1},
  langid = {english},
  keywords = {archived},
  file = {/Users/colin.madland/Zotero/storage/LDX6QJVL/bearmanPreparingUniversityAssessment2020.pdf}
}

@book{bearmanReimaginingUniversityAssessment2020,
  title = {Re-Imagining University Assessment in a Digital World},
  editor = {Bearman, Margaret and Dawson, Phillip and Ajjawi, Rola and Tai, Joanna and Boud, David},
  year = {2020},
  series = {The Enabling Power of Assessment},
  number = {volume 7},
  publisher = {Springer},
  address = {Cham, Switzerland},
  isbn = {978-3-030-41956-1 978-3-030-41958-5 978-3-030-41955-4},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/JVJW7DS3/bearmanReimaginingUniversityAssessment2020.pdf}
}

@article{bearmanSupportAssessmentPractice2016,
  title = {Support for Assessment Practice: Developing the {{Assessment Design Decisions Framework}}},
  shorttitle = {Support for Assessment Practice},
  author = {Bearman, Margaret and Dawson, Phillip and Boud, David and Bennett, Sue and Hall, Matt and Molloy, Elizabeth},
  year = {2016},
  month = jul,
  journal = {Teaching in Higher Education},
  volume = {21},
  number = {5},
  pages = {545--556},
  issn = {1356-2517, 1470-1294},
  doi = {10/gjsn3g},
  urldate = {2021-04-25},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/Y8UTZMPW/bearmanSupportAssessmentPractice2016.pdf}
}

@article{beaversPracticalConsiderationsUsing2013,
  title = {Practical {{Considerations}} for {{Using Exploratory Factor Analysis}} in {{Educational Research}}},
  author = {Beavers, Amy S. and Lounsbury, John W. and Richards, Jennifer K. and Huck, Schuyler W. and Skolits, Gary J. and Esquivel, Shelley L.},
  year = {2013},
  journal = {Practical Assessment, Research \& Evaluation},
  volume = {18},
  number = {6},
  pages = {1--13},
  publisher = {University of Massachusetts Amherst},
  doi = {10.7275/QV2Q-RK76},
  urldate = {2024-06-03},
  abstract = {The uses and methodology of factor analysis are widely debated and discussed, especially the issues of rotational use, methods of confirmatory factor analysis, and adequate sample size. The variety of perspectives and often conflicting opinions can lead to confusion among researchers about best practices for using factor analysis. The focus of the present review is to clarify terminology, identify key issues, and clarify areas of debate regarding best practices and functions of factor analytic procedures., The conclusions and implications drawn should be useful to researchers in education, psychology, and cognate social fields who employ factor analytic procedures or evaluate research using factor analytic methods. Accessed 27,993 times on https://pareonline.net from March 05, 2013 to December 31, 2019. For downloads from January 1, 2020 forward, please click on the PlumX Metrics link to the right.},
  file = {/Users/colin.madland/Zotero/storage/ATZ8BZIW/beaversPracticalConsiderationsUsing2013.pdf}
}

@article{becerra-alonsoEduZincToolCreation2020,
  title = {"{{EduZinc}}": {{A Tool}} for the {{Creation}} and {{Assessment}} of {{Student Learning Activities}} in {{Complex Open}}, {{Online}}, and {{Flexible Learning Environments}}},
  author = {{Becerra-Alonso}, David and {Lopez-Cobo}, Isabel and {G{\'o}mez-Rey}, Pilar and {Fern{\'a}ndez-Navarro}, Francisco and Barbera, Elena},
  year = {2020},
  month = jan,
  journal = {Distance Education},
  volume = {41},
  number = {1},
  pages = {86--105},
  publisher = {Distance Education},
  issn = {0158-7919},
  doi = {10.1080/01587919.2020.1724769},
  abstract = {This article describes the development of an application for the grading and provision of feedback on educational processes. The too, named "EduZinc," enables instructors to go through the complete process of creating and evaluating the activities and materials of a course. The application enables for the simultaneous management of two teaching-related aspects: (a) creation of individualized learning products (activities, tests and exams) and (b) automatic grading (for every learning product; automated creation of student, class, and competency-based reports; and delivery of personalized reports to students, instructors and tutors). The system also has a series of warnings in place to notify instructors and tutors when a student is falling behind. As a means to reward the efforts made during the course, the program keeps relevant statistics, notifying when a student is excelling in the course.},
  keywords = {College Faculty,College Students,Computer Software,Data Collection,Educational Technology,Evaluation Methods,Feedback (Response),Foreign Countries,Grades (Scholastic),Grading,Information Management,Instructional Materials,Learning Activities,Reports,Spain,Student Centered Learning,Student Role,Teacher Role,Technology Uses in Education}
}

@article{beckAssessingStudentsMental2022,
  title = {Assessing Students' Mental Health in Two {{American}} Dental Hygiene Programs},
  author = {Beck, Judith A. and Kornegay, Elizabeth C. and Phillips, Ceib and Harmon, Jennifer B.},
  year = {2022},
  journal = {International journal of dental hygiene},
  publisher = {Wiley},
  address = {HOBOKEN},
  issn = {1601-5029},
  doi = {10.1111/idh.12631},
  abstract = {ObjectivesDental hygiene students adapt to new environments while learning technical skills and providing clinical care during their education. Understanding how stress affects students in their professional healthcare program warrants exploration. This study assessed stress among dental hygiene students in two educational settings in the Southeastern United States. MethodsFirst and second-year dental hygiene students (N = 136) from a community college setting (n = 67) and a university setting (n = 69) were invited to complete an anonymous online survey on mental health in fall 2019. Validated surveys on depression, anxiety, social support, and burnout were included. Data analysis included chi-squared and Mantel-Haenszel statistics, depending on the scale of measurement, with the level of significance set at 0.05 for all analyses. ResultsParticipants included 54 dental hygiene students from a community college (Response rate = 80.6\%) and 69 dental hygiene students from a university (RR = 100\%). There was a statistically significant difference in the proportion of students reporting moderately severe or severe anxiety (p = 0.007), with 56\% (n = 30) of the community college respondents and 36\% (n = 24) of the university reporting these anxiety levels. Students attending a community college were also more likely to express feelings of worry (n = 34) compared to students in a university setting (p = 0.005). There was no statistically significant difference in depression (p = 0.07) or suicidal thoughts (p = 0.41). ConclusionDental hygiene students enrolled in these two programs reported high levels of self-reported stress, mental and emotional concerns that may increase suicidal tendencies.},
  keywords = {Dentistry Oral Surgery & Medicine,Life Sciences & Biomedicine,Science & Technology}
}

@article{beckettDeweyOnlineCritical2019,
  title = {Dewey {{Online}}: {{A Critical Examination}} of the {{Communities}} of {{Inquiry Approach}} to {{Online Discussions}}},
  author = {Beckett, Kelvin S.},
  year = {2019},
  journal = {Philosophical Studies in Education},
  volume = {50},
  pages = {46--58},
  issn = {ISSN-0160-7561},
  abstract = {Following the pioneering work of Randy Garrison and colleagues, online teachers in the US and internationally see their discussion boards as communities of inquiry (CoI) which promote sustained communication and higher-level learning. The CoI approach to online discussions is based on John Dewey's conception of education in which teachers and learners are participants in activities working towards a common goal. Teachers in CoI have three main roles: discussion design and organization, discourse facilitation, and direct instruction. Issues have arisen in research on CoI concerning the effectiveness of each role, of communities of inquiry themselves, and of online discussions generally in promoting sustained communication and higher-level learning. The author argues that there is a more fundamental issue at stake; namely, that as currently conceived and practiced, CoI are only loosely based on Dewey's analysis of the concept of education. Furthermore, he demonstrates with examples from his own research how "new modes of practice" based more firmly on Dewey's "new order of conceptions" can help CoI achieve their goals.},
  langid = {english},
  keywords = {College Faculty,Communities of Practice,Computer Mediated Communication,Constructivism (Learning),Direct Instruction,Distance Education,Educational History,Educational Philosophy,Group Discussion,Laboratory Schools,No DOI found,Online Courses,Teacher Attitudes,Teaching Methods,Writing (Composition)}
}

@book{beethamRethinkingPedagogyDigital2020,
  title = {Rethinking Pedagogy for a Digital Age: Principles and Practices of Design},
  shorttitle = {Rethinking Pedagogy for a Digital Age},
  editor = {Beetham, Helen and Sharpe, Rhona},
  year = {2020},
  edition = {Third Edition},
  publisher = {Routledge},
  address = {New York},
  isbn = {978-0-8153-6925-7 978-0-8153-6926-4},
  lccn = {LB1028.5 .R44 2020},
  keywords = {Computer-assisted instruction,Curricula Planning},
  file = {/Users/colin.madland/Zotero/storage/HLP8Y3VQ/beethamRethinkingPedagogyDigital2020.pdf}
}

@article{begnumDigitalAssessmentHigher2018,
  title = {Digital Assessment in Higher Education: {{Promoting}} Universal Usability through Requirements Specification and Universal Design Quality ({{UD-Q}}) Reviews},
  author = {Begnum, Miriam Eileen Nes and {Foss-Pedersen}, Rikke Julie},
  editor = {ROCHA, {\relax {\'A}LVARO} and SOUSA, MARIA JOS{\'E} and SOUSA, MARIA JOS{\'E} and ROCHA, {\relax {\'A}LVARO}},
  year = {2018},
  journal = {Universal access in the information society},
  volume = {17},
  number = {4},
  pages = {791--810},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin/Heidelberg},
  issn = {1615-5289},
  doi = {10/gmb8hv},
  abstract = {Statistics show there is a clear relationship between higher education and employment in Norway, especially for people with disabilities. The use of digital assessment solutions is increasing in Norwegian higher education. The overall goal of this study is therefore to highlight the potential for improvement of current practices related to universal design, both for providers of digital assessment solutions and for higher education institutions. Based on a case study of practices in Norwegian higher education sector, this article reviews existing requirements for ensuring universal design in digital assessment solutions, prototypes an approach to evaluating universal design quality (UD-Q) of two major Norwegian digital assessment solutions and investigates the compliance between providers' self-assessments from interviews and UD-Q evaluation scores. The article presents two contributions: (1) an improved set of requirements for universal usability when procuring digital assessments solutions and (2) UD-Q, a stepwise feature analysis-based expert inspection method for evaluating the UD-Q of digital assessment solutions.},
  keywords = {Computer Communication Networks,Computer Science,Computer Science Cybernetics,Computers and Society,Digital assessment,eLearning,Engineering,Ergonomics,Expert evaluation,Higher education,Information Storage and Retrieval,Information Systems Applications (incl.Internet),IT in Business,Requirement specification,Science & Technology,Technology,Universal design,Universal usability,User Interfaces and Human Computer Interaction}
}

@incollection{bejarAutomatedScoringValidity2016,
  title = {Automated Scoring with Validity in Mind},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {Bejar, Isaac I. and Mislevy, Robert J. and Zhang, Mo},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch10},
  pages = {226--246},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch10},
  abstract = {Summary In this chapter we present an overview of automated scoring and illustrate some of the design decisions that should be considered when developing or evaluating an assessment that relies on automated scoring. The overarching theme is score validity. Given the increasingly ambitious goals of twenty-first-century assessments, it is important to approach their design in a systematic fashion to ensure that the scores that will eventually be reported are valid. The evidence-centered design (ECD) framework is especially well-suited for the task because it pays special attention to characterizing the evidence in performances. We focus on the evidence identification component of an assessment design within this approach, which identifies and implements procedures for extracting evidence of the proficiencies an assessment claims to support. We illustrate key design decisions in a wide range of domains from writing assessment to games and simulations.},
  chapter = {10},
  isbn = {978-1-118-95658-8},
  keywords = {automated scoring,evidence-centered design,games and simulations,validity,writing assessment}
}

@article{belczewskiDecolonizingScienceEducation2009,
  title = {Decolonizing {{Science Education}} and the {{Science Teacher}}: {{A White Teacher}}'s {{Perspective}}},
  author = {Belczewski, Andrea},
  year = {2009},
  journal = {Canadian Journal of Science, Mathematics and Technology Education},
  volume = {9},
  number = {3},
  pages = {191--202},
  issn = {1492-6156},
  doi = {10.1080/14926150903118326},
  abstract = {This article recounts my ongoing process of becoming decolonized in my thinking and teaching practice in order to make science education relevant, meaningful, and respectful for First Nations students. Through close collaboration with Mi'kmaq and Maliseet education directors, students, children, parents, and elders I have gained insights into Mi'kmaq/Maliseet ways of being and ways of understanding the natural world. I have developed a deep appreciation for those who invite me to question my epistemologies by sharing ways of knowing the world that is different from my own. Viewing myself through a Mi'kmaq/Maliseet lens has impacted profoundly how I interact with First Nations children in summer camps and students in university classes.Cet article raconte le processus continu de d{\'e}colonisation de ma fa{\c c}on de penser et de mes pratiques p{\'e}dagogiques, dans le but de rendre ma enseignement des sciences pertinent, significatif et respectueux aux yeux des {\'e}tudiants des Premi{\`e}res nations. Gr{\^a}ce {\`a} une {\'e}troite collaboration avec des directeurs, des {\'e}tudiants, des enfants, des parents et des sages Micmaques et Mal{\'e}cites, j'ai eu l'occasion de mieux comprendre leurs fa{\c c}ons d'{\textasciicircum}etre et leurs interpr{\'e}tations du monde naturel. J'ai appris {\`a} appr{\'e}cier grandement ceux qui, en partageant avec moi des modes de connaissances diff{\'e}rents des miens, me poussent {\`a} remettre en question ma {\'e}pist{\'e}mologie. Le fait de pouvoir me voir {\`a} travers une lunette micmaque / mal{\'e}cite a eu un impact profond sur ma fa{\c c}on d'interagir avec les jeunes autochtones, aussi bien les enfants dans les camps d'{\'e}t{\'e} que les {\'e}tudiants dans les cours universitaires.},
  keywords = {Education,Engineering/Technology Education,Mathematics Education,Science Education}
}

@article{bellLearningChangingDoing2010,
  title = {Learning, Changing, and Doing: A Model for Transformational Leadership Development in Religious and Non-Profit Organizations},
  author = {Bell, Skip},
  year = {2010},
  journal = {Journal of Religious Leadership},
  volume = {9},
  number = {1},
  abstract = {Religious and non-profit organizations seek people who continually experience learning and growth within their work. Such persons will not stop at doing their jobs well; they develop as leaders who in turn create positive transformation within their group. The purpose of this article is to define a transformational leadership development process integrating learning, changing, and doing as the preferred model in the life of a religious or non-profit organization. The outcome will be persons who grow as leaders, experience meaning in their service, and contribute significant organizational change.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/bellLEARNINGCHANGINGDOING2010.pdf}
}

@article{bellousShouldWeTeach1995,
  title = {Should {{We Teach Students}} to {{Resist}}?},
  author = {Bellous, Joyce},
  year = {1995},
  journal = {Philosophical Inquiry in Education},
  volume = {24},
  number = {3}
}

@article{beltVideoUseOnline2021,
  title = {Video {{Use}} in {{Online}} and {{Blended Courses}}: {{A Qualitative Synthesis}}},
  author = {Belt, Eric S. and Lowenthal, Patrick R.},
  year = {2021},
  month = jan,
  journal = {Distance Education},
  volume = {42},
  number = {3},
  pages = {410--440},
  publisher = {Distance Education},
  issn = {0158-7919},
  doi = {10.1080/01587919.2021.1954882},
  abstract = {The use of video has become commonplace in education today. Educators are engaging students with video communication technology more frequently than ever before, given COVID-19. However, questions remain on how instructors use video as a communication and teaching tool in online and blended courses. The purpose of this literature review was to synthesize research on the use of video as a teaching tool in online and blended courses. A systematic approach was used to identify 64 peer-reviewed studies published from 2010 to 2020. A qualitative synthesis of the studies resulted in four themes: delivering video lectures, fostering discussions with video, using video assessments and feedback, and creating video check-ins. Each theme and related research are discussed in the article. Gaps in the literature are identified and recommendations are made for future research.},
  keywords = {Asia,Asynchronous Communication,Australia,Barriers,Blended Learning,Canada,Europe,Evaluation Methods,Feedback (Response),Foreign Countries,Group Discussion,Higher Education,Information Dissemination,Lecture Method,Meetings,Online Courses,Progress Monitoring,Synchronous Communication,Teaching Methods,Technology Uses in Education,United States,Video Technology,Videoconferencing},
  file = {/Users/colin.madland/Zotero/storage/9W8YJIRV/beltVideoUseOnline2021.pdf}
}

@inproceedings{benderDangersStochasticParrots2021,
  title = {On the {{Dangers}} of {{Stochastic Parrots}}: {{Can Language Models Be Too Big}}? },
  shorttitle = {On the {{Dangers}} of {{Stochastic Parrots}}},
  booktitle = {Proceedings of the 2021 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Bender, Emily M. and Gebru, Timnit and {McMillan-Major}, Angelina and Shmitchell, Shmargaret},
  year = {2021},
  month = mar,
  pages = {610--623},
  publisher = {ACM},
  address = {Virtual Event Canada},
  doi = {10.1145/3442188.3445922},
  urldate = {2024-06-10},
  isbn = {978-1-4503-8309-7},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/9QQWDPPT/benderDangersStochasticParrots2021.pdf}
}

@article{benedictsheehyWritingGetPublished2022,
  title = {Writing to {{Get Published}}: {{The Necessary Elements}} of {{Scholarly Journal Articles}}},
  shorttitle = {Writing to {{Get Published}}},
  author = {{Benedict Sheehy}},
  year = {2022},
  month = may,
  journal = {The International Journal of Law, Language \& Discourse},
  volume = {10},
  number = {1},
  pages = {24--37},
  issn = {1839-8308},
  doi = {10.56498/1012022337},
  urldate = {2022-11-14},
  abstract = {This article provides an analysis of the problems scholars face in publishing in higher quality, peer-reviewed English language journals and proposes specific solutions. It is based on observations made in numerous workshops and close one-on-one work with postgraduate students and academics primarily in Asia but also elsewhere. The article makes a contribution by making explicit understandings, values and practices that underpin academic publishing and describing and analyzing the six elements required by peer reviewed journals. Using a `scholarship of application' the article begins with an explanation of the literature review and then the element of novelty or necessity of a new idea. It then turns to the six elements of research and writing in terms of theory, themes and narrative as the first three and then the last three: the requirement for description, analysis and evaluation. Finally, it provides a series of specific tips to help manage each of these elements.},
  file = {/Users/colin.madland/Zotero/storage/TUTBDITV/benedictsheehyWritingGetPublished2022.pdf}
}

@article{benediktssonImmigrantStudentsExperiences2020,
  title = {Immigrant Students' Experiences of Assessment Methods Used in {{Icelandic}} Universities},
  author = {Benediktsson, Art{\"e}m Ingmar and Ragnarsd{\'o}ttir, Hanna},
  year = {2020},
  month = apr,
  journal = {Multicultural Education Review},
  volume = {12},
  number = {2},
  pages = {98--116},
  issn = {2005-615X, 2377-0031},
  doi = {10/gmcv29},
  urldate = {2021-07-31},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/MJCMH2AV/benediktssonImmigrantStudentsExperiences2020.pdf}
}

@article{bengtssonTakeHomeExamsHigher2019,
  title = {Take-{{Home Exams}} in {{Higher Education}}: {{A Systematic Review}}},
  author = {Bengtsson, Lars},
  year = {2019},
  journal = {Education Sciences},
  volume = {9},
  issn = {EISSN-2227-7102},
  abstract = {This work describes a systematic review of the research on take-home exams in tertiary education. It was found that there is some disagreement in the community about the virtues of take-home exams but also a lot of agreement. It is concluded that take-home exams may be the preferred choice of assessment method on the higher taxonomy levels because they promote higher-order thinking skills and allow time for reflection. They are also more consonant with constructive alignment theories and turn the assessment into a learning activity. Due to the obvious risk of unethical student behavior, take-home exams are not recommended on the lowest taxonomy level. It is concluded that there is still a lot of research missing concerning take-home exams in higher education and some of this research may be urgent due to the emergence of massive online open courses (MOOCs) and online universities where non-proctored exams prevail.},
  keywords = {Access to Information,Cheating,Ethics,Higher Education,Internet,No DOI found,Reflection,Retention (Psychology),STEM Education,Student Behavior,Study Habits,Supervision,Taxonomy,Test Items,Testing Problems,Tests,Thinking Skills,Time Factors (Learning)}
}

@article{benjaminAssessingRiskAutomating2019,
  title = {Assessing Risk, Automating Racism},
  author = {Benjamin, Ruha},
  year = {2019},
  journal = {Science},
  volume = {366},
  number = {6464},
  pages = {421},
  doi = {10/ggbrm8},
  file = {/Users/colin.madland/Zotero/storage/QIME2K3J/benjaminAssessingRiskAutomating2019.pdf}
}

@article{benjaminHistoryTeachingMachines1988,
  title = {A History of Teaching Machines.},
  author = {Benjamin, Ludy T.},
  year = {1988},
  journal = {American Psychologist},
  volume = {43},
  number = {9},
  pages = {703--712},
  issn = {0003-066X},
  doi = {10/djgzjr},
  abstract = {The development of teaching machines is traced from the patented educational devices of the 19th century through the initial teaching machines of Sidney Pressey in the 1920s to the machines invented by B. F. Skinner in the 1950s. The obscurity of Pressey's pioneering work in this field contrasted with the fame achieved by Skinner is discussed in a historical context. The final sections discuss the short-lived success and eventual failure of classroom teaching machines in the 1950s and 1960s. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {19th century through 1980s,History,history of teaching machines,Teaching Machines,Teaching Methods},
  file = {/Users/colin.madland/Zotero/storage/NXXSYCF3/benjaminHistoryTeachingMachines1988.pdf}
}

@book{benjaminRaceTechnologyAbolitionist2019,
  title = {Race after Technology: {{Abolitionist}} Tools for the New {{Jim Code}}},
  shorttitle = {Race after Technology},
  author = {Benjamin, Ruha},
  year = {2019},
  publisher = {Polity},
  address = {Medford, MA},
  isbn = {978-1-5095-2639-0 978-1-5095-2640-6},
  lccn = {HN90.I56 B46 2019},
  keywords = {21st century,African Americans,Digital divide,Information technology,Race relations,Social aspects,Social conditions,SOCIAL SCIENCE / Demography,United States,Whites}
}

@article{bennettChangingNatureEducational2015,
  title = {The {{Changing Nature}} of {{Educational Assessment}}},
  author = {Bennett, Randy Elliot},
  year = {2015},
  month = mar,
  journal = {Review of Research in Education},
  volume = {39},
  number = {1},
  pages = {370--407},
  issn = {0091-732X, 1935-1038},
  doi = {10/gf9s6x},
  urldate = {2021-03-02},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/9HSLKK6K/bennettChangingNatureEducational2015.pdf}
}

@article{bennettFormativeAssessmentCritical2011,
  ids = {bennettFormativeAssessmentCritical2011a},
  title = {Formative Assessment: A Critical Review},
  author = {Bennett, Randy Elliot},
  year = {2011},
  month = feb,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {18},
  number = {1},
  pages = {5--25},
  publisher = {Routledge},
  issn = {0969-594X},
  doi = {10/cfv4kn},
  mag_id = {2122513519},
  pmcid = {null},
  pmid = {null},
  keywords = {guskey},
  file = {/Users/colin.madland/Zotero/storage/ZM3Y28PG/bennettFormativeAssessmentCritical2011.pdf}
}

@article{bennettGoodSideCOVID192022,
  title = {The {{Good Side}} of {{COVID-19}}},
  author = {Bennett, R.},
  year = {2022},
  month = feb,
  journal = {Educational Measurement: Issues and Practice},
  doi = {10.1111/EMIP.12496},
  abstract = {This commentary focuses on one of the positive impacts of COVID-19, which was to tie societal inequity to testing in a manner that could motivate the reimagining of our field. That reimagining needs to account for our nation's dramatically changing demographics so that assessment generally, and standardized testing specifically, better fit the needs of a multicultural society.},
  file = {/Users/colin.madland/Zotero/storage/FI2LUHRP/bennettGoodSideCOVID192022.pdf}
}

@article{bennettHowTechnologyShapes2017,
  title = {How Technology Shapes Assessment Design : {{Findings}} from a Study of University Teachers},
  author = {Bennett, Sue and Dawson, Phillip and Bearman, Margaret and Molloy, Elizabeth and Boud, David},
  year = {2017},
  journal = {British Journal of Educational Technology},
  volume = {48},
  number = {2},
  pages = {672--682},
  publisher = {Wiley},
  address = {HOBOKEN},
  issn = {0007-1013},
  doi = {10.1111/bjet.12439},
  abstract = {A wide range of technologies has been developed to enhance assessment, but adoption has been inconsistent. This is despite assessment being critical to student learning and certification. To understand why this is the case and how it can be addressed, we need to explore the perspectives of academics responsible for designing and implementing technology-supported assessment strategies. This paper reports on the experience of designing technology-supported assessment based on interviews with 33 Australian university teachers. The findings reveal the desire to achieve greater efficiencies and to be contemporary and innovative as key drivers of technology adoption for assessment. Participants sought to shape student behaviours through their designs and made adaptations in response to positive feedback and undesirable outcomes. Many designs required modification because of a lack of appropriate support, leading to compromise and, in some cases, abandonment. These findings highlight the challenges to effective technology-supported assessment design and demonstrate the difficulties university teachers face when attempting to negotiate mixed messages within institutions and the demands of design work. We use these findings to suggest opportunities to improve support by offering pedagogical guidance and technical help at critical stages of the design process and encouraging an iterative approach to design. [Author abstract]},
  keywords = {Academic staff,Academic staff attitudes,Assessments,College Faculty,College teachers,Colleges & universities,Computer Assisted Testing,Demand,Design,Design analysis,Design improvements,Education & Educational Research,Educational evaluation,Educational technology,Evaluation Methods,Feedback,Feedback (Response),Foreign Countries,Higher education,ICT in education,Instructional design,Interviews,Pedagogy,Positive feedback,Social Sciences,Student assessment,Student Behavior,Students,Teacher Attitudes,Teachers,Teaching Methods,Technology adoption,Technology assessment,Technology education,Technology integration,Technology utilization,Test Construction,Universities,University professors,University students,University teaching},
  file = {/Users/colin.madland/Zotero/storage/Searches/bennettHowTechnologyShapes2017.pdf;/Users/colin.madland/Zotero/storage/TQFBM94Y/bennettHowTechnologyShapes2017preprint.pdf}
}

@article{bennettSustainableTechnologyenhancedInnovation2018,
  title = {Towards Sustainable Technology-Enhanced Innovation in Higher Education: {{Advancing}} Learning Design by Understanding and Supporting Teacher Design Practice},
  shorttitle = {Towards Sustainable Technology-Enhanced Innovation in Higher Education},
  author = {Bennett, Sue and Lockyer, Lori and Agostinho, Shirley},
  year = {2018},
  month = nov,
  journal = {British Journal of Educational Technology},
  volume = {49},
  number = {6},
  pages = {1014--1026},
  issn = {00071013},
  doi = {10.1111/bjet.12683},
  urldate = {2022-05-17},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/SJ4E3QFM/bennettSustainableTechnologyenhancedInnovation2018.pdf}
}

@book{bensonOnlineLearningAssessment2010,
  title = {Online Learning and Assessment in Higher Education: A Planning Guide},
  author = {Benson, Robyn and Brack, Charlotte},
  year = {2010},
  number = {Book, Whole},
  publisher = {Chandos Publishing},
  address = {Cambridge [England]},
  abstract = {The use of e-learning strategies in teaching is becoming increasingly popular, particularly in higher education. Online Learning and Assessment in Higher Education recognises the key decisions that need to be made by lecturers in order to introduce e-learning into their teaching. An overview of the tools for e-learning is provided, including the use of Web 2.0 and the issues surrounding the use of e-learning tools such as resources and support and institutional policy. The second part of the book focuses on e-assessment; design principles, different forms of online assessment and the benefits and limitations of e-assessment. Provides an accessible introduction to teaching with technologyAddresses the basic aspects of decision-making for successful introduction of e-learning, drawing on relevant pedagogical principles from contemporary learning theoriesCrosses boundaries between the fields of higher education and educational technology (within the discipline of education), drawing on discourse from both areas;The use of e-learning strategies in teaching is becoming increasingly popular, particularly in higher education. Online Learning and Assessment in Higher Education recognises the key decisions that need to be made by lecturers in order to introduce e-learning into their teaching. An overview of the tools for e-learning is provided, including the use of Web 2.0 and the issues surrounding the use of e-learning tools such as resources and support and institutional policy. The second part of the book focuses on e-assessment; design principles, different forms of online assessment and the benefits and limitations of e-assessment. * Provides an accessible introduction to teaching with technology* Addresses the basic aspects of decision-making for successful introduction of e-learning, drawing on relevant pedagogical principles from contemporary learning theories* Crosses boundaries between the fields of higher education and educational technology (within the discipline of education), drawing on discourse from both areas;The use of e-learning strategies in teaching is becoming increasingly popular, particularly in higher education. Online Learning and Assessment in Higher Education recognises the key decisions that need to be made by lecturers in order to introduce e-learning into their teaching. An overview of the tools for e-learning is provided, including the use of Web 2.0 and the issues surrounding the use of e-learning tools such as resources and support and institutional policy. The second part of the book focuses on e-assessment; design principles, different forms of online assessment and the benefits and limitations of e-assessment. Provides an accessible introduction to teaching with technology Addresses the basic aspects of decision-making for successful introduction of e-learning, drawing on relevant pedagogical principles from contemporary learning theories Crosses boundaries between the fields of higher education and educational technology (within the discipline of education), drawing on discourse from both areas.;},
  isbn = {9781843345770;9781780631653;1780631650;1843345773;},
  keywords = {College teaching,Computer programs,Computer-assisted instruction,Data processing,Education Higher,Educational technology,Educational tests and measurements,Internet in higher education}
}

@book{bensonOnlineLearningAssessment2010a,
  title = {Online Learning and Assessment in Higher Education : A Planning Guide},
  author = {Benson, {\relax Robyn}. and Brack, {\relax Charlotte}.},
  year = {2010},
  edition = {1st edition},
  publisher = {Chandos Publishing},
  address = {Cambridge [England},
  abstract = {The use of e-learning strategies in teaching is becoming increasingly popular, particularly in higher education. Online Learning and Assessment in Higher Education recognises the key decisions that need to be made by lecturers in order to introduce e-learning into their teaching. An overview of the tools for e-learning is provided, including the use of Web 2.0 and the issues surrounding the use of e-learning tools such as resources and support and institutional policy. The second part of the book focuses on e-assessment; design principles, different forms of online assessment and the benefits},
  isbn = {1-78063-165-0},
  keywords = {Education Higher -- Computer-assisted instruction,Educational technology,Educational tests and measurements -- Computer programs,Educational tests and measurements -- Data processing,Electronic books,Internet in higher education}
}

@article{bergstromDesigningUnknownDidactical2012,
  title = {Designing for the Unknown Didactical Design for Process Based Assessment in Technology Rich Learning Environments},
  author = {Bergstr{\"o}m, Peter},
  year = {2012},
  journal = {null},
  doi = {null},
  abstract = {This thesis is based on a study of the development of education through theinnovative use of process-based assessment in technology-rich learningenvironments in teacher and nurse education. The stu ...},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@article{bergstromDesigningUnknownDidactical2012a,
  title = {Designing for the Unknown Didactical Design for Process Based Assessment in Technology Rich Learning Environments},
  author = {Bergstr{\"o}m, Peter},
  year = {2012},
  journal = {null},
  doi = {null},
  abstract = {This thesis is based on a study of the development of education through theinnovative use of process-based assessment in technology-rich learningenvironments in teacher and nurse education. The stu ...},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@book{bernsteinClassCodesControl1977,
  title = {Class, Codes and Control. 3: {{Towards}} a Theory of Educational Transmissions},
  shorttitle = {Class, Codes and Control. 3},
  author = {Bernstein, Basil},
  year = {1977},
  series = {Primary Socialization, Language and Education},
  edition = {2., rev. ed},
  number = {4},
  publisher = {Routledge},
  address = {London},
  isbn = {978-0-7100-8666-2},
  langid = {english}
}

@incollection{bernsteinClassificationFramingEducational1973,
  ids = {bernsteinClassificationFramingEducational},
  title = {On the Classification and Framing of Educational Knowledge},
  booktitle = {Knowledge and Control: New Directions for the Sociology of Education},
  author = {Bernstein, Basil},
  editor = {Young, Michael F. D.},
  year = {1973},
  series = {Open {{University}} Set Boo},
  publisher = {Collier-Macmillan},
  address = {London},
  isbn = {0029783607 00297837},
  lccn = {LC191},
  keywords = {Educational sociology,Multiple DOI},
  annotation = {OCLC: 4152},
  file = {/Users/colin.madland/Zotero/storage/MJ54LMPN/bernsteinClassificationFramingEducational1973.pdf}
}

@article{bernsteinVerticalHorizontalDiscourse1999,
  title = {Vertical and {{Horizontal Discourse}}: {{An Essay}}},
  author = {Bernstein, Basil},
  year = {1999},
  journal = {British Journal of Sociology of Education},
  volume = {20},
  number = {2},
  pages = {157--173},
  publisher = {Taylor \& Francis, Ltd.},
  issn = {01425692, 14653346},
  doi = {10/ftmsvc},
  urldate = {2021-07-16},
  abstract = {[The analysis in this paper has its origins in a critical account of the sociology of education (Bernstein, 1975) where the various approaches to the study of sociology were taken as the distinguishing feature of the discourse. This matter was further developed (Bernstein, 1996), with the distinction between vertical and horizontal discourses and their various modalities introduced in the context of differentiating this mode of analysis from more 'Bourdieuan' perspectives. This present paper is concerned with filling out and extending the sketches adumbrated in earlier work in a more accessible form. The model proposed generates a language which relates the internal structure of specialised knowledges, the positional nature of their fields or arenas of practice, identity constructions and their change, and the forms of acquisition for successful performances.]},
  file = {/Users/colin.madland/Zotero/storage/E8YYKMRF/bernsteinVerticalHorizontalDiscourse1999.pdf}
}

@article{beseisoNovelAutomatedEssay2021,
  title = {A Novel Automated Essay Scoring Approach for Reliable Higher Educational Assessments},
  author = {Beseiso, Majdi and Alzubi, Omar A. and Rashaideh, Hasan},
  year = {2021},
  journal = {Journal of computing in higher education},
  volume = {33},
  number = {3},
  pages = {727--746},
  publisher = {Springer US},
  address = {New York},
  issn = {1042-1726},
  doi = {10.1007/s12528-021-09283-1},
  abstract = {E-learning is gradually gaining prominence in higher education, with universities enlarging provision and more students getting enrolled. The effectiveness of automated essay scoring (AES) is thus holding a strong appeal to universities for managing an increasing learning interest and reducing costs associated with human raters. The growth in e-learning systems in the higher education system and the demand for consistent writing assessments has spurred research interest in improving the accuracy of AES systems. This paper presents a transformer-based neural network model for improved AES performance using Bi-LSTM and RoBERTa language model based on Kaggle's ASAP dataset. The proposed model uses Bi-LSTM model over pre-trained RoBERTa language model to address the coherency issue in essays that is ignored by traditional essay scoring methods, including traditional NLP pipelines, deep learning-based methods, a mixture of both. The comparison of the experimental results on essay scoring with human raters concludes that the proposed model outperforms the existing methods in essay scoring in terms of QWK score. The comparative analysis of results demonstrates the applicability of the proposed model in automated essay scoring at higher education level.},
  keywords = {Analysis,Artificial Intelligence,Assessments,Automation,Colleges & universities,Computer science,Deep learning,Distance learning,Education,Education & Educational Research,Education Higher,Educational evaluation,Educational Technology,Essays,Higher Education,Learning and Instruction,Neural networks,Online instruction,Original Paper,Scoring,Social Sciences,Test Reliability,Writing Tests}
}

@article{besserFeedbackDigitalBadge2020,
  title = {Feedback in a {{Digital Badge Learning Experience}}: {{Considering}} the {{Instructor}}'s {{Perspective}}},
  author = {Besser, {\relax ED} and Newby, {\relax TJ}},
  year = {2020},
  journal = {TechTrends},
  volume = {64},
  number = {3},
  pages = {484--497},
  issn = {8756-3894},
  doi = {10.1007/s11528-020-00485-5},
  abstract = {There is growing interest in how various technical tools can be used to leverage the instructional process for both teaching and learning. Digital badges are a visual representation of learning and skills. Digital badges have been used as a way to reduce gaps in knowledge (Bowen and Thomas Change, 46(1), 21-25, 2014; Guskey Journal of Advanced Academics, 19(1), 8-31, 2007), increase engagement (Abramovich et al. Educational Technology Research and Development, 61, 217-232, 2013; Glover and Latif 2013), and develop mastery in key concepts (Academic Medicine, 88(10), 1418-1423, 2013). One challenge for educators in using digital badge systems is in how to provide detailed and specific assessment and feedback to students. A potential solution is to pair digital badges with Mastery Learning strategies. In order to examine the types and ways in which instructors provide feedback, individual instructor case studies were developed. Each case was investigated and analyzed holistically as a single entity representing the distinct evaluation style of that instructor. The coding schema used a deductive process based on feedback and Mastery Learning research including the functions of feedback (e.g. task, cognitive, and functional validity information) (Balzer et al. Psychological Bulletin, 106(3), 410, 1989; Butler and Winne Review of Educational Research, 65(3), 245-281, 1995), principles of feedback (e.g. principles supporting self-regulated learning) (Nicol \& Macfarlane-Dick Studies in Higher Education, 31(2), 199-218, 2006), framework of effective feedback (e.g. content, social and interpersonal negotiation, organization and management) (Yang and Carless Teaching in Higher Education, 18(3), 285-297, 2013), and essential elements of Mastery Learning (e.g. feedback, correctives, enrichment) (Guskey Journal of Advanced Academics, 19(1), 8-31, 2007). Instructors' feedback fell within six categories: 1) Outcome Feedback; 2) Clarification; 3) Decreasing Gaps in Knowledge; 4) Motivation and Interaction; 5) Opportunities to Further Knowledge; 6) Promotes Overall Learning and Cognitive Development. Based on the results, specific categories of feedback are discussed.},
  langid = {english},
  keywords = {ACADEMIC-ACHIEVEMENT,Case study research,Digital badges,EDUCATION,ENHANCEMENT,Feedback,FORMATIVE ASSESSMENT,Mastery learning,SELF-EFFICACY}
}

@article{bhuteMovingTimedRemote2020,
  title = {Moving to {{Timed Remote Assessments}}: {{The Impact}} of {{COVID-19}} on {{Year End Exams}} in {{Chemical Engineering}} at {{Imperial College London}}},
  author = {Bhute, Vijesh J and Campbell, James and Kogelbauer, Andreas and Shah, Umang V and Brechtelsbauer, Clemens},
  year = {2020},
  journal = {Journal of chemical education},
  volume = {97},
  number = {9},
  pages = {2760--2767},
  publisher = {{American Chemical Society and Division of Chemical Education, Inc}},
  address = {WASHINGTON},
  issn = {0021-9584},
  doi = {10.1021/acs.jchemed.0c00617},
  abstract = {Summative year end assessments are a major component of student assessment at the Department of Chemical Engineering, Imperial College London. More than 600 students participate in over 40 different exams during the summer term. At the end of the spring term, the college moved to fully remote operation due to COVID-19, leaving the academic community with the challenge of delivering examinations remotely. At the time the pandemic hit the UK, teaching for all modules in the department had been completed, the exam timetable had already been published, and all exam papers passed the mandatory external quality review. To implement time-limited remote exams as stipulated by the university, the department decided to proceed with an existing VLE platform for submission of answer-sheets. This study highlights stakeholder reflections from the academic and student community during the implementation of this approach culminating in a mock examination to gauge readiness of the infrastructure as well as the student population. Our survey found that the majority of students ({$>$}80\%) managed to follow the written instructions and readily engaged with scanning technologies and the uploading process. In the main, students did not have to adapt their learning or writing style. All stakeholders provided constructive suggestions at the end of the mock exam resulting in a relatively smooth transition to this new mode of examination. This study highlights challenges and reflections on making the summer year end exams remote in a very short time frame in a large and diverse Chemical Engineering department at very short notice.},
  keywords = {Academic achievement,Answer Sheets,Assessments,Chemical Engineering,Chemistry,Chemistry Multidisciplinary,College Students,Colleges & universities,Computer Assisted Testing,COVID-19,Distance Education,Education & Educational Research,Education Scientific Disciplines,Educational evaluation,Foreign Countries,Pandemics,Physical Sciences,Science & Technology,Science Tests,Social Sciences,Student Evaluation,Students,Summative Evaluation,Summer,Time,Timetables},
  file = {/Users/colin.madland/Zotero/storage/8K4NN5FC/bhuteMovingTimedRemote2020.pdf}
}

@article{biasuttiCodingSchemeAnalyse2017,
  title = {A Coding Scheme to Analyse the Online Asynchronous Discussion Forums of University Students},
  author = {Biasutti, M},
  year = {2017},
  journal = {Technology Pedagogy And Education},
  volume = {26},
  number = {5},
  pages = {601--615},
  issn = {1475-939X},
  doi = {10.1080/1475939X.2017.1365753},
  abstract = {The current study describes the development of a content analysis coding scheme to examine transcripts of online asynchronous discussion groups in higher education. The theoretical framework comprises the theories regarding knowledge construction in computer-supported collaborative learning (CSCL) based on a sociocultural perspective. The coding scheme was developed by inductive analysis of processes of forum discussions of university students performing collaborative tasks. The following themes emerged: (1) inferencing, (2) producing, (3) developing, (4) evaluating, (5) summarising, (6) organising and (7) supporting. A reliability analysis using the Kappa statistic indicated that there is a good degree of agreement among coders, rendering the coding scheme reliable. To demonstrate its utility, the coding scheme was applied to detect differences in the levels of interactions among university students with different backgrounds attending two degree programmes. Implications for the application of the coding scheme in further research are offered, such as comparing the processes activated by different online tools.},
  langid = {english},
  keywords = {asynchronous environment,Content analysis coding scheme,CSCL,forum assessment,KNOWLEDGE CONSTRUCTION,LEARNING ENVIRONMENTS,MESSAGES,online collaborative learning,online evaluation tools,PATTERNS}
}

@article{biggsAligningTeachingConstructing2003,
  title = {Aligning {{Teaching}} for {{Constructing Learning}}},
  author = {Biggs, John},
  year = {2003},
  month = jan,
  abstract = {Summary 'Constructive alignment' starts with the notion that the learner constructs his or her own learning through relevant learning activities. The teacher's job is to create a learning environment that supports the learning activities appropriate to achieving the desired learning outcomes. The key is that all components in the teaching system - the curriculum and its intended outcomes, the teaching methods used, the assessment tasks - are aligned to each other. All are tuned to learning activities addressed in the desired learning outcomes. The learner finds it difficult to escape without learning appropriately.},
  keywords = {No DOI found}
}

@article{biggsApproachesEnhancementTertiary1989,
  title = {Approaches to the {{Enhancement}} of {{Tertiary Teaching}}},
  author = {Biggs, John},
  year = {1989},
  month = jan,
  journal = {Higher Education Research \& Development},
  volume = {8},
  number = {1},
  pages = {7--25},
  issn = {0729-4360, 1469-8366},
  doi = {10/ft2jtr},
  urldate = {2021-07-12},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/ABFIMKS6/biggsApproachesEnhancementTertiary1989.pdf}
}

@article{biggsAssessmentClassroomLearning1998,
  title = {Assessment and {{Classroom Learning}}: A Role for Summative Assessment?},
  shorttitle = {Assessment and {{Classroom Learning}}},
  author = {Biggs, John},
  year = {1998},
  month = mar,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {5},
  number = {1},
  pages = {103--110},
  issn = {0969-594X, 1465-329X},
  doi = {10/fsbrnb},
  urldate = {2021-07-11},
  langid = {english},
  pmcid = {null},
  pmid = {null},
  file = {/Users/colin.madland/Zotero/storage/KFSL6Q33/biggsAssessmentClassroomLearning1998a.pdf}
}

@article{biggsEnhancingTeachingConstructive1996,
  title = {Enhancing Teaching through Constructive Alignment},
  author = {Biggs, John},
  year = {1996},
  month = oct,
  journal = {Higher Education},
  volume = {32},
  number = {3},
  pages = {347--364},
  issn = {0018-1560, 1573-174X},
  doi = {10/chx3gp},
  urldate = {2020-05-17},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/DTMQGFC2/biggsEnhancingTeachingConstructive1996.pdf}
}

@book{biggsEvaluatingQualityLearning1982,
  title = {Evaluating the Quality of Learning: {{The SOLO}} Taxonomy},
  author = {Biggs, John and Collis, Kevin},
  year = {1982},
  publisher = {Academic Press},
  address = {New York}
}

@article{biggsRevisedTwofactorStudy2001,
  title = {The Revised Two-Factor {{Study Process Questionnaire}}: {{R-SPQ-2F}}},
  shorttitle = {The Revised Two-Factor {{Study Process Questionnaire}}: {{R-SPQ-2F}}},
  author = {Biggs, John and Kember, David and Leung, Doris Y. P.},
  year = {2001},
  journal = {British Journal of Educational Psychology},
  volume = {71},
  pages = {133--149},
  issn = {2044-8279},
  doi = {10.1348/000709901158433},
  abstract = {Aim. To produce a revised two-factor version of the Study Process Questionnaire (R-SPQ-2F) suitable for use by teachers in evaluating the learning approaches of their students. The revised instrument assesses deep and surface approaches only, using fewer items. Method. A set of 43 items was drawn up for the initial tests. These were derived from: the original version of the SPQ, modified items from the SPQ, and new items. A process of testing and refinement eventuated in deep and surface motive and strategy scales each with 5 items, 10 items per approach score. The final version was tested using reliability procedures and confirmatory factor analysis. Sample. The sample for the testing and refinement process consisted of 229 students from the health sciences faculty of a university in Hong Kong. A fresh sample of 495 undergraduate students from a variety of departments of the same university was used for the test of the final version. Results. The final version of the questionnaire had acceptable Cronbach alpha values for scale reliability. Confirmatory factor analysis indicated a good fit to the intended two-factor structure. Both deep and surface approach scales had well identified motive and strategy subscales. Conclusion. The revision process has resulted in a simple questionnaire which teachers can use to evaluate their own teaching and the learning approaches of their students.},
  annotation = {1},
  file = {/Users/colin.madland/Zotero/storage/6NXDHVL6/biggsRevisedTwofactorStudy2001.pdf}
}

@book{biggsTeachingQualityLearning2011,
  title = {Teaching for Quality Learning at University: {{What}} the Student Does},
  shorttitle = {Teaching for Quality Learning at University: {{What}} the Student Does},
  author = {Biggs, John and Tang, Catherine},
  year = {2011},
  edition = {4th},
  publisher = {Society for Research into Higher Education \& Open University Press},
  address = {New York},
  file = {/Users/colin.madland/Zotero/storage/C3TVITH5/biggsTeachingQualityLearning2011.pdf}
}

@article{biggsTheoryPracticeCognitive1993,
  title = {From {{Theory}} to {{Practice}}: {{A Cognitive Systems Approach}}},
  shorttitle = {From {{Theory}} to {{Practice}}},
  author = {Biggs, John},
  year = {1993},
  month = jan,
  journal = {Higher Education Research \& Development},
  volume = {12},
  number = {1},
  pages = {73--85},
  issn = {0729-4360, 1469-8366},
  doi = {10/ccdmd9},
  urldate = {2021-07-12},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/4BWQJ2NP/biggsTheoryPracticeCognitive1993.pdf}
}

@article{biggsWhatStudentDoes1999,
  title = {What the {{Student Does}}: Teaching for Enhanced Learning},
  shorttitle = {What the {{Student Does}}},
  author = {Biggs, John},
  year = {1999},
  month = apr,
  journal = {Higher Education Research \& Development},
  volume = {18},
  number = {1},
  pages = {57--75},
  issn = {0729-4360, 1469-8366},
  doi = {10/drgphk},
  urldate = {2021-07-12},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/V8K4XEJ3/biggsWhatStudentDoes1999.pdf}
}

@incollection{bigumNewInformationTechnologies2005,
  title = {New {{Information Technologies}} and the {{Ambiguous Future}} of {{Schooling}} --- {{Some Possible Scenarios}}},
  booktitle = {Extending {{Educational Change}}},
  author = {Bigum, Chris and Kenway, Jane},
  editor = {Hargreaves, Andy},
  year = {2005},
  pages = {95--115},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/1-4020-4453-4_5},
  urldate = {2022-12-31},
  isbn = {978-1-4020-3291-2 978-1-4020-4453-3},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/8ZFLJ7QT/bigumNewInformationTechnologies2005.pdf}
}

@article{bilgicIssuesChallengesWebBased2020,
  title = {Issues and {{Challenges}} in {{Web-Based Distance Education Programs}} in {{Turkish Higher Education Institutes}}},
  author = {Bilgic, Hatice Gokce and Tuzun, Hakan},
  year = {2020},
  journal = {Turkish Online Journal of Distance Education},
  volume = {21},
  number = {1},
  pages = {143--164},
  issn = {EISSN-1302-6488},
  abstract = {This study aimed to examine the core issues and challenges with web-based distance education programs in Turkish higher education institutes. Formative research method, which is a qualitative research method in nature, was selected to analyze web-based distance education programs thoroughly. The study group comprised 4 higher education institutes, offering web-based distance education services in 2014-2015, located in different provinces of different geographical regions in Turkey, and with varying experiences. The research used interview transcripts from semi-structured interviews, documents (weekly reports, meeting reports, presentations, organization chart, and implementation procedures) shared by the distance education centers, and information gathered from their web sites. Primary research data were compiled from interviews with representatives of the distance education centers managing and upholding distance education services while the documents acquired from these centers were used to verify the interview findings. The study resulted in 9 core issues related to (1) program launching process, (2) legislation, (3) program structure, (4) instructional design, (5) assessment and evaluation, (6) communication and interaction, (7) support, (8) technical issues, and (9) program evaluation.},
  langid = {english},
  keywords = {Distance Education,Educational Assessment,Educational Objectives,Educational Technology,Foreign Countries,Higher Education,Instructional Design,Legislation,No DOI found,Program Design,Program Development,Program Evaluation,Web Based Instruction}
}

@article{birchPreserviceTeachersAcceptance2009,
  title = {Preservice Teachers' Acceptance of {{ICT}} Integration in the Classroom: Applying the {{UTAUT}} Model},
  shorttitle = {Preservice Teachers' Acceptance of {{ICT}} Integration in the Classroom},
  author = {Birch, A. and Irvine, V.},
  year = {2009},
  month = dec,
  journal = {Educational Media International},
  volume = {46},
  number = {4},
  pages = {295--315},
  issn = {0952-3987, 1469-5790},
  doi = {10.1080/09523980903387506},
  urldate = {2023-09-21},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/EF9GUZ79/birchPreserviceTeachersAcceptance2009.pdf}
}

@book{birenbaumAlternativesAssessmentAchievements1995,
  title = {Alternatives in Assessment of Achievements, Learning Processes and Prior Knowledge},
  editor = {Birenbaum, Menucha and Dochy, Filip},
  year = {1995},
  series = {Evaluation in Education and Human Services},
  publisher = {Kluwer Acad. Publ},
  address = {Boston u.a},
  isbn = {0-7923-9615-4},
  keywords = {Lehrerverhalten,Lernbehinderung,Lernerfolg,Mathematikunterricht,Messung,Naturwissenschaftlicher Unterricht,Problemlosen,Schulerfolg,Schulische Motivation,Schulklasse,Schulleistung,Sprachunterricht,Test,Testkonstruktion,Testtheorie,Validitat},
  file = {/Users/colin.madland/Zotero/storage/FU8W7J7C/birenbaumAlternativesAssessmentAchievements1995.pdf}
}

@incollection{birenbaumAssessment2000Pluralistic1996,
  title = {Assessment 2000: {{Towards}} a Pluralistic Approach to Assessment},
  booktitle = {Alternatives in Assessment of Achievements, Learning Processes and Prior Knowledge},
  author = {Birenbaum, Menucha},
  editor = {Birenbaum, Menucha and Dochy, F.J.R.C.},
  year = {1996},
  volume = {42},
  pages = {3--29},
  publisher = {Kluwer Academic/Plenum Publishers},
  file = {/Users/colin.madland/Zotero/storage/6E3BCN2D/birenbaumAssessment2000Pluralistic1996.pdf}
}

@incollection{birenbaumAssessmentCultureTesting2016,
  title = {Assessment {{Culture Versus Testing Culture}}: {{The Impact}} on {{Assessment}} for {{Learning}}},
  shorttitle = {Assessment {{Culture Versus Testing Culture}}},
  booktitle = {Assessment for {{Learning}}: {{Meeting}} the {{Challenge}} of {{Implementation}}},
  author = {Birenbaum, Menucha},
  editor = {Laveault, Dany and Allal, Linda},
  year = {2016},
  volume = {4},
  pages = {275--292},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-39211-0_16},
  urldate = {2022-05-07},
  isbn = {978-3-319-39209-7 978-3-319-39211-0},
  file = {/Users/colin.madland/Zotero/storage/YXU7AKZZ/birenbaumAssessmentCultureTesting2016.pdf}
}

@article{birenbaumAssessmentInstructionPreferences2007,
  title = {Assessment and {{Instruction Preferences}} and {{Their Relationship}} with {{Test Anxiety}} and {{Learning Strategies}}},
  author = {Birenbaum, Menucha},
  year = {2007},
  journal = {Higher Education},
  volume = {53},
  number = {6},
  pages = {749--768},
  publisher = {Springer},
  issn = {00181560, 1573174X},
  doi = {10/cqgvs8},
  urldate = {2021-07-16},
  abstract = {[The relationship between assessment and instruction preferences of undergraduate students was examined as well as the extent to which the combined set of preferences differentiates among four groups of students defined by their levels of test anxiety and learning strategies (high in both, low in both or high in one and low in the other). The results indicated a perceived alignment between instruction and assessment with respect to preferences and lent support to the integrated model of test anxiety. The discussion highlighted the need for a dialogue between instructors and students in order to structure expectations to fit the goals of higher education in the knowledge age.]},
  file = {/Users/colin.madland/Zotero/storage/SAYECUPQ/birenbaumAssessmentInstructionPreferences2007.pdf}
}

@incollection{birenbaumConceptualizingAssessmentCulture2014,
  title = {Conceptualizing {{Assessment Culture}} in {{School}}},
  booktitle = {Designing {{Assessment}} for {{Quality Learning}}},
  author = {Birenbaum, Menucha},
  editor = {{Wyatt-Smith}, Claire and Klenowski, Valentina and Colbert, Peta},
  year = {2014},
  volume = {1},
  pages = {285--302},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-94-007-5902-2_18},
  urldate = {2022-07-01},
  isbn = {978-94-007-5901-5 978-94-007-5902-2},
  file = {/Users/colin.madland/Zotero/storage/L68G9IG5/birenbaumConceptualizingAssessmentCulture2014.pdf}
}

@article{birenbaumInternationalTrendsImplementation2015,
  title = {International Trends in the Implementation of Assessment for Learning: {{Implications}} for Policy and Practice},
  shorttitle = {International Trends in the Implementation of Assessment for Learning},
  author = {Birenbaum, Menucha and DeLuca, Christopher and Earl, Lorna and Heritage, Margaret and Klenowski, Val and Looney, Anne and Smith, Kari and Timperley, Helen and Volante, Louis and {Wyatt-Smith}, Claire},
  year = {2015},
  month = jan,
  journal = {Policy Futures in Education},
  volume = {13},
  number = {1},
  pages = {117--140},
  issn = {1478-2103, 1478-2103},
  doi = {10.1177/1478210314566733},
  urldate = {2022-07-27},
  abstract = {This paper discusses the emergence of assessment for learning (AfL) across the globe with particular attention given to Western educational jurisdictions. Authors from Australia, Canada, Ireland, Israel, New Zealand, Norway, and the USA explain the genesis of AfL, its evolution and impact on school systems, and discuss current trends in policy directions for AfL within their respective countries. The authors also discuss the implications of these various shifts and the ongoing tensions that exist between A fL and summative forms of assessment within national policy initiatives.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/SCDWEXEI/birenbaumInternationalTrendsImplementation2015.pdf}
}

@incollection{birenbaumNewInsightsLearning2003,
  title = {New Insights into Learning and Teaching and Their Implications for Assessment},
  booktitle = {Opti- Mising New Modes of Assessment: {{In}} Search of Qualities and Standards},
  author = {Birenbaum, Menucha},
  editor = {Segers, M and Dochy, F and Cascallar, E},
  year = {2003},
  pages = {13--36},
  publisher = {Kluwer Academic Publishers},
  file = {/Users/colin.madland/Zotero/storage/SU3MSZPY/birenbaumNewInsightsLearning2003.pdf}
}

@article{Black_2003,
  title = {In Praise of Educational Research Formative Assessment},
  author = {Black, Paul and Wiliam, Dylan},
  year = {2003},
  journal = {British Educational Research Journal},
  doi = {10/dxqk5n},
  abstract = {The authors trace the development of the King's Formative Assessment Programme from its origins in diagnostic testing in the 1970s, through the graded assessment movement in the 1980s, to the present day. In doing so, they discuss the practical issues involved in reviewing research and outline the strategies that were used to try to communicate the findings to as wide an audience as possible (including policy-makers and practitioners as well as academics). They describe how they worked with teachers to develop formative practice in classrooms, and discuss the impact that this work has had on practice and policy. Finally, they speculate about some of the reasons for this impact, and make suggestions for how the impact of educational research on policy and practice might be improved.},
  mag_id = {1995595894},
  pmcid = {null},
  pmid = {null},
  keywords = {guskey}
}

@article{blackAssessmentClassroomLearning1998,
  ids = {Black_1998},
  title = {Assessment and {{Classroom Learning}}},
  author = {Black, Paul and Wiliam, Dylan},
  year = {1998},
  month = mar,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {5},
  number = {1},
  pages = {7--74},
  issn = {0969-594X, 1465-329X},
  doi = {10/fpnss4},
  urldate = {2020-10-31},
  langid = {english},
  mag_id = {1967555382},
  pmcid = {null},
  pmid = {null},
  keywords = {guskey},
  file = {/Users/colin.madland/Zotero/storage/RKJ2393I/blackAssessmentClassroomLearning1998.pdf}
}

@article{blackBlackBoxRaising1998,
  title = {Inside the Black Box: Raising Standards through Classroom Assessment},
  author = {Black, Paul and Wiliam, Dylan},
  year = {1998},
  month = oct,
  journal = {Phi Delta Kappan},
  volume = {80},
  number = {2},
  pages = {139+},
  issn = {00317217},
  urldate = {2022-05-08},
  chapter = {139},
  langid = {english},
  keywords = {Educational assessment,Learning},
  file = {/Users/colin.madland/Zotero/storage/FDV6ASKA/blackBlackBoxRaising1998.pdf}
}

@article{blackburnPerformingOnlineApproaches2017,
  title = {Performing Online: {{Approaches}} to Teaching Performance Studies in Higher Education within a Fully Online Environment},
  author = {Blackburn, Alana},
  year = {2017},
  journal = {Australian Journal of Music Education},
  volume = {51},
  number = {1},
  pages = {63--72},
  abstract = {Online education is becoming prevalent across the higher education sector and requires new approaches to teaching and learning. As music is seen as a `hands on' discipline, there has been a very gradual move toward the use of online technologies in music teaching in tertiary education, especially in the area of performance studies. By surveying existing scholarly research, this article investigates the technology available to consider the possibility of teaching performance studies within a fully online environment. Today, music students are also required to develop meta-skills such as social networking, entrepreneurism, self-management, self-regulation, and self-reflection. Through a constructivist teaching and learning paradigm, this article explores how online technology in instrumental or performance studies can support and develop these essential proficiencies as well as continuing to develop technical skills. This study serves as a foundation for further systematic research, and a practical application for online music education. Key words: music education and training, music performance, higher education, eLearning, online education.},
  langid = {english},
  keywords = {Constructivism (Learning),Educational Technology,Electronic Learning,Evaluation Methods,Foreign Countries,Higher Education,Music Education,Music Techniques,No DOI found,Online Courses,Performance,Student Evaluation,Teaching Methods,Transformative Learning},
  file = {/Users/colin.madland/Zotero/storage/YQQ4TPBV/blackburnPerformingOnlineApproaches2017.pdf}
}

@article{blackCanTeachersSummative2011,
  title = {Can Teachers' Summative Assessments Produce Dependable Results and Also Enhance Classroom Learning?},
  author = {Black, Paul and Harrison, Christine and Hodgen, Jeremy and Marshall, Bethan and Serret, Natasha},
  year = {2011},
  month = nov,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {18},
  number = {4},
  pages = {451--469},
  publisher = {Routledge},
  issn = {0969-594X},
  doi = {10/dk7gw9},
  file = {/Users/colin.madland/Zotero/storage/UMFPGUNH/blackCanTeachersSummative2011.pdf}
}

@article{blackClassroomAssessmentPedagogy2018,
  title = {Classroom Assessment and Pedagogy},
  author = {Black, Paul and Wiliam, Dylan},
  year = {2018},
  month = nov,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {25},
  number = {6},
  pages = {551--575},
  issn = {0969-594X, 1465-329X},
  doi = {10.1080/0969594X.2018.1441807},
  urldate = {2022-07-13},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/FSR3I73D/blackClassroomAssessmentPedagogy2018.pdf}
}

@article{blackDevelopingTheoryFormative2009,
  title = {Developing the Theory of Formative Assessment},
  author = {Black, Paul and Wiliam, Dylan},
  year = {2009},
  journal = {Educational Assessment, Evaluation and Accountability},
  volume = {21},
  doi = {10.1007/s11092-008-9068-5},
  abstract = {Whilst many definitions of formative assessment have been offered, there is no clear rationale to define and delimit it within broader theories of pedagogy. This paper aims to offer such a rationale, within a framework which can also unify the diverse set of practices which have been described as formative. The analysis is used to relate formative assessment both to other pedagogic initiatives, notably cognitive acceleration and dynamic assessment, and to some of the existing literature on models of self-regulated learning and on classroom discourse. This framework should indicate potentially fruitful lines for further enquiry, whilst at the same time opening up new ways of helping teachers to implement formative practices more effectively.},
  mag_id = {1984748091},
  pmcid = {null},
  pmid = {null},
  keywords = {guskey},
  file = {/Users/colin.madland/Zotero/storage/E5KNBSUQ/blackDevelopingTheoryFormative2009.pdf}
}

@unpublished{blackstockBreathLifeEmbodiment2007,
  title = {The Breath of Life versus the Embodiment of Life: Indigenous Knowledge and Western Research},
  author = {Blackstock, Cindy},
  year = {2007},
  month = jan
}

@article{blauDigitalTechnologiesPromoting2018,
  title = {Digital Technologies for Promoting "Student Voice" and Co-Creating Learning Experience in an Academic Course},
  author = {Blau, Ina and {Shamir-Inbal}, Tamar},
  year = {2018},
  journal = {Instructional science},
  volume = {46},
  number = {2},
  pages = {315--336},
  publisher = {Springer},
  address = {Dordrecht},
  issn = {0020-4277},
  doi = {10.1007/s11251-017-9436-y},
  abstract = {"Student voice" (SV) refers to listening to and valuing students' views regarding their learning experiences, as well as treating them as equal partners in the evaluation process. This is expected, in turn, to empower students to take a more active role in shaping their learning. This study explores the role played by digital technologies in creating a space for SV in academia. The qualitative study was conducted in an academic course, which combines face-to face, synchronous lessons with a variety of asynchronous self-directed and group learning activities. The participants were 54 Master's students in education. We analyzed the pedagogical design of the course, as well as interpretations of teaching, learning, assessment, and the role of technology as experienced and presented by the students. The findings demonstrated that students functioned as co-designers of the course content, co-creators of teaching and of their own learning experience. Students perceived the requirements of active learning, teamwork, and community participation (i.e., an advanced way of conveying SV---leadership; Mitra International handbook of student experience in elementary and secondary school, Springer Publishers, The Netherlands, 2007), as both challenges related to overload and stress, and benefits related to the gains of meaningful learning, innovative pedagogical design, and diverse instructional methods. The equalization effect of the digital environment, which diminishes status cues changed the power dynamic, promoted students' active participation and their pedagogical partnership with the instructor. Based on the findings, our conceptualization of SV and its implications for academia includes: (1) co-design of content, (2) co-teaching, (3) co-creation of learning experience and outcomes, and (4) embedded co-assessment for learning.},
  keywords = {Active Learning,Analysis,Asynchronous Communication,Blended Learning,Community participation,Computer Mediated Communication,Cooperative Learning,Cues,Design,Education,Education & Educational Research,Educational Attitudes,Educational Psychology,Educational Technology,Graduate Students,Group learning,Group work in education,Higher education,Independent Study,Information technology,Instructional Design,Instructional Innovation,Leadership,Learner Controlled Instruction,Learning,Learning Activities,Learning and Instruction,Listening,Masters Programs,Pedagogic Psychology,Pedagogy,Power Structure,Psychology,Psychology Educational,Qualitative Research,Secondary schools,Social Sciences,Stress Variables,Student Attitudes,Student Centered Learning,Student Empowerment,Students,Synchronous Communication,Teacher Student Relationship,Teaching,Teaching Methods,Team learning approach in education,Team Teaching,Teamwork,Technology}
}

@article{blayoneTheorisingEffectiveUses2019,
  title = {Theorising Effective Uses of Digital Technology with Activity Theory},
  author = {Blayone, Todd J. B.},
  year = {2019},
  month = aug,
  journal = {Technology, Pedagogy and Education},
  volume = {28},
  number = {4},
  pages = {447--462},
  issn = {1475-939X, 1747-5139},
  doi = {10.1080/1475939X.2019.1645728},
  urldate = {2022-05-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/9392W3B7/blayoneTheorisingEffectiveUses2019.pdf}
}

@article{blegurPeerAssessmentAcademicIntegrity2024,
  title = {Peer-{{Assessment Academic Integrity Scale}} ({{PAAIS-24}})},
  author = {Blegur, Jusuf and Subarjah, Herman and Hidayat, Yusuf and Ma'amun, Amung and Mahendra, Agus and Mahardika, I Made Sriundy and Hardiansyah, Sefri},
  year = {2024},
  month = apr,
  journal = {Emerging Science Journal},
  volume = {8},
  number = {2},
  pages = {513--526},
  issn = {2610-9182},
  doi = {10.28991/ESJ-2024-08-02-09},
  urldate = {2024-11-05},
  abstract = {This study aims to develop an academic integrity scale to help lecturers evaluate the academic integrity of university students with peer-assessment learning experiences using the ADDIE research and development method. Twenty-four items were designed using the concepts of academic integrity; honesty, trust, fairness, respect, responsibility, and courage validated by six raters and tested on 520 students from various universities in Indonesia. Testing content validity using the Aiken-V formula, construct validity testing using discriminant indexes, factor analysis (Exploratory and Confirmatory Factor Analysis), and concurrent validity testing by correlating PAAIS-24 with the developed Academic Integrity Scale. While the reliability test used Cronbach's alpha formula. The study results proved that each item of content validity meets with an Aiken value {$>$}0.80; on construct validity testing, the discriminant index value is {$>$}0.50, and the EFA and CFA loading factor values are {$>$}0.50. In addition, the model is appropriate because the theoretical model of PAAIS-24 is in accordance with empirical data. Whereas in reliability testing, Cronbach's alpha value is 0.95. Lastly, PAAIS-24 is one of the credible instruments. It contributes to developing knowledge that assists lecturers in measuring, assessing, and evaluating student academic integrity based on peer-assessment to promote increased academic performance.~Doi: 10.28991/ESJ-2024-08-02-09 Full Text: PDF},
  file = {/Users/colin.madland/Zotero/storage/blegurPeerAssessmentAcademicIntegrity2024.pdf}
}

@article{blissOERCOUPCollege2013,
  title = {An {{OER COUP}}: {{College}} Teacher and Student Perceptions of Open Education Resources},
  author = {Bliss, T. J. and Robinson, T. and Hilton, John and Wiley, David},
  year = {2013},
  month = feb,
  journal = {Journal of Interactive Media in Education},
  volume = {2013},
  doi = {10.5334/2013-04},
  abstract = {Despite increased development and dissemination, there has been very little empirical research on Open Educational Resources (OER). Teachers and students involved in a large-scale OER initiative at eight community colleges across the United States were given a detailed questionnaire aimed at uncovering their perceptions of the cost, outcomes, uses and perceptions of quality of the OER used in their courses. Teachers and students alike reported significant cost savings and various pedagogical and learning impacts due to the implementation of OER in the classroom. In addition, most students and teachers perceived their OER to be at least equal in quality to traditional textbooks they had used in the past. Implications for further research are discussed.},
  keywords = {oer,open educational resources,quality}
}

@article{blondeelStimulatingHigherEducation2021,
  title = {Stimulating Higher Education Students to Use Online Formative Assessments: The Case of Two Mid-Term Take-Home Tests},
  author = {Blondeel, Eva and Everaert, Patricia and Opdecam, Evelien},
  year = {2021},
  journal = {Assessment and evaluation in higher education},
  number = {Journal Article},
  pages = {1--16},
  issn = {0260-2938},
  doi = {10/gmb8hp}
}

@article{bloomLearningMasteryInstruction1968,
  title = {Learning for {{Mastery}}. {{Instruction}} and {{Curriculum}}. {{Regional Education Laboratory}} for the {{Carolinas}} and {{Virginia}}, {{Topical Papers}} and {{Reprints}}, {{Number}} 1.},
  author = {Bloom, Benjamin},
  year = {1968},
  journal = {Evaluation Comment},
  volume = {1},
  number = {2},
  pages = {12},
  urldate = {2021-07-07},
  abstract = {Most students, perhaps over 90 percent, can master what teachers have to teach them, and it is the task of instruction to find the means which will enable students to master the subject under consideration. A basic task is to determine what is meant by mastery of the subject and to search for methods and materials which will enable the largest proportion of students to attain such mastery. That is, the basic task in education is to find strategies which will take individual differences into consideration but in such a way as to promote the fullest development of the individual. The thesis of this paper is that, to promote mastery learning, 5 variables must be dealt with effectively: (1) aptitude for kinds of learning, viewed as the amount of time required by the learner to attain mastery of the task; (2) quality of instruction, viewed in terms of its approaching the optimum for a given learner; (3) ability to understand instruction, i.e., to understand the nature of the task and the procedures to follow; (4) perseverance, the amount of time one is willing to spend in learning; and (5) time allowed for learning, the key to mastery. (Author/TA)},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/SKUGACVJ/bloomLearningMasteryInstruction1968.pdf}
}

@article{bloomSigmaProblemSearch1984,
  title = {The 2 Sigma Problem: {{The}} Search for Methods of Group Instruction as Effective as One-to-One Tutoring},
  author = {Bloom, Benjamin},
  year = {1984},
  journal = {Educational Researcher},
  volume = {13},
  pages = {4--16},
  keywords = {2 sigma},
  file = {/Users/colin.madland/Zotero/storage/5Q5VBABB/bloomSigmaProblemSearch1984.pdf}
}

@article{blundellScopingReviewApplication2022,
  title = {A Scoping Review of the Application of the {{SAMR}} Model in Research},
  author = {Blundell, Christopher N. and Mukherjee, Michelle and Nykvist, Shaun},
  year = {2022},
  journal = {Computers and Education Open},
  volume = {3},
  pages = {100093},
  issn = {26665573},
  doi = {10.1016/j.caeo.2022.100093},
  urldate = {2023-01-19},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/LV5DSKQC/blundellScopingReviewApplication2022.pdf}
}

@article{blundellTeacherUseDigital2021,
  title = {Teacher Use of Digital Technologies for School-Based Assessment: A Scoping Review},
  shorttitle = {Teacher Use of Digital Technologies for School-Based Assessment},
  author = {Blundell, Christopher N.},
  year = {2021},
  month = may,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {28},
  number = {3},
  pages = {279--300},
  issn = {0969-594X, 1465-329X},
  doi = {10.1080/0969594X.2021.1929828},
  urldate = {2022-04-07},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/Y7SNJV8E/blundellTeacherUseDigital2021.pdf}
}

@article{bocanetChangeGapPerception2021a,
  title = {Change in {{Gap Perception}} within {{Current Practices}} in {{Assessing Students Learning Mathematics}}},
  author = {Bocanet, Vlad I. and Brown, Ken and Uukkivi, Anne and Soares, Filomena and Lopes, Ana Paula and Cellmer, Anna and Serrat, Carles and Feniser, Cristina and Serdean, Florina M. and Safiulina, Elena and Kelly, Gerald and Cymerman, Joanna and Kierkosz, Igor and Sushch, Volodymyr and Latonina, Marina and Labanova, Oksana and Bruguera, M. Montserrat and Pantazi, Chara and Estela, M. Rosa},
  year = {2021},
  journal = {Sustainability (Basel, Switzerland)},
  volume = {13},
  number = {8},
  pages = {4495},
  publisher = {Mdpi},
  address = {BASEL},
  issn = {2071-1050},
  doi = {10.3390/su13084495},
  abstract = {The COVID pandemic has touched many aspects of everyone's life. Education is one of the fields greatly affected by it, as students and teachers were forced to move online and quickly adapt to the online environment. Assessment is a crucial part of education, especially in STEM fields. A gap analysis was performed by expert groups in the frame of an Erasmus+ project looking at the practices of six European countries. Specialists teaching university-grade mathematics in seven European institutions were asked about their perception of gaps in the assessment of students both before (2019) and during (2021) the pandemic. This qualitative study looks at the difference in perception of such gaps after almost one year of online teaching. The analysis of their responses showed that some gaps were present before the pandemic, as well as others that are specific to it. Some gaps, such as the lack of IT infrastructure and the need to adapt materials to an online environment, have been exacerbated by the outbreak.},
  keywords = {CAI,Colleges & universities,Computer assisted instruction,Curricula,Design,Distance learning,e-assessment,Education,Engineering,Environmental Sciences,Environmental Sciences & Ecology,Environmental Studies,Feedback,Gap analysis,gap analysis method,Green & Sustainable Science & Technology,Higher education,Internet access,Learning management systems,Life Sciences & Biomedicine,Mathematical analysis,Mathematics,online education,Online instruction,Pandemics,Perception,School environment,Science & Technology,Science & Technology - Other Topics,Skills,student assessment,Students,Teachers,Teaching,Technical education},
  file = {/Users/colin.madland/Zotero/storage/HEBZWJYF/bocanetChangeGapPerception2021a.pdf}
}

@article{boelensFourKeyChallenges2017,
  title = {Four Key Challenges to the Design of Blended Learning: {{A}} Systematic Literature Review},
  shorttitle = {Four Key Challenges to the Design of Blended Learning},
  author = {Boelens, Ruth and De Wever, Bram and Voet, Michiel},
  year = {2017},
  month = nov,
  journal = {Educational Research Review},
  volume = {22},
  pages = {1--18},
  issn = {1747938X},
  doi = {10/gfb5zw},
  urldate = {2021-01-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/VPDEDBHH/boelensFourKeyChallenges2017a.pdf}
}

@article{boelensFourKeyChallenges2017a,
  title = {Four Key Challenges to the Design of Blended Learning: {{A}} Systematic Literature Review},
  shorttitle = {Four Key Challenges to the Design of Blended Learning},
  author = {Boelens, Ruth and De Wever, Bram and Voet, Michiel},
  year = {2017},
  month = nov,
  journal = {Educational Research Review},
  volume = {22},
  pages = {1--18},
  issn = {1747938X},
  doi = {10/gfb5zw},
  urldate = {2021-01-24},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/R32HIHT7/boelensFourKeyChallenges2017.pdf}
}

@techreport{bommineniPerformanceChatGPTMCAT2023,
  type = {Preprint},
  title = {Performance of {{ChatGPT}} on the {{MCAT}}: {{The Road}} to {{Personalized}} and {{Equitable Premedical Learning}}},
  shorttitle = {Performance of {{ChatGPT}} on the {{MCAT}}},
  author = {Bommineni, Vikas L and Bhagwagar, Sanaea and Balcarcel, Daniel and Davatzikos, Christos and Boyer, Donald},
  year = {2023},
  month = mar,
  institution = {Medical Education},
  doi = {10.1101/2023.03.05.23286533},
  urldate = {2023-11-02},
  abstract = {ABSTRACT           Despite an increasingly diverse population, an unmet demand for undergraduates from underrepresented racial and ethnic minority (URM) backgrounds exists in the field of medicine as a result of financial hurdles and insufficient educational support faced by URM students in the premedical journey. With the capacity to provide highly individualized and accessible no- or low-cost dynamic instruction, large language models (LLMs) and their chatbot derivatives are posed to change this dynamic and subsequently help shape a more diverse future physician workforce. While studies have established the passing performance and insightful explanations of one of the most accurate LLM-powered chatbots to date---Chat Generative Pre-trained Transformer (ChatGPT)---on standardized exams such as medical licensing exams, the role of ChatGPT in premedical education remains unknown. We evaluated the performance of ChatGPT on the Medical College Admission Test (MCAT), a standardized 230-question multiple choice exam that assesses a broad range of competencies in the natural, physical, social, and behavioral sciences as well as critical analysis and reasoning. Depending on its visual item response strategy, ChatGPT performed at or above the median performance of 276,779 student test takers on the MCAT. Additionally, ChatGPT-generated answers demonstrated both a high level of agreement with the official answer key as well as insight into its explanations. Based on these promising results, we anticipate two primary applications of ChatGPT and future LLM iterations in premedical education: firstly, such models could provide free or low-cost access to personalized and insightful explanations of MCAT competency-related questions to help students from all socioeconomic and URM backgrounds. Secondly, these models could be used to generate additional test questions by test-makers or for targeted preparation by pre-medical students. These applications of ChatGPT in premedical education could be an invaluable, innovative path forward to increase diversity and improve equity among premedical students.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/IQBRYAVV/bommineniPerformanceChatGPTMCAT2023.pdf}
}

@article{bondMetaSystematicReview2023,
  title = {A {{Meta Systematic Review}} of {{Artificial Intelligence}} in {{Higher Education}}: {{A}} Call for Increased Ethics, Collaboration, and Rigour},
  shorttitle = {A {{Meta Systematic Review}} of {{Artificial Intelligence}} in {{Higher Education}}},
  author = {Bond, Melissa and Khosravi, Hassan and De Laat, Maarten and Bergdahl, Nina and Negrea, Violeta and Oxley, Emily and Pham, Phuong and Chong, Sin Wang and Siemens, George},
  year = {2023},
  publisher = {Unpublished},
  doi = {10.13140/RG.2.2.31921.56162/1},
  urldate = {2023-10-10},
  abstract = {Although the field of Artificial Intelligence in Education (AIEd) has a substantial history as a research domain, never before has the rapid evolution of AI applications in education sparked such prominent public discourse. Given the growing AIEd literature base in higher education, it is important to ensure that the field has a solid research and conceptual grounding as AI adoption increases. This review of reviews is the first comprehensive meta review to explore the scope and nature of AIEd in higher education (AIHEd) research, by synthesising secondary research (e.g., systematic reviews), indexed in the Web of Science, Scopus, ERIC, EBSCOHost, IEEE Xplore, ScienceDirect and ACM Digital Library, or captured through snowballing in OpenAlex, ResearchGate and Google Scholar. Reviews were included if they synthesised applications of AI solely in formal higher or continuing education, were published in English between 2018 and July 2023, were journal articles or full conference papers, and if they had a method section. 66 publications were included for data extraction and synthesis in EPPI Reviewer, which were predominantly systematic reviews (66.7\%), published by authors from North America (27.3\%), conducted in teams (89.4\%) in mostly domestic-only collaborations (71.2\%). Findings show that these reviews mostly focused on AIHEd generally (47.0\%) or Profiling and Prediction (28.8\%) as thematic foci, however key findings indicated a predominance of the use of Adaptive Systems and Personalisation in higher education. Research gaps identified suggest a need for greater ethical, methodological, and contextual considerations within future research, alongside interdisciplinary approaches to AIHEd application. Suggestions are provided to guide future primary and secondary research.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/VTR6ZNBA/bondMetaSystematicReview2023.pdf}
}

@article{bonnerLargeLanguageModelbased2023,
  title = {Large Language Model-Based Artificial Intelligence in the Language Classroom: Practical Ideas for Teaching},
  shorttitle = {Large Language Model-Based Artificial Intelligence in the Language Classroom},
  author = {Bonner, Euan and Lege, Ryan and Frazier, Erin},
  year = {2023},
  journal = {Teaching English With Technology},
  volume = {2023},
  number = {1},
  issn = {16421027},
  doi = {10.56297/BKAM1691/WIEO1749},
  urldate = {2023-09-23},
  file = {/Users/colin.madland/Zotero/storage/WJYLFVBR/bonnerLargeLanguageModelbased2023.pdf}
}

@article{boothPeerReviewAssessment2016,
  title = {Peer {{Review}} of {{Assessment Network}}: {{Supporting Comparability}} of {{Standards}}},
  author = {Booth, Sara and Beckett, Jeff and Saunders, Cassandra},
  year = {2016},
  month = jan,
  journal = {Quality Assurance in Education: An International Perspective},
  volume = {24},
  number = {2},
  pages = {194--210},
  publisher = {Quality Assurance in Education: An International Perspective},
  issn = {0968-4883},
  doi = {10.1108/QAE-01-2015-0003},
  abstract = {Purpose: This paper aims to test the need in the Australian higher education (HE) sector for a national network for the peer review of assessment in response to the proposed HE standards framework and propose a sector-wide framework for calibrating and assuring achievement standards, both within and across disciplines, through the establishment of a peer review of assessment network (PRAN). Design/methodology/approach: This study used a "proof of concept" approach to test the need for a national network, using consultations (n = 67) which included teleconference meetings [39], face-to-face meetings [2], Skype [1], presentations [19], state-based workshops [6] and a national forum. Quantitative data from evaluation surveys from state-based workshops and national forum were computer-analysed to generate descriptive statistics. Qualitative data arising from open-ended questionnaire responses were analysed through progressive categorisation and data coding designed to identify and refine data themes. Findings: In all, 63 per cent of participants to the state-based workshops were satisfied with the workshop content. A further 29 per cent reported a high level of satisfaction. The interactive group discussions fostered a collaborative approach and facilitated engagement with the workshop content. A total of 58 per cent of participants to the national forum were satisfied with the forum, with a further 40 per cent reporting a high level of satisfaction. Participants indicated that presentation content was informative and covered a diverse range of topics and viewpoints highly relevant to the current clime across the HE sector. Practical implications: Many participants strongly supported the establishment of a national PRAN, with overwhelming support (88 per cent) for the forum to be made an annual event. Originality/value: This study contributes to existing literature and provides further evidence for the value of networks in the peer review of assessment to support academics in professional learning and calibration exercises.},
  keywords = {Academic Achievement,Academic Standards,Australia,Capacity Building,Coding,Communities of Practice,Consultants,Consultation Programs,Educational Assessment,Foreign Countries,Higher Education,Meetings,Needs Assessment,Networks,Peer Evaluation,Quality Assurance,Questionnaires,Satisfaction,Statistical Analysis,Surveys,Teleconferencing,Workshops}
}

@article{bopegederaUsingFamiliarNew2020,
  title = {Using {{Familiar}} and {{New Assessment Tools}} in {{Physical Chemistry Courses During COVID-19}}},
  author = {Bopegedera, A. M. R. P},
  year = {2020},
  journal = {Journal of chemical education},
  volume = {97},
  number = {9},
  pages = {3260--3264},
  publisher = {{American Chemical Society and Division of Chemical Education, Inc}},
  address = {WASHINGTON},
  issn = {0021-9584},
  doi = {10.1021/acs.jchemed.0c00789},
  abstract = {A fast track into online teaching in response to the COVID-19 crisis resulted in the author learning to use online platforms and tools to teach thermodynamics and quantum mechanics courses. These resources were used effectively to teach highly mathematical and challenging concepts, as presented in this communication. Student assessment using traditional (exams) and novel (projects) approaches are highlighted, especially the use of projects that examined students' ability to apply their knowledge to solve real world problems. A survey of students' responses to online learning revealed that they felt supported during the COVID-19 crisis and the teaching tools described in this work were successful in helping them learn. These students who completed parts of the two courses in face-to-face classes in previous quarters overwhelmingly preferred in-person instruction. The pedagogical approaches described in the communication were shared informally with fellow science faculty at the college. They may be successful in teaching other chemistry courses and STEM fields. The author feels better prepared for teaching online in the future as a result of this teaching experience.},
  keywords = {CAI,Chemistry,Chemistry Multidisciplinary,College Science,Colleges & universities,Computer assisted instruction,COVID-19,Distance Education,Education & Educational Research,Education Scientific Disciplines,Electronic Learning,Evaluation,Learning,Mechanics (Physics),Methods,Novels,Online Courses,Online instruction,Pandemics,Physical chemistry,Physical Sciences,Quantum Mechanics,School Closing,Science & Technology,Science Instruction,Social Sciences,STEM education,Student Attitudes,Student Evaluation,Students,Teaching,Thermodynamics,Undergraduate Study,World problems},
  file = {/Users/colin.madland/Zotero/storage/4J3JTMAR/bopegederaUsingFamiliarNew2020.pdf}
}

@article{bopegederaUsingFamiliarNew2020a,
  title = {Using {{Familiar}} and {{New Assessment Tools}} in {{Physical Chemistry Courses During COVID-19}}},
  author = {Bopegedera, A. M. R. P},
  year = {2020},
  journal = {Journal of chemical education},
  volume = {97},
  number = {9},
  pages = {3260--3264},
  publisher = {{American Chemical Society and Division of Chemical Education, Inc}},
  address = {WASHINGTON},
  issn = {0021-9584},
  doi = {10.1021/acs.jchemed.0c00789},
  abstract = {A fast track into online teaching in response to the COVID-19 crisis resulted in the author learning to use online platforms and tools to teach thermodynamics and quantum mechanics courses. These resources were used effectively to teach highly mathematical and challenging concepts, as presented in this communication. Student assessment using traditional (exams) and novel (projects) approaches are highlighted, especially the use of projects that examined students' ability to apply their knowledge to solve real world problems. A survey of students' responses to online learning revealed that they felt supported during the COVID-19 crisis and the teaching tools described in this work were successful in helping them learn. These students who completed parts of the two courses in face-to-face classes in previous quarters overwhelmingly preferred in-person instruction. The pedagogical approaches described in the communication were shared informally with fellow science faculty at the college. They may be successful in teaching other chemistry courses and STEM fields. The author feels better prepared for teaching online in the future as a result of this teaching experience.},
  keywords = {CAI,Chemistry,Chemistry Multidisciplinary,College Science,Colleges & universities,Computer assisted instruction,COVID-19,Distance Education,Education & Educational Research,Education Scientific Disciplines,Electronic Learning,Evaluation,Learning,Mechanics (Physics),Methods,Novels,Online Courses,Online instruction,Pandemics,Physical chemistry,Physical Sciences,Quantum Mechanics,School Closing,Science & Technology,Science Instruction,Social Sciences,STEM education,Student Attitudes,Student Evaluation,Students,Teaching,Thermodynamics,Undergraduate Study,World problems}
}

@article{bornEvaluatingDifferentEquating2019,
  title = {Evaluating {{Different Equating Setups}} in the {{Continuous Item Pool Calibration}} for {{Computerized Adaptive Testing}}},
  author = {Born, Sebastian and Fink, Aron and Spoden, Christian and Frey, Andreas},
  year = {2019},
  month = jun,
  journal = {Frontiers in Psychology},
  volume = {10},
  pages = {1277},
  issn = {1664-1078},
  doi = {10/gk75pj},
  urldate = {2021-07-17},
  file = {/Users/colin.madland/Zotero/storage/D2JHGXTC/bornEvaluatingDifferentEquating2019.pdf}
}

@article{Borsboom_2005,
  title = {Measuring the Mind Conceptual Issues in Contemporary Psychometrics},
  author = {Borsboom, Denny},
  year = {2005},
  journal = {null},
  doi = {null},
  abstract = {Preface 1. Introduction 2. True scores 3. Latent variables 4. Scales 5. Relations between the models 6. The concept of validity References Index.},
  mag_id = {1575530397},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@article{borsboomTheoreticalStatusLatent2003,
  title = {The Theoretical Status of Latent Variables.},
  author = {Borsboom, Denny and Mellenbergh, Gideon J. and Van Heerden, Jaap},
  year = {2003},
  month = apr,
  journal = {Psychological Review},
  volume = {110},
  number = {2},
  pages = {203--219},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/0033-295X.110.2.203},
  urldate = {2024-07-25},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/B4X9JUG5/borsboomTheoreticalStatusLatent2003.pdf}
}

@article{bort-mirUsingPenzuAcademic2020,
  title = {Using {{Penzu}} for {{Academic Online Diaries}} to {{Enhance Metacognitive Skills}} in {{Higher Education}}},
  author = {{Bort-Mir}, Lorena},
  year = {2020},
  journal = {The EUROCALL Review},
  volume = {28},
  number = {2},
  pages = {50--63},
  issn = {EISSN-1695-2618},
  doi = {10/gmbvzz},
  abstract = {Metacognition can be considered as knowledge about one's own cognitive activities and their regulation during learning processes (Flavell, 1979). Students are, then, involved in metacognitive mental activities when they think about what they have learned, how they have learned it, or how they can relate it to their personal experiences, among other things. Based on this, students who develop these skills should show more appropriate strategies to know what they need to find out or do while learning. Therefore, understanding and controlling these cognitive processes may be one of the most essential skills that teachers should encourage at all academic levels (Anderson, 2002). The Guided Learning Diary (GLD, Bort-Mir, 2016) was developed as a learning diary with several aims: (i) defining the general and specific objectives of the content to be taught, (ii) developing the students' metacognitive skills through strategic questions, and (iii) promoting the development of important competences such as self-criticism, autonomous learning, self-evaluation and capacity for improvement. The GLD also allows a self-evaluation process for teachers, thus facilitating the supervision and improvement both of the contents of the course and the didactic methodology. This tool was developed and applied within the Theatre in English subject at Universitat Jaume I, embedded in the third course of the English Studies Degree, and the students' results were significantly higher than those of previous years (Bort-Mir \& Silvestre-L{\'o}pez, 2017). The present research proposes a technological turn in the application of the GLD with the use of the open-source tool Penzu. The creation of academic online diaries with this tool may improve students' motivation while promoting meaningful and self-regulated learning in Higher Education environments, thus helping students reach academic success. Penzu allows this investigation to widen the scope of the GLD to the general public.},
  langid = {english},
  keywords = {College Students,Electronic Publishing,Foreign Countries,Learning Strategies,Metacognition,Reflection,Skill Development,Student Journals,Teaching Methods}
}

@article{boscardinChatGPTGenerativeArtificial2023,
  title = {{{ChatGPT}} and {{Generative Artificial Intelligence}} for {{Medical Education}}: {{Potential Impact}} and {{Opportunity}}},
  shorttitle = {{{ChatGPT}} and {{Generative Artificial Intelligence}} for {{Medical Education}}},
  author = {Boscardin, Christy K. and Gin, Brian and Golde, Polo Black and Hauer, Karen E.},
  year = {2023},
  month = aug,
  journal = {Academic Medicine},
  issn = {1938-808X, 1040-2446},
  doi = {10.1097/ACM.0000000000005439},
  urldate = {2023-09-23},
  abstract = {Abstract             ChatGPT has ushered in a new era of artificial intelligence (AI) that already has significant consequences for many industries, including health care and education. Generative AI tools, such as ChatGPT, refer to AI that is designed to create or generate new content, such as text, images, or music, from their trained parameters. With free access online and an easy-to-use conversational interface, ChatGPT quickly accumulated more than 100 million users within the first few months of its launch. Recent headlines in the popular press have ignited concerns relevant to medical education over the possible implications of cheating and plagiarism in assessments as well as excitement over new opportunities for learning, assessment, and research. In this Scholarly Perspective, the authors offer insights and recommendations about generative AI for medical educators based on literature review, including the AI literacy framework. The authors provide a definition of generative AI, introduce an AI literacy framework and competencies, and offer considerations for potential impacts and opportunities to optimize integration of generative AI for admissions, learning, assessment, and medical education research to help medical educators navigate and start planning for this new environment. As generative AI tools continue to expand, educators need to increase their AI literacy through education and vigilance around new advances in the technology and serve as stewards of AI literacy to foster social responsibility and ethical awareness around the use of AI.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/77QK2AHD/boscardinChatGPTGenerativeArtificial2023.pdf}
}

@article{bossettaDigitalArchitecturesSocial2018,
  title = {The {{Digital Architectures}} of {{Social Media}}: {{Comparing Political Campaigning}} on {{Facebook}}, {{Twitter}}, {{Instagram}}, and {{Snapchat}} in the 2016 {{U}}.{{S}}. {{Election}}},
  author = {Bossetta, Michael},
  year = {2018},
  journal = {Journalism \& Mass Communication Quarterly},
  volume = {95},
  number = {2},
  pages = {471--496},
  issn = {1077-6990},
  doi = {10/gdncmx},
  urldate = {2020-01-22},
  abstract = {The present study argues that political communication on social media is mediated by a platform?s digital architecture?the technical protocols that enable, constrain, and shape user behavior in a virtual space. A framework for understanding digital architectures is introduced, and four platforms (Facebook, Twitter, Instagram, and Snapchat) are compared along the typology. Using the 2016 U.S. election as a case, interviews with three Republican digital strategists are combined with social media data to qualify the study?s theoretical claim that a platform?s network structure, functionality, algorithmic filtering, and datafication model affect political campaign strategy on social media.},
  file = {/Users/colin.madland/Zotero/storage/963PUQGN/bossettaDigitalArchitecturesSocial2018.pdf}
}

@article{bosUseRecordedLectures2016,
  title = {The Use of Recorded Lectures in Education and the Impact on Lecture Attendance and Exam Performance},
  author = {Bos, Nynke and Groeneveld, Caspar and {\noopsort{bruggen}}{van Bruggen}, Jan and {Brand-Gruwel}, Saskia},
  year = {2016},
  journal = {British journal of educational technology},
  volume = {47},
  number = {5},
  pages = {906--917},
  publisher = {Blackwell Publishing Ltd},
  address = {HOBOKEN},
  issn = {0007-1013},
  doi = {10.1111/bjet.12300},
  abstract = {Universities increasingly record lectures and make them available online for students. Though the technology to record these lectures is now solidly implemented and embedded in many institutions, the impact of the usage of recorded lectures on exam performance is not clear. The purpose of the current study is to address the use of recorded lectures in an authentic setting by focusing on the actual time spent on the usage of recorded lectures and the impact on lecture attendance and exam performance. The participants were 396 first-year university psychology students attending a mandatory course on biological psychology. During the course, student attendance to face-to-face lectures was registered and the viewing of the recordings monitored. Results revealed that a large amount of students used the recorded lectures as a substitute for lecture attendance. The group who uses recorded lectures as a supplement when developing a knowledge base score significantly higher on the assessment. When assessing higher order thinking skills, no significant differences were found between using recording lectures and attending lectures. This can be partly explained by relatively low predictive value either form of lectures have on exam performance.},
  keywords = {Academic achievement,Assessments,Attendance,Biology,Butterflies & moths,Cats,College Freshmen,Colleges & universities,Crystals,Distance learning,Education,Education & Educational Research,Educational technology,Knowledge base,Lecture Method,Lectures,Predictor Variables,Psychology,Psychophysiology,Public speaking,Recording,Required Courses,Scores,Social Sciences,Student Evaluation,Students,Tests,Thinking Skills,Time on Task,Universities,University students,Use Studies,Video Equipment}
}

@article{boucheyRemoteStudentSupport2021,
  title = {Remote {{Student Support}} during {{COVID-19}}: {{Perspectives}} of {{Chief Online Officers}} in {{Higher Education}}},
  author = {Bouchey, Bettyjo and Gratz, Erin and Kurland, Shelley},
  year = {2021},
  journal = {Online Learning},
  volume = {25},
  number = {1},
  pages = {28--40},
  issn = {ISSN-2472-5749},
  abstract = {In order to understand the nature of online student support services during the COVID-19 pandemic, 31 chief online officers representing a range of colleges and universities were interviewed in late Spring 2020. Findings highlighted issues of access and equity in online student support services, the rapid expansion of student services due to the pandemic, and how strength in online programming enabled a more seamless pivot to emergency remote operations. This study adds texture to the literature on the gaps between support services offered to face-to-face versus online students, and also provides a foundation for important questions regarding the future of online student support after COVID-19. The study also begins a dialog into the long-term ramifications of siloing online organizational units at institutions of higher education.},
  langid = {english},
  keywords = {Academic Support Services,Access to Education,Administrator Attitudes,College Administration,College Students,COVID-19,Distance Education,Electronic Learning,Emergency Programs,Equal Education,No DOI found,Pandemics,Student Needs,Student Personnel Services,Synchronous Communication}
}

@article{boudAligningAssessmentLong2006a,
  ids = {boudAligningAssessmentLong2006},
  title = {Aligning {{Assessment}} with {{Long Term Learning}}},
  author = {Boud, David and Falchikov, Nancy},
  year = {2006},
  journal = {Assessment \& Evaluation in Higher Education},
  doi = {10.1080/02602930600679050},
  abstract = {Assessment in higher education is commonly held to contribute to feedback to students on their learning and the certification of their achievement. This paper argues that this short-term focus must be balanced against a longer-term emphasis for learning-oriented assessment to foster future learning after graduation. The paper proposes that students need to become assessors within the context of participation in practice, that is, the kinds of highly contextualised learning faced in life and work. It discusses the kinds of practices that are needed to refocus assessment within higher education courses to this end.},
  pmcid = {null},
  pmid = {null}
}

@techreport{boudAssessment2020Seven2010,
  title = {Assessment 2020: {{Seven}} Propositions for Assessment Reform in Higher Education},
  author = {Boud, David and Associates},
  year = {2010},
  pages = {4},
  urldate = {2021-04-10},
  abstract = {Universities face substantial change in a rapidly evolving global context. The challenges of meeting new expectations about academic standards in the next decade and beyond mean that assessment will need to be rethought and renewed. This document provides a stimulus for those involved in the redevelopment of assessment practices. It draws on the expertise of a group of highly experienced assessment researchers, academic development practitioners and senior academic managers to identify current best thinking about the ways assessment will need to address immediate and future demands.},
  file = {/Users/colin.madland/Zotero/storage/ZPGZU4VQ/boudAssessment2020Seven2010.pdf}
}

@incollection{boudAssessmentaslearningDevelopmentStudents2021,
  title = {Assessment-as-Learning for the Development of Students' Evaluative Judgement},
  booktitle = {Assessment as {{Learning}}},
  author = {Boud, David},
  editor = {Yan, Zi and Yang, Lan},
  year = {2021},
  edition = {1},
  pages = {25--37},
  publisher = {Routledge},
  address = {London},
  doi = {10.4324/9781003052081-3},
  urldate = {2023-03-20},
  isbn = {978-1-003-05208-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/5MCNDZQM/boudAssessmentaslearningDevelopmentStudents2021.pdf}
}

@article{boudAssessmentChallengeSocial2024,
  title = {The Assessment Challenge of Social and Collaborative Learning in Higher Education},
  author = {Boud, David and Bearman, Margaret},
  year = {2024},
  journal = {Educational Philosophy and Theory},
  volume = {56},
  number = {5},
  pages = {459--468},
  issn = {0013-1857, 1469-5812},
  doi = {10.1080/00131857.2022.2114346},
  urldate = {2024-10-24},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/boudAssessmentChallengeSocial2024.pdf}
}

@article{boudChallengesReformingHigher2020,
  title = {Challenges in Reforming Higher Education Assessment: A Perspective from Afar},
  shorttitle = {Challenges in Reforming Higher Education Assessment},
  author = {Boud, David},
  year = {2020},
  month = jun,
  journal = {RELIEVE - Revista Electr{\'o}nica de Investigaci{\'o}n y Evaluaci{\'o}n Educativa},
  volume = {26},
  number = {1},
  issn = {1134-4032},
  doi = {10/gjvpw5},
  urldate = {2021-05-04},
  abstract = {ENGLISH Can we be sure that assessment in higher education meets the need of developing and assuring high quality learning outcomes? Current assessment is typically a collection of conventional practices that have never been seriously questioned. Ten years ago, as part of a national project, representatives from Australian universities came together to identify an agenda for change in assessment. The resulting document---Assessment 2020: Seven propositions for assessment reform in higher education---focused on how assessment needed to change to support long term learning. That is, not how students can pass the next exam, but learning that is useful beyond the point of graduation. From a learning-centred view this paper examine progress on assessment reform in universities internationally from the perspective of one of the players. It starts by considering Assessment 2020 to see where action is still needed. It reviews some of the major shifts in assessment in higher education and considers their implications. These include the move from comparing students (norm-referencing) to judging outcomes against standards (standards-based); and importantly, the conceptual shift from the single purpose of assessment as certifying students to multiple purposes including aiding learning and building the capacity of students to make their own judgements. Espanol {\textquestiondown}Podemos estar seguros de que la evaluaci{\'o}n en la educaci{\'o}n superior satisface la necesidad de desarrollar y garantizar resultados de aprendizaje de alta calidad? La evaluaci{\'o}n actual es t{\'i}picamente una colecci{\'o}n de pr{\'a}cticas convencionales que nunca han sido seriamente cuestionadas. Hace diez a{\~n}os, como parte de un proyecto nacional, representantes de universidades australianas se reunieron para identificar una agenda para el cambio en la evaluaci{\'o}n. El documento resultante Evaluaci{\'o}n 2020: siete propuestas para la reforma de la evaluaci{\'o}n en la educaci{\'o}n superior, se centr{\'o} en c{\'o}mo deb{\'i}a cambiar la evaluaci{\'o}n para apoyar el aprendizaje a lo largo de la vida. Es decir, no se trata de c{\'o}mo los estudiantes pueden aprobar el pr{\'o}ximo examen, sino de que aprendan lo que ser{\'a} {\'u}til m{\'a}s all{\'a} del momento de la graduaci{\'o}n.  Desde una perspectiva centrada en el aprendizaje, este documento analiza a nivel internacional el progreso que se ha producido en las universidades en torno a la reforma de la evaluaci{\'o}n desde la perspectiva de uno de sus actores. Se inicia considerando el documento Evaluaci{\'o}n 2020 para ver d{\'o}nde a{\'u}n se necesitan acciones. Se revisa algunos de los principales cambios en la evaluaci{\'o}n en la educaci{\'o}n superior y sus implicaciones. Estos incluyen el tr{\'a}nsito de comparar estudiantes (evaluaci{\'o}n referida a normas) a juzgar resultados contra est{\'a}ndares (evaluaci{\'o}n basada en est{\'a}ndares) y, lo que es m{\'a}s importante, el cambio conceptual de pasar de un prop{\'o}sito simple de la evaluaci{\'o}n, como es el de certificar a los estudiantes, a considerar m{\'u}ltiples prop{\'o}sitos, incluyendo ayudar al aprendizaje y al desarrollo de la capacidad de los estudiantes para emitir sus propios juicios.},
  file = {/Users/colin.madland/Zotero/storage/V7IBSLSD/boudChallengesReformingHigher2020.pdf}
}

@incollection{boudCreatingAgendaDeveloping2018,
  title = {Creating an Agenda for Developing Students' Evaluative Judgement},
  booktitle = {Developing {{Evaluative Judgement}} in {{Higher Education}}},
  author = {Boud, David and Dawson, Phillip and Tai, Joanna and Ajjawi, Rola},
  editor = {Boud, David and Ajjawi, Rola and Dawson, Phillip and Tai, Joanna},
  year = {2018},
  month = apr,
  edition = {1},
  pages = {186--195},
  publisher = {Routledge},
  address = {Abingdon, Oxon ; New York, NY : Routledge, 2018.},
  doi = {10.4324/9781315109251-20},
  urldate = {2024-04-09},
  isbn = {978-1-315-10925-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/4GCJ2EPD/boudCreatingAgendaDeveloping2018.pdf}
}

@book{boudDevelopingEvaluativeJudgement2018,
  title = {Developing {{Evaluative Judgement}} in {{Higher Education}}: {{Assessment}} for {{Knowing}} and {{Producing Quality Work}}},
  shorttitle = {Developing {{Evaluative Judgement}} in {{Higher Education}}},
  editor = {Boud, David and Ajjawi, Rola and Dawson, Phillip and Tai, Joanna},
  year = {2018},
  month = apr,
  edition = {1},
  publisher = {Routledge},
  address = {Abingdon, Oxon ; New York, NY : Routledge, 2018.},
  doi = {10.4324/9781315109251},
  urldate = {2022-05-04},
  isbn = {978-1-315-10925-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/XK9VN43L/boudDevelopingEvaluativeJudgement2018.pdf}
}

@book{boudFeedbackHigherProfessional2012,
  title = {Feedback in {{Higher}} and {{Professional Education}}: {{Understanding}} It and Doing It Well},
  shorttitle = {Feedback in {{Higher}} and {{Professional Education}}},
  editor = {Boud, David and Molloy, Elizabeth},
  year = {2012},
  month = dec,
  edition = {0},
  publisher = {Routledge},
  address = {New York},
  doi = {10.4324/9780203074336},
  urldate = {2023-03-30},
  isbn = {978-0-203-07433-6},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/FPZYXHM6/boudFeedbackHigherProfessional2012.pdf}
}

@article{boudPeerLearningAssessment1999,
  title = {Peer {{Learning}} and {{Assessment}}},
  author = {Boud, David and Cohen, Ruth and Sampson, Jane},
  year = {1999},
  month = dec,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {24},
  number = {4},
  pages = {413--426},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/0260293990240405},
  urldate = {2024-05-10},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/YI8CYHDB/boudPeerLearningAssessment1999.pdf}
}

@article{boudRedesigningAssessmentLearning2005,
  title = {Redesigning Assessment for Learning beyond Higher Education},
  author = {Boud, David and Falchikov, Nancy},
  year = {2005},
  journal = {null},
  doi = {null},
  abstract = {An important rationale for higher education is that it equips students for learning beyond the point of graduation. Th is paper considers the role that assessment plays in this. It suggests we need to take a new perspective on assessment: assessment to promote learning throughout life. It focuses on ideas that can be used to contribute to the construction of assessment practices and on wider implications for course design. It concludes by exploring barriers to acceptance of this perspective and how they might be addressed.},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@article{boudRedesigningAssessmentLearning2005a,
  title = {Redesigning Assessment for Learning beyond Higher Education},
  author = {Boud, David and Falchikov, Nancy},
  year = {2005},
  journal = {null},
  doi = {null},
  abstract = {An important rationale for higher education is that it equips students for learning beyond the point of graduation. Th is paper considers the role that assessment plays in this. It suggests we need to take a new perspective on assessment: assessment to promote learning throughout life. It focuses on ideas that can be used to contribute to the construction of assessment practices and on wider implications for course design. It concludes by exploring barriers to acceptance of this perspective and how they might be addressed.},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@article{boudReframingAssessmentResearch2018,
  title = {Reframing Assessment Research: Through a Practice Perspective},
  shorttitle = {Reframing Assessment Research},
  author = {Boud, David and Dawson, Phillip and Bearman, Margaret and Bennett, Sue and Joughin, Gordon and Molloy, Elizabeth},
  year = {2018},
  month = jul,
  journal = {Studies in Higher Education},
  volume = {43},
  number = {7},
  pages = {1107--1118},
  issn = {0307-5079, 1470-174X},
  doi = {10.1080/03075079.2016.1202913},
  urldate = {2022-11-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/4QHHJS5Q/boudReframingAssessmentResearch2018.pdf}
}

@book{boudRethinkingAssessmentHigher2007,
  title = {Rethinking Assessment in Higher Education: Learning for the Longer Term},
  author = {Boud, David and Falchikov, Nancy},
  editor = {Boud, David and Falchikov, Nancy},
  year = {2007},
  number = {Book, Whole},
  publisher = {Routledge},
  address = {London;New York;},
  doi = {10.4324/9780203964309},
  abstract = {Assessment is a value-laden activity surrounded by debates about academic standards, preparing students for employment, measuring quality and providing incentives. There is substantial evidence that assessment, rather than teaching, has the major influence on students' learning. It directs attention to what is important and acts as an incentive for study. This book revisits assessment in higher education, examining it from the point of view of what assessment does and can do and argues that assessment should be seen as an act of informing judgement and proposes a way of integrating teaching, learning and assessment to better prepare students for a lifetime of learning. It is essential reading for practitioners and policy makers in higher education institutions in different countries, as well as for educational development and institutional research practitioners.;Assessment is a value-laden activity surrounded by debates about academic standards, preparing students for employment, measuring quality and providing incentives. There is substantial evidence that assessment, rather than teaching, has the major influence on students' learning. It directs attention to what is important and acts as an incentive for study. This book revisits assessment in higher education, examining it from the point of view of what assessment does and can do and argues that assessment should be seen as an act of informing judgement and proposes a way of integrating teaching, learning and assessment to better prepare students for a lifetime of learning. It is essential reading for practitioners and policy makers in higher education institutions in different countries, as well as for educational development and institutional research practitioners.;'Assessment is a value-laden activity surrounded by debates about academic standards, preparing students for employment, measuring quality and providing incentives. There is substantial evidence that assessment, rather than teaching, has the major influence on students' learning. It directs attention to what is important and acts as an incentive for study. This book revisits assessment in higher education, examining it from the point of view of what assessment does and can do and argues that assessment should be seen as an act of informing judgement and proposes a way of integrating teaching, learning and assessment to better prepare students for a lifetime of learning. It is essential reading for practitioners and policy makers in higher education institutions in different countries, as well as for educational development and institutional research practitioners.'-- Publisher's website;},
  isbn = {9780203964309;9780415397780;0203964306;0415397782;0415397790;9780415397797;},
  langid = {english},
  keywords = {Assessment practices,Assessment strategies,College students,Curriculum,Educational tests and measurements,Higher Education,Learning,Lifelong Learning,Post-Compulsory Education,Postsecondary education,Professional development,Rating of,Student assessment,Testing,Vocational education and training},
  file = {/Users/colin.madland/Zotero/storage/IMCNLMHC/boudRethinkingAssessmentHigher2007.pdf}
}

@article{boudRethinkingModelsFeedback2013,
  title = {Rethinking Models of Feedback for Learning: The Challenge of Design},
  shorttitle = {Rethinking Models of Feedback for Learning},
  author = {Boud, David and Molloy, Elizabeth},
  year = {2013},
  month = sep,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {38},
  number = {6},
  pages = {698--712},
  issn = {0260-2938, 1469-297X},
  doi = {10/gcphxw},
  urldate = {2021-04-04},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/MUHEHWV2/boudRethinkingModelsFeedback2013.pdf}
}

@article{boudSituatingAcademicDevelopment1999,
  title = {Situating Academic Development in Professional Work: {{Using}} Peer Learning},
  author = {Boud, David},
  year = {1999},
  journal = {International Journal for Academic Development},
  volume = {4},
  number = {1},
  pages = {3--10},
  doi = {10.1080/1360144990040102},
  abstract = {Abstract Academic development should be conceptualized not only as a university?wide process, but also as a local practice and as a process of peer learning in the workplace. The paper suggests that formal approaches need to more fully situate academic development in sites of academic practice. Two examples from the author's own setting ?teaching development projects and writing for publication groups?illustrate the argument. Challenges arising from such a shift in perspective are discussed.}
}

@article{boudSustainableAssessmentRethinking2000,
  title = {Sustainable {{Assessment}}: {{Rethinking}} Assessment for the Learning Society},
  shorttitle = {Sustainable {{Assessment}}},
  author = {Boud, David},
  year = {2000},
  month = nov,
  journal = {Studies in Continuing Education},
  volume = {22},
  number = {2},
  pages = {151--167},
  issn = {0158-037X, 1470-126X},
  doi = {10.1080/713695728},
  urldate = {2022-06-21},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/XNHBHHGT/boudSustainableAssessmentRethinking2000.pdf}
}

@article{boudSustainableAssessmentRevisited2016,
  title = {Sustainable Assessment Revisited},
  author = {Boud, David and Soler, Rebeca},
  year = {2016},
  month = apr,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {41},
  number = {3},
  pages = {400--413},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2015.1018133},
  urldate = {2022-06-21},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/AU3WZ79H/boudSustainableAssessmentRevisited2016.pdf}
}

@article{boudWhatFeedbackLiterate2021,
  title = {What Feedback Literate Teachers Do: An Empirically-Derived Competency Framework},
  shorttitle = {What Feedback Literate Teachers Do},
  author = {Boud, David and Dawson, Phillip},
  year = {2021},
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {48},
  number = {2},
  pages = {158--171},
  publisher = {Routledge},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2021.1910928},
  urldate = {2023-02-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/T4EUIM42/boudWhatFeedbackLiterate2021.pdf}
}

@incollection{boudWhatProblemFeedback2012,
  title = {What Is the Problem with Feedback?},
  booktitle = {Feedback in {{Higher}} and {{Professional Education}}: {{Understanding}} It and Doing It Well},
  author = {Boud, David and Molloy, Elizabeth},
  editor = {Boud, David and Molloy, Elizabeth},
  year = {2012},
  publisher = {Routledge},
  address = {New York},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/H69J7R82/boudWhatProblemFeedback2012.pdf}
}

@article{bowen-mendozaDesignPeerAssessment2022,
  title = {Design of Peer Assessment Rubrics for {{ICT}} Topics},
  author = {{Bowen-Mendoza}, Lorena and {Pinargote-Ortega}, Maricela and Meza, Jaime and Ventura, Sebasti{\'a}n},
  year = {2022},
  journal = {Journal of computing in higher education},
  volume = {34},
  number = {1},
  pages = {211--241},
  publisher = {Springer US},
  address = {New York},
  issn = {1042-1726},
  doi = {10.1007/s12528-021-09297-9},
  abstract = {Peer evaluation consists of the evaluation of students by their peers following criteria or rubrics provided by the teacher, where the way to evaluate students is specified so that they achieve the desired competencies. The quality of the measurement instrument must meet two essential criteria: validity and reliability. In this research, we explored the educational value of peer evaluation rubrics by analyzing the quality of the rubric through the study of content validity, reliability, and internal consistency. Our main purpose was to design an appropriate rubric to grade tasks in the field of information engineering, as well as performing content validation through a group of experts. It was carried out in three phases: 1) construction of a rubric, with its criteria, characteristics, and levels of achievement; 2) content validation by five experts in the field, and 3) application of the rubric to ascertain students' perceptions and satisfaction with its validity. The relevance of the criteria and the definition of their characteristics obtained a score higher than 3.75/4 on a Likert scale. The content validity values (CVR), content validity index (CVI), and general content validity index (GIVC) gave maximum values of\,+\,1. The results obtained indicate that the rubric is adequate, with Aiken's V higher than V 0.87 in all its criteria. The rubric was applied to 326 students of 4 subjects. Cronbach's alpha was used to calculate the reliability of the rubric, obtaining a value of 0.839. The students' perception of validity and satisfaction with the rubric was higher than 0.78. As future work, we intend to design a rubric validation engine according to the applied procedure.},
  keywords = {Analysis,Content Validity,Criteria,Education,Education & Educational Research,Educational evaluation,Educational Technology,Evaluation,Evaluation Criteria,Grading,Higher Education,Information engineering,Information Technology,Learning and Instruction,Likert Scales,Measuring instruments,Peer Evaluation,Peers,Reliability analysis,Scores,Scoring Rubrics,Social Sciences,Student Evaluation,Student Satisfaction,Students,Test Reliability,Validity}
}

@article{bowerCriticalAnalysisTechnologyenhanced2018,
  title = {A Critical Analysis of Technology-Enhanced Learning Design Frameworks},
  author = {Bower, Matt and Vlachopoulos, Panos},
  year = {2018},
  month = nov,
  journal = {British Journal of Educational Technology},
  volume = {49},
  number = {6},
  pages = {981--997},
  issn = {00071013},
  doi = {10.1111/bjet.12668},
  urldate = {2022-05-17},
  abstract = {Numerous models have been developed to help teachers efficiently and effectively design learning opportunities using new and emerging technologies. However, the literature to date makes little reference to the variation that exists within the models and frameworks as far as their scope, context, epistemological and pedagogical underpinnings and so on. In this paper, we critically contrast models of technology-enhanced learning design in order to support educator selection of models, as well as to derive an overarching understanding of how learning design models may differ ontologically. A total of 21 models were selected from a systematic search of the technology-enhanced learning design research literature. Findings indicated that technology-enhanced learning design models can be differentiated according to whether they constitute a conceptual framework or a procedural method, their epistemological and pedagogical underpinnings, the level of granularity of the model, the extent to which contextual elements are considered, whether interactions between teachers and students are integral, whether guidance for selecting technologies is included and whether any sort of evaluation of the model has been conducted. The utility of each of these dimensions in terms of supporting technology-enhanced learning design is considered, and the value more broadly of learning design models is critically discussed.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/EQ8NU9EF/bowerCriticalAnalysisTechnologyenhanced2018.pdf}
}

@book{bowerDesignTechnologyenhancedLearning2017,
  title = {Design of Technology-Enhanced Learning : Integrating Research and Practice},
  author = {Bower, Matt},
  year = {2017},
  publisher = {Emerald Publishing Limited},
  address = {Bingley, [England},
  abstract = {Educators and researchers worldwide are confronted by a tantalizing challenge - how should contemporary technologies be used to enhance learning? This book provides a broad academic and teaching audience with an integrated understanding of learning technology research, and how it can be used to enhance the design of learning environments. Whereas some books focus exclusively on research relating to learning technology and others propose ways to use technology effectively, this book synthesises research for the purpose of informing best practice. After laying pedagogical, technological and content foundations, it examines research relating to the educational use of Web 2.0, social networking, mobile devices and virtual worlds. Analysis across these contexts leaves readers with a nuanced understanding of how technology-enhanced learning design principles may (or may not) be abstracted across different learning technology environments. Providing an integrated portrayal of learning technology research enables educators (academics, school teachers, pre-service teachers and educational designers) to immediately adopt evidence-based approaches in their teaching. The comprehensive synthesis of the literature also helps learning technology researchers to more clearly identify the interrelationships between different areas of learning technology research, as well as position their work amongst the practical problems of the field. Rich with examples, this book is suitable for those who want to adopt a design-based and research-driven approach to enhancing learning using technology.},
  isbn = {1-78714-911-0},
  keywords = {Computer-assisted instruction,Education -- Computers & Technology,Education -- Research,Educational equipment & technology computer-aided learning (CAL)},
  file = {/Users/colin.madland/Zotero/storage/PCFT67M3/bowerDesignTechnologyenhancedLearning2017.pdf}
}

@inproceedings{bowerEffectReceivingPreferred2004,
  title = {The Effect of Receiving the Preferred Form of Online Assessment Feedback upon Middle School Mathematics Students},
  booktitle = {Proceedings of the {{Seventh IASTED International Conference}} on {{Computers}} and {{Advanced Technology}} in {{Education}}},
  author = {Bower, M.},
  year = {2004},
  pages = {462--467},
  abstract = {In this experiment students completed a web-based quadratics equations learning module followed by a randomly generated online quiz that they could practise as often as they liked. The effect of receiving their preferred form of feedback (either competitive or individualistic) upon academic performance and attitude indicators was measured. The three key findings of the study were that: i) the facility to practice lead to a significant improvement in test score ii) providing students with their non-preferred form of feedback had a significantly negative impact on their mathematics ability self-rating iii) boys appeared more likely to adopt a fixated approach to this "power based" repetitive practise task. The differential effect of competitive versus individualistic feedback was also analysed.},
  keywords = {Assessment,Competitive,Competitive feedback,Education,Feedback,Grading,Individualistic,Individualistic feedback,Mathematical techniques,Online,Online assessment,Online systems,Preferred,Preferred online assessment feedback,Students,Teaching,World Wide Web}
}

@article{bowerElevatedCeilingHeights2024,
  title = {Elevated Ceiling Heights Reduce the Cognitive Performance of Higher-Education Students during Exams},
  author = {Bower, Isabella S. and Broadbent, Jaclyn and Coussens, Scott and Enticott, Peter G.},
  year = {2024},
  month = aug,
  journal = {Journal of Environmental Psychology},
  volume = {97},
  pages = {102367},
  issn = {0272-4944},
  doi = {10.1016/j.jenvp.2024.102367},
  abstract = {Examinations are a widely used assessment method in higher education. They are often conducted in large indoor environments that can accommodate high numbers of students to maximize scheduling and cost efficiency. Recent evidence, however, suggests enlarged room scale impacts brain activity that is associated with concentration, which could negatively impact cognitive performance. We analysed data (N~=~15,400) from undergraduate students over eight years across three campuses at an Australian tertiary institution. Using a linear mixed model, we compared examination performance across different room scales, while accounting for coursework performance, and other variables. We found student examination performance was reduced in rooms with elevated ceiling heights. These results support the notion that built environment scale influences cognitive performance, and argue against conducting examinations in large scale, high-ceiling rooms.},
  keywords = {Assessment and evaluation,Built environment,Cognitive performance,Examination,Higher education,Interior design},
  file = {/Users/colin.madland/Zotero/storage/9LQQ7NED/bowerElevatedCeilingHeights2024.pdf}
}

@article{bowerPatternsPrinciplesBlended2014,
  title = {Patterns and Principles for Blended Synchronous Learning: {{Engaging}} Remote and Face-to-Face Learners in Rich-Media Real-Time Collaborative Activities},
  author = {Bower, Matt and Kenney, Jacqueline and Dalgarno, Barney and Lee, Mark JW and Kennedy, Gregor E},
  year = {2014},
  journal = {Australasian Journal of Educational Technology},
  volume = {30},
  pages = {261--272},
  abstract = {Blended synchronous learning involves using rich-media technologies to enable remote and face-to-face students to jointly participate in the same live classes. This article presents blended synchronous learning designs from seven case studies that were part of a project funded by the Australian Government Office for Learning and Teaching and articulates principles for implementation as espoused by the teachers who enacted them. A wide range of technologies (including video conferencing, web conferencing and virtual worlds), tasks (namely collaborative evaluation, group questioning, class discussion, problem solving and collaborative design) and levels of student interaction (from lightweight to tightly coupled) were present within the designs. The main issues that teachers confronted when facilitating blended synchronous lessons were those relating to communication and those relating to cognitive overload caused by split attention. Key pedagogical principles for enactment as identified by the lead teachers included the need for extensive preparation, clear instructions, composure, flexibility, advance preparation of students and savvy utilisation of support staff.},
  keywords = {multi-access}
}

@article{bowerTechnologymediatedLearningTheory2019,
  title = {Technology-mediated Learning Theory},
  author = {Bower, Matt},
  year = {2019},
  month = may,
  journal = {British Journal of Educational Technology},
  volume = {50},
  number = {3},
  pages = {1035--1048},
  issn = {0007-1013, 1467-8535},
  doi = {10.1111/bjet.12771},
  urldate = {2022-05-16},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/UI3PMPQH/bowerTechnologyMediatedLearning2019.pdf}
}

@article{bowlesThermostatsLocksLights2018,
  title = {Thermostats, {{Locks}} and {{Lights}}: {{Digital Tools}} of {{Domestic Abuse}}},
  shorttitle = {Thermostats, {{Locks}} and {{Lights}}},
  author = {Bowles, Nellie},
  year = {2018},
  month = jun,
  journal = {The New York Times},
  issn = {0362-4331},
  urldate = {2018-06-28},
  abstract = {Internet-connected home devices that are marketed as the newest conveniences are also being used to harass, monitor and control.},
  chapter = {Technology},
  langid = {american},
  keywords = {Domestic Violence,Home Appliances,Home Automation and Smart Homes,Mobile Applications,Women and Girls},
  file = {/Users/colin.madland/Zotero/storage/982CM2I5/smart-home-devices-domestic-abuse.html}
}

@article{boydNetworkedPrivacy2012,
  title = {Networked {{Privacy}}},
  author = {Boyd, Danah},
  year = {2012},
  month = dec,
  journal = {Surveillance \& Society},
  volume = {10},
  number = {3/4},
  pages = {348--350},
  issn = {1477-7487},
  doi = {10.24908/ss.v10i3/4.4529},
  urldate = {2021-12-23},
  abstract = {--},
  file = {/Users/colin.madland/Zotero/storage/AFZM5ADM/boydNetworkedPrivacy2012.pdf}
}

@article{bozkurtGlobalOutlookInterruption2020,
  title = {A Global Outlook to the Interruption of Education Due to {{COVID-19}} Pandemic: {{Navigating}} in a Time of Uncertainty and Crisis},
  shorttitle = {A Global Outlook to the Interruption of Education Due to {{COVID-19}} Pandemic},
  author = {Bozkurt, Aras and Jung, Insung and Xiao, Junhong and Vladimirschi, Viviane and Schuwer, Robert and Egorov, Gennady and Lambert, Sarah and {Al-Freih}, Maha and Pete, Judith and Don Olcott, Jr and Rodes, Virginia and Aranciaga, Ignacio and Bali, Maha and Alvarez, Abel Jr and Roberts, Jennifer and Pazurek, Angelica and Raffaghelli, Juliana Elisa and Panagiotou, Nikos and {\noopsort{co{\"e}tlogon}}de Co{\"e}tlogon, Perrine and Shahadu, Sadik and Brown, Mark and Asino, Tutaleni I. and Tumwesige, Josephine and Reyes, Tzinti Ram{\'i}rez and Ipenza, Emma Barrios and Ossiannilsson, Ebba and Bond, Melissa and Belhamel, Kamel and Irvine, Valerie and Sharma, Ramesh C. and Adam, Taskeen and Janssen, Ben and Sklyarova, Tatiana and Olcott, Nicoleta and Ambrosino, Alejandra and Lazou, Chrysoula and Mocquet, Bertrand and Mano, Mattias and Paskevicius, Michael},
  year = {2020},
  month = jun,
  journal = {Asian Journal of Distance Education},
  volume = {15},
  number = {1},
  pages = {1--126},
  issn = {1347-9008},
  urldate = {2024-02-09},
  abstract = {Uncertain times require prompt reflexes to survive and this study is a collaborative reflex to better understand uncertainty and navigate through it. The Coronavirus (Covid-19) pandemic hit hard and interrupted many dimensions of our lives, particularly education. As a response to interruption of education due to the Covid-19 pandemic, this study is a collaborative reaction that narrates the overall view, reflections from the K-12 and higher educational landscape, lessons learned and suggestions from a total of 31 countries across the world with a representation of 62,7\% of the whole world population. In addition to the value of each case by country, the synthesis of this research suggests that the current practices can be defined as emergency remote education and this practice is different from planned practices such as distance education, online learning or other derivations. Above all, this study points out how social injustice, inequity and the digital divide have been exacerbated during the pandemic and need unique and targeted measures if they are to be addressed. While there are support communities and mechanisms, parents are overburdened between regular daily/professional duties and emerging educational roles, and all parties are experiencing trauma, psychological pressure and anxiety to various degrees, which necessitates a pedagogy of care, affection and empathy. In terms of educational processes, the interruption of education signifies the importance of openness in education and highlights issues that should be taken into consideration such as using alternative assessment and evaluation methods as well as concerns about surveillance, ethics, and data privacy resulting from nearly exclusive dependency on online solutions.},
  copyright = {Copyright (c) 2020 Asian Journal of Distance Education},
  langid = {english},
  keywords = {Coronavirus Pandemic,COVID-19,distance education,emergency remote education,No DOI found,online learning},
  file = {/Users/colin.madland/Zotero/storage/IH3FRRKU/bozkurtGlobalOutlookInterruption2020.pdf}
}

@article{bozkurtSpeculativeFuturesChatGPT2023,
  title = {Speculative {{Futures}} on {{ChatGPT}} and {{Generative Artificial Intelligence}} ({{AI}}): {{A Collective Reflection}} from the {{Educational Landscape}}},
  shorttitle = {Speculative {{Futures}} on {{ChatGPT}} and {{Generative Artificial Intelligence}} ({{AI}})},
  author = {Bozkurt, Aras and Xiao, Junhong and Lambert, Sarah and Pazurek, Angelica and Crompton, Helen and Koseoglu, Suzan and Farrow, Robert and Bond, Melissa and Nerantzi, Chrissi and Honeychurch, Sarah and Bali, Maha and Dron, Jon and Mir, Kamran and Stewart, Bonnie and Costello, Eamon and Mason, Jon and Stracke, Christian M. and {Romero-Hall}, Enilda and Koutropoulos, Apostolos and Toquero, Cathy Mae and Singh, Lenandlar and Tlili, Ahmed and Lee, Kyungmee and Nichols, Mark and Ossiannilsson, Ebba and Brown, Mark and Irvine, Valerie and Raffaghelli, Juliana Elisa and {Santos-Hermosa}, Gema and Farrell, Orna and Adam, Taskeen and Thong, Ying Li and {Sani-Bozkurt}, Sunagul and Sharma, Ramesh C. and Hrastinski, Stefan and Jandri{\'c}, Petar},
  year = {2023},
  month = mar,
  journal = {Asian Journal of Distance Education},
  issn = {1347-9008},
  urldate = {2023-03-13},
  abstract = {While ChatGPT has recently become very popular, AI has a long history and philosophy. This paper intends to explore the promises and pitfalls of the Generative Pre-trained Transformer (GPT) AI and potentially future technologies by adopting a speculative methodology. Speculative future narratives with a specific focus on educational contexts are provided in an attempt to identify emerging themes and discuss their implications for education in the 21st century. Affordances of (using) AI in Education (AIEd) and possible adverse effects are identified and discussed which emerge from the narratives. It is argued that now is the best of times to define human vs AI contribution to education because AI can accomplish more and more educational activities that used to be the prerogative of human educators. Therefore, it is imperative to rethink the respective roles of technology and human educators in education with a future-oriented mindset.},
  copyright = {Copyright (c) 2023 Asian Journal of Distance Education},
  langid = {english},
  keywords = {artificial intelligence (AI),artificial intelligence in education (AIEd),future educational perspectives,generative pre-trained transformer (GPT),natural language processing,No DOI found,speculative methodology},
  file = {/Users/colin.madland/Zotero/storage/C3W68MAV/bozkurtSpeculativeFuturesChatGPT2023.pdf}
}

@incollection{bradshawDiagnosticClassificationModels2016,
  title = {Diagnostic Classification Models},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {Bradshaw, Laine},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch13},
  pages = {297--327},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch13},
  abstract = {Summary Diagnostic classification models (DCMs) are a class of psychometric models that characterize examinee traits as categorical latent variables. When coupled with careful assessment design principles, DCMs hold promise for reliably estimating high dimensionality under feasible testing conditions in order to provide a multivariate view of a student's knowledge that is aligned with cognitive theory. This chapter presents the DCM framework using log-linear cognitive diagnosis model parameterizations and then illustrates how DCMs can support the functionality of assessments as a research tool for refining cognitive theories as well as an educational tool for describing diverse student reasoning and knowledge profiles. Finally, the chapter discusses considerations researchers and practitioners make when using DCMs.},
  chapter = {13},
  isbn = {978-1-118-95658-8},
  keywords = {cognitive diagnostic model,diagnostic assessment,diagnostic classification model,multidimensional item response models}
}

@article{Brady_2005,
  title = {Assessment of Learning with Multiple Choice Questions},
  author = {Brady, Anne-Marie},
  year = {2005},
  journal = {Nurse Education in Practice},
  doi = {10/bzf7k4},
  abstract = {Summary Nurse educators aspire to learning outcomes that will produce competent practitioners. Assessment strategies should be consistent with desired learning outcomes [Manogue, M., Kelly, M., Bartakova Masaryk, S., Brown, G., Catalanotto, F., Choo-Soo, T., Delap, E., Godoroja, P., Murio, I., Rotgans, J., Saag, M., 2002. Evolving methods of assessment. European Journal of Dental Education 6 (3) 53--66] and there is a requirement to diversify approaches. Objective testing, specifically multiple-choice questions (MCQ's) are one of the approaches that may diversify the assessment approach in Irish undergraduate nursing education. In this paper, Quinn's [Quinn, F.M., 2000. The Principles and Practice of Nurse Education, fourth ed., Stanley Thorne (Publishers) Ltd, Cheltenham] cardinal criteria of assessment, practicality, reliability, validity and discrimination provide a useful framework to discuss the issues associated with the implementation of this type of assessment strategy. MCQ examinations that are consistent with educational outcomes can be used to effectively assess aspects of student performance and can facilitate timely feedback and contribute to the process of self-learning. Significant commitment is required to prepare MCQ test items and examination formats that are reliable and consistent with curriculum objectives. Appropriately constructed MCQ examinations are efficient, objective, capable of discrimination and can be combined with other assessment strategies to contribute to a comprehensive student assessment strategy for use in nursing education.},
  mag_id = {2065990448},
  pmcid = {null},
  pmid = {19038205}
}

@article{bradyAcademicStaffPerspectives2019,
  ids = {bradyAcademicStaffPerspectives2019a},
  title = {Academic {{Staff Perspectives}} on {{Technology}} for {{Assessment}} ({{TFA}}) in {{Higher Education}}: {{A Systematic Literature Review}}},
  author = {Brady, Mairead and Devitt, Ann and Kiersey, Rachel A.},
  year = {2019},
  month = nov,
  journal = {British Journal of Educational Technology},
  volume = {50},
  number = {6},
  pages = {3080--3098},
  publisher = {British Journal of Educational Technology},
  address = {HOBOKEN},
  issn = {0007-1013},
  doi = {10.1111/bjet.12742},
  abstract = {This paper presents a systematic literature review of academic staff experiences and perceptions of adopting Technology for Assessment OF/FOR/AS Learning in Higher Education. This paper is a qualitative synthesis of 65 peer-reviewed journal articles published between 2012 and 2017 reporting on the use of technology for assessment (TfA). The results suggest that there are some efficiencies for staff in implementing TfA but this can come with a cost at the set-up and maintenance phases. Furthermore, results indicated that assessment design is not of foremost concern to academic staff when introducing TfA, but that a wide variety of pressures and both educational and operational drivers are present. There were inconclusive findings in relation to understandings of appropriate institutional environments and supports for TfA to flourish in higher education. There is a need for empirical research, particularly longitudinal investigations, of academic experiences of implementations of TfA to investigate sustainability of adoption. The imperative of exploring the academic staff perspective as the instigator and manager of both the technology and the student learning experience requires deep consideration as TfA adoption progresses.},
  keywords = {Adoption (Ideas),College Faculty,Computer Assisted Testing,Costs,Design,Education,Education & Educational Research,Efficiency,Higher education,Learning,Literature reviews,Maintenance,Program Implementation,Social Sciences,Student Evaluation,Systematic review,Teacher Attitudes,Technology assessment,Technology Uses in Education},
  file = {/Users/colin.madland/Zotero/storage/YFQKE7IA/bradyAcademicStaffPerspectives2019.pdf}
}

@article{braguinskiArchiveCommunicationInteractive2018,
  title = {An ({{An}}){{Archive}} of {{Communication}}: {{Interactive Toys}} as {{Interlocutor}}},
  author = {Braguinski, Nikita},
  year = {2018},
  journal = {communication +1},
  volume = {7},
  number = {1},
  pages = {19},
  urldate = {2021-07-13},
  abstract = {In this article, I analyze the Speak \& Spell electronic toy (Texas Instruments, 1978) from the perspective of the communication that it enables. I argue that such interactive devices can be seen as archives of future communication. As a media archaeologist working with electronic toys I often find the conceptualizations of these devices as mere tools for playing unsatisfactory. They seem to share more characteristics with archives than with instruments. Like archives, interactive toys hold in themselves a predefined choice of informations and interactions, thus enabling certain modes of inquiry and discouraging others. Especially the electronic toys that draw on algorithms and data to present the user with an imitation of human communication are able to offer branching paths of interlocution within their domain or topic. In the first part of this article I offer an explanation of the toy's technical structures that store speech and spelling data and enforce certain patterns of input and output between the device and its user. Then, I propose the use of the notion of the archive, or, alternatively, anarchive to describe the space of possibilities that defines this process of communication. In the last part I argue that the study of such algorithmic archives of possible communication needs to be based on interactive experimentation and can not be grounded in static recordings or descriptions alone.},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/VIUW6AYM/braguinskiArchiveCommunicationInteractive2018.pdf}
}

@book{bransfordHowPeopleLearn2000,
  title = {How People Learn: {{Brain}}, Mind, Experience and School},
  author = {Bransford, John D and Brown, Ann L and Cocking, Rodney R},
  year = {2000},
  publisher = {National Academy Press},
  address = {Washington, DC}
}

@article{bregmanRealLordFlies2020,
  title = {The Real {{Lord}} of the {{Flies}}: What Happened When Six Boys Were Shipwrecked for 15 Months},
  shorttitle = {The Real {{Lord}} of the {{Flies}}},
  author = {Bregman, Rutger},
  year = {2020},
  month = may,
  journal = {The Guardian},
  issn = {0261-3077},
  urldate = {2020-05-09},
  abstract = {When a group of schoolboys were marooned on an island in 1965, it turned out very differently to William Golding's bestseller, writes Rutger Bregman},
  chapter = {Books},
  langid = {british},
  keywords = {Books,Culture,History books,Society books,William Golding},
  file = {/Users/colin.madland/Zotero/storage/A4UNYPZJ/the-real-lord-of-the-flies-what-happened-when-six-boys-were-shipwrecked-for-15-months.html}
}

@article{breienNarrativeCategorizationDigital2020,
  title = {Narrative Categorization in Digital Game-Based Learning: {{Engagement}}, Motivation \& Learning},
  author = {Breien, Fredrik and Wasson, B.},
  year = {2020},
  journal = {Br. J. Educ. Technol.},
  doi = {10.1111/BJET.13004},
  abstract = {His the his area of concerns narratives in game results show that effective to and effects on in single systems, when comparing to}
}

@article{brennanProblemsPitfallsParadoxes2005,
  title = {Some {{Problems}}, {{Pitfalls}}, and {{Paradoxes}} in {{Educational Measurement}}},
  author = {Brennan, Robert L.},
  year = {2005},
  month = oct,
  journal = {Educational Measurement: Issues and Practice},
  volume = {20},
  number = {4},
  pages = {6--18},
  issn = {07311745, 17453992},
  doi = {10.1111/j.1745-3992.2001.tb00071.x},
  urldate = {2022-03-31},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/PW3QNQUQ/brennanProblemsPitfallsParadoxes2005.pdf}
}

@incollection{brennanValidation2006,
  title = {Validation},
  booktitle = {Educational Measurement},
  editor = {Brennan, Robert L. and {National Council on Measurement in Education} and {American Council on Education}},
  year = {2006},
  series = {{{ACE}} / {{Praeger}} Series on Higher Education},
  edition = {4. ed},
  publisher = {Praeger Publ},
  address = {Westport, Conn},
  isbn = {978-0-275-98125-9},
  langid = {english},
  annotation = {OCLC: 610652954},
  file = {/Users/colin.madland/Zotero/storage/3MPKYNB4/brennanValidation2006.pdf;/Users/colin.madland/Zotero/storage/PLPLAC9H/brennanValidation2006.pdf}
}

@article{briggsExaminingDualPurpose2019,
  title = {Examining the {{Dual Purpose Use}} of {{Student Learning Objectives}} for {{Classroom Assessment}} and {{Teacher Evaluation}}},
  author = {Briggs, Derek C. and Chattergoon, Rajendra and Burkhardt, Amy},
  year = {2019},
  journal = {Journal of Educational Measurement},
  volume = {56},
  number = {4},
  pages = {686--714},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {0022-0655},
  doi = {10/ghbwr6},
  urldate = {2020-09-17},
  abstract = {Abstract The process of setting and evaluating student learning objectives (SLOs) has become increasingly popular as an example where classroom assessment is intended to fulfill the dual purpose use of informing instruction and holding teachers accountable. A concern is that the high-stakes purpose may lead to distortions in the inferences about students and teachers that SLOs can support. This concern is explored in the present study by contrasting student SLO scores in a large urban school district to performance on a common objective external criterion. This external criterion is used to evaluate the extent to which student growth scores appear to be inflated. Using 2 years of data, growth comparisons are also made at the teacher level for teachers who submit SLOs and have students that take the state-administered large-scale assessment. Although they do show similar relationships with demographic covariates and have the same degree of stability across years, the two different measures of growth are weakly correlated.},
  file = {/Users/colin.madland/Zotero/storage/CBQ2M5SH/briggsExaminingDualPurpose2019.pdf}
}

@article{brightMakingInstantAdjustments2020,
  title = {Making {{Instant Adjustments}} in {{Online Journalism Education}}: {{Responding}} to {{Continuous Needs Assessments}} in {{Asynchronous Courses}}},
  author = {Bright, Amanda C.},
  year = {2020},
  journal = {Online Learning},
  volume = {24},
  number = {2},
  pages = {245--253},
  issn = {ISSN-2472-5749},
  abstract = {The creation of an effective learning environment is always a challenge, but when the environment is online and the learners are a diverse group of adults in a specialized content area, the challenges become more complex. This best practices study used the intersection of the importance of the learner, Knowles's andragogy concepts, and the Dick and Carey instructional design model to make continuous needs assessment the cornerstone of three, graduate-level online courses during a single summer session. Through the use of recursive needs assessment, the instructor was able to provide a personal and practical level of instruction in the asynchronous courses that ultimately benefited the students.},
  langid = {english},
  keywords = {Adult Students,Asynchronous Communication,Graduate Students,Instructional Design,Journalism Education,Needs Assessment,No DOI found,Online Courses,Summative Evaluation}
}

@article{brijlallIntegratingOnlineDiagnostic2020,
  title = {Integrating {{Online Diagnostic Tests}} in a {{First Year Engineering Class}}},
  author = {Brijlall, Deonarain and Ally, Noor},
  year = {2020},
  journal = {EURASIA Journal of Mathematics, Science and Technology Education},
  volume = {16},
  number = {10},
  issn = {EISSN-1305-8223},
  doi = {10/gmbv3k},
  abstract = {The narrative permeating higher education institutions globally is the assimilation of advancing information and communications technology into mainstream Mathematics Education. In this paper we report on a mixed mode case study which explored possible mathematical gaps that created barrier/s when engineering students (n=162) worked with the online diagnostic tests. These engineering students were provided with online tasks on the learner management system (LMS) on factorization, fractions and logarithms. The study was carried out at a University of Technology in South Africa. The data collected from the LMS and written responses of students to quizzes were analysed. Findings emanating from the data analysis indicated that 1) all diagnostic tests logged positive increase in group averages, 2) greater repetition by students invoked better procedural proficiency and 3) better understanding of the basic mathematics leads to greater success in higher mathematics.},
  langid = {english},
  keywords = {Algebra,Calculus,College Freshmen,Diagnostic Tests,Electronic Learning,Engineering Education,Foreign Countries,Fractions,Fundamental Concepts,Integrated Learning Systems,Introductory Courses,Learning Analytics,Mathematical Concepts,Mathematics Education,Mathematics Skills,Numbers,Problem Solving,Repetition}
}

@article{brindleyCreatingEffectiveCollaborative2009,
  title = {Creating {{Effective Collaborative Learning Groups}} in an {{Online Environment}}},
  author = {Brindley, Jane and Blaschke, Lisa Marie and Walti, Christine},
  year = {2009},
  journal = {The International Review of Research In Open and Distance Learning},
  volume = {10},
  number = {3},
  abstract = {Collaborative learning in an online classroom can take the form of discussion among the whole class or within smaller groups. This paper addresses the latter, examining first whether assessment makes a difference to the level of learner participation and then considering other factors involved in creating effective collaborative learning groups. Data collected over a three year period (15 cohorts) from the Foundations course in the Master of Distance Education (MDE) program offered jointly by University of Maryland University College (UMUC) and the University of Oldenburg does not support the authors{\quotesinglbase}{\"A}{\^o} original hypothesis that assessment makes a significant difference to learner participation levels in small group learning projects and leads them to question how much emphasis should be placed on grading work completed in study groups to the exclusion of other strategies. Drawing on observations of two MDE courses, including the Foundations course, their extensive online teaching experience, and a review of the literature, the authors identify factors other than grading that contribute positively to the effectiveness of small collaborative learning groups in the online environment. In particular, the paper focuses on specific instructional strategies that facilitate learner participation in small group projects, which result in an enhanced sense of community, increased skill acquisition, and better learning outcomes.},
  keywords = {collaborative,Design,Distance,E-learning,Education,Instructional,learner,LEARNING,motivation,Online,open,Pedagogy}
}

@article{brinthauptWhatBestOnline2011,
  title = {What the Best Online Teachers Should Do},
  shorttitle = {What the Best Online Teachers Should Do},
  author = {Brinthaupt, T. M. and Fisher, L. S. and Gardner, J. G. and Raffo, D. M. and Woodard, J. B.},
  year = {2011},
  journal = {MERLOT Journal of Online Learning and Teaching},
  volume = {7},
  pages = {515--524},
  abstract = {As a core project, a university eLearning Pedagogy Faculty Learning Community (FLC) chose to apply recommendations for the ``art'' of good teaching to the online realm. There is relatively little discussion of this issue in the literature. In this paper, we use Bain{\quotedblbase}s (2004) book What the Best College Teachers Do to discuss some of the major ways that the practices of effective teaching in general can be applied to online teaching in particular. Specifically, we explore methods of fostering student engagement, stimulating intellectual development, and building rapport with students when teaching online. This analysis provides a much-needed ``art of teaching'' set of recommendations that complements the ``science of teaching'' best practices approach to online pedagogy.},
  keywords = {best practices,effective teaching,Ken Bain,online pedagogy},
  annotation = {4}
}

@article{BritishJournalEducational1971,
  title = {British Journal of Educational Technology ({{Online}})},
  year = {1971},
  journal = {British journal of educational technology (Online)},
  publisher = {National Council for Educational Technology},
  address = {London},
  issn = {1467-8535},
  keywords = {Audio-visual education,Education,Educational innovations,Educational technology,Electronic journals,Enseignement -- Innovations,Enseignement -- Methodes audiovisuelles,Materiel didactique,Onderwijstechnologie,Periodicals,Teaching -- Aids and devices,Technologie educative}
}

@article{broadbentSelfregulatedLearningStrategies2015,
  title = {Self-Regulated Learning Strategies \& Academic Achievement in Online Higher Education Learning Environments: {{A}} Systematic Review},
  author = {Broadbent, J. and Poon, W. L.},
  year = {2015},
  journal = {The Internet and Higher Education},
  volume = {27},
  pages = {1--13},
  issn = {1096-7516},
  doi = {10.1016/j.iheduc.2015.04.007},
  abstract = {As enrolments in online courses continue to increase, there is a need to understand how students can best apply self-regulated learning strategies to achieve academic success within the online environment. A search of relevant databases was conducted in December 2014 for studies published from 2004 to Dec 2014 examining SRL strategies as correlates of academic achievement in online higher education settings. From 12 studies, the strategies of time management, metacognition, effort regulation, and critical thinking were positively correlated with academic outcomes, whereas rehearsal, elaboration, and organisation had the least empirical support. Peer learning had a moderate positive effect, however its confidence intervals crossed zero. Although the contributors to achievement in traditional face-to-face settings appear to generalise to on-line context, these effects appear weaker and suggest that (1) they may be less effective, and (2) that other, currently unexplored factors may be more important in on-line contexts.},
  keywords = {Academic achievement,Distance education,Higher education,meta-cognition,Online,Self-regulated learning strategies,University}
}

@incollection{broadfootAssessmentTwentyFirstCenturyLearning2016,
  title = {Assessment for {{Twenty-First-Century Learning}}: {{The Challenges Ahead}}},
  shorttitle = {Assessment for {{Twenty-First-Century Learning}}},
  booktitle = {Learning, {{Design}}, and {{Technology}}},
  author = {Broadfoot, Patricia},
  editor = {Spector, Michael J and Lockee, Barbara B and Childress, Marcus D.},
  year = {2016},
  pages = {1--23},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-17727-4_64-1},
  urldate = {2021-01-04},
  isbn = {978-3-319-17727-4},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/I42CV6HP/broadfootAssessmentTwentyFirstCenturyLearning2016.pdf}
}

@incollection{broadfootSeedsChangePotential2014,
  title = {Seeds of {{Change}}: {{The Potential}} of the {{Digital Revolution}} to {{Promote Enabling Assessment}}},
  shorttitle = {Seeds of {{Change}}},
  booktitle = {Designing {{Assessment}} for {{Quality Learning}}},
  author = {Broadfoot, Patricia and Oldfield, Alison and Sutherland, Rosamund and Timmis, Sue},
  editor = {{Wyatt-Smith}, Claire and Klenowski, Valentina and Colbert, Peta},
  year = {2014},
  volume = {1},
  pages = {373--386},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-94-007-5902-2_23},
  urldate = {2022-05-07},
  isbn = {978-94-007-5901-5 978-94-007-5902-2},
  file = {/Users/colin.madland/Zotero/storage/W6JXGTYN/broadfootSeedsChangePotential2014.pdf}
}

@article{brockerhoff-macdonaldFlexibleWeightingOnline2018,
  title = {Flexible {{Weighting}} in {{Online Distance Education Courses}}},
  author = {{Brockerhoff-Macdonald}, Bettina and Morrison, Moira and Manitowabi, Susan},
  year = {2018},
  journal = {International Journal of E-Learning \& Distance Education},
  volume = {33},
  number = {1},
  pages = {1--14},
  publisher = {Canadian Network for Innovation in Education},
  address = {Ottawa},
  issn = {2292-8588},
  abstract = {Are current evaluation scheme practices really inclusive of differing teaching and learning preferences and cultural sensitivities? Are students and faculty satisfied with the assignments they have now? Do assignments accurately reflect a student's learning and skill acquisition? How can students be given assignment options to engage them more fully without increasing workload for faculty? This paper will examine how the flexible weighting option responds to the learning needs of students by promoting their success, building on their strengths, and giving them a sense of ownership and choice. Results of this pilot project have shown that flexible weighting can encourage student engagement and reduce their stress. What does this mean for faculty? Any course with a variety of assignments can implement flexible weighting. Flexible weighting can be successfully applied in courses regardless of the method of delivery and can be adapted for courses in a variety of disciplines.},
  keywords = {Computers,Core curriculum,Distance learning,Flexible weighting options,Higher education,Instructional design,Literature reviews,Mental health,Native North Americans,No DOI found,Online instruction,online learning,Perceptions,Pilot projects,Skills,Stress,Studies,Teaching,University students}
}

@article{brookhartCenturyGradingResearch2016,
  title = {A {{Century}} of {{Grading Research}}: {{Meaning}} and {{Value}} in the {{Most Common Educational Measure}}},
  shorttitle = {A {{Century}} of {{Grading Research}}},
  author = {Brookhart, Susan M. and Guskey, Thomas R. and Bowers, Alex J. and McMillan, James H. and Smith, Jeffrey K. and Smith, Lisa F. and Stevens, Michael T. and Welsh, Megan E.},
  year = {2016},
  month = dec,
  journal = {Review of Educational Research},
  volume = {86},
  number = {4},
  pages = {803--848},
  issn = {0034-6543, 1935-1046},
  doi = {10/gd2z6r},
  urldate = {2020-10-24},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/UBUWGVAH/brookhartCenturyGradingResearch2016.pdf}
}

@book{brookhartClassroomAssessmentEducational2019,
  title = {Classroom {{Assessment}} and {{Educational Measurement}}},
  editor = {Brookhart, Susan M. and McMillan, James H.},
  year = {2019},
  month = jul,
  edition = {1},
  publisher = {Routledge},
  doi = {10.4324/9780429507533},
  urldate = {2021-04-28},
  isbn = {978-0-429-50753-3},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/33S2XIUC/brookhartClassroomAssessmentEducational2019.pdf}
}

@article{brookhartDevelopingMeasurementTheory2003,
  title = {Developing {{Measurement Theory}} for {{Classroom Assessment Purposes}} and {{Uses}}},
  author = {Brookhart, Susan M.},
  year = {2003},
  month = dec,
  journal = {Educational Measurement: Issues and Practice},
  volume = {22},
  number = {4},
  pages = {5--12},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {0731-1745},
  doi = {10/dj7bxr},
  urldate = {2020-09-29},
  abstract = {In many fields of inquiry, the need for new theoretical developments is often best seen in areas of strain, and strain is apparent in several areas in which the conventions of measurement theory do not quite ?fit? classroom assessment. Three areas of strain are analyzed in order to suggest how theoretical development might focus directly on information quality in the classroom assessment context. This article describes the context dependence of classroom assessment, its inextricable relationship with instruction, and its simultaneous formative and summative functions. Thus a case is made for new theoretical developments in the area of measurement in the classroom.},
  keywords = {classroom assessment,reliability,validity},
  file = {/Users/colin.madland/Zotero/storage/HFMHZGQS/brookhartDevelopingMeasurementTheory2003.pdf}
}

@article{brookhartEducationalAssessmentKnowledge2011,
  title = {Educational {{Assessment Knowledge}} and {{Skills}} for {{Teachers}}},
  author = {Brookhart, Susan M.},
  year = {2011},
  journal = {Educational Measurement: Issues and Practice},
  volume = {30},
  pages = {3--12},
  doi = {10/cwcqj4},
  abstract = {The 1990 Standards for Teacher Competence in Educational Assessment of Students (AFT, NCME, \& NEA, 1990) made a documentable contribution to the field. However, the Standards have become a bit dated, most notably in two ways: (1) the Standards do not consider current conceptions of formative assessment knowledge and skills, and (2) the Standards do not consider teacher knowledge and skills required to successfully work in the current accountability and ``standards-based reform'' context. This article briefly reviews the 1990 Standards and their influence, describes some other lists of assessment knowledge and skills that might be considered in updating them, and then proposes educational assessment knowledge and skills for teachers that reflect current teacher assessment needs. This set of competencies should help focus the work of teachers, teacher supervisors, professional developers, teacher educators, and others responsible for teachers' assessment knowledge and skills.},
  file = {/Users/colin.madland/Zotero/storage/3ACZNMF8/brookhartEducationalAssessmentKnowledge2011.pdf}
}

@misc{brookhartEightEssentialPrinciples,
  title = {Eight {{Essential Principles}} for {{Improving Grading}} - {{Educational Leadership}}},
  author = {Brookhart, Susan and Guskey, Thomas R. and McTighe, Jay and Wiliam, Dylan},
  urldate = {2020-10-29},
  abstract = {Done well, grading can play a key role in a balanced district assessment system. At the 2019 Learning Sciences International's National Formative Assessment Conference, the four of us participated in a panel session to explore the place of grading as an important component of comprehensive and balanced district assessment systems. After this panel discussion, we met to summarize our discussion and make recommendations for how grading might be improved to enhance student learning, supporting our points with research and our practical experiences. Here are some of our thoughts on needed improvements.1},
  file = {/Users/colin.madland/Zotero/storage/3FFZTY6T/Eight-Essential-Principles-for-Improving-Grading.html}
}

@article{brookhartGradedAchievementTested2015,
  title = {Graded {{Achievement}}, {{Tested Achievement}}, and {{Validity}}},
  author = {Brookhart, Susan M.},
  year = {2015},
  journal = {Educational Assessment},
  volume = {20},
  number = {4},
  pages = {268--296},
  publisher = {Routledge},
  issn = {1062-7197},
  doi = {10/ghvkg9},
  abstract = {Twenty-eight studies of grades, over a century, were reviewed using the argument-based approach to validity suggested by Kane as a theoretical framework. The review draws conclusions about the meaning of graded achievement, its relation to tested achievement, and changes in the construct of graded achievement over time. Graded achievement reflects students' broad accomplishment of classroom and school learning goals, including goals about how to learn. Both high school and elementary grades contain information about school achievement that includes being socialized into the way learning happens in classrooms. Graded achievement reflects specific course learning goals and therefore varies according to subject; academic course grades align more closely with tested achievement than noncore course grades. Graded achievement also reflects individual teachers' grading practices and emphases about what is important to learn. Report card grades can be reliable and valid measures of graded achievement, but may not be depending on individual teachers' grading practices.}
}

@article{brookhartLearningPrimarySource2018,
  title = {Learning {{Is}} the {{Primary Source}} of {{Coherence}} in {{Assessment}}},
  author = {Brookhart, Susan M.},
  year = {2018},
  journal = {Educational Measurement: Issues and Practice},
  volume = {37},
  number = {1},
  pages = {35--38},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {0731-1745},
  doi = {10/gjn22f},
  urldate = {2021-04-08},
  file = {/Users/colin.madland/Zotero/storage/KERBX4Z5/brookhartLearningPrimarySource2018.pdf}
}

@article{brookhartQualityEffectivenessDescriptive2015,
  title = {The Quality and Effectiveness of Descriptive Rubrics},
  author = {Brookhart, Susan M. and Chen, Fei},
  year = {2015},
  month = jul,
  journal = {Educational Review},
  volume = {67},
  number = {3},
  pages = {343--368},
  issn = {0013-1911, 1465-3397},
  doi = {10.1080/00131911.2014.929565},
  urldate = {2024-04-19},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/GJULJAC6/brookhartQualityEffectivenessDescriptive2015.pdf}
}

@article{brookhartSuccessfulStudentsFormative2001,
  title = {Successful Students Formative and Summative Uses of Assessment Information},
  author = {Brookhart, Susan M.},
  year = {2001},
  journal = {Assessment in Education: Principles, Policy \& Practice},
  doi = {10/cft2wk},
  abstract = {The purpose of this study was to document successful students' perceptions about the formative and summative aspects of classroom assessments. Interviews with 50 students in high school English and Anatomy classes, about specific classroom assessment events, were coded according to students' descriptions of the formative and summative aspects of the assessments. These successful students engaged in self-assessment as a regular, ongoing process and actively tried to fit new information about their learning into their careers as students. They did not make neat distinctions between formative and summative assessment, but used assessment in a variety of integrated ways. This is consistent with their outlook on learning, which they reported viewing as one of their important life processes.},
  pmcid = {null},
  pmid = {null}
}

@article{brookhartSuccessfulStudentsFormative2001a,
  title = {Successful Students Formative and Summative Uses of Assessment Information},
  author = {Brookhart, Susan M.},
  year = {2001},
  journal = {Assessment in Education: Principles, Policy \& Practice},
  doi = {10/cft2wk},
  abstract = {The purpose of this study was to document successful students' perceptions about the formative and summative aspects of classroom assessments. Interviews with 50 students in high school English and Anatomy classes, about specific classroom assessment events, were coded according to students' descriptions of the formative and summative aspects of the assessments. These successful students engaged in self-assessment as a regular, ongoing process and actively tried to fit new information about their learning into their careers as students. They did not make neat distinctions between formative and summative assessment, but used assessment in a variety of integrated ways. This is consistent with their outlook on learning, which they reported viewing as one of their important life processes.},
  pmcid = {null},
  pmid = {null}
}

@article{brookhartTeachersGradingPractices1993,
  title = {Teachers' {{Grading Practices}}: {{Meaning}} and {{Values}}},
  shorttitle = {Teachers' {{Grading Practices}}},
  author = {Brookhart, Susan M.},
  year = {1993},
  month = jun,
  journal = {Journal of Educational Measurement},
  volume = {30},
  number = {2},
  pages = {123--142},
  issn = {0022-0655, 1745-3984},
  doi = {10/cqsh3c},
  urldate = {2020-10-29},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/GQMHBGE8/brookhartTeachersGradingPractices1993.pdf}
}

@article{brookhartTheoreticalFrameworkRole1997,
  title = {A {{Theoretical Framework}} for the {{Role}} of {{Classroom Assessment}} in {{Motivating Student Effort}} and {{Achievement}}},
  author = {Brookhart, Susan M.},
  year = {1997},
  month = apr,
  journal = {Applied Measurement in Education},
  volume = {10},
  number = {2},
  pages = {161--180},
  issn = {0895-7347, 1532-4818},
  doi = {10/c9jmtr},
  urldate = {2021-06-30},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/JZRXWU79/brookhartTheoreticalFrameworkRole1997.pdf}
}

@article{Brown_2010,
  title = {The Validity of Examination Essays in Higher Education Issues and Responses},
  author = {Brown, Gavin T. L.},
  year = {2010},
  journal = {Higher Education Quarterly},
  doi = {10/d56dtw},
  abstract = {The use of timed, essay examinations is a well-established means of evaluating student learning in higher education. The reliability of essay scoring is highly problematic and it appears that essay examination grades are highly dependent on language and organisational components of writing. Computer-assisted scoring of essays makes use of language features and has demonstrated strong similarity to human ratings. Studies of examiner behaviour show that attention to content and language features contributes to grading decisions. However, given the time constraints on essay examinations, an overemphasis on language aspects may weaken the validity of essay examination grades. This article suggests alternative approaches to the standard essay prompt which should raise the validity of essay tasks and scoring in higher education. Suggested options include redesigning tasks so that organisational and language features are less influential in scoring and the use of content maps.},
  mag_id = {1783430359},
  pmcid = {null},
  pmid = {null}
}

@article{Brown_2017,
  title = {Evaluating the Quality of Higher Education Instructor Constructed Multiple Choice Tests Impact on Student Grades},
  author = {Brown, Gavin T. L. and Abdulnabi, Hasan H. A.},
  year = {2017},
  journal = {Frontiers in Education},
  doi = {10/dxd8},
  abstract = {Multiple-choice questions (MCQs) are commonly used in higher education assessment tasks because they can be easily and accurately scored, while giving good coverage of instructional content in a short time. However, studies that have evaluated the quality of MCQs used in higher education assessments have found many flawed items, resulting in misleading insights about student performance and contaminating important decisions. Thus, MCQs need to be evaluated statistically to ensure high quality items are used as the basis of inferences. This study evaluated the quality of 100 instructor-written MCQs used in an undergraduate midterm test (50 items) and final exam (50 items), making up 50\% of the course grade, using the responses of 380 students enrolled in one 1st-year undergraduate general education course. Item difficulty, discrimination, and chance properties were determined using Classical Test Theory and Item Response Theory statistical item analysis models. The two-parameter logistic model consistently had the best fit to the data. The impact on overall course grades between the original raw score model and the IRT 2PL model showed 70\% of students would receive the same grade (i.e., D to A), but only one-third would get the same mark using the standard augmented grade scale (i.e., A+ to D-). The analyses show that higher education institutions need to ensure MCQs are evaluated before student grading decisions are made.},
  mag_id = {2618975095},
  pmcid = {null},
  pmid = {null},
  file = {/Users/colin.madland/Zotero/storage/A7VSKK76/Brown_2017.pdf}
}

@article{browneOverviewAnalyticRotation2001,
  title = {An {{Overview}} of {{Analytic Rotation}} in {{Exploratory Factor Analysis}}},
  author = {Browne, Michael W.},
  year = {2001},
  month = jan,
  journal = {Multivariate Behavioral Research},
  volume = {36},
  number = {1},
  pages = {111--150},
  publisher = {Routledge},
  issn = {0027-3171},
  doi = {10.1207/S15327906MBR3601_05},
  abstract = {The use of analytic rotation in exploratory factor analysis will be examined. Particular attention will be given to situations where there is a complex factor pattern and standard methods yield poor solutions. Some little known but interesting rotation criteria will be discussed and methods for weighting variables will be examined. Illustrations will be provided using Thurstone's 26 variable box data and other examples.},
  file = {/Users/colin.madland/Zotero/storage/NUKPFMRL/browneOverviewAnalyticRotation2001.pdf}
}

@book{brownEthicalUseTechnology2020,
  title = {{Ethical Use of Technology in Digital Learning Environments Graduate Student Perspectives}},
  author = {Brown, Barbara and Roberts, Verena and Jacobsen, Michele and {Open Textbook Library}},
  year = {2020},
  urldate = {2022-01-14},
  abstract = {This book is the result of a co-design project in a class in the Masters of Education program at the University of Calgary. The course, and the resulting book, focus primarily on the safe and ethical use of technology in digital learning environments. The course was organized according to four topics based on Farrow's (2016) Framework for the Ethics of Open Education.},
  isbn = {978-0-88953-438-4},
  langid = {In English},
  keywords = {archived},
  annotation = {https://doi.org/10.11575/ant1-kb38}
}

@article{brownEvaluatingQualityHigher2017,
  title = {Evaluating the {{Quality}} of {{Higher Education Instructor-Constructed Multiple-Choice Tests}}: {{Impact}} on {{Student Grades}}},
  shorttitle = {Evaluating the {{Quality}} of {{Higher Education Instructor-Constructed Multiple-Choice Tests}}},
  author = {Brown, Gavin T. L. and Abdulnabi, Hasan H. A.},
  year = {2017},
  month = jun,
  journal = {Frontiers in Education},
  volume = {2},
  pages = {24},
  issn = {2504-284X},
  doi = {10/dxd8},
  urldate = {2020-12-05},
  file = {/Users/colin.madland/Zotero/storage/JHP34MSK/brownEvaluatingQualityHigher2017a.pdf}
}

@article{brownEvaluatingQualityHigher2017a,
  title = {Evaluating the {{Quality}} of {{Higher Education Instructor-Constructed Multiple-Choice Tests}}: {{Impact}} on {{Student Grades}}},
  author = {Brown, Gavin T. L. and Abdulnabi, Hasan H. A.},
  year = {2017},
  journal = {Frontiers in Education},
  volume = {2},
  pages = {24},
  issn = {2504-284X},
  doi = {10/dxd8},
  abstract = {Multiple-choice questions (MCQs) are commonly used in higher education assessment tasks because they can be easily and accurately scored, while giving good coverage of instructional content in a short time. However, studies that have evaluated the quality of MCQs used in higher education assessments have found many flawed items, resulting in misleading insights about student performance and contaminating important decisions. Thus, MCQs need to be evaluated statistically to ensure high-quality items are used as the basis of inference. This study evaluated the quality of 100 instructor-written MCQs used in an undergraduate midterm test (50 items) and final exam (50 items), making up 50\% of the course grade, using the responses of 372 students enrolled in one first-year undergraduate general education course. Item difficulty, discrimination, and chance properties were determined using classical test theory and item response theory (IRT) statistical item analysis models. The two-parameter logistic (2PL) model consistently had the best fit to the data. The impact on overall course grades between the original raw score model and the IRT 2PL model showed 70\% of students would receive the same grade (i.e., D to A), but only one-third would get the same mark using the standard augmented grade scale (i.e., A+ to D-). The analyses show that higher education institutions need to ensure MCQs are evaluated before student grading decisions are made.},
  file = {/Users/colin.madland/Zotero/storage/62S5E8ZN/brownEvaluatingQualityHigher2017.pdf}
}

@article{brownFutureAssessmentHuman2017,
  title = {The {{Future}} of {{Assessment}} as a {{Human}} and {{Social Endeavor}}: {{Addressing}} the {{Inconvenient Truth}} of {{Error}}},
  shorttitle = {The {{Future}} of {{Assessment}} as a {{Human}} and {{Social Endeavor}}},
  author = {Brown, Gavin T. L.},
  year = {2017},
  month = feb,
  journal = {Frontiers in Education},
  volume = {2},
  issn = {2504-284X},
  doi = {10/gg29sw},
  urldate = {2020-06-26},
  file = {/Users/colin.madland/Zotero/storage/447JPINS/brownFutureAssessmentHuman2017.pdf}
}

@article{brownFutureAssessmentHuman2017a,
  title = {The {{Future}} of {{Assessment}} as a {{Human}} and {{Social Endeavor}}: {{Addressing}} the {{Inconvenient Truth}} of {{Error}}},
  shorttitle = {The {{Future}} of {{Assessment}} as a {{Human}} and {{Social Endeavor}}},
  author = {Brown, Gavin T. L.},
  year = {2017},
  month = feb,
  journal = {Frontiers in Education},
  volume = {2},
  issn = {2504-284X},
  doi = {10.3389/feduc.2017.00003},
  urldate = {2022-10-26},
  file = {/Users/colin.madland/Zotero/storage/UCWMH6ZH/brownFutureAssessmentHuman2017a.pdf}
}

@article{brownMovingKnowledgebuildingLessons2023,
  title = {Moving beyond Knowledge-Building: Lessons in Action-Oriented Antiracism Trainings},
  author = {Brown, Ian and Budish, Elaine Farber and Greene, Jennifer and {Stevens-Carter}, Wyvonne},
  year = {2023},
  journal = {COABE Journal: The Resource for Adult Education},
  volume = {12},
  number = {2},
  pages = {23--32},
  publisher = {Commission on Adult Basic Education},
  issn = {27719375},
  abstract = {The Massachusetts Department of Elementary and Secondary Education Adult and Community Learning Services Unit and UPD Consulting engaged in a multiyear partnership to provide adult education providers across the state with people-centered, action-oriented training opportunities focused on antiracism, diversity, equity, and inclusion (ADEI). This article explores the evolution of nine key strategies applied by the design and facilitation team as they engaged participants across the triad of thinking (head), feeling (heart), and doing (hands). [ABSTRACT FROM AUTHOR]},
  keywords = {ADEI,ADULT education,ANTI-racism,antiracism,CAREER development,change management,DEI,ELEMENTARY education,leadership,MASSACHUSETTS,No DOI found,professional development,SECONDARY education,training},
  file = {/Users/colin.madland/Zotero/storage/QEKUEQG9/brownMovingKnowledgebuildingLessons2023.pdf}
}

@article{brownQueenslandTeachersConceptions2011,
  title = {Queensland Teachers' Conceptions of Assessment: {{The}} Impact of Policy Priorities on Teacher Attitudes},
  shorttitle = {Queensland Teachers' Conceptions of Assessment},
  author = {Brown, Gavin T.L. and Lake, Robert and Matters, Gabrielle},
  year = {2011},
  month = jan,
  journal = {Teaching and Teacher Education},
  volume = {27},
  number = {1},
  pages = {210--220},
  issn = {0742051X},
  doi = {10/c3k8f5},
  urldate = {2021-07-14},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/42LV6TV7/brownQueenslandTeachersConceptions2011.pdf}
}

@article{brownReimaginingPedagogicalParadigm2019,
  title = {Re-Imagining the {{Pedagogical Paradigm Within}} a {{Technology Mediated Learning Environment}}},
  author = {Brown, Ken and Larionova, Viola and Stepanova, Natalia and Lally, Vic},
  year = {2019},
  journal = {Open Education Studies},
  volume = {1},
  number = {1},
  pages = {138--145},
  publisher = {De Gruyter Open},
  issn = {2544-7831},
  doi = {10.1515/edu-2019-0009},
  abstract = {Traditional didactic pedagogies employed within the culture of the Russian higher education system precluded students' engagement with problems which were described as generating dissonances in learning cognition. Addressing issues of dissonance within the higher education learning sphere requires re-imagining the educational culture. Re-imagining provides an opportunity to promote new approaches to learning through alternative affordances; one such affordance is technology mediated learning. Pedagogical re-design within an alternative learning paradigm requires deep understanding of the problems associated with the previous paradigm. Re-imagined pedagogical scope for exploration of the professional, learning, cultural, institutional and technical aspects expand the knowledge base beyond the didactic towards an engaging student-centered ethos using open education and gamification. To address issues of learning, culture, technology, and institution, a convergent mixed methods design using student questionnaires and academic interviews alongside performance observations was employed. The research study examined the re-imagining of the educational culture to promote new approaches to learning through the affordances of technology mediated learning within a constructivist, critical realism epistemology using thematic analysis. The re-imagined pedagogical design within a technology mediated learning environment demonstrates a cultural shift towards an engaging and supportive educational experience. The lessons learned may be applied in other higher educational contexts.},
  keywords = {e-learning,Education,gamification,learning,open education,student engagement,technology mediated learning},
  file = {/Users/colin.madland/Zotero/storage/KKGA7R2S/brownReimaginingPedagogicalParadigm2019.pdf}
}

@article{brownSchoolingCOVID19Unevenly2020,
  title = {Schooling {{Beyond COVID-19}}: {{An Unevenly Distributed Future}}},
  author = {Brown, Gavin},
  year = {2020},
  journal = {Frontiers in Education},
  doi = {10.3389/feduc.2020.00082},
  abstract = {The COVID-19 pandemic crisis has had a major impact on how schooling is done. With schools closed, teaching and learning continue dependent on information and communication technologies (ICT). To the degree that this has been a success, there is the possibility that post-pandemic societies might choose to de-school, switching to online teaching and learning only. In this perspective piece, I describe two major risks if that future were to be embraced; that is, lack of equitable access and dehumanization. My argument is that these futures already exist in pockets around the globe and we can use those experiences to evaluate those options. I suggest instead that the post-pandemic period gives us an opportunity to re-imagine what schools and schooling are for and advocate for a re-schooled society in which our investment in schools builds and develops society.},
  file = {/Users/colin.madland/Zotero/storage/DNBDU4RA/brownSchoolingCOVID19Unevenly2020.pdf}
}

@article{brownSelfregulationAssessmentBeliefs2011,
  title = {Self-Regulation of Assessment Beliefs and Attitudes: A Review of the {{Students}}' {{Conceptions}} of {{Assessment}} Inventory},
  shorttitle = {Self-Regulation of Assessment Beliefs and Attitudes},
  author = {Brown, Gavin T. L.},
  year = {2011},
  month = oct,
  journal = {Educational Psychology},
  volume = {31},
  number = {6},
  pages = {731--748},
  issn = {0144-3410, 1469-5820},
  doi = {10/d5wqx7},
  urldate = {2021-07-04},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/L7YMQM5N/brownSelfregulationAssessmentBeliefs2011.pdf}
}

@article{brownStudentConceptionsAssessment2022,
  title = {Student {{Conceptions}} of {{Assessment}}: {{Regulatory Responses}} to {{Our Practices}}},
  author = {Brown, Gavin T. L.},
  editor = {Yin, Hongbiao},
  year = {2022},
  journal = {ECNU review of education (Online)},
  volume = {5},
  number = {1},
  pages = {116--139},
  publisher = {SAGE Publications},
  address = {London, England},
  issn = {2096-5311},
  doi = {10.1177/20965311211007869},
  abstract = {Purpose: Universities assess and evaluate students concerning competence in essential disciplinary knowledge and skills. Those assessments impact learners' attitudes, beliefs, and emotions. Negative impacts may be overcome if students regulate their responses to assessment and feedback. Design/Approach/Methods: This article systematically locates research studies that cite three key early papers around student conceptions of assessment (SCoA). A narrative synthesis is based on 22 papers. Findings: In addition to the SCoA, 11 different research inventories reveal a variety of regulatory responses that are enhanced when assessments are deliberately formative, fair, and trustworthy. There is broad interest in this phenomenon but little consistency in methods, and even the SCoA has little consistency in factor structure across jurisdictions. Only one study provided an objective behavioral measure to validate self-reports, which are the dominant form of research. Originality/Value: This review gives readers insights into how assessment influences student thinking and how student cognition can regulate success.;Purpose: Universities assess and evaluate students concerning competence in essential disciplinary knowledge and skills. Those assessments impact learners' attitudes, beliefs, and emotions. Negative impacts may be overcome if students regulate their responses to assessment and feedback. Design/Approach/Methods: This article systematically locates research studies that cite three key early papers around student conceptions of assessment (SCoA). A narrative synthesis is based on 22 papers. Findings: In addition to the SCoA, 11 different research inventories reveal a variety of regulatory responses that are enhanced when assessments are deliberately formative, fair, and trustworthy. There is broad interest in this phenomenon but little consistency in methods, and even the SCoA has little consistency in factor structure across jurisdictions. Only one study provided an objective behavioral measure to validate self-reports, which are the dominant form of research. Originality/Value: This review gives readers insights into how assessment influences student thinking and how student cognition can regulate success.;},
  langid = {english}
}

@article{brownStudentConceptionsFeedback2016,
  title = {Student Conceptions of Feedback: {{Impact}} on Self-Regulation, Self-Efficacy, and Academic Achievement},
  author = {Brown, Gavin T. L. and Peterson, Elizabeth R. and Yao, Esther S.},
  year = {2016},
  journal = {British journal of educational psychology},
  volume = {86},
  number = {4},
  pages = {606--629},
  publisher = {Blackwell Publishing Ltd},
  address = {HOBOKEN},
  issn = {0007-0998},
  doi = {10.1111/bjep.12126},
  abstract = {Background: Lecturers give feedback on assessed work in the hope that students will take it on board and use it to help regulate their learning for the next assessment. However, little is known about how students' conceptions of feedback relate to students' self-regulated learning and self-efficacy beliefs and academic performance. Aims: This study explores student beliefs about the role and purpose of feedback and the relationship of those beliefs to self-reported self-regulation and self-efficacy, and achievement. Sample: A total of 278 university students in a general education course on learning theory and approaches in a research-intensive university. Methods: Self-reported survey responses for students' conceptions of feedback (SCoF), self-regulation (SRL), academic self-efficacy (ASE), and Grade Point Average (GPA) were evaluated first with confirmatory factor analysis and then interlinked in a structural equation~model. Results and conclusions: Three SCoF factors predicted SRL and/or GPA. The SCoF factor "I use feedback" had positive associations with SRL ({\ss}~=~0.44), GPA ({\ss}~=~0.45), and ASE ({\ss}~=~0.15). The SCoF factors "tutor/marker comments" and "peers help" both had negative relations to GPA ({\ss}~=~-0.41 and -0.16, respectively). "Peers help" had a positive connection to SRL ({\ss}~=~0.21). ASE itself made a small contribution to overall GPA ({\ss}~=~0.16), while SRL had no statistically significant relation to GPA. The model indicates the centrality of believing that feedback exists to guide next steps in learning and thus contributes to SRL, ASE, and increased GPA.;BACKGROUNDLecturers give feedback on assessed work in the hope that students will take it on board and use it to help regulate their learning for the next assessment. However, little is known about how students' conceptions of feedback relate to students' self-regulated learning and self-efficacy beliefs and academic performance.AIMSThis study explores student beliefs about the role and purpose of feedback and the relationship of those beliefs to self-reported self-regulation and self-efficacy, and achievement.SAMPLEA total of 278 university students in a general education course on learning theory and approaches in a research-intensive university.METHODSSelf-reported survey responses for students' conceptions of feedback (SCoF), self-regulation (SRL), academic self-efficacy (ASE), and Grade Point Average (GPA) were evaluated first with confirmatory factor analysis and then interlinked in a structural equation~model.RESULTS AND CONCLUSIONSThree SCoF factors predicted SRL and/or GPA. The SCoF factor 'I use feedback' had positive associations with SRL ({$\beta~$}=~.44), GPA ({$\beta~$}=~.45), and ASE ({$\beta~$}=~.15). The SCoF factors 'tutor/marker comments' and 'peers help' both had negative relations to GPA ({$\beta~$}=~-.41 and -.16, respectively). 'Peers help' had a positive connection to SRL ({$\beta~$}=~.21). ASE itself made a small contribution to overall GPA ({$\beta~$}=~.16), while SRL had no statistically significant relation to GPA. The model indicates the centrality of believing that feedback exists to guide next steps in learning and thus contributes to SRL, ASE, and increased GPA.;Background Lecturers give feedback on assessed work in the hope that students will take it on board and use it to help regulate their learning for the next assessment. However, little is known about how students' conceptions of feedback relate to students' self-regulated learning and self-efficacy beliefs and academic performance. Aims This study explores student beliefs about the role and purpose of feedback and the relationship of those beliefs to self-reported self-regulation and self-efficacy, and achievement. Sample A total of 278 university students in a general education course on learning theory and approaches in a research-intensive university. Methods Self-reported survey responses for students' conceptions of feedback (SCoF), self-regulation (SRL), academic self-efficacy (ASE), and Grade Point Average (GPA) were evaluated first with confirmatory factor analysis and then interlinked in a structural equation model. Results and conclusions Three SCoF factors predicted SRL and/or GPA. The SCoF factor 'I use feedback' had positive associations with SRL ({$\beta$} = .44), GPA ({$\beta$} = .45), and ASE ({$\beta$} = .15). The SCoF factors 'tutor/marker comments' and 'peers help' both had negative relations to GPA ({$\beta$} = -.41 and -.16, respectively). 'Peers help' had a positive connection to SRL ({$\beta$} = .21). ASE itself made a small contribution to overall GPA ({$\beta$} = .16), while SRL had no statistically significant relation to GPA. The model indicates the centrality of believing that feedback exists to guide next steps in learning and thus contributes to SRL, ASE, and increased GPA.;Lecturers give feedback on assessed work in the hope that students will take it on board and use it to help regulate their learning for the next assessment. However, little is known about how students' conceptions of feedback relate to students' self-regulated learning and self-efficacy beliefs and academic performance. This study explores student beliefs about the role and purpose of feedback and the relationship of those beliefs to self-reported self-regulation and self-efficacy, and achievement. A total of 278 university students in a general education course on learning theory and approaches in a research-intensive university. Self-reported survey responses for students' conceptions of feedback (SCoF), self-regulation (SRL), academic self-efficacy (ASE), and Grade Point Average (GPA) were evaluated first with confirmatory factor analysis and then interlinked in a structural equation~model. Three SCoF factors predicted SRL and/or GPA. The SCoF factor 'I use feedback' had positive associations with SRL ({$\beta~$}=~.44), GPA ({$\beta~$}=~.45), and ASE ({$\beta~$}=~.15). The SCoF factors 'tutor/marker comments' and 'peers help' both had negative relations to GPA ({$\beta~$}=~-.41 and -.16, respectively). 'Peers help' had a positive connection to SRL ({$\beta~$}=~.21). ASE itself made a small contribution to overall GPA ({$\beta~$}=~.16), while SRL had no statistically significant relation to GPA. The model indicates the centrality of believing that feedback exists to guide next steps in learning and thus contributes to SRL, ASE, and increased GPA.;Background Lecturers give feedback on assessed work in the hope that students will take it on board and use it to help regulate their learning for the next assessment. However, little is known about how students' conceptions of feedback relate to students' self-regulated learning and self-efficacy beliefs and academic performance. Aims This study explores student beliefs about the role and purpose of feedback and the relationship of those beliefs to self-reported self-regulation and self-efficacy, and achievement. Sample A total of 278 university students in a general education course on learning theory and approaches in a research-intensive university. Methods Self-reported survey responses for students' conceptions of feedback (SCoF), self-regulation (SRL), academic self-efficacy (ASE), and Grade Point Average (GPA) were evaluated first with confirmatory factor analysis and then interlinked in a structural equation~model. Results and conclusions Three SCoF factors predicted SRL and/or GPA. The SCoF factor `I use feedback' had positive associations with SRL ({$\beta~$}=~.44), GPA ({$\beta~$}=~.45), and ASE ({$\beta~$}=~.15). The SCoF factors `tutor/marker comments' and `peers help' both had negative relations to GPA ({$\beta~$}=~-.41 and -.16, respectively). `Peers help' had a positive connection to SRL ({$\beta~$}=~.21). ASE itself made a small contribution to overall GPA ({$\beta~$}=~.16), while SRL had no statistically significant relation to GPA. The model indicates the centrality of believing that feedback exists to guide next steps in learning and thus contributes to SRL, ASE, and increased GPA.;Background. Lecturers give feedback on assessed work in the hope that students will take it on board and use it to help regulate their learning for the next assessment. However, little is known about how students' conceptions of feedback relate to students' self-regulated learning and self-efficacy beliefs and academic performance. Aims. This study explores student beliefs about the role and purpose of feedback and the relationship of those beliefs to self-reported self-regulation and self-efficacy, and achievement. Sample. A total of 278 university students in a general education course on learning theory and approaches in a research-intensive university. Methods. Self-reported survey responses for students' conceptions of feedback (SCoF), self-regulation (SRL), academic self-efficacy (ASE), and Grade Point Average (GPA) were evaluated first with confirmatory factor analysis and then interlinked in a structural equation model. Results and conclusions. Three SCoF factors predicted SRL and/or GPA. The SCoF factor 'I use feedback' had positive associations with SRL (beta = .44), GPA (beta = .45), and ASE (beta = .15). The SCoF factors 'tutor/marker comments' and 'peers help' both had negative relations to GPA (beta = -.41 and -.16, respectively). 'Peers help' had a positive connection to SRL (beta = .21). ASE itself made a small contribution to overall GPA (beta = .16), while SRL had no statistically significant relation to GPA. The model indicates the centrality of believing that feedback exists to guide next steps in learning and thus contributes to SRL, ASE, and increased GPA.;Byline: Gavin T. L. Brown, Elizabeth R. Peterson, Esther S. Yao Keywords: feedback; self-regulated learning; academic self-efficacy; beliefs and attitudes; higher education students Background Lecturers give feedback on assessed work in the hope that students will take it on board and use it to help regulate their learning for the next assessment. However, little is known about how students' conceptions of feedback relate to students' self-regulated learning and self-efficacy beliefs and academic performance. Aims This study explores student beliefs about the role and purpose of feedback and the relationship of those beliefs to self-reported self-regulation and self-efficacy, and achievement. Sample A total of 278 university students in a general education course on learning theory and approaches in a research-intensive university. Methods Self-reported survey responses for students' conceptions of feedback (SCoF), self-regulation (SRL), academic self-efficacy (ASE), and Grade Point Average (GPA) were evaluated first with confirmatory factor analysis and then interlinked in a structural equation model. Results and conclusions Three SCoF factors predicted SRL and/or GPA. The SCoF factor 'I use feedback' had positive associations with SRL ([beta] = .44), GPA ([beta] = .45), and ASE ([beta] = .15). The SCoF factors 'tutor/marker comments' and 'peers help' both had negative relations to GPA ([beta] = -.41 and -.16, respectively). 'Peers help' had a positive connection to SRL ([beta] = .21). ASE itself made a small contribution to overall GPA ([beta] = .16), while SRL had no statistically significant relation to GPA. The model indicates the centrality of believing that feedback exists to guide next steps in learning and thus contributes to SRL, ASE, and increased GPA.;},
  langid = {english},
  keywords = {Academic Achievement,academic self-efficacy,Achievement,Adult,Analysis,beliefs and attitudes,College Students,Correlation,Factor Analysis,Feedback,Feedback (Response),Feedback Psychological,Female,Grade Point Average,higher education students,Humans,Independent Study,Laws regulations and rules,Learning,Male,Peer Influence,Psychology,Psychology Educational,Self control,Self Efficacy,Self Management,self-regulated learning,Social Sciences,Structural Equation Models,Student Attitudes,Student Surveys,Students - psychology,Teacher Influence,Universities,Young Adult}
}

@article{brownStudentsConceptionsAssessment2008,
  title = {Students' Conceptions of Assessment: {{Links}} to Outcomes},
  shorttitle = {Students' Conceptions of Assessment},
  author = {Brown, Gavin T.L. and Hirschfeld, Gerrit H.F.},
  year = {2008},
  month = mar,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {15},
  number = {1},
  pages = {3--17},
  issn = {0969-594X, 1465-329X},
  doi = {10/b4mvnx},
  urldate = {2021-07-04},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/JGFEGZ8X/brownStudentsConceptionsAssessment2008.pdf}
}

@article{brownTeachersConceptionsAssessment2004,
  title = {Teachers' Conceptions of Assessment: Implications for Policy and Professional Development},
  shorttitle = {Teachers' Conceptions of Assessment},
  author = {Brown, Gavin T. L.},
  year = {2004},
  month = sep,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {11},
  number = {3},
  pages = {301--318},
  issn = {0969-594X, 1465-329X},
  doi = {10.1080/0969594042000304609},
  urldate = {2022-04-16},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/NUNVWSXA/brownTeachersConceptionsAssessment2004.pdf}
}

@article{brownTeachersConceptionsAssessment2006,
  title = {Teachers' {{Conceptions}} of {{Assessment}}: {{Validation}} of an {{Abridged Version}}},
  shorttitle = {Teachers' {{Conceptions}} of {{Assessment}}},
  author = {Brown, Gavin T. L.},
  year = {2006},
  month = aug,
  journal = {Psychological Reports},
  volume = {99},
  number = {1},
  pages = {166--170},
  issn = {0033-2941, 1558-691X},
  doi = {10/bf67hf},
  urldate = {2021-07-16},
  abstract = {Psychometric characteristics of the abridged Teachers' Conceptions of Assessment-III are reported. Data are from a study of 525 New Zealand primary school teachers and from a second study of 692 Queensland primary school teachers. The abridged version of 27 statements using a positively packed response scale had good fit characteristics for primary teachers in both New Zealand ({$\chi$}               311               2               = 841.02; RMSEA = .057; TLI = .87) and Queensland ({$\chi$}               311               2               = 1492.61; RMSEA = .074; TLI = .80). While providing information of similar quality to that of the original the abridged version is more efficient than the full scale.},
  langid = {english},
  keywords = {validation},
  file = {/Users/colin.madland/Zotero/storage/TUY988EK/brownTeachersConceptionsAssessment2006.pdf}
}

@article{brownTeachersConceptionsAssessment2011,
  title = {Teachers' Conceptions of Assessment: {{Comparing}} Primary and Secondary Teachers in {{New Zealand}}},
  shorttitle = {Teachers' Conceptions of Assessment},
  author = {Brown, Gavin T. L.},
  year = {2011},
  month = jun,
  journal = {Assessment Matters},
  volume = {3},
  pages = {45--70},
  issn = {11767839, 2230617X},
  doi = {10.18296/am.0097},
  urldate = {2022-06-22},
  file = {/Users/colin.madland/Zotero/storage/L2CCMPNZ/brownTeachersConceptionsAssessment2011.pdf}
}

@article{brownTeachersConceptionsAssessment2017,
  title = {Teachers {{Conceptions}} of {{Assessment}} - {{Secondary Schools Long}} and {{Abridged}}},
  author = {Brown, Gavin},
  year = {2017},
  publisher = {Figshare},
  doi = {10/gj4tz6},
  urldate = {2021-05-21},
  abstract = {All files associated with the TCoA-III Long and TCoA-IIIA for secondary schools. {$<$}br{$>$}The full questionnaire of 50 items was administered but only the abridged data was used for reporting. The long version of the data was not used for reporting, please see the TCoA-IIIA for secondary schools for data that was reported on. {$<$}br{$><$}br{$>$}The SPSS data file containing all data information collected from the TCoA-III Long questionnaire administered in 2007 for secondary schools. {$<$}br{$>$}The SPSS data file containing abridged data information collected from the TCoA-III Long questionnaire administered in 2007 for secondary schools. {$<$}br{$>$}The AMOS data file is the confirmatory factor analysis input for the secondary school TCoA-IIIA data set.{$<$}br{$>$}Survey instrument for self-administered usage. The full 50 item questionnaire was administered in 2007 for secondary schools.{$<$}br{$>$}Inventory results were published in:Brown, G. T. L. (2011). Teachers' conceptions of assessment: Comparing primary and secondary teachers in New Zealand.\emph{Assessment Matters, 3, }45-70.{$<$}br{$>$}UoA Library Repository: https://researchspace.auckland.ac.nz/handle/2292/24816{$<$}br{$>$}},
  copyright = {CC BY},
  keywords = {130106 Secondary Education,170103 Educational Psychology,Developmental and Educational Psychology,Education,FOS: Educational sciences,FOS: Psychology}
}

@article{brownTechNotAnswer2020,
  title = {Tech Is Not the {{Answer}}: {{An}} Assessor's Response to Online Digital Schooling},
  author = {Brown, Gavin},
  year = {2020},
  keywords = {No DOI found}
}

@article{brownValidityExaminationEssays2010,
  title = {The Validity of Examination Essays in Higher Education: {{Issues}} and Responses},
  author = {Brown, Gavin T. L.},
  year = {2010},
  journal = {Higher education quarterly},
  volume = {64},
  number = {3},
  pages = {276--291},
  publisher = {Blackwell Publishing Ltd},
  address = {Oxford, UK},
  issn = {0951-5224;0263-9769;},
  doi = {10.1111/j.1468-2273.2010.00460.x},
  abstract = {The use of timed, essay examinations is a well-established means of evaluating student learning in higher education. The reliability of essay scoring is highly problematic and it appears that essay examination grades are highly dependent on language and organisational components of writing. Computer-assisted scoring of essays makes use of language features and has demonstrated strong similarity to human ratings. Studies of examiner behaviour show that attention to content and language features contributes to grading decisions. However, given the time constraints on essay examinations, an overemphasis on language aspects may weaken the validity of essay examination grades. This article suggests alternative approaches to the standard essay prompt which should raise the validity of essay tasks and scoring in higher education. Suggested options include redesigning tasks so that organisational and language features are less influential in scoring and the use of content maps.;Byline: Gavin T. L. Brown (1) The use of timed, essay examinations is a well-established means of evaluating student learning in higher education. The reliability of essay scoring is highly problematic and it appears that essay examination grades are highly dependent on language and organisational components of writing. Computer-assisted scoring of essays makes use of language features and has demonstrated strong similarity to human ratings. Studies of examiner behaviour show that attention to content and language features contributes to grading decisions. However, given the time constraints on essay examinations, an overemphasis on language aspects may weaken the validity of essay examination grades. This article suggests alternative approaches to the standard essay prompt which should raise the validity of essay tasks and scoring in higher education. Suggested options include redesigning tasks so that organisational and language features are less influential in scoring and the use of content maps. Author Affiliation: (1)The Hong Kong Institute of Education,gtlbrown@ied.edu.hk;The use of timed, essay examinations is a well-established means of evaluating student learning in higher education. The reliability of essay scoring is highly problematic and it appears that essay examination grades are highly dependent on language and organisational components of writing. Computer-assisted scoring of essays makes use of language features and has demonstrated strong similarity to human ratings. Studies of examiner behaviour show that attention to content and language features contributes to grading decisions. However, given the time constraints on essay examinations, an overemphasis on language aspects may weaken the validity of essay examination grades. This article suggests alternative approaches to the standard essay prompt which should raise the validity of essay tasks and scoring in higher education. Suggested options include redesigning tasks so that organisational and language features are less influential in scoring and the use of content maps. Adapted from the source document.;The use of timed, essay examinations is a well-established means of evaluating student learning in higher education. The reliability of essay scoring is highly problematic and it appears that essay examination grades are highly dependent on language and organisational components of writing. Computer-assisted scoring of essays makes use of language features and has demonstrated strong similarity to human ratings. Studies of examiner behaviour show that attention to content and language features contributes to grading decisions. However, given the time constraints on essay examinations, an overemphasis on language aspects may weaken the validity of essay examination grades. This article suggests alternative approaches to the standard essay prompt which should raise the validity of essay tasks and scoring in higher education. Suggested options include redesigning tasks so that organisational and language features are less influential in scoring and the use of content maps. [PUBLICATION ABSTRACT];The use of timed, essay examinations is a well-established means of evaluating student learning in higher education. The reliability of essay scoring is highly problematic and it appears that essay examination grades are highly dependent on language and organisational components of writing. Computer-assisted scoring of essays makes use of language features and has demonstrated strong similarity to human ratings. Studies of examiner behaviour show that attention to content and language features contributes to grading decisions. However, given the time constraints on essay examinations, an overemphasis on language aspects may weaken the validity of essay examination grades. This article suggests alternative approaches to the standard essay prompt which should raise the validity of essay tasks and scoring in higher education. Suggested options include redesigning tasks so that organisational and language features are less influential in scoring and the use of content maps. (HRK / Abstract {\"u}bernommen).;},
  langid = {english},
  keywords = {Academic Achievement,Academic grading,Achievement tests,Ausland,Colleges and universities,Computer Assisted Testing,Education,Essay,Essay Tests,Essays,Grossbritannien,Higher Education,Lehre,Measurement,Rating,Reliability,Scoring,Standards,Student,Studium,Testing,Validity,Writing Skills}
}

@article{bruffeeSharingOurToys1995,
  title = {Sharing {{Our Toys}}: {{Cooperative Learning}} versus {{Collaborative Learning}}},
  author = {Bruffee, Kenneth A.},
  year = {1995},
  journal = {Change},
  volume = {27},
  number = {1},
  pages = {12--18}
}

@article{bruggemanExpertsSpeakingCrucial2021,
  title = {Experts Speaking: {{Crucial}} Teacher Attributes for Implementing Blended Learning in Higher Education},
  shorttitle = {Experts Speaking},
  author = {Bruggeman, Bram and Tondeur, Jo and Struyven, Katrien and Pynoo, Bram and Garone, Anja and Vanslambrouck, Silke},
  year = {2021},
  journal = {The Internet and Higher Education},
  volume = {48},
  pages = {100772},
  issn = {10967516},
  doi = {10/ghwf65},
  urldate = {2021-01-28},
  langid = {english}
}

@article{bruntonDuellingIdentitiesRefugees2019,
  title = {Duelling {{Identities}} in {{Refugees Learning}} through {{Open}}, {{Online Higher Education}}},
  author = {Brunton, James and Farrell, Orna and Costello, Eamon and Delaney, Lorraine and Foley, Colum and Brown, Mark},
  year = {2019},
  journal = {Open Praxis},
  volume = {11},
  number = {4},
  pages = {397--408},
  issn = {EISSN-2304-070X},
  doi = {10/gmbvx9},
  abstract = {This paper reports on a qualitative study of the transition experiences of refugees studying through open and online higher education. Online, open education programmes have considerable potential to provide flexible access to education for refugees, who are not well represented within higher education. As part of a wider University of Sanctuary initiative, interview data from six Ireland-based refugees was analysed using a data-led, qualitative methodological framework grounded in discursive psychology. Findings indicate that participants' transition narratives are typical in many ways as they form student identities while managing their existing identities and begin to feel, or not, that they belong. Participants constructed a stark divide between two duelling identities, between their identity as a refugee and their new identity as an online learner. Identification with the university was emphasised in contrast to disidentification with the 'asylum world'. These findings indicate that a strategically connected approach to supporting refugees transition into higher education can impact positively on these students.},
  langid = {english},
  keywords = {Access to Education,Adult Students,College Students,Cultural Differences,Foreign Countries,Identification (Psychology),Online Courses,Open Universities,Refugees,Student Adjustment,Student Attitudes,Student Needs}
}

@book{bryanInnovativeAssessmentHigher2006,
  title = {Innovative Assessment in Higher Education},
  author = {Bryan, {\relax Cordelia}. and Clegg, {\relax Karen}.},
  year = {2006},
  publisher = {Routledge},
  address = {London},
  abstract = {Throughout higher education assessment is changing, driven by increased class size, changing curricula and the need to support students better. At the same time assessment regulations and external quality assurance demands are constraining assessment options, driven by worries about standards, reliability and plagiarism. Innovative Assessment in Higher Education explores the difficulty of changing assessment in sometimes unhelpful contexts. Topics discussed include: problems with traditional assessment methods rationales behind different kinds of innovation in},
  isbn = {1-134-25085-1},
  keywords = {Education Higher -- Great Britain -- Evaluation,Educational evaluation -- Great Britain,Electronic books,Universities and colleges -- Great Britain -- Examinations}
}

@book{bryanInnovativeAssessmentHigher2019,
  title = {Innovative {{Assessment}} in {{Higher Education}}: {{A Handbook}} for {{Academic Practitioners}}},
  shorttitle = {Innovative {{Assessment}} in {{Higher Education}}},
  editor = {Bryan, Cordelia and Clegg, Karen},
  year = {2019},
  month = apr,
  edition = {1},
  publisher = {Routledge},
  address = {Second Edition. {\textbar} New York : Routledge, 2019. {\textbar} ``[First edition published by Routledge 2006]''---T.p. verso.},
  doi = {10.4324/9780429506857},
  urldate = {2022-06-26},
  isbn = {978-0-429-50685-7},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/9FNVF6EH/bryanInnovativeAssessmentHigher2019.pdf}
}

@book{bryanInnovativeAssessmentHigher2019a,
  title = {Innovative Assessment in Higher Education : A Handbook for Academic Practitioners},
  author = {Bryan, Cordelia and Clegg, Karen},
  year = {2019},
  edition = {Second edition.},
  publisher = {Routledge},
  address = {London},
  abstract = {Contextualising why assessment is still the single most important factor affecting student learning in higher education, this second edition of Innovative Assessment in Higher Education: A Handbook for Academic Practitioners offers a critical discourse about the value of assessment for learning alongside practical suggestions about how to enhance the student experience of assessment and feedback. With 17 new chapters this edition: contextualises assessment within the current higher education landscape; explores how student, parent and government expectations impact on assessment design;presents case studies on how to develop, incorporate and assess employability skills; reviews how technology and social media can be used to enhance assessment and feedback; provides examples and critical review of the use and development of feedback practices and how to assess professional, creative and performance-based subjects; offers guidance on how to develop assessment that is inclusive and enables all students to advance their potential. Bridging the gap between theory and the practical elements of assessment, Innovative Assessment in Higher Education: A Handbook for Academic Practitioners is an essential resource for busy academics looking to make a tangible difference to their academic practice and their students' learning. This practical and accessible guide will aid both new and more experienced practitioners looking to learn more about how and why assessment in higher education can make such a difference to student learning.},
  isbn = {978-0-429-50685-7},
  keywords = {Education Higher -- Great Britain -- Evaluation,Educational evaluation -- Great Britain,Electronic books,Universities and colleges -- Great Britain -- Examinations},
  file = {/Users/colin.madland/Zotero/storage/NB6DQUL7/bryanInnovativeAssessmentHigher2019a.pdf}
}

@article{buchnerMediaComparisonStudies2023,
  title = {Media Comparison Studies Dominate Comparative Research on Augmented Reality in Education},
  author = {Buchner, Josef and Kerres, Michael},
  year = {2023},
  month = apr,
  journal = {Computers \& Education},
  volume = {195},
  pages = {104711},
  issn = {03601315},
  doi = {10.1016/j.compedu.2022.104711},
  urldate = {2024-10-22},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/buchnerMediaComparisonStudies2023.pdf}
}

@article{buckleyAreWeAnswering2023,
  title = {Are We Answering the Question That Has Been Set? {{Exploring}} the Gap between Research and Practice around Examinations in Higher Education},
  author = {Buckley, Alex},
  year = {2023},
  journal = {Studies in Higher Education},
  pages = {1--17},
  publisher = {Routledge},
  issn = {0307-5079},
  doi = {10.1080/03075079.2023.2283784},
  abstract = {Despite a large amount of critical research literature, traditional examinations continue to be widely used in higher education. This article reviews recent literature in order to assess the role played by the approaches adopted by researchers in the gap between research on exams, and the way exams are used. Viviane Robinson?s ?problem-based methodology? focuses on the need for researchers to engage with the challenges and priorities of practitioners. Drawing on Robinson?s approach, the article investigates how the strengths and weaknesses of exams and their alternatives are framed in the literature published between 2016 and 2021. The article concludes that there is an absence of evidence about how and why practitioners make decisions about assessment. This hinders the ability of assessment researchers to appropriately connect their work with the assessment challenges practitioners face. To make a difference, assessment research needs to live in the real world; a world which, at least as far as practitioners? assessment decisions are concerned, we do not yet sufficiently understand.},
  file = {/Users/colin.madland/Zotero/storage/ZI5WHZRK/buckleyAreWeAnswering2023.pdf}
}

@article{buczek-zawilaCateringAssessmentNeeds2021,
  title = {Catering to {{Assessment Needs}} of {{Students}} of {{English}} -- {{CALL}} to the {{Rescue}}?},
  author = {{Buczek-Zawila}, Anita},
  year = {2021},
  month = apr,
  journal = {Teaching English with Technology},
  volume = {21},
  number = {2},
  pages = {38--65},
  publisher = {Teaching English with Technology},
  issn = {1642-1027},
  abstract = {The study focuses on the process of assessing (a micro-skill) goal attainment in EFL pronunciation course via measures which can foster different students' attitudes and self-perceptions. Standard (pen-and-paper) tests offer immediate evidence of success but they put heavy demands on students' cognitive, performance and stress-controlling skills. CALL-related techniques can be used as supplementary ones, even if technically assessing different sub-skills, "Kahoot" or "Moodle" quizzes can complement and re-orientate the assessment as well as the learning processes. To investigate the impact of the diverse assessment measures a small-scale research was conducted among Year 1 students of the English Department at the Pedagogical University in Krak{\'o}w. They are participants in a 90-hours-a-year pronunciation course, where one of the components involves mastering transcribing skills. The specific element of the course evaluated by standard and CALL-related measures in the study were the phonetic variants of the -es and -ed endings in English. Through analysis of test scores, coupled with the ideas obtained via semi-structured interviews, the study hoped to verify the claim that matters such as student comfort, instant individual feedback and personal safety are most efficiently handled by the "Moodle" quizzes. Apart from providing well-balanced scores, they offer the least-threatening, stress-free environments for learning and assessment, thus developing students' self-monitoring their progress.},
  keywords = {College Freshmen,Computer Assisted Testing,English (Second Language),Feedback (Response),Foreign Countries,Game Based Learning,Integrated Learning Systems,No DOI found,Phonetic Transcription,Poland,Pronunciation,Second Language Instruction,Second Language Learning,Security (Psychology),Self Efficacy,Self Management,Student Evaluation,Student Needs,Test Anxiety,Test Format}
}

@article{bukarRoleComputerInstruction2016,
  title = {Role of {{Computer}} in {{Instruction}}, {{Assessment}} and {{Administrative Delivery}} of {{Education Goals}} in the {{University}} of {{Maiduguri}}, {{Nigeria}}},
  author = {Bukar, Ibrahim Bulama and Bello, Suleiman and Ibi, Mustapha Baba},
  year = {2016},
  month = jan,
  journal = {Journal of Education and Practice},
  volume = {7},
  number = {20},
  pages = {81--87},
  publisher = {{Journal of Education and Practice}},
  issn = {2222-1735},
  abstract = {Information and Communication Technologies have come to transform and reshape the school structures, curriculum, pedagogies, assessment and evaluation. Despite these advantages, very few institution of learning in Nigeria have been able to explore the inherent benefits of ICT to the fullest. The quest to attain Educational ends in response to the fast changing Society has indeed become a great challenge to the Nigerian Curriculum. Instructional delivery is the bridge between understanding and assimilation of knowledge. It is no longer news that developed Nations have moved from Desktop Computing Technology to what is now known as Cloud and Automated Computing and recently Computer Based Test (CBT). Improving the instructional delivery method requires whole lot of work. To this effect, this paper focuses on the ways to transform the Traditional driven methods of instructional and administrative delivery which in all ramification inactive. There are barriers hindering wholesome ICT integration in the University of Maiduguri such as inadequate power supply, lack of fund to equip schools, leadership focus and direction. Perhaps when the Universities, Government and stakeholders surmount these barriers, then we can propel to that paperless classroom. The paper further demonstrates how instructional delivery via computer transforms the thinking and impact on learners and general administration of Schools. It reflects on some of the impact and challenges of using CBI, CAI, CBT and recommends an optimum solution to the adaptation and use of the new Technologies to improve learning, evaluation and administrative delivery in the University of Maiduguri, Nigeria.},
  keywords = {Administrator Attitudes,Computer Assisted Instruction,Computer Assisted Testing,Computer Uses in Education,Delivery Systems,Educational Objectives,Educational Technology,Foreign Countries,Higher Education,Information Technology,Nigeria,No DOI found,Student Attitudes,Teacher Attitudes,Teaching Methods,Technological Advancement,Technology Integration,Technology Uses in Education},
  file = {/Users/colin.madland/Zotero/storage/E9DL74W3/bukarRoleComputerInstruction2016.pdf}
}

@article{bullockZoomFatigueAge2022,
  title = {Zoom {{Fatigue}} in the {{Age}} of {{COVID-19}}},
  author = {Bullock, Angela and Colvin, Alex D. and Jackson, M. Sebrena},
  year = {2022},
  month = apr,
  journal = {Journal of Social Work in the Global Community},
  volume = {6},
  number = {1},
  issn = {2642-1763},
  doi = {10.5590/JSWGC.2022.07.1.01},
  urldate = {2023-01-26},
  abstract = {As the COVID-19 pandemic has impacted how institutions of higher education function, colleges and universities have shifted to remote learning and now rely heavily on the use of web conferencing tools, such as Zoom, WebEx, Adobe Connect, and others. As a result, educators are increasingly experiencing the effects of Zoom fatigue. The purpose of this article is to explore the videoconferencing fatigue that has emerged during the COVID-19 pandemic. The technostress model is used as the framework to provide strategies for recognizing and addressing videoconferencing fatigue.},
  file = {/Users/colin.madland/Zotero/storage/6J2UX5PZ/bullockZoomFatigueAge2022.pdf}
}

@article{bullResearchAboriginalPeoples2010,
  title = {Research with {{Aboriginal Peoples}}: {{Authentic Relationships}} as a {{Precursor}} to {{Ethical Research}}},
  author = {Bull, Julie R.},
  year = {2010},
  month = dec,
  journal = {Journal of Empirical Research on Human Research Ethics},
  volume = {5},
  number = {4},
  pages = {13--22},
  issn = {1556-2646},
  doi = {10.1525/jer.2010.5.4.13},
  urldate = {2019-02-28},
  abstract = {Recent ethics guidelines and policies are changing the way health research is understood, governed, and practiced among Aboriginal communities in Canada. This provides a unique opportunity to examine the meanings and uses of such guidelines by Aboriginal communities themselves. This qualitative study, conducted in Labrador, Canada, with the Innu, Inuit, and Inuit-Metis, examined how communities and researchers collaborate in a co-learning environment whereby mutual interests and agendas are discussed and enacted throughout the entire research process?a process referred to an authentic research relationship. The purpose of this study was to answer the following questions: (1) Why are authentic research relationships important? (2) What is authenticity in research? (3) How do we achieve authenticity in research with Aboriginal peoples? This shift to more wholistic methodologies can be used in various contexts in Canada and internationally. This is the first study by an Aboriginal person to examine the perspectives of Aboriginal people, in an Aboriginal context, using Aboriginal methodologies.},
  annotation = {*},
  file = {/Users/colin.madland/Zotero/storage/QPRIPJSI/bullResearchAboriginalPeoples2010.pdf}
}

@phdthesis{bulutBetweenpersonWithinpersonSubscore2013,
  title = {Between-Person and {{Within-person Subscore Reliability}}: {{Comparison}} of {{Unidimensional}} and {{Multidimensional IRT Models}}},
  author = {Bulut, Okan},
  year = {2013},
  address = {Minnesota, USA},
  urldate = {2021-04-16},
  abstract = {The importance of subscores in educational and psychological assessments is undeniable. Subscores yield diagnostic information that can be used for determining how each examinee's abilities/skills vary over different content domains. One of the most common criticisms about reporting and using subscores is insufficient reliability of subscores. This study employs a new reliability approach that allows the evaluation of between-person subscore reliability as well as within-person subscore reliability. Using this approach, the unidimensional IRT (UIRT) and multidimensional IRT (MIRT) models are compared in terms of subscore reliability in simulation and real data studies. Simulation conditions in the simulation study are subtest length, correlations among subscores, and number of subtests. Both unidimensional and multidimensional subscores are estimated with the maximum a posteriori probability (MAP) method. Subscore reliability of ability estimates are evaluated in light of between-person reliability, within-person reliability, and total profile reliability. The results of this study suggest that the MIRT model performs better than the UIRT model under all simulation conditions. Multidimensional subscore estimation benefits from correlations among subscores as ancillary information, and it yields more reliable subscore estimates than unidimensional subscore estimation. The subtest length is positively associated with both between-person and within-person reliability. Higher correlations among subscores improve between-person reliability, while they substantially decrease within-person reliability. The number of subtests seems to influence between-person reliability slightly but it has no effect on within-person reliability. The two estimation methods provide similar results with real data as well.},
  langid = {english},
  school = {University of Minnesota},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/928HXTNQ/bulutBetweenpersonWithinpersonSubscore2013.pdf}
}

@article{BulutCutum2018qq,
  title = {When Technology Does Not Add up: {{ICT}} Use Negatively Predicts Mathematics and Science Achievement for Finnish and Turkish Students in {{pISA}} 2012},
  author = {Bulut, Okan and {Maria Cutumisu}},
  year = {2018},
  journal = {Journal of Educational Multimedia and Hypermedia},
  volume = {27},
  number = {1},
  pages = {25--42},
  publisher = {Association for the Advancement of Computing in Education (AACE)},
  address = {Waynesville, NC USA},
  issn = {1055-8896},
  abstract = {This study examines the data of students from Finland (n = 8,829) and Turkey (n = 4,848) who participated in the 2012 Programme for International Student Assessment (PISA). The purpose of this study is to discern whether the use and availability of information and communication technologies (ICT) at home and at school have a differential impact on academic achievement in mathematics and science. In both countries, structural equation modeling analyses revealed that the use of ICT at school for mathematics lessons was negatively associated with mathematics, while the use of ICT at home for schoolwork was not associated with mathematics and science. The availability of ICT at home and at school was positively associated with achievement in Turkey, but not in Finland. Finally, the use of ICT for entertainment was associated positively with achievement in Turkey, but negatively in Finland. These results have implications for the adoption of ICT in formal and informal learning environments.},
  keywords = {No DOI found}
}

@article{bulutEffectsDigitalScore2019,
  title = {Effects of {{Digital Score Reporting}} and {{Feedback}} on {{Students}}' {{Learning}} in {{Higher Education}}},
  author = {Bulut, Okan and Cutumisu, Maria and Aquilina, Alexandra M. and Singh, Deepak},
  year = {2019},
  month = jun,
  journal = {Frontiers in Education},
  volume = {4},
  pages = {65},
  issn = {2504-284X},
  doi = {10/ghnhsd},
  urldate = {2020-12-05},
  file = {/Users/colin.madland/Zotero/storage/8SKLCNX3/bulutEffectsDigitalScore2019.pdf}
}

@article{bulutGuidelinesGeneratingEffective2020,
  title = {Guidelines for {{Generating Effective Feedback}} from {{E-Assessments}}},
  author = {Bulut, O and Cutumisu, M and Singh, D and Aquilina, {\relax AM}},
  year = {2020},
  journal = {Hacettepe Universitesi Egitim Fakultesi Dergisi-Hacettepe University Journal of Education},
  volume = {35},
  pages = {60--72},
  issn = {2536-4758},
  doi = {10.16986/HUJE.2020063705},
  abstract = {Today's education systems continue to adopt new technologies to support student learning. One of these technologies is e-assessment, a form of assessment that enables students to answer items using digital devices, such as computers and tablets. One of the benefits of e-assessments is the ability to generate interactive, timely, and customized feedback for students. Yet, despite vast literature on the generation and delivery of feedback, there is no systematic review of the guidelines on how e-assessments can be used for generating effective feedback. The objectives of this study are threefold. First, we synthesize the literature on the current practices in feedback generation. Second, we provide researchers and practitioners with a synthesis of guidelines for best practices in generating effective feedback with e-assessments. Third, we introduce a new framework in which we demonstrate the six steps of creating an e-assessment that can help produce immediate, customized, and specific feedback for students. This framework combines multiple forms of feedback (e.g., graphs, tables, and text) to improve the understanding of feedback and engage students in the interpretation of their score reports. Implications for practice and future research are discussed.},
  langid = {english},
  keywords = {COMPUTER-BASED ASSESSMENT,computerized assessment,E-assessment,feedback,FORMATIVE ASSESSMENT,HIGHER-EDUCATION,ONLINE,REFLECTIONS,score reporting,test development,TESTS},
  file = {/Users/colin.madland/Zotero/storage/YIIWGTZE/bulutGuidelinesGeneratingEffective2020.pdf}
}

@misc{bulutHttpsRawGithubusercontent,
  title = {{{https://raw.githubusercontent.com/okanbulut/psychometrics/master/Update\%20R.R}}},
  author = {Bulut, Okan}
}

@misc{bulutLectureSurveyPiloting2021,
  type = {Course},
  title = {Lecture 6: {{Survey Piloting Strategies}}},
  author = {Bulut, Okan},
  year = {2021},
  address = {University of Alberta},
  file = {/Users/colin.madland/Zotero/storage/IREBYGXD/bulutLectureSurveyPiloting2021.pdf}
}

@misc{bulutLikertScalesFriend2021,
  title = {Likert {{Scales}}: {{Friend}} or {{Foe}}?},
  shorttitle = {Likert {{Scales}}},
  author = {Bulut, Okan},
  year = {2021},
  month = aug,
  journal = {Medium},
  urldate = {2021-08-05},
  abstract = {Pitfalls and caveats that survey researchers should know},
  howpublished = {https://towardsdatascience.com/likert-scales-friend-or-foe-76f865786fb7},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/SVIH26MD/likert-scales-friend-or-foe-76f865786fb7.html}
}

@article{bulutUsingComputerizedFormative2018,
  title = {Using {{Computerized Formative Testing}} to {{Support Personalized Learning}} in {{Higher Education}}: {{An Application}} of {{Two Assessment Technologies}}},
  author = {Bulut, Okan and Gierl, Mark and Zhang, Xinxin},
  year = {2018},
  pages = {99--119},
  issn = {1522539417},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/VG4NLRES/bulutUsingComputerizedFormative2018.pdf}
}

@misc{buolamwiniHowFightingBias2016,
  title = {How {{I}}'m Fighting Bias in Algorithms},
  author = {Buolamwini, Joy},
  year = {2016},
  urldate = {2022-03-16},
  abstract = {MIT grad student Joy Buolamwini was working with facial analysis software when she noticed a problem: the software didn't detect her face -- because the people who coded the algorithm hadn't taught it to identify a broad range of skin tones and facial structures. Now she's on a mission to fight bias in machine learning, a phenomenon she calls the "coded gaze." It's an eye-opening talk about the need for accountability in coding ... as algorithms take over more and more aspects of our lives.},
  keywords = {archived},
  annotation = {https://web.archive.org/web/20220316153734/https://www.ted.com/talks/joy\_buolamwini\_how\_i\_m\_fighting\_bias\_in\_algorithms},
  file = {/Users/colin.madland/Zotero/storage/Z8PBXMRF/joy_buolamwini_how_i_m_fighting_bias_in_algorithms.html}
}

@article{burianResearchRoadmapPrimer2010,
  title = {The {{Research Roadmap}}: {{A Primer To The Approach And Process}} {\textbar} {{Contemporary Issues}} in {{Education Research}} ({{CIER}})},
  shorttitle = {The {{Research Roadmap}}},
  author = {Burian, Philip E and Rogerson, Lynda and Maffei III, Francis R},
  year = {2010},
  journal = {Contemporary Issues In Education Research},
  volume = {3},
  number = {8},
  pages = {43--58},
  urldate = {2018-12-02},
  abstract = {Performing research can be an overwhelming and challenging endeavor. It's easy to get confused just from collecting, reading and deciphering textbooks and journal articles. Getting organized and mapping out the entire process would be extremely helpful and more importantly provide a path for accomplishing the research project. This paper will provide a research roadmap that can be used as a guide for accomplishing a research project or a doctoral dissertation. It will discuss research methods, ethics in research, key components, and provide a comprehensive graphic that can be used as a guide to quick-start the research effort.},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/75TQ8R93/burianResearchRoadmapPrimer2010.pdf;/Users/colin.madland/Zotero/storage/YA9K9NXD/226.html}
}

@book{burkeHowAssessAuthentic1999,
  title = {How to Assess Authentic Learning},
  author = {Burke, Kay},
  year = {1999},
  series = {The {{Mindful School}}},
  edition = {3rd},
  publisher = {SkyLight Professional Development},
  address = {Arlington Heights, Ill}
}

@article{burnetteRenewalCompetencyBasedEducation2016,
  title = {The {{Renewal}} of {{Competency-Based Education}}: {{A Review}} of the {{Literature}}},
  shorttitle = {The {{Renewal}} of {{Competency-Based Education}}},
  author = {Burnette, Diane M.},
  year = {2016},
  month = may,
  journal = {The Journal of Continuing Higher Education},
  volume = {64},
  number = {2},
  pages = {84--93},
  issn = {0737-7363, 1948-4801},
  doi = {10/gh3xmc},
  urldate = {2021-02-18},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/92T5MIC5/burnetteRenewalCompetencyBasedEducation2016.pdf}
}

@article{burnsSuccessFailureNo2013,
  title = {Success, {{Failure}} or "{{No Significant Difference}}"? {{The Arguments For}} and {{Against Technology}} as a {{Learning Tool}}},
  shorttitle = {Success, {{Failure}} or "{{No Significant Difference}}"?},
  author = {Burns, Mary},
  year = {2013},
  month = feb,
  journal = {International Journal of Emerging Technologies in Learning (iJET)},
  volume = {8},
  number = {1},
  pages = {38},
  issn = {1863-0383},
  doi = {10.3991/ijet.v8i1.2376},
  urldate = {2023-01-26},
  abstract = {The question of whether computers have positively or negatively impacted student learning is still hotly contested in educational technology circles, particularly in the area of international development, by proponents and critics of technology in education. Overall, research still provides conflicting answers to this question. Nonetheless, the abundant research on effective school change and innovation implementation points to practices which those who promote technology in schools should tap. This paper outlines the long-term structural conditions that can lead to the deep change technology initiatives seek to promote.},
  file = {/Users/colin.madland/Zotero/storage/RZVX6XJS/burnsSuccessFailureNo2013.pdf}
}

@book{buroscenterTwentyFirstMentalMeasurements2020,
  title = {Twenty-{{First Mental Measurements Yearbook}}},
  author = {{Buros Center}},
  year = {2020},
  publisher = {BUROS INSTITUTE OF MENTAL},
  address = {S.l.},
  isbn = {978-0-910674-68-3},
  langid = {english},
  annotation = {OCLC: 1151082917}
}

@article{Burton_2005,
  title = {Multiple Choice and True False Tests Myths and Misapprehensions},
  author = {Burton, Richard F.},
  year = {2005},
  journal = {Assessment \& Evaluation in Higher Education},
  doi = {10/bqgf2x},
  abstract = {Examiners seeking guidance on multiple-choice and true/false tests are likely to encounter various faulty or questionable ideas. Twelve of these are discussed in detail, having to do mainly with the effects on test reliability of test length, guessing and scoring method (i.e. number-right scoring or negative marking). Some misunderstandings could be based on evidence from tests that were badly written or administered, while others may have arisen through the misinterpretation of reliability coefficients. The usefulness of item response theory in the analysis of academic test items is briefly dismissed.},
  mag_id = {2128157466},
  pmcid = {null},
  pmid = {null}
}

@misc{businessTwitterLookingRacial,
  title = {Twitter Looking into Racial Bias in Tweet Image Previews},
  author = {Business, CNN, Rachel Metz},
  journal = {CNN},
  urldate = {2020-09-22},
  abstract = {Some Twitter users are pointing out that the automatic method the platform employs to display previews of images may be biased toward showing pictures of white people. Twitter agreed the issues was something it needs to work on.},
  howpublished = {https://www.cnn.com/2020/09/21/tech/twitter-racial-bias-preview/index.html},
  file = {/Users/colin.madland/Zotero/storage/QUMGLILI/index.html}
}

@article{butlerIntegratingCognitiveScience2014,
  title = {Integrating {{Cognitive Science}} and {{Technology Improves Learning}} in a {{STEM Classroom}}},
  author = {Butler, {\relax AndrewC}. and Marsh, {\relax ElizabethJ}. and Slavinsky, J.P. and Baraniuk, {\relax RichardG}.},
  year = {2014},
  month = mar,
  journal = {Educational Psychology Review},
  pages = {1--10},
  issn = {1040-726X},
  doi = {10.1007/s10648-014-9256-4},
  langid = {english},
  keywords = {Education,Feedback,Retrieval practice,Spacing,technology,Transfer of learning},
  file = {/Users/colin.madland/Zotero/storage/UE3EIP3B/butlerIntegratingCognitiveScience2014.pdf}
}

@article{butlerTaskinvolvingEgoinvolvingProperties1987,
  title = {Task-Involving and Ego-Involving Properties of Evaluation: {{Effects}} of Different Feedback Conditions on Motivational Perceptions, Interest, and Performance.},
  shorttitle = {Task-Involving and Ego-Involving Properties of Evaluation},
  author = {Butler, Ruth},
  year = {1987},
  journal = {Journal of Educational Psychology},
  volume = {79},
  number = {4},
  pages = {474--482},
  issn = {0022-0663},
  doi = {10/cw7kjv},
  urldate = {2021-02-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/7RNW972M/butlerTaskinvolvingEgoinvolvingProperties1987.pdf}
}

@article{byrneExploratoryStudyHow2021,
  title = {An Exploratory Study of How Novice Instructors Pivot to Online Assessments Strategies},
  author = {Byrne, Virginia L. and Hogan, Erin and Dhingra, Neil and Anthony, Monica and Gannon, Colleen},
  year = {2021},
  journal = {Distance education},
  volume = {42},
  number = {2},
  pages = {184--199},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0158-7919},
  doi = {10.1080/01587919.2021.1911624},
  abstract = {Increasingly, graduate student instructors (GSIs) teach online without prior formal training on how to design online assessments of learning and participation. We present findings from a collective case study of seven GSIs at a university in the United States of America to describe how these novice online instructors learned to enact assessment strategies in an online classroom. Findings reveal that the GSIs were influenced by professional learning networks such as peer communities of practice, the academic Twitter community, student feedback, and faculty gatekeeping of institutional resources and policies. With limited institutional and departmental support, the GSIs struggled to transform their face-to-face assessments to leverage technology but leaned on their professional judgment to prioritize traditional discussion and participation structures. Findings inform our understanding of how universities might prioritize professional learning networks on online teaching at differing institutional levels to increase GSIs' access to online teaching information and knowledgeable role models.},
  keywords = {assessment,Beginning teachers,Communities of Practice,Computer Assisted Testing,COVID-19,Distance Education,Distance learning,Education & Educational Research,Educational evaluation,Graduate Students,Online instruction,online teaching,Pandemics,participation,Social Media,Social networks,Social Sciences,Student Attitudes,Student Evaluation,Teaching,Teaching Assistants,Twitter,Web Based Instruction}
}

@book{byrneStructuralEquationModeling2013,
  title = {Structural {{Equation Modeling With EQS}}},
  author = {Byrne, Barbara M.},
  year = {2013},
  month = apr,
  edition = {0},
  publisher = {Routledge},
  doi = {10.4324/9780203726532},
  urldate = {2022-05-09},
  isbn = {978-1-135-80960-7},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/UB5J42RU/byrneStructuralEquationModeling2013.pdf}
}

@article{cabaleiro-cervinoImpactEducationalTechnologies2020,
  title = {The {{Impact}} of {{Educational Technologies}} in {{Higher Education}}},
  author = {{Cabaleiro-Cervi{\~n}o}, Goretti and Vera, Carolina},
  year = {2020},
  journal = {GIST Education and Learning Research Journal},
  issn = {ISSN-1692-5777},
  doi = {10/gmbv37},
  abstract = {The formation of human capital is key to countries' social, cultural, and economic development. The current literature review pays considerable attention to the ever-increasing proliferation of technology in the careers of college and school graduates. While the presence of educational technology in higher education offers multiple benefits, its implementation also presents challenges. In that sense, the literature has considered multiple tools for improving learning processes. However, the results of such tools vary and are difficult to measure in terms of quality. In this literature review, we analyze the issues surrounding educational technology in higher education.},
  langid = {english},
  keywords = {Barriers,College Faculty,Educational Benefits,Educational Quality,Educational Technology,Electronic Publishing,Handheld Devices,Higher Education,Human Capital,Learning Processes,Multimedia Instruction,Online Courses,Pedagogical Content Knowledge,Social Networks,Teacher Role,Teaching Methods,Technological Literacy,Telecommunications}
}

@article{caffarellaProfessionalDevelopmentFaculty1999,
  title = {Professional {{Development}} for {{Faculty}}: {{A Conceptual Framework}} of {{Barriers}} and {{Supports}}},
  author = {Caffarella, Rosemary S. and Zinn, Lynn F.},
  year = {1999},
  journal = {Innovative Higher Education},
  volume = {23},
  number = {4},
  pages = {241--254},
  abstract = {Professional development for faculty in higher education takes many forms, from self-directed activities to organized programs of learning. Described in this article is a comprehensive definition of continuing professional development followed by a conceptual framework for thinking about those factors that support or impede our professional development. We conclude with a case study of one professor's career development, noting where various factors in the framework have played a part.},
  keywords = {Humanities,Social Sciences and Law}
}

@article{cahapayKirkpatrickModelIts2021,
  title = {Kirkpatrick {{Model}}: {{Its Limitations}} as {{Used}} in {{Higher Education Evaluation}}},
  author = {Cahapay, Michael B.},
  year = {2021},
  journal = {International Journal of Assessment Tools in Education},
  volume = {8},
  number = {1},
  pages = {135--144},
  issn = {EISSN-2148-7456},
  doi = {10/gmbv2t},
  abstract = {One of the widely known evaluation models adapted to education is the Kirkpatrick model. However, this model has limitations when used by evaluators especially in the complex environment of higher education. Addressing the scarcity of a collective effort on discussing these limitations, this review paper aims to present a descriptive analysis of the limitations of the Kirkpatrick evaluation model in the higher education field. Three themes of limitations were found out: propensity towards the use of the lower levels of the model; rigidity which leaves out other essential aspects of the evaluand; and paucity of evidence on the causal chains among the levels. It is suggested that, when employing the Kirkpatrick model in higher education, evaluators should address these limitations by considering more appropriate methods, integrating contextual inputs in the evaluation framework, and establishing causal relationships among the levels. These suggestions to address the limitations of the model are discussed at the end of the study.},
  langid = {english},
  keywords = {Evaluation Problems,Higher Education,Models,Program Evaluation}
}

@article{cahapayReshapingAssessmentPractices2020,
  title = {Reshaping {{Assessment Practices}} in a {{Philippine Teacher Education Institution}} during the {{Coronavirus Disease}} 2019 {{Crisis}}},
  author = {Cahapay, Michael Bobias},
  year = {2020},
  month = jan,
  journal = {Pedagogical Research},
  volume = {5},
  number = {4},
  publisher = {Pedagogical Research},
  issn = {2468-4929},
  doi = {10.29333/pr/8535},
  abstract = {This case study analyzes the assessment practices in a Teacher Education Institution (TEI)in the Philippines during the Coronavirus Disease 2019 (COVID-19) crisis. The results showed that assessment practices were contextually reshaped as classes were suspended at the time when assessment evidence cannot be computed; limited internet connectivity posed logistical issues to move to online assessment; and institutional tradition of maintaining quality draws a major concern. As a consequence, changes were evident in the grading component solely focusing on student attendance; grading system shifting to descriptive binary; requirements for laboratory and research works significantly modified; and exclusion of grades earned in the current semester from the computation of grade point average. Drawing lessons from this case study, it is recommended that in reshaping assessment practices in this time, different contexts must be cogently considered, so that reasonable changes will be better understood.},
  keywords = {Attendance,COVID-19,Educational Change,Evaluation Methods,Foreign Countries,Grade Point Average,Grading,Pandemics,Philippines (Manila),Preservice Teacher Education,Student Evaluation},
  file = {/Users/colin.madland/Zotero/storage/H2QQHTAA/cahapayReshapingAssessmentPractices2020.pdf}
}

@inproceedings{caiAdaptiveLearningPractice2018,
  title = {Adaptive {{Learning Practice}} for {{Online Learning}} and {{Assessment}}},
  booktitle = {Proceedings of the 2018 {{International Conference}} on Distance Education and Learning},
  author = {Cai, Richard},
  year = {2018},
  pages = {103--108},
  publisher = {ACM},
  doi = {10/ggrgxr},
  abstract = {Adaptive Learning (AL) is a personalized learning technology. It can customize learning based on pre-determined knowledge state on a particular subject or topic. This assessment driven approach not only allows students to have their own learning path with individual learning nodes or steps, but also provides various formative and summative assessments the students' learning performance. With the appropriate mapping between course learning outcomes and program outcomes, the program outcomes can be assessed through the assessment results of AL in selected courses. Colorado Technical University (CTU) has been using AL technology in their Web-based Learning Management System (LMS) since October of 2012. CTU's AL approach is both assessment driven and facilitator/faculty driven. In this paper, we will share our experience and findings on using AL in Online Computer Science (CS) and Information Technology (IT) courses to enhance student learning and assess the program outcomes for continuous improvement and programmatic accreditation.},
  isbn = {1450364314;9781450364317;},
  keywords = {Accreditation,Adaptive Learning,Assessment,Intellipath,Learning Path,Online Education},
  annotation = {Conference Proceedings}
}

@article{cainDeficienciesTraditionalGrading2022,
  title = {Deficiencies of {{Traditional Grading Systems}} and {{Recommendations}} for the {{Future}}},
  author = {Cain, Jeff and Medina, Melissa and Romanelli, Frank and Persky, Adam},
  year = {2022},
  month = oct,
  journal = {American Journal of Pharmaceutical Education},
  volume = {86},
  number = {7},
  pages = {8850},
  issn = {00029459},
  doi = {10.5688/ajpe8850},
  urldate = {2025-03-04},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/cainDeficienciesTraditionalGrading2022.pdf}
}

@incollection{cainUsingTechnologyEnable2020,
  title = {Using {{Technology}} to {{Enable}} a {{Shift}} from {{Marks}} to {{Outcomes-Based Assessment}}},
  booktitle = {Re-Imagining {{University Assessment}} in a {{Digital World}}},
  author = {Cain, Andrew and Tubino, Laura and Krishnan, Siva},
  editor = {Bearman, Margaret and Dawson, Phillip and Ajjawi, Rola and Tai, Joanna and Boud, David},
  year = {2020},
  volume = {7},
  pages = {229--245},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-41956-1_16},
  urldate = {2022-03-19},
  isbn = {978-3-030-41955-4 978-3-030-41956-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/NUWURY8S/Cain2020_Chapter_UsingTechnologyToEnableAShiftF.pdf}
}

@article{cakirogluStudentsPreferencesOnline2017,
  title = {Students' Preferences in Online Assessment Process: Influences on Academic Performances},
  author = {Cakiroglu, Unal and Erdogdu, Fatih and Kokoc, Mehmet and Atabay, Melek},
  year = {2017},
  journal = {Turkish Online Journal of Distance Education},
  volume = {18},
  number = {1},
  pages = {132--132},
  publisher = {Anadolu University, Eskisehir},
  issn = {1302-6488},
  doi = {10/ggrgxt},
  abstract = {In the constructivist approach, various self-assessment techniques are being developed to enable students to assess themselves in the learning process. The purpose of the study is to investigate relation between students' preferences in assessment process and students' performances. The study was conducted with 67 sophomore students enrolled in Department of Computer Education and Instructional Technologies at a State University. The study was carried out in ``Measurement and Evaluation in Education'' course. At the beginning, Moodle LMS was used to define the preferences of students about their own assessment criteria (discussion, quiz, assignment and viewing of course content). Throughout the process, students were received the course instructional package in the classroom. Then they were asked to fill the assessment activities on the LMS. Students' actual performances in online activities in terms of their preference about assessment criteria was calculated as students course achievement scores. The mean value of the scores and the standard deviation were guided us to divide the participants into three groups (unsuccessful, moderately successful, successful) considering their means and standard deviations. Then, the preferences of students and their academic achievements were associated in each group. As a result, various criteria were come to front in both successful and unsuccessful groups. Surprisingly, none of the students preferred viewing course content and participating in discussions as the highest assessment criterion. Besides, it was found that all the students in successful group preferred viewing course content as lowest assessment criterion. The results indicated that, there were no prominent criteria in the relations between the preferences of students about assessment process and the academic performances. However, most of the students in unsuccessful group performed better in assignment although they did not preferred the assignment as the highest assessment criterion. At the end of the study, we noticed that while considering the criterion in the assessment process, taking students' perspectives and preferences into consideration motivated students positively and had somehow related to their academic achievements. Thus, it is hoped that the study can provides an insight to future studies to enrich assessment activities with giving responsibilities to students in learning, especially in assessment process.},
  keywords = {academic achievement,assessment,moodle,online learning,Students' preferences}
}

@article{cakmakAdvancingLearningorientedAssessment2023,
  title = {Advancing Learning-Oriented Assessment ({{LOA}}): Mapping the Role of Self-Assessment, Academic Resilience, Academic Motivation in Students' Test-Taking Skills, and Test Anxiety Management in {{Telegram-assisted-language}} Learning},
  author = {{\c C}akmak, Fidel and Ismail, Sayed M. and Karami, Samaneh},
  year = {2023},
  journal = {Language Testing in Asia},
  volume = {13},
  number = {1},
  pages = {20--19},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2229-0443},
  doi = {10.1186/s40468-023-00230-8},
  abstract = {Some impediments in language learning may have a detrimental impact on learners' actual performance on the test and lead to anxiety and demotivation. Language achievement is influenced by self-assessment (SA), academic resilience (AR), academic motivation (AM), and test-taking skills (T-TS) among other factors. Considering the relevance of these factors in language achievement, the current investigation aims to delve into the probable interactions of SA, AR, AM, T-TS, and test anxiety (TA) management among English as a foreign language (EFL) learners. A model was devised and evaluated using confirmatory factor analysis (CFA) and structural equation modeling (SEM) to achieve this objective. This research collected 512 by distributing online questionnaires to fifteen approved private institutions which applied Telegram-based language learning. The study findings reflected that SA, AR, and AM could predict EFL learners' T-TS. It was also confirmed that SA, AR, and AM modulated EFL learners' TA. The implications of the study are presented and accompanied by some future research proposals as well as instructional consequences.},
  keywords = {Academic motivation,Academic resilience,Anxiety,Assessment,Computer assisted language learning,Education,English as a second language,English as a second language learning,English as a second language tests,Language,Language Education,Learning oriented Assessment (LOA): A Window for Fairness in Classroom Assessment?,Motivation,Self evaluation,Self-assessment,Structural equation modeling,Test anxiety management,Test-taking skills,Testing and Evaluation},
  file = {/Users/colin.madland/Zotero/storage/5I2E22TJ/cakmakAdvancingLearningorientedAssessment2023.pdf}
}

@article{calvoComputerAssistedAssessmentOpenEnded2019,
  title = {Computer-{{Assisted Assessment}} in {{Open-Ended Activities}} through the {{Analysis}} of {{Traces}}: {{A Proof}} of {{Concept}} in {{Statistics}} with {{R Commander}}},
  author = {Calvo, Miquel and Carnicer, Artur and Cuadros, Jordi and Martori, Francesc and Mi{\~n}arro, Antonio and Serrano, Vanessa},
  year = {2019},
  month = jan,
  journal = {EURASIA Journal of Mathematics, Science and Technology Education},
  volume = {15},
  number = {9},
  publisher = {{EURASIA Journal of Mathematics, Science and Technology Education}},
  issn = {1305-8223},
  doi = {10.29333/ejmste/108456},
  abstract = {Open-ended tasks are common in Science, Technology, Engineering and Mathematics (STEM) education. However, as far as we know, no tools have been developed to assist in the assessment of the solution process of open-ended questions. In this paper, we propose the use of analysis of traces as a tool to address this need. To illustrate this approach, we developed a modified version of R Commander that collects traces of students' actions and described a way to analyze them by using regular expressions. We used this tool in an undergraduate introductory statistics course. The traces were analyzed by comparing them to predefined problem-solving steps, arranged by the instructor. The analyses provide information about the time students spent on the activity, their work intensity and the choices they made when solving open-ended questions. This automated assessment tool provides grades highly correlated to those obtained by a traditional test and traditional grading scheme.},
  keywords = {Comparative Analysis,Computer Assisted Testing,Correlation,Foreign Countries,Grading,Introductory Courses,Learning Activities,Learning Analytics,Problem Solving,Programming Languages,Research Universities,Spain,Statistics Education,STEM Education,Time Management,Undergraduate Students},
  file = {/Users/colin.madland/Zotero/storage/SG2VHJ5U/calvoComputerAssistedAssessmentOpenEnded2019.pdf}
}

@incollection{campanelliTestingSurveyQuestions2012,
  title = {Testing Survey {{Questions}}},
  booktitle = {International {{Handbook}} of {{Survey Methodology}}},
  author = {Campanelli, Pamela},
  editor = {{\noopsort{leeuw}}{de Leeuw}, Edith D. and Hox, Joop and Dillman, Don},
  year = {2012},
  month = oct,
  edition = {0},
  pages = {176--200},
  publisher = {Routledge},
  doi = {10.4324/9780203843123},
  urldate = {2023-03-13},
  isbn = {978-1-136-91063-0},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/66Y3GUCN/campanelliTestingSurveyQuestions2012.pdf}
}

@article{campbellPersonalCyberinfrastructure2009,
  title = {A {{Personal Cyberinfrastructure}}},
  author = {Campbell, Gardner},
  year = {2009},
  journal = {EDUCAUSE Review},
  volume = {44},
  pages = {58--59}
}

@article{campbellPrayIngPerson2022,
  title = {`{{Pray}}(Ing) the Person Marking Your Work Isn't Racist': Racialised Inequities in {{HE}} Assessment Practice},
  shorttitle = {`{{Pray}}(Ing) the Person Marking Your Work Isn't Racist'},
  author = {Campbell, Paul Ian},
  year = {2022},
  month = sep,
  journal = {Teaching in Higher Education},
  pages = {1--15},
  issn = {1356-2517, 1470-1294},
  doi = {10.1080/13562517.2022.2119075},
  urldate = {2022-10-04},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/VQPHDBC6/campbellPrayIngPerson2022.pdf}
}

@article{campbellUsingImplementationTrial2021,
  title = {Using an {{Implementation Trial}} of an {{ePortfolio System}} to {{Promote Student Learning}} through {{Self-Reflection}}: {{Leveraging}} the {{Success}}},
  author = {Campbell, C and Tran, {\relax TLN}},
  year = {2021},
  journal = {Education Sciences},
  volume = {11},
  number = {6},
  issn = {2227-7102},
  doi = {10.3390/educsci11060263},
  abstract = {This paper reports on a pilot study that was conducted during a technical trial of a new ePortfolio system at a large Australian university. Students from a large (n = 325) first-year educational technology course were given the opportunity to use the new ePortfolio system weekly as part of their reflective practice at the end of the hands-on tutorial classes and also through a blogging assignment that required six posts throughout the semester. Although the students reflecting on their work and ePortfolios themselves are not new concepts, this paper reports how assessment practices can be improved using ePortfolios and how students can improve their reflective practice through simple and regular use throughout the 12-week semester that the study was conducted. From the class, 208 students responded to the survey with the results being positive. The students were able to use the system easily and did not report many problems with crashing or freezing. The lessons learnt form an important part of this study for future iterations with these reported in the paper.},
  langid = {english},
  keywords = {ADOPTION,assessment,Chalk & Wire,DESIGN,EDUCATION,ePortfolio,higher education,initial teacher education,pre-service teacher education,self-reflection,TEACHERS},
  file = {/Users/colin.madland/Zotero/storage/UBSSGGXS/campbellUsingImplementationTrial2021.pdf}
}

@article{CanadianJournalLearning2002,
  title = {Canadian Journal of Learning and Technology = {{La}} Revue Canadienne de l'apprentissage et de La Technologie.},
  year = {2002},
  journal = {Canadian journal of learning and technology = La revue canadienne de l'apprentissage et de la technologie.},
  publisher = {{Association for Media and Technology in Education in Canada = Association des m{\'e}dias et de la technologie en {\'e}ducation au Canada}},
  address = {Etobicoke, Ont},
  issn = {1499-6685},
  keywords = {Education -- Data processing,Education -- Informatique,Educational technology,Electronic journals,Periodicals,Technologie educative}
}

@article{cancinoAssessingPreServiceEFL2020,
  title = {Assessing {{Pre-Service EFL Teachers}}' {{Perceptions Regarding}} an {{Online Student Response System}}},
  author = {Cancino, Marco and Capredoni, Rosana},
  year = {2020},
  month = jan,
  journal = {Taiwan Journal of TESOL},
  volume = {17},
  number = {2},
  pages = {91--118},
  publisher = {Taiwan Journal of TESOL},
  issn = {1814-9448},
  abstract = {Online Student Response Systems (OSRS) are web-based tools that can be used to collect and share language assessment data from students. Although they have been found to improve learner satisfaction, motivation, and learning, students' perceptions need to be taken into account when addressing the contextualized nature of OSRSs. Therefore, 23 pre-service EFL teachers studying at a private university in Santiago were asked to provide their perceptions regarding the Socrative OSRS in terms of its usability, its impact on learning, and its impact on engagement. Findings showed that students held positive perceptions towards the usability of the application, but remained neutral in relation to its impact on learning and engagement. This is explained in terms of the nature and the layout of the application.},
  keywords = {Audience Response Systems,Chile (Santiago),Educational Technology,English (Second Language),Foreign Countries,Instructional Effectiveness,Language Teachers,Learner Engagement,No DOI found,Preservice Teachers,Student Attitudes,Usability}
}

@book{canoInnovativePracticesHigher2017,
  title = {Innovative {{Practices}} for {{Higher Education Assessment}} and {{Measurement}}:},
  shorttitle = {Innovative {{Practices}} for {{Higher Education Assessment}} and {{Measurement}}},
  editor = {Cano, Elena and Ion, Georgeta and Keengwe, Jared},
  year = {2017},
  series = {Advances in {{Higher Education}} and {{Professional Development}}},
  publisher = {IGI Global},
  doi = {10.4018/978-1-5225-0531-0},
  urldate = {2022-06-26},
  isbn = {978-1-5225-0531-0 978-1-5225-0532-7},
  file = {/Users/colin.madland/Zotero/storage/GDFYE2VE/canoInnovativePracticesHigher2017.pdf}
}

@misc{CapeTownOpen2007,
  title = {The {{Cape Town Open Education Declaration}}},
  year = {2007},
  urldate = {2018-11-02},
  howpublished = {https://www.capetowndeclaration.org/read-the-declaration},
  keywords = {open},
  file = {/Users/colin.madland/Zotero/storage/4R87PAV6/read-the-declaration.html}
}

@misc{Capilano,
  title = {Capilano}
}

@article{capranosVoiceOnlineLearner2022,
  title = {Voice of the {{Online Learner}} 2022},
  author = {Capranos, David and Dyers, Loralee and Magda, Andrew J},
  year = {2022},
  pages = {49},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/64TQD4ZV/capranosVoiceOnlineLearner2022.pdf}
}

@article{caputiReflectionsNextGeneration2019,
  title = {Reflections on the {{Next Generation NCLEX}} with {{Implications}} for {{Nursing Programs}}},
  author = {Caputi, Linda J.},
  year = {2019},
  journal = {Nursing Education Perspectives},
  volume = {40},
  number = {1},
  pages = {2--3},
  issn = {1943-4685, 1536-5026},
  doi = {10/d8wq},
  urldate = {2021-07-13},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/AIR5CW53/caputiReflectionsNextGeneration2019.pdf}
}

@phdthesis{carboneExploringEvolutionAssessment2021,
  type = {M.{{Ed}}.},
  title = {Exploring the {{Evolution}} of {{Assessment Identity}} When {{Infusing Technology}} into {{Educational Contexts}}},
  author = {Carbone, Katrina},
  year = {2021},
  address = {Ann Arbor},
  abstract = {Classroom assessment is an essential component of the current standards-based education system. However, with the increase in classroom technology and sudden shift to remote learning, educators must alter and adapt their assessment strategies, even if they feel unprepared or uncomfortable doing so. Using teacher assessment identity (Looney et al., 2018) as a conceptual framework, this study explored the assessment practices and evolving assessment identity of educators as they implemented assessment via technology. This study utilized a secondary analysis drawing upon a subset of data collected during a collaborative program evaluation and responded to the following questions: (1) How do teachers leverage assessment via technology in their teaching practice to support the evolution of their classroom assessment conceptualizations and practices? (2) What can be understood about teacher assessment identity as they work to integrate technology in their teaching practice and expand their classroom assessment practices? Data was analyzed using an inductive, deductive, and hybrid approach using a four-phase qualitative analysis procedure (Bengtsson, 2016). Findings from the inductive analysis noted that teachers supported their reconceptualization of assessment through expanded assessment practices, seeking professional development, and developing core competencies for 21st century learners. The deductive analysis highlighted the interconnected nature of the five dimensions of the teachers' assessment identity framework and how these dimensions are informed and influenced by learning, catalyzed through reflection, collaboration, and a commitment to professional development. The findings and implications of this study are discussed in regard to research, practice, and policy to bolster an understanding of assessment, learning, and educational technology.},
  collaborator = {Searle, Michelle},
  langid = {english},
  school = {Queen's University (Canada)},
  keywords = {0443:Educational evaluation,0710:Educational technology,0727:Curriculum development,Collaboration,Coronaviruses,COVID-19,Curriculum development,Educational evaluation,Educational technology,Teachers,Teaching},
  file = {/Users/colin.madland/Zotero/storage/4U6HAUW8/carboneExploringEvolutionAssessment2021.pdf}
}

@article{carlessDevelopingSustainableFeedback2011,
  title = {Developing Sustainable Feedback Practices},
  author = {Carless, David and Salter, Diane and Yang, Min and Lam, Joy},
  year = {2011},
  month = jun,
  journal = {Studies in Higher Education},
  volume = {36},
  number = {4},
  pages = {395--407},
  issn = {0307-5079, 1470-174X},
  doi = {10.1080/03075071003642449},
  urldate = {2022-11-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/X46NQL5E/carlessDevelopingSustainableFeedback2011.pdf}
}

@article{carlessDevelopmentStudentFeedback2018,
  title = {The Development of Student Feedback Literacy: Enabling Uptake of Feedback},
  shorttitle = {The Development of Student Feedback Literacy},
  author = {Carless, David and Boud, David},
  year = {2018},
  month = nov,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {43},
  number = {8},
  pages = {1315--1325},
  issn = {0260-2938, 1469-297X},
  doi = {10/gf5fmn},
  urldate = {2021-04-23},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/M76NV5S6/carlessDevelopmentStudentFeedback2018.pdf}
}

@article{carlessDifferingPerceptionsFeedback2006,
  title = {Differing Perceptions in the Feedback Process},
  author = {Carless, David},
  year = {2006},
  month = apr,
  journal = {Studies in Higher Education},
  volume = {31},
  number = {2},
  pages = {219--233},
  issn = {0307-5079, 1470-174X},
  doi = {10.1080/03075070600572132},
  urldate = {2022-05-09},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/6HJX49YG/carlessDifferingPerceptionsFeedback2006.pdf}
}

@book{carlessExcellenceUniversityAssessment2015,
  title = {Excellence in {{University Assessment}}: {{Learning}} from Award-Winning Practice},
  shorttitle = {Excellence in {{University Assessment}}},
  author = {Carless, David},
  year = {2015},
  month = apr,
  edition = {1},
  publisher = {Routledge},
  doi = {10.4324/9781315740621},
  urldate = {2022-09-25},
  isbn = {978-1-315-74062-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/ZGKP9ZWN/carlessExcellenceUniversityAssessment2015.pdf}
}

@article{carlessExploringLearningorientedAssessment2015,
  title = {Exploring Learning-Oriented Assessment Processes},
  author = {Carless, David},
  year = {2015},
  month = jun,
  journal = {Higher Education},
  volume = {69},
  number = {6},
  pages = {963--976},
  issn = {0018-1560, 1573-174X},
  doi = {10/f7cbvj},
  urldate = {2021-04-25},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/4I4YHN6J/carlessExploringLearningorientedAssessment2015.pdf}
}

@article{carlessFeedbackLoopsLongerterm2019,
  title = {Feedback Loops and the Longer-Term: Towards Feedback Spirals},
  shorttitle = {Feedback Loops and the Longer-Term},
  author = {Carless, David},
  year = {2019},
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {44},
  number = {5},
  pages = {705--714},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2018.1531108},
  urldate = {2023-02-27},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/8GY24K7A/carlessFeedbackLoopsLongerterm2019.pdf}
}

@article{carlessLearningOrientedAssessment2006,
  title = {Learning Oriented Assessment Principles and Practice},
  author = {Carless, David and Joughin, Gordon and Mok, Magdalena Mo Ching},
  year = {2006},
  journal = {Assessment \& Evaluation in Higher Education},
  doi = {10/cmkrd2},
  abstract = {N/A: no abstract available},
  pmcid = {null},
  pmid = {null}
}

@article{carlessLearningOrientedAssessment2007,
  title = {Learning-oriented Assessment: Conceptual Bases and Practical Implications},
  shorttitle = {Learning-oriented Assessment},
  author = {Carless, David},
  year = {2007},
  month = feb,
  journal = {Innovations in Education and Teaching International},
  volume = {44},
  number = {1},
  pages = {57--66},
  issn = {1470-3297, 1470-3300},
  doi = {10/djg7b5},
  urldate = {2021-07-04},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/QKX4TEII/carlessLearningOrientedAssessment2007.pdf}
}

@book{carlessScalingAssessmentLearning2017,
  title = {Scaling up {{Assessment}} for {{Learning}} in {{Higher Education}}},
  editor = {Carless, David and Bridges, Susan M. and Chan, Cecilia Ka Yuk and Glofcheski, Rick},
  year = {2017},
  series = {The {{Enabling Power}} of {{Assessment}}},
  volume = {5},
  publisher = {Springer Singapore},
  address = {Singapore},
  doi = {10.1007/978-981-10-3045-1},
  urldate = {2022-05-07},
  isbn = {978-981-10-3043-7 978-981-10-3045-1},
  file = {/Users/colin.madland/Zotero/storage/GN48SUMG/carlessScalingAssessmentLearning2017.pdf}
}

@incollection{carlessScalingAssessmentLearning2017a,
  title = {Scaling {{Up Assessment}} for {{Learning}}: {{Progress}} and {{Prospects}}},
  booktitle = {Scaling up {{Assessment}} for {{Learning}} in {{Higher Education}}},
  author = {Carless, D},
  editor = {Carless, D and Bridges, {\relax SM} and Chan, {\relax CKY} and Glofcheski, R},
  year = {2017},
  volume = {5},
  pages = {3--17},
  doi = {10.1007/978-981-10-3045-1_1},
  abstract = {A definition of assessment for learning (AfL) is provided. From a synthesis of relevant literature, I outline four main AfL strategies: productive assessment task design, effective feedback processes, the development of student understanding of quality and activities where students make judgments. I explore the notion of scaling up in relation to spread, depth, sustainability and shifts in ownership. Then I present a rationale for the scaling up of AfL following from dissatisfaction with current practices and persuasive research evidence on practices congruent with AfL. I relate the notion of scaling up to the geographical spread of AfL research activity, its somewhat modest impact on university assessment policies and in relation to the expansion of feedback research. I then consider what conditions might facilitate deeper and broader implementation of AfL, including the role of quality assurance, the importance of leadership and incentives, the development of assessment literacy through professional development activities and the potential of technology to act as a lever for enabling AfL strategies.},
  isbn = {2198-2643},
  langid = {english},
  keywords = {CHALLENGE,COMPETENCE,DESIGN,FEEDBACK,FORMATIVE ASSESSMENT,HIGHER-EDUCATION,PEER,PERCEPTIONS}
}

@article{carlessTeacherFeedbackLiteracy2020,
  title = {Teacher Feedback Literacy and Its Interplay with Student Feedback Literacy},
  author = {Carless, David and Winstone, Naomi},
  year = {2020},
  month = jun,
  journal = {Teaching in Higher Education},
  pages = {1--14},
  issn = {1356-2517, 1470-1294},
  doi = {10/gjhdm6},
  urldate = {2021-04-24},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/4FYGBFCD/carlessTeacherFeedbackLiteracy2020.pdf}
}

@book{carlessTestingProductiveStudent2011,
  title = {From Testing to Productive Student Learning: Implementing Formative Assessment in Confucian-Heritage Settings},
  shorttitle = {From Testing to Productive Student Learning},
  author = {Carless, David},
  year = {2011},
  publisher = {Routledge},
  address = {New York},
  isbn = {978-0-415-88082-4 978-1-136-46748-6},
  langid = {english},
  annotation = {OCLC: 874197935},
  file = {/Users/colin.madland/Zotero/storage/C8UAGD8Z/carlessTestingProductiveStudent2011.pdf}
}

@incollection{carterServingAdultLearners2021,
  title = {Serving {{Adult Learners From International Backgrounds}} at {{Two Canadian Universities}}: {{Duty}} of {{Care}}, {{Student Success}}, and {{Approaches}} to {{Learning}}},
  shorttitle = {Serving {{Adult Learners From International Backgrounds}} at {{Two Canadian Universities}}},
  booktitle = {Advances in {{Educational Technologies}} and {{Instructional Design}}},
  author = {Carter, Lorraine and Carter, Alanna},
  editor = {Keengwe, Jared},
  year = {2021},
  pages = {107--131},
  publisher = {IGI Global},
  doi = {10.4018/978-1-7998-4360-3.ch006},
  urldate = {2023-09-29},
  abstract = {McMaster University Continuing Education (Hamilton, Ontario) and the Real Institute in the Chang School, Ryerson University (Toronto, Ontario) are two university continuing education units that respond to the needs of adult learners from newcomer and international backgrounds. McMaster Continuing Education is known for its expertise in online education and support of adult learners as they seek professionally focused education. The Real Institute provides dedicated in-class programming and support strategies for younger adult learners. In this chapter, the experiences of older and younger adults from diverse cultural backgrounds studying at the two units are presented. The authors suggest that the needs of this learner group may be better met within the continuing education unit than within the mainstream academy. Innovative learning strategies and flexibility are key elements in this position. Finally, it is suggested that the two profiled units take their duty of care and commitment to student success seriously.},
  isbn = {978-1-7998-4360-3 978-1-7998-4361-0},
  file = {/Users/colin.madland/Zotero/storage/7UVHUGRZ/carterServingAdultLearners2021.pdf}
}

@article{carvalhoHowCanWe2022,
  title = {How Can We Design for Learning in an {{AI}} World?},
  author = {Carvalho, Lucila and {Martinez-Maldonado}, Roberto and Tsai, Yi-Shan and Markauskaite, Lina and De Laat, Maarten},
  year = {2022},
  month = jan,
  journal = {Computers and Education: Artificial Intelligence},
  volume = {3},
  pages = {100053},
  issn = {2666-920X},
  doi = {10.1016/j.caeai.2022.100053},
  abstract = {Fast improvements in computing power and Artificial Intelligence (AI) algorithms enable us to automate important decisions that shape our everyday lives, and drive workplace transformations. It is predicted that many people will find themselves unprepared to deal with high degrees of change and uncertainty, increasingly posed by AI in some sectors. A critical educational challenge involves figuring out how to support young generations to develop the capabilities that they will need to adapt to, and innovate in, a world with AI. This article argues that both educators and learners should be involved not only in learning but also in co-designing for learning in an AI world. Further, they together should explore the knowledge, goals and actions that could help people shape future AI scenarios, and learn to deal with high degrees of uncertainty. A key contribution of the paper is a re-conceptualization of design for learning in an AI world, which explores a problem space of educational design, and illustrates how educators and learners can work together to re-imagine education futures in an AI world. As part of this problem space, the paper discusses underpinning philosophies (the capability approach and value creation), a high-level pedagogy (with an emphasis on co-creation), pedagogical strategies (speculative pedagogies), and pedagogical tactics (AI scenarios). It then proposes a design framework (ACAD) to support educators and learners' discussions about design for learning in an AI world. This participatory design approach aims to sensitize people for what education may mean, for whom, and how learning with AI may look like, and it highlights the active engagement of educators and learners in co-designing a future they desire, to help shape learning and living in an AI world.},
  keywords = {Artificial Intelligence,Capability approach,Design for learning},
  file = {/Users/colin.madland/Zotero/storage/UTCVQ4BK/carvalhoHowCanWe2022.pdf}
}

@article{casanovaGivingAwayTheir2021,
  title = {Giving Away Some of Their Powers! {{Towards}} Learner Agency in Digital Assessment and Feedback},
  author = {Casanova, D and Alsop, G and Huet, I},
  year = {2021},
  journal = {Research And Practice In Technology Enhanced Learning},
  volume = {16},
  number = {1},
  issn = {1793-7078},
  doi = {10.1186/s41039-021-00168-6},
  abstract = {Digital assessment and feedback have been a growing area of research and practice in the past decade in higher education. Within this theme, research has been published highlighting the importance of learner agency in the assessment and feedback process as a way to develop assessment literacy in contrast with the existing lecturer-led approach. In this research, we aimed to find out whether lecturers are willing to let go of some of the power they currently have in the digital assessment and feedback process and how they see opportunities for agency being developed in the digital assessment and feedback systems. We collected data from 10 sandpits with 58 lecturers in which, using a storytelling technique and one mock-up of a digital assessment and feedback system, we discussed and critiqued an assessment scenario intending to collect perceptions about digital assessment and feedback and the constraints felt by lecturers in their assessment practice. Based on these perceptions, we identify recommendations that may improve digital assessment and feedback systems and practices. We discuss the data and the recommendations based on three clusters of themes: (i) preparation for the assessment, (ii) formative feedback and (iii) feedback post-submission.},
  langid = {english},
  keywords = {Architectures for educational technology system,ENGAGEMENT,Human-computer interface,Information literacy,Pedagogical issues,Post-secondary education,SOCIAL COGNITIVE THEORY,TECHNOLOGY,UK,WRITTEN},
  file = {/Users/colin.madland/Zotero/storage/22PI5EI9/casanovaGivingAwayTheir2021.pdf}
}

@article{casanovaMovingLecturerStudentled2022,
  title = {Moving from Lecturer to Student-Led Digital Assessment and Feedback},
  author = {Casanova, D and Alsop, G and Huet, I},
  year = {2022},
  journal = {International Journal of Technology Enhanced Learning},
  volume = {14},
  number = {3},
  pages = {328--345},
  issn = {1753-5255},
  doi = {10.1504/IJTEL.2022.123668},
  abstract = {In this study, we provide insight into how digital assessment and feedback systems should be designed to promote student-led learning experiences. The study aims to answer the question: How can digital assessment and feedback systems better serve the purpose of improving the student's learning experience in HE? We conducted 10 focus groups with 58 lecturers in which, using a storytelling technique and mockups of a digital assessment and feedback system, we discussed and critique a scenario aiming at collecting lecturers' perceptions about digital assessment and feedback. Based on these perceptions, we identify three recommendations that may improve digital assessment and feedback: (i) students should proactively engage with the assessment; (ii) implementing a library of feedback that collects all the feedback received for the programme of study and (iii) encouraging more dialogue in the feedback process, by means of separating the provision of the feedback and the mark. We argue that the effective design of learning technologies can be a positive disruptive factor of the assessment practice.},
  langid = {english},
  keywords = {digital assessment and feedback,ENGAGEMENT,feedback literacy,learning management systems,pedagogical issues,post-secondary education,student-centred assessment,WRITTEN}
}

@book{caseCanadianAnthologySocial1999,
  title = {The {{Canadian}} Anthology of Social Studies : Issues and Strategies for Teachers},
  author = {Case, {\relax Roland}. and Clark, {\relax Penney}.},
  year = {1999},
  publisher = {Pacific Educational Press},
  address = {Vancouver},
  isbn = {1-895766-39-7 978-1-895766-39-4},
  langid = {english}
}

@article{caspari-sadeghiStudentGeneratedQuestionsDeveloping2021,
  title = {Student-{{Generated Questions}}: {{Developing Mathematical Competence}} through {{Online Assessment}}},
  author = {{Caspari-Sadeghi}, Sima and {Forster-Heinlein}, Brigitte and Maegdefrau, Jutta and Bachl, Lena},
  year = {2021},
  month = jan,
  journal = {International Journal for the Scholarship of Teaching and Learning},
  volume = {15},
  number = {1},
  publisher = {{International Journal for the Scholarship of Teaching and Learning}},
  issn = {1931-4744},
  doi = {10.20429/ijsotl.2021.150108},
  abstract = {This action research study presents the findings of using a formative assessment strategy in an online mathematic course during the world-wide outbreak of COVID-19 at the University of Passau, Germany. The main goals of this study were: (1) to enhance students' self-regulated learning by shifting the direction of assessment from instructors to the students; and (2) to promote deep active learning in mathematics. Students were required to conduct self-regulated learning on a selected topic. They were encouraged to formulate two multiple-choice questions (MCQs) and pose them after each presentation in an online course. The effectiveness of Student-generated Questions (SGQs) as a learning strategy was measured in terms of: (1) students' engagement; and (2) learning outcomes. While evidence on students' engagement was gathered through an online questionnaire survey, the learning outcomes were measured by analyzing the quality of SGQs. Results indicated that authoring questions, though leading to a higher students' engagement with the materials, could be quite challenging for students and did not lead to higher achievement. The authors provide some suggestions for improving the process through regular uses of digital technologies such as PeerWise.},
  keywords = {College Students,Computer Assisted Testing,COVID-19,Educational Technology,Evaluation Methods,Foreign Countries,Formative Evaluation,Germany,Learner Engagement,Mathematics Instruction,Multiple Choice Tests,Online Courses,Pandemics,Program Effectiveness,Questioning Techniques,Student Attitudes,Student Centered Learning,Student Evaluation,Technology Uses in Education},
  file = {/Users/colin.madland/Zotero/storage/PBLX8TCU/caspari-sadeghiStudentGeneratedQuestionsDeveloping2021.pdf}
}

@article{castanedaInternationalInsightsHolistic2021,
  title = {International Insights about a Holistic Model of Teaching Competence for a Digital Era: The Digital Teacher Framework Reviewed},
  author = {Casta{\~n}eda, Linda and {Esteve-Mon}, Francesc Marc and Adell, Jordi and Prestridge, Sarah},
  year = {2021},
  month = oct,
  journal = {European Journal of Teacher Education},
  pages = {1--20},
  publisher = {Routledge},
  issn = {0261-9768},
  doi = {10/gm5c7q},
  abstract = {ABSTRACTThis paper qualitative examines a holistic framework for teaching in the digital era. The examination is based on teachers? perspectives of their career, that is, what core features can be said to characterise teacher?s practice, across contexts, cultures and subjects. Semi-structured interviews of expert teachers, specifically from Australia, Europe and the Latin-America, are the main data source. The design process sought to examine teachers? approaches to their professional definition and their agency to enact this, against a theoretically validated framework. Results indicated the emergence of three defining categories based on the validation and synthesis of the relationships between six elements in the theoretical model.}
}

@misc{CatalystProjectSupporting,
  title = {The {{Catalyst Project}}: {{Supporting Faculty Uses}} of the {{Web}}...with the {{Web}}},
  urldate = {2020-09-02},
  howpublished = {https://www.educause.edu/ir/library/html/cem/cem99/cem9934.html},
  file = {/Users/colin.madland/Zotero/storage/RNP6JARR/cem9934.html}
}

@misc{CathedralBazaar,
  title = {The {{Cathedral}} and the {{Bazaar}}},
  urldate = {2020-04-29},
  howpublished = {http://www.catb.org/{\textasciitilde}esr/writings/cathedral-bazaar/cathedral-bazaar/index.html},
  file = {/Users/colin.madland/Zotero/storage/33UMPM9Q/index.html}
}

@article{catherinecroninOpenEducationOpen,
  title = {Open {{Education}}, {{Open Questions}}},
  author = {{Catherine Cronin}},
  urldate = {2018-11-05},
  abstract = {The use of open practices by learners and educators is complex, personal, and contextual; it is also continually negotiated. Higher education institut},
  langid = {english},
  keywords = {open education},
  file = {/Users/colin.madland/Zotero/storage/E7QW5PK6/open-education-open-questions.html}
}

@article{catheyFacultyForumPower2007,
  title = {Faculty {{Forum}}: {{Power}} of {{Peer Review}}: {{An Online Collaborative Learning Assignment}} in {{Social Psychology}}},
  author = {Cathey, Christie},
  year = {2007},
  journal = {Teaching of Psychology},
  volume = {34},
  number = {2},
  pages = {97--99},
  abstract = {In a semester-long, peer review assignment, undergraduates enrolled in a social psychology course wrote essays that applied course concepts to life experiences. Students anonymously posted essays for the entire class to view, and peers posted commentaries on classmates' essays using an online discussion board. Students rated the assignment as enjoyable and useful for improving their writing skills and conceptual understanding. For the instructor, the online nature of the assignment afforded all the benefits of peer review without increasing workload. [ABSTRACT FROM AUTHOR] Copyright of Teaching of Psychology is the property of Sage Publications Inc. and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
  keywords = {aspects,collaborative,Education,Higher,LEARNING,PEER,performance),Professional,programs,PSYCHOLOGICAL,review,scholarship,UNDERGRADUATE},
  annotation = {Cathey, Christie 1; Affiliations: 1 : Missouri Southern State University; Source Info: Spring2007, Vol. 34 Issue 2, p97; Thesaurus Term: PEER review (Professional performance); Thesaurus Term: LEARNING; Thesaurus Term: LEARNING \& scholarship; Thesaurus Term: UNDERGRADUATE programs; Thesaurus Term: HIGHER education; Thesaurus Term: COLLABORATIVE learning; Subject Term: PSYCHOLOGICAL aspects; Number of Pages: 3p; Illustrations: 1 Chart; Document Type: Article}
}

@article{cavalcante-pimentelLearningStrategiesDigital2022,
  title = {Learning Strategies through Digital Games in a University Context},
  author = {{Cavalcante-Pimentel}, {\relax FS} and {Morais-Marques}, M and {Barbosa-de-Sales}, V},
  year = {2022},
  journal = {COMUNICAR},
  volume = {30},
  number = {73},
  issn = {1134-3478},
  doi = {10.3916/C73-2022-07},
  abstract = {The relationship between digital games and the mobilization of cognitive and metacognitive learning strategies deserves attention and needs research that contributes to the understanding of how these strategies can favor the teaching and learning processes. This study describes how university students over 18 years of age mobilize cognitive and metacognitive learning strategies through digital games. The research methodology used was ex post facto with a quantitative approach. 941 students from 22 States and from the Federal District, enrolled in higher education courses at Brazilian colleges and universities, participated in this research. Data collection occurred through the application of an online questionnaire that integrates the Metacognitive Awareness Inventory (MAI) and the Inventory of Cognitive and Metacognitive Strategies with Digital Games (ICMSDG). The results indicated that university students make regular use of metacognitive knowledge, skills, and strategies. Moreover, cognitive and metacognitive learning strategies seem to be more mobilized by digital game players than by non-players, particularly among those who played over a longer period of time (9 years or more) and with higher intensity (playing every day). With the results found and analyzed, we observe that this study is relevant for both university professors and game designers who aim to promote metacognition skils.},
  langid = {english},
  keywords = {assessment,cognition,Digital games,higher education,metacognition,METACOGNITION,questionnaire},
  file = {/Users/colin.madland/Zotero/storage/846HBRVJ/cavalcante-pimentelLearningStrategiesDigital2022.pdf}
}

@article{cechTestIndustrySplit2008,
  title = {Test {{Industry Split Over}} '{{Formative}}' {{Assessment}}},
  author = {Cech, Scott J.},
  year = {2008},
  month = sep,
  journal = {Education Week},
  issn = {0277-4232},
  urldate = {2021-03-25},
  abstract = {There's a war of sorts going on within the normally staid assessment industry, and it's a war over the definition of a type of assessment that many educators understand in only the sketchiest fashion.},
  chapter = {Assessment},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/XUSCRHLT/09.html}
}

@article{celikResponseLearningAnalytics2022,
  title = {Response of Learning Analytics to the Online Education Challenges during Pandemic: {{Opportunities}} and Key Examples in Higher Education},
  author = {Celik, I and Gedrimiene, E and Silvola, A and Muukkonen, H},
  year = {2022},
  journal = {Policy Futures In Education},
  issn = {1478-2103},
  doi = {10.1177/14782103221078401},
  abstract = {Emerging technological advancements can play an essential role in overcoming challenges caused by the COVID-19 pandemic. As a promising educational technology field, Learning Analytics (LA) tools or systems can offer solutions to COVID-19 pandemic-related needs, obstacles, and expectations in higher education. In the current study, we systematically reviewed 20 papers to better understand the responses of LA tools to the online learning challenges that higher education students, instructors, and institutions faced during the pandemic. In addition, we attempted to provide key cases in which LA has been effectively deployed for various purposes during the pandemic in the higher education context. We found out several prominent challenges for stakeholders. Accordingly, learners needed of timely support and interaction, and experienced difficulty of time management. Instructors lacked pedagogical knowledge for online teaching. In particular, individual and collaborative assessment have been a challenge for them. Institutions have not been ready for a digital transformation and online teaching. In response to these challenges, LA tools have been deployed for the following opportunities: monitoring, planning online learning process, fostering learners' engagement and motivation, facilitating assessment process; increasing interaction, improving retention, being easy to use. Understanding these promises can also give insight into future higher education policies.},
  langid = {english},
  keywords = {DASHBOARD,DESIGN,higher education,Learning analytics,online learning,pandemic,policy making}
}

@article{cetinkorogluUsingDigitalFormative2021,
  title = {Using {{Digital Formative Assessment}} to {{Evaluate EFL Learners}}' {{English Speaking Skills}}},
  author = {{\c C}etin K{\"o}roglu, Zeynep},
  year = {2021},
  month = jan,
  journal = {GIST Education and Learning Research Journal},
  number = {22},
  pages = {103--123},
  publisher = {{GIST Education and Learning Research Journal}},
  issn = {1692-5777},
  doi = {10.26817/16925777.1001},
  abstract = {As it is known formative assessment focuses on both learning process and learner's performance. In this study, digital formative assessment and traditional speaking tests were utilized comparatively to evaluate 52 upper-intermediate EFL learners' English language speaking skills. The study was designed as a mixed-method. The quantitative data were collected via achievement tests which had been administered both in traditional speaking tests and digital formative tests. The qualitative findings were collected with students' interviews which consisted of four open-ended questions. The results of the study showed that participants outperformed in digital formative tests in comparison to traditional speaking tests. Another significant finding of the study is that participants are satisfied with the digital formative assessments in terms of peer collaboration during tests, enriched test materials, and preparation time for the speaking test. Although they have positive views on digital formative assessment, participants are dissatisfied with it in terms of technical problems that they encountered during the administration of digital formative tests.},
  keywords = {Computer Assisted Testing,English (Second Language),Foreign Countries,Formative Evaluation,Language Tests,Late Adolescents,Preservice Teachers,Public Colleges,Scores,Second Language Instruction,Second Language Learning,Skill Development,Speech Skills,Student Satisfaction,Test Preparation,Turkey},
  file = {/Users/colin.madland/Zotero/storage/WP85LUYX/cetinkorogluUsingDigitalFormative2021.pdf}
}

@article{cetinMetacognitionSelfRegulatedLearning2017,
  title = {Metacognition and {{Self-Regulated Learning}} in {{Predicting University Students}}' {{Academic Achievement}} in {{Turkey}}},
  author = {{\c C}etin, Baris},
  year = {2017},
  journal = {Journal of Education and Training Studies},
  volume = {5},
  pages = {132--138},
  issn = {2324-805X},
  abstract = {The purpose of this study was to determine whether perceived levels of self-regulated learning and metacognition predicted the ultimate grade point average (GPA) attained by 206 female and 70 male college seniors (aged 21 to 27) finishing their elementary education teaching certification studies at a university in Turkey. Data regarding individual levels of metacognition were collected through the administration of the "Metacognitive Skills Inventory for Adults" (Schraw \& Dennison, 1994) and translated to Turkish by Ozcan (2007). A separate scale authored by Turan (2009) was administered to the same set of participants to obtain levels of perceived self-regulated learning. Findings indicated that students' self-regulated learning and metacognition total scores correlated with each other but neither scale was predictive of the students' GPAs at a significant level in the hypothesized positive direction. Interestingly, self-regulated learning scores were significantly related to GPA but in a negative direction.},
  keywords = {Metacognition; Academic Achievement; Foreign Countries; Grade Point Average; College Seniors; Measures (Individuals); Teacher Education; Elementary School Teachers; Scores; Correlation; Multiple Regression Analysis}
}

@article{chadhaOpeningAssessmentAge2020,
  ids = {chadhaOpeningAssessmentAge2020a},
  title = {Opening up {{Assessment}} in the {{Age}} of {{COVID-19}}: {{Exploring}} the {{Utility}} of {{Online Open-Book Exams}}},
  author = {Chadha, Deesha and Maraj, Marsha and Kogelbauer, Andreas},
  year = {2020},
  journal = {Advances in Engineering Education},
  volume = {8},
  number = {4},
  publisher = {Advances in Engineering Education},
  issn = {EISSN-1941-1766},
  abstract = {COVID-19 has brought with it a tremendous sea-change in higher education globally. It has brought an opportunity to reconsider the way in which assessment is approached. The context for this paper is a chemical engineering department in a research-intensive university located in central London. Open book exams are used minimally in the degree programmes with retention and knowledge being tested mostly through closed-book exams. The COVID-19 outbreak meant there was now a pressing need to reconsider how students could effectively be assessed under extraordinary circumstances. In the UK [United Kingdom], students were effectively nearing the end of the academic year when ordered into lockdown. Students departed for home, both nationally and overseas and there were only a few options to address assessment. The authors turned to an examination provision that comprised open-book examinations which were taken in fixed, timed sessions. This raised several issues related to: (1) the use of open book exams which many students had not experienced as part of their university assessment; (2) the implication of staggered assessments, accommodating different time zones, given that a large proportion of students are international; (3) using appropriate platforms to deliver and mark exams; and (4) providing pastoral care and support to students during their examination and study periods. This paper outlines the authors' approach to these issues and the impact they have on future assessment provision.},
  langid = {english},
  keywords = {Chemical Engineering,Computer Assisted Testing,COVID-19,Doctoral Students,Engineering Education,Foreign Countries,Graduate Students,No DOI found,Pandemics,Student Evaluation,Test Format,Undergraduate Students,United Kingdom (London)}
}

@phdthesis{chalasPaintingPortraitOrganizational2019,
  title = {Painting a {{Portrait}} of {{Organizational Evaluation Capacity}} in the {{Canadian Art Museum Sector}}},
  author = {Chalas, Agnieszka},
  year = {2019},
  journal = {ProQuest Dissertations and Theses},
  address = {Ann Arbor},
  abstract = {Not only is research on program evaluation practice and capacity in art museums largely absent, but also the actual dimensions of evaluation capacity as they could be observed in these unique professional settings have heretofore neither been conceptualized or defined based on empirical data. This study sought to (a) develop a framework that conceptualized what evaluation capacity might look like in art museums and (b) examine how such capacity manifested itself across the framework's various dimensions both sector-wide and in those Canadian art museums that were most active in conducting a wide range of research and evaluation studies. A two-phase multiple method qualitative research design was used to address the purposes of this research. Phase One involved conducting an interview study to establish an initial knowledge base on Canadian art museum educators' program evaluation practices and capacities and test the degree to which the initial conceptual framework that was developed to guide this study could be considered an accurate and complete description of evaluation capacity in the Canadian art museum context. Phase Two involved conducting qualitative case studies of two art museums that, based on the interview findings, were identified as operating at the highest level of capacity for evaluation in the country. The study provided the evidence necessary to finalize the initial conceptual framework and concluded that evaluation capacity in Canadian art museums could be described through six central subdivided dimensions. The study results likewise both painted a portrait of moderate capacity for evaluation across the sector (with smaller pockets of high capacity) and shed empirical light on the phenomenon of developed capacity in selected Canadian art museums. In, demarcating the dimensions that comprise evaluation capacity in art museums, this research makes a significant theoretical contribution to the evaluation literature. Several key recommendations that outline what could be done to strengthen the evaluation capacity of art museums in Canada, meanwhile, represent the main practical implication of this study. These recommendations are likely to be useful not only to the growing number of art museums seeking to integrate evaluation into their organizational cultures but also to several other sectors and organizational types.},
  langid = {english},
  school = {Queen's University (Canada)},
  keywords = {(UMI)AAI13910034,0273:Art education,0703:Organizational behavior,0730:Museum studies,Art education,Art museums,Communication and the arts,Education,Museum studies,Organizational behavior,Social sciences},
  annotation = {13910034},
  file = {/Users/colin.madland/Zotero/storage/HGUQXUZT/chalasPaintingPortraitOrganizational2019.pdf}
}

@inproceedings{chanDecentralizedSynchronousLearning2020,
  title = {Decentralized {{Synchronous Learning Pods For Learner Discourse}} and {{Community-Building}}: {{An Alternative}} to {{Breakout Rooms}}},
  booktitle = {Let's {{Talk}} about {{Teaching}}},
  author = {Chan, Katy and Irvine, Valerie and Madland, Colin},
  year = {2020},
  publisher = {University of Victoria},
  address = {Victoria, BC},
  abstract = {A common critique of remote learning environments is that learners and faculty alike experience significant feelings of isolation. This may be especially acute for those who thrive in busy, social environments like face-to-face campuses. One strategy that we have found to be impactful for reducing this sense of isolation is to use decentralized synchronous learning pods where learners connect with a small group of 4 learners to discuss both course logistics and course content. This small group becomes a key source of social and academic support and peer review.},
  copyright = {All rights reserved}
}

@book{chandraQualitativeDataAnalysis2016,
  title = {Qualitative {{Data Analysis}} with {{RQDA}}},
  author = {Chandra, Yanto and Liang, Echo Shang},
  year = {2016},
  publisher = {Springer Singapore},
  abstract = {Qualitative research suffers from the ``no accepted boilerplate'' problem, which has hampered the progress and broader acceptance of the qualitative research enterprise. This book introduces and demonstrates RQDA, an open-source computer-assisted qualitative data analysis (CAQDAS)-based R extension that increases the transparency and trustworthiness of qualitative research. This book aims to highlight the rise of the Strauss-Corbin-Gioia (SCG) methodology as an important paradigm in qualitative research in the social sciences, and demonstrates how the SCG methodology can be operationalized and enhanced using RQDA. It provides a technical and methodological review of RQDA as a new CAQDAS tool. It uses samples of textual data and demonstrates the development of a data structure and grounded process model using the RQDA-based SCG methodology. Various techniques will be covered, including a general overview of R programming language, the installation of R, RStudio and RQDA; data preparation, data coding techniques, data attributes and memo-ing in RQDA; code abstraction and code plotting in RQDA and grounded theory development as the final output in qualitative research.Unlike other CAQDAS books which merely focuses on the technical aspects of CAQDAS (NVivo by Pat Bazeley; ATLAS.ti by Susanne Friese) or general qualitative research books that do not offer any tools or techniques on how to use the tools to operationalize qualitative research, this book offers a methodological guidance on how to connect CAQDAS tool with accepted paradigms in qualitative research particularly the SCG methodology to produce high quality qualitative research. The book offers a step-by-step instruction on using RQDA under the well-accepted SCR qualitative research paradigm. It provides a complete treatment on the methodological issues in qualitative research such as asking the right question, collecting qualitative data, analyzing and presenting the results in the ways that are appealing to journal editors/reviewers, as well as other stakeholders and publication outlets.This will be the first book that discusses and applies an open source (i.e., free) CAQDAS tool called RQDA for qualitative research in the social sciences; as an alternative to the proprietary tools such as NVivo and ATLAS.ti. This book is timely especially in the era of budget cutting in universities, corporations, and non-profit organizations.This book will help qualitative scholars, quantitative scholars who are familiar with programming languages to ``cross over'' to analyzing qualitative data, as well as PhD/post-doctoral students and coursework students taking qualitative methodology courses in the broader social sciences.},
  keywords = {Data analysis,METHODOLOGY,Methodology of social sciences,Open Source Software,qualitative research,R programming}
}

@book{chandraQualitativeResearchUsing2019,
  title = {Qualitative {{Research Using R}}: {{A Systematic Approach}}},
  shorttitle = {Qualitative {{Research Using R}}},
  author = {Chandra, Yanto and Shang, Liang},
  year = {2019},
  publisher = {Springer Singapore},
  address = {Singapore},
  doi = {10.1007/978-981-13-3170-1},
  urldate = {2020-07-06},
  isbn = {978-981-13-3169-5 978-981-13-3170-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/GZLGG4YB/chandraQualitativeResearchUsing2019.pdf}
}

@article{chandraRQDAbasedConstructivistMethodology2017,
  title = {An {{RQDA-based}} Constructivist Methodology for Qualitative Research},
  author = {Chandra, Yanto and Shang, Liang},
  year = {2017},
  month = jan,
  journal = {Qualitative Market Research: An International Journal},
  volume = {20},
  number = {1},
  pages = {90--112},
  issn = {1352-2752},
  doi = {10/gfkhgt},
  urldate = {2020-07-06},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/KIZ3Z4F3/chandraRQDAbasedConstructivistMethodology2017.pdf}
}

@article{chanExploringTeacherPerceptions2022,
  title = {Exploring Teacher Perceptions of Different Types of 'feedback Practices' in Higher Education: Implications for Teacher Feedback Literacy},
  author = {Chan, Cecilia Ka Yuk and Luo, Jiahui},
  year = {2022},
  journal = {Assessment and evaluation in higher education},
  volume = {47},
  number = {1},
  pages = {61--76},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0260-2938},
  doi = {10.1080/02602938.2021.1888074},
  abstract = {Universities around the world are encouraging teachers to provide more constructive feedback to support student learning, but do teachers know how to distinguish constructive feedback? What pedagogical practice is considered as feedback and what is not? For example, is a rubric a type of feedback? To date, very limited research has answered these questions from university teachers' perspectives and the current study aims to address this gap. In this study, ten teacher training workshops were conducted in a university in Hong Kong, with an intention to enhance teachers' competence in assessment and feedback. During the workshops, we first adopted Poll Everywhere to survey whether teachers (N = 248) recognise six types of common pedagogical practices as feedback, and subsequently used this as a base to discuss with teachers the reasons behind their responses. Findings reveal teachers' varied perceptions of these practices as feedback, which may be related to their varied understandings of feedback purposes. The paper calls for an explicit acknowledgement of the multiple purposes of feedback, and concludes with implications for teacher feedback literacy in higher education.},
  langid = {english},
  keywords = {Education & Educational Research,Feedback,feedback literacy,feedback purpose,Higher education,Learning,Literacy,Pedagogy,Polls & surveys,Social Sciences,Teacher attitudes,Teacher education,teacher perceptions,Teachers}
}

@article{chanFourdimensionalConceptualFramework2021,
  title = {A Four-Dimensional Conceptual Framework for Student Assessment Literacy in Holistic Competency Development},
  author = {Chan, Cecilia Ka Yuk and Luo, Jiahui},
  year = {2021},
  month = apr,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {46},
  number = {3},
  pages = {451--466},
  issn = {0260-2938, 1469-297X},
  doi = {10/gk33r4},
  urldate = {2021-07-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/LWEDC333/chanFourdimensionalConceptualFramework2021.pdf}
}

@article{changAssessingPeerSupport2014,
  title = {Assessing Peer Support and Usability of Blogging in Hybrid Learning Environments},
  author = {Chang, Y.J. and Chang, Y.S.},
  year = {2014},
  month = jan,
  journal = {Interactive Learning Environments},
  volume = {22},
  number = {1},
  pages = {3--17},
  issn = {1049-4820, 1744-5191},
  doi = {10/d49ppk},
  urldate = {2021-05-04},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/XRTIWC84/changAssessingPeerSupport2014.pdf}
}

@article{changEffectsMobileBasedPeerAssessment2020,
  title = {Effects of a {{Mobile-Based Peer-Assessment Approach}} on {{Enhancing Language-Learners}}' {{Oral Proficiency}}},
  author = {Chang, Ching and Lin, Hao-Chiang Koong},
  year = {2020},
  month = jan,
  journal = {Innovations in Education and Teaching International},
  volume = {57},
  number = {6},
  pages = {668--679},
  publisher = {{Innovations in Education and Teaching International}},
  issn = {1470-3297},
  doi = {10.1080/14703297.2019.1612264},
  abstract = {Peer assessment (PA) has transformed traditional teacher-only assessment into the student-centred assessment. While this pedagogical approach has been adopted online in recent years, incorporating PA into classrooms has proven to be challenging. In this study, mobile-supported PA (M-PA) activities using Instant Response System (IRS) mechanisms to enhance oral proficiency are proposed for English as a Foreign Language (EFL) students. A quasi-experiment was conducted to evaluate the effectiveness of this approach in the context of an English language course at a university. A total of 60 university students participated, 30 of whom were in the experimental group using the M-PA method and 30 of whom were in the control group using the conventional teacher-only assessment method. The results show that the M-PA method can effectively promote students' oral proficiency, facilitate personal reflection, and foster positive perceptions of learning.},
  keywords = {Audience Response Systems,Electronic Learning,English (Second Language),Feedback (Response),Foreign Countries,Handheld Devices,Instructional Effectiveness,Language Proficiency,Oral Language,Peer Evaluation,Reflection,Second Language Instruction,Second Language Learning,Speech Skills,Student Attitudes,Taiwan,Technology Integration,Undergraduate Students}
}

@incollection{changIndividualCollaborativeAutoethnography2021,
  title = {Individual and {{Collaborative Autoethnography}} for {{Social Science Research}}},
  booktitle = {Handbook of {{Autoethnography}}},
  author = {Chang, Heewon},
  editor = {Adams, Tony E. and Jones, Stacy Holman and Ellis, Carolyn},
  year = {2021},
  month = jul,
  edition = {2},
  pages = {53--65},
  publisher = {Routledge},
  address = {New York},
  doi = {10.4324/9780429431760-6},
  urldate = {2023-11-19},
  isbn = {978-0-429-43176-0},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/EG7ZJ6BJ/changIndividualCollaborativeAutoethnography2021.pdf}
}

@book{chanOnlineTeachingLearning2021,
  title = {Online Teaching and Learning in Higher Education during {{Covid-19}} : International Perspectives and Experiences},
  author = {Chan, Roy Y. and Bista, Krishna and Allen, Ryan M.},
  year = {2021},
  series = {Routledge Studies in Global Student Mobility},
  publisher = {Routledge},
  address = {New York, NY},
  abstract = {"This timely volume documents the immediate, global impacts of the coronavirus pandemic (COVID-19) on teaching and learning in Higher Education. Focussing on student and faculty experiences of online and distance education, the text provides reflection on novel initiatives, unexpected challenges, and lessons learnt. Responding to the urgent need to better understand online teaching and learning during the COVID-19 pandemic, this book investigates how the use of information and communication technologies (ICT) impacted students, faculty, and staff experiences during the COVID-19 lockdown. Chapters initially look at the challenges faced by universities and educators in their attempts to overcome the practical difficulties involved in developing effective online programming and pedagogy. The text then builds on these insights to highlight student experiences and consider issues of social connection and inequality. Finally, the volume looks forward to ask what lessons COVID-19 can offer for the future development of online and distance learning in Higher Education. This engaging volume will benefit researchers, academics, and educators with an interest in online teaching and eLearning, curriculum design, and more specifically those involved with the digitalization of higher education. The text will also support further discussion and reflection around pedagogical transformation, international teaching and learning, and educational policy more broadly. Roy Y. Chan is Assistant Professor of Education and Director of the Doctorate of Education (Ed.D.) program in Leadership and Professional Practice in the Helen DeVos College of Education at Lee University, Tennessee, USA. Krishna Bista is Professor in the Department of Advanced Studies, Leadership and Policy at Morgan State University, Maryland, USA. Ryan M. Allen is Assistant Professor of Practice in the Attallah College of Educational Studies at Chapman University, California, USA"-- Provided by publisher.},
  isbn = {1-000-42676-9},
  keywords = {COVID-19 Pandemic 2020-,Education Higher -- Computer-assisted instruction,Electronic books,Social distancing (Public health) and education},
  file = {/Users/colin.madland/Zotero/storage/EQIRFBCC/chanOnlineTeachingLearning2021.pdf}
}

@article{chanpetOnlineProjectBasedLearning2020,
  title = {Online {{Project-Based Learning}} and {{Formative Assessment}}},
  author = {Chanpet, P and Chomsuwan, K and Murphy, E},
  year = {2020},
  journal = {Technology Knowledge and Learning},
  volume = {25},
  number = {3},
  pages = {685--705},
  issn = {2211-1662},
  doi = {10.1007/s10758-018-9363-2},
  abstract = {Project-based learning (PBL) involves a highly complex and learner-centered approach. It relies on formative assessment (FA) with ongoing feedback to help learners move through the PBL process to the eventual co-construction of a shared artefact. Conversation and discussion are central to the process. However, in a face-to-face context of learning, they are difficult to capture for later review or reflection as part of FA. This study investigates the role that technology might play in addressing this limitation using online PBL and FA in a media-creation course in a Thai university. Participants were undergraduate, pre-service teachers preparing to teach English as a foreign language. Objectives included the local design and implementation of online PBL and FA; identification of pre-service teachers' (n = 28) post-implementation perceptions of the convenience, benefits and barriers of this form of learning; perceptions of their PBL skills and; post-implementation measures of PBL knowledge and skills compared with learners participating in a face-to-face section of the course (n = 30). Results revealed that the technology provided a foundational scaffold to support both the learners' and the instructor's activity and interaction. The design of a simple learning management system with communication and file-sharing tools supported not only the learners, but the instructor, not only the assessment, but the learning. Learners' perceptions were positive and post-implementation measures of PBL knowledge and skill were significantly higher for the online section.},
  langid = {english},
  keywords = {ANALYTICS,DESIGN,E-portfolio,EDUCATION,Higher education,IMPACT,Learning management system,Online formative assessment,Project-based learning}
}

@article{chanStudentPartnershipAssessment2023,
  title = {Student Partnership in Assessment in Higher Education: A Systematic Review},
  author = {Chan, Cecilia Ka Yuk and Chen, Siaw Wee},
  year = {2023},
  month = nov,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {48},
  number = {8},
  pages = {1402--1414},
  publisher = {Routledge},
  issn = {0260-2938},
  doi = {10.1080/02602938.2023.2224948},
  abstract = {This systematic review aims to explore how student partnership is enacted in higher education assessment using community of practice and liminality of student roles as the conceptual framework. Forty-three empirical studies were selected, and extracted data were synthesised using thematic analysis. The results show that student partnership occurs in four main areas of assessment ? assessment and feedback design, execution and implementation, quality assurance, policy establishment ? and that students adopt the role of co-designers, assessors, consultants and decision-makers in assessment partnerships. The analysis also reveals four types of support university staff can provide to facilitate partnerships: essential knowledge, training and coaching, accuracy and quality check and partnership management. Based on the findings, a framework is proposed to elucidate student partnership in assessment as situated learning in a community of practice. The findings of this review have theoretical and practical implications for policy makers, researchers and practitioners.},
  file = {/Users/colin.madland/Zotero/storage/BE7CWHVW/chanStudentPartnershipAssessment2023.pdf}
}

@article{chanSystematicReviewHandwritten2023,
  title = {A Systematic Review -- Handwritten Examinations Are Becoming Outdated, Is It Time to Change to Typed Examinations in Our Assessment Policy?},
  author = {Chan, Cecilia Ka Yuk},
  year = {2023},
  month = nov,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {48},
  number = {8},
  pages = {1385--1401},
  publisher = {Routledge},
  issn = {0260-2938},
  doi = {10.1080/02602938.2023.2219422},
  abstract = {With the advances of technologies, possessing digital and information literacy is crucial for the selection of candidates by employers in this digital AI era. For most students, receiving and outputting electronic text has become the norm, and thus examinations with writing components done by hand may not accurately reflect their abilities. It seems that such traditional handwritten examinations are incongruous when assignments are now expected to be in typed formats, so the question is should it become part of the university assessment policy to make it compulsory for students to type their examinations? To better assist higher education institutions in planning for long-term, future-oriented assessment policies, this study provides a systematic review of the literature focusing on typed and handwritten examinations. A classification scheme of the unambiguous advantages and disadvantages, ambivalent factors, and impacts and perceptions for different stakeholders, is developed based on the findings to provide a thorough and concrete foundation for stakeholders to act upon and navigate the complexities of transitioning to typed examinations.},
  file = {/Users/colin.madland/Zotero/storage/2USQZGR2/chanSystematicReviewHandwritten2023.pdf}
}

@book{chapelleArgumentBasedValidationTesting2021,
  title = {Argument-{{Based Validation}} in {{Testing}} and {{Assessment}}},
  author = {Chapelle, Carol A.},
  year = {2021},
  publisher = {SAGE Publications, Inc.},
  address = {2455 Teller Road,~Thousand Oaks~California~91320},
  doi = {10.4135/9781071878811},
  urldate = {2022-03-30},
  isbn = {978-1-5443-3448-6 978-1-0718-7881-1},
  file = {/Users/colin.madland/Zotero/storage/AETFVH28/chapelleArgumentBasedValidationTesting2021.pdf}
}

@article{chaseImprovingDigitalAssessment2017,
  title = {Improving {{Digital Assessment Practice}}: {{A Case Study}} of a {{Cross-Institutional Initiative}}},
  author = {Chase, {\relax AM} and Ross, B and Robbie, D},
  year = {2017},
  journal = {Journal of University Teaching and Learning Practice},
  volume = {14},
  number = {2},
  issn = {1449-9789},
  doi = {10.53761/1.14.2.5},
  abstract = {Assessment practice is a crucial component of higher education learning and teaching, however many academic teachers lack formal teaching qualifications and often fall back on teaching and assessing the way they themselves were taught. Furthermore, with increasingly diverse student cohorts, larger classes and increasing components of teaching delivered online, it is unsurprising that students rate assessment as one of the poorest features of their learning experiences. For these reasons, understanding the specific contexts of assessment is important now more than ever. This paper will present the findings of a case study of a cross-institutional initiative aimed at exploring how to improve digital assessment practice by focusing on context, and encouraging and facilitating collegial collaboration. The aim of the case study was to progress a digital assessment project at an Australian higher education provider. Teams of staff from two higher education providers collaborated to develop and implement eight prototype assessments to reform digital assessment practices. The assessments were selected from online undergraduate academic subjects across a range of disciplines. Findings reveal that both staff and students felt that there were benefits to the cross-institutional collaboration. The resulting assessment was perceived as improving student motivation and engagement and more tailored for the online environment than the existing assessment.},
  langid = {english},
  keywords = {assessment,ASSESSMENT DESIGN,BELIEFS,collaboration,COLLABORATION,DECISIONS,digital assessment,EVOLUTION,HIGHER-EDUCATION,PERSPECTIVE,student satisfaction,TEACHERS,TRUST,UNIVERSITY},
  file = {/Users/colin.madland/Zotero/storage/DKXBJ85B/chaseImprovingDigitalAssessment2017.pdf}
}

@misc{ChatGPTIDGAFHow,
  title = {{{ChatGPT}}: {{IDGAF}} ({{Or}}: {{How I Learned}} to {{Stop Worrying}} and {{Ignore}} the {{Bot}}) -- {{Peter Bryant}}: {{Post Digital Learning}}},
  urldate = {2023-01-27},
  howpublished = {https://www.peterbryant.org/chatgpt-idgaf-or-how-i-learned-to-stop-worrying-and-ignore-the-bot/},
  file = {/Users/colin.madland/Zotero/storage/YTSWB5U3/chatgpt-idgaf-or-how-i-learned-to-stop-worrying-and-ignore-the-bot.html}
}

@book{checklandSystemsThinkingSystems1981,
  title = {Systems Thinking, Systems Practice},
  author = {Checkland, Peter},
  year = {1981},
  series = {Systems {{Inquiry}} and Its Application in Education},
  publisher = {Wiley},
  address = {New York}
}

@book{chenbrianHowIPhoneCould2009,
  title = {How the {{iPhone}} Could Reboot Education},
  author = {Chen, Brian, X.},
  year = {2009},
  month = dec
}

@article{chenExploringDesignElements2018,
  title = {Exploring {{Design Elements}} for {{Online STEM Courses}}: {{Active Learning}}, {{Engagement}} \& {{Assessment Design}}},
  author = {Chen, Baiyun and Bastedo, Kathleen and Howard, Wendy},
  year = {2018},
  journal = {Online Learning},
  volume = {22},
  number = {2},
  pages = {59--75},
  issn = {ISSN-2472-5749},
  abstract = {The purpose of this study was to examine effective design elements for online courses in the science, technology, engineering, and mathematics (STEM) fields at a large four-year public university in southeastern United States. Our research questions addressed the influence of online design elements on students' perception of learning and learning satisfaction. An online survey was completed by 537 students from 15 online STEM courses in spring 2016. The survey results indicated that student perceptions of learning and satisfaction were correlated with their perceptions of the efficacy of specific design elements, such as integrated active learning activities, interactive engagement strategies, and robust assessment design. In particular, perception of assessment design efficacy was significantly correlated with students' self-perceived learning and learning satisfaction for students of all subpopulations. The findings inform instructors and instructional designers on how to design effective, inclusive, and engaging online STEM courses. Student survey responses were observed to support universal design for learning (UDL) and in light of this, online STEM instructors are also strongly encouraged to utilize UDL principles in course design, which benefit not only students with disabilities but all students.},
  langid = {english},
  keywords = {Active Learning,Blended Learning,College Students,Educational Technology,Evaluation Methods,Higher Education,Interaction,No DOI found,Online Courses,Online Surveys,Program Effectiveness,Statistical Analysis,STEM Education,Student Attitudes,Student Satisfaction,Student Surveys,Technology Uses in Education}
}

@article{chenExploringDesignElements2018a,
  title = {Exploring {{Design Elements}} for {{Online STEM Courses}}: {{Active Learning}}, {{Engagement}} \& {{Assessment Design}}},
  author = {Chen, Baiyun and Bastedo, Kathleen and Howard, Wendy},
  year = {2018},
  journal = {Online Learning Journal (OLJ)},
  volume = {22},
  number = {2},
  pages = {59},
  publisher = {Online Learning Consortium},
  issn = {1939-5256},
  doi = {10/ggrgxk},
  keywords = {Analysis,Learning strategies,Online education,Perception,Satisfaction}
}

@article{chengInnovativeAssessmentMethod2019,
  title = {An {{Innovative Assessment Method}} to {{Establish Employability Map Based}} on {{Students}}' {{Learning Portfolio}}},
  author = {Cheng, {\relax SC} and Chang, {\relax SL}},
  year = {2019},
  journal = {Problems of Education in the 21st Century},
  volume = {77},
  number = {2},
  pages = {209--227},
  issn = {1822-7864},
  doi = {10.33225/pec/19.77.209},
  abstract = {This research focuses on the approach adopted by a university of science and technology in Taiwan (hereinafter the university) to develop students' employability indices and to explore the questionnaire analyses. The university developed the "Employability Map; E-Map" by weighting the learning hours, which was used to evaluate students' various employability items over the course of their schooling. Considering it not so appropriate to use students' credits on courses to be the standard of judgment, the Department of Computer Science \& Information Engineering (hereinafter the department) proposed an innovative method to convert the E-Map of weighting by learning achievement to conduct assessments that is more reflection students' employability indices for graduate, and analyzed the questionnaires of alumni and their employers' various core employability indices. From those questionaires, finding the graduating students and alumni are lack of self-confidentce. The statistical data shall serve as a reference for guiding students at course selection, as well as improving department courses and planning.},
  langid = {english},
  keywords = {employability indices,employability map,learning achievement,learning portfolio,SELF-PERCEIVED EMPLOYABILITY},
  file = {/Users/colin.madland/Zotero/storage/2VSP4PNT/chengINNOVATIVEASSESSMENTMETHOD2019.pdf}
}

@article{chengTeachersGradingDecisions2020,
  title = {Teachers' Grading Decisions and Practices across Cultures: {{Exploring}} the Value, Consistency, and Construction of Grades across {{Canadian}} and {{Chinese}} Secondary Schools},
  shorttitle = {Teachers' Grading Decisions and Practices across Cultures},
  author = {Cheng, Liying and DeLuca, Christopher and Braund, Heather and Yan, Wei and Rasooli, Amir},
  year = {2020},
  month = dec,
  journal = {Studies in Educational Evaluation},
  volume = {67},
  pages = {100928},
  issn = {0191491X},
  doi = {10/ghg5pd},
  urldate = {2020-10-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/TSIGZ9KR/chengTeachersGradingDecisions2020.pdf}
}

@book{chenHowIPhoneCould2009,
  title = {How the {{iPhone}} Could Reboot Education},
  author = {Chen, Brian},
  year = {2009},
  month = dec
}

@article{chenInstructorSelfAssessmentContent2018,
  title = {Instructor's {{Self-Assessment}} of {{Content Design}} in {{Online Courses}}},
  author = {Chen, Li-Ting and Liu, Leping},
  year = {2018},
  journal = {International Journal of Technology in Teaching and Learning},
  volume = {14},
  number = {1},
  pages = {24--41},
  issn = {EISSN-1551-2576},
  abstract = {There are only a handful of studies focused on assessing online teaching. Yet, the uniqueness of online course environment provides instructors more opportunities to conduct self-assessment of their own teaching than the traditional face-to-face classroom. In this paper, we demonstrate two types of self-assessment through two cases that online course instructors can use to evaluate the course content during their regular online instructional procedures. An end-of-semester oral examination was used in Case One whereas the weekly discussion posts were used in Case Two. The instructors performed self-assessment, based on which they redesigned the course contents and activities. Nonparametric analyses were used to examine students' learning outcomes. Results indicate that, in both cases, student learning improved with the redesigned contents and activities.},
  langid = {english},
  keywords = {Computer Software,Course Content,Decision Making,Distance Education,Educational Change,Faculty Development,Feedback (Response),Graduate Students,Instructional Design,Learning Processes,Management Systems,Masters Programs,Methods Courses,No DOI found,Online Courses,Oral Language,Outcomes of Education,Self Evaluation (Individuals),Student Attitudes,Teaching Skills,Tests}
}

@misc{chenKnowledgeInfrastructuresInitial2021,
  title = {Knowledge {{Infrastructures}}: {{Initial Thoughts}}},
  shorttitle = {Knowledge {{Infrastructures}}},
  author = {Chen, Bodong},
  year = {2021},
  month = oct,
  journal = {Bodong Chen},
  urldate = {2021-10-23},
  abstract = {Some initial thoughts on knowledge infrastructures and what it means for knowledge building.},
  howpublished = {https://meefen.github.io/post/2021-10-knowledge-infrastructures/},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/QDIC6RFE/2021-10-knowledge-infrastructures.html}
}

@article{chenUseTechnologybasedAssessments2023,
  title = {Use of Technology-Based Assessments: A Systematic Review Covering over 30 Countries},
  author = {Chen, Dandan and Jeng, Amos and Sun, Shiyu and Kaptur, Bradley},
  year = {2023},
  month = nov,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {30},
  number = {5-6},
  pages = {396--428},
  publisher = {Routledge},
  issn = {0969-594X},
  doi = {10.1080/0969594X.2023.2270181},
  abstract = {The widespread adoption of technology-based assessments during the COVID-19 pandemic has exacerbated concerns about the digital divide, given global disparities in digital access, connectivity, and coping strategies. This systematic review was intended to assess how the use of technology-based assessments has affected the education system?s functioning in pre-college education, compared to traditional assessments. It covered 34 countries from 34 full-text English sources in 2018?2022. A total of 12 assumptions were tested, corresponding to six hypotheses about the learning, educating, and management facets associated with the use of technology-based assessments. Our findings revealed mixed evidence about technology-based assessments in reducing cheating, enhancing learning, supporting monitoring, improving instruction, and reducing non-teaching workload. However, strong evidence supported the assumptions that technology-based assessments improve measurement precision, interpretability, engagement, interaction, and teacher-parent communication. Limited but positive evidence supported the assumptions that technology-based assessments may reduce the cost and time of test administration.},
  file = {/Users/colin.madland/Zotero/storage/chenUseTechnologybasedAssessments2023.pdf}
}

@misc{cherryImportanceReliabilityPsychological,
  title = {The {{Importance}} of {{Reliability}} in {{Psychological Tests}}},
  author = {Cherry, Kendra},
  journal = {Verywell Mind},
  urldate = {2020-09-07},
  abstract = {Reliability is a vital component of a trustworthy psychological test. Learn more about what reliability is and how it is measured.},
  chapter = {Verywell},
  howpublished = {https://www.verywellmind.com/what-is-reliability-2795786},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/Z8YDZQFW/cherryImportanceReliabilityPsychological.pdf;/Users/colin.madland/Zotero/storage/GST7E9MR/what-is-reliability-2795786.html}
}

@misc{cherryWhyValidityImportant,
  title = {Why {{Validity Is Important}} to {{Psychological Tests}}},
  author = {Cherry, Kendra},
  journal = {Verywell Mind},
  urldate = {2020-09-07},
  abstract = {Learn why validity is one of the most important factors to consider when determining the merits of a psychological test.},
  chapter = {Verywell},
  howpublished = {https://www.verywellmind.com/what-is-validity-2795788},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/2VVMPT4G/cherryWhyValidityImportant.pdf;/Users/colin.madland/Zotero/storage/WG48439X/what-is-validity-2795788.html}
}

@article{chewEnhancingInternationalPostgraduates2016,
  title = {Enhancing International Postgraduates' Learning Experience with Online Peer Assessment and Feedback Innovation},
  author = {Chew, E and Snee, H and Price, T},
  year = {2016},
  journal = {Innovations in Education and Teaching International},
  volume = {53},
  number = {3},
  pages = {247--259},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {1470-3297},
  doi = {10.1080/14703297.2014.937729},
  abstract = {Internationalisation and assessment and feedback are one of the main research agenda in the UK higher education. The study reports the Higher Education Academy Economics Network-funded research for international students' experience with peer assessment and feedback innovation. The Vygotsky's Zone of Proximal Development (ZPD) theoretical framework is used to analyse students' experience. The finding demonstrates that peer assessment practice enhances assessment and feedback experience for international students. However, the heterogeneity in assessors' ability levels may affect the confidence of students in peer assessment. Independent justification for providing peer assessment or making sense of received feedback is necessary. The model of PeerMark's ZPD is suggested to become part of the peer assessment for learning ecosystem in order to empower learning experience rather than to provoke diffidence.},
  langid = {english},
  keywords = {Achievement Gains,Active Learning,assessment and feedback,Cameroon,China,EDUCATION & EDUCATIONAL RESEARCH,Educational Practices,Electronic Learning,Evaluation Criteria,Feedback (Response),Foreign Countries,Foreign Students,Graduate Students,India,Instructional Innovation,international postgraduates,Learning Experience,Mexico,Nigeria,Pakistan,peer assessment,Peer Evaluation,PeerMark,Qualitative Research,Semi Structured Interviews,Spain,Student Improvement,Tanzania,Teaching Methods,Technology-enhanced learning}
}

@article{chiappeOpenAssessmentLearning2016,
  title = {Open {{Assessment}} of {{Learning}}: {{A Meta-Synthesis}}},
  author = {Chiappe, A and Pinto, R and Arias, V},
  year = {2016},
  journal = {International Review of Research in Open and Distributed Learning},
  volume = {17},
  number = {6},
  pages = {44--61},
  issn = {1492-3831},
  abstract = {Open Assessment of Learning (OAoL) is an emerging educational concept derived from the incorporation of Information and Communication Technologies (ICT) to education and is related with the Open Education Movement. In order to improve understanding of OAoL a literature review was conducted as a meta-synthesis of 100 studies on ICT-based assessment published from 1995 to 2015, selected from well-established peer-reviewed databases. The purpose of this study focused on identifying the common topics between ICT-based assessment and OAoL which is considered as an Open Educational Practice. The review showed that extensive use of the Internet makes it easy to achieve some special features of OAoL as collaboration or sharing, which are considered negative or inconvenient in traditional assessment but at the same time become elements that promote innovation on that topic. It was also found that there is still a great resistance to accept change (as OAoL does) when structural elements of traditional assessment are questioned or challenged.},
  langid = {english},
  keywords = {collaboration,educational technology,FEEDBACK,FORMATIVE ASSESSMENT,HIGHER-EDUCATION,ICT,KNOWLEDGE,learning assessment,No DOI found,open educational practice,peer assessment,PEER-ASSESSMENT,QUALITATIVE METASYNTHESIS,REFLECTIONS,SCHOOL,SELF-ASSESSMENT}
}

@article{chickeringImplementingSevenPrinciples1996,
  title = {Implementing the Seven Principles: {{Technology}} as Lever},
  author = {Chickering, Arthur W and Ehrmann, Stephen C},
  year = {1996},
  journal = {American Association of Higher Education Bulletin},
  volume = {49},
  number = {2},
  pages = {3}
}

@article{chickeringSevenPrinciplesGood1987,
  title = {Seven {{Principles}} for Good Practice in Undergraduate Education},
  shorttitle = {Seven {{Principles}} for Good Practice in Undergraduate Education},
  author = {Chickering, Arthur W and Gamson, Zelda},
  year = {1987},
  journal = {American Association of Higher Education Bulletin},
  volume = {39},
  pages = {4},
  annotation = {7}
}

@article{chiorescuExploringOpenEducational2017,
  title = {Exploring {{Open Educational Resources}} for {{College Algebra}}},
  author = {Chiorescu, Marcela},
  year = {2017},
  month = jun,
  journal = {The International Review of Research in Open and Distributed Learning},
  volume = {18},
  number = {4},
  issn = {1492-3831},
  urldate = {2018-07-07},
  copyright = {Copyright (c) 2017 Marcela Chiorescu},
  langid = {english},
  keywords = {college algebra,hybrid course,math,open education resources},
  file = {/Users/colin.madland/Zotero/storage/9XJCK3IW/chiorescuExploringOpenEducational2017.pdf;/Users/colin.madland/Zotero/storage/PUWD3K9V/4223.html}
}

@article{chirumamillaEexamsNorwegianHigher2021,
  title = {E-Exams in {{Norwegian}} Higher Education: {{Vendors}} and Managers Views on Requirements in a Digital Ecosystem Perspective},
  author = {Chirumamilla, Aparna and Sindre, Guttorm},
  year = {2021},
  journal = {Computers and education},
  volume = {172},
  pages = {104263},
  publisher = {Elsevier Ltd},
  address = {OXFORD},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2021.104263},
  abstract = {E-assessment has been supported in Learning Management Systems for decades. More recently, dedicated e-exam systems have emerged on the market, more specifically supporting the workflow and security needs surrounding high stakes exams. For instance, in Norway, LMS's Canvas and Blackboard are only used for ungraded assessment tasks, while e-exam systems like WISEflow and Inspera Assessment are used for graded ones. Since the systems are mass-market software, vendors must satisfy the needs of several customers, and needs that are specific to only one or a few customers will receive low priority, perhaps forcing teachers to adapt their assessments to what the tool supports, rather than having the tool adapt to the preferred pedagogy. So far, there has been considerable research on views of students and teachers on e-exam systems, much less on the views of vendors and managers. In this paper, we investigate what these stakeholder groups consider to be the key features of e-exam systems, and by what process they are determined. An exploratory case study was conducted, based on interviews with 12 participants belonging to three different groups: vendors, process manager and system managers in Norwegian universities. Our findings indicate much agreement among these groups about key features of e-exam systems, though observing that not all functionality requested by end-users will be prioritized. Also, there was much agreement that a movement towards standardization, open interfaces and digital ecosystems would allow smoother integration with other information systems in the higher education sector, and easier addition of plug-ins for specific functionality -- but that there still is a way to go to reach the ambitions of a flexible ecosystem. Currently, vendors give more priority for adding functional features in e-exam systems rather than better interoperability, and integration with third-party tools remains a challenge. {$\bullet$}Describes the key features of two e-exam solutions that are widely being used in higher education institutions in Norway.{$\bullet$}Describes that the third-party national body procurement of e-exam systems is beneficial for institutions.{$\bullet$}Identifies enablers for vendors, process managers, and universities towards a more open digital ecosystem for e-exams.{$\bullet$}Shows that progress of interoperability between e-exam systems with supporting exam systems is not too impressive.{$\bullet$}Shows that the third-party tools access on BYOD laptops during supervised onsite lockdown e-exams is still in pilot stage.},
  keywords = {Case studies,Computer Science,Computer Science Interdisciplinary Applications,Computer software industry,Digital ecosystem,E-exam system,Ecosystems,Education,Education & Educational Research,Education parks,Environmental aspects,Features,Interoperability,Learning management systems,Norway,Requirements engineering process,School facilities,Science & Technology,Social Sciences,Technology},
  file = {/Users/colin.madland/Zotero/storage/ID329JZG/chirumamillaEexamsNorwegianHigher2021.pdf}
}

@article{choInternationalStudentsSelfdetermined2021,
  title = {International Students' Self-Determined Motivation, Beliefs about Classroom Assessment, Learning Strategies, and Academic Adjustment in Higher Education},
  author = {Cho, Hyun Jin and {Levesque-Bristol}, Chantal and Yough, Mike},
  year = {2021},
  journal = {Higher education},
  volume = {81},
  number = {6},
  pages = {1215--1235},
  publisher = {SPRINGER},
  address = {DORDRECHT},
  issn = {0018-1560},
  doi = {10/gmb8hq},
  abstract = {As an increasing number of international students are studying in English-speaking universities, there has been growing interest in exploring the factors and complexities that impact international students' academic achievement and adaptation during their studies. The present study aimed to investigate how international students adapt to new academic environments in US universities by exploring the relationships between self-determined motivation, beliefs about classroom assessments, the use of self-regulatory learning strategies, and academic performance based on self-determination theory. To examine international students' learning experiences, 321 international Asian undergraduate students at a large research-intensive midwestern university participated in an online survey. Structural equation modeling was conducted to test the proposed model. The findings demonstrated that self-determined motivation in courses led to adaptive beliefs about classroom assessments, which promoted a variety of self-regulatory learning strategies, including shallow and metacognitive strategies. Metacognitive learning strategies were significantly related to students' academic performance. This study allows us to better understand how Asian international students adapt to US academic environments through their motivation to learn, perspectives about classroom assessments, and learning strategies across different academic disciplines at the university level.},
  keywords = {Academic achievement,Classroom environment,College students,Education & Educational Research,Educational research,Learning strategies,Management,Methods,Motivation in education,Psychological aspects,Research,Social aspects,Social Sciences,Students Foreign}
}

@article{chongReconsideringStudentFeedback2021,
  title = {Reconsidering Student Feedback Literacy from an Ecological Perspective},
  author = {Chong, Sin Wang},
  year = {2021},
  month = jan,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {46},
  number = {1},
  pages = {92--104},
  issn = {0260-2938, 1469-297X},
  doi = {10/gjsfrx},
  urldate = {2021-04-23},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/WZQ5MNWS/chongReconsideringStudentFeedback2021.pdf}
}

@article{choRelationshipsBeliefsAssessment2020,
  title = {Relationships between Beliefs about Assessment and Self-Regulated Learning in Second Language Learning},
  author = {Cho, Hyun Jin and Yough, Mike and {Levesque-Bristol}, Chantal},
  year = {2020},
  journal = {International Journal of Educational Research},
  volume = {99},
  pages = {101505},
  issn = {08830355},
  doi = {10/gmct78},
  urldate = {2021-07-31},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/BHIWMBLE/choRelationshipsBeliefsAssessment2020.pdf}
}

@article{choudhuryAssessmentAnatomicalKnowledge2017,
  title = {Assessment of Anatomical Knowledge: {{Approaches}} Taken by Higher Education Institutions},
  author = {Choudhury, Bipasha and Freemont, Anthony},
  year = {2017},
  journal = {Clinical anatomy (New York, N.Y.)},
  volume = {30},
  number = {3},
  pages = {290--299},
  publisher = {Wiley},
  address = {HOBOKEN},
  issn = {0897-3806},
  doi = {10.1002/ca.22835},
  abstract = {Assessment serves the primary function of determining a student's competence in a subject. Several different assessment formats are available for assessing anatomical skills, knowledge and understanding and, as assessment can drive learning, a careful selection of assessments can help to engender the correct deep learning facility required of the safe clinical practitioner. The aim of this review was to survey the published literature to see whether higher education institutions are taking an andragogical approach to assessment. Five databases (EMBASE, ERIC, Medline, PubMed, and Web of Knowledge) were searched using standardized search terms with two limits applied (English language, and 2000 to the present). Among the 2,094 papers found, 32 were deemed suitable for this review. Current literature on assessment can be categorized into the following themes: assessment driven learning, types of assessments, frequency of assessments, and use of images in assessments. The consensus is to use a variety of methods, written and practical, to assess anatomical knowledge and skill in different domains. Institutions aim for different levels of Bloom's taxonomy for students at similar stages of their medical degree. Formative assessments are used widely, in differing formats, with mostly good effects on the final examination grade. In conclusion, a wide variety of assessments, each aimed at a different level of Bloom's taxonomy, are used by different institutions. Clin. Anat. 30:290--299, 2017. {\copyright} 2017 Wiley Periodicals, Inc.},
  keywords = {Analysis,anatomy,Anatomy - education,Anatomy & Morphology,assessment,Assessments,Education,Education parks,Educational Measurement,English language,Higher education,Higher education institutions,Humans,Institutions,learning,Life Sciences & Biomedicine,Literature reviews,Machine learning,School facilities,Schools Medical,Science & Technology,Students Medical,Taxonomy}
}

@article{choyStudentPerceptionsQuality2017,
  title = {Student's Perceptions of Quality Learning in a {{Malaysian}} University -- a Mixed Method Approach},
  author = {Choy, S. Chee and Yim, Joanne Sau-Ching and Tan, Poh Leong},
  year = {2017},
  journal = {Quality assurance in education},
  volume = {25},
  number = {4},
  pages = {500--515},
  publisher = {Emerald Publishing Limited},
  address = {Bradford},
  issn = {0968-4883},
  doi = {10/gkzfc7},
  abstract = {Purpose This paper aims to examine students' perceptions of quality learning using a mixed-methods approach in a Malaysian university, with an aim to fill existing knowledge gaps in the literature on relationships among relevant quality variables. The study also assesses the extent to which detailed results from a few participants can be generalised to a larger sample from the population. Design/methodology/approach A sequential, mixed-methods approach was used to obtain a more meaningful and balanced analysis of the data. In total, 12 students were purposively selected and interviewed in Phase 1, to gain insights into their perceptions of quality learning at a selected university. The results of the qualitative analysis were used to develop hypotheses for a quantitative survey of 1,490 students in Phase 2. The samples consisted of students enrolled in full-time bachelor's degree programmes. The survey data were analysed using structural equation modelling (SEM) to confirm a series of hypotheses about pathways of influence of key quality constructs. Findings The results of the study showed strong positive relationships between student perceptions of learning outcomes, curriculum, instructional delivery and support, learning environment and quality learning. The overall findings suggest that the influences of these quality variables on the perceived quality of learning experiences of students may be complex. Practical implications All Malaysian higher education providers are currently concerned with providing high-quality education that caters to students' needs. The results generate useful evidence for governors, administrators and other stakeholders regarding the students' perceptions of quality learning. The results provide insights for supporting diverse students served by these providers. Originality/value The sequential, mixed-methods research design of the study contributed a rich contextual description of students' perceptions of quality learning. It also fills the knowledge gap mentioned.;Purpose This paper aims to examine students' perceptions of quality learning using a mixed-methods approach in a Malaysian university, with an aim to fill existing knowledge gaps in the literature on relationships among relevant quality variables. The study also assesses the extent to which detailed results from a few participants can be generalised to a larger sample from the population. Design/methodology/approach A sequential, mixed-methods approach was used to obtain a more meaningful and balanced analysis of the data. In total, 12 students were purposively selected and interviewed in Phase 1, to gain insights into their perceptions of quality learning at a selected university. The results of the qualitative analysis were used to develop hypotheses for a quantitative survey of 1,490 students in Phase 2. The samples consisted of students enrolled in full-time bachelor's degree programmes. The survey data were analysed using structural equation modelling (SEM) to confirm a series of hypotheses about pathways of influence of key quality constructs. Findings The results of the study showed strong positive relationships between student perceptions of learning outcomes, curriculum, instructional delivery and support, learning environment and quality learning. The overall findings suggest that the influences of these quality variables on the perceived quality of learning experiences of students may be complex. Practical implications All Malaysian higher education providers are currently concerned with providing high-quality education that caters to students' needs. The results generate useful evidence for governors, administrators and other stakeholders regarding the students' perceptions of quality learning. The results provide insights for supporting diverse students served by these providers. Originality/value The sequential, mixed-methods research design of the study contributed a rich contextual description of students' perceptions of quality learning. It also fills the knowledge gap mentioned.;},
  keywords = {College Curriculum,College Environment,College Instruction,Curricula,Design,Educational Quality,Foreign Countries,Higher education,Humanities,Hypotheses,Interviews,Learning,Mixed Methods Research,Outcomes of Education,Perceptions,Quality control,Research methodology,School environment,Standards,Structural Equation Models,Student Attitudes,Student Surveys,Studies,Teaching methods,Undergraduate Students,University colleges}
}

@misc{christodoulouThisFutureAssessment2022,
  title = {Is This the Future of Assessment? {\textbar} {{Tes Magazine}}},
  shorttitle = {Is This the Future of Assessment?},
  author = {Christodoulou, Daisy},
  year = {2022},
  journal = {TES Magazine},
  urldate = {2022-12-15},
  abstract = {Calls for exams to be scrapped have grown louder in the wake of the Covid-19 pandemic. But rather than getting rid of exams, we may just need to reimagine them, says Daisy Christodoulou},
  howpublished = {https://www.tes.com/magazine/teaching-learning/secondary/future-of-assessment-onscreen-exams-no-grades-ai},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/XS3EMR2Y/future-of-assessment-onscreen-exams-no-grades-ai.html}
}

@article{christoforidouDevelopingTeacherAssessment2021,
  title = {Developing Teacher Assessment Skills: {{The}} Impact of the Dynamic Approach to Teacher Professional Development},
  author = {Christoforidou, Margarita and Kyriakides, Leonidas},
  year = {2021},
  journal = {Studies in Educational Evaluation},
  doi = {10/gkhq2r},
  abstract = {Abstract   This study investigates the extent to which the Dynamic Approach (DA) to Teacher Professional Development (TPD) can help teachers develop their assessment skills and through that contribute to the improvement of student learning outcomes. To achieve this aim, a multi-treatment group randomisation study was conducted to compare the impact of the DA with the impact of the Competency-Based Approach (CBA) on developing assessment skills and promoting student learning outcomes. Assessment skills of 178 teachers and achievement of their students (n = 2358) were measured before and after the intervention. The DA had greater impact on teacher assessment skills and student learning outcomes than the CBA. Differential effects were also identified since differences in the impact of each approach were only identified for teachers who were situated at higher stages of assessment skills. Implications of findings for research, policy and practice are drawn.}
}

@article{chughImplementingEducationalTechnology2023,
  title = {Implementing Educational Technology in {{Higher Education Institutions}}: {{A}} Review of Technologies, Stakeholder Perceptions, Frameworks and Metrics},
  author = {Chugh, Ritesh and Turnbull, Darren and Cowling, Michael A. and Vanderburg, Robert and Vanderburg, Michelle A.},
  year = {2023},
  month = may,
  journal = {Education and Information Technologies},
  issn = {1573-7608},
  doi = {10.1007/s10639-023-11846-x},
  abstract = {In a world driven by constant change and innovation, Higher Education Institutions (HEIs) are undergoing a rapid transformation, often driven by external factors such as emerging technologies. One of the key drivers affecting the design and development of educational delivery mechanisms in HEIs is the fast pace of educational technology development which not only impacts an institution's technical capacity to infuse hardware and software solutions into existing learning infrastructure but also has implications for pedagogical practice, stakeholder acceptance of new technology, and HEI administrative structures. However, little is known about the implementation of contemporary educational technology in HEI environments, particularly as they relate to competing stakeholder perceptions of technology effectiveness in course delivery and knowledge acquisition. This review fills that gap by exploring the evidence and analyses of 46 empirical research studies focussing on technology implementation issues in a diverse range of institutional contexts, subject areas, technologies, and stakeholder profiles. This study found that the dynamic interplay of educational technology characteristics, stakeholder perceptions on the effectiveness of technology integration decisions, theoretical frameworks and models relevant to technology integration in pedagogical practices, and metrics to gauge post-implementation success are critical dimensions to creating viable pathways to effective educational technology~implementation. To that end, this study proposes a framework to guide the development of sound implementation strategies that incorporates five dimensions: technology, stakeholder perceptions, academic discipline, success metrics, and theoretical frameworks. This study will benefit HEI decision-makers responsible for re-engineering complex course delivery systems to accommodate the infusion of new technologies and pedagogies in ways that will maximise their utility to students and faculty.},
  file = {/Users/colin.madland/Zotero/storage/I3RY9BT5/chughImplementingEducationalTechnology2023.pdf}
}

@article{chyungEvidenceBasedSurveyDesign2017,
  title = {Evidence-{{Based Survey Design}}: {{The Use}} of a {{Midpoint}} on the {{Likert Scale}}},
  shorttitle = {Evidence-{{Based Survey Design}}},
  author = {Chyung, Seung Youn Yonnie and Roberts, Katherine and Swanson, Ieva and Hankinson, Andrea},
  year = {2017},
  month = nov,
  journal = {Performance Improvement},
  volume = {56},
  number = {10},
  pages = {15--23},
  issn = {10908811},
  doi = {10.1002/pfi.21727},
  urldate = {2024-06-25},
  copyright = {http://doi.wiley.com/10.1002/tdm\_license\_1.1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/6NAKBLPI/chyungEvidenceBasedSurveyDesign2017.pdf;/Users/colin.madland/Zotero/storage/PB3YL6M8/147014152.pdf}
}

@article{cilli-turnerMasteryGradingBuildASyllabus2020,
  title = {Mastery {{Grading}}: {{Build-A-Syllabus Workshop}}},
  shorttitle = {Mastery {{Grading}}},
  author = {{Cilli-Turner}, Emily and Dunmyre, Justin and Mahoney, Thomas and Wiley, Chad},
  year = {2020},
  month = nov,
  journal = {PRIMUS},
  volume = {30},
  number = {8-10},
  pages = {952--978},
  issn = {1051-1970, 1935-4053},
  doi = {10/gh3xth},
  urldate = {2021-02-18},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/MP4C48ZZ/cilli-turnerMasteryGradingBuildASyllabus2020.pdf}
}

@article{cingilliogluDetectingAIgeneratedEssays2023,
  title = {Detecting {{AI-generated}} Essays: The~{{ChatGPT}} Challenge},
  author = {Cingillioglu, Ilker},
  year = {2023},
  month = jan,
  journal = {The International Journal of Information and Learning Technology},
  volume = {40},
  number = {3},
  pages = {259--268},
  publisher = {Emerald Publishing Limited},
  issn = {2056-4880},
  doi = {10.1108/IJILT-03-2023-0043},
  urldate = {2023-09-27},
  abstract = {Purpose With the advent of ChatGPT, a sophisticated generative artificial intelligence (AI) tool, maintaining academic integrity in all educational settings has recently become a challenge for educators. This paper discusses a method and necessary strategies to confront this challenge. Design/methodology/approach In this study, a language model was defined to achieve high accuracy in distinguishing ChatGPT-generated essays from human written essays with a particular focus on ``not falsely'' classifying genuinely human-written essays as AI-generated (Negative). Findings Via support vector machine (SVM) algorithm 100\% accuracy was recorded for identifying human generated essays. The author discussed the key use of Recall and F2 score for measuring classification performance and the importance of eliminating False Negatives and making sure that no actual human generated essays are incorrectly classified as AI generated. The results of the proposed model's classification algorithms were compared to those of AI-generated text detection software developed by OpenAI, GPTZero and Copyleaks. Practical implications AI-generated essays submitted by students can be detected by teachers and educational designers using the proposed language model and machine learning (ML) classifier at a high accuracy. Human (student)-generated essays can and must be correctly identified with 100\% accuracy even if the overall classification accuracy performance is slightly reduced. Originality/value This is the first and only study that used an n-gram bag-of-words (BOWs) discrepancy language model as input for a classifier to make such prediction and compared the classification results of other AI-generated text detection software in an empirical way.}
}

@book{clairehowellmajorTeachingOnlineGuide2015,
  title = {Teaching {{Online}} : {{A Guide}} to {{Theory}}, {{Research}}, and {{Practice}}},
  author = {{Claire Howell Major}},
  year = {2015},
  series = {Tech.Edu: A {{Hopkins Series}} on {{Education}} and {{Technology}}},
  publisher = {Johns Hopkins University Press},
  address = {Baltimore},
  abstract = {Demystifies online teaching for both enthusiastic and wary educators and helps faculty who teach online do their best work as digital instructors.It is difficult to imagine a college class today that does not include some online component---whether a simple posting of a syllabus to course management software, the use of social media for communication, or a full-blown course offering through a MOOC platform. In Teaching Online, Claire Howell Major describes for college faculty the changes that accompany use of such technologies and offers real-world strategies for surmounting digital teaching challenges.Teaching with these evolving media requires instructors to alter the ways in which they conceive of and do their work, according to Major. They must frequently update their knowledge of learning, teaching, and media, and they need to develop new forms of instruction, revise and reconceptualize classroom materials, and refresh their communication patterns. Faculty teaching online must also reconsider the student experience and determine what changes for students ultimately mean for their own work and for their institutions. Teaching Online presents instructors with a thoughtful synthesis of educational theory, research, and practice as well as a review of strategies for managing the instructional changes involved in teaching online. In addition, this book presents examples of best practices from successful online instructors as well as cutting-edge ideas from leading scholars and educational technologists. Faculty members, researchers, instructional designers, students, administrators, and policy makers who engage with online learning will find this book an invaluable resource.},
  isbn = {978-1-4214-1623-6},
  langid = {english},
  keywords = {EDUCATION / Computers & Technology,EDUCATION / Distance Open & Online Education,EDUCATION / Schools / Levels / Higher,Teaching--Methodology,Web-based instruction}
}

@book{clandininEngagingNarrativeInquiry2013,
  title = {Engaging in Narrative Inquiry},
  author = {Clandinin, D. Jean},
  year = {2013},
  series = {Developing Qualitative Inquiry},
  volume = {9},
  publisher = {Left Coast Press}
}

@article{clandininNarrativeInquiryMethodology2006,
  title = {Narrative {{Inquiry}}: {{A Methodology}} for {{Studying Lived Experience}}},
  author = {Clandinin, D. Jean},
  year = {2006},
  month = dec,
  journal = {Research Studies in Music Education},
  volume = {27},
  number = {1},
  pages = {44--54},
  issn = {1321-103X},
  doi = {10.1177/1321103X060270010301},
  urldate = {2019-02-09},
  abstract = {The paper briefly outlines the history and development of the methodology of narrative inquiry. It draws attention to the need for careful delineation of terms and assumptions. A Deweyan view of experience is central to narrative inquiry methodology and is used to frame a metaphorical three-dimensional narrative inquiry space. An illustration from a recent narrative inquiry into curriculum making is used to show what narrative inquirers do. Issues of social significance, purpose and ethics are also outlined.}
}

@article{clarke-miduraAssessmentTechnologyChange2010,
  title = {Assessment, {{Technology}}, and {{Change}}},
  author = {{Clarke-Midura}, Jody and Dede, Chris},
  year = {2010},
  month = mar,
  journal = {Journal of Research on Technology in Education},
  volume = {42},
  number = {3},
  pages = {309--328},
  issn = {1539-1523, 1945-0818},
  doi = {10/ghdnhh},
  urldate = {2021-01-04},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/DDCRY8UD/clarke-miduraAssessmentTechnologyChange2010.pdf}
}

@book{clarkElearningScienceInstruction2011,
  title = {E-Learning and the Science of Instruction: {{Proven}} Guidelines for Consumers and Designers of Multimedia Learning},
  author = {Clark, Ruth Colvin and Mayer, Richard E},
  year = {2011},
  edition = {3rd},
  publisher = {Pfeiffer},
  address = {San Francisco, CA}
}

@article{clarkeRefocusingPortfolioAssessment2018,
  title = {Refocusing Portfolio Assessment: {{Curating}} for Feedback and Portrayal},
  author = {Clarke, {\relax JL} and Boud, D},
  year = {2018},
  journal = {Innovations in Education and Teaching International},
  volume = {55},
  number = {4},
  pages = {479--486},
  issn = {1470-3297},
  doi = {10.1080/14703297.2016.1250664},
  abstract = {Portfolios are embraced extensively in higher professional education as effective tools for students to represent their learning and help prepare them for future practice. They are very diverse, used for both formative and summative purposes; however, concerns are raised that the current emphasis on academic standards and/or the focus on employability may lead to the perception of portfolios simply as means to portray achievements. This paper argues that contemporary portfolios in digital environments can readily facilitate both purposes. It conceptualises a whole-of-programme approach to the use of portfolios in which consideration is given to the need to bring curation skills and feedback processes to the forefront of portfolio practices. For teachers considering these issues, a planning framework for the design of programme-wide portfolios is proposed.},
  langid = {english},
  keywords = {curation for learning,EDUCATION,feedback,formative assessment,higher education,MODEL,portfolio assessment,Portfolios,professional education,STUDENT},
  file = {/Users/colin.madland/Zotero/storage/UF58HRGK/clarkeRefocusingPortfolioAssessment2018.pdf}
}

@misc{clarkgrayResistingSurveillanceTechnology2021,
  title = {Resisting {{Surveillance Technology}}},
  author = {Clark Gray, Brenna and Madland, Colin},
  year = {2021},
  month = jun,
  address = {Online},
  abstract = {Use of surveillance technologies has surged as a result of the COVID-19 pandemic. Please join us as we discuss local, regional, and systemic responses.},
  copyright = {All rights reserved}
}

@article{clarkMediaInstruction601982,
  title = {Media in {{Instruction}}: 60 {{Years}} of {{Research}} [{{Book Review}}]},
  author = {Clark, Richard E.},
  editor = {Wilkinson, Gene L.},
  year = {1982},
  journal = {Educational Communication and Technology},
  volume = {30},
  number = {1},
  pages = {60--60},
  issn = {01485806}
}

@article{clarkMediaWillNever1994,
  title = {Media Will Never Influence Learning},
  author = {Clark, Richard E.},
  year = {1994},
  month = jun,
  journal = {Educational Technology Research and Development},
  volume = {42},
  number = {2},
  pages = {21--29},
  issn = {1042-1629, 1556-6501},
  doi = {10.1007/BF02299088},
  urldate = {2023-08-05},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/E7ECEKY9/clarkMediaWillNever1994.pdf}
}

@book{clarkMixedMethodsResearch2016,
  title = {Mixed {{Methods Research}}: {{A Guide}} to the {{Field}}},
  shorttitle = {Mixed {{Methods Research}}},
  author = {Clark, Vicki L. Plano and Ivankova, Nataliya V.},
  year = {2016},
  publisher = {SAGE Publications, Inc.},
  address = {2455 Teller Road,~Thousand Oaks~California~91320},
  urldate = {2021-05-14},
  isbn = {978-1-4833-0675-9 978-1-4833-9834-1},
  annotation = {https://dx-doi-org.ezproxy.library.uvic.ca/10.4135/9781483398341}
}

@incollection{clarkNewVisionPublic2011,
  title = {A {{New Vision}} for {{Public Media}}},
  booktitle = {Media and {{Social Justice}}},
  author = {Clark, Jessica and Aufderheide, Patricia},
  editor = {Jansen, Sue Curry and Pooley, Jefferson and {Taub-Pervizpour}, Lora},
  year = {2011},
  pages = {55--67},
  publisher = {Palgrave Macmillan US},
  address = {New York},
  doi = {10.1057/9780230119796_5},
  urldate = {2021-12-23},
  isbn = {978-1-349-29139-7 978-0-230-11979-6},
  langid = {english}
}

@article{clarkReconsideringResearchLearning1983,
  title = {Reconsidering {{Research}} on {{Learning}} from {{Media}}},
  author = {Clark, Richard E.},
  year = {1983},
  journal = {Review of Educational Research},
  volume = {53},
  number = {4},
  pages = {445--459},
  issn = {00346543, 19351046},
  doi = {10.2307/1170217},
  abstract = {Recent meta-analyses and other studies of media's influence on learning are reviewed. Consistent evidence is found for the generalization that there are no learning benefits to be gained from employing any specific medium to deliver instruction. Research showing performance or time-saving gains from one or another medium are shown to be vulnerable to compelling rival hypotheses concerning the uncontrolled effects of instructional method and novelty. Problems with current media attribute and symbol system theories are described and suggestions made for more promising research directions.},
  file = {/Users/colin.madland/Zotero/storage/UDXGSQVX/clarkReconsideringResearchLearning1983.pdf}
}

@article{clarkSupportiveClassroomAssessment2020,
  title = {Supportive {{Classroom Assessment}} for {{Remote Instruction}}},
  author = {Clark, Renee M. and {Besterfield-Sacre}, Mary and Dukes, April},
  year = {2020},
  month = sep,
  journal = {Advances in Engineering Education},
  volume = {8},
  number = {4},
  publisher = {Advances in Engineering Education},
  issn = {1941-1766},
  abstract = {During the summer 2020, when remote instruction became the norm for universities due to COVID-19, expectations were set at our school of engineering for interactivity and activity within synchronous sessions and for using technology for engaging asynchronous learning opportunities. Instructors were asked to participate in voluntary assessment of their instructional techniques, and this "supportive" assessment was intended to enable growth in remote teaching as well as demonstrate excellence in the School's instruction. Preliminary results demonstrated what is possible with voluntary assessment with a "support" focus -- namely instructor willingness to participate and encouragement in the use of desirable teaching practices.},
  keywords = {Asynchronous Communication,College Faculty,COVID-19,Distance Education,Engineering Education,Instructional Effectiveness,No DOI found,Pandemics,Pennsylvania (Pittsburgh),Synchronous Communication,Teacher Evaluation,Teaching Methods,Web Based Instruction}
}

@article{clarkSupportiveClassroomAssessment2020b,
  title = {Supportive {{Classroom Assessment}} for {{Remote Instruction}}},
  author = {Clark, Renee M and {Besterfield-Sacre}, Mary},
  year = {2020},
  volume = {8},
  number = {4},
  abstract = {During the summer 2020, when remote instruction became the norm for universities due to COVID-19, expectations were set at our school of engineering for interactivity and activity within synchronous sessions and for using technology for engaging asynchronous learning opportunities. Instructors were asked to participate in voluntary assessment of their instructional techniques, and this ``supportive'' assessment was intended to enable growth in remote teaching as well as demonstrate excellence in the School's instruction. Preliminary results demonstrated what is possible with voluntary assessment with a ``support'' focus -- namely instructor willingness to participate and encouragement in the use of desirable teaching practices.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/9YLISC66/clarkSupportiveClassroomAssessment2020a.pdf}
}

@misc{clarkTwitterRuiningOpen2021,
  title = {Twitter Is Ruining the Open for a Surprise Meme with Better Image Crops},
  author = {Clark, Mitchell},
  year = {2021},
  month = may,
  journal = {The Verge},
  urldate = {2022-10-24},
  abstract = {``Open for a surprise'' memes are quaking.},
  howpublished = {https://www.theverge.com/2021/5/5/22421574/twitter-crop-issue-bigger-images-rollout},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/FR34LRDX/twitter-crop-issue-bigger-images-rollout.html}
}

@article{clarkWhenResearchersSwim1991,
  title = {When {{Researchers Swim Upstream}}: {{Reflections}} on an {{Unpopular Argument About Learning}} from {{Media}}},
  author = {Clark, Richard E.},
  year = {1991},
  journal = {Educational Technology},
  volume = {31},
  number = {2},
  pages = {34--40},
  issn = {00131962},
  file = {/Users/colin.madland/Zotero/storage/EZCYRKUZ/clarkWhenResearchersSwim1991.pdf}
}

@misc{ClassroomTechnologiesFirst,
  title = {Classroom {{Technologies}} and {{First Peoples Principles}} of {{Learning}} {\textbar} {{SET-BC}}},
  urldate = {2018-10-30},
  langid = {canadian},
  keywords = {indigenous,ways of knowing},
  file = {/Users/colin.madland/Zotero/storage/QE7CP99Y/classroom-technologies-and-first-peoples-principles-of-learning.html}
}

@article{cleveland-innesSocialAcademicInteraction2005,
  title = {Social and Academic Interaction in Higher Education Contexts and the Effect on Deep Learning},
  shorttitle = {Social and Academic Interaction in Higher Education Contexts and the Effect on Deep Learning},
  author = {{Cleveland-Innes}, Martha and Emes, Claudia},
  year = {2005},
  journal = {NASPA Journal},
  volume = {42},
  pages = {241--262},
  annotation = {2}
}

@article{clevelandUsingDigitalPortfolios2018,
  title = {Using {{Digital Portfolios}}: {{Reflection}}, {{Assessment}} \& {{Employment}}},
  author = {Cleveland, {\relax RE}},
  year = {2018},
  journal = {TechTrends},
  volume = {62},
  number = {3},
  pages = {276--285},
  issn = {8756-3894},
  doi = {10.1007/s11528-018-0262-0},
  abstract = {Many programs utilize digital portfolios for students to archive assignments. This manuscript highlights how one counselor education program implemented digital portfolios as a means for fostering student reflection, and subsequently evolved the portfolios towards satisfying both comprehensive exam and student employment goals. The author introduced a digital portfolio component to a core curriculum course in hopes of fostering students' reflection. Simultaneously, counselor education program faculty were addressing inadequacies of norm-referenced testing employed for students' comprehensive exam. Together faculty pursued building assessment components within the reflection blogs, utilizing the platform as digital portfolios. This effort was aimed at meeting three goals: (1) fostering student reflection; (2) satisfying program comprehensive exam/assessment requirements; and (3) serving as a professional website for students' post-program employment searches/interviews. Students receiving formative feedback on their digital reflections demonstrated significantly higher mean reflection scores than students only utilizing portfolios as a "digital journal". This manuscript presents an overview of the initiative in its first year of implementation, resources and obstacles experienced, and preliminary findings from data collected. Technology platform information and student work samples are highlighted.},
  langid = {english},
  keywords = {Assessment,Counselor education,Digital portfolios,MEDICAL-STUDENTS,Reflection}
}

@article{cliffeReviewBenefitsDrawbacks2017,
  title = {A Review of the Benefits and Drawbacks to Virtual Field Guides in Today's {{Geoscience}} Higher Education Environment},
  author = {Cliffe, Anthony David},
  year = {2017},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {14},
  number = {1},
  pages = {1--14},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-017-0066-x},
  abstract = {Virtual Field Guides are a way for educators to tackle the growing issue of funding pressures in areas of higher education, such as geography. Virtual Field Guides are however underutilised and can offer students a different way of learning. Virtual Field Guides have many benefits to students, such as being more inclusive, building student skills and confidence in a controlled environment pre fieldtrip and can increase engagement in the topic studied. There are also benefits to the educator, such as reduced cost, more efficient students on fieldwork tasks and the ability to tailor and update their field guides to suit their needs. However there are drawbacks in the challenge of creation and their outcome as educational standalone tools. This paper reviews the literature around the benefits and draw backs to the creation and incorporation of virtual field guides in geoscience education.},
  keywords = {Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Earth science,Education,Educational Technology,Field study,Fieldwork,Geography,Geoscience,Higher Education,Humanities,Information Systems Applications (incl.Internet),Law,Review,Review Article,Statistics for Social Sciences,Students,Technology,Virtual environments,Virtual field guides},
  file = {/Users/colin.madland/Zotero/storage/JJ2MX7ZF/cliffeReviewBenefitsDrawbacks2017.pdf}
}

@article{Clifton_2010,
  title = {Assessing the Quality of Multiple Choice Test Items},
  author = {Clifton, Sandra L. and Schriner, Cheryl L.},
  year = {2010},
  journal = {Nurse Educator},
  doi = {10/fsmmnh},
  abstract = {With the focus of nursing education geared toward teaching students to think critically, faculty need to assure that test items require students to use a high level of cognitive processing. To evaluate their examinations, the authors assessed multiple-choice test items on final nursing examinations. The assessment included determining cognitive learning levels and frequency of items among 3 adult health courses, comparing difficulty values with cognitive learning levels, and examining discrimination values and the relationship to distracter performance.},
  mag_id = {2000989929},
  pmcid = {null},
  pmid = {20010262}
}

@article{coatesAssessingStudentLearning2016,
  title = {Assessing {{Student Learning Outcomes Internationally}}: {{Insights}} and {{Frontiers}}},
  author = {Coates, Hamish},
  year = {2016},
  month = jan,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {41},
  number = {5},
  pages = {662--676},
  publisher = {Assessment \& Evaluation in Higher Education},
  issn = {0260-2938},
  doi = {10.1080/02602938.2016.1160273},
  abstract = {As higher education systems and institutions expand, more energy is being invested in ensuring that sufficient learning has been achieved to warrant the award of a qualification. Many commonly used assessment approaches do not scale well, and there remains a pressing need for reform. This paper distils insights from international investigations of student learning outcomes assessment, using this analysis to chart frontiers for innovation. This paper sets out principles for guiding change in this field, presents an evaluation of progress via a review of signature assessment initiatives, reviews likely facilitators and blockers and, through these analyses, derives a strategy for spurring development.},
  keywords = {Academic Achievement,Australia,Colleges,Educational Change,Educational Improvement,Evaluation,Foreign Countries,Higher Education,Outcomes of Education,Teaching Methods,Technological Advancement,Technology Uses in Education}
}

@article{coghlanGoodProctorBig2021,
  title = {Good {{Proctor}} or ``{{Big Brother}}''? {{Ethics}} of {{Online Exam Supervision Technologies}}},
  shorttitle = {Good {{Proctor}} or ``{{Big Brother}}''?},
  author = {Coghlan, Simon and Miller, Tim and Paterson, Jeannie},
  year = {2021},
  month = aug,
  journal = {Philosophy \& Technology},
  issn = {2210-5433, 2210-5441},
  doi = {10.1007/s13347-021-00476-1},
  urldate = {2021-10-21},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/KEVHMDPC/coghlanGoodProctorBig2021.pdf}
}

@article{cohenDevelopmentOnlineLearning2020,
  title = {The {{Development}} of {{Online Learning}} in {{Israeli Higher Education}}},
  author = {Cohen, Erez and Davidovitch, Nitza},
  year = {2020},
  journal = {Journal of Education and Learning},
  volume = {9},
  number = {5},
  pages = {15--26},
  issn = {ISSN-1927-5250},
  doi = {10/gmbvx7},
  abstract = {The COVID-19 pandemic that swept through the world in 2020 and forced the various higher education institutions in Israel and around the world to promptly embrace the online teaching method, placed on the agenda the question of this method's efficacy as well as deliberations regarding its future implications. The current study reviews the development of online teaching in Israel's higher education and examines whether this development derives from an organized and well-formulated public policy with a view to the future or is the result of the constraints and various actors within the free market. In addition, the study presents a case study of an academic institution, examining the opinions of students with regard to the benefits and shortcomings of online teaching. The research findings indicate that the development of online teaching in Israel is the result of needs, constraints, and opportunities that emerged in the free market rather than a result of organized public policy by the Ministry of Education and the Council for Higher Education. Consequently, the study presents the various implications of these unregulated developments for the quality of teaching and for student satisfaction. The study illuminates a thorough discussion that should be conducted by movers of higher education and academic institutions concerning a new effective designation of the campuses following the COVID-19 crisis as well as the distinction between virtual and real-life dimensions of academic teaching.},
  langid = {english},
  keywords = {College Students,COVID-19,Distance Education,Educational History,Educational Policy,Electronic Learning,Foreign Countries,Higher Education,Instructional Development,Instructional Effectiveness,Online Courses,Pandemics,Public Policy,Student Attitudes,Student Satisfaction,Web Based Instruction}
}

@article{cohenOnlineQuizzesVirtual2016,
  title = {Online {{Quizzes}} in a {{Virtual Learning Environment}} as a {{Tool}} for {{Formative Assessment}}},
  author = {Cohen, Donita and Sasson, Irit},
  year = {2016},
  month = jan,
  journal = {Journal of Technology and Science Education},
  volume = {6},
  number = {3},
  pages = {188--208},
  publisher = {{Journal of Technology and Science Education}},
  issn = {2014-5349},
  abstract = {Assessment in education employing web tools, also known as e-assessment, deals with the effective use of technology to support successful instruction. The aim of this study was to investigate learning outcomes and the students' attitudes to online Moodle quizzes in order to improve instructional design. The research population included 204 college students enrolled in life sciences who were participating in an introductory physics course. A blended learning model was used, based on large, traditional face-to-face lectures, practice sessions held with smaller groups of about 25 students and a rich Moodle learning environment. The students' knowledge and understanding were assessed weekly throughout the semester, using two different methods: three ordinary short written tests and online quizzes in the Moodle environment. The students' attitudes towards the online quizzes as compared to the written tests were investigated by questionnaire. Results indicate that both the average grade on written tests and the average grade on online quizzes were found to be significant predictors of the grade on the final exam. Students significantly improved their scores and greatly shortened their performance time on the last attempts of the online quiz, as compared to their first attempts. The investigation into the students' attitudes towards online quizzes reveals a generally positive attitude. Learning outcomes and the students' attitudes to online Moodle quizzes were considered to improve instructional design, which demonstrates formative assessment in higher education.},
  keywords = {Blended Learning,College Science,Computer Assisted Testing,Foreign Countries,Formative Evaluation,Higher Education,Integrated Learning Systems,Israel,No DOI found,Outcomes of Education,Physics,Science Instruction,Statistical Analysis,Technology Integration,Technology Uses in Education,Virtual Classrooms}
}

@incollection{colaizzip.f.PsychologicalResearchPhenomenologist1978,
  title = {Psychological Research as the Phenomenologist Views It},
  booktitle = {Existential-Phenomenological Alternatives for Psychology},
  author = {Colaizzi, P. F.},
  editor = {Valle, R. and Kings, M.},
  year = {1978},
  pages = {48--71},
  publisher = {Oxford University Press},
  address = {New York}
}

@inproceedings{colbeckFacultyMotivationUse2002,
  title = {Faculty {{Motivation To Use Alternative Teaching Methods}}},
  booktitle = {Annual {{Meeting}} of the {{American Educational Research Association}}},
  author = {Colbeck, Carol L and Cabrera, Alberto F and Marine, Robert J},
  year = {2002},
  month = apr,
  publisher = {American Educational Research Association},
  address = {New Orleans, LA},
  urldate = {2021-06-18},
  abstract = {Motivational Systems Theory (MST; M. Ford, 1992) was used as a framework to investigate how varying motivational patterns influence faculty members use of teaching practices in their undergraduate classes. Researchers compared the factors associated with faculty members assigning students to work in groups to solve ill-defined design problems with their use of traditional lecture and textbook problem set assignments. The study hypothesized that faculty members use of teaching practices is a function of their backgrounds, training, experiences, teaching goals, beliefs in their own skills, and their perceptions of the extent to which their organizations provide adequate rewards and resources for teaching. The total sample for the analysis, 426, represented 61\% of the population of tenured and tenure-track engineering faculty at 3 universities. Participants completed a seven-section instrument that gathered information about teaching practices and beliefs. Findings indicate that faculty members own goals for teaching and beliefs about their own professional skills are strongly associated with the extent to which they use traditional teaching practices or group design projects. (Contains 1 figure, 6 tables, and 29 references.) (SLD)}
}

@article{colburnPreparedPractitionerAssessment2009,
  title = {The {{Prepared Practitioner}}: {{An Assessment Primer}}},
  author = {Colburn, Alan},
  year = {2009},
  journal = {The Science Teacher},
  volume = {76},
  number = {4},
  pages = {10--10},
  publisher = {National Science Teachers Association},
  issn = {00368555, 19434871},
  urldate = {2022-10-16},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/WM77LC69/colburnPreparedPractitionerAssessment2009.pdf}
}

@article{coleOverlookedNotUnimportant2015,
  title = {Overlooked but {{Not Unimportant}}: {{Changes}} in the {{University Landscape}} and {{Assessment Results}}},
  author = {Cole, Alexandra},
  year = {2015},
  journal = {Journal of Assessment and Institutional Effectiveness},
  volume = {5},
  number = {2},
  pages = {131--147},
  publisher = {Penn State University Press},
  issn = {21606765, 21606757},
  doi = {10.5325/jasseinsteffe.5.2.0131},
  urldate = {2023-05-10},
  abstract = {[Much is made about the various challenges of assessment but little is made about the changing landscape of the American university system and whether such changes have made their way into assessment results. A case study based upon assessment work undertaken over a ten-year period is used to illustrate how outside factors may influence assessment results but may not be caught in regular assessment processes. Based upon the lessons of this case study, we suggest that assessment should not only present student-learning outcomes, but seek to interpret student learning outcomes in the context of educational change over time.]},
  file = {/Users/colin.madland/Zotero/storage/WTHFI9KA/coleOverlookedNotUnimportant2015.pdf}
}

@misc{colinmadland@colinmadlandFacultyMemberHas2020,
  type = {Tweet},
  title = {A Faculty Member Has Been Asking How to Stop {{Zoom}} from Removing His Head When He Uses a Virtual Background. {{We}} Suggested the Usual Plain Background, Good Lighting Etc, but It Didn't Work. {{I}} Was in a Meeting with Him Today When {{I}} Realized Why It Was Happening.},
  author = {Madland, Colin [@colinmadland]},
  year = {2020},
  month = sep,
  journal = {Twitter},
  urldate = {2022-10-17},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/RR3UKRTE/1307111816250748933.html}
}

@misc{colinmadland@colinmadlandGeezAnyGuesses2020,
  type = {Tweet},
  title = {Geez...Any Guesses Why @{{Twitter}} Defaulted to Show Only the Right Side of the Picture on Mobile? {{https://t.co/UYL7N3XG9k}}},
  author = {Madland, Colin [@colinmadland]},
  year = {2020},
  month = sep,
  journal = {Twitter},
  urldate = {2022-10-17},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/2PC9EM2B/1307115534383710208.html}
}

@article{collinsEcologyEthicsParticipatory2004,
  title = {Ecology and Ethics in Participatory Collaborative Action Research: An Argument for the Authentic Participation of Students in Eduational Research},
  author = {Collins, Steve},
  year = {2004},
  month = sep,
  journal = {Educational Action Research},
  volume = {12},
  number = {3},
  pages = {347--362},
  issn = {0965-0792},
  doi = {10.1080/09650790400200255},
  abstract = {Abstract A conception of action research is offered that is collaborative, participatory, targets ethical issues and includes students. Collaboration is ?organic? in that all members share the goal of the research and are interdependent in pursuing that goal. Participation is authentic, requiring a continuing negotiation of planning, roles, power differences and language. An ecological approach to ethics is examined in which the research community is regarded as an interconnected, interdependent, holistic system of language, relationships and ideas. A rationale for the authentic participation of studentsin research is offered based on ethical requirements, improved research benefits and professional enhancement.},
  file = {/Users/colin.madland/Zotero/storage/R8T6LAEH/collinsEcologyEthicsParticipatory2004.pdf}
}

@article{coltmanFormativeReflectiveMeasurement2008,
  title = {Formative versus Reflective Measurement Models: {{Two}} Applications of Formative Measurement},
  author = {Coltman, Tim and Devinney, Timothy M. and Midgley, David F. and Venaik, Sunil},
  year = {2008},
  month = dec,
  journal = {Formative Indicators},
  volume = {61},
  number = {12},
  pages = {1250--1262},
  issn = {0148-2963},
  doi = {10.1016/j.jbusres.2008.01.013},
  abstract = {This paper presents a framework that helps researchers to design and validate both formative and reflective measurement models. The framework draws from the existing literature and includes both theoretical and empirical considerations. Two important examples, one from international business and one from marketing, illustrate the use of the framework. Both examples concern constructs that are fundamental to theory-building in these disciplines, and constructs that most scholars measure reflectively. In contrast, applying the framework suggests that a formative measurement model may be more appropriate. These results reinforce the need for all researchers to justify, both theoretically and empirically, their choice of measurement model. Use of an incorrect measurement model undermines the content validity of constructs, misrepresents the structural relationships between them, and ultimately lowers the usefulness of management theories for business researchers and practitioners. The main contribution of this paper is to question the unthinking assumption of reflective measurement seen in much of the business literature.},
  keywords = {Formative,Integration-responsiveness,International business,Market orientation,Marketing,Reflective},
  file = {/Users/colin.madland/Zotero/storage/KVVSAA56/coltmanFormativeReflectiveMeasurement2008.pdf}
}

@article{combrinckComputerassistedAssessmentOld2020,
  title = {Computer-Assisted Assessment: {{An}} Old Remedy for Challenges in Open Distance Learning},
  author = {Combrinck, M and {\noopsort{vollenhoven}}{van Vollenhoven}, {\relax WJ}},
  year = {2020},
  journal = {Independent Journal of Teaching and Learning},
  volume = {15},
  number = {1},
  pages = {22--34},
  issn = {1818-9687},
  abstract = {The article reports on the experiences of lecturers on the implementation of computer-assisted assessment in an open distance learning context. Open distance learning is growing rapidly worldwide. The North-West University and Unit for Open Distance Learning are no different and the institution has a large component of open distance learning students. The aim of the research was to reflect on the experiences of lecturers with regard to the use of computer-assisted assessment. The Technology Acceptance Model and ADKAR model were used as conceptual frameworks. This study adopted a qualitative approach: interviews were conducted with 26 lecturers during 2015 and 2016. The data showed that computer-assisted assessment (multiple-choice questions) have certain challenges, but can also contribute to a more effective open distance learning assessment strategy. Recommendations were formulated according to findings. The article concludes that computer-assisted assessment has a place in an open distance learning context.},
  langid = {english},
  keywords = {computer-assisted assessment,formative assessment,FORMATIVE ASSESSMENT,HIGHER-EDUCATION,multiple choice questions,No DOI found,open distance learning,qualitative research,summative assessment},
  file = {/Users/colin.madland/Zotero/storage/HMF6LW59/combrinckComputerassistedAssessmentOld2020.pdf}
}

@book{committeeonhowpeoplelearnii:thescienceandpracticeoflearningHowPeopleLearn2018,
  title = {How {{People Learn II}}: {{Learners}}, {{Contexts}}, and {{Cultures}}},
  shorttitle = {How {{People Learn II}}},
  author = {{Committee on How People Learn II: The Science and Practice of Learning} and {Board on Behavioral, Cognitive, and Sensory Sciences} and {Board on Science Education} and {Division of Behavioral and Social Sciences and Education} and {National Academies of Sciences, Engineering, and Medicine}},
  year = {2018},
  month = sep,
  publisher = {National Academies Press},
  address = {Washington, D.C.},
  doi = {10.17226/24783},
  urldate = {2020-05-14},
  isbn = {978-0-309-45964-8}
}

@article{ComputersEducationOnline1976,
  title = {Computers \& Education ({{Online}})},
  year = {1976},
  journal = {Computers \& education (Online)},
  publisher = {Elsevier Science},
  address = {Exeter},
  issn = {1873-782X},
  keywords = {Education -- Data processing,Electronic journals,Periodicals}
}

@article{ComputersHumanBehavior1985,
  title = {Computers in Human Behavior ({{Online}})},
  year = {1985},
  journal = {Computers in human behavior (Online)},
  publisher = {Elsevier Science},
  address = {New York},
  issn = {0747-5632},
  keywords = {Computers -- Psychological aspects,Electronic journals,Periodicals,Psychology -- Data processing}
}

@book{condonFacultyDevelopmentStudent2016,
  title = {Faculty {{Development}} and {{Student Learning}} : {{Assessing}} the {{Connections}}},
  author = {Condon, William and Haswell, Richard and Iverson, Ellen R. and Manduca, Cathryn A. and Rutz, Carol and Willett, Gudrun and Huber, Mary Taylor and Haswell, Richard and Huber, Mary Taylor},
  year = {2016},
  publisher = {Indiana University Press},
  address = {Bloomington, UNITED STATES},
  isbn = {978-0-253-01886-1},
  keywords = {College teachers - In-service training}
}

@book{conoleDesigningLearningOpen2013,
  title = {Designing for Learning in an Open World},
  author = {Conole, Gr{\'a}inne},
  year = {2013},
  series = {Explorations in the Learning Sciences, Instructional Systems and Performance Technologies},
  number = {v. 4},
  publisher = {Springer},
  address = {New York ; Heidelberg},
  isbn = {978-1-4419-8516-3},
  lccn = {LB1028.38 .C655 2013},
  keywords = {Administration,Design,Educational innovations,Educational technology,Instructional systems,Internet in higher education},
  annotation = {OCLC: ocn731915958}
}

@book{conradAssessmentStrategiesOnline2018,
  ids = {conradAssessmentStrategiesOnline2018a},
  title = {Assessment {{Strategies}} for {{Online Learning}}: {{Engagement}} and {{Authenticity}}},
  shorttitle = {Assessment {{Strategies}} for {{Online Learning}}},
  author = {Conrad, Dianne and Openo, Jason},
  year = {2018},
  month = jun,
  publisher = {Athabasca University Press},
  doi = {10.15215/aupress/9781771992329.01},
  urldate = {2019-07-09},
  isbn = {978-1-77199-233-6},
  keywords = {21st century c 2000 to c 2100,blended learning,cheating,constructivism,Distance education - Evaluation,Distance education students,e-portfolios,Education,Educational tests and measurements,English,For adult education,group work,LMS,MOOC,moodle,moodle LMS MOOC cheating constructivism e-portfolios group work open education blended learning,open education,World},
  file = {/Users/colin.madland/Zotero/storage/5U4Z69TU/conradAssessmentStrategiesOnline2018.pdf}
}

@article{conradEducationSocialInnovation2015,
  title = {Education and {{Social Innovation}}: {{The Youth Uncensored Project}}---{{A Case Study}} of {{Youth Participatory Research}} and {{Cultural Democracy}} in {{Action}}},
  author = {Conrad, Diane},
  year = {2015},
  journal = {Canadian Journal of Education / Revue canadienne de l'{\'e}ducation},
  volume = {38},
  number = {1},
  pages = {1--25},
  issn = {03802361, 19185979},
  abstract = {[Abstract This article discusses social innovation in education informed by arts-based and Indigenous ways of knowing. I use the term Indigenous to refer to First Peoples' and their wisdom traditions from places around the world and the term Aboriginal to refer to the diverse First Nations, M{\'e}tis, and Inuit peoples of Canada. The article looks at the ethical imperative for doing socially innovative work, and examines practices with potential for embedding social innovation in educational scholarship, including experiential and relational educational approaches, such as community-service learning and restorative justice; participatory action research as an allied research approach; and community arts framed as cultural democracy. It describes a research project with street-involved youth as a case study for research that moves toward social innovation through the Government of Canada Policy Research Initiative's five steps involved in a co-creative social innovation project.]}
}

@misc{contactnorthHowOnlineLearning2014,
  title = {How Online Learning Can Help Address the Talent and Skills Challenge for the New Economy},
  author = {{Contact North}},
  year = {2014},
  month = mar,
  journal = {Contact North},
  urldate = {2014-04-26},
  abstract = {As Premier Kathleen Wynne's call to action and the invitation to the March 18, 2014 Summit on Talent and Skills in the New Economy points out, Ontario, like all other jurisdictions in Canada, faces a major skills challenge now and for the foreseeable future.   A knowledge economy demands more skilled and highly qualified people at a time when many of those seeking work do not have the skills employers are looking for.  We need to a look at innovative approaches to building and sustaining a highly qualified workforce in Ontario.  One of the innovative (and cost-effective) ways to do this is through the systematic use of online learning, an area where Ontario is a recognized leader in Canada.},
  howpublished = {http://contactnorth.ca/trends-directions/how-online-learning-can-help-address-talent-and-skills-challenge-new-economy}
}

@article{contreras-higueraUniversityStudentsPerceptions2016,
  ids = {contreras-higueraUniversityStudentsPerceptions2016a,contreras-higueraUniversityStudentsPerceptions2016b},
  title = {University {{Students}}' {{Perceptions}} of {{E-Portfolios}} and {{Rubrics}} as {{Combined Assessment Tools}} in {{Education Courses}}},
  author = {{Contreras-Higuera}, Williams E. and {Mart{\'i}nez-Olmo}, Francesc and {Jos{\'e} Rubio-Hurtado}, M. and {Vil{\`a}-Ba{\~n}os}, Ruth},
  year = {2016},
  journal = {Journal of educational computing research},
  volume = {54},
  number = {1},
  pages = {85--107},
  publisher = {SAGE Publications},
  address = {Los Angeles, CA},
  issn = {0735-6331},
  doi = {10.1177/0735633115612784},
  abstract = {This article presents a study with a twofold research aim: (a) to ascertain university students' perceptions on two combined assessment tools (e-portfolios and formative rubrics) and (b) to identify if among students there were differing perceptions on the use of e-portfolios, and what factors favored acceptance of these. The data gathering method was a questionnaire administered to 247 students on the Education Degree at the University of Barcelona. Regarding our first aim, it was confirmed that although the portfolio and rubrics were used in combination, students viewed each of them independently. Regarding the second aim, we identified four groups and a range of factors that may explain the varying perceptions of the portfolios and rubrics. Favorable factors were, in first place, greater teacher experience in using the digital portfolios; second, continuous technical support for their use; third, their having greater weight in assessment; and fourth, smaller class sizes.},
  keywords = {Acceptance tests,Assessments,Avaluacio dels estudiants,Class Size,College Students,Educacio superior,Education,Education & Educational Research,education courses,Education Majors,evaluation methodologies,Evaluation Methods,Foreign Countries,Higher education,Internet,pedagogical issues,Perception,PERFORMANCE,Portfolios (Background Materials),postsecondary education,Questionnaires,Rating of students,Rubriques d'avaluacio,Scoring Rubrics,Social Sciences,Spain (Barcelona),Statistical Analysis,strategies,Student Attitudes,Student Evaluation,Students,Teachers,Teaching Experience,teaching/learning,Technical services,Technical Support,Universities},
  file = {/Users/colin.madland/Zotero/storage/X9ILKXEJ/contreras-higueraUniversityStudentsPerceptions2016.pdf}
}

@article{cookActiveLearningOnline2017,
  title = {Active {{Learning}} through {{Online Quizzes}}: {{Better Learning}} and {{Less}} ({{Busy}}) {{Work}}},
  author = {Cook, Brian Robert and Babon, Andrea},
  year = {2017},
  month = jan,
  journal = {Journal of Geography in Higher Education},
  volume = {41},
  number = {1},
  pages = {24--38},
  publisher = {Journal of Geography in Higher Education},
  issn = {0309-8265},
  doi = {10.1080/03098265.2016.1185772},
  abstract = {Active learning is increasingly promoted within institutions of higher education to assist students develop higher order thinking and link knowledge to meaning. In this paper, the authors evaluate the use of weekly online quizzes based on prescribed preparatory material as a tool to incentivize preparatory reading in order to enable and encourage active learning. The study is based on mixed data sources, including three years of student-evaluation data, to understand student perceptions of the role and value of online quizzes. The study shows a high level of student engagement with the quizzes and positive assessment of their role in encouraging the completion of prescribed reading. Online quizzes were found to be an effective mechanism for incentivizing student completion of preparatory work, enhancing active learning (such as through in-class discussions), and were relatively time efficient from the perspective of the educator.},
  keywords = {Active Learning,Australia,College Students,Computer Assisted Testing,Discussion (Teaching Technique),Foreign Countries,Geography,Integrated Learning Systems,Learner Engagement,Multiple Choice Tests,Reading Assignments,Statistical Analysis,Student Attitudes,Student Evaluation,Student Motivation,Teaching Methods}
}

@article{coolidgeBCOpenTextbook2015,
  title = {The {{BC}} Open Textbook Project Turns Three},
  author = {Coolidge, Amanda},
  year = {2015}
}

@article{coombeLanguageAssessmentLiteracy2020,
  title = {Language {{Assessment Literacy}}: {{What Do We Need}} to {{Learn}}, {{Unlearn}}, and {{Relearn}}?.},
  author = {Coombe, Christine and Vafadar, Hossein and Mohebbi, Hassan},
  year = {2020},
  journal = {Language Testing in Asia},
  doi = {10/gh5k69},
  abstract = {Recently, we have witnessed a growing interest in developing teachers' language assessment literacy. The ever increasing demand for and use of assessment products and data by a more varied group of stakeholders than ever before, such as newcomers with limited assessment knowledge in the field, and the knowledge assessors need to possess (Stiggins, Phi Delta Kappa 72:534-539, 1991) directs an ongoing discussion on assessment literacy. The 1990 Standards for Teacher Competence in Educational Assessment of Students (AFT, NCME, \& NEA, Educational Measurement: Issues and Practice 9:30-32, 1990) made a considerable contribution to this field of study. Following these Standards, a substantial number of for and against studies have been published on the knowledge base and skills for assessment literacy, assessment goals, the stakeholders, formative assessment and accountability contexts, and measures examining teacher assessment literacy levels. This paper elaborates on the nature of the language assessment literacy, its conceptual framework, the related studies on assessment literacy, and various components of teacher assessment literacy and their interrelationships. The discussions, which focus on what language teachers and testers need to learn, unlearn, and relearn, should develop a deep understanding of the work of teachers, teacher trainers, professional developers, stakeholders, teacher educators, and educational policymakers. Further, the outcome of the present paper can provide more venues for further research.}
}

@article{coombeLanguageAssessmentLiteracy2020a,
  title = {Language Assessment Literacy: What Do We Need to Learn, Unlearn, and Relearn?},
  author = {Coombe, C. and Vafadar, H. and Mohebbi, H.},
  year = {2020},
  journal = {Language Testing in Asia},
  volume = {10},
  pages = {1--16},
  doi = {10/gh5k69},
  abstract = {Recently, we have witnessed a growing interest in developing teachers' language assessment literacy. The ever increasing demand for and use of assessment products and data by a more varied group of stakeholders than ever before, such as newcomers with limited assessment knowledge in the field, and the knowledge assessors need to possess (Stiggins, Phi Delta Kappa 72:534-539, 1991) directs an ongoing discussion on assessment literacy. The 1990 Standards for Teacher Competence in Educational Assessment of Students (AFT, NCME, \& NEA, Educational Measurement: Issues and Practice 9:30-32, 1990) made a considerable contribution to this field of study. Following these Standards, a substantial number of for and against studies have been published on the knowledge base and skills for assessment literacy, assessment goals, the stakeholders, formative assessment and accountability contexts, and measures examining teacher assessment literacy levels. This paper elaborates on the nature of the language assessment literacy, its conceptual framework, the related studies on assessment literacy, and various components of teacher assessment literacy and their interrelationships. The discussions, which focus on what language teachers and testers need to learn, unlearn, and relearn, should develop a deep understanding of the work of teachers, teacher trainers, professional developers, stakeholders, teacher educators, and educational policymakers. Further, the outcome of the present paper can provide more venues for further research.}
}

@article{coombsChangingApproachesClassroom2018,
  title = {Changing Approaches to Classroom Assessment: {{An}} Empirical Study across Teacher Career Stages},
  shorttitle = {Changing Approaches to Classroom Assessment},
  author = {Coombs, Andrew and DeLuca, Christopher and {LaPointe-McEwan}, Danielle and Chalas, Agnieszka},
  year = {2018},
  month = apr,
  journal = {Teaching and Teacher Education},
  volume = {71},
  pages = {134--144},
  issn = {0742051X},
  doi = {10/gdfmcv},
  urldate = {2021-05-21},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/HGVW2X3F/coombsChangingApproachesClassroom2018.pdf}
}

@article{coombsPersoncenteredAnalysisTeacher2020,
  title = {A Person-Centered Analysis of Teacher Candidates' Approaches to Assessment},
  author = {Coombs, Andrew and DeLuca, Christopher and MacGregor, Stephen},
  year = {2020},
  month = jan,
  journal = {Teaching and Teacher Education},
  volume = {87},
  pages = {102952},
  issn = {0742051X},
  doi = {10/gh5k6v},
  urldate = {2021-06-11},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/WMTAD4PT/coombsPersoncenteredAnalysisTeacher2020.pdf}
}

@article{coombsSeaSeaCanadian2020,
  ids = {coombsSeaSeaCanadian2020a},
  title = {From Sea to Sea: {{The Canadian}} Landscape of Assessment Education},
  shorttitle = {From Sea to Sea},
  author = {Coombs, Andrew and Ge, Jenny and DeLuca, Christopher},
  year = {2020},
  month = oct,
  journal = {Educational Research},
  pages = {1--17},
  issn = {0013-1881, 1469-5847},
  doi = {10/gh5k4z},
  urldate = {2021-02-25},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/U57M2AXC/coombsSeaSeaCanadian2020.pdf}
}

@book{corbinBasicsQualitativeResearch2008,
  title = {Basics of Qualitative Research: {{Techniques}} and Procedures for Developing Grounded Theory},
  shorttitle = {Basics of Qualitative Research: {{Techniques}} and Procedures for Developing Grounded Theory},
  author = {Corbin, Juliet M. and Strauss, Anselm L.},
  year = {2008},
  edition = {3rd},
  publisher = {Sage Publications},
  address = {Thousand Oaks, CA},
  file = {/Users/colin.madland/Zotero/storage/EIPIBK8F/Basics of Qualitative Research - Corbin.pdf}
}

@article{corbinTalkCheapWhy2025,
  title = {Talk Is Cheap: Why Structural Assessment Changes Are Needed for a Time of {{GenAI}}},
  shorttitle = {Talk Is Cheap},
  author = {Corbin, Thomas and Dawson, Phillip and Liu, Danny},
  year = {2025},
  month = may,
  journal = {Assessment \& Evaluation in Higher Education},
  pages = {1--11},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2025.2503964},
  urldate = {2025-05-20},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/corbinTalkCheapWhy2025.pdf}
}

@article{corralAssessingStudentsUse2020,
  title = {Assessing Students' Use of Optional Online Lecture Reviews},
  author = {Corral, Daniel and Carpenter, Shana K. and Perkins, Kyle and Gentile, Douglas A.},
  year = {2020},
  month = mar,
  journal = {Applied Cognitive Psychology},
  volume = {34},
  number = {2},
  pages = {318--329},
  publisher = {John Wiley \& Sons},
  issn = {0888-4080},
  doi = {10.1002/acp.3618},
  abstract = {Online practice quizzes can be used to supplement instruction in the classroom. Such quizzes can engage retrieval practice, thereby improving learning and retention. However, despite their potential benefits, recent work suggests that students typically underutilize online practice quizzes. This article reports an observational classroom study, in which students were provided optional online reviews throughout the semester. The reviews could be accessed in test format, in which students were given multiple-choice questions and provided correct answer feedback, or in read format in which students were given the same questions and were shown the correct answers. Students who used the test format performed better on exams than students who used the read format or did not use the reviews. Nevertheless, the massive majority of the online reviews (approximately 88\%) were not completed, highlighting the tendency for students to underutilize optional online reviews. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  keywords = {classroom study,Classrooms,Computer Assisted Instruction,Feedback,Learning,Lecture Method,online technology in the classroom,optional online reviews,Retention,retrieval practice,students' study behavior,Study Habits},
  file = {/Users/colin.madland/Zotero/storage/Y6BUZ4AP/corralAssessingStudentsUse2020.pdf}
}

@incollection{corrinReimaginingPeerAssessment2020,
  title = {Re-Imagining {{Peer Assessment}} in {{Self-Paced Online Learning Environments}}},
  booktitle = {Re-Imagining {{University Assessment}} in a {{Digital World}}},
  author = {Corrin, Linda and Bakharia, Aneesha},
  editor = {Bearman, Margaret and Dawson, Phillip and Ajjawi, Rola and Tai, Joanna and Boud, David},
  year = {2020},
  volume = {7},
  pages = {197--212},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-41956-1_14},
  urldate = {2022-03-19},
  isbn = {978-3-030-41955-4 978-3-030-41956-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/7I9W9A5N/Corrin-Bakharia2020_Chapter_Re-imaginingPeerAssessmentInSe.pdf}
}

@article{cosiFormativeAssessmentUniversity2020,
  title = {Formative Assessment at University Using Digital Technology Tools},
  author = {Cosi, S and Voltas, N and {Lazaro-Cantabrana}, {\relax JL} and Morales, P and Calvo, M and Molina, S and Quiroga, {\relax MA}},
  year = {2020},
  journal = {Profesorado,   revista   de   curr{\'i}culum   y   formaci{\'o}n   del  profesorado},
  volume = {24},
  number = {1},
  pages = {164--183},
  issn = {1138-414X},
  doi = {10.30827/profesorado.v24i1.9314},
  abstract = {Assessment in its various forms is a key element in any teaching process. This research focuses on how formative assessment can be used to improve the teaching-learning process and provide students with feedback about their progress rather than just grades. The main aim is to analyze how individual formative self-assessment processes - via the Socrative application (SA) and Moodle questionnaires (MQ) - affect the teaching-learning process and whether they improve student performance and satisfaction. A quantitative methodology (a case study) was used. The sample studied consisted of 374 students (315 women and 59 men) from the second year of the Teaching degree. Of these, 245 were part of a control group who did not participate in any self-assessment, and 129 were part of the experimental group (SA: 77 students and MQ: 52 students). Results show that the use of self-assessment tools during the teaching process improved the academic performance by around one point out of ten and generated a good level of satisfaction among students and teachers. Overall, no significant differences were found between MQ and SA in relation to satisfaction and performance. The results also indicate that the use of a self-assessment tool by itself is not enough to bring about a change in the way students learn. Thus, other factors should be investigated for greater insight into the variables involved in the student learning process.},
  langid = {english},
  keywords = {DIALOGUE,educational technology,ENGAGEMENT,FEEDBACK,formative evaluation,HIGHER-EDUCATION,learning strategy,PERFORMANCE,SELF-ASSESSMENT,self-evaluation,SHARED ASSESSMENT,teaching methods},
  file = {/Users/colin.madland/Zotero/storage/LC9KYD7E/cosiFormativeAssessmentUniversity2020.pdf}
}

@article{costelloBigCourseSmall2018,
  title = {Big Course Small Talk: Twitter and {{MOOCs}} --- a Systematic Review of Research Designs 2011--2017},
  author = {Costello, Eamon and Brown, Mark and Mhich{\'i}l, Mair{\'e}ad Nic Giolla and Zhang, Jingjing},
  year = {2018},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {15},
  number = {1},
  pages = {1--16},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-018-0127-9},
  abstract = {Although research on the use of Twitter in support of learning and teaching has become an established field of study the role of Twitter in the context of Massive Open Online Courses (MOOCs) has not yet been adequately considered and specifically in the literature. Accordingly, this paper addresses a number of gaps in the scholarly interface between Twitter and MOOCs by undertaking a comprehensive mapping of the current literature. In so doing the paper examines research design through: data collection and analysis techniques; scope and scale of existing studies; and theoretical approaches and underpinnings in the empirical research published between 2011 and 2017. Findings serve to demonstrate the diversity of this line of research, particularly in scale and scope of studies and in the approaches taken. By mapping the research using a systematic review methodology it is shown that there is a lack of qualitative data on how Twitter is used by learners and teachers in MOOCs. Moreover, a number of methodological gaps exist in published quantitative survey research at the interface between Twitter and MOOCs, including issues in the trustworthy reporting of results and full consideration of tweet and tweet meta-data collection. At the same time the paper highlights areas of methodological ``best practice'' in the research around these issues and in other important areas such as large-scale hashtag analyses of the use of Twitter in MOOCs. In reviewing the literature the findings aim to strengthen the methodological foundation of future work and help shape a stronger research agenda in this emerging area.},
  keywords = {Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Educational Technology,Higher Education,Humanities,Information Systems Applications (incl.Internet),Law,Methodology,MOOC,Research Article,Statistics for Social Sciences,Systematic review,Twitter},
  file = {/Users/colin.madland/Zotero/storage/E8ZBSLPA/costelloBigCourseSmall2018.pdf}
}

@article{coughlanCreatingOpenOnline2019,
  title = {Creating {{Open Online Courses}} with {{Learner Representative Partners}} to {{Widen Participation}} in {{Higher Education}}},
  author = {Coughlan, Tim and Goff, Jenny},
  year = {2019},
  journal = {Journal of Learning for Development},
  volume = {6},
  number = {2},
  pages = {143--159},
  issn = {EISSN-2311-1550},
  abstract = {Open online courses could provide stepping stones for audiences that are underrepresented in higher education (HE). However, there are concerns that these instead proliferate forms of exclusion and do not address known difficulties for widening participation. We explore how organisations that represent the perspectives of particular underserved audiences for HE can act as 'Learner Representative Partners' to support the creation of appropriate courses and to highlight practices that exclude. Six course development processes where a university worked with different partners are analysed using interviews, documentation of resource use, and data on learner behaviour. The analysis utilises previously identified challenges to widening participation and collaborative course creation. Getting partners to directly engage in authoring the course was particularly beneficial but all partners prompted critical thought and greater understanding of the intended audiences. We suggest principles to support such partnerships effectively. These include adapting to a variable capacity of partners to contribute, to encourage reuse or creation of resources by partners, and to facilitate partners to feel confident in expressing their views.},
  langid = {english},
  keywords = {Access to Education,Caregiver Training,Disproportionate Representation,Education Work Relationship,Educational Cooperation,Entrepreneurship,Foreign Countries,Health Education,No DOI found,Nontraditional Students,Online Courses,Open Educational Resources,Open Universities,Organizations (Groups),Participation,Partnerships in Education,Qualifications,Relevance (Education),Teacher Education,Voluntary Agencies}
}

@book{councilforaidtoeducationCollegiateLearningAssessmentn.d.,
  title = {Collegiate {{Learning Assessment}}},
  author = {{Council for Aid to Education}},
  year = {n.d.},
  number = {April 9, 2012}
}

@incollection{courosChapterDevelopingPersonal2010,
  title = {Chapter 6 - {{Developing Personal Learning Networks}} for {{Open}} and {{Social Learning}}},
  booktitle = {Emerging Technologies in Distance Education},
  author = {Couros, Alec},
  editor = {Veletsianos, George},
  year = {2010},
  publisher = {AU Press},
  address = {Athabasca},
  urldate = {2021-12-23},
  isbn = {978-1-897425-77-0},
  langid = {english},
  annotation = {OCLC: 880489604}
}

@article{coxExploringImpactArtificial2021,
  title = {Exploring the Impact of {{Artificial Intelligence}} and Robots on Higher Education through Literature-Based Design Fictions},
  author = {Cox, A. M.},
  year = {2021},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {18},
  number = {1},
  pages = {1--19},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-020-00237-8},
  abstract = {Artificial Intelligence (AI) and robotics are likely to have a significant long-term impact on higher education (HE). The scope of this impact is hard to grasp partly because the literature is siloed, as well as the changing meaning of the concepts themselves. But developments are surrounded by controversies in terms of what is technically possible, what is practical to implement and what is desirable, pedagogically or for the good of society. Design fictions that vividly imagine future scenarios of AI or robotics in use offer a means both to explain and query the technological possibilities. The paper describes the use of a wide-ranging narrative literature review to develop eight such design fictions that capture the range of potential use of AI and robots in learning, administration and research. They prompt wider discussion by instantiating such issues as how they might enable teaching of high order skills or change staff roles, as well as exploring the impact on human agency and the nature of datafication.},
  keywords = {Artificial Intelligence,Big data,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Data Analysis,Education,Educational Administration,Educational Change,Educational Technology,Futures (of Society),Higher Education,Humanities,Information Systems Applications (incl.Internet),Instructional Design,Law,Learning analytics,Literature reviews,Personal Autonomy,Research Article,Research Methodology,Robotics,Robots,Social robots,Statistics for Social Sciences,Teacher Role,Teaching Methods,Thinking Skills},
  file = {/Users/colin.madland/Zotero/storage/9V39UFLG/coxExploringImpactArtificial2021.pdf}
}

@article{cramNegotiatingSolidarityIndigenous2016,
  title = {Negotiating Solidarity between Indigenous and Transformative Paradigms in Evaluation},
  author = {Cram, Fiona and Mertens, Donna},
  year = {2016},
  month = jul,
  journal = {Evaluation Matters---He Take T{\=o} Te Aromatawai},
  volume = {2},
  pages = {161--189},
  issn = {24230804},
  doi = {10.18296/em.0015},
  urldate = {2019-03-21},
  file = {/Users/colin.madland/Zotero/storage/L5L695RS/cramNegotiatingSolidarityIndigenous2016.pdf}
}

@article{crawfordCOVID1920Countries2020,
  title = {{{COVID-19}}: 20 Countries' Higher Education Intra-Period Digital Pedagogy Responses},
  shorttitle = {{{COVID-19}}},
  author = {Crawford, Joseph and {Butler-Henderson}, Kerryn and Rudolph, J{\"u}rgen and Malkawi, Bashar and Glowatz, Matt and Burton, Rob and Magni, Paola A. and Lam, Sophia},
  year = {2020},
  month = apr,
  journal = {Journal of Applied Learning \& Teaching},
  volume = {3},
  number = {1},
  issn = {2591-801X, 2591-801X},
  doi = {10.37074/jalt.2020.3.1.7},
  urldate = {2023-02-07},
  abstract = {The Coronavirus 2019 (COVID-19) pandemic has created significant challenges for the global higher education community. Through a desktop analysis leveraging university and government sources where possible, we provide a timely map of the intra-period higher education responses to COVID-19 across 20 countries. We found that the responses by higher education providers have been diverse from having no response through to social isolation strategies on campus and rapid curriculum redevelopment for fully online offerings. We provide in our discussion a typology of the types of responses currently undertaken and assess the agility of higher education in preparing for the pandemic. We believe there are significant opportunities to learn from the pedagogical developments of other universities, in order to strengthen our collective response to COVID-19 now and into the future.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/3V32PYTB/crawfordCOVID1920Countries2020.pdf}
}

@book{creamerIntroductionFullyIntegrated2018,
  title = {An {{Introduction}} to {{Fully Integrated Mixed Methods Research}}},
  author = {Creamer, Elizabeth G.},
  year = {2018},
  publisher = {SAGE Publications, Inc.},
  address = {2455 Teller Road,~Thousand Oaks~California~91320},
  doi = {10.4135/9781071802823},
  urldate = {2021-08-01},
  isbn = {978-1-4833-5093-6 978-1-0718-0282-3},
  file = {/Users/colin.madland/Zotero/storage/5XBFHGI8/creamerIntroductionFullyIntegrated2018.pdf}
}

@misc{CreativecommonsOrg,
  title = {Creativecommons.Org},
  journal = {Creative Commons},
  urldate = {2018-12-01},
  abstract = {Share, Collaborate, Remix, Reuse We're changing the way people share around the world with our Global Community and 1.4 billion pieces of content under our simple, easy-to-use open licenses. State of the Commons},
  howpublished = {https://creativecommons.org/},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/M79F7IMB/creativecommons.org.html}
}

@book{creswellDesigningConductingMixed2010,
  title = {Designing and Conducting Mixed Methods Research},
  author = {Creswell, John W and Plano Clark, Vicki L},
  year = {2010},
  edition = {2},
  publisher = {Sage},
  address = {Thousand Oaks, CA}
}

@book{creswellQualitativeInquiryResearch2007,
  title = {Qualitative {{Inquiry}} and {{Research Design}}: {{Choosing Among Five Approaches}}},
  shorttitle = {Qualitative {{Inquiry}} and {{Research Design}}: {{Choosing Among Five Approaches}}},
  author = {Creswell, John W},
  year = {2007},
  edition = {2nd},
  publisher = {Sage Publications},
  address = {Thousand Oaks, CA},
  isbn = {978-1-4129-1607-3}
}

@book{creswellResearchDesignQualitative2009,
  title = {Research {{Design}}: {{Qualitative}}, Quantitative and Mixed Method Approaches},
  shorttitle = {Research {{Design}}: {{Qualitative}}, Quantitative and Mixed Method Approaches},
  author = {Creswell, John W},
  year = {2009},
  edition = {3rd},
  publisher = {Sage Publications},
  address = {Thousand Oaks, CA}
}

@incollection{croftDevelopmentEvolutionSAT2021,
  title = {Development and Evolution of the {{SAT}} and {{ACT}}},
  booktitle = {The History of Educational Measurement: Key Advancements in Theory, Policy, and Practice},
  author = {Croft, Michelle and Beard, Jonathan J.},
  editor = {Clauser, Brian E. and Bunch, Michael B.},
  year = {2021},
  publisher = {Routledge},
  address = {New York, NY},
  abstract = {"The History of Educational Measurement collects essays on the most important topics in educational testing, measurement, and psychometrics. Authored by the field's top scholars, this book offers unique historical viewpoints, from origins to modern applications, of formal testing programs and mental measurement theories. Topics as varied as large-scale testing, validity, item-response theory, federal involvement, and notable assessment controversies complete a survey of the field's greatest challenges and most important achievements. Graduate students, researchers, industry professionals, and other stakeholders will find this volume relevant for years to come"--},
  isbn = {978-0-367-37095-4 978-0-367-41575-4},
  lccn = {LB3051 .H56 2021},
  keywords = {Educational tests and measurements,History}
}

@article{cronbachCourseImprovementEvaluation1963,
  title = {Course {{Improvement}} through {{Evaluation}}},
  author = {Cronbach, Lee J.},
  year = {1963},
  month = may,
  journal = {Teachers College Record: The Voice of Scholarship in Education},
  volume = {64},
  number = {8},
  pages = {1--13},
  issn = {0161-4681, 1467-9620},
  doi = {10.1177/016146816306400802},
  urldate = {2022-04-23},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/R7L8R87B/cronbachCourseImprovementEvaluation1963.pdf}
}

@article{croninConceptualisingOEPReview2018,
  title = {Conceptualising {{OEP}}: {{A}} Review of Theoretical and Empirical Literature in {{Open Educational Practices}}},
  author = {Cronin, Catherine and MacLaren, Iain},
  editor = {{Gil-Jaurena}, In{\'e}s},
  year = {2018},
  journal = {Open Praxis},
  volume = {10},
  number = {2},
  pages = {127--143},
  doi = {10.5944/openpraxis.10.2.825},
  abstract = {Conceptualisations of open educational practices (OEP) vary widely, ranging from those centred primarily on the creation and use of open educational resources (OER) to broader definitions of OEP, inclusive of but not necessarily focused on OER. The latter, referred to in this paper asexpansive definitions of OEP, encompass open content but also allow for multiple entry points to, and avenues of, openness. This paper explores the theoretical and empirical literature to outline how the concept of OEP has evolved historically. The paper aims to provide a useful synthesis of OEP literature for education researchers and practitioners.},
  keywords = {OEP}
}

@article{croninOpennessPraxisExploring2017,
  title = {Openness and {{Praxis}}: {{Exploring}} the {{Use}} of {{Open Educational Practices}} in {{Higher Education}}},
  shorttitle = {Openness and {{Praxis}}},
  author = {Cronin, Catherine},
  year = {2017},
  month = aug,
  journal = {The International Review of Research in Open and Distributed Learning},
  volume = {18},
  number = {5},
  issn = {1492-3831},
  doi = {10.19173/irrodl.v18i5.3096},
  urldate = {2018-11-03},
  abstract = {Open educational practices (OEP) is a broad descriptor of practices that include the creation, use, and reuse of open educational resources (OER) as well as open pedagogies and open sharing of teaching practices. As compared with OER, there has been little empirical research on individual educators' use of OEP for teaching in higher education. This research study addresses that gap, exploring the digital and pedagogical strategies of a diverse group of university educators, focusing on whether, why, and how they use OEP for teaching. The study was conducted at one Irish university; semi-structured interviews were carried out with educators across multiple disciplines. Only a minority of educators used OEP. Using constructivist grounded theory, a model of the concept ``Using OEP for teaching'' was constructed showing four dimensions shared by open educators: balancing privacy and openness, developing digital literacies, valuing social learning, and challenging traditional teaching role expectations. The use of OEP by educators is complex, personal, and contextual; it is also continually negotiated. These findings suggest that research-informed policies and collaborative and critical approaches to openness are required to support staff, students, and learning in an increasingly complex higher education environment.},
  copyright = {Copyright (c) 2017 Catherine Cronin},
  langid = {english},
  keywords = {higher education,oep,OEP,open,open education,open education practices,open educational practices,open educational resources},
  file = {/Users/colin.madland/Zotero/storage/PILNQGUT/croninOpennessPraxisExploring2017.pdf;/Users/colin.madland/Zotero/storage/DWY3LNT3/3096.html}
}

@article{crookAssessmentRelationshipsHigher2006,
  title = {Assessment Relationships in Higher Education the Tension of Process and Practice},
  author = {Crook, Charles and Gross, Harriet and Dymott, Roy},
  year = {2006},
  journal = {British Educational Research Journal},
  doi = {10/dzn6v5},
  abstract = {It is argued that the auditing demands of quality assurance have encouraged a greater proceduralisation of university coursework assessment. Interviews with academics from a cross-section of Psychology departments illustrated how assessment had acquired the tightly scripted character of an organisational process. Yet undergraduate focus group conversations suggested that this proceduralisation obstructed the experience students sought from assessment as a form of educational practice. It is argued that educational contexts can create a distinctive form of process/practice tension. In particular, formalising assessment into a process may conceal students' unease, inhibit the expression of that unease, and create a distracting focus on study products rather than study practices. A striking interpersonal dissociation of author and reader (student and tutor) was apparent in the organisational processes documented here. This was identified as the source of significant student discontent, and the likely starting point for its repair.},
  pmcid = {null},
  pmid = {null}
}

@article{crookAssessmentRelationshipsHigher2006a,
  title = {Assessment Relationships in Higher Education the Tension of Process and Practice},
  author = {Crook, Charles and Gross, Harriet and Dymott, Roy},
  year = {2006},
  journal = {British Educational Research Journal},
  doi = {10/dzn6v5},
  abstract = {It is argued that the auditing demands of quality assurance have encouraged a greater proceduralisation of university coursework assessment. Interviews with academics from a cross-section of Psychology departments illustrated how assessment had acquired the tightly scripted character of an organisational process. Yet undergraduate focus group conversations suggested that this proceduralisation obstructed the experience students sought from assessment as a form of educational practice. It is argued that educational contexts can create a distinctive form of process/practice tension. In particular, formalising assessment into a process may conceal students' unease, inhibit the expression of that unease, and create a distracting focus on study products rather than study practices. A striking interpersonal dissociation of author and reader (student and tutor) was apparent in the organisational processes documented here. This was identified as the source of significant student discontent, and the likely starting point for its repair.},
  pmcid = {null},
  pmid = {null}
}

@article{crooksImpactClassroomEvaluation1988,
  title = {The {{Impact}} of {{Classroom Evaluation Practices}} on {{Students}}},
  author = {Crooks, Terence J.},
  year = {1988},
  month = dec,
  journal = {Review of Educational Research},
  volume = {58},
  number = {4},
  pages = {438--481},
  issn = {0034-6543, 1935-1046},
  doi = {10/dvd8nf},
  urldate = {2021-07-05},
  abstract = {In most educational programs, a substantial proportion of teacher and student time is devoted to activities which involve (or lead directly to) evaluation by the teacher of student products or behavior. This review summarizes results from 14 specific fields of research that cast light on the relationships between classroom evaluation practices and student outcomes. Particular attention is given to outcomes involving learning strategies, motivation, and achievement. Where possible, mechanisms are suggested that could account for the reported effects. The conclusions derived from the individual fields are then merged to produce an integrated summary with clear implications for effective educational practice. The primary conclusion is that classroom evaluation has powerful direct and indirect impacts, which may be positive or negative, and thus deserves very thoughtful planning and implementation.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/3A7ZDBPR/crooksImpactClassroomEvaluation1988.pdf}
}

@article{crooksMarksMarkingSystems1933,
  title = {Marks and {{Marking Systems}}: {{A Digest}}},
  author = {Crooks, A. Duryee},
  year = {1933},
  journal = {The Journal of Educational Research},
  volume = {27},
  number = {4},
  pages = {259--272},
  publisher = {Taylor \& Francis, Ltd.},
  issn = {00220671, 19400675},
  doi = {10.1080/00220671.1933.10880402},
  urldate = {2022-11-15},
  file = {/Users/colin.madland/Zotero/storage/HTJDULQZ/crooksMarksMarkingSystems1933.pdf}
}

@inproceedings{crosbyStudentPerceptionsAssessment2021,
  title = {Student {{Perceptions}} of {{Assessment}} and {{Feedback}} - Are They Valid?},
  booktitle = {Computing {{Education Practice}} 2021},
  author = {Crosby, Ryan},
  year = {2021},
  month = jan,
  pages = {5--8},
  publisher = {ACM},
  address = {Durham United Kingdom},
  doi = {10/fp34},
  urldate = {2021-07-30},
  isbn = {978-1-4503-8959-4},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/YUSHTR4U/crosbyStudentPerceptionsAssessment2021.pdf}
}

@article{crossouardUsingFormativeAssessment2011,
  title = {Using Formative Assessment to Support Complex Learning in Conditions of Social Adversity},
  author = {Crossouard, Barbara},
  year = {2011},
  month = feb,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {18},
  number = {1},
  pages = {59--72},
  publisher = {Routledge},
  issn = {0969-594X},
  doi = {10/cmfgvf},
  file = {/Users/colin.madland/Zotero/storage/SMKP88J6/crossouardUsingFormativeAssessment2011.pdf}
}

@book{crumpOpenToolsWriting,
  title = {Open Tools for Writing Open Interactive Textbooks (and More)},
  author = {Crump, Matthew},
  urldate = {2022-02-04},
  abstract = {A tutorial and working resources for writing open-source textbooks using open-source tools},
  keywords = {archived},
  annotation = {https://web.archive.org/web/20220108180756/https://www.crumplab.com/OER\_bookdown/},
  file = {/Users/colin.madland/Zotero/storage/B7IH3PYI/OER_bookdown.html}
}

@article{csapoPotentialAssessingDynamic2017,
  title = {Potential for {{Assessing Dynamic Problem-Solving}} at the {{Beginning}} of {{Higher Education Studies}}},
  author = {Csapo, Beno and Molnar, Gyongyver},
  year = {2017},
  journal = {Frontiers in psychology},
  volume = {8},
  pages = {2022--2022},
  publisher = {Frontiers Media Sa},
  address = {LAUSANNE},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2017.02022},
  abstract = {There is a growing demand for assessment instruments which can be used in higher education, which cover a broader area of competencies than the traditional tests for disciplinary knowledge and domain-specific skills, and which measure students' most important general cognitive capabilities. Around the age of the transition from secondary to tertiary education, such assessments may serve several functions, including selecting the best-prepared candidates for certain fields of study. Dynamic problem-solving (DPS) is a good candidate for such a role, as tasks that assess it involve knowledge acquisition and knowledge utilization as well. The purpose of this study is to validate an online DPS test and to explore its potential for assessing students' DPS skills at the beginning of their higher education studies. Participants in the study were first-year students at a major Hungarian university (n = 1468). They took five tests that measured knowledge from their previous studies: Hungarian language and literature, mathematics, history, science and English as a Foreign Language (EFL). A further, sixth test based on the MicroDYN approach, assessed students' DPS skills. A brief questionnaire explored learning strategies and collected data on students' background. The testing took place at the beginning of the first semester in three 2-h sessions. Problem-solving showed relatively strong correlations with mathematics (r = 0.492) and science (r = 0.401), and moderate correlations with EFL (r = 0.227), history (r = 0.192), and Hungarian (r = 0.125). Weak but still significant correlations were found with certain learning strategies, positive correlations with elaboration strategies, and a negative correlation with memorization strategies. Significant differences were observed between male and female students; men performed significantly better in DPS than women. Results indicated the dominant role of the first phase of solving dynamic problems, as knowledge acquisition correlated more strongly with any other variable than knowledge utilization.},
  keywords = {Analysis,dynamic problem-solving,Education,Learning strategies,predictive validity,Problem solving,Psychology,Psychology Multidisciplinary,Social Sciences,technology-based assessment,university admissions},
  file = {/Users/colin.madland/Zotero/storage/FGEDCHDD/csapoPotentialAssessingDynamic2017.pdf}
}

@inbook{cubanEncyclopediaEducationalTheory2018,
  title = {Encyclopedia of {{Educational Theory}} and {{Philosophy}}},
  author = {Cuban, Larry},
  year = {2018},
  publisher = {SAGE Publications, Inc.},
  address = {Thousand Oaks,},
  doi = {10.4135/9781483346229},
  collaborator = {{pages 589-592}}
}

@article{cubanOpenClassroom2004,
  title = {The {{Open Classroom}}},
  author = {Cuban, Larry},
  year = {2004},
  journal = {Education Next},
  volume = {4},
  number = {2},
  urldate = {2018-10-20},
  abstract = {Like automotive models, women's hemlines, and children's toys, pedagogical fads come and go, causing an immediate stir but rarely influencing teaching practice in any significant way. The notion that every innovation dreamed up by reformers inside and outside public schools makes its way into the nation's classrooms is popular among those hunting for reasons to {\dots}},
  langid = {american},
  keywords = {history,open},
  file = {/Users/colin.madland/Zotero/storage/CZGZCKK2/theopenclassroom.html}
}

@inproceedings{cuiCreatingCapacityDigital2024,
  title = {Creating {{Capacity}} for {{Digital Transformation}} of {{Education}}: {{Mode}} and {{Disciplinary Barriers}} in the {{Development}} of {{Highly Qualified Personnel}}},
  booktitle = {Proceedings of the {{Open}}/{{Technology}} in {{Education}}, {{Society}}, and {{Scholarship Association Conference}}},
  author = {Cui, Hongran and Irvine, Valerie and Miller, Mariel and Madland, Colin},
  year = {2024},
  address = {Montr{\'e}al, QC}
}

@article{cuiCreatingCapacityDigitalInPreparation,
  title = {Creating {{Capacity}} for {{Digital Transformation}} of {{Education}}: {{Mode}} and {{Disciplinary Barriers}} in the {{Development}} of {{Highly Qualified Personnel}}},
  author = {Cui, Hongran and Irvine, Valerie and Miller, Mariel and Madland, Colin},
  year = {In Preparation},
  journal = {Canadian Journal of Learning and Technology}
}

@incollection{cuiRuleSpaceAttribute2016,
  title = {The Rule Space and Attribute Hierarchy Methods},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {Cui, Ying and Gierl, Mark J. and Guo, Qi},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch15},
  pages = {354--378},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch15},
  abstract = {Summary In this chapter we provide an overview of and discuss important issues associated with the rule space method (RSM) and the attribute hierarchy method (AHM). We discuss general principles of sound test design consistent with both the RSM and the AHM, review the statistical aspects of the two methods, and conclude the chapter by discussing future directions that could promote the better use of the RSM and the AHM in contributing to skills diagnostic testing.},
  chapter = {15},
  isbn = {978-1-118-95658-8},
  keywords = {artificial neural network,attribute hierarchy method,cognitive attribute,cognitive diagnostic assessment,item response theory,principled test design,rule space method}
}

@article{cunningham-nelsonTextAnalysisEducation2018,
  title = {Text Analysis in Education: A Review of Selected Software Packages with an Application for Analysing Students' Conceptual Understanding},
  shorttitle = {Text Analysis in Education},
  author = {{Cunningham-Nelson}, Samuel and Mukherjee, Michelle and Goncher, Andrea and Boles, Wageeh},
  year = {2018},
  month = jan,
  journal = {Australasian Journal of Engineering Education},
  volume = {23},
  number = {1},
  pages = {25--39},
  issn = {2205-4952, 1325-4340},
  doi = {10.1080/22054952.2018.1502914},
  urldate = {2022-10-31},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/6LEFRLVW/cunningham-nelsonTextAnalysisEducation2018.pdf}
}

@article{cunninghamTeachingDisembodiedOthering2014,
  title = {Teaching the {{Disembodied}}: {{Othering}} and {{Activity Systems}} in a {{Blended Synchronous Learning Situation}}},
  author = {Cunningham, Una},
  year = {2014},
  month = dec,
  journal = {International Review of Research in Open and Distance Learning},
  volume = {15},
  number = {6},
  pages = {33--51},
  issn = {1492-3831},
  abstract = {This study examines what happens when online and campus students participate in real time in the same campus classroom. Before this study, postgraduate students studying online in a course intended primarily as professional development for language educators were taking the course through reading the course literature including assigned articles, writing reflective texts in the asynchronous forum and doing the course assignments. They had a very different experience than the campus students who met weekly for discussion of the reading. Some online students were not active enough in the course, and showed low levels of engagement. The online students were invited to participate in scheduled campus classes via Skype on iPads. After some hesitation, four of the six online students took up this real-time participation option. Initial difficulties with the technology were addressed after seeking input from campus and online students. A series of adjustments were made and evaluated, including a move to a model in which three online students in different locations participated in a single Skype group video call on a laptop in the campus classroom rather than on multiple individual Skype calls on iPads. After the course, the online and campus students were asked to evaluate the experience of having physical and virtual participants sharing a physical space and to relate this experience to the asynchronous channels previously available to the participants. The comments of both groups of participants were interpreted in the light of previous work on social presence and of activity theory. It appears that student beliefs and student expectations lead to hidden challenges associated with mixing these groups of students, and the study concludes that unless teaching assistance is available, it is not easy to afford online students the same right to speak as campus students.},
  keywords = {Beliefs,Blended Learning,Electronic Learning,Expectation,Graduate Students,Learner Engagement,Social Distance,Student Attitudes,Student Experience,Student Participation,Synchronous Communication}
}

@article{cunsolowilloxStorytellingDigitalAge2012,
  title = {Storytelling in a Digital Age: Digital Storytelling as an Emerging Narrative Method for Preserving and Promoting Indigenous Oral Wisdom},
  author = {Cunsolo Willox, Ashlee and Harper, Sherilee L and Edge, Victoria L},
  year = {2012},
  month = oct,
  journal = {Qualitative Research},
  volume = {13},
  number = {2},
  pages = {127--147},
  issn = {1468-7941},
  doi = {10.1177/1468794112446105},
  urldate = {2019-04-06},
  abstract = {This article outlines the methodological process of a transdisciplinary team of indigenous and nonindigenous individuals, who came together in early 2009 to develop a digital narrative method to engage a remote community in northern Labrador in a research project examining the linkages between climate change and physical, mental, emotional, and spiritual health and well-being. Desiring to find a method that was locally appropriate and resonant with the narrative wisdom of the community, yet cognizant of the limitations of interview-based narrative research, our team sought to discover an indigenous method that united the digital media with storytelling. Using a case study that illustrates the usage of digital storytelling within an indigenous community, this article will share how digital storytelling can stand as a community-driven methodological strategy that addresses, and moves beyond, the limitations of narrative research and the issues of colonization of research and the Western analytic project. In so doing, this emerging method can preserve and promote indigenous oral wisdom, while engaging community members, developing capacities, and celebrating myriad stories, lived experiences, and lifeworlds.}
}

@article{curtinuniversityPurposebuiltWebbasedProfessional2017,
  ids = {curtinuniversityPurposebuiltWebbasedProfessional2017a},
  title = {Purpose-Built, {{Web-based Professional Portfolios}}: {{Reflective}}, {{Developmental}} and {{Showcase}}},
  shorttitle = {Purpose-Built, {{Web-based Professional Portfolios}}},
  author = {{Curtin University} and Blackley, Susan and Bennett, Dawn and {Curtin University} and Sheffield, Rachel and {Curtin University}},
  year = {2017},
  month = may,
  journal = {Australian Journal of Teacher Education},
  volume = {42},
  number = {5},
  pages = {1--16},
  doi = {10.14221/ajte.2017v42n5.1},
  urldate = {2022-10-31},
  file = {/Users/colin.madland/Zotero/storage/LCLGY83U/curtinuniversityPurposebuiltWebbasedProfessional2017.pdf}
}

@book{czarniawskaNarrativeApproachOrganization2019,
  title = {A {{Narrative Approach}} to {{Organization Studies}}},
  author = {Czarniawska, Barbara},
  year = {2019},
  address = {Thousand Oaks, California},
  doi = {10.4135/9781412983235},
  keywords = {Sage Methods}
}

@article{czaudernaRemoteCollaborationHigher2021,
  title = {Remote {{Collaboration}} in {{Higher Game Development Education}}. {{Online Practices}} and {{Learning Processes}} of {{Students}} between {{Professional Routines}} and {{Psychosocial Challenges}}},
  author = {Czauderna, Andr{\'e} and Guardiola, Emmanuel},
  year = {2021},
  journal = {Higher Education Studies},
  volume = {11},
  number = {2},
  pages = {1--19},
  issn = {ISSN-1925-4741},
  doi = {10/gmbvz9},
  abstract = {The development of digital games over physical distance is a common practice in the gaming industry, yet widely neglected in the curricula of digital game development programs at university level. The coronavirus pandemic, however, pushed project-oriented game programs all over the world towards an implementation of ad hoc approaches to remote development in their project-based courses. The present article demonstrates practice-based research examining such a course and its 30 third-year undergraduate students of game arts, game design, and game programming, who remotely collaborated in interdisciplinary groups of two to five persons over the course of half a semester during Germany's logdown in spring 2020. Applying a mixed-method approach including quantitative and qualitative analyses of survey data (n=22) and qualitative content analyses of students' postmortem documentations (n=30), this exploratory study reconstructed the online practices, experiences, and learning processes of these students between their professional routines and psychosocial challenges. The results of this study can be used in curriculum development to inform the advancement of courses focused on the development of prototypes over physical distance, which may not only be relevant for the field of games education, but also for related creative and project-oriented fields of higher education, such as design, digital media, and software engineering.},
  langid = {english},
  keywords = {Active Learning,Computer Mediated Communication,Cooperative Learning,COVID-19,Design,Distance Education,Foreign Countries,Pandemics,Student Attitudes,Student Projects,Teaching Methods,Teleconferencing,Undergraduate Students,Video Games,Videoconferencing}
}

@article{d428d677022c2513d6180d56f800ead3134660d7,
  title = {A Call for Critical Dialogue: {{EAP}} Assessment from the {{Practitioner}}'s Perspective in {{Canada}}},
  author = {Huang, Li-Shih},
  year = {2018},
  journal = {Journal of English for Academic Purposes},
  volume = {35},
  pages = {70--84},
  doi = {10/gh5k6s},
  abstract = {Abstract Using an explanatory sequential design, this study integrated survey and interview data gathered from 35 English-for-academic-purposes (EAP) practitioners across 14 institutions in Canada in order to address questions associated with their assessment practices. Specifically, we explored the participants' training, experience, and perceived skills in testing and assessment; their perceptions about EAP testing and assessment; their approaches to and practices of EAP testing and assessment; and their testing- and assessment-related professional development needs. In addition to revealing the participating EAP instructors' assessment approaches and practices in the Canadian context, the results highlighted a reported paucity of training in EAP testing and assessment both within and outside of teacher-education programs. They also revealed self-perceived gaps of EAP instructors regarding their lack of assessment knowledge, skills in developing tests, skills in aligning needs with tests and assessments, and self-confidence in designing, modifying, and implementing tests. The sharing of these results is intended to raise awareness of the current testing and assessment practices of EAP instructors in the Canadian context, with the hope of opening a dialogue about them as well as reflecting on ways to encourage the sharing of knowledge, skills, and understanding about these practices within the professional community.}
}

@book{dabbaghOnlineDiscussionProtocols2003,
  title = {Online {{Discussion Protocols}} and {{Rubrics}}},
  author = {Dabbagh, Nada},
  year = {2003},
  volume = {2010}
}

@article{dahalWorkshoppingOnlineCourses2019,
  title = {Workshopping in {{Online Courses}}: {{Insights}} for {{Learning}} and {{Assessment}} in {{Higher Education}}},
  author = {Dahal, Niroj and Pangeni, Shesha Kanta},
  year = {2019},
  journal = {International Journal of Multidisciplinary Perspectives in Higher Education},
  volume = {4},
  number = {1},
  pages = {89--110},
  issn = {ISSN-2474-2546},
  doi = {10/gmbvnq},
  abstract = {Designed to explore effective pedagogical uses of the Workshop activity tool, which is native to Moodle learning management system, the study reported in this article was an action research. Using the standard steps of planning, intervening, assessing effectiveness, and information sharing, the study sought to identify the best ways to engage students in the process of learning and peer assessment by using Workshop as a learning and assessment tool. After identifying some challenges against students learning during the submission and peer review process, this article highlights some key strengths of the Workshop activity application, based on our study. Then it discusses the application's key affordances for conducting peer and self-assessment, for enhanced engagement in learning, and for the development of higher-order skills such as analysis and evaluation. We conclude by noting that effective use of the tool demands teachers' careful attention to issues such as time provided, peer allocation, and students' skills for effective tool use.},
  langid = {english},
  keywords = {Affordances,Feedback (Response),Foreign Countries,Graduate Students,Instructional Effectiveness,Integrated Learning Systems,Interaction,Mathematics Education,Online Courses,Peer Evaluation,Reflection,Self Evaluation (Individuals),Teacher Education}
}

@article{dahalWorkshoppingOnlineCourses2019a,
  title = {Workshopping in {{Online Courses}}: {{Insights}} for {{Learning}} and {{Assessment}} in {{Higher Education}}},
  shorttitle = {Workshopping in {{Online Courses}}},
  author = {Dahal, Niroj and Pangeni, Shesha Kanta},
  year = {2019},
  month = dec,
  journal = {International Journal of Multidisciplinary Perspectives in Higher Education},
  volume = {4},
  number = {1},
  pages = {89--110},
  issn = {2474-2554, 2474-2546},
  doi = {10/gmbvnq},
  urldate = {2021-07-27},
  abstract = {Designed to explore effective pedagogical uses of the Workshop activity tool, which is native to Moodle learning management system, the study reported in this article was an action research. Using the standard steps of planning, intervening, assessing effectiveness, and information sharing, the study sought to identify the best ways to engage students in the process of learning and peer assessment by using Workshop as a learning and assessment tool. After identifying some challenges against students learning during the submission and peer review process, this article highlights some key strengths of the Workshop activity application, based on our study. Then it discusses the application's key affordances for conducting peer and self-assessment, for enhanced engagement in learning, and for the development of higher-order skills such as analysis and evaluation. We conclude by noting that effective use of the tool demands teachers' careful attention to issues such as time provided, peer allocation, and students' skills for effective tool use.},
  file = {/Users/colin.madland/Zotero/storage/QJNTVIH2/dahalWorkshoppingOnlineCourses2019.pdf}
}

@article{dallasExaminingEducationalBenefits2016,
  title = {Examining the {{Educational Benefits}} of and {{Attitudes}} toward {{Closed Captioning}} among {{Undergraduate Students}}},
  author = {Dallas, Bryan K. and McCarthy, Amanda K. and Long, Greg},
  year = {2016},
  month = apr,
  journal = {Journal of the Scholarship of Teaching and Learning},
  volume = {16},
  number = {2},
  pages = {50--65},
  publisher = {{Journal of the Scholarship of Teaching and Learning}},
  issn = {1527-9316},
  abstract = {Closed-captioning technology has been available for decades and is often used by individuals with disabilities to access video-based information. Videos are routinely used by educators in higher education settings throughout the United States. It is unknown, however, if closed captions are educationally beneficial for all students. The purpose of this study was to examine the educational benefits of closed captioning among college students without disabilities and their associated attitudes toward the technology. The use of closed captions adheres to the principles of Universal Design that encourage stakeholders to build environments and products that are accessible to all individuals. However, more evidence-based research is needed on the utility of this technology in college classrooms. Two separate video-based studies were conducted at one university, and groups were randomly assigned to "caption" or "no-caption" conditions. It was hypothesized that exposure to closed captions would increase students' recall and understanding of video-based information and improve attitudes toward the technology. Results suggested that participants who were exposed to closed captions scored significantly higher on the subsequent assessment. Participants who already used closed captions in their daily lives had significantly more positive attitudes toward the technology. Recommendations for college-level educators and further study are provided.},
  keywords = {Assistive Technology,Educational Benefits,Educational Technology,Evidence Based Practice,Hypothesis Testing,Instructional Design,Layout (Publications),Likert Scales,No DOI found,Regression (Statistics),Scores,Student Attitudes,Undergraduate Students,United States (Midwest),Video Technology,Visual Aids}
}

@article{danielsRelationshipsPreserviceTeachers2017,
  title = {Relationships between Pre-Service Teachers' Conceptions of Assessment, Approaches to Instruction, and Assessment: An Achievement Goal Theory Perspective},
  author = {Daniels, Lia M. and Poth, Cheryl A.},
  year = {2017},
  journal = {Educational psychology (Dorchester-on-Thames)},
  volume = {37},
  number = {7},
  pages = {835--853},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0144-3410},
  doi = {10.1080/01443410.2017.1293800},
  abstract = {The purpose of this paper was to examine the relationships between pre-service teachers' conceptions of assessment and their intended approaches to classroom instruction and assessment. We operationalised approaches to instruction and assessment according to Achievement Goal Theory, postulating that pre-service teachers approach instruction and assessment from either a mastery or performance perspective. The results from a correlational study of 344 Canadian pre-service teachers showed that intended instruction and assessment practices were separated according to mastery and performance approaches. However, there was also alignment between the concepts such that pre-service teachers who had a mastery approach to instruction were more inclined towards a mastery approach to assessment. Approaches to assessment were also related to pre-service teachers' conceptions: beliefs that assessment holds students and schools accountable were positively related to a performance approach to assessment. In contrast, a belief that assessment improves teaching was positively related to a mastery approach to assessment and negatively to a performance approach. We discuss relationships between conceptions of assessment, approaches to classroom instruction and assessment as conceptualised from an Achievement Goal Theory perspective.},
  keywords = {Academic Achievement,Accountability,approaches to instruction,classroom assessment,Conceptions of assessment,Correlation,Education & Educational Research,Educational psychology,Elementary School Teachers,Factor Analysis,Foreign Countries,Goal Orientation,Instructional Improvement,Mastery Learning,Motivation,Online Surveys,pre-service teachers,Preservice Teachers,Psychology,Psychology Educational,Regression (Statistics),Research Universities,Secondary School Teachers,Social Sciences,Student Evaluation,Student teachers,Teacher Attitudes,Teacher education,Teaching Methods}
}

@article{danielUsingTACTFramework2019,
  title = {Using the {{TACT Framework}} to {{Learn}} the {{Principles}} of {{Rigour}} in {{Qualitative Research}}},
  author = {Daniel, Ben K.},
  year = {2019},
  month = sep,
  journal = {Electronic Journal of Business Research         Methods},
  volume = {17},
  number = {3},
  issn = {1477-7029},
  doi = {10/gmcttz},
  urldate = {2021-07-31},
  abstract = {Assessing the quality of qualitative research to ensure rigour in the findings is critical, especially if findings are to contribute to theory and be utilised in practice. However, teaching students concepts of rigour and how to apply them to their research is challenging. This article presents a generic framework of rigour with four critical dimensions---Trustworthiness, Auditability, Credibility and Transferability (TACT) intended to teach issues of rigour to postgraduate students and those new to qualitative research methodology. The framework enables them to explore the key dimensions necessary for assessing the rigour of qualitative research studies and checklist questions against each of the dimensions. TACT was offered through 10 workshops, attended by 64 participants. Participants positively evaluated the workshops and reported that the workshops enable them to learn the principles of qualitative research and better understanding issues of rigour. Work presented in the article is part of a large research programme investigating the pedagogy of research methods in higher education.},
  file = {/Users/colin.madland/Zotero/storage/96PUQMNU/danielUsingTACTFramework2019.pdf}
}

@article{Dann_2019,
  title = {Feedback as a Relational Concept in the Classroom},
  author = {Dann, Ruth},
  year = {2019},
  journal = {Curriculum Journal},
  doi = {10/ghhtsp},
  abstract = {AbstractThis paper constructs a theoretical argument to frame feedback as a relational concept. It addresses contemporary concern that formative assessment, of which feedback is a part, is under th...},
  mag_id = {2959258001},
  pmcid = {null},
  pmid = {null},
  keywords = {guskey}
}

@article{dannMobileDevicesContribute2020a,
  title = {Mobile Devices Contribute to Feedback Processes},
  author = {Dann, Beverly},
  year = {2020},
  journal = {null},
  doi = {10/ghp9cn},
  abstract = {N/A: no abstract available},
  pmcid = {null},
  pmid = {null}
}

@book{dannTechnologyEnhancedFormativeAssessment2019,
  title = {Technology-{{Enhanced Formative Assessment Practices}} in {{Higher Education}}},
  author = {Dann, Christopher Ewart and O'Neill, Shirley},
  year = {2019},
  publisher = {IGI Global},
  address = {Hershey},
  abstract = {Considering the permeation of various mobile and internet technologies into daily life, their extension into the context of learning and work is unsurprising. With a global push in universities to blend and deepen their learning and delivery methods, effective application of mobile and internet technologies is essential for the promotion of student success. Technology-Enhanced Formative Assessment Practices in Higher Education is a comprehensive scholarly book that aims to explore the current impact of mobile technologies and the use of video capture via mobile devices on the learning and assessment of students in higher education, particularly where practical performance examples of their work are required as evidence of attaining competence. Featuring a wide range of topics such as course development, teacher evaluation, and higher education, this book is ideal for deans, educators, academicians, educational administrators, curriculum developers, researchers, students, and higher education professionals.},
  isbn = {1-7998-0426-7},
  keywords = {Computer-assisted instruction,Education Higher-Effect of technological innovations on,Educational tests and measurements,Mobile communication systems in education}
}

@book{dannTechnologyEnhancedFormativeAssessment2020,
  ids = {dannTechnologyEnhancedFormativeAssessment2019,dannTechnologyenhancedFormativeAssessment2020},
  title = {Technology-{{Enhanced Formative Assessment Practices}} in {{Higher Education}}:},
  shorttitle = {Technology-{{Enhanced Formative Assessment Practices}} in {{Higher Education}}},
  editor = {Dann, Christopher Ewart and O'Neill, Shirley and Keengwe, Jared},
  year = {2020},
  series = {Advances in {{Higher Education}} and {{Professional Development}}},
  publisher = {IGI Global},
  doi = {10.4018/978-1-7998-0426-0},
  urldate = {2022-08-17},
  isbn = {978-1-7998-0426-0 978-1-7998-0427-7},
  keywords = {Computer-assisted instruction,Education Higher -- Effect of technological innovations on,Education Higher-Effect of technological innovations on,Educational tests and measurements,Electronic books,Mobile communication systems in education},
  file = {/Users/colin.madland/Zotero/storage/NUGZC23E/dannTechnologyEnhancedFormativeAssessment2020.pdf}
}

@book{darbySmallTeachingOnline2019,
  title = {Small Teaching Online: Applying Learning Science in Online Classes},
  shorttitle = {Small Teaching Online},
  author = {Darby, Flower and Lang, James M.},
  year = {2019},
  edition = {First edition},
  publisher = {Jossey-Bass},
  address = {San Francisco, CA},
  abstract = {"BUILDS OFF OUR PREVIOUS SUCCESS: Small Teaching (9781118944493, February 2016) has sold 27,498 units life-to-date. We are building off of our success with that title to address the specific challenges that online instructors face in higher education. Author James Lang is partnering with eLearning expert Flower Darby to write and promote the book. RAPIDLY GROWING SEGMENT OF STUDENT POPULATION: According to the Online Learning Consortium, in 2016, 5.8 million students were enrolled in at least one online course. This represents a 263\% increase over the last decade. Two-thirds of these 5.8 million students take online courses through public institutions. ONLINE LEARNING IS PREFERRED BY TODAY'S LEARNER: The Online Learning Consortium study also shows that 90\% of today's student believes online learning is as good as or better than the traditional classroom experience. INCREASED ENGAGEMENT WITH EDTECH: A survey of university Chief Information Officers shows that 96\% believe adaptive technology has potential to improve student outcomes, while 87\% believe technology provides a richer experience for students. Students agree, except that 4 out of 5 would also say universities should be doing more with technology-based learning experiences. This book will help higher education instructors do that"--},
  isbn = {978-1-119-61909-3},
  lccn = {LB1028.5 .D322 2019},
  keywords = {Computer-assisted instruction,Internet in education,Learning Psychology of,Motivation in education}
}

@article{darling-hammondPoliciesThatSupport1995,
  title = {Policies That Support Professional Development in an Era of Reform},
  author = {{Darling-Hammond}, Linda and McLaughlin, Milbrey W.},
  year = {1995},
  journal = {Phi Delta Kappan},
  volume = {76},
  number = {8},
  abstract = {The situation-specific nature of the kind of teaching and learning envisioned by school reformers is the key challenge for teachers' professional development, and it is the chief obstacle to policy makers' efforts to engender systemic reform. Some design principles to guide those who are struggling with this issue are discussed.},
  keywords = {Development,Education,making,policy,PROFESSIONAL,reform,Teacher},
  file = {/Users/colin.madland/Zotero/storage/XXKZ3TGC/darling-hammondPoliciesThatSupport1995.pdf}
}

@article{darnisCooperativeLearningDyadic2013,
  title = {Cooperative Learning and Dyadic Interactions: Two Modes of Knowledge Construction in Socio-Constructivist Settings for Team-Sport Teaching},
  author = {Darnis, Florence and Lafont, Lucile},
  year = {2013},
  month = jun,
  journal = {Physical Education and Sport Pedagogy},
  pages = {1--15},
  issn = {1740-8989},
  doi = {10.1080/17408989.2013.803528},
  urldate = {2014-09-06},
  abstract = {Background: Within a socio-constructivist perspective, this study is situated at the crossroads of three theoretical approaches. First, it is based upon team sport and the tactical act model in games teaching. Second, it took place in dyadic or small group learning conditions with verbal interaction. Furthermore, these interventions were based on cooperative learning (CL) models. The cultural context is the French school curriculum, so it emphasizes the role of sports as social practice and uses the applied concept of French didactic transposition. It took place in a socio-constructivist perspective of the teaching-learning process and extends the notion of debate-of-idea. Purpose: This article explores the role of CL in a Physical Education (PE) classroom setting and particularly the role of verbal exchanges among peers in team-sport teaching. Research design: This article reports two interventions. The first study showed the positive effects of discussions within a team in an adapted basketball game. Seventeen boys and 13 girls from a French school (third and fourth grades), all novices in basketball, were assigned to two independent groups of a two (Learning condition) design. Dependent measures included collective game efficacy and individual skill levels. A second study concerned an instructional setting of a handball team game (two attackers against a defender in each half of the ground) with 11?12-year-old girls. Two groups were constituted by learning condition: symmetrical versus dissymmetrical dyads. Data collection and analysis: During PE lessons, verbal interactions were filmed and recorded for the two studies. Matches were filmed in study 1, while data in study 2 were collected by an expert on an observation worksheet. ANOVA were conducted in both studies. Results: The two studies showed that oral discussions between peers about the goal and the strategies of the game facilitated the development of motor and tactical skills. The second study showed the superiority of a slightly dissymmetric dyadic condition. The low-skilled pupils in dissymmetrical dyads obtained more benefit from the verbal interactions than those in a symmetrical setting. In the dissymmetrical condition, while the initially low-skilled participants had the highest rate of progression, the initially high-skilled players had to explain their solution and could also benefit from the dyadic interaction. Conclusion: In both studies, action rules were constructed by peers' verbal exchanges in a reflective way. In a PE socio-constructivist setting, the teaching of games facilitates mutual aid, social relationships, and participation in community activities.}
}

@article{dashtestaniOnlineCoursesHigher2020,
  title = {Online {{Courses}} in {{Higher Education}} in {{Iran}}: {{A Stakeholder-Based Investigation}} into {{Preservice Teachers}}' {{Acceptance}}, {{Learning Achievements}}, and {{Satisfaction--A Mixed-Methods Study}}},
  author = {Dashtestani, Reza},
  year = {2020},
  journal = {International Review of Research in Open and Distributed Learning},
  volume = {21},
  number = {4},
  pages = {117--142},
  issn = {EISSN-1492-3831},
  doi = {10/gmbv27},
  abstract = {This study focused on the perspectives of higher education stakeholders on teaching English as a foreign language (TEFL) in online courses in Iran, as well as preservice teachers' learning achievements in online courses. Three cohorts of participants were included in the study: preservice teachers of TEFL (n = 104), TEFL university instructors (n = 23), and heads of TEFL departments (n = 10). Data was collected using a questionnaire and semi-structured interviews. The Kruskal Wallis test was used to detect differences among participants' perspectives. Preservice teachers' mid-term and final scores in the online courses were also compared. Results show significant differences among the perspectives of the three participant groups regarding online courses. The preservice teachers appeared to have relatively positive attitudes about online learning, while the university instructors and department heads showed lower levels of satisfaction with this medium. Participants identified several challenges in online learning, including lack of rigor in online courses, lack of credibility of course certificates, lack of technological infrastructures, technical problems, lack of practical content in the lessons, lack of human interaction, students' low knowledge of the content, and employers' lack of interest in employing graduates of online courses. Participants also noted the need for pedagogical and technological training for both university instructors and preservice teachers of TEFL. The comparison of preservice teachers' mid-term and final scores in the online courses showed a significant difference and improvement in students' learning achievements with medium to large effect sizes. In the interviews, participants confirmed that online courses could improve student learning.},
  langid = {english},
  keywords = {Academic Achievement,Affordances,Barriers,Department Heads,Educational Needs,Electronic Learning,English (Second Language),Foreign Countries,Graduate Students,Online Courses,Preservice Teachers,Satisfaction,Second Language Instruction,Stakeholders,Teacher Educators}
}

@article{dattaTraditionalStorytellingEffective2017,
  title = {Traditional Storytelling: An Effective {{Indigenous}} Research Methodology and Its Implications for Environmental Research},
  author = {Datta, Ranjan},
  year = {2017},
  journal = {AlterNative: An International Journal of Indigenous Peoples},
  volume = {14},
  number = {1},
  pages = {35--44},
  issn = {1177-1801},
  doi = {10.1177/1177180117741351},
  urldate = {2019-02-16},
  abstract = {Using traditional Western research methods to explore Indigenous perspectives has often been felt by the Indigenous people themselves to be inappropriate and ineffective in gathering information and promoting discussion. On the contrary, using traditional storytelling as a research method links Indigenous worldviews, shaping the approach of the research; the theoretical and conceptual frameworks; and the epistemology, methodology, and ethics. The aims of this article are to (a) explore the essential elements and the value of traditional storytelling for culturally appropriate Indigenous research; (b) develop a model of a collaborative community and university research alliance, looking at how to address community concerns and gather data that will inform decision-making and help the community prepare for the future; (c) build up and strengthen research capacity among Indigenous communities in collaboration with Indigenous Elders and Knowledge-holders; and (d) discuss how to more fully engage Indigenous people in the research process. In two case studies with Indigenous and immigrant communities in Canada and Bangladesh that are grounded in the relational ways of participatory action research, the author found that traditional storytelling as a research method could lead to culturally appropriate research, build trust between participants and researcher, build a bridge between Western and Indigenous research, and deconstruct meanings of research. The article ends with a discussion of the implications of using traditional storytelling in empowering both research participants and researcher.}
}

@phdthesis{daveyItWillNever2019,
  type = {{{MEd}}},
  title = {``{{It}} Will Never Be My First Choice to Do an Online Course'' {{Examining Experiences}} of {{Indigenous Learners Online}} in {{Canadian Post-Secondary Educational Institutions}}},
  author = {Davey, Robline},
  year = {2019},
  address = {Kamloops, BC},
  urldate = {2022-01-19},
  abstract = {ii Abstract In the era of Truth and Reconciliation (TRC), educational administrators have a responsibility to answer the Calls to Action to transform post-secondary education, to increase access for Indigenous learners and decreasing education disparity between Indigenous and non-Indigenous learners (TRC, 2015a). If distance education is an option for expanding educational opportunities, online learning environments should be scrutinized to ensure learner engagement and meaningful support for Indigenous students. This thesis uses a Community of Inquiry (CoI) (Garrison, Anderson \& Archer, 2000) framework to examine existing literature and to frame the voices of 21 Indigenous participants about their experiences of supports, preferences, and online best practices. By exploring, understanding and incorporating what may be unique preferences, cultures, languages, worldviews, and ways of knowing, mechanisms to transform distance learning environments to improve engagement for Indigenous students can be identified. With the aim of synthesizing potential findings with online best practices, it may be possible to transform online delivery and development to provide a rich educational experience for students.},
  school = {Thompson Rivers University},
  file = {/Users/colin.madland/Zotero/storage/SBNUCLJA/daveyItWillNever2019.pdf}
}

@misc{davidkestenbaumHowCollegeStudents,
  title = {How {{College Students Battled Textbook Publishers To A Draw}}, {{In}} 3 {{Graphs}}},
  author = {{David Kestenbaum}},
  urldate = {2018-08-02},
  abstract = {The price of new textbooks has gone through the roof. But what students spend on books has barely budged.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/MW3ZCI6J/how-college-students-battled-textbook-publishers-to-a-draw-in-3-graphs.html}
}

@article{daviesCoherenceDisparityAssessment2018,
  title = {Coherence and {{Disparity}} in {{Assessment Literacies}} among {{Higher Education Staff}}},
  author = {Davies, Mark S. and Taras, Maddalena},
  year = {2018},
  journal = {London Review of Education},
  volume = {16},
  number = {3},
  pages = {474--490},
  issn = {EISSN-1474-8479},
  abstract = {Assessment literacies are finding leverage, but there is little exploration of links between theory, practice and perceived understandings in higher education (HE). This article builds on and consolidates research that has taken place over ten years that evaluates assessment literacies among HE lecturers in education and science, and in staff developers, by presenting a comparative view of the data. The results indicate that there was generally a good understanding of theoretical and practical aspects of summative assessment across all groups. However, understandings of formative assessment showed little concordance between and within the groups, particularly among staff developers, but this group was better at clarifying the necessary link between formative assessment and feedback. Although education lecturers had a firmer grasp of central terminologies, in general there are still deficits in understanding about how these terms interrelate. Staff developers' relative weakness of understanding in some areas is of concern since this group shapes those who teach. These issues are exacerbated by a lack of acknowledgement that they exist, which may seriously hamper the development of both staff and students in clarifying processes they encounter daily. Basic shared understandings are required that can translate into personal, coherent assessment literacies. As a community we need to take on this task, because if we do not, as individuals, or individual groups, we will continue to have fragmented assessment literacies.},
  langid = {english},
  keywords = {College Faculty,Definitions,Evaluation,Evaluation Methods,Foreign Countries,Formative Evaluation,No DOI found,Staff Development,Summative Evaluation,Theories,Theory Practice Relationship}
}

@misc{davisColinmadlandTheNotoriousRBFPatvatar2021,
  type = {Tweet},
  title = {@colinmadland @{{TheNotoriousRBF}} @patvatar @{{NotAFile}} @taintedavenue @chochosmx @{{Twitter}} {{https://t.co/m9UK0mXWQ2}}},
  author = {Davis, Dantley [@dantley]},
  year = {2021},
  month = may,
  journal = {Twitter},
  urldate = {2022-10-17},
  file = {/Users/colin.madland/Zotero/storage/APY2WDIR/1390789795408842752.html}
}

@book{davisComplexityEducation2014,
  title = {Complexity and {{Education}}},
  author = {Davis, Brent and Sumara, Dennis},
  year = {2014},
  month = jun,
  publisher = {Routledge},
  doi = {10.4324/9780203764015},
  urldate = {2022-07-31},
  isbn = {978-1-134-81578-4},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/66FC44XX/davisComplexityEducation2014.pdf}
}

@article{davisPerceivedUsefulnessPerceived1989,
  title = {Perceived {{Usefulness}}, {{Perceived Ease}} of {{Use}}, and {{User Acceptance}} of {{Information Technology}}},
  author = {Davis, Fred D.},
  year = {1989},
  month = sep,
  journal = {MIS Quarterly},
  volume = {13},
  number = {3},
  eprint = {249008},
  eprinttype = {jstor},
  pages = {319},
  issn = {02767783},
  doi = {10.2307/249008},
  urldate = {2022-11-27},
  file = {/Users/colin.madland/Zotero/storage/UG2VI5G8/davisPerceivedUsefulnessPerceived1989.pdf}
}

@misc{davisTheNotoriousRBFAdrian_cademPatvatar2020,
  type = {Tweet},
  title = {@{{TheNotoriousRBF}} @adrian\_cadem @patvatar @{{NotAFile}} @taintedavenue @chochosmx @colinmadland @{{Twitter It}}'s 100\% Our Fault. {{No}} One Should Say Otherwise. {{Now}} the next Step Is Fixing It.},
  author = {Davis, Dantley [@dantley]},
  year = {2020},
  month = sep,
  journal = {Twitter},
  urldate = {2022-10-17},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/EWJ8E44H/1307432466441859072.html}
}

@misc{davisTheNotoriousRBFPatvatarNotAFile2021,
  type = {Tweet},
  title = {@{{TheNotoriousRBF}} @patvatar @{{NotAFile}} @taintedavenue @chochosmx @colinmadland @{{Twitter Fix}}'t},
  author = {Davis, Dantley [@dantley]},
  year = {2021},
  month = may,
  journal = {Twitter},
  urldate = {2022-10-17},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/ZSW4B6MC/1390686813321261060.html}
}

@misc{Davos2019Press,
  title = {Davos 2019 - {{Press Conference The Value}} of {{Digital Identity}} for the {{Global Economy}} and {{Society}}},
  publisher = {World Economic Forum}
}

@article{dawsonAssessmentMightDictate2013,
  title = {Assessment {{Might Dictate}} the {{Curriculum}}, but {{What Dictates Assessment}}?},
  author = {Dawson, Phillip and Bearman, Margaret and Boud, Daniel and Hall, Matt and Molloy, Elizabeth and Bennett, Sue and Joughin, Gordon},
  year = {2013},
  month = mar,
  journal = {Teaching \& Learning Inquiry The ISSOTL Journal},
  volume = {1},
  number = {1},
  pages = {107--111},
  issn = {21674787},
  doi = {10.20343/teachlearninqu.1.1.107},
  urldate = {2022-11-28},
  file = {/Users/colin.madland/Zotero/storage/TZP9XX9L/dawsonAssessmentMightDictate2013.pdf}
}

@article{dawsonAssessmentRubricsClearer2017,
  title = {Assessment Rubrics: Towards Clearer and More Replicable Design, Research and Practice},
  shorttitle = {Assessment Rubrics},
  author = {Dawson, Phillip},
  year = {2017},
  month = apr,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {42},
  number = {3},
  pages = {347--360},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2015.1111294},
  urldate = {2024-04-19},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/WWCHKLT2/dawsonAssessmentRubricsClearer2017.pdf}
}

@article{dawsonAuthenticFeedbackSupporting2021,
  title = {Authentic {{Feedback}}: {{Supporting Learners}} to {{Engage}} in {{Disciplinary Feedback Practices}}},
  author = {Dawson, Phillip and Carless, David and Lee, Pamela Pui Wah},
  year = {2021},
  month = jan,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {46},
  number = {2},
  pages = {286--296},
  publisher = {Assessment \& Evaluation in Higher Education},
  issn = {0260-2938},
  abstract = {How can learners be supported to engage productively in the kinds of feedback practices they may encounter after they graduate? This article introduces a novel concept of authentic feedback to denote processes which resemble the feedback practices of the discipline, profession or workplace. Drawing on the notion of authentic assessment, a framework for authentic feedback is proposed with five dimensions: realism, cognitive challenge, affective challenge, evaluative judgement and enactment of feedback. This framework is exemplified and interrogated through two cases of authentic feedback practice, one in the subject of digital media in an Australian university, the other focussed on bedside rounds in medicine at a university in Hong Kong. The framework enables the identification of both highly authentic aspects of feedback, and aspects that could be made more authentic. The framework informs the design of feedback practices that carry the potential to bridge university and workplace environments.},
  keywords = {Affective Behavior,Australia,Cognitive Ability,College Faculty,Computer Assisted Instruction,Computer Software,Decision Making,Difficulty Level,Feedback (Response),Foreign Countries,Guidelines,Hong Kong,Hospitals,Information Science Education,Information Technology,Introductory Courses,Medical Education,Multiple DOI,Patients,Pediatrics,Performance Based Assessment,Social Media,Student Evaluation,Teacher Student Relationship,Teaching Methods,Undergraduate Students}
}

@incollection{dawsonCognitiveOffloadingAssessment2020,
  title = {Cognitive {{Offloading}} and {{Assessment}}},
  booktitle = {Re-Imagining {{University Assessment}} in a {{Digital World}}},
  author = {Dawson, Phillip},
  editor = {Bearman, Margaret and Dawson, Phillip and Ajjawi, Rola and Tai, Joanna and Boud, David},
  year = {2020},
  volume = {7},
  pages = {37--48},
  publisher = {Springer International Publishing},
  address = {Cham},
  urldate = {2022-03-19},
  abstract = {Cognitive offloading refers to using tools like notes, calculators or spellcheckers to reduce the cognitive demands of a task. Assessment has a patchy history in attending to cognitive offloading. In some settings, such as exams, there are explicit rules that relate to cognitive offloading, such as the allowance or prohibition of textbooks and notes. However in other settings, particularly authentic open-ended tasks there is less clarity. This chapter proposes principles for incorporating cognitive offloading into assessment, with a focus on transparency, programmatic assessment, evaluative judgement and authentic assessment.},
  isbn = {978-3-030-41955-4 978-3-030-41956-1},
  langid = {english},
  keywords = {archived},
  file = {/Users/colin.madland/Zotero/storage/T62IJI4C/dawsonCognitiveOffloadingAssessment2020.pdf}
}

@incollection{dawsonConcludingCommentsReimagining2020,
  title = {Concluding {{Comments}}: {{Reimagining University Assessment}} in a {{Digital World}}},
  shorttitle = {Concluding {{Comments}}},
  booktitle = {Re-Imagining {{University Assessment}} in a {{Digital World}}},
  author = {Dawson, Phillip and Bearman, Margaret},
  editor = {Bearman, Margaret and Dawson, Phillip and Ajjawi, Rola and Tai, Joanna and Boud, David},
  year = {2020},
  volume = {7},
  pages = {291--296},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-41956-1_20},
  urldate = {2022-03-19},
  isbn = {978-3-030-41955-4 978-3-030-41956-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/UZ7ISQ85/dawsonConcludingCommentsReimagining2020.pdf}
}

@book{dawsonDefendingAssessmentSecurity2020,
  title = {Defending {{Assessment Security}} in a {{Digital World}}: {{Preventing E-Cheating}} and {{Supporting Academic Integrity}} in {{Higher Education}}},
  shorttitle = {Defending {{Assessment Security}} in a {{Digital World}}},
  author = {Dawson, Phillip},
  year = {2020},
  month = oct,
  edition = {1},
  publisher = {Routledge},
  address = {Abingdon, Oxon ; New York, NY : Routledge, 2021.},
  urldate = {2022-01-12},
  isbn = {978-0-429-32417-8},
  langid = {english},
  keywords = {archived},
  file = {/Users/colin.madland/Zotero/storage/2982V6M5/dawsonDefendingAssessmentSecurity2020.pdf}
}

@incollection{dawsonHowDoesTechnology2017,
  title = {How {{Does Technology Enable Scaling Up Assessment}} for {{Learning}}?},
  booktitle = {Scaling up {{Assessment}} for {{Learning}} in {{Higher Education}}},
  author = {Dawson, Phillip and Henderson, Michael},
  editor = {Carless, David and Bridges, Susan M. and Chan, Cecilia Ka Yuk and Glofcheski, Rick},
  year = {2017},
  volume = {5},
  pages = {209--222},
  publisher = {Springer Singapore},
  address = {Singapore},
  doi = {10.1007/978-981-10-3045-1_14},
  urldate = {2022-05-07},
  isbn = {978-981-10-3043-7 978-981-10-3045-1},
  file = {/Users/colin.madland/Zotero/storage/ACL3INJ5/dawsonHowDoesTechnology2017.pdf}
}

@article{dawsonPlagiarismStudentsKnow2006,
  title = {Plagiarism: {{Do Students Know What It Is}}},
  author = {Dawson, Maureen M. and Overfield, Joyce A.},
  year = {2006},
  journal = {Bioscience Education},
  volume = {8},
  pages = {1--15},
  issn = {null},
  doi = {10.3108/beej.8.1 doi: 10.3108/beej.8.1},
  abstract = {AbstractThe ability of students to plagiarise coursework assessments has been a topic of much debate in recent years. The consequences of plagiarism for students may be devastating, since their failure to learn and use appropriate study skills will affect both their university experience and their subsequent career. This project set out to investigate students? perceptions of what constitutes plagiarism. A scenario-based questionnaire was given to undergraduate bioscience students from Level 0, that is, Foundation level, to Level 3. Analysis of the completed questionnaires showed student uncertainty about several aspects of plagiarism, including downloading of material from the Internet. Students were unclear about the distinctions between collusion, plagiarism and permissible group work. Thus, despite the media attention given to plagiarism, students are not always aware of the boundaries between plagiarism and acceptable practice. Since the penalties for plagiarising may be severe, it is essential that guidelines are provided early in the programme. A case-study approach is more likely to engage the students than issuing them with a set of penalties should they be caught.As a result of these findings guidelines have been produced, aimed at addressing misconceptions. Future work is planned to adapt the exercise to an interactive format within a managed learning environment.}
}

@article{dawsonValidityMattersMore2024,
  title = {Validity Matters More than Cheating},
  author = {Dawson, Phillip and Bearman, Margaret and Dollinger, Mollie and Boud, David},
  year = {2024},
  month = aug,
  journal = {Assessment \& Evaluation in Higher Education},
  pages = {1--12},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2024.2386662},
  urldate = {2024-09-07},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/K5R84KSZ/dawsonValidityMattersMore2024.pdf}
}

@article{dawsonWhatMakesEffective2019,
  title = {What Makes for Effective Feedback: Staff and Student Perspectives},
  shorttitle = {What Makes for Effective Feedback},
  author = {Dawson, Phillip and Henderson, Michael and Mahoney, Paige and Phillips, Michael and Ryan, Tracii and Boud, David and Molloy, Elizabeth},
  year = {2019},
  month = jan,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {44},
  number = {1},
  pages = {25--36},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2018.1467877},
  urldate = {2023-03-30},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/4QL9ZUS9/dawsonWhatMakesEffective2019.pdf}
}

@article{dayUniversityTeachersConceptions2019,
  title = {University Teachers' Conceptions of Their Current and Ideal Intermediate Assessment: An {{A}}+ Is Good, but Speaking Your Mind Is Better},
  author = {Day, Indira N. Z. and {\noopsort{blankenstein}}{van Blankenstein}, F. M. and Westenberg, P. M. and Admiraal, W. F.},
  year = {2019},
  journal = {Studies in higher education (Dorchester-on-Thames)},
  volume = {44},
  number = {12},
  pages = {2223--2234},
  publisher = {Routledge},
  address = {Abingdon},
  issn = {0307-5079},
  doi = {10.1080/03075079.2018.1483326},
  abstract = {Assessment in higher education with a transformational instead of a reproductive purpose can be a powerful way of supporting student learning. Since university teachers usually design their own assessments, it is important to investigate their conceptions of assessment. The current study focuses on teachers' conceptions of their current and ideal assessment with a focus on intermediate assessment. Thirteen teachers teaching law, psychology and criminology, reflected on their current and ideal assessment in an attempt to eliminate the influence of practical constraints on assessment practice. Results indicate that the majority of teachers have transformational conceptions of their intermediate assessment practice, and in general, their conceptions of the ideal assessment are even more transformational. This suggests that teachers' main focus for assessment is on student learning and that a lack of transformational assessments in practice may be mainly caused by external constraints.},
  langid = {english},
  keywords = {Academic grading,College Faculty,Conceptions of assessment,continuous assessment,Criminology,Educational evaluation,Evaluation Methods,Feedback (Response),Formative Evaluation,Higher education,intermediate assessment,interviews,Learning,Legal Education (Professions),Psychological assessment,Psychology,Student Evaluation,Summative Evaluation,Teacher Attitudes,Teachers,Teaching,Test Format,Tests,university teachers}
}

@incollection{deboeckExplanatoryItemResponse2016,
  title = {Explanatory Item Response Models},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {De Boeck, Paul and Cho, Sun-Joo and Wilson, Mark},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch11},
  pages = {247--266},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch11},
  abstract = {Summary A promising approach to cognitive assessment is to make use of explanatory measurement, which utilizes item and person covariates to explain what is being measured and thus adds explanatory value to the measurements. The basic notions of explanatory item response models (EIRM) are explained in this chapter and three kinds of application are presented. All three applications are based on data from a spelling test and the lme4 code for model estimation is included for all three. The first application illustrates how EIRM can be used as a technology for test construction and item generation, starting from the explanation of item difficulties even when that explanation is far from perfect. The second application demonstrates how EIRM can be a basis for diagnostic assessment through the explanation of test performance based on item attributes linked with cognitive processes. The third application shows how EIRM provides us with a tool to correct ability estimates that are affected by confounding using a new dimensionality method that allows the source of confounding to vary depending on the person.},
  chapter = {11},
  isbn = {978-1-118-95658-8},
  keywords = {cognitive diagnostics,explanatory measurement,item generation,multidimensionality,test construction,unconfounding}
}

@article{debrunEvaluationFormativePeer2022,
  title = {Evaluation of a Formative Peer Assessment in Research Methods Teaching Using an Online Platform: {{A}} Mixed Methods Pre-Post Study},
  author = {De Br{\'u}n, A. and Rogers, L. and Drury, A. and Gilmore, B.},
  year = {2022},
  journal = {Nurse education today},
  volume = {108},
  pages = {105166--105166},
  publisher = {Elsevier Ltd},
  address = {EDINBURGH},
  issn = {0260-6917},
  doi = {10.1016/j.nedt.2021.105166},
  abstract = {In higher education settings, there are increasing calls to shift away from traditional summative assessment practices, such end of term written tests, to explore methods of assessing learning in alternative ways. Peer assessment has been advocated as a means of formative assessment to enhance student engagement, empowering students to take responsibility for their own learning. While there is accumulating evidence for the value of peer assessment in higher education, one cannot assume peer feedback will translate appropriately to all settings and educational contexts. This study evaluated the implementation of formative online peer assessment in a nursing and midwifery research methods module. We explored students' expectations, experiences, and ultimately the acceptability of this approach. A quantitative descriptive study. Ireland. An online survey to collate expectations and experiences of engagement in peer assessment. Scales were drawn from previous research and non-parametric tests explored changes in perceptions over time. Qualitative content analysis explored patterns evident in open-text responses. The response rate was 28\% (n~=~74) at baseline and 31\% at follow-up (n~=~81). Peer assessment was a new experience for 95\% of respondents. Students initially expressed apprehension, perceiving the task as daunting, and doubting their ability to provide feedback to peers. However, through providing instruction and tools to support students in the activity, high levels of satisfaction with the process and the experience were reported. Significant differences in perceptions of peer assessment were evident over time, including an enhanced belief that respondents had the requisite skills to appraise the work of their peers. In sum, nursing and midwifery students agreed that peer assessment was a valuable learning experience as part of research methods training and critical skills development.},
  keywords = {Academic assessment,Anxiety,Assessment practices,Clinical Competence,Content analysis,Education & Educational Research,Education Scientific Disciplines,Evaluation,Feedback,Formative assessment,Higher education,Humans,Learning,Life Sciences & Biomedicine,Methodology,Methods,Midwifery,Nursing,Peer assessment,Peer Group,Peer Review,Peers,Perceptions,Research methodology,Response rates,Science & Technology,Skill development,Social Sciences,Students,Teaching,Teaching methods}
}

@article{debuseBenefitsDrawbacksComputerBased2016,
  title = {Benefits and {{Drawbacks}} of {{Computer-Based Assessment}} and {{Feedback Systems}}: {{Student}} and {{Educator Perspectives}}},
  author = {Debuse, Justin C. W. and Lawley, Meredith},
  year = {2016},
  month = mar,
  journal = {British Journal of Educational Technology},
  volume = {47},
  number = {2},
  pages = {294--301},
  publisher = {British Journal of Educational Technology},
  issn = {0007-1013},
  doi = {10.1111/bjet.12232},
  abstract = {Providing students with high quality feedback is important and can be achieved using computer-based systems. While student and educator perspectives of such systems have been investigated, a comprehensive multidisciplinary study has not yet been undertaken. This study examines student and educator perspectives of a computer-based assessment and feedback system at undergraduate and postgraduate levels across a range of disciplines, course sizes and educator experience levels. The results suggest that students and educators may enjoy quality, efficiency and quantity benefits from such an approach, without the drawbacks of low personalisation and specificity identified within the literature. Time and effort are, however, required by educators for training and installation. Thus, workload and training allowances are recommended for practitioners, particularly for large courses where group assignments require highly personalised feedback.},
  keywords = {Computer Assisted Instruction,Computer Assisted Testing,Computer Uses in Education,Educational Benefits,Feedback (Response),Graduate Students,Graduate Study,Higher Education,Influence of Technology,Information Systems,Outcomes of Education,Student Attitudes,Teacher Attitudes,Teacher Student Relationship,Teaching Methods,Undergraduate Students,Undergraduate Study}
}

@article{decuypereIntroductionCriticalStudies2021,
  title = {Introduction: {{Critical}} Studies of Digital Education Platforms},
  shorttitle = {Introduction},
  author = {Decuypere, Mathias and Grimaldi, Emiliano and Landri, Paolo},
  year = {2021},
  month = jan,
  journal = {Critical Studies in Education},
  volume = {62},
  number = {1},
  pages = {1--16},
  issn = {1750-8487, 1750-8495},
  doi = {10.1080/17508487.2020.1866050},
  urldate = {2022-03-20},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/4GM7F738/decuypereIntroductionCriticalStudies2021.pdf}
}

@article{decuypereOpenEducationPlatforms2019,
  title = {Open {{Education}} Platforms: {{Theoretical}} Ideas, Digital Operations and the Figure of the Open Learner},
  shorttitle = {Open {{Education}} Platforms},
  author = {Decuypere, Mathias},
  year = {2019},
  month = jul,
  journal = {European Educational Research Journal},
  volume = {18},
  number = {4},
  pages = {439--460},
  issn = {1474-9041, 1474-9041},
  doi = {10.1177/1474904118814141},
  urldate = {2022-06-28},
  abstract = {Open Education (OE), a generic term for a collection of practices that seek to broaden the access to education through digital means, has gained increasing traction and popularity over the last years and from various corners, both globally and in European circles. Rather than taking the technologies OE makes use of at face value, this article analyzes the concrete operations that Massive Open Online Courses (MOOC) platforms perform, and more specifically the sorts of open learning and the type of open learner that are being shaped by these platforms. Understanding such platforms as active, socio-technical devices, the article first provides an overview of the conceptual milieu out of which these MOOC platforms originated. In a second part, contemporary MOOC platforms that have concretized out of this milieu are analyzed. Different types of operations that enact a very specific figure of the open learner (and types of open learning) are advanced: The open learner is increasingly being lured and made flexible, controlled and molded, communalized and responsibilized, and finally trained and empowered. The article ends with some outlines for possible future concretizations of OE and its MOOC platforms.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/6C3MKG42/decuypereOpenEducationPlatforms2019.pdf}
}

@article{decuypereResearchingEducationalApps2019,
  title = {Researching Educational Apps: Ecologies, Technologies, Subjectivities and Learning Regimes},
  shorttitle = {Researching Educational Apps},
  author = {Decuypere, Mathias},
  year = {2019},
  month = oct,
  journal = {Learning, Media and Technology},
  volume = {44},
  number = {4},
  pages = {414--429},
  issn = {1743-9884, 1743-9892},
  doi = {10.1080/17439884.2019.1667824},
  urldate = {2022-06-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/F8ELX486/decuypereResearchingEducationalApps2019.pdf}
}

@article{dedeEnablingDistributedLearning2004,
  title = {Enabling {{Distributed Learning Communities Via EmergingTechnologies}} -- {{Part Two}}},
  author = {Dede, Chris},
  year = {2004},
  journal = {T H E Journal},
  volume = {32},
  number = {3},
  pages = {16--26},
  abstract = {Focuses on the role of emerging technologies in augmented reality and ubiquitous computing interfaces in a distributed learning community. Description of a distributed learning community for students based on the emerging technology of multi-user virtual environments; Implications of a learning communities model of education for teacher education, induction and professional development; Information on learning tools created by the Milwaukee Public Schools' Professional Support Portal, an emerging design for teacher induction and retention based on a distributed learning communities model.},
  keywords = {CAREER,Development,Education,EDUCATIONAL,Effect,innovations,of,on,portals,reality,TEACHERS,technological,technology,Training,VIRTUAL,Web},
  annotation = {Accession Number: 15340044; Dede, Chris 1; Affiliations: 1 : Harvard University; Source Info: Oct2004, Vol. 32 Issue 3, p16; Thesaurus Term: EDUCATIONAL technology; Thesaurus Term: EDUCATION -- Effect of technological innovations on; Thesaurus Term: TEACHERS -- Training of; Thesaurus Term: CAREER development; Thesaurus Term: EDUCATIONAL innovations; Subject Term: VIRTUAL reality; Subject Term: WEB portals; Number of Pages: 5p; Document Type: Article; Full Text Word Count: 3191}
}

@article{dedeEnablingDistributedLearning2004a,
  title = {Enabling {{Distributed Learning Communities Via EmergingTechnologies}}--{{Part One}}},
  author = {Dede, Chris},
  year = {2004},
  journal = {T H E Journal},
  volume = {32},
  number = {2},
  pages = {12--22},
  abstract = {Focuses on illustrative implications of distributed learning strategy for teacher education, induction and professional development in the U.S. Assumptions about educational improvement; Implications of computers and telecommunication for teachers and the National Commission on Teaching and America's Future; Several dimensions of the skills teachers require to facilitate classroom-based learning communities.},
  keywords = {CAREER,Change,COMPUTERS,Development,ECOMMUNICATION,EDUCATIONAL,LEARNING,of,States,Strategies,TEACHERS,Training,United},
  annotation = {Accession Number: 15340015; Dede, Chris 1; Affiliations: 1 : Harvard University; Source Info: Sep2004, Vol. 32 Issue 2, p12; Thesaurus Term: LEARNING strategies; Thesaurus Term: TEACHERS -- Training of; Thesaurus Term: CAREER development; Thesaurus Term: EDUCATIONAL change; Thesaurus Term: COMPUTERS; Subject Term: TELECOMMUNICATION; Subject: UNITED States; Number of Pages: 5p; Illustrations: 2 Color Photographs; Document Type: Article; Full Text Word Count: 2990}
}

@article{deeleyUsingTechnologyFacilitate2018,
  title = {Using Technology to Facilitate Effective Assessment for Learning and Feedback in Higher Education},
  author = {Deeley, Susan J.},
  year = {2018},
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {43},
  number = {3},
  pages = {439--448},
  issn = {0260-2938},
  doi = {10.1080/02602938.2017.1356906},
  abstract = {The aims of this paper are to examine and critically evaluate a selection of different technological methods that were specifically chosen for their alignment with, and potential to enhance, extant assessment for learning practice. The underpinning perspectives are that: (a) both formative and summative assessment are valuable opportunities for learning, and (b) using technology may enhance learning in assessment and feedback processes. Drawing on the literature and empirical evidence from a research study in a Scottish university, the advantages and drawbacks of using technology are examined. It is asserted that, by adopting a flexible approach and taking small incremental steps, the use of different types of technology can be beneficial in facilitating effective assessment for learning and feedback in higher education.},
  keywords = {alignment,Assessment for learning,Case Studies,College Students,Education & Educational Research,Educational Technology,feedback,Feedback,Feedback (Response),Foreign Countries,Formative Evaluation,higher education,Higher Education,Learning,Partnerships in Education,Semi Structured Interviews,Service Learning,Social Sciences,Summative Evaluation,technology,Technology Uses in Education,Universities},
  file = {/Users/colin.madland/Zotero/storage/HPH75TJU/deeleyUsingTechnologyFacilitate2018.pdf}
}

@article{delangeHowCanVideoBased2020,
  title = {How {{Can Video-Based Assignments Integrate Practical}} and {{Conceptual Knowledge}} in {{Summative Assessment}}? {{Student Experiences}} from a {{Longitudinal Experiment}}},
  author = {{\noopsort{lange}}{de Lange}, Thomas and M{\o}ystad, Anne and Torgersen, Gerald},
  year = {2020},
  month = dec,
  journal = {British Educational Research Journal},
  volume = {46},
  number = {6},
  pages = {1279--1299},
  publisher = {British Educational Research Journal},
  issn = {0141-1926},
  doi = {10.1002/berj.3632},
  abstract = {This article focuses on how video assignments presenting clinical situations can be implemented in digital summative assessment to enhance the integration of practical and conceptual knowledge. The underlying perspective is that sustainable assessment should comprise evaluative practices that equip students for the challenges they will face in their future professional lives. Drawing on the literature and on empirical results of a qualitative longitudinal research study at a Norwegian university, the integrative potential and challenges of video assignments are examined. The study confirms that video-based assignments are well suited for assessing integrated competencies. However, the complexities of videos' visual displays have clear consequences that indicate how these resources should be produced. To optimise the potential of video use in enhancing sustainable summative assessment, we must strike a balance between technical accommodation, task clarity and integrative potential.},
  keywords = {Assignments,Clinical Experience,College Students,Competency Based Education,Foreign Countries,Instructional Effectiveness,Knowledge Level,Norway,Student Experience,Summative Evaluation,Theory Practice Relationship,Video Technology},
  file = {/Users/colin.madland/Zotero/storage/2IK6WIEW/delangeHowCanVideoBased2020.pdf}
}

@article{delapenaestebanWebGamificationProblem2020,
  title = {Web Gamification with Problem Simulators for Teaching Engineering},
  author = {{\noopsort{pe{\~n}a esteban}}{de la Pe{\~n}a Esteban}, F. David and Lara Torralbo, Juan A. and Lizcano Casas, David and Burgos Garc{\'i}a, Mar{\'i}a Concepci{\'o}n},
  year = {2020},
  journal = {Journal of Computing in Higher Education},
  volume = {32},
  number = {1},
  pages = {135--161},
  issn = {1042-1726, 1867-1233},
  doi = {10.1007/s12528-019-09221-2},
  urldate = {2022-11-05},
  langid = {english}
}

@article{delengExplorationElearningModel2009,
  title = {Exploration of an E-Learning Model to Foster Critical Thinking on Basic Science Concepts during Work Placements},
  author = {{\noopsort{leng}}{de Leng}, Bas A. and Dolmans, Diana H.J.M. and J{\"o}bsis, Rijn and Muijtjens, Arno M.M. and {\noopsort{vleuten}}{van der Vleuten}, Cees P.M.},
  year = {2009},
  month = aug,
  journal = {Computers \& Education},
  volume = {53},
  number = {1},
  pages = {1--13},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2008.12.012},
  abstract = {We designed an e-learning model to promote critical thinking about basic science topics in online communities of students during work placements in higher education. To determine the effectiveness and efficiency of the model we explored the online discussions in two case studies. We evaluated the quantity of the interactions by looking at quantitative data of the discussion `threads' and we evaluated the quality of the discussion by content analysis of the individual messages. Both the procedural facilitation of the discussion and the instrument for content analysis were based on Garrison's `Practical Inquiry model of Cognitive Presence'. Furthermore, we explored the experiences of the students and moderators by interviewing them and we organised their perceptions using the framework of an activity system. On the basis of the quantitative and qualitative data we conclude that the e-learning model was successful in establishing a dialogue among a group of students and an expert during work placements at different locations. The `Practical Inquiry model' was useful in facilitating a sustained on-topic discourse involving critical thinking. Although the amount of critical thinking was moderate, the results suggest ways to increase integration and resolution activities in the online discussions.},
  keywords = {Computer-mediated-communication,Cooperative/collaborative learning,Distributed learning environments,Learning communities,Pedagogical issues}
}

@incollection{delgiudiceInformationSocietyNetwork2014,
  title = {From {{Information Society}} to {{Network Society}}: {{The Challenge}}},
  shorttitle = {From {{Information Society}} to {{Network Society}}},
  booktitle = {Social {{Media}} and {{Emerging Economies}}},
  author = {Del Giudice, Manlio},
  editor = {Del Giudice, Manlio and Della Peruta, Maria Rosaria and Carayannis, Elias G.},
  year = {2014},
  pages = {71--88},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-02490-5_5},
  urldate = {2021-12-23},
  isbn = {978-3-319-02489-9 978-3-319-02490-5}
}

@article{delgobboAutomaticEvaluationOpenended2023,
  title = {Automatic Evaluation of Open-Ended Questions for Online Learning. {{A}} Systematic Mapping},
  author = {{\noopsort{gobbo}}{del Gobbo}, Emiliano and Guarino, Alfonso and Cafarelli, Barbara and Grilli, Luca and Limone, Pierpaolo},
  year = {2023},
  journal = {Studies in educational evaluation},
  volume = {77},
  pages = {101258},
  publisher = {Elsevier Ltd},
  address = {AMSTERDAM},
  issn = {0191-491X},
  doi = {10.1016/j.stueduc.2023.101258},
  abstract = {The assessment of students' performances in Higher Education is one of the essential components of teaching activities. Open-ended tasks allow a more in-depth assessment of students' learning levels, but their evaluation and grading are time-consuming and prone to subjective bias. Since the Covid-19 pandemic, most traditional Higher Education courses converted to online courses; automatic grading and feedback tools and methods (AGFTM) have become critical components of online learning systems, especially with regards to short answers and essays assessment. This work frames the recent advancement in AGFTM through a systematic mapping of the research field and a literature review. This analysis gives an overview of the trends, specific goals, methods, quality of proposals, challenges and limitations in this research area. The results indicate that it is a growing research area, with a large set of techniques involved, but still not mature, where practical implementations have yet to come. {$\bullet$}Mapping proposals on automatic grading and feedback for open-ended questions (AGFTM).{$\bullet$}A bibliometric analysis of the AGFTM literature from 2016 to 2021.{$\bullet$}The literature mapping encompasses 80 AGFTM papers from 2018 to 2021.{$\bullet$}Summary of main goals, datasets, features, methods, results and contributions.{$\bullet$}AGFTM is a promising field, but proposals are not ready for production.},
  keywords = {Automatic grading,Education & Educational Research,Educational technology,Literature review,Performance assessment in Higher Education,Psychology,Psychology Educational,Short-answer assessment,Social Sciences,Students' evaluation},
  file = {/Users/colin.madland/Zotero/storage/532LTDVU/delgobboAutomaticEvaluationOpenended2023.pdf}
}

@misc{delhiseptember22TwitterZoomFace,
  title = {Twitter and {{Zoom}} Face Backlash over Racial Algorithmic Bias},
  author = {DelhiSeptember 22, Yasmin Ahmed New and September 22, 2020UPDATED: and Ist, 2020 14:19},
  journal = {India Today},
  urldate = {2020-09-22},
  abstract = {Zoom and Twitter's AI highlight photos of people or characters with lighter skin tones, recent tweets show.},
  howpublished = {https://www.indiatoday.in/technology/news/story/twitter-and-zoom-face-backlash-over-racial-algorithmic-bias-1724174-2020-09-22},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/GLF3YWE8/twitter-and-zoom-face-backlash-over-racial-algorithmic-bias-1724174-2020-09-22.html}
}

@article{delosrios-carmenadoProposalsImprovingAssessment2016,
  title = {Proposals for {{Improving Assessment Systems}} in {{Higher Education}}: {{An Approach}} from the {{Model}} "{{Working}} with {{People}}"},
  author = {{\noopsort{r{\'i}os-carmenado}}{de los R{\'i}os-Carmenado}, I. and {Sastre-Merino}, Susana and Fern{\'a}ndez Jim{\'e}nez, Consuelo and {N{\'u}{\~n}ez del R{\'i}o}, M Cristina and Reyes Pozo, Encarnaci{\'o}n and Garc{\'i}a Arjona, Noemi},
  year = {2016},
  month = jan,
  journal = {Journal of Technology and Science Education},
  volume = {6},
  number = {2},
  pages = {104--120},
  publisher = {{Journal of Technology and Science Education}},
  issn = {2014-5349},
  doi = {10.3926/jotse.192},
  abstract = {The European Higher Education Area (EHEA) represents a challenge to university teachers to adapt their assessment systems, directing them towards continuous assessment. The integration of competence-based learning as an educational benchmark has also led to a perspective more focused on student and with complex learning situations closer to reality. However, its assessment entails an increase in lecturers' workload and a continuous demand for students due to the diversity of assessment tests required to assess each aspect of competences. After a period in which those changes have been introduced, the Technical University of Madrid (UPM) considered to analyse the assessment systems and the ways to improve them, at both bachelor's and master's degree programmes. The methodology used is based on the model "Working with People", which for the first time at the UPM, creates a participatory process with students and lecturers aimed at knowing their opinion and their feelings about the assessment process and the potential for improvement. Eight WWW-workshops were developed, with 32 students and 39 university teachers in total. The results indicate that the perception of students and lecturers regarding the assessment systems have many common points, as well as the need to undertake an improvement strategy for integrating actions from all three model dimensions, seeking a balance in joint work among lecturers, university administrators and students. This work has been performed within the framework of educational innovations cross-cutting project named "Analysis of the UPM Degree Programmes Evaluation Procedures and Proposal for Improvements" (EVAL{\'U}A), supported by the Educational Innovation Department.},
  keywords = {Academic Achievement,College Faculty,Competence,Competency Based Education,Educational Improvement,Educational Innovation,Foreign Countries,Grounded Theory,Higher Education,Spain (Madrid),Teaching Methods,Workshops},
  file = {/Users/colin.madland/Zotero/storage/CL3QWDBC/delosrios-carmenadoProposalsImprovingAssessment2016.pdf}
}

@misc{delucaACAIInstrumentSpecificationsND,
  title = {{{ACAI Instrument}}, {{Specifications}}, and {{Related Material}}},
  author = {DeLuca, Christopher},
  year = {ND},
  publisher = {Classroom Assessment Research Team (CART)},
  file = {/Users/colin.madland/Zotero/storage/C73529CK/delucaACAIInstrumentSpecificationsND.pdf}
}

@article{delucaApproachesClassroomAssessment2016,
  title = {Approaches to Classroom Assessment Inventory: {{A}} New Instrument to Support Teacher Assessment Literacy},
  author = {DeLuca, Christopher and {LaPointe-McEwan}, Danielle and Luhanga, Ulemu},
  year = {2016},
  journal = {Educational Assessment},
  volume = {21},
  pages = {248--266},
  doi = {10/gfgtsg},
  abstract = {Teacher assessment literacy has become a central priority across many educational systems in North America and elsewhere in response to growing accountability demands. Although many scholars have aimed to measure teacher assessment literacy, recent research has identified that current assessment literacy instruments do not fully reflect current transformations in the assessment landscape and remain predicated on dated standards for teacher classroom assessment practice. Given significant shifts in classroom assessment over the past 20 years, the purpose of this article is to construct a reliable instrument reflective of contemporary assessment practices and contexts. Specifically, this article describes our instrument development process including construct validation and reliability testing with more than 400 teachers. The result of this research is the Approaches to Classroom Assessment Inventory, which can be used by researchers and practitioners to support teacher assessment literacy in relation to the current accountability framework evident across educational systems.},
  file = {/Users/colin.madland/Zotero/storage/MUBNUSWU/delucaApproachesClassroomAssessment2016.pdf}
}

@article{delucaAssessmentLiteracyDevelopment2010,
  title = {Assessment Literacy Development: Identifying Gaps in Teacher Candidates' Learning},
  author = {DeLuca, Christopher and Klinger, D.},
  year = {2010},
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {17},
  pages = {419--438},
  doi = {10/c2cw5r},
  abstract = {As a result of the standards-based movement in education there is an increased need for teacher competency in the area of student assessment and evaluation. This study examines assessment education at one pre-service teacher education program in Ontario, Canada. Through a questionnaire administered to 288 teacher candidates, this study identified teacher candidates' perceived confidence levels in assessment practice, theory, and philosophy. These teacher candidates also provided their views towards assessment topics that it is important to include in a pre-service educational assessment course. Descriptive statistics, factor analysis, and analysis of variance were used to analyse questionnaire responses. In general, findings support the need for direct instruction in assessment with specific topics identified (e.g. reporting achievement, modifying assessments, developing constructed-response items, item reliability, validity, articulating a philosophy of assessment, etc.) as important to developing teacher assessment literacy.},
  file = {/Users/colin.madland/Zotero/storage/4DVW9RTK/delucaAssessmentLiteracyDevelopment2010.pdf}
}

@article{delucaCrossculturalComparisonGerman2020,
  title = {A Cross-Cultural Comparison of {{German}} and {{Canadian}} Student Teachers' Assessment Competence},
  author = {DeLuca, Christopher and Schneider, Christoph and Coombs, Andrew and Pozas, Marcela and Rasooli, Amirhossein},
  year = {2020},
  month = jan,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {27},
  number = {1},
  pages = {26--45},
  issn = {0969-594X, 1465-329X},
  doi = {10.1080/0969594X.2019.1703171},
  urldate = {2022-05-29},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/HP6TTLHI/delucaCrossculturalComparisonGerman2020.pdf}
}

@article{delucaCurrentStateAssessment2013,
  title = {The {{Current State}} of {{Assessment Education}}: {{Aligning Policy}}, {{Standards}}, and {{Teacher Education Curriculum}}},
  author = {DeLuca, Christopher and Bellara, Aarti},
  year = {2013},
  journal = {Journal of teacher education},
  volume = {64},
  number = {4},
  pages = {356--372},
  publisher = {SAGE Publications},
  address = {Los Angeles, CA},
  issn = {0022-4871},
  doi = {10.1177/0022487113488144},
  abstract = {In response to the existing accountability movement in the United States, a plethora of educational policies and standards have emerged at various levels to promote teacher assessment competency, with a focus on preservice assessment education. However, despite these policies and standards, research has shown that beginning teachers continue to maintain low competency levels in assessment. Limited assessment education that is potentially misaligned to assessment standards and classroom practices has been identified as one factor contributing to a lack of assessment competency. Accordingly, the purpose of this study was to analyze the alignment between teacher education accreditation policies, professional standards for teacher assessment practice, and preservice assessment course curriculum. Through a curriculum alignment methodology involving two policy documents, two professional standards documents, and syllabi from 10 Florida-based, Council for Accreditation of Teacher Education--certified teacher education programs, the results of this study serve to identify points of alignment and misalignment across policies, standards, and curricula. The study concludes with a discussion on the current state of assessment education with implications for enhancing teacher preparation in this area and future research on assessment education.},
  keywords = {Accreditation,Competency based education,Curricula,Education,Education policy,Educational accountability,Educational assessment,Educational evaluation,First year teachers,Professional standards,Study and teaching,Teacher centers,Teacher centres,Teacher education,Teacher evaluations,Teachers,Training},
  file = {/Users/colin.madland/Zotero/storage/8PS6QG2P/delucaCurrentStateAssessment2013.pdf}
}

@article{delucaDevelopingAssessmentCapable2017,
  title = {Developing Assessment Capable Teachers in This Age of Accountability},
  author = {DeLuca, Christopher and Johnson, Sandra},
  year = {2017},
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {24},
  pages = {121--126},
  doi = {10/gh5k6z},
  abstract = {Over the past two decades, a global movement towards accountability in education has emerged. This movement is marked by government demands for ever higher academic standards and commensurate student achievement throughout education systems, and the proliferation of student assessments at all levels -- classroom, district, state, national and international (Nichols \& Harris, 2016; Stobart, 2008). Accountability has become the prevailing watchword, with teacher assessment capability (and assessment literacy) now considered a fundamental competency for all educators (Popham, 2009; Xu \& Brown, 2016). Educational policies and professional standards throughout the world call for educators to integrate assessments throughout instruction to support, monitor and report on student learning, and to use summative forms of assessment to document and demonstrate achievement of educational standards (DeLuca, LaPointe-McEwan, \& Luhanga, 2016; Gotch \& French, 2014). The accountability movement is supported by educational research that confirms assessment-based teaching as a potentially effective educational strategy to improve student achievement (e.g. Black \& Wiliam, 1998; Hattie, 2009). Stressing the importance of assessment literacy, James Popham (2009, p. 4) notes `educators' inadequate knowledge in assessment can cripple the quality of education. Assessment literacy is seen as a sine qua non for today's competent educator'. Likewise, Johnson (2011, p. 121), in the context of summative assessment for system monitoring, observes that `the increasing politicisation of assessment over recent decades has strengthened [the] need for a high degree of assessment literacy among practitioners and others involved in the business of education'. DeLuca and Bellara (2013) further comment that as the landscape of educational assessment changes to include accountability mandates and standards-based teaching but also studentcentred pedagogies and student-directed assessments, `there is a continued need to shift preservice assessment education experiences that prepare teachers to embrace multiple purposes and practices of assessment in schools' (p. 367). Despite these widespread calls for assessment capable teachers, research indicates that teachers generally maintain low levels of assessment knowledge and skills, with beginning teachers particularly unprepared for assessment in schools (DeLuca \& Klinger, 2010; MacLellan, 2004). This persistent finding is unsurprising as assessment has historically been a neglected area of study in teacher education programmes, at least in Anglophone countries (La Marca, 2006; Shepard, Hammerness, Darling-Hammond, \& Rust, 2005; Stiggins, 1999; Taras, 2007). Moreover, current teacher education models maintain several challenges for supporting teacher candidates' and initial teachers' developing conceptions and practices of assessment. The often short and fragmented (i.e. on-campus versus practicum) structure of teacher education programmes, diversity of instructors and variability in their approaches to assessment, and competing learning priorities limit the consistency and prominence of effective assessment education within initial preparatory programmes (DeLuca \& Volante, 2016; Taras, 2007). Instructors' own levels of assessment capability might also, in some cases, be lacking. Once in field, and especially within their first five years, beginning teachers work to establish confidence across their practice with explicit professional learning in assessment not always accessible or available. Instead, practising teachers tend to learn about assessment through},
  file = {/Users/colin.madland/Zotero/storage/I4V64XVU/698ad648931ef3e3e6a821a6278c3e882f1c585c.pdf}
}

@article{delucaDifferentialSituatedView2019,
  title = {Toward a Differential and Situated View of Assessment Literacy: {{Studying}} Teachers' Responses to Classroom Assessment Scenarios},
  author = {DeLuca, Christopher and Coombs, A. and Macgregor, S. and Rasooli, A.},
  year = {2019},
  journal = {Frontiers in Education},
  volume = {4},
  doi = {10/gh5k63},
  abstract = {Research has consistently demonstrated that teachers' assessment actions have a significant influence on students' learning experience and achievement. While much of the assessment research to date has investigated teachers' understandings of assessment purposes, their developing assessment literacy, or specific classroom assessment practices, few studies have explored teachers' differential responses to specific and common classroom assessment scenarios. Drawing on a contemporary view of assessment literacy, and providing empirical evidence for assessment literacy as a differential and situated professional competency, the purpose of this study is to explore teachers' approaches to assessment more closely by examining their differential responses to common classroom assessment scenarios. By drawing on data from 453 beginning teachers who were asked to consider their teaching context and identify their likely actions in response to common assessment scenarios, this paper makes a case for a situated and contextualized view of assessment work, providing an empirically-informed basis for reconceptualizing assessment literacy as negotiated, situated, and differential across teachers, scenarios, and contexts. Data from survey that presents teachers with assessment scenarios are analyzed through descriptive statistics and significance testing to observe similarities and differences by scenario and by participants' teaching division (i.e., elementary and secondary). The paper concludes by considering implications for assessment literacy theory and future related research.},
  file = {/Users/colin.madland/Zotero/storage/D6DWKJAG/delucaDifferentialSituatedView2019.pdf}
}

@article{delucaEstablishingFoundationValid2013,
  title = {Establishing a Foundation for Valid Teacher Judgement on Student Learning: The Role of Pre-Service Assessment Education},
  shorttitle = {Establishing a Foundation for Valid Teacher Judgement on Student Learning},
  author = {DeLuca, Christopher and Chavez, Teresa and Cao, Chunhua},
  year = {2013},
  month = feb,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {20},
  number = {1},
  pages = {107--126},
  issn = {0969-594X, 1465-329X},
  doi = {10/gj5v98},
  urldate = {2021-05-23},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/BHLBD3N6/delucaEstablishingFoundationValid2013.pdf}
}

@article{delucaExploringAssessmentCultures2021,
  title = {Exploring Assessment across Cultures: {{Teachers}}' Approaches to Assessment in the {{U}}.{{S}}., {{China}}, and {{Canada}}},
  shorttitle = {Exploring Assessment across Cultures},
  author = {DeLuca, Christopher and Rickey, Nathan and Coombs, Andrew},
  editor = {Fai Hui, Sammy King},
  year = {2021},
  month = jan,
  journal = {Cogent Education},
  volume = {8},
  number = {1},
  pages = {1921903},
  issn = {2331-186X},
  doi = {10/gjxvc7},
  urldate = {2021-05-25},
  langid = {english},
  keywords = {latent class analysis},
  file = {/Users/colin.madland/Zotero/storage/Z74ZMILP/delucaExploringAssessmentCultures2021.pdf}
}

@article{delucaGradingPoliciesPractices2017,
  title = {Grading {{Policies}} and {{Practices}} in {{Canada}}: {{A Landscape Study}}},
  author = {DeLuca, Christopher and Braund, Heather and Valiquette, Adelina and Cheng, Liying},
  year = {2017},
  journal = {Canadian Journal for Educational Administration and Policy},
  volume = {184},
  number = {2017},
  urldate = {2021-07-08},
  abstract = {Given the longstanding role of grades in education, and their increased use for high-stakes decisions including student mobility, admission, selection, and accountability, this paper paper presents a systematic review of grading policies across all 10 Canadian provinces and 3 territories. In total, 23 policies were inductively analyzed for their articulation of (a) the purposes of grades, (b) the methods used for generating grades, and (c) the relationship between grading and formative assessment. Our analysis revealed significant areas of consistency across Canada while also highlighting important areas of variation. Implications of these findings on the value and use of grades within and across educational systems in Canada are discussed.},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/LSI73IPW/delucaGradingPoliciesPractices2017.pdf}
}

@incollection{delucaImplementingAssessmentLearning2016,
  title = {Implementing {{Assessment}} for {{Learning}} in {{Canada}}: {{The Challenge}} of {{Teacher Professional Development}}},
  shorttitle = {Implementing {{Assessment}} for {{Learning}} in {{Canada}}},
  booktitle = {Assessment for {{Learning}}: {{Meeting}} the {{Challenge}} of {{Implementation}}},
  author = {DeLuca, Christopher and Valiquette, Adelina and Klinger, Don A.},
  editor = {Laveault, Dany and Allal, Linda},
  year = {2016},
  volume = {4},
  pages = {145--160},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-39211-0_9},
  urldate = {2022-05-07},
  isbn = {978-3-319-39209-7 978-3-319-39211-0},
  file = {/Users/colin.madland/Zotero/storage/SH9Z22JK/delucaImplementingAssessmentLearning2016.pdf}
}

@incollection{delucaLeveragingTechnologyPromote2012,
  title = {Leveraging {{Technology}} to {{Promote Assessment}} for {{Learning}} in {{Higher Education}}},
  booktitle = {{{ICTs}} for {{Advancing Rural Communities}} and {{Human Development}}: {{Addressing}} the {{Digital Divide}}},
  author = {DeLuca, Christopher and McEwen, Laura April},
  editor = {Chhabra, Susheel},
  year = {2012},
  pages = {224--236},
  publisher = {IGI Global},
  address = {Hershey, PA, USA},
  doi = {10.4018/978-1-4666-0047-8.ch015},
  abstract = {Assessment for learning (AFL) is a highly effective strategy for promoting student learning, development and achievement in higher education (Falchikov, 2003; Kirby \& Downs, 2007; Nicol \& Macfarlane-Dick, 2006; Rust, Price, \& O'Donovan, 2003; Vermunt, 2005). However, since AFL relies on continuous monitoring of student progress through instructor feedback, peer collaboration, and student self-assessment, enacting AFL within large-group learning formats is challenging. This paper considers how technology can be leveraged to promote AFL in higher education. Drawing on data from students and instructors and recommendations from an external instructional design consultant, this paper documents the process of pairing technology and AFL within a large-group pre-service teacher education course at one Canadian institution. Recommendations for the improvement of the web-based component of the course are highlighted to provide practical suggestions for instructors to evaluate their own web-based platforms and improve their use of technology in support of AFL. The paper concludes with a discussion of areas for continued research related to the effectiveness of this pairing between assessment theory and technology.},
  isbn = {978-1-4666-0047-8},
  file = {/Users/colin.madland/Zotero/storage/G66BRRNM/delucaLeveragingTechnologyPromote2012.pdf}
}

@article{delucaPedagogiesPreserviceAssessment2013,
  title = {Pedagogies for Preservice Assessment Education: {{Supporting}} Teacher Candidates' Assessment Literacy Development},
  author = {DeLuca, Christopher and Chavez, Teresa and Bellara, Aarti P. and Cao, Chunhua},
  year = {2013},
  journal = {The Teacher Educator},
  volume = {48},
  pages = {128--142},
  doi = {10/drv2},
  abstract = {Despite assessment-based accountability movements throughout educational systems in the United States, teacher assessment literacy continues to be an identified area of concern. Contributing to this concern is a dearth of research on preservice assessment education including both its curricular and pedagogical approaches. The purpose of this study was to examine pedagogies that support positive changes in teacher candidates' conceptions of assessment. Drawing on open-ended questionnaire data from teacher candidate participants, this study found four explicit pedagogical constructs that teacher candidates identified as instrumental in contributing to their learning about assessment. Specifically, these constructs were: (a) perspective-building conversations, (b) praxis activities, (c) modeling, and (d) critical reflection and planning for learning. In addition to providing practical descriptive examples of each pedagogical approach, this article concludes with suggestions for future research and practice in assessment education.}
}

@article{delucaPedagogySlowSignificant2021,
  title = {Toward a Pedagogy for Slow and Significant Learning about Assessment in Teacher Education},
  author = {DeLuca, Christopher and Searle, Michelle and Carbone, Katrina and Ge, Jenny and {LaPointe-McEwan}, Danielle},
  year = {2021},
  journal = {Teaching and Teacher Education},
  volume = {101},
  pages = {103316},
  issn = {0742051X},
  doi = {10/gh7mjt},
  urldate = {2021-03-08},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/87SGWGU6/delucaPedagogySlowSignificant2021.pdf}
}

@article{delucaPoliciesProgramsPractices2019,
  title = {Policies, {{Programs}}, and {{Practices}}: {{Exploring}} the {{Complex Dynamics}} of {{Assessment Education}} in {{Teacher Education Across Four Countries}}},
  shorttitle = {Policies, {{Programs}}, and {{Practices}}},
  author = {DeLuca, Christopher and Willis, Jill and Cowie, Bronwen and Harrison, Christine and Coombs, Andrew and Gibson, Andrew and Trask, Suzanne},
  year = {2019},
  month = nov,
  journal = {Frontiers in Education},
  volume = {4},
  pages = {132},
  issn = {2504-284X},
  doi = {10/gh5k2r},
  urldate = {2021-02-25},
  file = {/Users/colin.madland/Zotero/storage/KYRZQ34S/delucaPoliciesProgramsPractices2019.pdf}
}

@article{delucaPreparingTeachersAge2012,
  title = {Preparing Teachers for the Age of Accountability: {{Toward}} a Framework for Assessment Education},
  author = {DeLuca, Christopher},
  year = {2012},
  journal = {Action in Teacher Education},
  volume = {34},
  pages = {576--591},
  doi = {10.1080/01626620.2012.730347},
  abstract = {Within the current accountability context of education in the United States and Canada, there is a clear need to educate teachers on effectively using assessments to support, measure, and communicate student learning. Despite this need, assessment has historically been a neglected area in teacher education programs with comparatively little research to support assessment education structures. Accordingly, the purpose of this article is to develop a preliminary assessment education framework as a foundation for future teacher education research and for designing theoretically informed assessment education that responds to multiple stakeholder perspectives. As a basis for this framework, three critical perspectives on assessment education are delineated (i.e., preservice policy perspective, teacher educator perspective, and teacher-candidate perspective) by reviewing current research, standards, and policies in fields of teacher education and assessment. The article concludes with recommendations for a research agenda aimed at further developing a scholarship for assessment education.},
  file = {/Users/colin.madland/Zotero/storage/9SMUTZWS/delucaPreparingTeachersAge2012.pdf}
}

@article{delucaPreparingTeachersAssessment2018,
  title = {Preparing Teachers for Assessment in Schools: {{The}} Influence of Teacher Educators},
  author = {DeLuca, Christopher and Coombs, A. and Sherman, A.},
  year = {2018},
  doi = {https://doi-org.ezproxy.library.uvic.ca/10.1007/978-981-13-2026-2_11},
  abstract = {In this chapter, we examine the influence of teacher educators on teacher candidates' learning and beliefs in educational assessment. Specifically, we aim to consider how teacher educators shape teacher candidates' readiness for classroom assessment and how they might be mediating teacher candidates' classroom experiences. Despite their potential influence, there has been limited scholarship devoted to exploring teacher educators' approaches to assessment and the direct influence these approaches have on candidates' assessment literacy. Within the current climate of accountability across schools in North America and in many other parts of the world, studying how teachers are prepared in the area of assessment is both timely and critical. In this chapter, we present data on teacher educators' approaches to assessment with consideration for how these approaches might shape teacher candidates' readiness for practice.},
  file = {/Users/colin.madland/Zotero/storage/7ANCZJPX/delucaPreparingTeachersAssessment2018.pdf}
}

@incollection{delucaProvocationMoreRadical2021,
  title = {Provocation 1: {{Towards More Radical Assessment Systems}}},
  booktitle = {Teaching {{Performance Assessments}} as a {{Cultural Disruptor}} in {{Initial Teacher Education}}: {{Standards}}, {{Evidence}} and {{Collaboration}}},
  author = {DeLuca, Christopher},
  editor = {{Wyatt-Smith}, Claire and Adie, Lenore and Nuttall, Joce},
  year = {2021},
  pages = {167--170},
  publisher = {Springer Singapore},
  address = {Singapore},
  doi = {10.1007/978-981-16-3705-6_10},
  abstract = {In Provocation 1, DeLuca proposes that the COVID-19 pandemic has provided the opportunity to pause and experience deep reflexivity to reimagine a fundamental new future for education. He suggests that in this re-imagining, the focus should turn to well-being, connections and understanding of self. DeLuca notes the imperative of socially orientated curriculum and assessment in which students work collaboratively, responding to challenge and building compassion. He asks, ``How can assessment support a curriculum of care?''. His call is to empower teachers to imagine new assessment possibilities by radically rethinking assessment theories and practices. He suggests education systems need to provide opportunities for teachers' professional learning that will equip them with the capacity to experiment and think radically to innovate assessment and to respond to the social consequences of assessments that consider students' well-being.},
  isbn = {978-981-16-3705-6},
  file = {/Users/colin.madland/Zotero/storage/5ANGGY9B/delucaProvocationMoreRadical2021.pdf}
}

@article{delucaStudentPerspectivesAssessment2018,
  title = {Student Perspectives on Assessment for Learning},
  author = {DeLuca, Christopher and {Chapman-Chin}, Allison E. A. and {LaPointe-McEwan}, Danielle and Klinger, Don A.},
  year = {2018},
  month = mar,
  journal = {The Curriculum Journal},
  volume = {29},
  number = {1},
  pages = {77--94},
  issn = {0958-5176, 1469-3704},
  doi = {10/gf4xvc},
  urldate = {2021-06-20},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/E4ATHKI5/delucaStudentPerspectivesAssessment2018.pdf}
}

@article{delucaTeacherAssessmentLiteracy2016,
  title = {Teacher Assessment Literacy: A Review of International Standards and Measures},
  author = {DeLuca, Christopher and {LaPointe-McEwan}, Danielle and Luhanga, Ulemu},
  year = {2016},
  journal = {Educational Assessment, Evaluation and Accountability},
  volume = {28},
  pages = {251--272},
  doi = {10/f828mh},
  abstract = {Assessment literacy is a core professional requirement across educational systems. Hence, measuring and supporting teachers' assessment literacy have been a primary focus over the past two decades. At present, there are a multitude of assessment standards across the world and numerous assessment literacy measures that represent different conceptions of assessment literacy. The purpose of this research is to (a) analyze assessment literacy standards from five English-speaking countries (i.e., Australia, Canada, New Zealand, UK, and USA) plus mainland Europe to understand shifts in the assessment landscape over time and across regions and (b) analyze prominent assessment literacy measures developed after 1990. Through a thematic analysis of 15 assessment standards and an examination of eight assessment literacy measures, results indicate noticeable shifts in standards over time yet the majority of measures continue to be based on early conceptions of assessment literacy. Results also serve to define the multiple dimensions of assessment literacy and yield important recommendations for measuring teacher assessment literacy.},
  file = {/Users/colin.madland/Zotero/storage/3BGGXJ3K/delucaTeacherAssessmentLiteracy2016.pdf}
}

@article{delucaTeachersApproachesClassroom2016,
  title = {Teachers' Approaches to Classroom Assessment: A Large-Scale Survey},
  author = {DeLuca, Christopher and Valiquette, Adelina and Coombs, A. and {LaPointe-McEwan}, Danielle and Luhanga, Ulemu},
  year = {2016},
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {25},
  pages = {355--375},
  doi = {10/gh5k6p},
  abstract = {Abstract Classroom assessment has become a cornerstone of today's standards-based system of education. However, recent policy developments, professional standards, and variable assessment education have led to significant variability in teachers' approaches to assessment. The primary purpose of this research was to use a new instrument predicated on recently published classroom assessment standards -- the Approaches to Classroom Assessment Inventory -- to measure teachers' (a) approaches to assessment, (b) perceived skill in current assessment tasks and responsibilities, and (c) professional learning preferences and priorities. Based on 404 teachers from across North America, this study contributes initial evidence of how teachers approach classroom assessment with respect to four dimensions: Assessment Purposes, Assessment Processes, Assessment Fairness and Measurement Theory. Results from this study point to significant differences based on career stage and previous assessment education. The study concludes with four key implications for assessment research and practice.},
  file = {/Users/colin.madland/Zotero/storage/YGNVBZDI/delucaTeachersApproachesClassroom2016.pdf}
}

@phdthesis{delucaValidatingComplexProgram2010,
  title = {Validating Complex Program Aims : Constructing a Framework for the Validation of One {{Teacher}} Education Program's Aim to Promote Inclusivity as a Fundamental Pedagogical Principle},
  author = {DeLuca, {\relax Christopher}.},
  year = {2010},
  address = {Kingston, Ont},
  abstract = {Educational programs are typically guided by complex overarching aims that demark broad expectations for program graduates. In practice, these aims tend to become operationalized into specific, measurable learning objectives, which form the basis for assessment of student learning. Research suggests that this practice limits the accuracy and validity of overarching program aims and may result in misrepresentation of student competency. This limitation is in part due to the use of traditional assumptions of measurement that operate on a validity of correspondence that is linear, singular, and value-free. Accordingly, through this research, I construct a framework for understanding the validity of complex program aims by drawing on contemporary validity theory. Specifically, I use an interpretive, argument-based approach to validation to connect, analyse, and evaluate multiple interpretations towards a program's overarching aims. Methodologically, I draw on hermeneutics to collect validity evidence for the construction of a multiple perspective validity argument. I contend that this framework for validation results in a complex articulation of the quality of program coherence between program users' interpretations of complex aims and their practices. In this dissertation, I apply this validation framework to one teacher education program and its aim to promote inclusivity as a fundamental pedagogical principle. In doing so, I provide a complex description of the multiple ways inclusivity is interpreted by diverse program users (i.e., senior program administrators, faculty members, and teacher candidates) and through various program structures. Thus in addition to articulating a validity argument for one teacher education program, this work also contributes a framework of inclusivity towards broader educational discourse.},
  isbn = {9780494803670},
  school = {Queen's University},
  keywords = {Assessment,Educational program aims,Evaluation,Hermeneutics,Validity},
  file = {/Users/colin.madland/Zotero/storage/N5HM4YSQ/delucaValidatingComplexProgram2010.pdf}
}

@article{demaraEngineeringAssessmentStrata2019,
  title = {Engineering Assessment Strata: {{A}} Layered Approach to Evaluation Spanning {{Bloom}}'s Taxonomy of Learning},
  author = {DeMara, {\relax RF} and Tian, T and Howard, W},
  year = {2019},
  journal = {Education and Information Technologies},
  volume = {24},
  number = {2},
  pages = {1147--1171},
  issn = {1360-2357},
  doi = {10.1007/s10639-018-9812-5},
  abstract = {Fostering metacognition can be challenging within large enrollment settings, particularly within STEM fields concentrating on problem-solving skills and their underlying theories. Herein, the research problem of realizing more frequent, insightful, and explicitly-rewarded metacognition activities at significant scale is investigated via a strategy utilizing a hierarchy of assessments. Referred to as the STEM-Optimal Digitized Assessment Strategy (SODAS), this targeted approach engages frequent assessment, instructor feedback, and learner self-reflection across the hierarchy of learning mechanisms comprising Bloom's Taxonomy of Learning Domains. SODAS spans this hierarchy of learning mechanisms via a progression of (i) unregulated online assessment, (ii) proctored Computer-Based Assessment (CBA), (iii) problem-based learning activities assessed in the laboratory setting, and (iv) personalized Socratic discussions of scanned scrap sheets that accompanied each learner's machine-graded formative assessments. Results of a case study integrating SODAS within a high-enrollment Mechanical Engineering Heat Transfer course at a large state university are presented for enrollment of 118 students. Six question types were delivered with lockdown proctored testing via auto-grading within the Canvas Learning Management System (LMS), along with bi-weekly laboratory activities to address the higher layers of Bloom's Taxonomy. Sample assessment formats were validated through student use and schedules of responsibilities for instructors across four tiers of assessment levels (facts, concepts, procedures, and metacognition), two testing delivery mechanisms (electronic textbook exercises and proctored CBA), and three remediation mechanisms (self-paced, score clarification, and experiment clarification), which showed that learning achievement can increase by up to 16.9\% compared to conventional assessment strategies, while utilizing comparable instructor resources and workloads.},
  langid = {english},
  keywords = {Asynchronous testing,Computer-based assessment,Degree productivity and quality,Lockdown proctored assessment,Rapid remediation,STEM education,STUDENTS,SYSTEM}
}

@article{demirCorrectionUsingOnline2020,
  title = {Correction to: {{Using}} Online Peer Assessment in an {{Instructional Technology}} and {{Material Design}} Course through Social Media},
  author = {Demir, Mehmet},
  year = {2020},
  journal = {Higher education},
  volume = {80},
  number = {4},
  pages = {801--801},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  issn = {0018-1560},
  doi = {10.1007/s10734-020-00505-6},
  abstract = {The original version of this article unfortunately requires correction with respect to the affiliation of the author.},
  keywords = {Correction,Education,Educational technology,Equipment and supplies,Higher Education,Internet,Peer assessment,Social media,Teaching,Technology}
}

@article{demirUsingOnlinePeer2018,
  title = {Using Online Peer Assessment in an {{Instructional Technology}} and {{Material Design}} Course through Social Media},
  author = {Demir, Mehmet},
  year = {2018},
  journal = {Higher education},
  volume = {75},
  number = {3},
  pages = {399--414},
  publisher = {Springer},
  address = {Dordrecht},
  issn = {0018-1560},
  doi = {10.1007/s10734-017-0146-9},
  abstract = {This study was designed to investigate the student teachers perceptions about and benefits and challenges of using Facebook as an online peer assessment tool for the student teachers' works. The study group included 24 student teachers in science education department of a state university located in the southeast region of Turkey. A case study approach of the qualitative method was employed in the research. Semi-structured interviews were conducted to collect the data. The interviews were audio recorded, and records of all the interviews were transcribed into full text in Turkish. Collected data were analyzed using an emergent coding approach. Codes, then, were categorized to constitute themes and subthemes. The findings indicated that the student teachers were able to give objective feedback on their peers' work and engaged more actively in class after participating in online peer assessment. Additionally, the students found it exciting and productive to use Facebook as a peer assessment tool in their learning. (HRK / Abstract {\"u}bernommen).},
  keywords = {Analysis,Ausland,Case Studies,Coding,College students,Computer Uses in Education,Distance learning,Education,Education & Educational Research,Educational Technology,Equipment and supplies,Evaluation,Feedback,Feedback (Response),Foreign Countries,Higher Education,Internet,Interviews,Kommunikationstechnik,Learner Engagement,Learning,Lehre,Mass media,Multimedia,Peer assessment,Peer Evaluation,Peers,Perceptions,Preservice Teachers,Qualitative Research,Science education,Sciences education,Semi Structured Interviews,Social classes,Social Media,Social networks,Social Sciences,Student,Student Attitudes,Student teachers,Students,Studium,Teachers,Teaching,Technology,Turkei},
  file = {/Users/colin.madland/Zotero/storage/UE2ZP48B/demirUsingOnlinePeer2018.pdf}
}

@article{demosthenousUseCollaborativeAssignment2020,
  title = {The {{Use}} of {{Collaborative Assignment}} in {{Online Learning Environments}}: {{The Case}} of {{Higher Education}}},
  author = {Demosthenous, George and Panaoura, Areti and Eteokleous, Nikleia},
  year = {2020},
  journal = {International Journal of Technology in Education and Science},
  volume = {4},
  number = {2},
  pages = {108--117},
  issn = {EISSN-2651-5369},
  doi = {10/gmbvzs},
  abstract = {Many studies investigated the use of collaboration at conventional teaching environment in different educational levels. The present study examines students' behavior during a collaborative assignment in an online learning environment in higher education. Data were collected by graduate students who were attending a course at a distance learning master degree program in Special Education. The developed group dynamics and students' beliefs about their role during the activity were "revealed" by their reactions to the discussion forum, their private e-mails to the instructor, their activity at the platform and their contribution on the assignment, for which the wiki tool was used. Results indicated that although students were at the same time in-service or pre-service teachers at primary and secondary education and they were expected to implement group work at their teaching, they had low self-efficacy beliefs in using it as students in online learning environment. Their major difficulties were related with their fear about possible negative consequences concerning their marks due to other members' behavior and the lack of experiences. Suggestions on how the group work and the collaborative assignment can be integrated more effectively in an online learning environment in higher education courses are discussed.},
  langid = {english},
  keywords = {Collaborative Writing,Computer Mediated Communication,Cooperative Learning,Distance Education,Electronic Learning,Graduate Students,Group Dynamics,Online Courses,Self Efficacy,Special Education,Student Attitudes,Student Participation,Writing Assignments}
}

@article{demuyakorCOVID19PandemicHigher2021,
  title = {{{COVID-19 Pandemic}} and {{Higher Education}}: {{Leveraging}} on {{Digital Technologies}} and {{Mobile Applications}} for {{Online Learning}} in {{Ghana}}},
  author = {Demuyakor, John},
  year = {2021},
  journal = {Shanlax International Journal of Education},
  volume = {9},
  number = {3},
  pages = {26--38},
  issn = {ISSN-2320-2653},
  doi = {10/gmbvz4},
  abstract = {Since mid-March 2020, educational systems worldwide and particularly Ghana were under increasing pressure to use the new Digital Technologies (DTs) and mobile applications (apps) to assist teachers in guiding students to continue with online learning activities due to the COVID-19 pandemic. The study is aimed at assessing the utilization of DTs and apps tools by students during the COVID-19 pandemic and how those technologies have affected online learning in institutions of higher education in Ghana. The researcher adopted an online survey and exploratory-based design that utilized quantitative and qualitative approaches to purposively collect data from N=784 students from three major public universities in Ghana. Also, the study applied Uses and Gratification as the theoretical basis in understanding the utilization of DTs and their possible limitations for remote learning during the peak of COVID-19 in Ghana. This study reported that the specific DMTs and mobile apps used by students in higher education for online learning are smarts phones and apps such as Class In, Zoom, Skype, and Instagram live stream. This study also revealed that Personal Learning Network (PLN) such as WhatsApp, Facebook, Twitter were also actively used by students for remote online learning. Again, the study shows that 77.1\% of students in the sampled three universities were fully aware of the DTs and apps utilized for online learning during COVID-19. Also, the findings from this study report that students in higher institutions identified unstable electricity for continuous online learning, especially for those students in rural areas, unreliable internet service, poor WiFi connections, expensive smartphones /laptops, and high cost of inter bundle as key challenges of using DMTs and mobile apps for online learning during the COVID-19 pandemic. Finally, on the perceived usefulness of DTs and mobile apps among students for online learning in higher educational institutions, the findings from this study suggest that DMT's and apps were of great benefit to students for remote online learning.},
  langid = {english},
  keywords = {Access to Computers,Barriers,College Students,Computer Oriented Programs,Costs,COVID-19,Distance Education,Educational Technology,Foreign Countries,Handheld Devices,Higher Education,Internet,Online Courses,Pandemics,Rural Areas,School Closing,Student Attitudes,Technology Uses in Education,Telecommunications,Value Judgment}
}

@article{deneenConnectingTeacherStudent2021,
  title = {Connecting Teacher and Student Assessment Literacy with Self-Evaluation and Peer Feedback},
  author = {Deneen, Christopher C. and Hoo, Hui-Teng},
  year = {2021},
  month = sep,
  journal = {Assessment \& Evaluation in Higher Education},
  pages = {1--13},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2021.1967284},
  urldate = {2021-12-09},
  langid = {english}
}

@article{deneenPatternsResistanceManaging2014,
  title = {Patterns of Resistance in Managing Assessment Change},
  author = {Deneen, Christopher and Boud, David},
  year = {2014},
  month = jul,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {39},
  number = {5},
  pages = {577--591},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2013.859654},
  urldate = {2023-04-15},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/EQ8KA2WB/deneenPatternsResistanceManaging2014.pdf}
}

@article{deneenStudentsConceptionsEportfolios2018,
  title = {Students' Conceptions of Eportfolios as Assessment and Technology},
  author = {Deneen, Christopher Charles and Brown, Gavin Thomas Lumsden and Carless, David},
  year = {2018},
  journal = {Innovations in education and teaching international},
  volume = {55},
  number = {4},
  pages = {487--496},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {1470-3297},
  doi = {10.1080/14703297.2017.1281752},
  abstract = {Student beliefs about assessment and technology play an important role in deploying technology-enabled assessments. Using eportfolios to develop and assess the achievement of curricular outcomes is a global trend, yet little research has investigated student technology and assessment perceptions around eportfolios. This paper examines the interaction of students' perceptions of technology and assessment and impact on performance. Survey data (n~=~360) was gathered from multiple faculties at one university in Hong Kong. Confirmatory factor analysis and structural equation modelling determined relationships among the two conceptual areas and as predictors of educational achievement. Results showed a positive attitude towards eportfolio use led to positive views about eportfolios as contributing to assessment for learning. Endorsing intention to actively engage with eportfolios and rejecting assessment as irrelevant contributed to a moderate, statistically significant increase in students' self-reported GPA. Implications for continued research into how eportfolios can be designed to promote learning-oriented assessment are discussed.;Student beliefs about assessment and technology play an important role in deploying technology-enabled assessments. Using eportfolios to develop and assess the achievement of curricular outcomes is a global trend, yet little research has investigated student technology and assessment perceptions around eportfolios. This paper examines the interaction of students' perceptions of technology and assessment and impact on performance. Survey data (n=360) was gathered from multiple faculties at one university in Hong Kong. Confirmatory factor analysis and structural equation modelling determined relationships among the two conceptual areas and as predictors of educational achievement. Results showed a positive attitude towards eportfolio use led to positive views about eportfolios as contributing to assessment for learning. Endorsing intention to actively engage with eportfolios and rejecting assessment as irrelevant contributed to a moderate, statistically significant increase in students' self-reported GPA. Implications for continued research into how eportfolios can be designed to promote learning-oriented assessment are discussed.;},
  langid = {english},
  keywords = {Academic Achievement,Assessment,College Students,Education & Educational Research,Education portfolios,Educational technology,Electronic Publishing,eportfolios,Foreign Countries,Formative Evaluation,Grade Point Average,higher education,Intention,Learning,Perceptions,Portfolio Assessment,Predictor Variables,Social Sciences,Student Attitudes,technology-enabled assessment}
}

@book{denisonHandbookMeasurementAssessment2017,
  title = {Handbook on {{Measurement}}, {{Assessment}}, and {{Evaluation}} in {{Higher Education}}},
  author = {Denison, Brian and Secolsky, Charles},
  year = {2017},
  publisher = {{Taylor and Francis}},
  doi = {10.4324/9781315709307},
  abstract = {In this valuable resource, well-known scholars present a detailed understanding of contemporary theories and practices in the fields of measurement, assessment, and evaluation, with guidance on how to apply these ideas for the benefit of students and institutions. Bringing together terminology, analytical perspectives, and methodological advances, this second edition facilitates informed decision-making while connecting the latest thinking in these methodological areas with actual practice in higher education. This research handbook provides higher education administrators, student affairs personnel, institutional researchers, and faculty with an integrated volume of theory, method, and application. List of Figures List of Tables Foreword Edward J. Yaw Preface: Improving Institutional Decision-Making through Educational Measurement, Assessment, and Evaluation Charles Secolsky and D. Brian Denison Acknowledgements Part I Measurement, Assessment, and Evaluation in Higher Education: Past, Present, and Future Introduction to Part I 1. The Failure of Higher Education to Follow the Standards It has Established in Methodology and Evaluation Michael Scriven 2. On Measurement in Educational Assessment Robert J. Mislevy Part II Assessment and Evaluation in Higher Education Introduction to Part II 3. Assessing the Quality of a University, Particularly Its Teaching Robert E. Stake, Gloria Contreras, and Isabel Arbes{\'u} 4. Validity Issues in Measuring Student Success Dwight L. Smith III 5. Course-Embedded Assessment: Aligning Pedagogical Practices to Enhance Student Learning Kathryne Drezek McConnell and Peter E. Doolittle 6. Implementing Undergraduate Student Learning Outcomes Assessment at the Program and Institutional Levels Thomas Judd and Bruce Keith 7. The Perennial Challenges of Accountability James C. Palmer 8. Talking About Data: The Faculty Discourse on Practice, Student Learning, and Evaluative Processes William H. Rickards 9. Benchmarking in Community Colleges Lou A. Guthrie and Jeffrey A. Seybert 10. Mixed-Methods Specialists in Action: Linking Mixed-Methods Research to Learning and Classroom Assessment Delwyn L. Harnisch, John W. Creswell, and Timothy C. Guetterman Part III Theoretical Foundations of Educational Measurement Introduction to Part III 11. The Validation of Tests in Higher Education Kurt F. Geisinger, Leslie R. Hawley, and Carina McCormick 12. Reliability Bruce Thompson and Tammi Vacha-Haase 13. Using Classical Test Theory in Higher Education David A. G. Berg, Elizabeth Schaughency, Jacques van der Meer, and Jeffrey K. Smith 14. Item Response Theory in Measurement, Assessment, and Evaluation for Higher Education Steven J. Osterlind and Ze Wang 15. Generalizability Theory in Assessment Contexts Noreen M. Webb, Richard J. Shavelson, and Jeffrey T. Steedle Part IV Testing and Assessment: Implications for Decision-Making Introduction to Part IV 16. Scaling, Norming, and Equating Michael J. Kolen and Amy B. Hendrickson 17. Setting and Validating Cut Scores for Tests Mary J. Pitoniak and Deanna L. Morgan 18. College Placement Testing of Entering Students Deanna L. Morgan 19. Admissions Testing in College and Graduate Education Rebecca Zwick 20. Closing the Accommodation Gap: New Thinking on Accessibility and Accommodations for Secondary and Postsecondary Students with Disabilities Manju Banerjee and Martha L. Thurlow Part V Test Construction and Development Introduction to Part V 21. Evidence-Centered Design and Postsecondary Assessment Geneva D. Haertel and Reina Fujii 22. Building Content and Statistical Test Specifications Tawnya Knupp and Deborah J. Harris 23. Item Analysis for Classroom Assessments in Higher Education Jerome C. Clauser and Ronald K. Hambleton 24. Computer-Based Testing in Higher Education Robert P. Dolan and Kelly S. Burling Part VI Statistical Approaches in Higher Education Measurement, Assessment, and Evaluation Introduction to Part VI 25. Issues in the Analysis of Change D. Betsy McCoach and Karen Rambo-Hernandez 26. Multilevel Linear Modeling in Higher Education Contexts Ying Lu, Sharon L. Weinberg, and Marc A. Scott 27. Statistical Modeling in Educational Research Ze Wang and Steven J. Osterlind 28. An Introduction to Bayesian Statistics with Applications for Higher Education Assessment Guili Zhang Part VII Approaches to Evaluation in Higher Education Introduction to Part VII Thomas E. Grayson 29. Program Evaluation, Performance Measures, and Evaluability Assessment in Higher Education Thomas E. Grayson 30. Naturalistic Evaluation David A. Erlandson 31. Responsive Evaluation Kelly E. Godfrey and Doreen B. Finkelstein 32. Case Studies Edith J. Cisneros-Cohernour 33. Survey Use in Academic Contexts: Considerations and Guidelines Daphna Harel and Ellen Wentland 34. Empowerment Evaluation: Linking Theories, Principles, and Concepts to Practical Steps David M. Fetterman Part VIII Approaches to Assessment in Higher Education Introduction to Part VIII 35. Rubric Development Linda Suskie 36. New Learning About Learning: An Introduction to ePortfolio Assessment Susan Kahn 37. The Role of Faculty Grading Processes in Program and General-Education Assessment Barbara E. Walvoord 38. Postsecondary Writing Assessment Peggy O'Neill and Sandra Murphy 39. Testing and Evaluation of English-Language Learners in Higher Education Young Yee Kim, James Hart, Jamal Abedi, and Alan Vanneman 40. Evaluation and Assessment in an Online Setting: The Case of Asynchronous Online Discussion Amir Hedayati Mehdiabadi and Wenhao David Huang Part IX Issues in Assessment and Evaluation in Higher Education Introduction to Part IX 41. Cognitive Flexibility Theory and the Assessment of 21st-Century Skills Rand J. Spiro, Hannah A. Klautke, Cui Cheng, and Aric Gaunt 42. Reporting Assessment Results in Higher Education April L. Zenisky and Jerold S. Laguilles 43. Presenting Learning Outcomes Assessment Results to Foster Use Staci J. Provezis and Natasha A. Jankowski 44. Revisiting Reliability and Validity in Higher Education Research and Program Evaluation Margaret D. LeCompte and Dorothy E. Aguilera-Black Bear 45. Assessment of Learning Outcomes in Higher Education: International Comparisons and Perspectives Olga Zlatkin-Troitschanskaia, Richard J. Shavelson, and Hans Anand Pant 46. Ethical Assessment and Institutional Advancement: Connecting Good Practice with the Need to Move Campuses Forward Ashley Finley About the Contributors "This updated edition of the Handbook on Measurement, Assessment, and Evaluation in Higher Education draws on a veritable `Who's Who' of experts in higher education assessment and evaluation to explain everything from terminology to technique. This comprehensive volume will be a constant desk companion of mine in the decades to come." ---Peter T. Ewell, President Emeritus, National Center for Higher Education Management Systems (NCHEMS) and Senior Fellow, National Institute for Learning Outcomes Assessment (NILOA), USA "This is the most extensive collection of research on measurement, evaluation, and assessment in higher education available. Covering a broad range of theoretical and practical topics addressed by the most knowledgeable professionals in the field, this book is essential reading for anyone working in higher education who is interested in making evidence based decisions that will benefit students and institutions." ---Linda Cook, past President, National Council on Measurement in Education, USA "This handbook is a must-have for faculty, staff, and administrators who lead assessment efforts or are involved with faculty development on their campus. The editors have brought together stellar contributors who, together, balance the practical, theoretical, and technical aspects of measurement, evaluation, and learning assessment in ways that are immediately useful." ---Monica Stitt-Bergh, President, Association for the Assessment of Learning in Higher Education, USA Charles Secolsky is on the faculty at Rockland Community College and County College of Morris, USA. D. Brian Denison is Institutional Research Analyst in the Director of Studies' Office for Champlain Regional College, Quebec, Canada .},
  isbn = {1-138-89214-9},
  keywords = {accountability,accreditation,Alan Vanneman,Amir Hedayati Mehdiabadi,Amy B. Hendrickson,April L. Zenisky,Aric Gaunt,Ashley Finley,Assessment,assessment techniques,Barbara E. Walvoord,Bruce Keith,Bruce Thompson,Carina McCormick,Charles Secolsky,classroom assessment,Cui Cheng,D. Betsy McCoach,D. Brian Denison,Daphna Harel,David A. Erlandson,David A. G. Berg,David M. Fetterman,Deanna L. Morgan,Deborah J. Harris,Delwyn L. Harnisch,Doreen B. Finkelstein,Dorothy E. Aguilera-Black Bear,Dwight L. Smith,Edith J. Cisneros-Cohernour,Educational Research,Elizabeth Schaughency,Higher Education},
  file = {/Users/colin.madland/Zotero/storage/9J2VVC84/denisonHandbookMeasurementAssessment2017.pdf}
}

@incollection{dennenCognitiveApprenticeshipEducational2004,
  title = {Cognitive {{Apprenticeship}} in {{Educational Practice}}: {{Research}} on {{Scaffolding}}, {{Modeling}}, {{Mentoring}}, and {{Coaching}} as {{Instructional Strategies}}.},
  booktitle = {Handbook of Research on Educational Communications and Technology, 2nd Ed.},
  author = {Dennen, Vanessa Paz},
  year = {2004},
  pages = {813--828},
  publisher = {Lawrence Erlbaum Associates Publishers},
  address = {Mahwah,  NJ,  US},
  abstract = {Apprenticeship is an inherently social learning method with a long history of helping novices become experts in various diverse fields. At the center of apprenticeship is the concept of more experienced people assisting less experienced ones, providing structure and examples to support the attainment of goals. However, the overall concept of learning from experts through social interactions is not one that should be relegated to vocational and trade-based training while K-12 and higher educational institutions seek to prepare students for operating in an information-based society. Cognitive apprenticeship--essentially, the use of an apprentice model to support learning in the cognitive domain--is one method that has gained respect and popularity. Scaffolding, modeling, mentoring, and coaching are all methods of teaching and learning that draw on social constructivist learning theory. As such, they promote learning that occurs through social interactions involving negotiation of content, understanding, and learner needs, and, though not the only methods, all three generally are considered forms of cognitive apprenticeship. This chapter first explores prevailing definitions and underlying theories of these teaching and learning strategies and then reviews the state of research in these areas. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  isbn = {0-8058-4145-8 (Hardcover)},
  keywords = {*Apprenticeship,*Cognitive Processes,*Constructivism,*Social Interaction,*Teaching Methods,Coaching,Imitation (Learning),Learning Theory,Mentor,Scaffolding,Social Learning},
  file = {/Users/colin.madland/Zotero/storage/HAQTZ9H2/dennenCognitiveApprenticeshipEducational2004.pdf}
}

@article{dennisBloggingPublicPedagogy2015,
  title = {Blogging as Public Pedagogy: Creating Alternative Educational Futures},
  author = {Dennis, Carol Azumah},
  year = {2015},
  journal = {International Journal of Lifelong Education},
  volume = {34},
  pages = {284--299},
  issn = {0260-1370},
  doi = {10.1080/02601370.2014.1000408 doi: 10.1080/02601370.2014.1000408},
  abstract = {In this study, I explore ?blogging?, the use of a regularly updated website or web page, authored and curated by an individual or small group, written in a conversational style, as a form of public pedagogy. I analyse blogs as pre-figurative spaces where people go to learn with/in a public sphere, through collaboration with interested others. However, my intention is not to conceptualize blogging spaces as such, but rather?having framed them in a particular way?to explore the extent to which they globalise dissent. My argument is that the blogs I explore, understood as public pedagogic spaces, cultivate voices of educational dissent. Positioning itself within the global research imagination, the study draws extensively on data generated by two blogging communities with a combined international readership in excess of 40,000 people; one of the blogs is based in the UK, written by a group of adult educators. The other is based in Canada written by a group of adult literacy practitioners. Whilst both blogs are authored, curated and carried by a named individual, as public pedagogic spaces, they are implicated in the creation of a dialogic self: a self which is developed collaboratively with/in the interests of and through a public that coalesces around them. The pedagogies associated with these spaces are argued as explicit and intentioned. The public that coalesces around them learns how to survive a global neoliberal policy nexus that is unsympathetic towards the ideals they pre-figuratively embody. In so doing, they call into being the creation of alternative educational understandings of themselves and each other in relation to policy, pedagogy and the purposes of education.}
}

@book{denzinHandbookCriticalIndigenous2008,
  title = {Handbook of Critical and Indigenous Methodologies},
  editor = {Denzin, Norman K. and Lincoln, Yvonna S. and Smith, Linda Tuhiwai},
  year = {2008},
  publisher = {Sage},
  address = {Los Angeles},
  isbn = {978-1-4129-1803-9},
  lccn = {GN345 .H364 2008},
  keywords = {Critical theory,Ethnology,Methodology,Research,Social sciences},
  annotation = {OCLC: ocn181910152}
}

@inbook{denzinHandbookCriticalIndigenous2019,
  title = {Handbook of {{Critical}} and {{Indigenous Methodologies}}},
  author = {Denzin, Norman K. and Lincoln, Yvonna S.},
  year = {2019},
  publisher = {SAGE Publications, Inc.},
  address = {Thousand Oaks, California},
  doi = {10.4135/9781483385686},
  collaborator = {{pages 1-20}}
}

@book{denzinHandbookCriticalIndigenous2019a,
  title = {Handbook of {{Critical}} and {{Indigenous Methodologies}}},
  author = {Denzin, Norman and Lincoln, Yvonna and Smith, Linda},
  year = {2019},
  publisher = {Sage Publications},
  address = {Thousand Oaks, California},
  doi = {10.4135/9781483385686}
}

@article{denzinMomentsMixedMethods2010,
  title = {Moments, {{Mixed Methods}}, and {{Paradigm Dialogs}}},
  author = {Denzin, Norman K.},
  year = {2010},
  month = mar,
  journal = {Qualitative Inquiry},
  volume = {16},
  number = {6},
  pages = {419--427},
  issn = {1077-8004},
  doi = {10.1177/1077800410364608},
  urldate = {2019-03-24},
  abstract = {I reread the 50-year-old history of the qualitative inquiry that calls for triangulation and mixed methods. I briefly visit the disputes within the mixed methods community asking how did we get to where we are today, the period of mixed-multiple-methods advocacy, and Teddlie and Tashakkori?s third methodological moment.},
  file = {/Users/colin.madland/Zotero/storage/X39T5EZ7/denzinMomentsMixedMethods2010.pdf}
}

@misc{departmentofeducationskillsandemploymentcanberraHigherEducationStandards,
  title = {Higher {{Education Standards Framework}} ({{Threshold Standards}}) 2021},
  author = {{Department of Education, Skills and Employment, Canberra}},
  urldate = {2024-01-03},
  file = {/Users/colin.madland/Zotero/storage/IMAWK6CF/F2022C00105.pdf}
}

@article{dermoEAssessmentStudentLearning2009,
  title = {E-{{Assessment}} and the Student Learning Experience: {{A}} Survey of Student Perceptions of e-Assessment: {{Student}} Perceptions of e-Assessment},
  shorttitle = {E-{{Assessment}} and the Student Learning Experience},
  author = {Dermo, John},
  year = {2009},
  month = mar,
  journal = {British Journal of Educational Technology},
  volume = {40},
  number = {2},
  pages = {203--214},
  issn = {00071013},
  doi = {10/d36k5z},
  urldate = {2021-07-27},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/L7SAI7LF/dermoEAssessmentStudentLearning2009.pdf}
}

@misc{derosaOpenPedagogy2018,
  title = {Open {{Pedagogy}}},
  author = {DeRosa, Robin and Jhangiani, Rajiv},
  year = {2018},
  month = mar,
  journal = {Open Pedagogy Notebook},
  urldate = {2018-10-15},
  abstract = {There are many ways to begin a discussion of ``Open Pedagogy.''~Although providing a framing definition might be the obvious place to start, we want to resist that for just a moment to ask a set of r{\dots}},
  howpublished = {http://openpedagogy.org/open-pedagogy/},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/HALPTPNM/open-pedagogy.html}
}

@article{derosaPedagogyTechnologyExample2015,
  title = {Pedagogy, Technology, and the Example of Open Educational Resources},
  author = {DeRosa, Robin and Robison, Scott},
  year = {2015},
  abstract = {{$\bullet$}When no meaningful relationship exists between an educational technology and pedagogy, the tool itself loses value. {$\bullet$}We should start with a vision for our courses and curricula, and then identify the technologies or strategies that can help us achieve or further develop that vision. {$\bullet$}Open educational resources provide a relevant example of how pedagogy can point toward a richer way to integrate technology into our courses and our teaching philosophies, shifting to a student-centered approach to learning.},
  keywords = {oer pedagogy remix hypothesis}
}

@article{derossiHybridSolutionsDidactics2019,
  title = {Hybrid Solutions for Didactics in Higher Education: {{An}} Interdisciplinary Workshop of '{{Visual Storytelling}}' to Develop Documentation Competences},
  author = {De Rossi, M and Restiglian, E},
  year = {2019},
  journal = {Tuning Journal for Higher Education},
  volume = {6},
  number = {2},
  pages = {391--419},
  issn = {2340-8170},
  doi = {10.18543/tjhe-6(2)-2019pp175-203},
  abstract = {The article reports on the results of a Design-Based Research path realized through a workshop about the "Visual Storytelling" (VS). The workshop aimed to develop teacher's professional competences about digital narrative documentation to be certified through the Open Badge system. The interdisciplinary design was developed according to the ICT-TPACK framework between the two courses "Methodologies, Didactics and Technologies for Teaching" and "Educational Research" in the Master's degree in Primary Teaching. 32 students were involved to deal with the documentation of some real educational experiences observed at school. They were asked to fill a semi-structured questionnaire at the end of the workshop. Other data came from a rubric used to evaluate VS products from three different points of views (students' self-assessment; university teachers; school teachers). The workshop stimulated the students to use technologies creatively, critically and reflectively to develop an authentic task realizing a VS product. According to the students' opinion, the workshop also facilitated collaborative processes as well as skills of self-assessment and the personalization of learning.},
  langid = {english},
  keywords = {assessment skills,educational design,higher education,hybrid solutions,ICT,narrative digital documentation,Teacher training},
  file = {/Users/colin.madland/Zotero/storage/7UHP58VB/derossiHybridSolutionsDidactics2019.pdf}
}

@article{deryFormingRankingTied2023,
  title = {Forming a Ranking from Tied Evaluations: A Case of an Online, Interactive Student Peer Assessment System},
  author = {Dery, Lihi},
  year = {2023},
  journal = {arXiv.org},
  publisher = {Cornell University Library, arXiv.org},
  address = {Ithaca},
  issn = {2331-8422},
  abstract = {In higher education courses, peer assessment activities are common for keeping students engaged during presentations. Defining precisely how students assess the work of others requires careful consideration. Asking the student for numeric grades is the most common method. However, students tend to assign high grades to most projects. Aggregating peer assessments, therefore, results in all projects receiving the same grade. Moreover, students might strategically assign low grades to the projects of others so that their projects will shine. Asking students to order all projects from best to worst imposes a high cognitive load on them, as studies have shown that people find it difficult to order more than a handful of items. To address these issues, we propose a novel peer rating model consisting of (a) an algorithm that elicits student assessments and (b) a protocol for aggregating grades to produce a single order. The algorithm asks students to evaluate projects and answer pairwise comparison queries. These are then aggregated into a ranking over the projects. An application based on our model was deployed and tested in a university course and showed promising results, including fewer ties between alternatives and a significant reduction in the communication load on students. These results indicate that the model provides a simple, accurate, and efficient approach to peer review.},
  keywords = {Agglomeration,Algorithms,Evaluation,No DOI found,Ranking,Students,Voters}
}

@article{deschenesRecommenderSystemsSupport2020,
  title = {Recommender Systems to Support Learners' {{Agency}} in a {{Learning Context}}: A Systematic Review},
  author = {Desch{\^e}nes, Michelle},
  year = {2020},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {17},
  number = {1},
  pages = {1--23},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-020-00219-w},
  abstract = {Recommender systems for technology-enhanced learning are examined in relation to learners' agency, that is, their ability to define and pursue learning goals. These systems make it easier for learners to access resources, including peers with whom to learn and experts from whom to learn. In this systematic review of the literature, we apply an Evidence for Policy and Practice Information (EPPI) approach to examine the context in which recommenders are used, the manners in which they are evaluated and the results of those evaluations. We use three databases (two in education and one in applied computer science) and retained articles published therein between 2008 and 2018. Fifty-six articles meeting the requirements for inclusion are analyzed to identify their approach (content-based, collaborative filtering, hybrid, other) and the experiment settings (accuracy, user satisfaction or learning performance), as well as to examine the results and the manner in which they were presented. The results of the majority of the experiments were positive. Finally, given the results introduced in this systematic review, we identify future research questions.},
  keywords = {Accuracy,Collaborative filtering,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Content-based filtering,Context,Decision Making,Educational Technology,Evaluation Methods,Higher Education,Humanities,Information Systems,Information Systems Applications (incl.Internet),Law,Learning,Literature reviews,Recommender systems,Review Article,Statistics for Social Sciences,Systematic review,User satisfaction,User Satisfaction (Information)},
  file = {/Users/colin.madland/Zotero/storage/XAG6SXWT/deschenesRecommenderSystemsSupport2020.pdf}
}

@book{desjardinsHandbookEducationalMeasurement2018,
  title = {Handbook of {{Educational Measurement}} and {{Psychometrics Using R}}},
  author = {Desjardins, Christopher D. and Bulut, Okan},
  year = {2018},
  month = sep,
  edition = {1},
  publisher = {{Chapman and Hall/CRC}},
  address = {Boca Raton, Florida : CRC Press, [2018]},
  doi = {10.1201/b20498},
  urldate = {2024-01-08},
  isbn = {978-1-315-15426-8},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/4L3MN4NT/desjardinsHandbookEducationalMeasurement2018.pdf}
}

@book{desmondTheoreticalPrinciplesDistance1993,
  title = {Theoretical Principles of Distance Education},
  shorttitle = {Theoretical Principles of Distance Education},
  author = {Desmond, Keegan},
  year = {1993},
  publisher = {Taylor \& Francis},
  abstract = {Advances in technology have since the Industrial Revolution brought about a new form of education, known today as distance education'. The revolution in electronic communications of recent decades has given distance education new status. Today more than 10 million of the world's 600 million students study at a distance. Distance education is now a formal form of learning for those in employment, for homemakers and for those who choose not to go to schools or universities. In the corporate sector distance education is fast becoming the preferred type of training. Theoretical Principles of Distance Education highlights for the first time the implications of these developments for both conventional and distance education. The book explores the problems that distance education poses the theorist. In a closely planned and balanced study, fifteen of the world's leading scholars examine the didactic, underpinnings of distance education, making use of contemporary philosophy, educational philosophy and communications theory. The book sets new levels for the analysis and study of distance education.; It demonstrates for the first time that contemporary educational philosophy, didactic strategies and administrative theory can no longer focus solely on the classroom and lecture theatre but must embrace teaching at a distance too. Desmond Keegan is manager of the European Virtual Classroom for Vocational Training project at the Audio Visual Centre, University College Dublin.},
  isbn = {9786610168415},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/5VXTI5EQ/Theoretical Principles of DE - Keegan.pdf}
}

@article{despujolCorrectionWhatWe2022,
  title = {Correction: {{What}} Do We Want to Know about {{MOOCs}}? {{Results}} from a Machine Learning Approach to a Systematic Literature Mapping Review},
  author = {Despujol, Ignacio and Casta{\~n}eda, Linda and Mar{\'i}n, Victoria I. and Turr{\'o}, Carlos},
  year = {2022},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {19},
  number = {1},
  pages = {1--1},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-022-00370-6},
  keywords = {Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Correction,Educational Technology,Higher Education,Humanities,Information Systems Applications (incl.Internet),Law,Statistics for Social Sciences},
  file = {/Users/colin.madland/Zotero/storage/IWP9HB5Y/despujolCorrectionWhatWe2022.pdf}
}

@article{despujolWhatWeWant2022,
  title = {What Do We Want to Know about {{MOOCs}}? {{Results}} from a Machine Learning Approach to a Systematic Literature Mapping Review},
  author = {Despujol, Ignacio and Casta{\~n}eda, Linda and Mar{\'i}n, Victoria I. and Turr{\'o}, Carlos},
  year = {2022},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {19},
  number = {1},
  pages = {53--53},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-022-00359-1},
  abstract = {By the end of 2020, over 16,300 Massive Open Online Courses (MOOCs) from 950 universities worldwide had enrolled over 180 million students. Interest in MOOCs has been matched by significant research on the topic, including a considerable number of reviews. This study uses Machine Learning techniques and human expert supervision to generate a comprehensive systematic literature mapping review that overcomes some limitations of the traditional ones and provides a broader overview of the content and main topics studied in the specialized literature devoted to MOOCs. The sample consisted of 6320 publications automatically classified within six research topics, denominated by human experts: institutional approach, pedagogical approach, evaluation, analytics, participation, and educational resources. The content analysis of the topics identified was conducted using visual network analysis, which supported the identification of different thematic sub-clusters and endorsed the classification. Results from the review show that the lowest production of MOOC papers is within the topics of the pedagogical approach and educational resources. In contrast, participation and evaluation are the most frequent ones. In addition, the most cited papers are on the topics of analytics and resources, being the pedagogical approach and the institutional approach the less cited. This highlights the need for more MOOC research from a pedagogical perspective and calls upon the presence of educators.},
  keywords = {Clustering,Colleges & universities,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Content analysis,Distance learning,Education,Educational Technology,Evaluation,Higher Education,Humanities,Information Systems Applications (incl.Internet),Law,Literature reviews,Machine learning,Mapping,MOOCs,Network analysis,Online instruction,Pedagogy,Review Article,Statistics for Social Sciences},
  file = {/Users/colin.madland/Zotero/storage/ENPCLYCT/despujolWhatWeWant2022.pdf}
}

@phdthesis{deutschInstructorExperiencesImplementing2010,
  type = {3429155},
  title = {Instructor Experiences with Implementing Technology in Blended Learning Courses in Higher Education},
  shorttitle = {Instructor Experiences with Implementing Technology in Blended Learning Courses in Higher Education},
  author = {Deutsch, Nellie},
  year = {2010},
  address = {United States -- Arizona},
  abstract = {Organizational leaders in institutions of higher education expect instructors to implement blended learning courses without understanding instructor experiences with technology. Requiring faculty to teach blended learning courses without fully understanding the experiences instructors had implementing technology may lead to developing inappropriate professional training programs, ineffective use of technology, or to instructor disuse of technology in the future. The purpose of this qualitative phenomenological research study was to explore the experiences instructors had implementing technology in blended learning courses in campus-based institutions of higher education worldwide. This qualitative phenomenological research study used a modified van Kaam method by Moustakas (1994) with in-depth, semi-structured interviews to explore the experiences instructors had implementing technology in blended learning courses. The analysis of the transcribed interviews revealed four themes: (a) facilitates instruction and learning, (b) frustrating, (c) satisfying and rewarding, and (d) socially connecting. The conclusions derived from the study suggest that learning about the experiences instructors had implementing technology in blended learning courses may guide educational leaders in providing support and in preparing professional development workshops on how to teach blended learning courses.},
  school = {University of Phoenix},
  keywords = {Curriculum,Curriculum development,Development,EDUCATIONAL,Educational leadership,Educational technology,Leadership,technology}
}

@article{deutschTheoryCooperationCompetition1949,
  title = {A Theory of Co-Operation and Competition},
  author = {Deutsch, Morton},
  year = {1949},
  journal = {Human Relations},
  volume = {2},
  number = {2},
  pages = {129--152}
}

@article{devisaktiDoesOnlineAssessments2022,
  title = {Does Online Assessments Support of Students in Higher Education? {{The}} Moderating Role of {{IT}} Experience},
  author = {Devisakti, A. and Muftahu, Muhammad},
  year = {2022},
  journal = {The international journal of information and learning technology},
  volume = {39},
  number = {4},
  pages = {305--318},
  publisher = {Emerald Publishing Limited},
  address = {BINGLEY},
  issn = {2056-4880},
  doi = {10.1108/IJILT-12-2021-0186},
  abstract = {PurposeThe advancement of technology in the last decades transformed the education from mortar and brick into online teaching and learning. It also changed the assessments from paper-based to technology-supported assessments. This study aims to examine how technology support student's online assessments in higher education institutions from diverse background.Design/methodology/approachData were collected from 411 undergraduates in both public and private universities in Malaysia and analysed using partial least square-structural equation modelling.FindingsThe findings implied that performance expectancy and resources-facilitating conditions have a positive significant relationship with behavioural intention. IT experience moderates the relationship between effort expectancy, social influence and behaviour intention to use online assessment.Originality/valueThis study offered new insights into the intention to use online assessment among diverse student's background.},
  keywords = {Computer Science,Computer Science Interdisciplinary Applications,Science & Technology,Technology}
}

@article{devlinCommentaryCriteriaEffective2022,
  title = {A Commentary on the Criteria of Effective Teaching in Post-{{COVID}} Higher Education},
  author = {Devlin, Marcia and Samarawickrema, Gayani},
  year = {2022},
  month = jan,
  journal = {Higher Education Research \& Development},
  volume = {41},
  number = {1},
  pages = {21--32},
  issn = {0729-4360, 1469-8366},
  doi = {10.1080/07294360.2021.2002828},
  urldate = {2022-10-31},
  langid = {english}
}

@phdthesis{devriesOpenCourseDesign2013,
  title = {Open {{Course Design}} and {{Development}}: {{A Case Study}} in the {{Open Educational Resource University}}},
  author = {Devries, Irwin},
  year = {2013},
  address = {Burnaby},
  abstract = {The purpose of this comparative case study is to explore and examine the practices of open course design and development as they are being undertaken in the Open Education Resource university (OERu) network, an international partnership of member post-secondary institutions. With a focus on the design and development of an OER-based university-level course, the study identifies and describes features of OERu open design and development processes and compares and contrasts them to similar practices in traditional instructional design and the open source software (OSS) development field. The study was conducted in three parts. First, a detailed description of the OERu project and its explicit purposes, structure and logic models was provided. Second, a review of the literature traced conceptual roots of the OERu in the history of reusable learning objects, open educational resources, sharing of learning design knowledge and OSS development, interwoven with the functions of social processes and mediating artifacts in collaborative design settings. Third, data were collected though interviews with developers and analysis of communications, artifacts and developer contribution histories within the OERu WikiEducator development environment. The study concludes that the goal of enabling achievement of university credit through study of free OER-based courses imposes important considerations on the planning stages of open design and development at both course development team and partner institution levels. Further, attention to community development is key to the success of open design and development in the OERu.},
  school = {Simon Fraser University},
  keywords = {open educational resources; learning design; collaborative design; open source software; OERu},
  file = {/Users/colin.madland/Zotero/storage/8ZILRRH5/devriesOpenCourseDesign2013.docx;/Users/colin.madland/Zotero/storage/XHYVZWYY/devriesOpenCourseDesign2013.pdf}
}

@article{dewaardRevisioningPotentialFreire2021,
  ids = {dewaardRevisioningPotentialFreire2021a},
  title = {Revisioning the Potential of {{Freire}}'s Principles of Assessment: {{Influences}} on the Art of Assessment in Open and Online Learning through Blogging},
  author = {DeWaard, Helen and Roberts, Verena},
  year = {2021},
  journal = {Distance Education},
  pages = {1--17},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0158-7919},
  doi = {10/gjvg5k},
  abstract = {ABSTRACTWhen the art of assessment in online and distributed learning is grounded in Freirean writings, instructors have the opportunity to craft a nuanced and layered learning environment where the potential for critical consciousness is enhanced through carefully codesigned assessment strategies. Patton (2017) summarized 10 pedagogical principles based on the writings of Freire, which he determined relevant as a result of their connection to critical pedagogy of evaluation. We explore a revisioning of those principles: using evaluative thinking to cultivate critical consciousness; learning resides in communities, not just individuals; critical pedagogy must be dialogical and interactive; assessment should integrate reflection, action, thinking, and emotion; and critical consciousness is co-intentional, focusing on process and product. We use them as a framework to describe what we call Freirean principles of assessment, through the application of student blogs within online and distributed assessment practices. Our intention is to share the potential of blogging, in connection with Freirean principles of assessment, when considering open assessment in higher education.},
  keywords = {Blogs,College Students,Consciousness,Critical Theory,Distance Education,Distance learning,Education & Educational Research,Educational evaluation,Electronic Learning,Electronic Publishing,Evaluation Methods,Freire Paulo (1921-1997),Higher Education,learning design,Open Education,open educational practices (OEP),Paulo Freire,Pedagogy,principles of assessment,Social Sciences,Student Evaluation,Web Sites},
  file = {/Users/colin.madland/Zotero/storage/MENAVX7S/dewaardRevisioningPotentialFreire2021.pdf}
}

@incollection{deweyActivityTrainingThought1910,
  title = {Activity and the {{Training}} of {{Thought}}},
  booktitle = {How We Think.},
  author = {Dewey, John},
  editor = {Dewey, John},
  year = {1910},
  pages = {157--169},
  publisher = {D C Heath},
  abstract = {In this chapter we shall gather together and amplify considerations that have already been advanced, in various passages of the preceding pages, concerning the relation of action to thought. We shall follow, though not with exactness, the order of development in the unfolding human being. The chapter specifically looks at the early stages of activity, play, work, and allied forms of activity, and constructive occupations. (PsycINFO Database Record (c) 2010 APA, all rights reserved). (from the create)},
  keywords = {activity,Behavior,Cognition,Cognitive,constructive,Development,Education,Human,occupations,play,Processes,Recreation,Thinking,thought,Training,work},
  annotation = {Accession Number: 2006-03523-012. First Author \& Affiliation: Dewey, John; Columbia University, New York, NY, US. Release Date: 20060327. Publication Type: Book, (0200); Authored Book, (0240); . Media Covered: Print. Document Type: Chapter. Book Type: Classic Book. Language: English. Major Descriptor: Behavior; Cognition; Cognitive Processes; Human Development. Minor Descriptor: Education; Occupations; Recreation; Thinking. Classification: Cognitive Processes (2340) . Population: Human (10); . Intended Audience: Psychology: Professional \& Research (PS)}
}

@incollection{deweyAnalysisCompleteAct1910,
  title = {The {{Analysis}} of a {{Complete Act}} of {{Thought}}},
  booktitle = {How We Think.},
  author = {Dewey, John},
  editor = {Dewey, John},
  year = {1910},
  pages = {68--78},
  publisher = {D C Heath},
  abstract = {The purport of the second part, upon which we are now entering, is giving a fuller statement of the nature and normal growth of thinking, preparatory to considering in the concluding part the special problems that arise in connection with its education. In this chapter we shall make an analysis of the process of thinking into its steps or elementary constituents, basing the analysis upon descriptions of a number of extremely simple, but genuine, cases of reflective experience. (PsycINFO Database Record (c) 2010 APA, all rights reserved). (from the chapter)},
  keywords = {Cognition,Cognitive,of,process,Processes,Thinking,thought},
  annotation = {Accession Number: 2006-03523-006. First Author \& Affiliation: Dewey, John; Columbia University, New York, NY, US. Release Date: 20060327. Publication Type: Book, (0200); Authored Book, (0240); . Media Covered: Print. Document Type: Chapter. Book Type: Classic Book. Language: English. Major Descriptor: Cognition; Cognitive Processes. Minor Descriptor: Thinking. Classification: Cognitive Processes (2340) . Population: Human (10); . Intended Audience: Psychology: Professional \& Research (PS)}
}

@incollection{deweyConcreteAbstractThinking1910,
  title = {Concrete and {{Abstract Thinking}}},
  booktitle = {How We Think.},
  author = {Dewey, John},
  editor = {Dewey, John},
  year = {1910},
  pages = {135--144},
  publisher = {D C Heath},
  abstract = {The maxim enjoined upon teachers, "to proceed from the concrete to the abstract," is perhaps familiar rather than comprehended. Few who read and hear it gain a clear conception of the starting-point, the concrete; of the nature of the goal, the abstract; and of the exact nature of the path to be traversed in going from one to the other. At times the injunction is positively misunderstood, being taken to mean that education. should advance from things to thought--as if any dealing with things in which thinking is not involved could possibly be educative. So understood, the maxim encourages mechanical routine or sensuous excitation at one end of the educational scale--the lower--and academic and unapplied learning at the upper end. (PsycINFO Database Record (c) 2010 APA, all rights reserved). (from the chapter)},
  keywords = {abstract,Abstraction,Cognition,concrete,Thinking},
  annotation = {Accession Number: 2006-03523-010. First Author \& Affiliation: Dewey, John; Columbia University, New York, NY, US. Release Date: 20060327. Publication Type: Book, (0200); Authored Book, (0240); . Media Covered: Print. Document Type: Chapter. Book Type: Classic Book. Language: English. Major Descriptor: Abstraction; Cognition; Thinking. Classification: Cognitive Processes (2340) . Population: Human (10); . Intended Audience: Psychology: Professional \& Research (PS)}
}

@book{deweyDemocracyEducation1916,
  title = {Democracy and Education},
  author = {Dewey, John},
  year = {1916},
  publisher = {Macmillan}
}

@incollection{deweyEmpiricalScientificThinking1910,
  title = {Empirical and {{Scientific Thinking}}},
  booktitle = {How We Think.},
  author = {Dewey, John},
  editor = {Dewey, John},
  year = {1910},
  pages = {145--156},
  publisher = {D C Heath},
  abstract = {This chapter examines empirical thinking and the disadvantages of it, as well the scientific method. In contrast with the empirical method, which depends on past habits, stands the scientific. Scientific method replaces the repeated conjunction or coincidence of separate facts by discovery of a single comprehensive fact, effecting this replacement by breaking up the coarse or gross facts of observation into a number of minuter processes not directly accessible to perception. (PsycINFO Database Record (c) 2010 APA, all rights reserved). (from the create)},
  keywords = {empirical,Experimental,method,Methods,scientific,Thinking},
  annotation = {Accession Number: 2006-03523-011. First Author \& Affiliation: Dewey, John; Columbia University, New York, NY, US. Release Date: 20060327. Publication Type: Book, (0200); Authored Book, (0240); . Media Covered: Print. Document Type: Chapter. Book Type: Classic Book. Language: English. Major Descriptor: Empirical Methods; Thinking. Minor Descriptor: Experimental Methods. Classification: Cognitive Processes (2340) . Population: Human (10); . Intended Audience: Psychology: Professional \& Research (PS)}
}

@incollection{deweyGeneralConclusions1910,
  title = {Some {{General Conclusions}}},
  booktitle = {How We Think.},
  author = {Dewey, John},
  editor = {Dewey, John},
  year = {1910},
  pages = {214--224},
  publisher = {D C Heath},
  abstract = {This chapter concludes this book of how we think and how we should think by presenting some factors of thinking which should balance each other, but which constantly tend to become so isolated that they work against each other instead of cooperating to make reflective inquiry efficient. The chapter looks specifically at the unconscious and conscious. The understood being the unconscious and inquiry being conscious formulation. It also examines process and product. A like balance in mental life characterizes process and product. Finally, the chapter looks at the far and the near. For example, teachers who have heard that they should avoid matters foreign to pupils' experience, are frequently surprised to find pupils wake up when something beyond their ken is introduced, while they remain apathetic in considering the familiar. (PsycINFO Database Record (c) 2010 APA, all rights reserved). (from the create)},
  keywords = {balance,inquiry,Questioning,reflective,Reflectiveness,Thinking},
  annotation = {Accession Number: 2006-03523-016. First Author \& Affiliation: Dewey, John; Columbia University, New York, NY, US. Release Date: 20060327. Publication Type: Book, (0200); Authored Book, (0240); . Media Covered: Print. Document Type: Chapter. Book Type: Classic Book. Language: English. Major Descriptor: Questioning; Reflectiveness; Thinking. Classification: Cognitive Processes (2340) . Population: Human (10); . Intended Audience: Psychology: Professional \& Research (PS)}
}

@book{deweyHowWeThink1910,
  title = {How We Think},
  author = {Dewey, John},
  year = {1910},
  publisher = {D.C. Heath},
  address = {Boston, MA}
}

@incollection{deweyJudgmentInterpretationFacts1910,
  title = {Judgment: {{The Interpretation}} of {{Facts}}},
  booktitle = {How We Think.},
  author = {Dewey, John},
  editor = {Dewey, John},
  year = {1910},
  pages = {101--115},
  publisher = {D C Heath},
  abstract = {This chapter examines the three factors of judging: uncertainty the antecedent of judgment, judgment defines the issue, and judgment terminates in a decision or statement. It looks at the origin and nature of ideas, as well as the analysis and synthesis of judgment. Judging clears up things or analysis and it reveals the bearing or significance of facts or synthesis. (PsycINFO Database Record (c) 2010 APA, all rights reserved). (from the create)},
  keywords = {analysis,ideas,Ideation,judgment,synthesis,Uncertainty},
  annotation = {Accession Number: 2006-03523-008. First Author \& Affiliation: Dewey, John; Columbia University, New York, NY, US. Release Date: 20060327. Publication Type: Book, (0200); Authored Book, (0240); . Media Covered: Print. Document Type: Chapter. Book Type: Classic Book. Language: English. Major Descriptor: Judgment. Minor Descriptor: Analysis; Ideation; Uncertainty. Classification: Cognitive Processes (2340) . Population: Human (10); . Intended Audience: Psychology: Professional \& Research (PS)}
}

@incollection{deweyLanguageTrainingThought1910,
  title = {Language and the {{Training}} of {{Thought}}},
  booktitle = {How We Think.},
  author = {Dewey, John},
  editor = {Dewey, John},
  year = {1910},
  pages = {170--187},
  publisher = {D C Heath},
  abstract = {This chapter examines language as the tool of thinking. The conviction that language is necessary to thinking (is even identical with it) is met by the contention that language perverts and conceals thought. It looks at the intimate connection of meanings and signs (or language), (1) for specific meanings, and (2) for the organization of meanings. Next, the chapter examines the abuse of linguistic methods in education. Learning, in the proper sense, is not learning things, but the meanings of things, and this process involves the use of signs, or language in its generic sense. Finally, the chapter looks at the use of language in its educational bearings. (PsycINFO Database Record (c) 2010 APA, all rights reserved). (from the create)},
  keywords = {Cognition,Cognitive,Education,language,linguistic,Linguistics,meaning,meanings,Methods,Processes,signs,Thinking,thought,Training},
  annotation = {Accession Number: 2006-03523-013. First Author \& Affiliation: Dewey, John; Columbia University, New York, NY, US. Release Date: 20060327. Publication Type: Book, (0200); Authored Book, (0240); . Media Covered: Print. Document Type: Chapter. Book Type: Classic Book. Language: English. Major Descriptor: Cognition; Cognitive Processes; Language; Linguistics; Meaning. Minor Descriptor: Education; Thinking. Classification: Cognitive Processes (2340) . Population: Human (10); . Intended Audience: Psychology: Professional \& Research (PS)}
}

@incollection{deweyMeaningConceptionsUnderstanding1910,
  title = {Meaning: {{Or Conceptions}} and {{Understanding}}},
  booktitle = {How We Think.},
  author = {Dewey, John},
  editor = {Dewey, John},
  year = {1910},
  pages = {116--134},
  publisher = {D C Heath},
  abstract = {As in our discussion of judgment we were making more explicit what is involved in inference, so in the discussion of meaning we are only recurring to the central function of all reflection. For one thing to mean, signify, betoken, indicate, or point to, another we saw at the outset to be the essential mark of thinking (see p. 8). To find out what facts, just as they stand, mean, is the object of all discovery; to find out what facts will carry out, substantiate, support a given meaning, is the object of all testing. When an inference reaches a satisfactory conclusion, we attain a goal of meaning. The act of judging involves both the growth and the application of meanings. In short, in this chapter we are not introducing a new topic; we are only coming to closer quarters with what hitherto has been constantly assumed. The chapter begins by considering the equivalence of meaning and understanding, and the two types of understanding, direct and indirect. It then goes on to look at concepts and meaning. (PsycINFO Database Record (c) 2010 APA, all rights reserved). (from the create)},
  keywords = {Comprehension,conceptions,Concepts,meaning,reflection,Reflectiveness,understanding},
  annotation = {Accession Number: 2006-03523-009. First Author \& Affiliation: Dewey, John; Columbia University, New York, NY, US. Release Date: 20060327. Publication Type: Book, (0200); Authored Book, (0240); . Media Covered: Print. Document Type: Chapter. Book Type: Classic Book. Language: English. Major Descriptor: Comprehension; Concepts; Meaning; Reflectiveness. Classification: Cognitive Processes (2340) . Population: Human (10); . Intended Audience: Psychology: Professional \& Research (PS)}
}

@incollection{deweyMeansEndMental1910,
  title = {The {{Means}} and {{End}} of {{Mental Training}}: {{The Psychological}} and the {{Logical}}},
  booktitle = {How We Think.},
  author = {Dewey, John},
  editor = {Dewey, John},
  year = {1910},
  pages = {56--67},
  publisher = {D C Heath},
  abstract = {In the preceding chapters we have considered (i) what thinking is; (ii) the importance of its special training; (iii) the natural tendencies that lend themselves to its training; and (iv) some of the special obstacles in the way of its training under school conditions. We come now to the relation of logic to the purpose of mental training. This chapter looks at the meaning, discipline, and freedom of logic. (PsycINFO Database Record (c) 2010 APA, all rights reserved). (from the create)},
  keywords = {Cognition,Education,logic,Logical,mental,psychology,Thinking,Training},
  annotation = {Accession Number: 2006-03523-005. First Author \& Affiliation: Dewey, John; Columbia University, New York, NY, US. Release Date: 20060327. Publication Type: Book, (0200); Authored Book, (0240); . Media Covered: Print. Document Type: Chapter. Book Type: Classic Book. Language: English. Major Descriptor: Cognition; Education; Logical Thinking; Psychology. Classification: Cognitive Processes (2340) . Population: Human (10); . Intended Audience: Psychology: Professional \& Research (PS)}
}

@incollection{deweyMyPedagogicCreed1897,
  title = {My Pedagogic Creed},
  booktitle = {Dewey on Education},
  author = {Dewey, John},
  editor = {Dworkin, Martin S},
  year = {1897},
  publisher = {Teachers College Press},
  address = {NewYork, NY}
}

@incollection{deweyNaturalResourcesTraining1910,
  title = {Natural {{Resources}} in the {{Training}} of {{Thought}}},
  booktitle = {How We Think.},
  author = {Dewey, John},
  editor = {Dewey, John},
  year = {1910},
  pages = {29--44},
  publisher = {D C Heath},
  abstract = {The very importance of thought for life makes necessary its control by education because of its natural tendency to go astray, and because social influences exist that tend to form habits of thought leading to inadequate and erroneous beliefs. Training must, however, be itself based upon the natural tendencies,--that is, it must find its point of departure in them. A being who could not think without training could never be trained to think ; one may have to learn to think well, but not to think. Training, in short, must fall back upon the prior and independent existence of natural powers; it is concerned with their proper direction, not with creating them. This chapter looks at curiosity in the physical, social, and intellectual realm, the dimensions of suggestion, and orderliness. (PsycINFO Database Record (c) 2010 APA, all rights reserved). (from the create)},
  keywords = {Cognition,Cognitive,curiosity,Education,environment,habits,Human,natural,Nature,orderliness,Processes,suggestion,tendencies,Thinking,thought,Training},
  annotation = {Accession Number: 2006-03523-003. First Author \& Affiliation: Dewey, John; Columbia University, New York, NY, US. Release Date: 20060327. Publication Type: Book, (0200); Authored Book, (0240); . Media Covered: Print. Document Type: Chapter. Book Type: Classic Book. Language: English. Major Descriptor: Cognition; Cognitive Processes; Education; Habits; Human Nature. Minor Descriptor: Curiosity; Environment; Thinking. Classification: Cognitive Processes (2340) . Population: Human (10); . Intended Audience: Psychology: Professional \& Research (PS)}
}

@incollection{deweyNeedTrainingThought1910,
  title = {The {{Need}} for {{Training Thought}}},
  booktitle = {How We Think.},
  author = {Dewey, John},
  editor = {Dewey, John},
  year = {1910},
  pages = {14--28},
  publisher = {D C Heath},
  abstract = {To expatiate upon the importance of thought would be absurd. The traditional definition of man as "the thinking animal" fixes thought as the essential difference between man and the brutes,--surely an important matter. More relevant to our purpose is the question how thought is important, for an answer to this question will throw light upon the kind of training thought requires if it is to subserve its end. This chapter examines the values of thought, the importance of direction in order to realize these values, tendencies needing constant regulation, and how regulation transforms inference into proof. (PsycINFO Database Record (c) 2010 APA, all rights reserved). (from the create)},
  keywords = {Cognition,Cognitive,Education,of,Processes,regulation,tendencies,Thinking,thought,Training,value},
  annotation = {Accession Number: 2006-03523-002. First Author \& Affiliation: Dewey, John; Columbia University, New York, NY, US. Release Date: 20060327. Publication Type: Book, (0200); Authored Book, (0240); . Media Covered: Print. Document Type: Chapter. Book Type: Classic Book. Language: English. Major Descriptor: Cognition; Cognitive Processes; Education. Minor Descriptor: Thinking. Classification: Cognitive Processes (2340) . Population: Human (10); . Intended Audience: Psychology: Professional \& Research (PS)}
}

@incollection{deweyObservationInformationTraining1910,
  title = {Observation and {{Information}} in the {{Training}} of {{Mind}}},
  booktitle = {How We Think.},
  author = {Dewey, John},
  editor = {Dewey, John},
  year = {1910},
  pages = {188--200},
  publisher = {D C Heath},
  abstract = {Thinking is an ordering of subject-matter with reference to discovering what it signifies or indicates. Thinking no more exists apart from this arranging of subject-matter than digestion occurs apart from the assimilating of food. The way in which the subject matter is furnished marks, therefore, a fundamental point. If the subject-matter is provided in too scanty or too profuse fashion, if it comes in disordered array or in isolated scraps, the effect upon habits of thought is detrimental. If personal observation and communication of information by others (whether in books or speech) are rightly conducted, half the logical battle is won, for they are the channels of obtaining subject-matter. This chapter looks at the nature and value of observation, the methods and materials of observation used in schools, and how information is communicated. (PsycINFO Database Record (c) 2010 APA, all rights reserved). (from the create)},
  keywords = {Cognition,communication,Education,Information,LEARNING,Methods,mind,observation,Observational,of,Schools,Thinking,Training},
  annotation = {Accession Number: 2006-03523-014. First Author \& Affiliation: Dewey, John; Columbia University, New York, NY, US. Release Date: 20060327. Publication Type: Book, (0200); Authored Book, (0240); . Media Covered: Print. Document Type: Chapter. Book Type: Classic Book. Language: English. Major Descriptor: Cognition; Education; Information; Observation Methods; Thinking. Minor Descriptor: Communication; Mind; Observational Learning. Classification: Educational Psychology (3500) Cognitive Processes (2340) . Population: Human (10); . Intended Audience: Psychology: Professional \& Research (PS)}
}

@incollection{deweyRecitationTrainingThought1910,
  title = {The {{Recitation}} and the {{Training}} of {{Thought}}},
  booktitle = {How We Think.},
  author = {Dewey, John},
  editor = {Dewey, John},
  year = {1910},
  pages = {201--213},
  publisher = {D C Heath},
  abstract = {In the recitation the teacher comes into his closest contact with the pupil. In the recitation focus the possibilities of guiding children's activities, influencing their language habits, and directing their observations. In discussing the significance of the recitation as an instrumentality of education, we are accordingly bringing to a head the points considered in the last three chapters, rather than introducing a new topic. The method in which the recitation is carried on is a crucial test of a teacher's skill in diagnosing the intellectual state of his pupils and in supplying the conditions that will arouse serviceable mental responses: in short, of his art as a teacher. This chapter looks at the formal steps of instruction and the factors in recitation. (PsycINFO Database Record (c) 2010 APA, all rights reserved). (from the create)},
  keywords = {Cognition,Cognitive,Education,instruction,Processes,recitation,Teaching,Thinking,thought,Training},
  annotation = {Accession Number: 2006-03523-015. First Author \& Affiliation: Dewey, John; Columbia University, New York, NY, US. Release Date: 20060327. Publication Type: Book, (0200); Authored Book, (0240); . Media Covered: Print. Document Type: Chapter. Book Type: Classic Book. Language: English. Major Descriptor: Cognition; Cognitive Processes; Education; Teaching. Minor Descriptor: Thinking. Classification: Curriculum \& Programs \& Teaching Methods (3530) . Population: Human (10); . Intended Audience: Psychology: Professional \& Research (PS)}
}

@incollection{deweySchoolConditionsTraining1910,
  title = {School {{Conditions}} and the {{Training}} of {{Thought}}},
  booktitle = {How We Think.},
  author = {Dewey, John},
  editor = {Dewey, John},
  year = {1910},
  pages = {45--55},
  publisher = {D C Heath},
  abstract = {This chapter looks at the methods and school conditions of training thought. It examines the influence of the habits of others by looking at the students' response to their environment, the influence of teacher's own habits, judging others by ourselves, exaggeration of direct personal influence, and independent thinking as opposed to "getting the answer." Next, the chapter looks at the influence of the nature of studies. Studies are conventionally and conveniently grouped under these heads: (1) Those especially involving the acquisition of skill in performance--the school arts, such as reading, writing, figuring, and music. (2) Those mainly concerned with acquiring knowledge--"informational" studies, such as geography and history. (3) Those in which skill in doing and bulk of information are relatively less important, and appeal to abstract thinking, to "reasoning," is most marked--"disciplinary" studies, such as arithmetic and formal grammar. Finally, it examines the influence of current aims and ideals. (PsycINFO Database Record (c) 2010 APA, all rights reserved). (from the chapter)},
  keywords = {Cognition,Cognitive,conditions,Education,environment,habits,Methods,Processes,SCHOOL,Teaching,Thinking,thought,Training},
  annotation = {Accession Number: 2006-03523-004. First Author \& Affiliation: Dewey, John; Columbia University, New York, NY, US. Release Date: 20060327. Publication Type: Book, (0200); Authored Book, (0240); . Media Covered: Print. Document Type: Chapter. Book Type: Classic Book. Language: English. Major Descriptor: Cognition; Cognitive Processes; Education; School Environment; Teaching Methods. Minor Descriptor: Habits; Thinking. Classification: Educational Psychology (3500) . Population: Human (10); . Intended Audience: Psychology: Professional \& Research (PS)}
}

@incollection{deweySystematicInferenceInduction1910,
  title = {Systematic {{Inference}}: {{Induction}} and {{Deduction}}},
  booktitle = {How We Think.},
  author = {Dewey, John},
  editor = {Dewey, John},
  year = {1910},
  pages = {79--100},
  publisher = {D C Heath},
  abstract = {This chapter examines the double movement of reflection. The facts as they stand are the data, the raw material of reflection; their lack of coherence perplexes and stimulates to reflection. This the going back and forth between facts and meaning. There is thus a double movement in all reflection: inductive and deductive. This chapter looks at the guidance of the inductive movement and the deductive movement and experimental variation of conditions. (PsycINFO Database Record (c) 2010 APA, all rights reserved). (from the create)},
  keywords = {deduction,Deductive,double,induction,Inductive,Inference,movement,Reasoning,reflection,Reflectiveness},
  annotation = {Accession Number: 2006-03523-007. First Author \& Affiliation: Dewey, John; Columbia University, New York, NY, US. Release Date: 20060327. Publication Type: Book, (0200); Authored Book, (0240); . Media Covered: Print. Document Type: Chapter. Book Type: Classic Book. Language: English. Major Descriptor: Inductive Deductive Reasoning; Reflectiveness. Minor Descriptor: Inference. Classification: Cognitive Processes (2340) . Population: Human (10); . Intended Audience: Psychology: Professional \& Research (PS)}
}

@incollection{deweyWhatThought1910,
  title = {What Is Thought?},
  shorttitle = {What Is Thought?},
  booktitle = {How We Think.},
  author = {Dewey, John},
  editor = {Dewey, John},
  year = {1910},
  pages = {1--13},
  publisher = {D C Heath},
  abstract = {No words are oftener on our lips than thinking and thought. So profuse and varied, indeed, is our use of these words that it is not easy to define just what we mean by them. The aim of this chapter is to find a single consistent meaning. Assistance may be had by considering some typical ways in which the terms are employed. In the first place thought is used broadly, not to say loosely. Everything that comes to mind, that "goes through our heads," is called a thought. To think of a thing is just to be conscious of it in any way whatsoever. Second, the term is restricted by excluding whatever is directly presented; we think (or think of) only such things as we do not directly see, hear, smell, or taste. Then, third, the meaning is further limited to beliefs that rest upon some kind of evidence or testimony. This chapter looks at the four senses of thought, the central factor in thinking, and elements in reflective thinking. (PsycINFO Database Record (c) 2010 APA, all rights reserved). (from the create)},
  keywords = {Cognition,Cognitive,Cognitive Processes,meaning,Processes,reflective,reflective thinking,Reflectiveness,Thinking,thought}
}

@article{dewinterExploratoryFactorAnalysis2009,
  title = {Exploratory {{Factor Analysis With Small Sample Sizes}}},
  author = {{\noopsort{winter}}{de Winter}, J. C. F. and Dodou, D. and Wieringa, P. A.},
  year = {2009},
  month = apr,
  journal = {Multivariate Behavioral Research},
  volume = {44},
  number = {2},
  pages = {147--181},
  publisher = {Routledge},
  issn = {0027-3171},
  doi = {10.1080/00273170902794206},
  abstract = {Exploratory factor analysis (EFA) is generally regarded as a technique for large sample sizes (N), with N = 50 as a reasonable absolute minimum. This study offers a comprehensive overview of the conditions in which EFA can yield good quality results for N below 50. Simulations were carried out to estimate the minimum required N for different levels of loadings (?), number of factors (f), and number of variables (p) and to examine the extent to which a small N solution can sustain the presence of small distortions such as interfactor correlations, model error, secondary loadings, unequal loadings, and unequal p/f. Factor recovery was assessed in terms of pattern congruence coefficients, factor score correlations, Heywood cases, and the gap size between eigenvalues. A subsampling study was also conducted on a psychological dataset of individuals who filled in a Big Five Inventory via the Internet. Results showed that when data are well conditioned (i.e., high ?, low f, high p), EFA can yield reliable results for N well below 50, even in the presence of small distortions. Such conditions may be uncommon but should certainly not be ruled out in behavioral research data. * These authors contributed equally to this work * These authors contributed equally to this work},
  file = {/Users/colin.madland/Zotero/storage/DA7TIQMA/dewinterExploratoryFactorAnalysis2009.pdf}
}

@article{DiBattista_2011,
  title = {Examination of the Quality of Multiple Choice Items on Classroom Tests},
  author = {DiBattista, David and Kurzawa, Laura},
  year = {2011},
  journal = {The Canadian Journal for the Scholarship of Teaching and Learning},
  doi = {10/fzvh5z},
  abstract = {Because multiple-choice testing is so widespread in higher education, we assessed the quality of items used on classroom tests by carrying out a statistical item analysis. We examined undergraduates' responses to 1198 multiple-choice items on sixteen classroom tests in various disciplines. The mean item discrimination coefficient was +0.25, with more than 30\% of items having unsatisfactory coefficients less than +0.20. Of the 3819 distractors, 45\% were flawed either because less than 5\% of examinees selected them or because their selection was positively rather than negatively correlated with test scores. In three tests, more than 40\% of the items had an unsatisfactory discrimination coefficient, and in six tests, more than half of the distractors were flawed. Discriminatory power suffered dramatically when the selection of one or more distractors was positively correlated with test scores, but it was only minimally affected by the presence of distractors that were selected by less than 5\% of examinees. Our findings indicate that there is considerable room for improvement in the quality of many multiple-choice tests. We suggest that instructors consider improving the quality of their multiple-choice tests by conducting an item analysis and by modifying distractors that impair the discriminatory power of items. Etant donne que les examens a choix multiple sont tellement generalises dans l'enseignement superieur, nous avons effectue une analyse statistique des items utilises dans les examens en classe afin d'en evaluer la qualite. Nous avons analyse les reponses des etudiants de premier cycle a 1198 questions a choix multiples dans 16 examens effectues en classe dans diverses disciplines. Le coefficient moyen de discrimination de l'item etait +0.25. Plus de 30 \% des items avaient des coefficients insatisfaisants inferieurs a + 0.20. Sur les 3819 distracteurs, 45 \% etaient imparfaits parce que moins de 5 \% des etudiants les ont choisis ou a cause d'une correlation negative plutot que positive avec les resultats des examens. Dans trois examens, le coefficient de discrimination de plus de 40 \% des items etait insatisfaisant et dans six examens, plus de la moitie des distracteurs etait imparfaits. Le pouvoir de discrimination etait considerablement affecte en cas de correlation positive entre un distracteur ou plus et les resultatsde l'examen, mais la presence de distracteurs choisis par moins de 5 \% des etudiants avait une influence minime sur ce pouvoir. Nos resultats indiquent que les examens a choix multiple peuvent etre considerablement ameliores. Nous suggerons que les enseignants procedent a une analyse des items et modifient les distracteurs qui compromettent le pouvoir de discrimination des items.},
  mag_id = {2158712864},
  pmcid = {null},
  pmid = {null},
  file = {/Users/colin.madland/Zotero/storage/BPST763W/DiBattista_2011.pdf}
}

@incollection{dicerboFutureAssessmentTechnologyRich2016,
  title = {The {{Future}} of {{Assessment}} in {{Technology-Rich Environments}}: {{Psychometric Considerations}}},
  shorttitle = {The {{Future}} of {{Assessment}} in {{Technology-Rich Environments}}},
  booktitle = {Learning, {{Design}}, and {{Technology}}},
  author = {DiCerbo, Kristen E and Shute, Valerie and Kim, Yoon Jeon},
  editor = {Spector, Michael J and Lockee, Barbara B and Childress, Marcus D.},
  year = {2016},
  pages = {1--21},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-17727-4_66-1},
  urldate = {2021-01-04},
  isbn = {978-3-319-17727-4},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/QWQUJSZQ/dicerboFutureAssessmentTechnologyRich2016.pdf}
}

@article{dichevGamifyingEducationWhat2017,
  title = {Gamifying Education: What Is Known, What Is Believed and What Remains Uncertain: A Critical Review},
  author = {Dichev, Christo and Dicheva, Darina},
  year = {2017},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {14},
  number = {1},
  pages = {1--36},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-017-0042-5},
  abstract = {Gamification of education is a developing approach for increasing learners' motivation and engagement by incorporating game design elements in educational environments. With the growing popularity of gamification and yet mixed success of its application in educational contexts, the current review is aiming to shed a more realistic light on the research in this field by focusing on empirical evidence rather than on potentialities, beliefs or preferences. Accordingly, it critically examines the advancement in gamifying education. The discussion is structured around the used gamification mechanisms, the gamified subjects, the type of gamified learning activities, and the study goals, with an emphasis on the reliability and validity of the reported outcomes. To improve our understanding and offer a more realistic picture of the progress of gamification in education, consistent with the presented evidence, we examine both the outcomes reported in the papers and how they have been obtained. While the gamification in education is still a growing phenomenon, the review reveals that (i) insufficient evidence exists to support the long-term benefits of gamification in educational contexts; (ii) the practice of gamifying learning has outpaced researchers' understanding of its mechanisms and methods; (iii) the knowledge of how to gamify an activity in accordance with the specifics of the educational context is still limited. The review highlights the need for systematically designed studies and rigorously tested approaches confirming the educational benefits of gamification, if gamified learning is to become a recognized instructional approach.},
  keywords = {Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Critical literature review,Education,Educational Technology,Empirical studies,Gamification,Gamification in education,Gamifying learning,Higher Education,Humanities,Information Systems Applications (incl.Internet),Law,Learning,Literature reviews,Review Article,Statistics for Social Sciences},
  file = {/Users/colin.madland/Zotero/storage/5FMZ3M2H/dichevGamifyingEducationWhat2017.pdf}
}

@article{dicksLessonsLearnedCOVID192020,
  ids = {dicksLessonsLearnedCOVID192020a},
  title = {Lessons {{Learned}} from the {{COVID-19 Crisis}}: {{Adjusting Assessment Approaches}} within {{Introductory Organic Courses}}},
  author = {Dicks, Andrew P and Morra, Barbora and Quinlan, Kristine B},
  year = {2020},
  journal = {Journal of chemical education},
  volume = {97},
  number = {9},
  pages = {3406--3412},
  publisher = {{American Chemical Society and Division of Chemical Education, Inc}},
  address = {WASHINGTON},
  issn = {0021-9584},
  doi = {10.1021/acs.jchemed.0c00529},
  abstract = {This communication describes a variety of virtual student assessment strategies employed at the University of Toronto during the academic disruption caused by the 2020 COVID-19 global pandemic. Instructors focused their efforts toward maintaining a positive learning environment and offering meaningful evaluation methods for students in each of three introductory organic chemistry courses. Assessment schemes were initially modified in response to moving courses to a virtual platform, and a variety of support measures were used while students completed the course material and prepared for online ``final assignments'', which in two courses included a virtual rehearsal test. The readiness for and delivery of online final assignments is outlined (including methods to effectively maintain academic integrity), and the important roles of graduate student teaching assistants in successfully completing each course are highlighted. Specific outcomes and reflections are discussed, including approaches which, with hindsight, were considered unnecessary, and others that proved to be valuable virtual teaching and assessment tools.},
  keywords = {Chemistry,Chemistry Multidisciplinary,Classroom communication,College students,Colleges & universities,Computer Assisted Testing,COVID-19,Education & Educational Research,Education Scientific Disciplines,Educational Technology,Evaluation Methods,Foreign Countries,Graduate students,Higher Education,Learning environment,Online Courses,Online instruction,Organic Chemistry,Pandemics,Physical Sciences,Science & Technology,Social Sciences,Student Evaluation,Students,Teachers,Teaching Assistants,Technology Uses in Education,Undergraduate Students,Virtual reality},
  file = {/Users/colin.madland/Zotero/storage/4M4WHS7N/dicksLessonsLearnedCOVID192020.pdf}
}

@article{dieterichMaximizingOnlineInstructional2020,
  title = {Maximizing {{Online Instructional Pedagogy}} in {{Teacher Education Courses}} for {{Career Changers}}},
  author = {Dieterich, Cynthia and Hamsher, Sarah},
  year = {2020},
  journal = {Journal of Educators Online},
  volume = {17},
  number = {1},
  issn = {EISSN-1547-500X},
  abstract = {In the past 20 years there has been a dramatic increase in adults desiring to change careers, and a great number of these adults are transitioning to careers in teaching. To meet the needs of these adult learners, there is an increasing desire and need for online learning, particularly for the adult learner who continues to work full time while pursuing a teaching license. Recognizing that institutions of higher education--particularly private institutions--do not have limitless fiscal and human resources, there is a need to appropriately invest in instructor resources in order to provide the most effective and efficient learning environment for career changers. This current study surveyed career changers in a College of Education at a Midwestern institution on the behaviors of course instructors they value most and value least in the online learning atmosphere. The career changers noted that they highly value effective communication, feedback, and a positive disposition from online course instructors. Recognizing that career changers valued these three behaviors the most, universities need to inform faculty about the importance of ongoing communication, providing meaningful feedback, and designing explicit strategies to provide encouragement within the online learning management system. Career changers have many options for online teacher preparation programs; therefore, universities need to distinguish themselves by offering high quality, pedagogically-sound programs that are also responsive to the career changers' desires and needs.},
  langid = {english},
  keywords = {Adult Learning,Career Change,College Faculty,Educational Technology,Feedback (Response),Integrated Learning Systems,Interpersonal Communication,No DOI found,Online Courses,Preservice Teacher Education,Student Attitudes,Student Needs,Teacher Behavior,Teacher Education Programs,Teacher Student Relationship,Technology Uses in Education}
}

@techreport{digitallearningadvisorycommitteePostSecondaryDigitalLearning2022,
  title = {B.{{C}}.'s {{Post-Secondary Digital Learning Strategy}}},
  author = {{Digital Learning Advisory Committee}},
  year = {2022},
  institution = {Province of British Columbia},
  urldate = {2023-08-10},
  abstract = {In Spring 2020, British Columbia's post-secondary system pivoted towards online services in response to the COVID-19 pandemic, initiating a transition that has impacted postsecondary operations across the entire system. This initial shift to emergency online learning was anticipated to be short-lived, however the nearly universal use of online learning throughout repeated pandemic waves reinforced the use of digital models for learning and services. This shift to emergency online teaching and learning impacted all areas of the post-secondary system, from learners to educators, staff, administration, and other areas of post-secondary communities. This document is intended to provide a provincial synthesis of priorities and recommended actions for the post-secondary system, including the Ministry of PostSecondary Education and Future Skills (PSFS), based on best practices, lessons learned, and forward-thinking approaches to enhance the ongoing digital aspects of postsecondary studies across B.C. The strategy is not intended to introduce new requirements for the post-secondary system or conflict with collective agreement rights, and implementation is voluntary.},
  file = {/Users/colin.madland/Zotero/storage/9RE987TX/digital_learning_strategy.pdf}
}

@article{dilauroEmployingWikipediaGood2017,
  title = {Employing {{Wikipedia}} for {{Good Not Evil}}: {{Innovative Approaches}} to {{Collaborative Writing Assessment}}},
  author = {Di Lauro, Frances and Johinke, Rebecca},
  year = {2017},
  month = jan,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {42},
  number = {3},
  pages = {478--491},
  publisher = {Assessment \& Evaluation in Higher Education},
  issn = {0260-2938},
  doi = {10.1080/02602938.2015.1127322},
  abstract = {Wikipedia is an open educational resource that connects writers and editors to diverse discourse communities around the world. Unwarranted stigma is attached to the use of Wikipedia in higher education due to fears that students will not pursue rigorous research practices because of the easy access to information that Wikipedia facilitates. In studies referred to in this paper, undergraduate writing students are taught about the need to interrogate any information they find on Wikipedia just as they would other online source material. They are inducted into fact checking, editing and creating Wikipedia articles as a means to analyse source material critically and to advance their research, writing and digital literacy. Meanwhile, in a postgraduate course in magazine studies, instead of writing essays, students are promoting Australian magazines and print culture by writing Wikipedia entries about Antipodean magazines and their editors. These courses experiment with new approaches to formative and summative assessment; promote group research, collaborative and participatory writing, writing across networks and negotiating discourse communities; and challenge students' perceptions about peer review and the legitimacy of Wikipedia.},
  keywords = {Australia,Case Studies,Collaborative Writing,Critical Reading,Editing,Educational Innovation,Electronic Publishing,Encyclopedias,Essays,Evaluation Methods,Foreign Countries,Formative Evaluation,Graduate Students,Journal Articles,Open Source Technology,Peer Evaluation,Research Skills,Technological Literacy,Undergraduate Students,Writing Evaluation,Writing Skills}
}

@article{dilauroIfItNot2020,
  title = {'{{If It Is Not}} in {{Wikipedia}}, {{Blame Yourself}}:' {{Edit-a-thons}} as {{Vehicles}} for {{Computer Supported Collaborative Learning}} in {{Higher Education}}},
  author = {Di Lauro, Frances},
  year = {2020},
  month = jan,
  journal = {Studies in Higher Education},
  volume = {45},
  number = {5},
  pages = {1003--1014},
  publisher = {Studies in Higher Education},
  issn = {0307-5079},
  doi = {10.1080/03075079.2020.1750191},
  abstract = {This paper brings to light the notable contributions of Wikipedian Adrianne Wadewitz (1977-2014) who enlisted her peers and students to help reduce the gender imbalance by participating in mass collaborative initiatives like edit-a-thons to increase the stock of knowledge about and of interest to women. Such projects, and the edit-a-thons that continue to be convened in Wadewitz's honour, help to reconcile the imbalance and simultaneously present pedagogical opportunities. Drawing upon scholarly literature, this paper also illustrates how Wikipedia editing supports and reinforces the principles of both academic and public writing and represents an open and sustainable platform for formative and summative assessment. Moreover, the paper emphasises the superiority of digital informative texts created by mass-collaboration and participation over those compiled by individuals or through small group collaboration, both of which delimit the homogeneity of networked knowledge.},
  keywords = {Academic Language,Collaborative Writing,Cooperative Learning,Editing,Encyclopedias,Epistemology,Females,Gender Differences,Higher Education,Medical Research,Schemata (Cognition),Sex Fairness,Summative Evaluation,Teaching Methods,Web Sites},
  file = {/Users/colin.madland/Zotero/storage/YF9IENAM/dilauroIfItNot2020.pdf}
}

@article{dillard-wrightDraftingDiversityEquity2021,
  title = {Drafting a Diversity, Equity, and Inclusion Textbook Inventory: {{Assumptions}}, Concepts, Conceptual Framework},
  shorttitle = {Drafting a Diversity, Equity, and Inclusion Textbook Inventory},
  author = {{Dillard-Wright}, Jessica and Gazaway, Shena},
  year = {2021},
  month = jul,
  journal = {Teaching and Learning in Nursing},
  volume = {16},
  number = {3},
  pages = {247--253},
  issn = {15573087},
  doi = {10/gk36md},
  urldate = {2021-07-04},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/JE26VYG8/dillard-wrightDraftingDiversityEquity2021.pdf}
}

@article{divjakEassessmentMathematicsHigher2022,
  title = {E-Assessment in Mathematics in Higher Education: A Student Perspective},
  author = {Divjak, Bla{\v z}enka and {\v Z}ugec, Petra and Pa{\v z}ur Ani{\v c}i{\'c}, Katarina},
  year = {2022},
  journal = {International journal of mathematical education in science and technology},
  volume = {ahead-of-print},
  number = {ahead-of-print},
  pages = {1--23},
  publisher = {Taylor \& Francis},
  issn = {0020-739X},
  doi = {10.1080/0020739X.2022.2117659},
  abstract = {Assessment is among the inevitable components of a curriculum and directs students' learning. E-assessment, as prepared and administered with the use of ICT, provides opportunities to make the process easier in some aspects, but also brings certain challenges. This paper presents an e-assessment framework from a student perspective. Our study lasted for one academic year and incorporated a total of 631 students' responses to questionnaires conducted three times in two different mathematics courses. The courses are compulsory for undergraduate informatics students. The research included a three-step factor analysis: two exploratory factor analyses and a confirmatory factor analysis. It yielded a model of a student perspective on e-assessment consisting of four factors: Transparency and fairness of assessment, Formative and summative assessment and feedback, Meaningful use of technology in assessment and Difficulty of learning outcomes. The students' opinion about the use of e-assessment was generally positive. The students appreciated the student-centred approach based on sound pedagogical alignment of all teaching and learning elements with assessment. They found it important that technology should not distract students during assessment tasks and considered cheating in a controlled e-assessment environment to be no more frequent than in face-to-face assessment.},
  keywords = {97-02,assessment fairness,E-assessment,face-to-face assessment,feedback,higher education,mathematical education,student perspective,technology-enhanced learning},
  file = {/Users/colin.madland/Zotero/storage/5IULXKJD/divjakEassessmentMathematicsHigher2022.pdf}
}

@article{divjakFlippedClassroomsHigher2022,
  title = {Flipped Classrooms in Higher Education during the {{COVID-19}} Pandemic: Findings and Future Research Recommendations},
  author = {Divjak, Bla{\v z}enka and Rienties, Bart and Iniesto, Francisco and Vondra, Petra and {\v Z}i{\v z}ak, Mirza},
  year = {2022},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {19},
  number = {1},
  pages = {9--9},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-021-00316-4},
  abstract = {Flipped classroom (FC) approaches have gotten substantial attention in the last decade because they have a potential to stimulate student engagement as well as active and collaborative learning. The FC is generally defined as a strategy that flips the traditional education setting, i.e., the information transmission component of a traditional face-to-face lecture is moved out of class time. The FC relies on technology and is therefore suitable for online or blended learning, which were predominant forms of learning during the COVID-19 pandemic (March 2020--July 2021). In this paper we present a systematic literature review (SLR) of studies that covered online FC approaches in higher education during the pandemic. We analyzed 205 publications in total and 18 in detail. Our research questions were related to the main findings about the success of implementation of online FC and recommendations for future research. The findings indicated that those who had used FC approaches in face-to-face or blended learning environments more successfully continued to use them in online environments than those who had not used it before. The SLR opened possible questions for future research, such as the effectiveness of the FC for different courses and contexts, the cognitive and emotional aspects of student engagement, and students' data protection. It pointed to the need to examine different aspects of online delivery of the FC more comprehensively, and with more research rigor.},
  keywords = {Blended learning,Classrooms,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Coronaviruses,COVID-19,COVID-19 pandemic,Disease transmission,Distance learning,Educational Technology,Flipped classroom,Higher Education,Humanities,Information Systems Applications (incl.Internet),Law,Learning,Learning design,Literature reviews,Online instruction,Online learning,Pandemics,Questions,Review,Review Article,Statistics for Social Sciences,Student participation,Systematic literature review},
  file = {/Users/colin.madland/Zotero/storage/NUHXCXTT/divjakFlippedClassroomsHigher2022.pdf}
}

@article{dixonEnactingAssessmentLearning2011,
  title = {Enacting {{Assessment}} for {{Learning}}: The Beliefs Practice Nexus},
  author = {Dixon, Helen R. and Hawe, Eleanor and Parr, Judy},
  year = {2011},
  month = nov,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {18},
  number = {4},
  pages = {365--379},
  publisher = {Routledge},
  issn = {0969-594X},
  doi = {10/bmggbj},
  file = {/Users/colin.madland/Zotero/storage/972HHUAJ/dixonEnactingAssessmentLearning2011.pdf}
}

@incollection{dochyAssessmentEngineeringBreaking2007,
  title = {Assessment Engineering {{Breaking}} down Barriers between Teaching and Learning, and Assessment},
  booktitle = {Rethinking Assessment in Higher Education: Learning for the Longer Term},
  author = {Dochy, Filip and Seigers, Mein and Gijbels, David and Struyven, Katrien},
  editor = {Boud, David and Falchikov, Nancy},
  year = {2007},
  number = {Book, Whole},
  publisher = {Routledge},
  address = {London;New York;},
  doi = {10.4324/9780203964309},
  abstract = {Assessment is a value-laden activity surrounded by debates about academic standards, preparing students for employment, measuring quality and providing incentives. There is substantial evidence that assessment, rather than teaching, has the major influence on students' learning. It directs attention to what is important and acts as an incentive for study. This book revisits assessment in higher education, examining it from the point of view of what assessment does and can do and argues that assessment should be seen as an act of informing judgement and proposes a way of integrating teaching, learning and assessment to better prepare students for a lifetime of learning. It is essential reading for practitioners and policy makers in higher education institutions in different countries, as well as for educational development and institutional research practitioners.;Assessment is a value-laden activity surrounded by debates about academic standards, preparing students for employment, measuring quality and providing incentives. There is substantial evidence that assessment, rather than teaching, has the major influence on students' learning. It directs attention to what is important and acts as an incentive for study. This book revisits assessment in higher education, examining it from the point of view of what assessment does and can do and argues that assessment should be seen as an act of informing judgement and proposes a way of integrating teaching, learning and assessment to better prepare students for a lifetime of learning. It is essential reading for practitioners and policy makers in higher education institutions in different countries, as well as for educational development and institutional research practitioners.;'Assessment is a value-laden activity surrounded by debates about academic standards, preparing students for employment, measuring quality and providing incentives. There is substantial evidence that assessment, rather than teaching, has the major influence on students' learning. It directs attention to what is important and acts as an incentive for study. This book revisits assessment in higher education, examining it from the point of view of what assessment does and can do and argues that assessment should be seen as an act of informing judgement and proposes a way of integrating teaching, learning and assessment to better prepare students for a lifetime of learning. It is essential reading for practitioners and policy makers in higher education institutions in different countries, as well as for educational development and institutional research practitioners.'-- Publisher's website;},
  isbn = {9780203964309;9780415397780;0203964306;0415397782;0415397790;9780415397797;},
  langid = {english},
  keywords = {Assessment practices,Assessment strategies,College students,Curriculum,Educational tests and measurements,Higher Education,Learning,Lifelong Learning,Post-Compulsory Education,Postsecondary education,Professional development,Rating of,Student assessment,Testing,Vocational education and training},
  file = {/Users/colin.madland/Zotero/storage/ZYZFMQSQ/dochyAssessmentEngineeringBreaking2007.pdf}
}

@article{dolencMaintainingScientificInquiry2020,
  title = {Maintaining {{Scientific Inquiry}} in {{Online Education}}},
  author = {Dolenc, Nathan R. and Beaulieu, Patricia and Sheppard, Peter},
  year = {2020},
  journal = {Research Issues in Contemporary Education},
  volume = {5},
  number = {3},
  pages = {13--25},
  issn = {ISSN-},
  abstract = {Teachers were given the challenging task of transferring their formal science classroom lessons to an online format at the onset of the COVID-19 pandemic. How were teachers able to recreate student-centered science lessons online? What challenges did teachers face in teaching science online? This study examined how a group of teachers, working to create a summer online science camp, were able to maintain a science inquiry-based learning environment in an online format. Teachers revealed positive attitudes toward producing a scientific inquiry-based learning environment online, new opportunities for creativity in teaching science, and different perspectives on how teachers interact with students.},
  langid = {english},
  keywords = {Barriers,COVID-19,Curriculum Development,Distance Education,Electronic Learning,Inquiry,Middle School Teachers,No DOI found,Pandemics,Preservice Teachers,Science Instruction,Student Attitudes,Student Centered Learning,Summer Programs,Teacher Attitudes}
}

@article{dominguezfigaredoImpactRapidAdoption2022,
  title = {The {{Impact}} of {{Rapid Adoption}} of {{Online Assessment}} on {{Students}}' {{Performance}} and {{Perceptions}}: {{Evidence}} from a {{Distance Learning University}}},
  shorttitle = {The {{Impact}} of {{Rapid Adoption}} of {{Online Assessment}} on {{Students}}' {{Performance}} and {{Perceptions}}},
  author = {Dominguez Figaredo, Daniel and {Ines Gil Jaurena} and {Javier Morentin Encina}},
  year = {2022},
  month = mar,
  journal = {Electronic Journal of e-Learning},
  volume = {20},
  number = {3},
  pages = {pp224-241},
  issn = {1479-4403},
  doi = {10.34190/ejel.20.3.2399},
  urldate = {2023-06-20},
  abstract = {One of the most sensitive changes faced by universities due to the COVID-19 crisis was the remote assessment of student learning. This research analysed the case of a massive distance learning university that rapidly changed the final assessment (N=126,653 undergraduate students in 2020) from face-to-face exams to entirely online exams. The research focused on the influence of online assessment on academic performance and students' perception of the new method. Two data sources were used: the contrast of academic performance indicators (assessment, success and achievement rates, and average marks obtained) between the online examination call and the previous ones with face-to-face examinations; and a questionnaire to a sample of students (n=714) on their perception of the online assessment experience. The results show that all the academic performance indicators in the 28 Bachelor Degrees offered at the university increased when the final assessment method turned to online due to the pandemic crisis; and that a majority of students are more favourable to online assessment methods. The discussion places these findings in a context of rapid change, and concludes by identifying the possible implications of online assessment for student retention, organisational challenges, as well as possible further studies.},
  file = {/Users/colin.madland/Zotero/storage/EQMH3DHV/dominguezfigaredoImpactRapidAdoption2022.pdf}
}

@article{donaldCriticalAppraisalState1982,
  title = {A {{Critical Appraisal Of The State Of Evaluation In Higher Education In Canada}}},
  author = {Donald, Janet Gail},
  year = {1982},
  month = jun,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {7},
  number = {2},
  pages = {108--126},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/0260293820070202},
  urldate = {2022-12-19},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/IDHZFKXD/donaldCriticalAppraisalState1982.pdf}
}

@article{donnellyBuildingDigitalCapacity2020,
  title = {Building {{Digital Capacity}} for {{Higher Education Teachers}}: {{Recognising Professional Development}} through a {{National Peer Triad Digital Badge Ecosystem}}},
  author = {Donnelly, Roisin and Maguire, Terry},
  year = {2020},
  month = jan,
  journal = {European Journal of Open, Distance and E-Learning},
  volume = {23},
  number = {2},
  pages = {1--19},
  publisher = {{European Journal of Open, Distance and E-Learning}},
  issn = {1027-5207},
  doi = {10.2478/eurodl-2020-0007},
  abstract = {Digital Badge design and practice at a national level is a relatively new field of scrutiny and this study reports on a sector-wide initiative for building digital capacity with the design, and implementation of an ecosystem of 15 open courses in teaching and learning with digital badges to recognise the professional development of teachers in Irish higher education. Each course is provided in three delivery modes and mapped to Ireland's National Professional Development Framework for teachers. This enables multiple access points for teachers to engage in professional development via the Framework and recognize their engagement through peer triads and a digital badge ecosystem. The paper critically discusses and reflects on the study of the complex phenomena of the application of the open courses within professional contexts. A novel dimension is the implementation of a peer triad system for recognition of PD. Implementing the open courses digital badges ecosystem was challenging as this different form of assessment required a clear understanding of all stakeholder expectations, the language of recognition and how the learning outcomes could be met and validated using a peer triad assessment. This paper concludes with sectoral learning on nationally recognized open course development, including success factors for building digital capacity, challenges encountered and transferability to other contexts.},
  keywords = {Awards,Barriers,Blended Learning,Capacity Building,College Faculty,Course Descriptions,Evaluation Methods,Faculty Development,Foreign Countries,Guidelines,Higher Education,Ireland,Online Courses,Open Education,Outcomes of Education,Pedagogical Content Knowledge,Peer Evaluation,Professional Recognition,Reflective Teaching,Teaching Methods,Teaching Skills,Technological Literacy},
  file = {/Users/colin.madland/Zotero/storage/FK2UZKEX/donnellyBuildingDigitalCapacity2020.pdf}
}

@article{dooMetaAnalysisScaffoldingEffects2020,
  title = {A {{Meta-Analysis}} of {{Scaffolding Effects}} in {{Online Learning}} in {{Higher Education}}},
  author = {Doo, Min Young and Bonk, Curtis J. and Heo, Heeok},
  year = {2020},
  journal = {International Review of Research in Open and Distributed Learning},
  volume = {21},
  number = {3},
  pages = {60--80},
  issn = {EISSN-1492-3831},
  abstract = {The significance of scaffolding in education has received considerable attention. Many studies have examined the effects of scaffolding with diverse groups of participants, purposes, learning outcomes, and learning environments. The purpose of this research was to conduct a meta-analysis of the effects of scaffolding on learning outcomes in an online learning environment in higher education. This meta-analysis included studies with 64 effect sizes from 18 journal articles published in English, in eight countries, from 2010 to 2019. The meta-analysis revealed that scaffolding in an online learning environment has a large and statistically significant effect on learning outcomes. The meta-cognitive domain yielded a larger effect size than did the affective and cognitive domains. In terms of types of scaffolding activities, meta-cognitive scaffolding outnumbered other types of scaffolding. Computers as a scaffolding source in an online learning environment were also more prevalent than were human instructors. In addition, scholars in the United States have produced a large portion of the scaffolding research. Finally, the academic area of language and literature has adopted scaffolding most widely. Given that effective scaffolding can improve the quality of learning in an online environment, the current research is expected to contribute to online learning outcomes and learning experiences.},
  langid = {english},
  keywords = {Affective Behavior,Cognitive Processes,Educational Environment,Effect Size,Electronic Learning,Higher Education,Meta Analysis,Metacognition,No DOI found,Online Courses,Outcomes of Education,Scaffolding (Teaching Technique)}
}

@article{dossantosImprovingLearningVirtual2020,
  title = {Improving Learning in Virtual Learning Environments Using Affective Pedagogical Agent},
  author = {{\noopsort{santos}}{dos Santos}, M{\'a}rcio Aur{\'e}lio and Netto, Jos{\'e} Francisco de Magalh{\~a}es},
  year = {2020},
  month = oct,
  journal = {International Journal of Distance Education Technologies},
  volume = {18},
  number = {4},
  pages = {1--16},
  publisher = {IGI Global},
  issn = {1539-3100},
  abstract = {Emotions are part of human life, and they are present on several occasions, like decision making and in social interactions. Computational identification of emotions in texts can be useful in many applications, especially in distance learning courses. This research introduces an animated pedagogic agent, integrated to a Moodle virtual learning environment, with the objective of assisting the tutor in accompanying students, helping the students to acquire knowledge, identifying their emotions, and motivating the student to participate in activities and discussions. As a way of assessing students' emotional state, an experiment was conducted using real data from a completed course, involving students. The results obtained are promising, evidencing the importance of knowing the emotional state of the students, contributing to the learning process. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  keywords = {Affective Computing,AIML,Animated Pedagogical Agent,Animation,Educational Audiovisual Aids,Emotions,JADE,Learning,Learning Management Systems,Moodle,Multi-Agent System,No DOI found,Sentiment Analysis,Virtual Classrooms,Virtual Learning Environment}
}

@techreport{doucetThinkingPedagogyUnfolding,
  title = {Thinking about {{Pedagogy}} in an {{Unfolding Pandemic}}},
  author = {Doucet, Armand and Netolicky, Deborah and Timmers, Koen and Tuscano, Francis Jim},
  file = {/Users/colin.madland/Zotero/storage/UEDJHB8X/doucetThinkingPedagogyUnfolding.pdf}
}

@book{downesWebYourOwnn.d.,
  title = {Web 2.0 and {{Your Own Learning}} and {{Development}}},
  author = {Downes, Stephen},
  year = {n.d.}
}

@article{downieTechnologyEnhancedLearning2021,
  title = {Technology Enhanced Learning Environments in Higher Education: {{A}} Cross-Discipline Study on Teacher and Student Perceptions},
  shorttitle = {Technology Enhanced Learning Environments in Higher Education},
  author = {Downie, Sue and Gao, Xiaoping and Bedford, Simon and Bell, Kenton and Kuit, Tracey},
  year = {2021},
  month = oct,
  journal = {Journal of University Teaching and Learning Practice},
  volume = {18},
  number = {4},
  pages = {147--168},
  issn = {14499789, 14499789},
  doi = {10.53761/1.18.4.12},
  urldate = {2023-01-15},
  abstract = {Teacher and student perceptions of using technology enhanced learning (TEL) in higher education have received growing attention, particularly during COVID-19, however existing studies are mainly disciplinespecific. This study adopts a holistic cross-disciplinary approach. It compares teacher and student perceptions on defining TEL, promotors and barriers for its use, and solutions offered for better use of TEL in the future. Both qualitative and quantitative data were collected from an Australian university. A total of 75 teachers and 48 students completed an online survey, and of these participants, 24 teachers and 29 students participated in follow-up focus group interviews that included Kahoot! surveys. Quantitative results show that teacher and student perceptions on TEL were generally aligned except that self-reported technology savviness and confidence was rated higher than how students and staff rated each other. Qualitative analyses reveal that both teachers and students identified the main promoters for TEL as being: modern and expected in higher education, while being equalising, efficient, engaging, authentic, collaborative and flexible. The common barriers for using TEL were identified as fear, time, organisational culture, knowledge and technical/support issues, along with the perceived pitfalls of distraction, and superficial student learning. Solutions offered for TEL in the future from staff focused on the institution and a desire for strategic, pedagogical and holistic approaches, while students focussed on the accessibility, flexibility and collaborative potential of TEL. This cross-discipline pre-COVID-19 study of TEL perceptions offered by teachers and students has contributed to knowledge in this area by identifying barriers and solutions for TEL common to all disciplines that have the potential to be applied to whole of institution strategic approaches for the more effective use of TEL in teaching and learning in higher education. Student accessibility to TEL and the development of pedagogically sound digital learning resources bringing together educational developers and discipline experts are of particular relevance during and post-COVID-19.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/SQ4Z8M4T/downieTechnologyEnhancedLearning2021.pdf}
}

@article{Downing_2005,
  title = {The Effects of Violating Standard Item Writing Principles on Tests and Students the Consequences of Using Flawed Test Items on Achievement Examinations in Medical Education},
  author = {Downing, Steven M.},
  year = {2005},
  journal = {Advances in Health Sciences Education},
  doi = {10/c3dz2f},
  abstract = {The purpose of this research was to study the effects of violations of standard multiple-choice item writing principles on test characteristics, student scores, and pass--fail outcomes. Four basic science examinations, administered to year-one and year-two medical students, were randomly selected for study. Test items were classified as either standard or flawed by three independent raters, blinded to all item performance data. Flawed test questions violated one or more standard principles of effective item writing. Thirty-six to sixty-five percent of the items on the four tests were flawed. Flawed items were 0--15 percentage points more difficult than standard items measuring the same construct. Over all four examinations, 646 (53\%) students passed the standard items while 575 (47\%) passed the flawed items. The median passing rate difference between flawed and standard items was 3.5 percentage points, but ranged from -1 to 35 percentage points. Item flaws had little effect on test score reliability or other psychometric quality indices. Results showed that flawed multiple-choice test items, which violate well established and evidence-based principles of effective item writing, disadvantage some medical students. Item flaws introduce the systematic error of construct-irrelevant variance to assessments, thereby reducing the validity evidence for examinations and penalizing some examinees.},
  mag_id = {2152398619},
  pmcid = {null},
  pmid = {16078098}
}

@article{downingTestItemDevelopment1997,
  title = {Test {{Item Development}}: {{Validity Evidence From Quality Assurance Procedures}}},
  shorttitle = {Test {{Item Development}}},
  author = {Downing, Steven M. and Haladyna, Thomas M.},
  year = {1997},
  month = jan,
  journal = {Applied Measurement in Education},
  volume = {10},
  number = {1},
  pages = {61--82},
  issn = {0895-7347, 1532-4818},
  doi = {10/fhf4rh},
  urldate = {2020-12-22},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/I8EHDSKP/downingTestItemDevelopment1997.pdf}
}

@article{doyleAssessmentCoCreationExploratory2019,
  title = {Assessment {{Co-Creation}}: {{An Exploratory Analysis}} of {{Opportunities}} and {{Challenges Based}} on {{Student}} and {{Instructor Perspectives}}},
  author = {Doyle, Elaine and Buckley, Patrick and Whelan, Joanne},
  year = {2019},
  month = jan,
  journal = {Teaching in Higher Education},
  volume = {24},
  number = {6},
  pages = {739--754},
  publisher = {Teaching in Higher Education},
  issn = {1356-2517},
  doi = {10.1080/13562517.2018.1498077},
  abstract = {In recent years, research and practice focused on academics and students working in partnership to co-design learning and teaching in higher education has increased [Deeley and Bovill 2017. 'Staff student partnership in assessment: enhancing assessment literacy through democratic practices.' "Assessment \& Evaluation in Higher Education" 42 (3): 463-477. doi:10.1080/02602938.2015.1126551]. Student generation of content has been advocated as a means of fostering deep learning and high levels of students engagement, leading to enhanced conceptual understanding [Draper 2009. 'Catalytic Assessment: Understanding how MCQs and EVS can Foster Deep Learning.' "British Journal of Educational Technology" 40 (2): 285-293.]. However, within the discourse exploring staff-student co-creation, some concerns have been raised about whether students ought to, or indeed can, meaningfully act as partners in assessment [Cook-Sather, Bovill, and Felten 2014. "Engaging Students as Partners in Learning and Teaching." San~Francisco, CA: Jossey Bass.]. This paper describes the introduction of a co-creation assignment into an undergraduate tax module. Students' and instructors' perceptions of several aspects of the assignment were examined, facilitating the cataloguing and elucidation of the tensions involved in assessment co-creation. The paper suggests techniques to manage these challenges effectively, thereby providing a case study for others with an interest in implementing assessment co-creation within their own disciplinary context.},
  keywords = {Assignments,Business Administration Education,College Faculty,Multiple Choice Tests,Student Attitudes,Student Developed Materials,Teacher Attitudes,Teacher Developed Materials,Teacher Student Relationship,Test Construction,Undergraduate Students}
}

@article{doyumgacUnderstandingMostImportant2021,
  title = {Understanding the {{Most Important Facilitators}} and {{Barriers}} for {{Online Education}} during {{COVID-19}} through {{Online Photovoice Methodology}}},
  author = {Doyumga{\c c}, Ibrahim and Tanhan, Ahmet and Kiymaz, Mustafa Said},
  year = {2021},
  journal = {International Journal of Higher Education},
  volume = {10},
  number = {1},
  pages = {166--190},
  issn = {ISSN-1927-6044},
  doi = {10/gmbv28},
  abstract = {There are three main research goals in this study including (a) understanding the most important facilitators (support, strength) and complicators (barrier, concern, issues, problems) for online or distance education during COVID-19 from the unique perspective of college students, academicians, and teachers through Online Photovoice (OPV); (b) advocating with the volunteer participants and partners as allies to share the results with the key people and institutions through online avenues to enhance facilitators and address complicators; and finally, (c) investigating participants' attribution of facilitators and complicators based on Ecological Systems Theory (EST) levels. The researchers utilized the adapted Turkish version of OPV to collect and used Online Interpretative Phenomenological Analysis (OIPA) to analyze the data. Community-Based Participatory Research (CBPR) grounded in EST constructed the theoretical framework for the research. In total, 115 participants completed and consented for the study. Sixteen main "facilitator-related themes" emerged, and the five most expressed were having technology (n = 31, 35\%), internet (n = 28, 32\%), communication (n =18, 20\%), emotions (n = 17, 19\%), and economic resources (n = 16, \%18). Thirteen main complicators"-related themes" emerged, and the five most reported barriers were lacks of technological resources (n = 41, 47\%), internet (n = 40, 46\%), appropriate learning environments, learning opportunities (n = 32, 36\%) appropriate resources for online or distance education (n = 18, 20\%), and interaction (n = 14, 16\%). Participants attributed the facilitator and complicators to EST levels respectively as follows: individual/intrapsychic factors (84\%; 69\%), microsystem (45\%; 59\%), exosystem (36\%; 43\%), and macrosystem (34\%; 44\%). The researchers provided practical recommendations. The researchers obtained an institutional review board approval for this study.},
  langid = {english},
  keywords = {Access to Computers,Barriers,College Faculty,College Students,COVID-19,Economic Factors,Educational Environment,Educational Resources,Educational Technology,Electronic Learning,Emotional Response,Foreign Countries,Interaction,Internet,Interpersonal Communication,Online Courses,Pandemics,School Closing,Student Attitudes,Teacher Attitudes}
}

@book{draaijerTechnologyEnhancedAssessment2019,
  title = {Technology {{Enhanced Assessment}} 21st {{International Conference}}, {{TEA}} 2018, {{Amsterdam}}, {{The Netherlands}}, {{December}} 10--11, 2018, {{Revised Selected Papers}}},
  author = {Draaijer, {\relax Silvester}. and {Joosten-ten Brinke}, {\relax Desir{\'e}e}. and Ras, {\relax Eric}.},
  year = {2019},
  series = {Communications in {{Computer}} and {{Information Science}}, 1014},
  edition = {1st ed. 2019.},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-25264-9},
  abstract = {This book constitutes the proceedings of the 21st International Conference on Technology Enhanced Assessment, TEA 2018, held in Amsterdam, The Netherlands, in December 2018. The 14 papers presented were carefully selected from 34 submissions. They are centered around topics like e-learning, computer-assisted instruction, interactive learning environments, collaborative learning, computing education, student assessment.},
  isbn = {3-030-25264-7},
  keywords = {Application software,Computer Appl. in Social and Behavioral Sciences,Computer security,Computers and Education,Education-Data processing,Image Processing and Computer Vision,Information Systems Applications (incl. Internet),Optical data processing,Pattern recognition,Pattern Recognition,Systems and Data Security},
  file = {/Users/colin.madland/Zotero/storage/HH25HGTJ/draaijerTechnologyEnhancedAssessment2019.pdf}
}

@book{drasgowTechnologyTesting2015,
  title = {Technology and {{Testing}}},
  editor = {Drasgow, Fritz},
  year = {2015},
  month = aug,
  edition = {0},
  publisher = {Routledge},
  doi = {10.4324/9781315871493},
  urldate = {2021-04-28},
  isbn = {978-1-317-97589-2},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/5J9WGHVT/drasgowTechnologyTesting2015.pdf}
}

@book{drasgowTechnologyTestingImproving2016,
  title = {Technology and Testing: Improving Educational and Psychological Measurement},
  shorttitle = {Technology and Testing},
  editor = {Drasgow, Fritz},
  year = {2016},
  series = {Ncme Applications of Educational Measurement and Assessment Book Series},
  publisher = {Routledge},
  address = {New York},
  isbn = {978-0-415-71715-1 978-0-415-71716-8 978-1-315-87149-3},
  lccn = {LB3051 .T43 2016},
  keywords = {Educational technology,Educational tests and measurements},
  file = {/Users/colin.madland/Zotero/storage/NXPD492P/drasgowTechnologyTestingImproving2016.pdf}
}

@article{drawsonIndigenousResearchMethods2017,
  title = {Indigenous {{Research Methods}}: {{A Systematic Review}}},
  shorttitle = {Indigenous {{Research Methods}}},
  author = {Drawson, Alexandra and Toombs, Elaine and Mushquash, Christopher},
  year = {2017},
  month = apr,
  journal = {International Indigenous Policy Journal},
  volume = {8},
  number = {02},
  issn = {19165781, 19165781},
  doi = {10.18584/iipj.2017.8.2.5},
  urldate = {2019-03-13},
  abstract = {Indigenous communities and federal funding agencies in Canada have developed policy for ethical research with Indigenous Peoples. Indigenous scholars and communities have begun to expand the body of research regarding their peoples, and novel and innovative methods have begun to appear in the published literature. This review attempts to catalogue the wide array of Indigenous research methods in the peer-reviewed literature and describe commonalities among methods in order to guide researchers and communities in future method development. A total of 64 articles met inclusionary criteria and five themes emerged: General Indigenous Frameworks, Western Methods in an Indigenous Context, Community-Based Participatory Research, Storytelling, and Culture-Specific Methods.},
  file = {/Users/colin.madland/Zotero/storage/BWV4X5JJ/drawsonIndigenousResearchMethods2017.pdf}
}

@book{driscollPsychologyLearningInstruction2005,
  title = {Psychology of Learning for Instruction},
  shorttitle = {Psychology of Learning for Instruction},
  author = {Driscoll, Marcy P.},
  year = {2005},
  edition = {3rd},
  publisher = {Pearson Education},
  address = {Boston},
  isbn = {0-205-37519-7}
}

@article{dronEducationalTechnologyWhat2022,
  title = {Educational Technology: What It Is and How It Works},
  shorttitle = {Educational Technology},
  author = {Dron, Jon},
  year = {2022},
  journal = {AI \& Society},
  volume = {37},
  number = {1},
  pages = {155--166},
  issn = {0951-5666, 1435-5655},
  doi = {10.1007/s00146-021-01195-z},
  urldate = {2023-01-26},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/UDKJ8USZ/dronEducationalTechnologyWhat2022.pdf}
}

@misc{dronEvaluatingAssessment2020,
  title = {Evaluating Assessment},
  author = {Dron, Jon},
  year = {2020},
  month = aug,
  journal = {Jon Dron's home page},
  urldate = {2020-09-01},
  abstract = {A group of us at AU have begun discussions about how we might transform our assessment practices, in the light of the far-reaching AU Imagine plan~and principles. This is a rare and exciting o{\dots}},
  langid = {canadian},
  file = {/Users/colin.madland/Zotero/storage/WXN7WC4B/evaluating-assessment.html}
}

@inproceedings{dronLearningDistanceTeaching2013,
  title = {Learning in a {{Distance Teaching Community}}: {{A Case Study}}},
  booktitle = {Society for {{Information Technology}} \& {{Teacher Education International Conference}} 2013},
  author = {Dron, Jon and Anderson, Terry},
  editor = {McBride, Ron and Searson, Michael},
  year = {2013},
  pages = {402--413},
  publisher = {Association for the Advancement of Computing in Education (AACE)},
  abstract = {Athabasca University (AU) is an open and distance university. This distance applies not only to students but to the staff, who are distributed over thousands of kilometres across Canada and, in some cases, beyond. The consequences of this distribution mean that, as a learning community, transactional distance is a problem for teachers as well as for students. In this paper we report on how this problem evolves and presents itself, and describe progress we have been making to reduce the distance, notably through Athabasca Landing, a social construction kit and shared informal and formal learning environment intended to fill some of the gaps. In the process, we extend and develop the notion of transactional distance to describe how it applies outside the closed formal groups of intentional learning into network, set and collective contexts.},
  file = {/Users/colin.madland/Zotero/storage/TSN7VYEG/dronLearningDistanceTeaching2013.pdf}
}

@article{drummFolkPedagogiesPseudotheories2019,
  title = {Folk Pedagogies and Pseudo-Theories: How Lecturers Rationalise Their Digital Teaching},
  shorttitle = {Folk Pedagogies and Pseudo-Theories},
  author = {Drumm, Louise},
  year = {2019},
  month = feb,
  journal = {Research in Learning Technology},
  volume = {27},
  number = {0},
  issn = {2156-7077},
  doi = {10/gghm48},
  urldate = {2020-01-13},
  file = {/Users/colin.madland/Zotero/storage/ZTVM3AMY/drummFolkPedagogiesPseudotheories2019.pdf}
}

@article{dsaAnalysisMultipleChoice2017,
  title = {Analysis of {{Multiple Choice Questions}}: {{Item Difficulty}}, {{Discrimination Index}} and {{Distractor Efficiency}}},
  shorttitle = {Analysis of {{Multiple Choice Questions}}},
  author = {D'Sa, Juliana Linnette and {Visbal-Dionaldo}, Maria Liza},
  year = {2017},
  journal = {International Journal of Nursing Education},
  volume = {9},
  number = {3},
  pages = {109},
  issn = {0974-9349, 0974-9357},
  doi = {10.5958/0974-9357.2017.00079.4},
  urldate = {2023-06-24},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/X7S9XND2/dsaAnalysisMultipleChoice2017.pdf}
}

@book{duarteNetworkSovereigntyBuilding2017,
  title = {Network Sovereignty: Building the {{Internet}} across {{Indian Country}}},
  author = {Duarte, Marisa Elena},
  year = {2017},
  series = {Indigenous Confluences},
  publisher = {University of Washington},
  address = {Seattle},
  abstract = {"The histories of information and communication technologies (ICTs) are intertwined with U.S. histories of colonization, and the sovereignty and self-determination of Native peoples. This book examines case studies of tribal governments building out broadband infrastructures--the infrastructures that undergird uses of ICTs such as mobile phones, computers, databases, and streaming radio--to reveal how the processes of network design and deployment embed these information and communication infrastructures within the ongoing exercise of tribal sovereignty in the U.S."--Provided by publisher},
  isbn = {978-0-295-74181-9 0-295-74181-3 978-0-295-74182-6 0-295-74182-1},
  lccn = {E98.C73 D83 2017},
  keywords = {21st century,Broadband communication systems,Communication,Computer networks,Digital divide,Government policy,Government relations History,History,Indians of North America,Information technology,Internet,Social aspects,Sovereignty,Telecommunication systems,United States},
  annotation = {OCLC: ocn960969109},
  file = {/Users/colin.madland/Zotero/storage/QX95S7LW/duarteNetworkSovereigntyBuilding2017.pdf}
}

@article{ducasseOralReflectionTasks2022,
  title = {Oral {{Reflection Tasks}}: {{Advanced Spanish L2 Learner Insights}} on {{Emergency Remote Teaching Assessment Practices}} in a {{Higher Education Context}}},
  author = {Ducasse, Ana Maria},
  year = {2022},
  journal = {Languages (Basel)},
  volume = {7},
  number = {1},
  pages = {26},
  publisher = {MDPI AG},
  address = {Basel},
  issn = {2226-471X},
  doi = {10.3390/languages7010026},
  abstract = {This paper reports on a small-scale study that is the first to explore Advanced Spanish L2 learners' personal awareness of their language and culture learning through e-assessment tasks in an Emergency Remote Teaching (ERT) context, mediated by five task-specific, individual spoken reflections. The value of reflection in education, particularly for L2 writing and distance learning, has been explored in different modalities, e.g., individual spoken reflection and group spoken reflection. Building on previous research, this study explores a group of advanced Spanish L2 learners (n = 25) reflecting on five multi-modal e-assessments through individually assessed oral audio-recorded post-assessment reflection tasks (n = 125). A thematic content analysis applied to transcriptions yields findings from a pedagogical perspective on language learning, completing assessments and personal affective responses. The learners' candid and explicit orientations towards various types of multimodal language-learning e-assessment tasks offer instructors information on learners' awareness of classroom-based assessment tasks being enablers for individual learning goals.},
  keywords = {assessment in COVID-19,Collaboration,Content analysis,COVID-19,Cultural instruction,Digital photography,Distance learning,e-assessment,Educational activities,Educational objectives,Emergency Remote Teaching (ERT),Higher education,Instructional design,L2 learner reflection,Language acquisition,Learning,Learning environment,Multimodality,Online instruction,Pandemics,Pedagogy,Reflective teaching,Second language learning,Second language writing,Spanish as a second language,Spanish teaching,Spoken language,Students,synchronous mode,Teaching},
  file = {/Users/colin.madland/Zotero/storage/QME3RFGI/ducasseOralReflectionTasks2022.pdf}
}

@article{duesberyDevelopingDesigningOpen2019,
  title = {Developing and {{Designing Open Border Teacher Education Programs}}: {{Case Studies}} in {{Online Higher Education}}},
  author = {Duesbery, Luke and Frizelle, Sara and Twyman, Todd and Naranjo, Jason and Timmermans, Karren},
  year = {2019},
  journal = {Journal of Educators Online},
  volume = {16},
  number = {1},
  issn = {EISSN-1547-500X},
  doi = {10/gmbvzv},
  abstract = {Online classes in teacher education are becoming more common in higher education in the United States as universities realize that the same outcomes can be achieved without requiring preservice and in-service teachers to enter a physical classroom. This provides savings to both the student and university and fosters broader access to higher education and teacher education. In this series of case studies, we highlight both practical and innovative approaches as we analyze and discuss our experiences building and implementing online teacher education programs. We describe three new online programs on the west coast of the United States: a master's degree in teaching in California, a reading endorsement program in Oregon, and a credential program in special education in Washington State. We discuss the initial program outcomes and the lessons learned to help guide teacher educators, administrators, and researchers in institutes of higher education. We culminate with five general recommendations for those considering program change or creation.},
  langid = {english},
  keywords = {Case Studies,Distance Education,Electronic Learning,Higher Education,Inclusion,Masters Degrees,Masters Programs,Online Courses,Program Development,Reading Programs,Special Education,Special Education Teachers,Teacher Education,Teacher Education Programs}
}

@book{duffyLearnercenteredTheoryPractice2004,
  title = {Learner-Centered Theory and Practice in Distance Education : Cases from Higher Education},
  author = {Duffy, Thomas M. and Kirkley, Jamie R.},
  year = {2004},
  publisher = {Lawrence Erlbaum Associates},
  address = {Mahwah, N.J},
  doi = {10.4324/9781410609489},
  abstract = {Learner-Centered Theory and Practice in Distance Education: Cases From Higher Education brings the voice of the learning sciences to the study and design of distance learning. The contributors examine critical issues in the design of theoretically and pedagogically based distance education programs. Eight distance education programs are described in enough detail to allow readers with different interests to understand the pedagogical approaches and the implications of implementing those approaches. Issues of theory, pedagogy, design, assessment, communities of practice, collabor},
  isbn = {1-135-62392-9},
  keywords = {Distance education -- United States,Electronic books,Instructional systems -- United States -- Design,Internet in higher education -- United States},
  file = {/Users/colin.madland/Zotero/storage/EHQ54ZNV/duffyLearnercenteredTheoryPractice2004.pdf}
}

@article{Duncan2007FactorsAT,
  title = {Factors Affecting Teachers' Grading and Assessment Practices.},
  author = {Duncan, C. R. and Noonan, B.},
  year = {2007},
  journal = {Alberta Journal of Educational Research},
  volume = {53},
  pages = {1--21},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/2GZHSW59/Duncan2007FactorsAT.pdf}
}

@article{duncanNecessityLackThereof2022,
  title = {On the Necessity (or Lack Thereof) of Digital Proctoring: {{Drawbacks}}, Perceptions, and Alternatives},
  author = {Duncan, Alex and Joyner, David},
  year = {2022},
  journal = {Journal of Computer Assisted Learning},
  volume = {38},
  number = {5},
  pages = {1482--1496},
  publisher = {John Wiley \& Sons, Inc},
  address = {Chichester, UK},
  issn = {0266-4909},
  doi = {10.1111/jcal.12700},
  abstract = {Background It is important for institutions of higher education to maintain academic integrity, both for students and the institutions themselves. Proctoring is one way of accomplishing this, and with the increasing popularity of online courses---along with the sudden shift to online education sparked by the COVID-19 pandemic---digital proctoring has seen an increase in use. However, there are privacy and bias concerns related to digital proctoring, so it is important to critically examine its role in higher education---when it should and should not be used, and how it is perceived among those who interact with it. Objectives In this paper, we: examine the features of and concerns about digital proctoring; analyse the results of a survey regarding student and teaching assistant (TA) attitudes towards digital proctoring; and present alternatives to digital proctoring and a framework for evaluating the need for a digital proctoring tool. Methods We surveyed students and TAs in an online graduate computer science program, asking them to provide their agreement or disagreement with 20 statements related to digital proctoring. For each response option on each statement, we calculated overall percentages as well as percentages broken out by demographics. We compared these percentages to develop a picture of student and TA perceptions. Results and Conclusions Students and TAs alike are generally tolerant of digital proctoring software and perceive some benefits to using it, including adding integrity to course grades and value to degree programs. However, they have some concerns in the areas of privacy, equity, and technical difficulties. Takeaways Digital proctoring software should be used only when necessary, with thought devoted to its impact on students and TAs and any concerns they may have. There exist alternative methods for maintaining academic integrity in a course. The framework we have presented can help with determining the need for digital proctoring. Lay Description Current Knowledge Digital proctoring is increasing in usage, particularly in the wake of the COVID-19 pandemic. Students are more likely to cheat in un-proctored environments. There are privacy and equity concerns related to the use of digital proctoring software. Not much research exists on student and teaching assistant attitudes towards digital proctoring. Our Contributions We define the features that most digital proctoring tools share and articulate their benefits and drawbacks. We present the results of a survey about student and teaching assistant attitudes towards digital proctoring. We provide alternative methods for maintaining academic integrity focusing on assessment design and administration. We provide a framework for determining whether it is necessary to use digital proctoring in a course. Implications of Findings Digital proctoring should only be used when absolutely necessary. Students and teaching assistants are generally positive about the use of digital proctoring. Concerns about privacy, bias, and technical difficulties should be considered when using digital proctoring.},
  keywords = {academic integrity,assessment design,Attitudes,Bias,CAI,cheating,Computer assisted instruction,Computer science,COVID-19,digital proctoring,Distance learning,Education & Educational Research,Education Higher,Educational technology,Higher education,Higher education institutions,Integrity,Online instruction,Pandemics,Privacy,Social Sciences,Software,Student attitudes,Students,Teaching assistants},
  file = {/Users/colin.madland/Zotero/storage/2PBIL6K4/duncanNecessityLackThereof2022.pdf}
}

@article{Dunn_2009,
  title = {A Critical Review of Research on Formative Assessment the Limited Scientific Evidence of the Impact of Formative Assessment in Education},
  author = {Dunn, Karee E. and Mulvenon, Sean W.},
  year = {2009},
  journal = {Practical Assessment, Research and Evaluation},
  doi = {10/ghhtsk},
  abstract = {The existence of a plethora of empirical evidence documenting the improvement of educational outcomes through the use of formative assessment is conventional wisdom within education. In reality, a limited body of scientifically based empirical evidence exists to support that formative assessment directly contributes to positive educational outcomes. The use of formative assessments, or other diagnostic efforts within classrooms, provides information that should help facilitate improved pedagogical practices and instructional outcomes. However, a review of the formative assessment literature revealed that there is no agreed upon lexicon with regard to formative assessment and suspect methodological approaches in the efforts to demonstrate positive effects that could be attributed to formative assessments. Thus, the purpose of this article was two-fold. First, the authors set out to clarify the terminology related to formative assessment and its usage. Finally, the article provides a critical analysis of the seminal literature on formative assessment, beginning with Black and Wiliam (1998), and extending through current published materials.},
  mag_id = {27638224},
  pmcid = {null},
  pmid = {null},
  keywords = {guskey}
}

@article{dunnYourOnlineTextbook2021,
  title = {Your Online Textbook Is Ready: A Shareable, Interactive Online Textbook in Response to {{COVID-19}} Lockdowns},
  shorttitle = {Your Online Textbook Is Ready},
  author = {Dunn, Peter K. and Brunton, Elizabeth A. and Farrar, Michael B.},
  year = {2021},
  month = oct,
  journal = {International Journal of Mathematical Education in Science and Technology},
  pages = {1--12},
  issn = {0020-739X, 1464-5211},
  doi = {10.1080/0020739x.2021.1983051},
  urldate = {2021-11-09},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/UU8NREPT/dunnYourOnlineTextbook2021.pdf}
}

@article{duretCollaborativeLearningPeerWise2018,
  title = {Collaborative Learning with {{PeerWise}}},
  author = {Duret, Denis and Christley, Rob and Denny, Paul and Senior, Avril},
  year = {2018},
  month = jan,
  journal = {Research in Learning Technology},
  volume = {26},
  number = {0},
  issn = {2156-7077},
  doi = {10/gg9jtn},
  urldate = {2020-08-30},
  file = {/Users/colin.madland/Zotero/storage/MBMCT9T9/duretCollaborativeLearningPeerWise2018.pdf}
}

@book{dweckMindsetNewPsychology2006,
  title = {Mindset: {{The}} New Psychology of Success},
  author = {Dweck, Carol S.},
  year = {2006},
  edition = {1st ed.},
  publisher = {Random House},
  address = {New York},
  isbn = {1-4000-6275-6},
  keywords = {Belief and doubt,Success -- Psychological aspects}
}

@article{dwivediReexaminingUnifiedTheory2019,
  title = {Re-Examining the {{Unified Theory}} of {{Acceptance}} and {{Use}} of {{Technology}} ({{UTAUT}}): {{Towards}} a {{Revised Theoretical Model}}},
  author = {Dwivedi, Yogesh K. and Rana, Nripendra P. and Jeyaraj, Anand and Clement, Marc and Williams, Michael D.},
  year = {2019},
  journal = {Information Systems Frontiers},
  volume = {21},
  number = {3},
  pages = {719--734},
  issn = {1572-9419},
  doi = {10/gdvjnv},
  abstract = {Based on a critical review of the Unified Theory of Acceptance and Use of Technology (UTAUT), this study first formalized an alternative theoretical model for explaining the acceptance and use of information system (IS) and information technology (IT) innovations. The revised theoretical model was then empirically examined using a combination of meta-analysis and structural equation modelling (MASEM) techniques. The meta-analysis was based on 1600 observations on 21 relationships coded from 162 prior studies on IS/IT acceptance and use. The SEM analysis showed that attitude: was central to behavioural intentions and usage behaviours, partially mediated the effects of exogenous constructs on behavioural intentions, and had a direct influence on usage behaviours. A number of implications for theory and practice are derived based on the findings.},
  file = {/Users/colin.madland/Zotero/storage/735V5UF2/dwivediReexaminingUnifiedTheory2019.pdf}
}

@article{dwyerCutScoresTesting1996,
  title = {Cut Scores and Testing: {{Statistics}}, Judgment, Truth, and Error.},
  shorttitle = {Cut Scores and Testing},
  author = {Dwyer, Carol Anne},
  year = {1996},
  journal = {Psychological Assessment},
  volume = {8},
  number = {4},
  pages = {360--362},
  issn = {1939-134X, 1040-3590},
  doi = {10/d795hq},
  urldate = {2021-01-07},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/HNJP3DU8/dwyerCutScoresTesting1996.pdf}
}

@book{dwyerFutureAssessmentShaping2017,
  title = {The Future of Assessment: Shaping Teaching and Learning},
  shorttitle = {The Future of Assessment},
  author = {Dwyer, Carol Anne},
  year = {2017},
  edition = {1st},
  publisher = {Routledge},
  address = {London},
  isbn = {978-1-351-54441-2},
  langid = {english},
  annotation = {OCLC: 1005608225}
}

@book{dwyerNarrativeResearchPractice2017,
  title = {Narrative Research in Practice: Stories from the Field},
  author = {Dwyer, Rachael and Davis, Ian and {emerald}, elke},
  year = {2017},
  number = {Book, Whole},
  publisher = {Springer},
  address = {Singapore, Singapore},
  abstract = {This book directly addresses the multiplicity and complexity of narrative research by illustrating a variety of avenues to pursuing and publishing research that falls under the umbrella of narrative work. The chapters are drawn from a wide range of disciplines including education, literary studies, cultural studies, music and clinical studies. Each chapter considers a particular methodological issue or approach, illustrating how it was addressed in the course of the research. Each of the chapters concludes with a set of discussion exercises and a further reading list. The book offers a valuable resource for established researchers seeking to expand their methodological and theoretical repertoire, and for graduate students and researchers new to narrative methods.},
  isbn = {9789811015779;9811015775;9789811015793;9811015791;},
  keywords = {Narrative inquiry (Research method),Social sciences_xMethodology}
}

@article{dymentOnlineInitialTeacher2018,
  title = {Online {{Initial Teacher Education Students}}' {{Perceptions}} of {{Using Web Conferences}} to {{Support Professional Conversations}}},
  author = {Dyment, Janet E. and Downing, Jill},
  year = {2018},
  journal = {Australian Journal of Teacher Education},
  volume = {43},
  number = {4},
  pages = {68--91},
  issn = {ISSN-0313-5373},
  doi = {10/gmbv33},
  abstract = {This paper draws on the work of Helen Timperley (2015) who suggests there are six clear enablers that support educators to have professional conversations: processes, resources, culture, knowledge, relationships, as well as context. This purpose of this paper is two-fold: first, it describes how weekly web conferences that were offered for online initial teacher education students (ITES) were designed with due consideration for Timperley's enablers for professional conversations; and second, it reports on student experiences of the ways in which the web conferences served to support professional conversations. In order to understand the complex and multifaceted ways that web conferences served to facilitate ITES engagement in professional conversations, data is drawn from thirty-two online ITES enrolled in a capstone unit in their final semester of study in a teacher education course. Using a descriptive mixed-methods case study approach, the ITES completed questionnaires, participated in follow-up interviews and completed their assessment tasks to shed insight into the impact of the web conferences. The findings reveal the powerful ways that the web conferences allowed the students to participate in meaningful professional conversations and helped develop the professional attributes expected of graduates. Importantly, the study revealed that ITES perceived that the web conferences prompted a deeper level of engagement, satisfaction and sense of achievement than alternative activities, including face-to-face tutorials.},
  langid = {english},
  keywords = {Blended Learning,Computer Mediated Communication,Educational Technology,Foreign Countries,Higher Education,Interpersonal Relationship,Knowledge Level,Masters Programs,Mixed Methods Research,Online Courses,Preservice Teacher Education,Preservice Teachers,School Culture,Student Attitudes,Teaching Methods,Technology Uses in Education,Videoconferencing}
}

@article{eadyRightsRespectResponsibilities2018,
  title = {Rights, {{Respect}} and {{Responsibilities Online--Reflections}} and {{Efficacy}}},
  author = {Eady, Michelle J. and Jones, Michael L. and Alony, Irit and Berry, Yoke},
  year = {2018},
  journal = {Australian Journal of Teacher Education},
  volume = {43},
  number = {3},
  pages = {35--54},
  issn = {ISSN-0313-5373},
  doi = {10/gmbv2v},
  abstract = {Demands for moral development are increasing in business and professional training. Mixed results of diversity training programs in the higher education sector suggest that innovative approaches are required for preparing students to become morally upright leaders and teachers. This research looks at the implementation of an online interactive tutorial that focuses on students working and learning together with others from a variety of diverse backgrounds. The study comprises a three-year investigation on the attitudes and understandings of students prior to a group work assessment task, and after completing the online tutorial. First year primary education students (n = 594) completed pre- and post-surveys on their perspective of working with others, with a moderating educational intervention. Results revealed mixed views about the value of the program to this generation of students. We make suggestions for institutions of higher education to consider when creating diversity training and support for university students.},
  langid = {english},
  keywords = {Civil Rights,College Students,Cultural Pluralism,Diversity (Institutional),Electronic Learning,Foreign Countries,Group Activities,Mixed Methods Research,Moral Development,Online Courses,Reflection,Self Efficacy,Social Attitudes,Student Attitudes,Student Responsibility,Student Surveys,Training,Tutorial Programs}
}

@book{earlAssessmentLearningUsing2013,
  ids = {earlAssessmentLearningUsing2013a},
  title = {Assessment as Learning: Using Classroom Assessment to Maximize Student Learning},
  shorttitle = {Assessment as Learning},
  author = {Earl, Lorna M.},
  year = {2013},
  edition = {Second edition},
  publisher = {Corwin Press},
  address = {Thousand Oaks, Calif},
  isbn = {978-1-4522-4297-2},
  lccn = {LB3051 .E19 2013},
  keywords = {Educational tests and measurements,Learning},
  file = {/Users/colin.madland/Zotero/storage/DWR5P44L/earlAssessmentLearningUsing2013.pdf}
}

@incollection{earlChallengingConceptionsAssessment2014,
  title = {Challenging {{Conceptions}} of {{Assessment}}},
  booktitle = {Designing {{Assessment}} for {{Quality Learning}}},
  author = {Earl, Lorna M. and Timperley, Helen},
  editor = {{Wyatt-Smith}, Claire and Klenowski, Valentina and Colbert, Peta},
  year = {2014},
  volume = {1},
  pages = {325--336},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-94-007-5902-2_20},
  urldate = {2022-05-07},
  isbn = {978-94-007-5901-5 978-94-007-5902-2},
  file = {/Users/colin.madland/Zotero/storage/RUFG9BNN/earlChallengingConceptionsAssessment2014.pdf}
}

@article{earleBalancingDemandsValidity2020,
  title = {Balancing the Demands of Validity and Reliability in Practice: Case Study of a Changing System of Primary Science Summative Assessment},
  author = {Earle, Sarah},
  year = {2020},
  journal = {London Review of Education},
  doi = {10/gmgbps},
  abstract = {Teacher summative judgements of children's attainment in science, statutory at age 11 in England, require consideration of both valid sampling of the construct and reliable comparison of outcomes. In order to develop understanding of the enacted `trade off' between validity and reliability, this three-year case study, within the Teacher Assessment in Primary Science (TAPS) project, was undertaken during a period of statutory assessment change in England. The case demonstrates an ongoing balancing act between the demands of reliability and validity, and resulted in the development of a Teacher Assessment Seesaw, which provides a model for both interpreting and supporting practice, within and beyond primary science.}
}

@article{earleFormativeDecisionMakingResponse2021,
  title = {Formative {{Decision-Making}} in {{Response}} to {{Primary Science Classroom Assessment}}: {{What}} to Do {{Next}}?},
  author = {Earle, Sarah},
  year = {2021},
  journal = {Frontiers in Education},
  doi = {10/gmgbpt},
  abstract = {Classroom assessment is purposeful when the information is utilised by teachers to support learning. Such formative assessment practices can be difficult to enact in a primary science classroom, with the whole class often involved in practical activities and with limited lesson time. This preliminary study seeks to explore formative decision-making and the subsequent actions taken by teachers in the classroom. Primary teachers who used a Teacher Assessment in Primary Science (TAPS) Focused Assessment activity were asked to describe what action they took as a result of the classroom interactions stimulated by the activity. 142 teachers in 9 regions of England completed a paper questionnaire at a training day. The qualitative data pertinent to the study was extracted and thematic content analysis carried out to determine the kinds of actions and changes to practice that were described. It was found that the `next step' described by teachers varied in timing; some made changes within the lesson, others provided follow up activities or made longer-term adaptation to teaching practices. Being responsive to the assessment information provided by the children took many forms, for example, supporting pupils to reflect on investigations during the lesson, discussing vocabulary or concepts, providing time for further exploration, or explicit modelling of science skills. Formative decisions were taken at a whole class level, rather than making individual adaptations. It is argued that enabling teachers to be more explicit about their tacit decision-making could support them to make more formative use of assessment information to support pupil learning.}
}

@phdthesis{earleRelationshipFormativeSummative2018,
  title = {The Relationship between Formative and Summative Teacher Assessment of Primary Science in {{England}}},
  author = {Earle, Sarah},
  year = {2018},
  urldate = {2021-07-27},
  abstract = {Assessment drives the taught curriculum, defines what is valued (Stobart 2008) and can enhance or hinder learning (Mansell et al. 2009). In England, the complexities of assessment are compounded by ongoing changes to statutory assessment procedures and a lack of centralised guidance for judgements of primary science (Turner et al. 2013). The Nuffield expert group (2012) proposed a pyramid-shaped model of teacher assessment which utilised formative information to inform summative judgements. The model was operationalised by the Teacher Assessment in Primary Science (TAPS) project (Davies et al. 2014), but there was no explicit explanation of the 'formative to summative' process. This study sought to develop understanding of the relationship between formative and summative teacher assessment of primary science, in action and over time. A Design-Based Research (DBR) approach was used in order to develop guidance directly relevant to practice. Analysis of 91 submissions from the Primary Science Quality Mark (PSQM) database provided a mapping of current practice in England. Two case studies of TAPS project schools considered the enacted relationship between formative and summative assessment, during implementation of a 'formative to summative' approach. New insights have been gained into the conceptualisation and enactment of the relationship between formative and summative assessment. Teacher conceptualisations of assessment were found to encapsulate a wide range of dimensions such as purpose, value, audience, assessor, timing, formality, rigidity and support. Refinements to the TAPS pyramid model are proposed to explain the 'formative to summative' process, conceptualising summative assessment as a summary judgement of attainment, which may be informed by snapshot and focused assessment activities. It was found that implementation of a 'formative to summative' approach required a shared understanding of key assessment concepts like validity and reliability; a seesaw balance model is proposed to support the development of such a shared understanding.},
  school = {Bath Spa University}
}

@incollection{eatonAcademicIntegrityCanada2022,
  title = {Academic {{Integrity}} in {{Canada}}: {{Historical Perspectives}} and {{Current Trends}}},
  shorttitle = {Academic {{Integrity}} in {{Canada}}},
  booktitle = {Academic {{Integrity}} in {{Canada}}},
  author = {Eaton, Sarah Elaine and Christensen Hughes, Julia},
  editor = {Eaton, Sarah Elaine and Christensen Hughes, Julia},
  year = {2022},
  volume = {1},
  pages = {3--24},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-83255-1_1},
  urldate = {2023-04-17},
  abstract = {Abstract             In this chapter we discuss the development of academic integrity in Canada. We begin by offering insights into how provincial and territorial educational governance and policy structures have affected academic integrity in Canada, compared to other countries, such as the United States. In particular, we discuss why it may not make sense for Canadian schools to try to adopt the American honour code model. We explore the evolution of higher education in Canada, highlighting the earliest incidents of academic misconduct on record as well as the development of academic integrity scholarship, focusing on significant contributions and its impact over time. In particular, we draw attention to the emergence of policies, practices, associations, and networks intended to help Canada's higher educational institutions develop and strengthen cultures of integrity. Following, we discuss how the academic integrity landscape has shifted, noting recent trends such as the rise of contract cheating. We conclude with a call to action for more enhanced support for academic integrity scholarship to support advocacy, policy, and practice.},
  isbn = {978-3-030-83254-4 978-3-030-83255-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/7YY566D5/eatonAcademicIntegrityCanada2022.pdf}
}

@article{eatonAcademicIntegrityCOVID192020,
  title = {Academic {{Integrity During COVID-19}}: {{Reflections From}} the {{University}} of {{Calgary}}},
  author = {Eaton, Sarah Elaine},
  year = {2020},
  journal = {International Studies in Educational Administration},
  volume = {48},
  number = {1},
  pages = {80--85},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/PFRJZND7/eatonAcademicIntegrityCOVID192020.pdf}
}

@incollection{eatonComprehensiveAcademicIntegrity2024,
  title = {Comprehensive {{Academic Integrity}} ({{CAI}}): {{An Ethical Framework}} for {{Educational Contexts}}},
  booktitle = {Second {{Handbook}} of {{Academic Integrity}}},
  author = {Eaton, Sarah Elaine},
  editor = {Eaton, Sarah Elaine},
  year = {2024},
  pages = {1--14},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-54144-5_194},
  abstract = {In this introductory chapter, the Comprehensive Academic Integrity (CAI) framework is introduced. The CAI framework includes eight (8) overlapping and intertwined elements: (1) everyday ethics, (2) institutional ethics, (3) ethical leadership, (4) professional and collegial ethics, (5) instructional ethics, (6) student academic conduct, (7) research integrity and ethics, and (8) publication ethics. The central argument of this framework is that academic integrity must encompass, but extend beyond, notions of student conduct, and should be considered a foundation of all aspects of education.},
  isbn = {978-3-031-54144-5},
  file = {/Users/colin.madland/Zotero/storage/eatonComprehensiveAcademicIntegrity2024.pdf}
}

@article{ebertEnhancingReflectivePractice2020,
  title = {Enhancing {{Reflective Practice}} of {{Student Physical Therapists}} through {{Video-Assisted Self}} and {{Peer-Assessment}}: {{A Pilot Study}}},
  author = {Ebert, Jeffrey G. and Anderson, Jeannette R. and Taylor, Leslie F.},
  year = {2020},
  month = jan,
  journal = {International Journal of Teaching and Learning in Higher Education},
  volume = {32},
  number = {1},
  pages = {31--38},
  publisher = {{International Journal of Teaching and Learning in Higher Education}},
  issn = {1812-9129},
  abstract = {Reflective practice, in its comprehensive intent, allows a practitioner to make meaning of complex situations. While opportunities for developing reflective thinking are readily available in health professional education programs, opportunities for developing reflective practice abilities are limited. This pilot study was undertaken to address that gap and assess student physical therapists' perceptions of a series of non-graded, video-recorded practice experiences on developing their reflective practice abilities. The study used a quasi-experimental design with collection of quantitative and qualitative data. Physical therapy students reported an increased awareness of their verbal and nonverbal strengths and areas for improvement, their ability to give and receive feedback to a peer, and ways to improve their psychomotor skill performance. Students identified that they would have liked to have initiated this type of self- and peer-assessment earlier in the curriculum. The assignment served as a specific method of teaching reflective practice in the physical therapy curriculum and has broader application for other healthcare and higher education programs.},
  keywords = {Allied Health Occupations Education,College Students,Feedback (Response),No DOI found,Nonverbal Ability,Peer Evaluation,Physical Therapy,Psychomotor Skills,Reflection,Self Evaluation (Individuals),Student Attitudes,Verbal Ability,Video Technology},
  file = {/Users/colin.madland/Zotero/storage/Z2KPIPKK/ebertEnhancingReflectivePractice2020.pdf}
}

@article{ederBringingNavajoStorytelling2007,
  title = {Bringing {{Navajo Storytelling Practices}} into {{Schools}}: {{The Importance}} of {{Maintaining Cultural Integrity}}},
  author = {Eder, Donna J.},
  year = {2007},
  journal = {Anthropology \& Education Quarterly},
  volume = {38},
  number = {3},
  pages = {278--296},
  issn = {0161-7761},
  doi = {10.1525/aeq.2007.38.3.278},
  abstract = {This article examines storytelling practices among Navajos as one example of a non-Western approach to education. The article discusses two stories-one regarding the perspectives of Navajo storytellers concerning the importance of the context of storytelling practices and the other about the research process that led to these perspectives. Eight storytellers were interviewed about storytelling practices in the past and those they would like to see in the future. Implications of the importance of key storytelling practices for Navajo education as well as for changes in Western approaches to schooling are presented.;This article examines storytelling practices among Navajos as one example of a non-Western approach to education. The article discusses two stories-one regarding the perspectives of Navajo storytellers concerning the importance of the context of storytelling practices and the other about the research process that led to these perspectives. Eight storytellers were interviewed about storytelling practices in the past and those they would like to see in the future. Implications of the importance of key storytelling practices for Navajo education as well as for changes in Western approaches to schooling are presented. Reprinted by permission of the American Anthropological Association and the University of California Press;~ This article examines storytelling practices among Navajos as one example of a non-Western approach to education. The article discusses two stories-one regarding the perspectives of Navajo storytellers concerning the importance of the context of storytelling practices and the other about the research process that led to these perspectives. Eight storytellers were interviewed about storytelling practices in the past and those they would like to see in the future. Implications of the importance of key storytelling practices for Navajo education as well as for changes in Western approaches to schooling are presented. [PUBLICATION ABSTRACT];This article examines storytelling practices among Navajos as one example of a non-Western approach to education. The article discusses two stories -- one regarding the perspectives of Navajo storytellers concerning the importance of the context of storytelling practices and the other about the research process that led to these perspectives. Eight storytellers were interviewed about storytelling practices in the past and those they would like to see in the future. Implications of the importance of key storytelling practices for Navajo education as well as for changes in Western approaches to schooling are presented. Adapted from the source document;},
  keywords = {American Indian Culture,American Indian education,American minorities,Animal tales,Anthropology,Anthropology of education,Applied anthropology,article,Arts,Behavioral sciences,Children,Children & youth,Cognitive processes,Cognitive psychology,Communication skills,Communications,Context,Cultural anthropology,Cultural customs,Culturally Relevant Education,Culture,Decolonization,decolonizing research,Education,EDUCATION & EDUCATIONAL RESEARCH,Educational Research,Entertainment,Ethnic groups,Ethnology,Evaluation,Fiction,Folk Culture,Folklore,Formal education,Human populations,Integrity,Interviews,Language skills,Learning,Leisure studies,Literacy,Literary genres,Literature,Narratives,Native Americans,Navaho,Navajo,Navajo (Nation),Navajo education,Navajos,Oral tradition,Pedagogy,Persons,Population studies,Psychology,Reading,Recreation,Research & development--R&D,Schools,Social aspects,Social sciences,Specialized education,Story Telling,Storytelling,Studies,Tales,Teaching,Teaching methods,teaching practices,Traditions,Urban schools,Westerns}
}

@article{edigerReDesigning2SemesterAnatomy2020,
  title = {Re-{{Designing}} a 2-{{Semester Anatomy}} and {{Physiology Lab Course}} for the {{Online Environment}}},
  author = {Ediger, Tracy L. and Rockwell, Katherine A.},
  year = {2020},
  month = dec,
  journal = {HAPS Educator},
  volume = {24},
  number = {3},
  pages = {75--82},
  publisher = {HAPS Educator},
  issn = {2473-3806},
  doi = {10.21692/haps.2020.024},
  abstract = {In March 2020, in-person, on-campus courses were temporarily suspended due to the Covid-19 pandemic. For summer and fall semesters of 2020, we have conducted Anatomy and Physiology courses in the online environment, which required re-design of the lab component of the course. Objectives for our re-design included maintaining key curricular components; replicating a hands-on lab experience for students, maintaining engagement with students, and employing our existing pool of teaching assistants. In the new online lab course, students complete at-home hands-on lab activities, guided by teaching assistants during a weekly one-hour video conferencing session. Lab assessments are shorter, weekly assessments outside of lab time. With this new format, we have continuity of content coverage along with the ability to serve students and maintain support of teaching assistants.},
  keywords = {Anatomy,College Science,COVID-19,Educational Technology,Electronic Learning,Georgia,Online Courses,Pandemics,Physics,School Closing,Science Laboratories,Videoconferencing}
}

@article{EducationalTechnologyResearch1989,
  title = {Educational Technology Research and Development ({{Online}})},
  year = {1989},
  journal = {Educational technology research and development (Online)},
  publisher = {{Association for Educational Communications and Technology}},
  address = {Washington, D.C},
  issn = {1556-6501},
  keywords = {Czasopismo pedagogiczne,Educational technology,Educational technology -- Evaluation,Electronic journals,Periodicals}
}

@article{EducationalTechnologySociety1998,
  title = {Educational Technology \& Society : Journal of {{International Forum}} of {{Educational Technology}} \& {{Society}} and {{IEEE Learning Technology Task Force}}.},
  year = {1998},
  journal = {Educational technology \& society : journal of International Forum of Educational Technology \& Society and IEEE Learning Technology Task Force.},
  publisher = {International Forum of Educational Technology \& Society},
  address = {Palmerston North, N.Z},
  issn = {1176-3647},
  abstract = {It provides information on the issues affecting the developers of educational systems and educators who implement and manage such systems.},
  keywords = {Computer-assisted instruction,Czasopismo pedagogiczne,Educational technology,Educational technology society artificial intelligence educators instruction technology culture context performance learning,Electronic journals,Institute of Electrical and Electronics Engineers. International Forum of Educational Technology and Society,Komputeryzacja,Periodicals}
}

@book{educationCollegiateLearningAssessmentn.d.,
  title = {Collegiate {{Learning Assessment}}},
  author = {{\noopsort{education}}to Education, Council for Aid},
  year = {n.d.},
  number = {April 9, 2012}
}

@misc{educationFoundationSkillsAssessment,
  title = {Foundation {{Skills Assessment}} ({{FSA}}) - {{Province}} of {{British Columbia}}},
  author = {{\noopsort{education}}of Education, Ministry},
  publisher = {Province of British Columbia},
  urldate = {2021-04-14},
  abstract = {The Foundation Skills Assessment is administered annually to all B.C. students in grades 4 and 7 to assess basic skills in reading, writing and numeracy.},
  howpublished = {https://www2.gov.bc.ca/gov/content/education-training/k-12/administration/program-management/assessment/foundation-skills-assessment},
  langid = {english},
  annotation = {Last Modified: 2021-02-11},
  file = {/Users/colin.madland/Zotero/storage/53ZEY8N5/foundation-skills-assessment.html}
}

@misc{EducationIndigenousPeoples,
  title = {Education of {{Indigenous Peoples}} in {{Canada}} {\textbar} {{The Canadian Encyclopedia}}},
  urldate = {2019-07-10},
  howpublished = {https://www.thecanadianencyclopedia.ca/en/article/aboriginal-people-education},
  file = {/Users/colin.madland/Zotero/storage/MNTWH6HL/aboriginal-people-education.html}
}

@misc{EducationRegulationEmpowering,
  title = {Education before {{Regulation}}: {{Empowering Students}} to {{Question Their Data Privacy}}},
  shorttitle = {Education before {{Regulation}}},
  urldate = {2019-10-14},
  abstract = {In higher education, we must work not only toward providing better security around student data but also toward educating students about the need to c},
  howpublished = {https://er.educause.edu/articles/2019/10/education-before-regulation-empowering-students-to-question-their-data-privacy},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/PUS45HRP/education-before-regulation-empowering-students-to-question-their-data-privacy.html}
}

@article{edwardsExploringStudentEngagement2020,
  title = {Exploring Student Engagement Factors in a Blended Undergraduate Course},
  author = {Edwards, Rebecca and Davis, Sarah K and Hadwin, Allyson F and Milford, Todd M},
  year = {2020},
  journal = {Canadian Journal for the Scholarship of Teaching and Learning},
  volume = {11},
  number = {3},
  issn = {1918-2902},
  doi = {10.5206/cjsotl-rcacea.2020.3.8293},
  file = {/Users/colin.madland/Zotero/storage/IMSVSQBD/edwardsExploringStudentEngagement2020.pdf}
}

@article{edwardsKnowledgeInfrastructuresInscrutability2015,
  title = {Knowledge Infrastructures and the Inscrutability of Openness in Education},
  author = {Edwards, Richard},
  year = {2015},
  journal = {Learning, Media and Technology},
  volume = {40},
  number = {3},
  pages = {251--264},
  issn = {1743-9884},
  doi = {10.1080/17439884.2015.1006131},
  abstract = {Openness has a long genealogy in education. Whether through the use of post, radio, television and digital technologies, extending learning opportunities to more and a wider range of people has been a significant aspect of educational history. Transcending barriers to learning has been promoted as the means of opening educational opportunities in highly normative ways, focusing on the media through which to remove the limits of institutional selection, and of space and time. While there is an obvious attractiveness is such notions, they do little to engage with the critical research on the selectiveness and exclusions inherent in all curricula and pedagogic approaches, however open. The nature, scale and range of digital technologies have seen resurgent interest in the possibilities of openness in education. However, these technologies work on the basis of ontologies, code, algorithms and standards to build knowledge infrastructures that are not always open or opening. This article will suggest that the work of the knowledge infrastructures of open education results in an inherent inscrutability within its practices, which is elusive in terms of significance, processes and effects.}
}

@misc{edwardsTellingAIModel2023,
  title = {Telling {{AI}} Model to ``Take a Deep Breath'' Causes Math Scores to Soar in Study},
  author = {Edwards, Benj},
  year = {2023},
  month = sep,
  journal = {Ars Technica},
  urldate = {2023-09-22},
  abstract = {DeepMind used AI models to optimize their own prompts, with surprising results.},
  howpublished = {https://arstechnica.com/information-technology/2023/09/telling-ai-model-to-take-a-deep-breath-causes-math-scores-to-soar-in-study/},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/NRLNMXD9/edwardsTellingAIModel2023.pdf;/Users/colin.madland/Zotero/storage/EDARLAGW/telling-ai-model-to-take-a-deep-breath-causes-math-scores-to-soar-in-study.html}
}

@article{egarterImpactCOVID19Digital2021,
  title = {Impact of {{COVID-19}} on Digital Medical Education: Compatibility of Digital Teaching and Examinations with Integrity and Ethical Principles},
  author = {Egarter, Saskia and Mutschler, Anna and Brass, Konstantin},
  year = {2021},
  journal = {International journal for educational integrity},
  volume = {17},
  number = {1},
  pages = {1--19},
  publisher = {Springer Singapore},
  address = {Singapore},
  issn = {1833-2595},
  doi = {10.1007/s40979-021-00084-8},
  abstract = {The COVID-19 (coronavirus disease 2019) pandemic in 2020 has had a lasting impact on all areas of personal life. However, the political, economic, legal and healthcare system, as well as the education system have also experienced the effects. Universities had to face new challenges and requirements in teaching and examinations as quickly as possible in order to be able to guarantee high-quality education for their students. This study aims to examine how the German-speaking medical faculties of the Umbrella Consortium of Assessment Network (UCAN) have dealt with the challenges but also the opportunities that the outbreak of the COVID-19 pandemic created in medical education and whether digitalisation has been driven forward as a result. In an initial online-survey we focused our questions on the current teaching situation with regard to digitised teaching content, the support or establishment of adequate framework conditions by the medical faculties and IT facilities and also the execution of examinations during the summer semester 2020. Between August and September 2020, a total of 88 examiners, educators, dean of study and/or technical admins from 32 partner faculties took part in the survey. Students were not included in our survey. Most respondents stated that a switch to a digital semester had worked, the use of e-learning increased compared to previous semesters and that most courses could be converted, with the exception of practical courses, which were largely cancelled. The respondents also indicated that most examinations could still be taken, with the exception of~practical examination formats, like Objective Structured Clinical Examinations (OSCEs). However, in the case of face-to-face examinations, strict distance and hygiene conditions had to be obeyed or there had to be a switch to distance-online examinations, which raised many open issues such as equal opportunities of students (technical equipment, internet access, premises) and attempts at deception (third-party help with the exam, mutual exchange between students, web search). In conclusion, we identified several issues regarding the rapid transition to a digital semester due to COVID-19 which were categorised into the following topics: Face-to-face teaching could not take place, (2) know-how of educators, (3) integrity aspects, (4) technical aspects, (5) additional personnel required, (6) additional time and effort required for implementation of digital teaching. Our study shows that a switch to digital teaching and distance online examinations is feasible, but many problems were encountered concerning academic integrity and basic ethical principles still need to be solved. In order to investigate whether above mentioned issued could be solved one year after the transition to a digital semester, we conducted a second survey in which the 32 initially surveyed institutions were questioned again.},
  keywords = {Barriers,College Faculty,Computer Assisted Testing,Coronaviruses,COVID-19,Digitalisation,Distance Education,Distance learning,E-assessment,E-learning,Education,Education & Educational Research,Electronic Learning,Ethics,Higher Education,Integrity,Integrity in an Emergency: Pandemics,International and Comparative Education,Medical Education,Natural Disasters and Other Extreme Conditions,Online instruction,Online Surveys,Original,Original Article,Pandemics,Social Sciences,Students,Technology Integration},
  file = {/Users/colin.madland/Zotero/storage/Y94G633Y/egarterImpactCOVID19Digital2021.pdf}
}

@book{ehlersChangingCulturesHigher2010,
  title = {Changing {{Cultures}} in {{Higher Education Moving Ahead}} to {{Future Learning}}},
  author = {Ehlers, Ulf-Daniel. and Ehlers, Ulf-Daniel. and Schneckenberg, {\relax Dirk}.},
  year = {2010},
  edition = {1st ed. 2010.},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-03582-1},
  abstract = {More and more educational scenarios and learning landscapes are developed using blogs, wikis, podcasts and e-portfolios. Web 2.0 tools give learners more control, by allowing them to easily create, share or reuse their own learning materials, and these tools also enable social learning networks that bridge the border between formal and informal learning. However, practices of strategic innovation of universities, faculty development, assessment, evaluation and quality assurance have not fully accommodated these changes in technology and teaching. Ehlers and Schneckenberg present strategic approaches for innovation in universities. The contributions explore new models for developing and engaging faculty in technology-enhanced education, and they detail underlying reasons for why quality assessment and evaluation in new -- and often informal -- learning scenarios have to change. Their book is a practical guide for educators, aimed at answering these questions. It describes what E-learning 2.0 is, which basic elements of Web 2.0 it builds on, and how E-learning 2.0 differs from Learning 1.0. The book also details a number of quality methods and examples, such as self-assessment, peer-review, social recommendation, and peer-learning, using illustrative cases and giving practical recommendations. Overall, it offers a step-by-step guide for educators so that they can choose their own quality assurance or assessment methods, or develop their own evaluation methodology for specific learning scenarios. The book addresses everyone involved in higher education -- university leaders, chief information officers, change and quality assurance managers, and faculty developers. Pedagogical advisers and consultants will find new insights and practices for the integration and management of novel learning technologies in higher education. The volume fosters in lecturers and teachers a sound understanding of the need and strategy for change, and it provides them with practical recommendations on competence and quality methodologies.},
  isbn = {1-282-83576-9},
  keywords = {Assessment,Assessment Testing and Evaluation,Computers and Education,Education-Data processing,Educational technology,Educational Technology,Electronic books,Human Resource Management,Multimedia information systems,Multimedia Information Systems,Personnel management},
  file = {/Users/colin.madland/Zotero/storage/PSW5YR8R/ehlersChangingCulturesHigher2010.pdf}
}

@article{ehlersExtendingTerritoryOpen2011,
  title = {Extending the {{Territory}}: {{From Open Educational Resources}} to {{Open Educational Practices}}},
  author = {Ehlers, Ulf-Daniel},
  year = {2011},
  journal = {Journal of Open, Flexible, and Distance Learning},
  volume = {15},
  number = {2},
  pages = {1--10},
  urldate = {2018-11-17},
  abstract = {This article examines the findings of the recent OPAL report Beyond OER: Shifting Focus from Resources to Practices. In doing so, it defines current understanding of open educational resources and open educational practices, and highlights the shift from open content to open practice. The article includes a framework for supporting open educational practices. The conclusions emphasise that open access is a necessary but not sufficient condition for the opening of education, and foreshadows ongoing moves toward changes in educational architectures that promote increased uptake of open educational resources and wider application of open education.}
}

@inproceedings{ehlersOpenEducationalPractices2010,
  title = {Open {{Educational Practices}}: {{Unleashing}} the Power of {{OER}}},
  booktitle = {{{UNESCO Workshop}} on {{OER}} in {{Namibia}} 2010},
  author = {Ehlers, Ulf-Daniel and Conole, Grainne C.},
  year = {2010},
  publisher = {Windhoek},
  address = {Namibia},
  abstract = {This paper presents the initial findings of the OPAL project. OPAL aims to move beyond a focus on the development of open educational resources (OER) to articulation of the associated open educational practices (OEP) around the creation, use and management of OER. In this paper we provide a definition of Open educational practices, along with an associated set of dimensions. We describe how these were derived based on an extensive survey and analysis of OER case studies. The article focuses on three aspects: First it provides a working definition of open educational practices and articulates how better understanding of OEP might lead to enhancements in both quality and innovation in education. Secondly it is discusses the ways in which adopting more `open' approaches to educational practices might impact on the quality of education. Thirdly, the case study findings are presented and the ways in which the different stakeholders involved influence open educational practices are discussed.}
}

@article{eibFacultyDevelopmentCommunity2006,
  title = {Faculty Development as Community Building},
  author = {Eib, {\relax BJ} and Miller, Pam},
  year = {2006},
  journal = {International Review of Research in Open and Distance Learning},
  volume = {7},
  number = {2},
  abstract = {When faculty development is viewed as an ongoing need and when we approach faculty development as a long-term, continuous effort, community building becomes a part of the process. Carefully designed faculty development approaches can facilitate and create a culture that supports a thoughtful focus on teaching, while at the same time, nurture a sense of connectedness and collegiality across the organization that is vital to continuous innovation and improvement. This paper reports on a program designed to improve the collegial culture at a higher educational organization in Western Canada. While the program was aimed at a Social Work Faculty at a research university, we believe the design can be modified and applied in other disciplines and in other environments, such as distant and open universities. We conclude with suggestions for applying our approach to faculty development in open and distance institutional contexts.},
  keywords = {community of practice collegiality,faculty development community building professional development higher education open and distance education}
}

@misc{EightQualitiesOpen,
  title = {Eight {{Qualities}} of {{Open Pedagogy}} {\textbar} {{NextThought}}},
  urldate = {2018-10-21},
  howpublished = {https://nextthought.com/thoughts/2015/02/ten-qualities-of-open-pedagogy},
  keywords = {open},
  file = {/Users/colin.madland/Zotero/storage/JUG7SBBK/ten-qualities-of-open-pedagogy.html}
}

@inproceedings{ekubanUsingGitLabInteractions2021,
  title = {Using {{GitLab Interactions}} to {{Predict Student Success When Working}} as {{Part}} of a {{Team}}},
  author = {Ekuban, Audrey Beatrice and Mikroyannidis, Alexander and Third, Allan and Domingue, John},
  year = {2021},
  series = {Advances in {{Intelligent Systems}} and {{Computing}}},
  pages = {127--138},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-68198-2_11},
  abstract = {This paper explores machine learning algorithms that can be used to predict student results in an assignment of a Software Engineering course, based on weekly cumulative average source code submissions to GitLab. GitLab is a source code version control system, commonly used in Software Engineering courses in Higher Education. The aim of this work is to create models that can be used to predict if a group of students in a team will pass or fail an assignment. In this paper, we present results from Decision Tree, Random Forest, Extra Trees, Ada Boost and Gradient Boosting machine learning models. These models were evaluated using cross-validation, with Ada Boost achieving the highest average score.},
  isbn = {2194-5357},
  keywords = {Educational Data Mining,Learning analytics,Machine learning},
  file = {/Users/colin.madland/Zotero/storage/DTL5S99V/ekubanUsingGitLabInteractions2021.pdf}
}

@article{elkhatatEvaluatingAuthenticityChatGPT2023,
  title = {Evaluating the Authenticity of {{ChatGPT}} Responses: A Study on Text-Matching Capabilities},
  author = {Elkhatat, Ahmed M.},
  year = {2023},
  month = aug,
  journal = {International Journal for Educational Integrity},
  volume = {19},
  number = {1},
  pages = {15},
  issn = {1833-2595},
  doi = {10.1007/s40979-023-00137-0},
  abstract = {Academic plagiarism is a pressing concern in educational institutions. With the emergence of artificial intelligence (AI) chatbots, like ChatGPT, potential risks related to cheating and plagiarism have increased. This study aims to investigate the authenticity capabilities of ChatGPT models 3.5 and 4 in generating novel, coherent, and accurate responses that evade detection by text-matching software. The repeatability and reproducibility of both models were analyzed, showing that the generation of responses remains consistent. However, a two-sample t-test revealed insufficient evidence to support a statistically significant difference between the text-matching percentages of both models. Several strategies are proposed to address the challenges posed by AI integration in academic contexts; one probable solution is to promote self-transcendent ideals by implementing honor codes. It is also necessary to consider the restricted knowledge base of AI language models like GPT and address any inaccuracies in generated references. Additionally, designing assignments that extract data from imaged sources and integrating oral discussions into the evaluation process can mitigate the challenges posed by AI integration. However, educators should carefully consider the practical constraints and explore alternative assessment methods to prevent academic misconduct while reaping the benefits of these strategies.},
  file = {/Users/colin.madland/Zotero/storage/QQ39F6VG/elkhatatEvaluatingAuthenticityChatGPT2023.pdf}
}

@article{elliottIndigenousResurgenceDrive2018,
  title = {Indigenous {{Resurgence}}: {{The Drive}} for {{Renewed Engagement}} and {{Reciprocity}} in the {{Turn Away}} from the {{State}}},
  author = {Elliott, M.},
  year = {2018},
  journal = {CANADIAN JOURNAL OF POLITICAL SCIENCE-REVUE CANADIENNE DE SCIENCE POLITIQUE},
  volume = {51},
  number = {1},
  pages = {61--81},
  issn = {0008-4239},
  doi = {10.1017/S0008423917001032},
  abstract = {Indigenous resurgence centres on three contentions: (1) that colonialism is an active structure of domination premised, at base, on Indigenous elimination; (2) that the prevailing normative-discursive environment continues to reflect this imperative; and (3) that Indigenous peoples must therefore turn away from this hostile environment and pursue independent programmes of social and cultural rejuvenation. The principal movement advocated under the resurgence paradigm thus appears as one of disengagement with the settler order. I also argue, however, that there is an important secondary drive within the movement that presses in the opposite direction. It figures further engagement both as a longer term goal (in the form of renewed dialogue on decolonization) and as an immediate imperative (in order to expose and remove obstacles to reciprocal dialogue). I aim, here, to excavate this secondary drive and consider what it connotes in terms of settler engagement.;"Indigenous resurgence" centres on three contentions: (1) that colonialism is an active structure of domination premised, at base, on Indigenous elimination; (2) that the prevailing normative-discursive environment continues to reflect this imperative; and (3) that Indigenous peoples must therefore turn away from this hostile environment and pursue independent programmes of social and cultural rejuvenation. The principal movement advocated under the resurgence paradigm thus appears as one of disengagement with the settler order. I also argue, however, that there is an important secondary drive within the movement that presses in the opposite direction. It figures further engagement both as a longer term goal (in the form of renewed dialogue on decolonization) and as an immediate imperative (in order to expose and remove obstacles to reciprocal dialogue). I aim, here, to excavate this secondary drive and consider what it connotes in terms of settler engagement.;},
  keywords = {CANADA,Colonialism,DECOLONIZATION,DISCOURSE,Disengagement,Dominance,Education,Indigenous populations,Native peoples,Political economy,POLITICAL SCIENCE,Political theory,Politics,Reciprocity,RIGHTS,SETTLER COLONIALISM,Social programs,Society,SOLIDARITY,Sovereignty,SUSTAINABLE SELF-DETERMINATION}
}

@book{elliottUsingNarrativeSocial2005,
  title = {Using Narrative in Social Research: Qualitative and Quantitative Approaches},
  author = {Elliott, Jane},
  year = {2005},
  number = {Book, Whole},
  publisher = {SAGE},
  address = {London;Thousand Oaks;},
  abstract = {'Jane Elliott's examination of the use of "narrative" within the broad context of social science inquiry is a must-read for both qualitative and quantitative researchers, novice and expert alike' - Journal of Advanced Nursing `This important book does an impressive job of synthesising a complex literature and bringing together both qualitative and quantitative methods of narrative analysis. It will become a milestone in the development of narrative methods. Although ground-breaking in many ways, it is very clearly written and accessible to readers from a wide variety of backgrounds and methodological experience' - Nigel Gilbert, University of Surrey `An elegantly written, scholarly and accessible text. Jane Elliott shows a sophisticated appreciation of contemporary methodological developments, and makes a persuasive case for the use of narrative approaches in both qualitative and quantitative research. The book challenges and advances debates about combining methods, and shows how stories can work within and across conventional research boundaries. It is a truly original contribution to the literature' - Amanda Coffey, Cardiff School of Social Sciences `An outstanding book. Jane Elliott breaks new ground by demonstrating to new generations of social scientists how the power of narrative can fruitfully be harnessed in social research. This is a "must read" book' - Professor Mike Savage, University of Manchester This is a lucid and accessible introduction to narrative methods in social research. It is also an important book about the nature, role and theoretical basis of research methodology in general. Jane Elliott instructs the reader on the basic methods and methodological assumptions that form the basis of narrative methods. She does so in a way that is practical and accessible and in a way that will make the book a favourite with students and experienced researchers alike. Elliott argues that both qualitative and quantitative methods are characterised by a concern with narrative, and that our research data can best be analyzed if it is seen in narrative terms. In concrete, step-by-step terms she details for the reader how to go about collecting data and how to subject that data to narrative analysis, while at the same time placing this process in its wider theoretical context. She works across the traditional quantitative/qualitative divide to set out the ways in which narrative researchers can uncover such issues as social change, causality and social identity. She also shows how the techniques and skills used by qualitative researchers can be deployed when doing quantitative research and, similarly, how qualitative researchers can sometimes profit from using quantitative skills and techniques. "This book provides both a fascinating and a challenging read. What sets this text apart from other books on research methodology and methods is that it does not focus exclusively on either quantitative or qualitative research approaches, but rather attempts to bridge the divide. The book should be compulsory reading not only for those aspiring to undertake narrative research and those students undertaking higher degree research courses, but also for those more experienced researches wishing to explore contemporary issues in research methods and methodology. As a recent recruit to a lecturer-practitioner post with little recnt experience in the subject area covered by this book, i found it met my needs very well. I would certainly recomment this book for purchase." Dr Andrew Pettipher, University of Nottingham, UK.;'Jane Elliott's examination of the use of "narrative" within the broad context of social science inquiry is a must-read for both qualitative and quantitative researchers, novice and expert alike' - Journal of Advanced Nursing 'This important book does an impressive job of synthesising a complex literature and bringing together both qualitative and quantitative methods of narrative analysis. It will become a milestone in the development of narrative methods. Although ground-breaking in many ways, it is very clearly written and accessible to readers from a wide variety of backgrounds and methodological experience' - Nigel Gilbert, University of Surrey 'An elegantly written, scholarly and accessible text. Jane Elliott shows a sophisticated appreciation of contemporary methodological developments, and makes a persuasive case for the use of narrative approaches in both qualitative and quantitative research. The book challenges and advances debates about combining methods, and shows how stories can work within and across conventional research boundaries. It is a truly original contribution to the literature' - Amanda Coffey, Cardiff School of Social Sciences 'An outstanding book.Jane Elliott breaks new ground by demonstrating to new generations of social scientists how the power of narrative can fruitfully be harnessed in social research. This is a "must read" book' - Professor Mike Savage, University of Manchester This is a lucid and accessible introduction to narrative methods in social research. It is also an important book about the nature, role and theoretical basis of research methodology in general. Jane Elliott instructs the reader on the basic methods and methodological assumptions that form the basis of narrative methods. She does so in a way that is practical and accessible and in a way that will make the book a favourite with students and experienced researchers alike. Elliott argues that both qualitative and quantitative methods are characterised by a concern with narrative, and that our research data can best be analyzed if it is seen in narrative terms. In concrete, step-by-step terms she details for the reader how to go about collecting data and how to subject that data to narrative analysis, while at the same time placing this process in its wider theoretical context.She works across the traditional quantitative/qualitative divide to set out the ways in which narrative researchers can uncover such issues as social change, causality and social identity. She also shows how the techniques and skills used by qualitative researchers can be deployed when doing quantitative research and, similarly, how qualitative researchers can sometimes profit from using quantitative skills and techniques. "This book provides both a fascinating and a challenging read. What sets this text apart from other books on research methodology and methods is that it does not focus exclusively on either quantitative or qualitative research approaches, but rather attempts to bridge the divide. The book should be compulsory reading not only for those aspiring to undertake narrative research and those students undertaking higher degree research courses, but also for those more experienced researches wishing to explore contemporary issues in research methods and methodology. As a recent recruit to a lecturer-practitioner post with little recnt experience in the subject area covered by this book, i found it met my needs very well.I would certainly recomment this book for purchase." Dr Andrew Pettipher, University of Nottingham, UK.;},
  isbn = {1412900417;9781412900409;1412900409;9781412900416;},
  keywords = {Discourse analysis Narrative,Methodology,Narration (Rhetoric),Narratives,Qualitative analysis,Quantitative analysis,Research,Social research,Social sciences,Sociology,Sociology Social Studies}
}

@article{ellisAssessingUniversityStudent2021,
  title = {Assessing University Student Collaboration in New Ways},
  author = {Ellis, Robert and Han, Feifei},
  year = {2021},
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {46},
  number = {4},
  pages = {509--524},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0260-2938},
  doi = {10.1080/02602938.2020.1788504},
  abstract = {This study argues for the importance of using the different evidence to assess and evaluate a key graduate skill - collaboration. To do so, it investigates the experience of 356 first-year students in a blended course design and measures their collaborative patterns. Combining research methodologies from student approaches to learning and social network analysis, the results reveal evidence of different collaborative patterns across the population sample. The investigation uncovers contrasting groupings of students with deep and surface approaches to inquiry and to online learning technologies, positive and negative conceptions of the learning environment, and relatively higher or lower academic outcomes. These are discovered to logically relate to different collaborative patterns. The most effective collaboration strategies involve collaborating only as much as tasks needed, in smaller groups, and being reciprocal by accepting and inviting peers to work together. Effective collaboration strategies also include students positioning themselves to gather information easily in their collaboration networks and to develop closely knit collaborative groups. The results offer an evidence-base to identify different experiences of student learning and collaboration to improve program design and the attribute of collaboration, and to improve the concepts underpinning policy development for quality improvement of university graduates.},
  keywords = {Assessment in new ways,Blended Learning,Collaboration,collaborative patterns,College Freshmen,College students,Cooperative Learning,Curriculum development,Distance learning,Education & Educational Research,Evaluation Methods,Foreign Countries,Learning environment,Peer Relationship,social network analysis,Social Networks,Social Sciences,student approaches to learning research,Student Attitudes,Student Evaluation},
  file = {/Users/colin.madland/Zotero/storage/D57EY2EQ/ellisAssessingUniversityStudent2021.pdf}
}

@article{ellisAutoethnographyOverview2011,
  title = {Autoethnography: {{An Overview}}},
  shorttitle = {Autoethnography},
  author = {Ellis, Carolyn and Adams, Tony E. and Bochner, Arthur P.},
  year = {2011},
  journal = {Forum Qualitative Sozialforschung / Forum: Qualitative Social Research},
  volume = {12},
  number = {1},
  issn = {1438-5627},
  doi = {10.17169/fqs-12.1.1589},
  urldate = {2023-11-13},
  abstract = {Autoethnografie ist ein Ansatz zum Forschen und zur Pr{\"a}sentation von Forschungsergebnissen,  der pers{\"o}nliche Erfahrungen systematisch beschreibt und analysiert, um auf diesem Weg kulturelle Erfahrung zu verstehen. Hierbei werden traditionelle Wege des Forschens und der Darstellung "der Anderen" kritisch infrage gestellt, denn Forschung wird als politisches, auf soziale Gerechtigkeit  zielendes und sozial bewusstes Handeln verstanden. Forschende nutzen Mittel der Autobiografie und der Ethnografie, um Autoethnografie zu betreiben und darzustellen. Als Methode bezeichnet Autoethnografie gleicherma{\ss}en einen Prozess und ein Produkt. URN: http://nbn-resolving.de/urn:nbn:de:0114-fqs1101108},
  copyright = {Copyright (c) 2010 Carolyn Ellis, Tony E. Adams, Arthur P. Bochner},
  langid = {english},
  keywords = {autoethnography,co-constructed narratives,ethnography,interactive interviews,narrative,narrative ethnographies,personal narrative,relational ethics},
  file = {/Users/colin.madland/Zotero/storage/V9H5AGDK/ellisAutoethnographyOverview2011.pdf}
}

@article{ellisChallengesAssessingNature2021,
  title = {Challenges in Assessing the Nature of Effective Collaboration in Blended University Courses},
  author = {Ellis, Robert and Bliuc, Ana-Maria and Han, Feifei},
  year = {2021},
  journal = {Australasian Journal Of Educational Technology},
  volume = {37},
  number = {1},
  pages = {1--14},
  publisher = {Australasian Soc Computers Learning Tertiary Education-Ascilite},
  address = {TUGUN},
  issn = {1449-5554},
  doi = {10.14742/ajet.5576},
  abstract = {The ability to collaborate effectively face-to-face and online represents a critical skill for university graduates. However, there are still challenges regarding how to accurately assess this skill through traditional student learning measures. To better understand the nature of effective collaboration of university students in blended courses, the current study drew on the student approaches to learning framework and social network analysis techniques. We examined how student approaches to inquiry, approaches to online learning technologies, perceptions of the blended learning environment, different learning outcomes and configurations of collaboration are related. The methodologies commonly used in student approaches to learning research identified deep and surface approaches to inquiry and technologies, positive and negative perceptions of the integration of the learning environment, and of online workload, which also showed logical alignment with relatively better and poorer academic achievement in the course. Based on approaches, perceptions, and learning outcomes, students were divided into groups orientated towards understanding versus reproducing learning. The social network analysis techniques revealed features of different configurations of collaborations by different groups of students and their choices as to whether and with whom to collaborate during the learning process. Nuanced differences were found amongst different configurations of collaborations. [Author abstract]},
  keywords = {Academic Achievement,Blended Learning,Collaboration,College Students,Cooperative Learning,Distance learning,Education & Educational Research,Foreign Countries,Group activities,Higher education,Inquiry,Instructional Effectiveness,Learning environment,Learning strategies,Measures (Individuals),Online learning,Outcomes of education,Social network analysis,Social network analysis (SNA),Social networks,Social Sciences,Student Attitudes,Student Experience,Students,Teamwork,University students},
  file = {/Users/colin.madland/Zotero/storage/DW6QVGSW/ellisChallengesAssessingNature2021.pdf}
}

@article{ellisExpandingPersonalisingFeedback2016,
  title = {Expanding and {{Personalising Feedback}} in {{Online Assessment}}: {{A Case Study}} in a {{School}} of {{Pharmacy}}},
  author = {Ellis, Steven and Barber, Jill},
  year = {2016},
  month = jan,
  journal = {Practitioner Research in Higher Education},
  volume = {10},
  number = {1},
  pages = {121--129},
  publisher = {Practitioner Research in Higher Education},
  issn = {1755-1382},
  abstract = {In the Manchester Pharmacy School, we first adopted summative on-line examinations in 2005. Since then, we have increased the range of question types to include short answers, short essays and questions incorporating chemical structures and we achieve time savings of up to 90\% in the marking process. Online assessments allow two novel forms of feedback. An anonymised spreadsheet containing all the marked exam scripts is made available to all students. This enables students to see a variety of answers than are awarded good marks, rather than a single model answer. Secondly, "Smallvoice" a novel app provides confidential personalised feedback. Feedback statements, though written by the instructor, are selected by a computer in response to various aspects of a student's performance. Evidence of improved student satisfaction comes from the unit questionnaires and from the National Student Survey. Evidence of improved learning comes from comparing pre- and post-feedback assessments (typically course tests and end of unit examinations.).},
  keywords = {Chemistry,Computer Assisted Testing,Educational Technology,Feedback (Response),Foreign Countries,Higher Education,National Surveys,No DOI found,Online Surveys,Pharmacy,Spreadsheets,Student Satisfaction,Student Surveys,Technology Uses in Education,Test Items,United Kingdom}
}

@article{Ellsworth_1990,
  title = {Multiple Choice Test Items What Are Textbook Authors Telling Teachers},
  author = {Ellsworth, Randy and Dunnell, Pat and Duell, Orpha K.},
  year = {1990},
  journal = {Journal of Educational Research},
  doi = {10/dxfq},
  abstract = {AbstractThe purposes of this study were to (a) Look at what teachers are being told about multiple-choice test item construction by introductory educational psychology textbook authors and (b) to evaluate the quality of test items that preservice teachers may be exposed to if their university instructors use unedited multiple-choice items provided by the publishers of their classroom text. A comprehensive survey of educational psychology texts was completed to identify the textbook authors' recommended guidelines for teachers to follow when writing multiple-choice test items. Next, a reduced set of 12 guidelines was identified on the basis of the frequency of author recommendations. These 12 guidelines were used to evaluate 60 multiple-choice items (N = 1,080) that were randomly selected from 18 different instructor guides to introductory educational psychology texts. The results indicated that approximately 60\% of the items violated one or more guidelines.},
  mag_id = {2018200225},
  pmcid = {null},
  pmid = {null}
}

@article{elshaerStudentsPerceptionsValue2020,
  title = {Students' {{Perceptions}} of the {{Value}} of {{Electronic Feedback--Does Disciplinary Background Really Matter}}?},
  author = {El Shaer, Amr and Casanova, Diogo and Freestone, Nicholas S. and Calabrese, Gianpiero},
  year = {2020},
  month = mar,
  journal = {British Journal of Educational Technology},
  volume = {51},
  number = {2},
  pages = {590--606},
  publisher = {British Journal of Educational Technology},
  issn = {0007-1013},
  doi = {10.1111/bjet.12881},
  abstract = {Feedback on student work is a key mechanism for improving learning in higher education (HE) and can be provided in a variety of forms. Recently, many institutions have moved to the provision of electronic feedback, although evidence for the effectiveness of this is mixed. While many studies evaluating the students' perception of feedback are now available, there is little evidence of contrasting perceptions of its value according to different disciplines. This work aims to evaluate the relationship between students' expectations and perception of feedback, especially electronic, and the disciplinary area of study in HE. Students (n~=~1017) across different courses from a post-1992 university in the UK were surveyed and categorised into five disciplinary clusters: Science, Technology, Engineering and Mathematics; Business and Accounting; Art and Design; Media and Languages; and Psychology and Social Care. Perceived relevance as well as the most pertinent features and expectations of the quality of electronic feedback for students varies according to disciplinary cluster and thus closely aligns with a specific cluster's learning and teaching practices. The findings of this study may help institutions to reflect on the role of electronic feedback as part of their ongoing assessment practice and how teaching in the different disciplines may result in different understandings of the value of electronic feedback.},
  keywords = {College Students,Educational Technology,Evaluation Methods,Expectation,Feedback (Response),Foreign Countries,Higher Education,Intellectual Disciplines,Student Attitudes,Technology Uses in Education,United Kingdom},
  file = {/Users/colin.madland/Zotero/storage/69FSMRHJ/elshaerStudentsPerceptionsValue2020.pdf}
}

@article{eltonComplexityTheoryApproach2010,
  title = {Complexity Theory - an Approach to Assessment That Can Enhance Learning and - More Generally - Could Transform University Management},
  author = {Elton, Lewis},
  year = {2010},
  journal = {Assessment and evaluation in higher education},
  volume = {35},
  number = {5},
  pages = {637--646},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0260-2938},
  doi = {10.1080/02602931003782533},
  abstract = {The paper discusses the continued relevance of the Humboldtian model of university education and interprets it in terms of the two fundamental concepts of complexity and collegiality. These are then applied to issues of assessment in universities. Beyond issues arising directly from complexity and collegiality, present university failings in assessment also arise from the continuation of university malpractices relating to a better understanding of the professionalisation of teaching and learning, of teaching and learning as a form of scholarship (Wissenschaft) and of the relevance of students' freedom to learn.},
  keywords = {assessment,College Administration,College Faculty,College Instruction,College professors,College students,Collegiality,Complexity,Complexity theory,Education & Educational Research,Educational Assessment,enhance learning,Higher Education,Humboldt,Instructional design,Learning,Models,Professional Development,Scholarship,Social Sciences,Systems Approach,Teaching methods},
  file = {/Users/colin.madland/Zotero/storage/NSH8B8LY/eltonComplexityTheoryApproach2010.pdf}
}

@incollection{embretsonIntegrativeFrameworkConstruct2016,
  title = {An Integrative Framework for Construct Validity},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {Embretson, Susan},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch5},
  pages = {102--123},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch5},
  abstract = {Summary The impact of cognitively based approaches on test development has become an increasingly prevalent topic in that many test development systems that incorporate cognitive psychology principles have been proposed and illustrated in the educational and psychological measurement literature. In this chapter I present an integrated and interactive framework for construct validity based on the Standards for Educational and Psychological Testing (2014) to articulate the potential impact of cognitive-based approaches to item and test design. I then apply this framework to an alternative form of a fluid intelligence test developed with automatically generated items and demonstrate, through various types of empirical evidence, that the construct validity of this test is supported.},
  chapter = {5},
  isbn = {978-1-118-95658-8},
  keywords = {cognitive psychometric modeling,construct validity,item design,response processes,test development,validity framework}
}

@book{engagementFosteringStudentEngagement2011,
  title = {Fostering Student Engagement Campuswide - Annual Results 2011},
  author = {Engagement, National Survey of Student},
  year = {2011},
  publisher = {Indiana University Center for Postsecondary Research},
  abstract = {The National Survey of Student Engagement (NSSE) documents dimensions of quality in undergraduate education and provides information and assistance to colleges, universities, and other organizations to improve student learning. Its primary activity is annually surveying college students to assess the extent to which they engage in educational practices associated with high levels of learning and development.},
  keywords = {engagement,nsse,Student}
}

@article{entwistleApproachesLearningEvaluations1990,
  title = {Approaches to Learning, Evaluations of Teaching, and Preferences for Contrasting Academic Environments},
  author = {Entwistle, Noel and Tait, Hilary},
  year = {1990},
  journal = {Higher Education},
  volume = {19},
  number = {2},
  pages = {169--194},
  abstract = {Previous research has demonstrated that the academic environments provided by departments in higher education have direct effects on students' approaches to studying. But other studies have indicated that these effects are mediated by the students' own perceptions of those environments. Here two studies are reported which explore the relationships between approaches to learning, or study orientations, and perceptions of the academic environment. Those perceptions are measured in two distinct ways, one which minimises the effects of differential perceptions, and one which highlights them. Factor analyses of the responses of three groups of students taking engineering and psychology are used to clarify the nature of the relationships between study orientations and perceptions of the academic environment. It is found, as in earlier studies, that there are relationships which associate deep approaches with perceptions of relevance, and surface approaches with a heavy workload. But here it is also shown that students with contrasting study orientations are likely to define effective teaching in ways which reflect those orientations. Implications both for the design of feedback questionnaires and for the improvement of teaching and learning in higher education are discussed.},
  keywords = {Humanities,Social Sciences and Law}
}

@article{entwistleApproachesStudyingLevels1988,
  title = {Approaches to Studying and Levels of Processing in University Students},
  author = {Entwistle, Noel and Waterston, Susan},
  year = {1988},
  journal = {British Journal of Educational Psychology},
  volume = {58},
  number = {3},
  pages = {258--265},
  abstract = {Summary. Attempts at measuring students' study styles and strategies have been derived from different theoretical standpoints. Traditionally these have emerged from a combination of mainstream psychology and personal experience. More recently concepts have been derived from the qualitative analysis of students' experiences of studying and subsequently operationalised through inventories. This study compares the dimensions emerging from these two contrasting approaches. A sample of 218 mainly first-year university students were given shortened versions of two inventories, one based on concepts from cognitive psychology and the other from educational research. Correlations between subscales from the two inventories, and factor analyses of them, are reported which show substantial agreement between the main concepts used from the two theoretical traditions to describe study strategies.}
}

@incollection{entwistleRecentResearchStudent2013,
  title = {Recent Research on Student Learning and the Learning Learning Route},
  booktitle = {Management of {{Independent Learning Systems}}},
  author = {Entwistle, Noel},
  editor = {Knight, Peter and Tait, Jo},
  year = {2013},
  month = jan,
  edition = {0},
  pages = {109--124},
  publisher = {Routledge},
  doi = {10.4324/9780203062173-15},
  urldate = {2022-09-26},
  isbn = {978-0-203-06217-3},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/HDIP5LPD/entwistleRecentResearchStudent2013.pdf}
}

@book{entwistleUnderstandingStudentLearning2015,
  title = {Understanding {{Student Learning}} ({{Routledge Revivals}})},
  author = {Entwistle, Noel and Ramsden, Paul},
  year = {2015},
  month = aug,
  edition = {0},
  publisher = {Routledge},
  doi = {10.4324/9781315718637},
  urldate = {2025-01-23},
  isbn = {978-1-317-51358-2},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/entwistleUnderstandingStudentLearning2015.pdf}
}

@misc{EpicRapBattle,
  title = {Epic {{Rap Battle}} of {{Educational Technology History}} -- {{Alastair}}},
  urldate = {2018-11-02},
  langid = {canadian},
  keywords = {open,open pedagogy},
  file = {/Users/colin.madland/Zotero/storage/UP2EG3XN/epic-rap-battle-of-educational-technology-history.html}
}

@article{eraslanIntegratingGitLabMetrics2020,
  title = {Integrating {{GitLab}} Metrics into Coursework Consultation Sessions in a Software Engineering Course},
  author = {Eraslan, Sukru and {Kopec-Harding}, Kamilla and Jay, Caroline and Embury, Suzanne M. and Haines, Robert and Cort{\'e}s R{\'i}os, Julio C{\'e}sar and Crowther, Peter},
  year = {2020},
  journal = {The Journal of systems and software},
  volume = {167},
  pages = {110613},
  publisher = {Elsevier Inc},
  issn = {0164-1212},
  doi = {10.1016/j.jss.2020.110613},
  abstract = {{$\bullet$}Activity metrics from software development tools can be used to monitor student progress.{$\bullet$}Students find checkpoint sessions where these metrics are shared with the team useful.{$\bullet$}The metrics highlight uneven distribution of workload.{$\bullet$}It would be useful to include further detail about the work completed/code written.{$\bullet$}Presentation of the metrics in checkpoint sessions was associated with a higher student pass rate. Software developers use version control systems for collaborative coding. These systems are integrated into several software development platforms (including GitLab and GitHub) which support additional software engineering functionalities. Using these platforms in an educational context allows students to gain skills relevant to industry, whilst providing a means of keeping track of their activities. In this paper, we investigate the effect of presenting teams of students with GitLab metrics about their performance at coursework consultation sessions (checkpoint sessions), with a particular focus on the number of issues assigned and completed, and the number of commits made to the repository. A comparative analysis of project marks in two consecutive academic years indicates that these checkpoint sessions may lead to better student outcomes. An interview study with students and teaching assistants identified viewing the GitLab metrics in the checkpoints as an opportunity to see the relative contributions of team members and address resulting issues, and as a catalyst for improving engagement with the team project. The study also identified drawbacks of using the metrics too simplistically, and suggested that it was important to consider the quality and amount of written code, as well as the number of times someone committed to the repository.},
  keywords = {Collaborative software development,Git,Software engineering education,Undergraduate education,Version control system},
  file = {/Users/colin.madland/Zotero/storage/MRWILA4A/eraslanIntegratingGitLabMetrics2020.pdf}
}

@article{erbilReviewFlippedClassroom2020,
  title = {A {{Review}} of {{Flipped Classroom}} and {{Cooperative Learning Method Within}} the {{Context}} of {{Vygotsky Theory}}},
  author = {Erbil, Deniz G{\"o}k{\c c}e},
  year = {2020},
  month = jun,
  journal = {Frontiers in Psychology},
  volume = {11},
  pages = {1157},
  issn = {1664-1078},
  doi = {10/gg29tz},
  urldate = {2020-06-26},
  file = {/Users/colin.madland/Zotero/storage/A33A8CDB/erbilReviewFlippedClassroom2020.pdf}
}

@article{erCollaborativeLearningApproach2021,
  title = {A Collaborative Learning Approach to Dialogic Peer Feedback: A Theoretical Framework},
  shorttitle = {A Collaborative Learning Approach to Dialogic Peer Feedback},
  author = {Er, Erkan and Dimitriadis, Yannis and Ga{\v s}evi{\'c}, Dragan},
  year = {2021},
  month = may,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {46},
  number = {4},
  pages = {586--600},
  issn = {0260-2938, 1469-297X},
  doi = {10/gk33rc},
  urldate = {2021-07-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/SVBHSTI5/erCollaborativeLearningApproach2021.pdf}
}

@article{ericksonConceptionsSchoolCulture1987,
  title = {Conceptions of {{School Culture}}: {{An Overview}}},
  author = {Erickson, Frederick},
  year = {1987},
  month = nov,
  journal = {Educational Administration Quarterly},
  volume = {23},
  number = {4},
  pages = {11--24},
  issn = {0013-161X},
  doi = {10.1177/0013161X87023004003},
  urldate = {2018-09-22},
  abstract = {It is not clear what the term culture means in current discussion of school culture. Is it to refer globally to everything that happens routinely in schools, or are there more precise definitions that can be useful? This article reviews a range of definitions of culture. Three main conceptions of culture are discussed; a culture as bits of information, culture as conceptual structure and symbols, and culture as meanings generated in political struggle. Through examples and commentary the author considers the relative utility of the different conceptions of culture for helping one think about the diverse and systematically patterned ways of making sense that students, teachers, and administrators bring to their everyday encounters with one another in schools.}
}

@misc{EricStollerWhat,
  title = {Eric {{Stoller}} - {{What}} Is {{Digital Identity}}?},
  publisher = {University of Derby}
}

@misc{ErosionHighStakesSummative,
  title = {The {{Erosion}} of {{High-Stakes Summative Tests}}: {{Adding}} a {{New Compass}}},
  shorttitle = {The {{Erosion}} of {{High-Stakes Summative Tests}}},
  journal = {Mindful Measurement},
  urldate = {2020-10-13},
  abstract = {Rather than frequently interrupting learning with benchmarking tests, ``stealth assessments'' provide guidance just-in-time, which means many students will do better when high-stakes summative tests are administered. These diagnostic assessments are not substitutes for psychometrically reliable and va},
  howpublished = {https://www.mindfulmeasurement.com/blog/strongthe-erosion-of-high-stakes-summative-tests-adding-a-new-compassstrong},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/ULLIJDZ8/strongthe-erosion-of-high-stakes-summative-tests-adding-a-new-compassstrong.html}
}

@article{ersozFacebookPeerAssessmentPlatform2018,
  title = {Facebook as a {{Peer-Assessment Platform}}: {{A Case Study}} in {{Art Teacher Education Context}}},
  author = {Ers{\"o}z, Yasemin and Sad, S{\"u}leyman Nihat},
  year = {2018},
  month = jan,
  journal = {International Journal of Assessment Tools in Education},
  volume = {5},
  number = {4},
  pages = {740--753},
  publisher = {International Journal of Assessment Tools in Education},
  issn = {2148-7456},
  doi = {10.21449/ijate.478277},
  abstract = {This research intended to answer the question "Is Peer-Assessment on Facebook useful in visual art education?" in an intrinsic case study. Participants were a group of prospective visual-art teachers, who regularly share and comment on the photographs of their paintings in a special group they created on Facebook. Ten volunteering prospective visual-art teachers were involved in the study during 2013-2014 academic year. Focus group interviews were conducted with the participants to collect data in addition to online digital documents, including photographs of students' paintings and comments on them. In general, participants stated that Facebook-based peer assessment is beneficial, since it helps them notice their deficiencies, look at their works from a different perspective and improve their artistic skills. Thanks to the productive feedback, their motivation and self-confidence are boosted. It was also found that peer-assessment on Facebook has the advantage of ubiquity, allowing more peer involvement, easy and objective criticism, and sustainable learning opportunities in the long-run. The participants also emphasized some disadvantages of the practice of peer assessment on Facebook such as subjective feedback and poor quality of digitalized visuals.},
  keywords = {Art Teachers,Evaluation,Foreign Countries,Methods,Motivation,Painting (Visual Arts),Peer Evaluation,Preservice Teachers,Self Esteem,Social Media,Student Attitudes,Turkey},
  file = {/Users/colin.madland/Zotero/storage/7ZKBDK9U/ersozFacebookPeerAssessmentPlatform2018.pdf}
}

@article{ertmerBehaviorismCognitivismConstructivism1993,
  title = {Behaviorism, {{Cognitivism}}, {{Constructivism}}: {{Comparing Critical Features}} from an {{Instructional Design Perspective}}},
  author = {Ertmer, Peggy A. and Newby, Timothy J.},
  year = {1993},
  month = dec,
  journal = {Performance Improvement Quarterly},
  volume = {6},
  number = {4},
  pages = {50--72},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {0898-5952},
  doi = {10/dt6ktw},
  urldate = {2020-04-29},
  abstract = {ABSTRACT The way we define learning and what we believe about the way learning occurs has important implications for situations in which we want to facilitate changes in what people know and/ or do. Learning theories provide instructional designers with verified instructional strategies and techniques for facilitating learning as well as a foundation for intelligent strategy selection. Yet many designers are operating under the constraints of a limited theoretical background. This paper is an attempt to familiarize designers with three relevant positions on learning (behavioral, cognitive, and constructivist) which provide structured foundations for planning and conducting instructional design activities. Each learning perspective is discussed in terms of its specific interpretation of the learning process and the resulting implications for instructional designers and educational practitioners. The information presented here provides the reader with a comparison of these three different viewpoints and illustrates how these differences might be translated into practical applications in instructional situations.},
  file = {/Users/colin.madland/Zotero/storage/NPYH27N3/ertmerBehaviorismCognitivismConstructivism1993.pdf}
}

@article{esareyBlogsOnlineSeminars2018,
  title = {Blogs, {{Online Seminars}}, and {{Social Media}} as {{Tools}} of {{Scholarship}} in {{Political Science}}},
  author = {Esarey, Justin and Wood, Andrew R.},
  year = {2018},
  journal = {PS: Political Science \& Politics},
  edition = {2018/03/19},
  volume = {51},
  number = {4},
  pages = {811--819},
  publisher = {Cambridge University Press},
  issn = {1049-0965},
  doi = {10/gfhhtr},
  abstract = {How do political scientists use online tools as part of their scholarly work? Are there systematic differences in how they value these tools by field, gender, or other demographics? How important are these tools relative to traditional practices of political scientists? The answers to these questions will shape how our discipline chooses to reward academics who engage with ``new media'' such as blogs, online seminars (i.e., webinars), Twitter, and Facebook. We find that traditional tools of scholarship are more highly regarded and used more often than any new media, although blogs are considered most important among new media. However, we also find evidence that these webinars are used and valued at rates comparable to traditional tools when they are provided in ways that meet political scientists' needs. Finally, we observe that women and graduate students are substantially more likely than men and tenure-track academics to report that webinars and online videos are important sources of new ideas and findings.}
}

@article{esfandiariMixedmethodsCrosssectionalStudy2016,
  title = {A {{Mixed-methods}}, {{Cross-sectional Study}} of {{Assessment Literacy}} of {{Iranian University Instructors}}: {{Implications}} for {{Teachers}}' {{Professional Development}}},
  shorttitle = {A {{Mixed-methods}}, {{Cross-sectional Study}} of {{Assessment Literacy}} of {{Iranian University Instructors}}},
  author = {Esfandiari, Rajab and {Imam Khomeini International University, Qazvin} and Nouri, Razieh and {Imam Khomeini International University, Qazvin}},
  year = {2016},
  month = sep,
  journal = {Iranian Journal of Applied Linguistics},
  volume = {19},
  number = {2},
  pages = {115--154},
  issn = {1735-1634, 1735-1634},
  doi = {10/gmdnd9},
  urldate = {2021-08-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/5HCRJ59F/esfandiariMixedmethodsCrosssectionalStudy2016.pdf}
}

@article{esselTransformingHigherEducation2021,
  title = {Transforming Higher Education in {{Ghana}} in Times of Disruption: Flexible Learning in Rural Communities with High Latency Internet Connectivity},
  shorttitle = {Transforming Higher Education in {{Ghana}} in Times of Disruption},
  author = {Essel, Harry Barton and Vlachopoulos, Dimitrios and Adom, Dickson and {Tachie-Menson}, Akosua},
  year = {2021},
  month = apr,
  journal = {Journal of Enterprising Communities: People and Places in the Global Economy},
  volume = {ahead-of-print},
  number = {ahead-of-print},
  issn = {1750-6204, 1750-6204},
  doi = {10/gjpx2t},
  urldate = {2021-04-13},
  abstract = {Purpose               The purpose of this study is to explore the characteristics and potential effects of teaching and learning through audio teleconferencing (dial-in) with a cell phone. In addition, the study aims to identify the associations between the audio teleconferencing and video teleconferencing in a 12-week postgraduate course.                                         Design/methodology/approach               The study is a cross-sectional survey conducted at the Department of Educational Innovations at the Kwame Nkrumah University of Science and Technology from March to June 2020. The purposive sampling technique was used to sample 100 postgraduate students who registered for a course in the department. The data for the study were collected using the System Usability Scale (SUS) and 17-item self-administered eQuestionnaire. Multiple Linear Regression analysis, ANOVA, Independent sample T-test and Mann--Whitney U-test were used to estimate the differences in course achievements of students who experienced education through audio teleconferencing and those who experienced education through video teleconferencing.                                         Findings                                In total, 59\% of the participating postgraduate students chose to attend the synchronous online lectures via audio teleconferencing (dial-in). The participants gave a high SUS score (SUS\,{$>$}\,80.3; Grade A; Excellent) for audio conferencing service. Among the students in the audio teleconferencing cohort, the results evidenced a strong positive linear correlation, (r (57)\,=\,0.79, p\,{$<$}\,0.05), between the individual adjective ratings and the SUS scores. There was marginal significance among demography of students in the audio teleconference (AT) cohort with regards to their perception about the dial-in lecture. There was no statistically significant difference, (                 t                 (98)\,=\,1.88, p\,=\,0.063), in the achievement test for AT students and video teleconference (VT) students. The instructors and the students were satisfied with the AT.                                                        Practical implications               Based on the students' preference, AT offers equal benefit as VT with regards to system satisfaction and perceived quality of online teaching. AT, as teaching modality, should be an option for students who reside in communities with high latency internet connectivity. It is recommended that instructors are trained on how to engage and motivate students via AT.                                         Originality/value               Higher education institutions in Ghana are facing decisions about how to continue learning and teaching through flexible pedagogy, while keeping their faculty members and students protected from the COVID-19 pandemic. Many of these institutions have canceled the brick-and-mortar education and other conventional learning practices and have instructed faculty to adopt online teaching through synchronous video teleconferencing platforms. However, the learning experience is not the same for students who reside in remote or rural communities with low bandwidth. There is very little research in this topic, especially in developing countries like Ghana, and the present study aims to bridge the gap in the literature by exploring the characteristics and potential effects of teaching and learning through audio teleconferencing (dial-in) with a cell phone, in the context of a 12-week postgraduate course.},
  langid = {english}
}

@article{estajiImmediateDelayedEffect2019,
  title = {The {{Immediate}} and {{Delayed Effect}} of {{Dynamic Assessment Approaches}} on {{EFL Learners}}' {{Oral Narrative Performance}} and {{Anxiety}}},
  author = {Estaji, Masoomeh and Farahanynia, Mahsa},
  year = {2019},
  month = jan,
  journal = {Educational Assessment},
  volume = {24},
  number = {2},
  pages = {135--154},
  publisher = {Educational Assessment},
  issn = {1062-7197},
  doi = {10.1080/10627197.2019.1578169},
  abstract = {The present study aimed to investigate the effect of two major approaches of Dynamic Assessment, namely, interventionist and interactionist approaches, on learners' oral narrative performance and anxiety. To this end, 34 Iranian EFL learners were assigned to an Interactionist Group (InA.G) and Interventionist Group (InV.G). Initially, both groups were given the Foreign Language Classroom Anxiety Scale and a pretest of speaking. In the treatment phase, the InV.G was asked to narrate a video and received instructions on their errors. The InA.G narrated the video while being provided with scaffolding during narration. Then both groups were given a posttest and, two weeks later, a delayed posttest. The results indicated that both groups' oral performance significantly increased, while their anxiety reduced. In the end, a semi-structured interview was conducted whose results revealed that the InA.G experienced more anxiety mostly due to feeling a sense of interruption and losing face.},
  keywords = {Alternative Assessment,Anxiety,College Students,English (Second Language),Feedback (Response),Foreign Countries,Foreign Language Classroom Anxiety Scale,Interaction,Intervention,Iran,Language Skills,Oral Language,Program Effectiveness,Second Language Learning,Teaching Methods,Video Technology}
}

@article{eubankmorrisAssessmentLeadershipStudy2017,
  title = {Toward {{Assessment Leadership}}: {{Study}} of {{Assessment Practices}} among {{School}} and {{Classroom Leaders}}.},
  author = {{Eubank Morris} and {Carrie Elizabeth Eubank Morris} and {Carrie Elizabeth}},
  year = {2017},
  doi = {10/gmgbpp}
}

@article{evansMakingSenseAssessment2013,
  title = {Making {{Sense}} of {{Assessment Feedback}} in {{Higher Education}}},
  author = {Evans, Carol},
  year = {2013},
  month = mar,
  journal = {Review of Educational Research},
  volume = {83},
  number = {1},
  pages = {70--120},
  issn = {0034-6543, 1935-1046},
  doi = {10.3102/0034654312474350},
  urldate = {2021-03-21},
  abstract = {This article presents a thematic analysis of the research evidence on assessment feedback in higher education (HE) from 2000 to 2012. The focus of the review is on the feedback that students receive within their coursework from multiple sources. The aims of this study are to (a) examine the nature of assessment feedback in HE through the undertaking of a systematic review of the literature, (b) identify and discuss dominant themes and discourses and consider gaps within the research literature, (c) explore the notion of the feedback gap in relation to the conceptual development of the assessment feedback field in HE, and (d) discuss implications for future research and practice. From this comprehensive review of the literature, the concept of the feedback landscape, informed by sociocultural and socio-critical perspectives, is developed and presented as a valuable framework for moving the research agenda into assessment feedback in HE forward.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/YK2DFE46/evansMakingSenseAssessment2013.pdf}
}

@article{evaServantLeadershipSystematic2019,
  title = {Servant Leadership: {{A}} Systematic Review and Call for Future Research.},
  author = {Eva, Nathan and Robin, Mulyadi and Sendjaya, Sen and {\noopsort{dierendonck}}{van Dierendonck}, Dirk and Liden, Robert C.},
  year = {2019},
  month = feb,
  journal = {Leadership Quarterly},
  doi = {10.1016/J.LEAQUA.2018.07.004},
  abstract = {Abstract   Notwithstanding the proliferation of servant leadership studies with over 100 articles published in the last four years alone, a lack of coherence and clarity around the construct has impeded its theory development. We provide an integrative and comprehensive review of the 285 articles on servant leadership spanning 20\,years (1998--2018), and in so doing extend the field in four different ways. First, we provide a conceptual clarity of servant leadership vis-a-vis other value-based leadership approaches and offer a new definition of servant leadership. Second, we evaluate 16 existing measures of servant leadership in light of their respective rigor of scale construction and validation. Third, we map the theoretical and nomological network of servant leadership in relation to its antecedents, outcomes, moderators, mediators. We finally conclude by presenting a detailed future research agenda to bring the field forward encompassing both theoretical and empirical advancement. All in all, our review paints a holistic picture of where the literature has been and where it should go into the future.}
}

@article{evendiAssessingStudentsCritical2022,
  title = {Assessing Students' Critical Thinking Skills Viewed from Cognitive Style: {{Study}} on Implementation of Problem-Based e-Learning Model in Mathematics Courses},
  author = {Evendi, Erpin and Al Kusaeri, Al Kusaeri and Pardi, M. Habib Husnial and Sucipto, Lalu and Bayani, Faizul and Prayogi, Saiful},
  year = {2022},
  journal = {Eurasia Journal of Mathematics, Science and Technology Education},
  volume = {18},
  number = {7},
  pages = {em2129},
  address = {East Sussex},
  issn = {1305-8215},
  doi = {10.29333/ejmste/12161},
  abstract = {The digitalization system that continues to roll has brought changes to the learning system, where face-to-face learning is replaced by an online system. On the one hand, learning experiences to acquire critical thinking (CT) skills as one of the essential skills of the 21st century must also be encouraged. The objective of this study is to assess students' CT skills in terms of cognitive style by implementing the problem-based e-learning (e-PBL) model in mathematics courses. This study is an evaluative study with an experimental approach, where as many as 28 students as research samples were taken purposively from Mandalika University of Education, Indonesia. A set of instruments was prepared to measure every aspect of CT and cognitive style, including descriptive and statistical data analysis so that the results of the CT assessment were found. In general, the results of the CT evaluation show that e-PBL is effective in improving students' CT skills, so this is a recommendation to use e-PBL widely and intensively.},
  keywords = {Cognitive style,Critical thinking,Online instruction,Students},
  file = {/Users/colin.madland/Zotero/storage/ICSVX5E2/evendiAssessingStudentsCritical2022.pdf}
}

@misc{EverydayOpenLearning2013,
  title = {Everyday Open Learning so Unremarkable That It Amazes Me},
  year = {2013},
  month = dec,
  journal = {Abject},
  urldate = {2020-07-16},
  abstract = {Happened to look in on a blog for a course on Philosophy and Pop Culture at TRU. Saw a post that I thought was remarkable for a couple reasons. A student had just posted some fresh reflections, tho{\dots}},
  howpublished = {https://abject.ca/unremarkable-and-amazing/},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/9TPFUS3V/unremarkable-and-amazing.html}
}

@misc{EverythingAliveEveryone,
  title = {Everything Is Alive and Everyone Is Related: {{Indigenous}} Knowing and Inclusive Education {\textbar} {{Federation}} for the {{Humanities}} and {{Social Sciences}}},
  urldate = {2019-03-30},
  howpublished = {https://www.ideas-idees.ca/blog/everything-alive-and-everyone-related-indigenous-knowing-and-inclusive-education},
  file = {/Users/colin.madland/Zotero/storage/NTDBL4DJ/everything-alive-and-everyone-related-indigenous-knowing-and-inclusive-education.html}
}

@article{ewellChapterCaptureIneffable1991,
  title = {Chapter 3: {{To Capture}} the {{Ineffable}}: {{New Forms}} of {{Assessment}} in {{Higher Education}}},
  shorttitle = {Chapter 3},
  author = {Ewell, Peter T.},
  year = {1991},
  month = jan,
  journal = {Review of Research in Education},
  volume = {17},
  number = {1},
  pages = {75--125},
  issn = {0091-732X, 1935-1038},
  doi = {10.3102/0091732X017001075},
  urldate = {2023-03-08},
  langid = {english}
}

@book{ExploratoryFactorAnalysis,
  title = {Exploratory {{Factor Analysis}} in {{R}}},
  urldate = {2024-02-21},
  abstract = {This online course describe how to extract and use open source data for factor analysis in R.},
  file = {/Users/colin.madland/Zotero/storage/8YGQPFWW/EFA_in_R.html}
}

@article{eyalDigitalAssessmentLiteracy2012,
  title = {Digital {{Assessment Literacy}} --- the {{Core Role}} of the {{Teacher}} in a {{Digital Environment}}},
  author = {Eyal, Liat},
  year = {2012},
  journal = {Journal of Educational Technology \& Society},
  volume = {15},
  number = {2},
  pages = {37--49},
  publisher = {International Forum of Educational Technology \& Society},
  issn = {11763647, 14364522},
  urldate = {2022-04-23},
  abstract = {[ABSTRACT One of the main functions of a teacher in a digital environment is student assessment. The need for assessment literacy based on measurement and quantitative data is weakening, both in terms of the traditional approach of the assessment on which it is based on, and given that information technologies can address these needs effectively. The assessment literacy required of a teacher today is of a completely different kind --- one that is adapted to the digital environment and tailored for the pedagogical approaches of the 21st century. This article will focus on the skills, abilities, and perceptions required of the teacher in the digital environment with respect to assessment, and will demonstrate the importance of adapting the various technologies to the different assessment purposes. This definition of the term ``Digital assessment literacy'' is based on a doctoral thesis that examined the Relationship between the technological environment and the teaching, learning and assessment processes in online courses (Eyal, 2010).]},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/VWDHPZ58/eyalDigitalAssessmentLiteracy2012.pdf}
}

@article{f.alquraanCrossculturalStudyStudents2014,
  title = {A Cross-Cultural Study of Students' Perceptions of Assessment Practices in Higher Education},
  author = {F. Alquraan, Mahmoud},
  year = {2014},
  month = oct,
  journal = {Education, Business and Society: Contemporary Middle Eastern Issues},
  volume = {7},
  number = {4},
  pages = {293--315},
  issn = {1753-7983},
  doi = {10/ghhbn8},
  urldate = {2020-10-30},
  langid = {english}
}

@article{f0f48df7540e2f50cb24f3d14f9ab3c6439ef689,
  title = {Multi-Level Model of Contextual Factors and Teachers' Assessment Practices: An Integrative Review of Research},
  author = {Fulmer, G. and Lee, I. H. and Tan, Kelvin},
  year = {2015},
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {22},
  pages = {475--494},
  doi = {10/gh5k6q},
  abstract = {We present a multi-level model of contextual factors that may influence teachers' assessment practices, and use this model in a selected review of existing literature on teachers' assessment knowledge, views and conceptions with respect to these contextual factors. Adapting Kozma's model, we distinguish three levels of influence on teachers' practices: micro, meso and macro. We searched for relevant articles in EBSCO, JSTOR and other databases, and review selected articles with a focus on the complex relationships within and across these levels. Findings reveal a large body of research at the micro-level (teacher), such as on teachers' values, conceptions and knowledge. However, there is relatively less research at the meso-level (school) or connecting it with the micro- or macro-levels. Implications for future research are also discussed.}
}

@article{f17959bbc527e09fd9108b2766fce33c6d04b373,
  title = {Exploring Assessment Literacy},
  author = {Huang, J. and He, Zonghui},
  year = {2016},
  journal = {Higher Education of Social Science},
  volume = {11},
  pages = {18--27},
  doi = {10.3968/N},
  abstract = {Language assessment literacy represents an important aspect of teachers' professional knowledge. Research of this kind can serve the dual purpose of informing the nature and scope of teacher education reforms and the specific direction of professional development initiatives for pre-service and in-service teachers. This article attempted to explore the concept of assessment literacy and its training components through related literature review.},
  keywords = {Invalid DOI}
}

@article{faberEffectsDigitalFormative2017,
  title = {The Effects of a Digital Formative Assessment Tool on Mathematics Achievement and Student Motivation: {{Results}} of a Randomized Experiment},
  author = {Faber, {\relax JM} and Luyten, H and Visscher, {\relax AJ}},
  year = {2017},
  journal = {Computers \& Education},
  volume = {106},
  pages = {83--96},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2016.12.001},
  abstract = {In this study a randomized experimental design was used to examine the effects of a digital formative assessment tool on mathematics achievement and motivation in grade three primary education (n schools = 79, n students = 1808). Experimental schools used a digital formative assessment tool whereas control schools used their regular teaching methods and materials. The tool provides student feedback, feedback to teachers, and adaptive assignments. Data included standardized achievement pre-posttest data, student motivation survey data, classroom observation data, and student log files. Multilevel analysis revealed positive effects on student achievement and motivation. Students' intensity of use measurements support the effects found on student achievement and motivation. Furthermore, achievement effects were higher for high-performing students. (C) 2016 Elsevier Ltd. All rights reserved.},
  langid = {english},
  keywords = {ATTITUDES,COMPUTER-BASED ASSESSMENT,CONNECTED CLASSROOM TECHNOLOGY,Elementary education,FEEDBACK,Improving classroom teaching,INSTRUCTION,INTERVENTION,LITERACY,METAANALYSIS,PERFORMANCE,SYSTEM,Teaching/learning strategies}
}

@article{fabrigarEvaluatingUseExploratory1999,
  title = {Evaluating the {{Use}} of {{Exploratory Factor Analysis}} in {{Psychological Research}}},
  author = {Fabrigar, Leandre R and Wegener, Duane T and MacCallum, Robert C and Strahan, Erin J},
  year = {1999},
  journal = {Psychological methods},
  volume = {4},
  number = {3},
  pages = {272--299},
  publisher = {American Psychological Association},
  address = {Washington, DC},
  issn = {1082-989X},
  doi = {10.1037/1082-989X.4.3.272},
  abstract = {Despite the widespread use of exploratory factor analysis in psychological research, researchers often make questionable decisions when conducting these analyses. This article reviews the major design and analytical decisions that must be made when conducting a factor analysis and notes that each of these decisions has important consequences for the obtained results. Recommendations that have been made in the methodological literature are discussed. Analyses of 3 existing empirical data sets are used to illustrate how questionable decisions in conducting factor analyses can yield problematic results. The article presents a survey of 2 prominent journals that suggests that researchers routinely conduct analyses using such questionable methods. The implications of these practices for psychological research are discussed, and the reasons for current practices are reviewed.},
  keywords = {Biological and medical sciences,Evaluation,Experimentation,Exploratory Factor Analysis,Factor Analysis,Fundamental and applied biological sciences. Psychology,Psychology,Psychology. Psychoanalysis. Psychiatry,Psychology. Psychophysiology,Psychometrics. Statistics. Methodology,Scientific Communication,Statistics. Mathematics},
  file = {/Users/colin.madland/Zotero/storage/T7NYKN7X/fabrigarEvaluatingUseExploratory1999.pdf}
}

@book{facerLearningFuturesEducation2011,
  title = {Learning Futures: Education, Technology, and Social Change},
  shorttitle = {Learning Futures},
  author = {Facer, Keri},
  year = {2011},
  edition = {1st ed},
  publisher = {Routledge},
  address = {London ; New York},
  isbn = {978-0-415-58142-4 978-0-415-58143-1},
  lccn = {LB1028.5 .F32 2011},
  keywords = {Computer-assisted instruction,Cyberspace,Education,Effect of technological innovations on,Information technology,Internet,Social aspects,Technological innovations},
  file = {/Users/colin.madland/Zotero/storage/KJI4IT4C/facerLearningFuturesEducation2011.pdf}
}

@article{facerTaking21stCentury2012,
  title = {Taking the 21st Century Seriously: Young People, Education and Socio-Technical Futures},
  author = {Facer, Keri},
  year = {2012},
  month = feb,
  journal = {Oxford Review of Education},
  volume = {38},
  number = {1},
  pages = {97--113},
  publisher = {Routledge},
  issn = {0305-4985},
  doi = {10/ct2gzp},
  file = {/Users/colin.madland/Zotero/storage/FAIHFFG9/facerTaking21stCentury2012.pdf}
}

@misc{FacialRecognitionChallenge2020,
  title = {In Facial Recognition Challenge, Top-Ranking Algorithms Show Bias against {{Black}} Women},
  year = {2020},
  month = sep,
  journal = {VentureBeat},
  urldate = {2020-09-25},
  abstract = {The results from a recent facial recognition competition demonstrate that even the best algorithms are still prone to gender and racial bias.},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/7CM6NBUX/in-facial-recognition-challenge-top-ranking-algorithms-show-bias-against-black-women.html}
}

@article{fahyPreferencesResidentsFour2009,
  title = {Preferences of {{Residents}} in {{Four Northern Alberta Communities Regarding Local Post-Secondary Programming}}},
  author = {Fahy, Patrick J. and Steel, Nancy and Martin, Patricia},
  year = {2009},
  month = jun,
  journal = {The International Review of Research in Open and Distributed Learning},
  volume = {10},
  number = {3},
  issn = {1492-3831},
  doi = {10.19173/irrodl.v10i3.673},
  urldate = {2019-02-16},
  langid = {english},
  keywords = {Distance delivery,northern Aboriginal education in Canada,remote education,socioeconomic factors in learning},
  file = {/Users/colin.madland/Zotero/storage/BVLSRS6C/fahyPreferencesResidentsFour2009.pdf;/Users/colin.madland/Zotero/storage/U9MAIKBA/673.html}
}

@article{fairtloughHabermasConceptLifeworld1991,
  ids = {fairtloughHabermasConceptLifeworld1991a},
  title = {Habermas' Concept of ``{{Lifeworld}}''},
  author = {Fairtlough, Gerard H.},
  year = {1991},
  month = dec,
  journal = {Systems practice},
  volume = {4},
  number = {6},
  pages = {547--563},
  issn = {1573-9295},
  doi = {10/b7jgwc},
  abstract = {The philosophical basis for Jurgen Habermas' later work is a communicative one: our ability to understand nature, society, and even ourselves arises from our communication with each other. ``Lifeworld'' is a key concept in this work, elaborated well beyond the lifeworld concept in the work of, e.g., Schutz. This paper describes Habermas' theory, relating it to his theories of communicative action and of societal steering media. It also suggests some parallels with the work of Vickers and makes proposals for the practical use of Habermas' lifeworld concept.}
}

@article{fallaceEthnocentricOriginsLearning2019,
  title = {The {{Ethnocentric Origins}} of the {{Learning Style Idea}}},
  author = {Fallace, Thomas},
  year = {2019},
  month = aug,
  journal = {Educational Researcher},
  volume = {48},
  number = {6},
  pages = {349--355},
  issn = {0013-189X, 1935-102X},
  doi = {10.3102/0013189X19858086},
  urldate = {2022-07-06},
  abstract = {In recent years, researchers have questioned the legitimacy of the so-called myth of learning styles and expressed confusion about exactly when and why the idea first emerged. This historical study traces the origin and emergence of the learning style idea. The author argues that the learning style idea originated in the 1960s as part of a broader effort to reach inner-city African American youth that certain educators deemed culturally deficient. By the time scholars developed learning style inventory instruments for mostly white children, they removed the race-specific language, and educators quickly forget the ethnocentric origins of the learning style idea.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/WH5PGR85/fallaceEthnocentricOriginsLearning2019.pdf}
}

@article{fangCultivationStudentTranslator2021,
  title = {Cultivation of {{Student Translator Autonomy}} in {{UK Higher Education}}},
  author = {Fang, Xiaoqing and Morris, Philip},
  year = {2021},
  journal = {English Language Teaching},
  volume = {14},
  number = {5},
  pages = {41--57},
  issn = {ISSN-1916-4742},
  doi = {10/gmbv3b},
  abstract = {This study, based on two questionnaires directed to translation lecturers in UK Higher Education (HE), aims to explore the teacher awareness of learner autonomy in the UK university translation classroom, and the extent to which students of translation are encouraged to become autonomous learners. It covers six aspects of translation education, i.e., objective setting, learning strategies, resources, technology, learner reflection and assessment, and teacher's role. The results provide insights to the teachers' understanding of student choice, control and responsibility in autonomous translation learning. The findings suggest that the translation students in UK HE are offered the most choice in translation resources and technologies, and the least choice in co-deciding translation syllabi, specialized professional goal and teaching materials; they seem to share consistent control with their teachers over the whole learning process, from goal-setting, to translation task completion, group collaboration, final version and translation quality criteria decision, to self-evaluation and reflection; they are encouraged to take responsibility for their translation products, collaboration in class, for learning to translate, and learning to evaluate and reflect. Nevertheless, the importance of encouraging student self-evaluation, peer-evaluation and self reflection in UK translation education seems to be underestimated, and is recommended to be brought to the forefront of further research.},
  langid = {english},
  keywords = {College Students,Cooperative Learning,Educational Resources,Educational Technology,Foreign Countries,Independent Study,Language Teachers,Learning Processes,Peer Evaluation,Personal Autonomy,Reflection,Self Evaluation (Individuals),Self Management,Student Journals,Student Responsibility,Teacher Attitudes,Teacher Student Relationship,Translation}
}

@article{fangOnlineCollaborativePeerAssessment2021,
  title = {An {{Online Collaborative Peer-Assessment Approach}} to {{Strengthening Pre-Service Teachers}}' {{Digital Content Development Competence}} and {{Higher-Order Thinking Tendency}}},
  author = {Fang, Jian-Wen and Chang, Shao-Chen and Hwang, Gwo-Jen and Yang, Gang},
  year = {2021},
  month = apr,
  journal = {Educational Technology Research and Development},
  volume = {69},
  number = {2},
  pages = {1155--1181},
  publisher = {{Educational Technology Research and Development}},
  issn = {1042-1629},
  doi = {10.1007/s11423-021-09990-7},
  abstract = {The competences of making good use of digital information and technology as well as making critical judgments and communicating with others have been considered as important educational objectives, in particular, for teacher education. Peer assessment is a frequently adopted learning strategy to assist students in rating and offering instant feedback to peers from the perspective of instructors, which has good potential for fostering students' critical thinking. However, the conventional peer-assessment approach mainly focuses on communications between reviewers and reviewees, while peer communications for collaboratively providing comments or suggestions are generally ignored. As a result, the present study proposed a Collaborative Feedback-based Peer-Assessment (CFPA) learning approach; moreover, a learning system was developed for evaluating the effectiveness of the different collaborative peer-assessment approaches by conducting a quasi-experiment in a pre-service teacher training program. Two classes of students participated in the experiment. One class including 48 students was the experimental group learning with the CFPA approach, while the other class with 49 students was the control group learning with the Non-Collaborative Peer Assessment (NCPA) approach. The findings indicated that the pre-service teachers who learned with the proposed approach showed significantly better instructional video development quality and commenting quality as well as higher self-efficacy and critical thinking tendency than those learning with the Non-Collaborative Peer Assessment approach.},
  keywords = {Cooperative Learning,Critical Thinking,Electronic Learning,Feedback (Response),Instructional Films,Material Development,Peer Evaluation,Preservice Teachers,Self Efficacy,Skill Development,Teacher Competencies,Thinking Skills,Video Technology}
}

@article{farrellPortafoglioEportfolioEvolution2020,
  title = {From {{Portafoglio}} to {{Eportfolio}}: {{The Evolution}} of {{Portfolio}} in {{Higher Education}}},
  shorttitle = {From {{Portafoglio}} to {{Eportfolio}}},
  author = {Farrell, Orna},
  year = {2020},
  month = sep,
  journal = {Journal of Interactive Media in Education},
  volume = {2020},
  number = {1},
  pages = {19},
  issn = {1365-893X},
  doi = {10.5334/jime.574},
  urldate = {2023-01-25},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/GQL5KK3L/farrellPortafoglioEportfolioEvolution2020.pdf}
}

@article{farrowOpenEducationCritical2017,
  title = {Open Education and Critical Pedagogy},
  author = {Farrow, Robert},
  year = {2017},
  journal = {Learning, Media and Technology},
  volume = {42},
  pages = {130--146},
  issn = {1743-9892},
  abstract = {This paper argues for a revaluation of the potential of open education to support more critical forms of pedagogy.  Section I examines contemporary discourses around open education, offering a commentary on the perception of openness as both a disruptive force in education, and a potential solution to contemporary challenges.  Section II examines the implications of the lack of consensus around what it means to be open, focusing on the example of commercial and proprietary claims to openness commonly known as ?openwashing?.  Section III uses Raymond?s influential essay on open source software ?The Cathedral and the Bazaar? as a framework for thinking through these issues, and about alternative power structures in open education.  In Section IV an explicit link is drawn between more equal or democratic power structures and the possibility for developing pedagogies which are critical and reflexive, providing examples which show how certain interpretations of openness can raise opportunities to support critical approaches to pedagogy.},
  keywords = {critical pedagogy,critical theory,critique,discourse analysis,evidence,MOOC,OER,open education,openwashing}
}

@article{fawnsAuthenticAssessmentPanacea2024,
  title = {Authentic Assessment: From Panacea to Criticality},
  shorttitle = {Authentic Assessment},
  author = {Fawns, Tim and Bearman, Margaret and Dawson, Phillip and Nieminen, Juuso Henrik and {Ashford-Rowe}, Kevin and Willey, Keith and Jensen, Lasse X and Dam{\c s}a, Crina and Press, Nona},
  year = {2024},
  month = sep,
  journal = {Assessment \& Evaluation in Higher Education},
  pages = {1--13},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2024.2404634},
  urldate = {2024-10-30},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/fawnsAuthenticAssessmentPanacea2024.pdf}
}

@incollection{fawnsOnlyWayEthics2023,
  title = {The Only Way Is Ethics: {{A}} Dialogue of Assessment and Social Good},
  shorttitle = {23. {{The}} Only Way Is Ethics},
  booktitle = {Higher {{Education}} for {{Good}}},
  author = {Fawns, Tim and Nieminen, Juuso Henrik},
  editor = {Czerniewicz, Laura and Cronin, Catherine},
  year = {2023},
  month = oct,
  edition = {1},
  pages = {533--554},
  publisher = {Open Book Publishers},
  address = {Cambridge, UK},
  doi = {10.11647/obp.0363.23},
  urldate = {2023-10-27},
  abstract = {What is assessment for good in the current higher education landscape? Assessment does not just ``drive learning''. It plays a role in shaping students' orientations towards future learning, beyond any course, and beyond graduation. It influences the kinds of knowledge and identity that hold legitimate status in disciplines and communities. It shapes power and trust relationships between junior and senior members of organisations, between those with different roles, between educational institutions and society. Through dialogue, this chapter challenges foundational assumptions about assessment in HE by considering meanings, possibilities and examples of `assessment for good' in two disciplinary contexts of medical (Tim) and mathematics (Juuso) education. In doing so, tensions are highlighted between traditions of individualism and authentic, messy forms of learning and unpredictable outcomes. The dialogue in this chapter emphasises that there is no right way to go about assessment for good, and that multiple perspectives need to be taken into account.},
  isbn = {978-1-80511-127-6 978-1-80511-128-3 978-1-80511-129-0 978-1-80511-133-7 978-1-80511-132-0 978-1-80511-130-6},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/Y26U73IT/fawns23OnlyWay2023.pdf}
}

@article{fedorovaApplicationBlockchainTechnology2020,
  title = {Application of {{Blockchain Technology}} in {{Higher Education}}},
  author = {Fedorova, Elena P. and Skobleva, Ella I.},
  year = {2020},
  journal = {European Journal of Contemporary Education},
  volume = {9},
  number = {3},
  pages = {552--571},
  issn = {EISSN-2305-6746},
  abstract = {Emergence and development of the blockchain technology, which is able to transform into "a most powerful disruptive innovation", shall definitely concern universities. Moreover, nowadays the blockchain technology meets the challenges that both the system of higher education and the entire society are currently facing. Advantages of the blockchain technology are decentralized open data, absence of forgeries, safe storage of information, and reduction of transaction expenses related to data checkup, control, and verification. This paper provides a critical analysis of application of the blockchain technology considering with its applicability opportunities and restrictions in education; it also aims to identify the consequences of its influence upon the development of education. The article analyzes real cases when this technology was applied, with the Massachusetts Institute of Technology (MIT) as an example. The MIT applied it to protect and validate the certificates that it issued. Another example is the Sony Global Education that forms individual data on its trainees' competencies and productivity; a third one relates to the University of Nicosia, which was the first to use smart contracts and accept cryptocurrency as a form of payment. The paper also considers the elements of the blockchain technology at universities (both in Russia and outside it), which participate in massive open online courses. It determines the scope of application of this technology in the Russian educational system. In addition, this article provides a literature review related to application of the blockchain technology; the review includes works by such renowned researchers as D. Tapscott, B. Bleir, A. Watters, A. Grech, A. Camilleri, M. Swan, A. Zaslavsky, etc. The paper analyzes the obtained findings of the survey that its authors have conducted among experts, professors, and specialists involved in accreditation. Thus, the paper provides an analysis of opportunities and restrictions related to application of the blockchain technology in higher education.},
  langid = {english},
  keywords = {Artificial Intelligence,Competence,Educational Technology,Foreign Countries,Higher Education,Information Management,Information Security,Information Storage,Intellectual Disciplines,Large Group Instruction,No DOI found,Online Courses,Productivity,Research,Technology Uses in Education}
}

@article{feinmanSecurityMechanismsWebBased2018,
  title = {Security {{Mechanisms}} on {{Web-Based Exams}} in {{Introductory Statistics Community College Courses}}},
  author = {Feinman, Yelena},
  year = {2018},
  month = nov,
  journal = {Journal of Social, Behavioral, and Health Sciences},
  volume = {12},
  number = {1},
  issn = {1948-3260},
  doi = {10.5590/JSBHS.2018.12.1.11},
  urldate = {2022-06-17},
  abstract = {The credibility of unsupervised online exams is an ongoing concern in higher education. Proctoring, in the form of physical or remote supervision, has been the main mechanism for maintaining academic integrity. However, both forms of proctoring are expensive and inconvenient. Several researchers have examined security mechanisms as a substitute for proctoring and obtained mixed results. This article describes a quasi-experimental study, the main goal of which was to examine the effectiveness of nonbiometric security mechanisms. The security mechanisms were selected based on the taxonomy of cheating reduction techniques rooted in the fraud triangle theory. The security mechanisms were considered effective if the scores were equivalent or lower on the unproctored exams. Two one-sided dependent {$<$}em{$>$}t {$<$}/em{$>$}tests were used to test for equivalence of scores on two sets of proctored and unproctored exams in face-to-face ({$<$}em{$>$}N {$<$}/em{$>$}= 704), hybrid ({$<$}em{$>$}N {$<$}/em{$>$}= 91), and online ({$<$}em{$>$}N {$<$}/em{$>$}= 55) introductory statistics community college courses. In the first set, the proctored exam was followed by the unproctored exam; in the second set, the order was reversed. In the first set, the scores on proctored and unproctored exams were equivalent in face-to-face and online groups, but students in the hybrid group had significantly lower scores on the unproctored exam. In the second set, the students' scores were lower on the unproctored exam in all groups. The study's results suggest that the used security mechanisms were effective.},
  file = {/Users/colin.madland/Zotero/storage/FTYTESY5/feinmanSecurityMechanismsWebBased2018.pdf}
}

@techreport{feldmanCanWeTrust2024,
  title = {Can {{We Trust The Transcript}}? {{Recognizing Student Potential Through More Accurate Grading}}},
  author = {Feldman, Joe},
  year = {2024},
  pages = {30},
  abstract = {Grades matter a lot. They shape a student's journey through school, dictating the courses they can take -- perhaps, more importantly, the courses they can't take -- the sports they can play, and what they are able to do when they graduate. For many of the nearly 2 million students who dropout of high school each year, grades provided the final push, symbolizing failure in the classroom.},
  file = {/Users/colin.madland/Zotero/storage/BQDZZ5WR/White-Paper-Can-We-Trust-The-Transcript.pdf}
}

@phdthesis{felicianoCollaborativeLearningPlatform2015,
  type = {{{MSc}}},
  title = {Towards a {{Collaborative Learning Platform}}: {{The Use}} of {{GitHub}} in {{Computer Science}} and {{Software Engineering Courses}}},
  author = {Feliciano, Joseph},
  year = {2015},
  address = {Victoria, BC},
  urldate = {2021-12-14},
  abstract = {Technical fields such as computer science and software engineering have placed an emphasis on collaboration and teamwork, and training students entering these fields is a challenge that educators and researchers have attempted to tackle. To develop students' skills for these technical fields, some educators have integrated learning ac- tivities where students collaborate heavily and make contributions to each other's learning, emulating the type of work students will perform in industry. Consequently, the learning tools that instructors use for their courses need to support these collab- orative and contributive activities. GitHub is a social coding tool that has seen rapid adoption in the software devel- opment field because of the open, collaborative workflow it encourages. This thesis explores the use of GitHub as a collaborative platform for computer science and soft- ware engineering education. GitHub provides users with opportunities to contribute to each other's work through its transparency features, supports integrated discus- sions, and provides support for reusing and remixing work---opportunities which may be extended to education. In this thesis, I investigate how GitHub's unique features, such as `pull requests' and commit histories, can be used to support learning and teaching. This work also explores the benefits and challenges that emerge from using GitHub in this context from both the instructor's and the student's perspectives. We found that GitHub afforded instructors with opportunities to encourage student participation by con- tributing to the course materials through the use of `pull requests' and provided instructors with ways to reuse and share their course materials. As well, students iv gained experience with a tool and a workflow they expected to encounter in indus- try, and were provided ways to further engage in their learning by giving feedback to or further developing other students' work. However, we found that instructors and students were challenged by GitHub's lack of educational focus, as well as the implications of using GitHub's open workflow on the public availability of student work. Findings from this work determine the viability of GitHub as a tool for supporting computer science and software engineering education, and contribute to our under- standing of what activities and benefits GitHub provides beyond traditional learning tools. The contributions of this work include a set of recommendations for instruc- tors wishing to use GitHub to augment their courses, utilizing GitHub's features to support educational activities such as student contributions to course materials and providing continuous feedback to students},
  school = {University of Victoria},
  file = {/Users/colin.madland/Zotero/storage/4JZDVRMS/felicianoCollaborativeLearningPlatform2015.pdf}
}

@article{Fellenz_2004,
  title = {Using Assessment to Support Higher Level Learning the Multiple Choice Item Development Assignment},
  author = {Fellenz, Martin R.},
  year = {2004},
  journal = {Assessment \& Evaluation in Higher Education},
  doi = {10/bh783v},
  abstract = {This paper describes the multiple choice item development assignment (MCIDA) that was developed to support both content and higher level learning. The MCIDA involves students in higher level learning by requiring them to develop multiple choice items, write justifications for both correct and incorrect answer options and determine the highest cognitive level that the item is testing. The article discusses the benefits and limitations of the scheme and presents data on the largely positive student reactions to the scheme. The development of the MCIDA also serves as an example for how traditional summatively oriented assessment procedures can be developed into tools that directly support student learning.},
  mag_id = {2155389165},
  pmcid = {null},
  pmid = {null}
}

@article{fellkurbanDesigningEffectiveContemporary2019,
  title = {Designing Effective, Contemporary Assessment on a Flipped Educational Sciences Course},
  author = {Fell Kurban, Caroline},
  year = {2019},
  journal = {Interactive learning environments},
  volume = {27},
  number = {8},
  pages = {1143--1159},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {1049-4820},
  doi = {10.1080/10494820.2018.1522650},
  abstract = {Evidence shows flipped learning increases academic performance and student satisfaction. Yet, often practitioners flip instruction but keep traditional curricula and assessment. Assessment in higher education is often via written exams. But these provide limited feedback and do not ask students to put knowledge into practice. This does not support the tenets of flipped learning. For two years, the author flipped instruction but retained traditional curricula and assessment. However, on the author's current course, all three aspects were redesigned to better support flipped learning. The aim of this research is to test the effectiveness of this redesign regarding student engagement and satisfaction. Thus, it is asked: How, on this course, can meaningful, continuous assessment be provided as well as effective, personalized feedback, while staying in line with the philosophy of flipped learning? Action research took place from September 2016 to June 2017. Quantitative data from a student survey, and qualitative data from a research diary and student focus group were gathered. What emerged is: a little-and-often assessment approach is effective for learning and engagement; tasks must be authentic and test demonstration of knowledge, not memory; quality, not quantity, is key for student learning; and students desire individualized feedback.},
  keywords = {21st Century Skills,assessment,Blended Learning,Curricula,curriculum,Curriculum Development,Distance learning,Education & Educational Research,Elementary School Students,Feedback,Feedback (Response),Flipped classroom,Flipped learning,Higher education,Individualized Instruction,instruction,Instructional design,Learner Engagement,Learning,Preservice Teachers,Qualitative analysis,Redesign,Social Sciences,Student Evaluation,Student Satisfaction,Teacher Education,Tutoring,University students,Video Technology}
}

@article{feltenReassessingAssessment2024,
  title = {Reassessing {{Assessment}}},
  author = {Felten, Peter and Meinking, Kristina},
  year = {2024},
  journal = {Change: The Magazine of Higher Learning},
  volume = {56},
  number = {1},
  pages = {65--72},
  issn = {0009-1383, 1939-9146},
  doi = {10.1080/00091383.2024.2297640},
  urldate = {2024-02-08},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/ZTC4U5L5/feltenReassessingAssessmentGrading2024.pdf}
}

@article{feltenSoTLSignaturePedagogy2018,
  title = {Is {{SoTL}} a {{Signature Pedagogy}} of {{Educational Development}}?},
  author = {Felten, Peter and Chick, Nancy},
  year = {2018},
  journal = {To Improve the Academy},
  volume = {37},
  number = {1},
  pages = {4--16},
  issn = {2334-4822},
  doi = {10.1002/tia2.20077},
  urldate = {2018-12-07},
  abstract = {Abstract In this article, we focus on questions that come into view when we look at educational development through the lenses of signature pedagogies and the Scholarship of Teaching and Learning (SoTL). We offer this as a thought experiment in which we consider if SoTL is a signature pedagogy of educational development, simultaneously enacting and revealing the practices, values, and assumptions that underpin the diverse work of our field. By envisioning SoTL in this way, we may more clearly see the purposes and practices that unite?and that ought to guide?educational developers and educational development.},
  keywords = {faculty development,organizational development,signature pedagogy,SoTL,values}
}

@article{feltenSoTLSignaturePedagogy2018a,
  title = {Is {{SoTL}} a {{Signature Pedagogy}} of {{Educational Development}}?},
  author = {Felten, Peter and Chick, Nancy},
  year = {2018},
  journal = {To Improve the Academy},
  volume = {37},
  number = {1},
  pages = {4--16},
  issn = {2334-4822},
  doi = {10.1002/tia2.20077},
  urldate = {2018-11-21},
  abstract = {Abstract In this article, we focus on questions that come into view when we look at educational development through the lenses of signature pedagogies and the Scholarship of Teaching and Learning (SoTL). We offer this as a thought experiment in which we consider if SoTL is a signature pedagogy of educational development, simultaneously enacting and revealing the practices, values, and assumptions that underpin the diverse work of our field. By envisioning SoTL in this way, we may more clearly see the purposes and practices that unite?and that ought to guide?educational developers and educational development.},
  keywords = {faculty development,organizational development,signature pedagogy,SoTL,values}
}

@book{fengeKeepingPromisesRoyal2015,
  title = {Keeping Promises: The {{Royal Proclamation}} of 1763, Aboriginal Rights, and Treaties in {{Canada}}},
  shorttitle = {Keeping Promises},
  author = {Fenge, T. and Aldridge, Jim},
  year = {2015},
  series = {{{McGill-Queen}}'s {{Native}} and Northern Series},
  number = {78},
  publisher = {McGill-Queen's University Press},
  address = {Montreal ; Kingston ; London ; Chicago},
  abstract = {"In 1763 King George III of Great Britain, victorious in the Seven Years' War with France, issued a Proclamation to organize the governance of territory newly acquired by the Crown in North America and the Caribbean. The Proclamation reserved land west of the Appalachian Mountains for Indians, and required the Crown to purchase Indian land through treaties, negotiated without coercion and in public, before issuing rights to newcomers to use and settle on the land. Marking its 250th anniversary Keeping Promises shows how central the application of the Proclamation is to the many treaties that followed it and the settlement and development of Canada. Promises have been made to Aboriginal peoples in historic treaties from the late eighteenth to the early twentieth centuries in Ontario, the Prairies, and the Mackenzie Valley, and in modern treaties from the 1970s onward, primarily in the North. In this collection, essays by historians, lawyers, treaty negotiators, and Aboriginal leaders explore how -- and how well -- these treaties are executed. Addresses by the governor general of Canada and the federal minister of Aboriginal Affairs and Northern Development are also included. In 2003 Aboriginal leaders formed the Land Claims Agreements Coalition to make sure that treaties -- building blocks of Canada -- are fully implemented. Unique in breadth and scope, Keeping Promises is a testament to the research, advocacy, solidarity, and accomplishments of this coalition and those holding the Crown to its commitments"--Back cover},
  isbn = {978-0-7735-4586-1 978-0-7735-4587-8},
  lccn = {KIB496 .K44 2015},
  keywords = {Autochtones,Canada,Civil rights,Claims,Droit,Droits,Great Britain,Indians of North America,Indigenous peoples,Land tenure,Legal status laws etc,Native peoples,Reclamations,Sovereign (1760-1820 : George III),Terres,Treaties}
}

@article{fergusonDesperatelySeekingRelevant2012,
  title = {Desperately Seeking . Relevant Assessment? : A Case Study on the Potential for Using Online Simulated Group Based Learning to Create Sustainable Assessment Practices},
  author = {Ferguson, Anneka and Lee, Elizabeth},
  year = {2012},
  journal = {Legal Education Review},
  volume = {22},
  number = {1/2},
  pages = {121--145},
  publisher = {Legal Education Review (Australia)},
  issn = {1033-2839},
  abstract = {Over the last couple of decades in Australia a number of factors have set the scene for a radical rethinking of the way practical legal training should occur between the completion of an undergraduate degree and admission to legal practice.;Over the last couple of decades in Australia there has been a number of factors that have set the scene for a radical re-think about the way practical legal training should occur between the completion of an undergraduate degree and being admitted to legal practice. One institution's response to these factors has been to redefine the core of its Graduate Diploma in Legal Practice as an online, group based, integrated and simulated learning environment. In this new learning environment, the integration of assessment within the 'course work' has potentially had the outcome of creating a sustainable assessment regime that results in learning outcomes that benefits students as they move beyond academia to the legal profession. This paper provides a case study of this teaching methodology and analyses whether sustainable assessment has been achieved. [Publisher abstract];},
  keywords = {Australian National University (ANU),Case studies,Computer simulation,Graduate study,Group activities,Higher education,Internet in education,Law,Law students,Lawyers,Legal education,Methods,No DOI found,Online education,Online learning,Simulated environment,Student assessment,Study and teaching,Team learning approach in education,Training,Training of,Usage}
}

@article{fernandesAssessmentHigherEducation2022,
  title = {Assessment in Higher Education: Voices of Programme Directors},
  shorttitle = {Assessment in Higher Education},
  author = {Fernandes, Eva Lopes and Flores, Maria Assun{\c c}{\~a}o},
  year = {2022},
  month = jan,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {47},
  number = {1},
  pages = {45--60},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2021.1888869},
  urldate = {2022-01-30},
  langid = {english},
  keywords = {archived},
  annotation = {https://web.archive.org/web/20220130060340/https://www.tandfonline.com/action/cookieAbsent},
  file = {/Users/colin.madland/Zotero/storage/7T694V6H/fernandesAssessmentHigherEducation2022.pdf}
}

@article{fernandez-bataneroOnlineEducationHigher2022,
  title = {Online Education in Higher Education: Emerging Solutions in Crisis Times},
  author = {{Fern{\'a}ndez-Batanero}, Jos{\'e} Mar{\'i}a and {Montenegro-Rueda}, Marta and {Fern{\'a}ndez-Cerero}, Jos{\'e} and Tadeu, Pedro},
  year = {2022},
  month = aug,
  journal = {Heliyon},
  volume = {8},
  number = {8},
  pages = {e10139},
  issn = {2405-8440},
  doi = {10.1016/j.heliyon.2022.e10139},
  abstract = {The COVID-19 pandemic caused changes in higher education institutions, mainly due to the temporary closure of face-to-face activities in universities worldwide. The transformation from face-to-face to online education was one of the emerging solutions to this crisis. This research aims to analyse and describe the adaptation process from face-to-face to online education and the perceptions of faculty and students during the pandemic in a literature review study. We developed this study following the methodology supported by the PRISMA statement and the PICoS strategy, retrieving scientific literature from Web of Science, Scopus, ERIC and PsycINFO. Of the 241 studies that the search yielded, 29 have been included. The results showed that online education was an enabling alternative for the development of higher education, but numerous weaknesses in the transition to online education were identified. The study concludes that online learning is a future direction in higher education. Therefore, institutions should invest more in online education platforms and improve faculty training plans.},
  keywords = {COVID-19,Higher education,Online education,Review},
  file = {/Users/colin.madland/Zotero/storage/N28KUYAD/fernandez-bataneroOnlineEducationHigher2022.pdf}
}

@article{fernandez-ferrerInfluenceInternetPedagogical2016,
  title = {The Influence of the Internet for Pedagogical Innovation: Using Twitter to Promote Online Collaborative Learning},
  author = {{Fernandez-Ferrer}, M and Cano, E},
  year = {2016},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {13},
  issn = {2365-9440},
  doi = {10.1186/s41239-016-0021-2},
  abstract = {This article analyses a practice of formative peer-assessment based on an experience in university teaching innovation. From a review of the literature on feedback for self-regulation, the traits of formative assessment practices are determined and a task and the assessment criteria are designed in a consistent way with these traits. After the application of the experience, the results are discussed in terms of students' involvement; activity performance of said experience and of the whole subject; motivation and self-perception of learning and of the competency-based development of the students. The results show positive effects on the involvement, motivation and learning perception but not on performance improvement, suggesting that future research should address the effects of self-regulating feedback on the estimated learning from objective measurements and should expand the studies of the effects of these practices on the immediate and future self-regulating capacity.},
  langid = {english},
  keywords = {Feedback,Formative assessment,Higher education,HIGHER-EDUCATION,Innovation,PEER FEEDBACK,PERCEPTIONS,Self-regulation},
  file = {/Users/colin.madland/Zotero/storage/ZK4WZRCG/fernandez-ferrerInfluenceInternetPedagogical2016.pdf}
}

@article{fernandez-sanchezCurricularIntegrationDigital2022,
  title = {Curricular Integration of Digital Technologies in Teaching Processes},
  author = {{Fern{\'a}ndez-S{\'a}nchez}, Mar{\'i}a Rosa and {Garrido-Arroyo}, Mar{\'i}a del Carmen and {Porras-Masero}, Isabel},
  year = {2022},
  journal = {Frontiers in Education},
  volume = {7},
  issn = {2504-284X},
  doi = {10.3389/feduc.2022.1005499},
  abstract = {The integration of digital technologies in the classroom is a complex and multidimensional process with different dynamics including, among others, those related to: the digital culture of the center, the competency of teachers and students, the support of families and innovation within educational programs. This paper presents a systematic literature review (SLR) to analyze how the curricular integration of educational technology in classroom practice has been developed at non-university levels in recent years. The PRISMA 2020 standards have been applied. For the selection of articles, the ERIC database was used, taking as a reference, key concepts from its Thesaurus, related to the objective of the research, performing a temporal search of scientific articles from 2018 up to the present day. After screening according to the inclusion criteria established by consensus among researchers, a total of 88 articles were obtained (n = 88). The main results point to several variables that should be strengthened to promote the integration of digital technologies in the classroom, among which teacher training stands out as a determining factor, with special emphasis on initial training. This opens a debate about the training that future teachers receive in relation to the integration of digital technologies in the teaching process.Systematic review registration[https://doi.org/10.5281/zenodo.6909261].},
  file = {/Users/colin.madland/Zotero/storage/7Z7IITU9/fernandez-sanchezCurricularIntegrationDigital2022.pdf}
}

@article{fernandoShowMeYour2018,
  title = {Show Me Your True Colours: {{Scaffolding}} Formative Academic Literacy Assessment through an Online Learning Platform},
  author = {Fernando, Weronika},
  year = {2018},
  journal = {Assessing Writing},
  volume = {36},
  number = {Journal Article},
  pages = {63--76},
  publisher = {Elsevier Inc},
  address = {OXFORD},
  issn = {1075-2935},
  doi = {10/gdnfdg},
  abstract = {{$\bullet$}Formative academic literacy assessment should focus on composing processes.{$\bullet$}Digital platforms and multimodal resources help to make composing processes explicit.{$\bullet$}Online platforms offer richer opportunities for formative assessment practices. In higher education, formative academic literacy assessment tends to prioritise the product, i.e. a written text, rather than the writing processes, i.e. an active and focused reading which leads to the development of an evidence-based argument. This paper shifts the emphasis from the written product to the writing processes and investigates the effectiveness of formative academic literacy assessment in facilitating students' engagement with composing processes and in helping them develop evidence-based writing. The study was conducted on a presessional programme, involved 15 students and used an online learning platform to stimulate students' criticality, evidence their active reading, and compile their formative essay in incremental steps of note-taking, outlining and paragraphing. Collected data (outlines/essays with feedback, student-generated digital artefacts, and questionnaires/follow-up interviews) were analysed qualitatively, employing genre/inductive analysis for student writing, semiotic analysis for students' digital sites, and thematic analysis for questionnaires/interviews. The findings indicate that emphasising composing processes and utilising an online platform to scaffold formative academic literacy assessment boosts students' understanding of text composition and helps to uncover and overcome difficulties encountered by student-writers while learning to write. The discussion highlights the educational value of online learning platforms and the affordances of multimodal resources in creating innovative assessment practices.;In higher education, formative academic literacy assessment tends to prioritise the product, i.e. a written text, rather than the writing processes, i.e. an active and focused reading which leads to the development of an evidence-based argument. This paper shifts the emphasis from the written product to the writing processes and investigates the effectiveness of formative academic literacy assessment in facilitating students' engagement with composing processes and in helping them develop evidence-based writing. The study was conducted on a presessional programme, involved 15 students and used an online learning platform to stimulate students' criticality, evidence their active reading, and compile their formative essay in incremental steps of note-taking, outlining and paragraphing. Collected data (outlines/essays with feedback, student-generated digital artefacts, and questionnaires/follow-up interviews) were analysed qualitatively, employing genre/inductive analysis for student writing, semiotic analysis for students' digital sites, and thematic analysis for questionnaires/interviews. The findings indicate that emphasising composing processes and utilising an online platform to scaffold formative academic literacy assessment boosts students' understanding of text composition and helps to uncover and overcome difficulties encountered by student-writers while learning to write. The discussion highlights the educational value of online learning platforms and the affordances of multimodal resources in creating innovative assessment practices.;To access, purchase, authenticate, or subscribe to the full-text of this article, please visit this link: http://dx.doi.org/10.1016/j.asw.2018.03.005;},
  keywords = {Academic literacy,Composing processes,EDUCATION & EDUCATIONAL RESEARCH,Educational evaluation,Formative assessment,HIGHER-EDUCATION,LINGUISTICS,Literacy,Literacy programs,METHODOLOGY,Online education,Online learning,Reading and writing,Scaffolding,STUDENTS}
}

@article{ferraraFormativeAssessmentTest2014,
  title = {Formative {{Assessment}} and {{Test Security}}: {{The Revised Standards Are Mostly Fine}}; {{Our Practices Are Not}}},
  shorttitle = {Formative {{Assessment}} and {{Test Security}}},
  author = {Ferrara, Steve},
  year = {2014},
  month = dec,
  journal = {Educational Measurement: Issues and Practice},
  volume = {33},
  number = {4},
  pages = {25--28},
  issn = {07311745},
  doi = {10/gcpgxb},
  urldate = {2020-10-01},
  langid = {english}
}

@incollection{ferraraPrincipledApproachesAssessment2016,
  title = {Principled Approaches to Assessment Design, Development, and Implementation},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {Ferrara, Steve and Lai, Emily and Reilly, Amy and Nichols, Paul D.},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch3},
  pages = {41--74},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch3},
  abstract = {Summary In this chapter we review five principled approaches to assessment design, development, and implementation: evidence-centered design, cognitive design systems, assessment engineering, the BEAR assessment system, and principled design for efficacy. We propose five foundational elements and an organizing element that can be used to characterize principled approaches. We demonstrate that all five approaches are similarly principled, but reflect principled elements in their own unique ways, and how they are similar to, and different from, conventional approaches to principled test design. Finally, we discuss practical challenges and considerations for selecting a principled approach and end with speculations about the evolution of principled approaches in the future.},
  chapter = {3},
  isbn = {978-1-118-95658-8},
  keywords = {and implementation,assessment engineering,BEAR assessment system,cognitive design systems,development,evidence-centered design,principled approaches to design,principled design for efficacy}
}

@article{ferrariWritingNarrativeStyle2015,
  title = {Writing Narrative Style Literature Reviews},
  author = {Ferrari, Rossella},
  year = {2015},
  journal = {Medical writing (Leeds)},
  volume = {24},
  number = {4},
  pages = {230--235},
  issn = {2047-4806},
  doi = {10.1179/2047480615Z.000000000329},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/8NDRGXX4/ferrariWritingNarrativeStyle2015.pdf}
}

@article{ferreiraMetaphorsWeRe2020,
  title = {Metaphors We're Colonised by? {{The}} Case of Data-Driven Educational Technologies in {{Brazil}}},
  author = {Ferreira, Giselle Martins dos Santos and Rosado, Luiz Alexandre da Silva and Lemgruber, M{\'a}rcio Silveira and Carvalho, Jaciara de S{\'a}},
  year = {2020},
  journal = {Learning, Media and Technology},
  volume = {45},
  number = {1},
  pages = {46--60},
  publisher = {Routledge},
  issn = {1743-9884},
  doi = {10/gh3wb2}
}

@misc{ferrellPrinciplesGoodAssessment2022,
  title = {Principles of Good Assessment and Feedback},
  author = {Ferrell, Gill and Knight, Sarah},
  year = {2022},
  journal = {Jisc},
  urldate = {2022-06-15},
  abstract = {We're a membership organisation, providing digital solutions for UK education and research.},
  howpublished = {https://www.jisc.ac.uk/full-guide/principles-of-good-assessment-and-feedback},
  langid = {british},
  file = {/Users/colin.madland/Zotero/storage/DVZQMHQQ/principles-of-good-assessment-and-feedback.html}
}

@article{ferrettiAssessmentPracticesBeliefs2021,
  title = {Assessment {{Practices}} and {{Beliefs}}: {{Teachers}}' {{Perspectives}} on {{Assessment}} during {{Long Distance Learning}}},
  author = {Ferretti, Federica and Santi, George Richard Paul and Del Zozzo, Agnese and Garzetti, Marzia and Bolondi, Giorgio},
  year = {2021},
  journal = {Education sciences},
  volume = {11},
  number = {6},
  pages = {264},
  publisher = {Mdpi},
  address = {BASEL},
  issn = {2227-7102},
  doi = {10.3390/educsci11060264},
  abstract = {The COVID-19 crisis has strongly affected the school system. In Italy, at-distance forms of didactics have been activated, changing the physiognomy of schools in terms of social interaction, practices and the identity of the individuals. In this paper, we address the issue of how teachers are facing the crisis: our focus is on assessment, as a key variable catalyzing personal history; beliefs; the interface between students; teachers and the school system. We study teachers' beliefs as part of their identities and assessment as a fundamental variable of beliefs. A qualitative content analysis of the open-ended answers to an online questionnaire is carried out to understand the main characteristics associated with assessment by teachers and the obstacles to overcome in the context of long distance learning (LDL). The data show that teachers did not identify valid assessment methods for LDL during the lockdown, especially due to the lack of control over the students. A misconception emerges concerning the definition of formative assessment together with a new awareness of the possibilities offered by digital technologies regarding the individualization of didactics. This study helps to understand which teachers' beliefs are related to assessment are and how they are shaped.},
  keywords = {Content analysis,COVID-19,Distance learning,Education & Educational Research,formative assessment,long distance learning,Social Sciences,Students,teacher identity,teachers' beliefs,Teaching},
  file = {/Users/colin.madland/Zotero/storage/FWJ6J4EE/ferrettiAssessmentPracticesBeliefs2021.pdf}
}

@book{fersterTeachingMachinesLearning2014,
  title = {Teaching {{Machines}} : {{Learning}} from the {{Intersection}} of {{Education}} and {{Technology}}},
  author = {Ferster, Bill},
  year = {2014},
  publisher = {Johns Hopkins University Press},
  address = {Baltimore, UNITED STATES},
  isbn = {978-1-4214-1541-3},
  file = {/Users/colin.madland/Zotero/storage/JNNMEARJ/fersterTeachingMachinesLearning2014.pdf}
}

@article{fettersAchievingIntegrationMixed2013,
  title = {Achieving {{Integration}} in {{Mixed Methods Designs-Principles}} and {{Practices}}},
  author = {Fetters, Michael D. and Curry, Leslie A. and Creswell, John W.},
  year = {2013},
  month = dec,
  journal = {Health Services Research},
  volume = {48},
  number = {6pt2},
  pages = {2134--2156},
  issn = {00179124},
  doi = {10/gbd7p5},
  urldate = {2021-05-14},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/Q6WHHSC7/fettersAchievingIntegrationMixed2013.pdf}
}

@article{fettersSpecialIssueCOVID192021,
  title = {Special {{Issue}} on {{COVID-19}} and {{Novel Mixed Methods Methodological Approaches During Catastrophic Social Changes}}},
  author = {Fetters, Michael D. and {Molina-Azorin}, Jos{\'e} F.},
  year = {2021},
  month = jul,
  journal = {Journal of Mixed Methods Research},
  volume = {15},
  number = {3},
  pages = {295--303},
  issn = {1558-6898, 1558-6901},
  doi = {10/gmbmbw},
  urldate = {2021-07-26},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/3VZWA5I3/fettersSpecialIssueCOVID192021.pdf}
}

@misc{fieldDesigningQuestionnaire2003,
  title = {Designing a {{Questionnaire}}},
  author = {Field, Andy},
  year = {2003},
  file = {/Users/colin.madland/Zotero/storage/YN6QJGKV/fieldDesigningQuestionnaire2003.pdf}
}

@book{fieldDiscoveringStatisticsUsing2012,
  title = {Discovering Statistics Using {{R}}},
  author = {Field, Andy P. and Miles, Jeremy and Field, {\relax Zo{\"e}}.},
  year = {2012},
  publisher = {Sage},
  address = {London [England},
  isbn = {978-1-4462-0045-2},
  keywords = {R (Computer program language),Social sciences -- Statistical methods -- Computer programs,Statistics -- Computer programs},
  file = {/Users/colin.madland/Zotero/storage/ZVK443DL/fieldDiscoveringStatisticsUsing2012.pdf}
}

@book{fieldDiscoveringStatisticsUsing2018,
  title = {Discovering Statistics Using {{IBM SPSS}} Statistics},
  author = {Field, Andy P.},
  year = {2018},
  edition = {5th edition, North American edition},
  publisher = {Sage Publications Inc},
  address = {Thousand Oaks, California},
  isbn = {978-1-5264-4027-3 978-1-5264-3656-6},
  lccn = {HA32 .F54 2018},
  keywords = {Social sciences,SPSS for Windows,Statistical methods Computer programs,Statistics as Topic},
  annotation = {OCLC: on1004266568}
}

@manual{fieldDiscovrInteractiveTutorials2023,
  type = {Manual},
  title = {Discovr: {{Interactive}} Tutorials and Data for "{{Discovering Statistics Using R}} and {{RStudio}}"},
  author = {Field, Andy},
  year = {2023}
}

@misc{FinalNailCoffin,
  title = {A {{Final Nail}} in the {{Coffin}} for {{Turnitin}}? {\textbar} {{Inside Higher Ed}}},
  shorttitle = {A {{Final Nail}} in the {{Coffin}} for {{Turnitin}}?},
  urldate = {2020-01-18},
  abstract = {I didn't think it could get more absurd.},
  howpublished = {https://www.insidehighered.com/blogs/just-visiting/final-nail-coffin-turnitin},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/YQ8DGSDS/final-nail-coffin-turnitin.html}
}

@book{finchEducationalPsychologicalMeasurement2019,
  title = {Educational and Psychological Measurement},
  author = {Finch, W. Holmes and French, Brian F.},
  year = {2019},
  publisher = {Routledge},
  address = {New York, NY},
  abstract = {"This new text provides the most current coverage of measurement and psychometrics in a single volume. Authors W. Holmes Finch and Brian F. French first review the basics of psychometrics and measurement, before moving on to more complex topics such as equating and scaling, item response theory, standard setting, and computer adaptive testing. Also included are discussions of cutting-edge topics utilized by practitioners in the field, such as automated test development, game based assessment, and automated test scoring. This book is ideal for use as a primary text for graduate-level psychometrics/measurement courses, as well as for researchers in need of a broad resource for understanding test theory"--},
  isbn = {978-1-138-96343-6 978-1-138-96344-3},
  lccn = {BF39 .F49 2019},
  keywords = {Educational psychology,Educational tests and measurements,Psychometrics},
  file = {/Users/colin.madland/Zotero/storage/GGC3BXSZ/finchEducationalPsychologicalMeasurement2019.pdf}
}

@incollection{finchExploratoryFactorAnalysis2013,
  title = {Exploratory {{Factor Analysis}}},
  booktitle = {Handbook of {{Quantitative Methods}} for {{Educational Research}}},
  author = {Finch, W. Holmes},
  editor = {Teo, Timothy},
  year = {2013},
  pages = {167--186},
  publisher = {SensePublishers},
  address = {Rotterdam},
  doi = {10.1007/978-94-6209-404-8_8},
  urldate = {2024-06-22},
  isbn = {978-94-6209-404-8},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/P3XWUHIH/finchExploratoryFactorAnalysis2013.pdf}
}

@book{finchExploratoryFactorAnalysis2020,
  title = {Exploratory {{Factor Analysis}}},
  author = {Finch, W. Holmes},
  year = {2020},
  series = {Quantitative {{Applications}} in the {{Social Sciences}}},
  publisher = {SAGE Publications, Inc.},
  urldate = {2024-02-22},
  abstract = {A firm knowledge of factor analysis is key to understanding much published research in the social and behavioral sciences. Exploratory Factor Analysis by W. Holmes Finch provides a solid foundation in exploratory factor analysis (EFA), which along with confirmatory factor analysis, represents one of the two major strands in this field. The book lays out the mathematical foundations of EFA; explores the range of methods for extracting the initial factor structure; explains factor rotation; and outlines the methods for determining the number of factors to retain in EFA. The concluding chapter addresses a number of other key issues in EFA, such as determining the appropriate sample size for a given research problem, and the handling of missing data. It also offers brief introductions to exploratory structural equation modeling, and multilevel models for EFA. Example computer code, and the annotated output for all of the examples included in the text are available on an accompanying website.},
  isbn = {978-1-5443-3988-7 978-1-5443-3990-0},
  file = {/Users/colin.madland/Zotero/storage/RXZCZR4E/finchExploratoryFactorAnalysis2020.pdf}
}

@book{finkCreatingSignificantLearning2003,
  title = {Creating {{Significant Learning Experiences}}},
  shorttitle = {Creating {{Significant Learning Experiences}}},
  author = {Fink, L. Dee},
  year = {2003},
  publisher = {Josse-Bass},
  address = {San Francisco},
  isbn = {0-7879-6055-1},
  lccn = {LB 2331.F495 2003}
}

@article{finkInnovativeWaysAssessing2013,
  title = {Innovative {{Ways}} of {{Assessing Faculty Development}}},
  author = {Fink, L. Dee},
  year = {2013},
  journal = {New Directions for Teaching and Learning},
  volume = {2013},
  number = {133},
  pages = {47--59}
}

@misc{FirstNationsData,
  title = {The {{First Nations Data Centre}} {\textbar} {{FNIGC}}},
  urldate = {2019-02-28},
  howpublished = {https://fnigc.ca/fndc},
  file = {/Users/colin.madland/Zotero/storage/BZH7PWVL/fndc.html}
}

@techreport{firstnationseducationsteeringcommitteeFirstPeoplesPrinciples2008,
  title = {First {{Peoples Principles}} of {{Learning}}},
  author = {First Nations Education Steering Committee},
  year = {2008},
  institution = {First Nations Education Steering Committee}
}

@misc{FirstNationsPedagogy,
  title = {First {{Nations Pedagogy Online}}},
  urldate = {2018-11-22},
  howpublished = {https://firstnationspedagogy.ca/index.html},
  file = {/Users/colin.madland/Zotero/storage/KYXSLC3V/index.html}
}

@article{fischerHowDoesAssessment2023,
  title = {How Does Assessment Drive Learning? {{A}} Focus on Students' Development of Evaluative Judgement},
  shorttitle = {How Does Assessment Drive Learning?},
  author = {Fischer, Juan and Bearman, Margaret and Boud, David and Tai, Joanna},
  year = {2023},
  month = may,
  journal = {Assessment \& Evaluation in Higher Education},
  pages = {1--13},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2023.2206986},
  urldate = {2023-05-07},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/UFQMAS42/fischerHowDoesAssessment2023.pdf}
}

@article{fischerMultiinstitutionalStudyImpact2015,
  title = {A Multi-Institutional Study of the Impact of Open Textbook Adoption on the Learning Outcomes of Post-Secondary Students},
  author = {Fischer, Lane and Hilton, John and Robinson, T. Jared and Wiley, DavidA},
  year = {2015},
  journal = {J Comput High Educ},
  pages = {1--14},
  issn = {1042-1726},
  doi = {10.1007/s12528-015-9101-x},
  keywords = {Improving classroom teaching,Media in education,OER,Open educational resources,Pedagogical issues,Post-secondary education}
}

@article{fischerRatingQualityOpen2017,
  title = {Rating the {{Quality}} of {{Open Textbooks}}: {{How Reviewer}} and {{Text Characteristics Predict Ratings}}},
  shorttitle = {Rating the {{Quality}} of {{Open Textbooks}}},
  author = {Fischer, Lane and Ernst, David and Mason, Stacie L.},
  year = {2017},
  month = jun,
  journal = {The International Review of Research in Open and Distributed Learning},
  volume = {18},
  number = {4},
  issn = {1492-3831},
  urldate = {2018-07-07},
  copyright = {Copyright (c) 2017 Lane Fischer, David Ernst, Stacie L Mason},
  langid = {english},
  keywords = {open educational resources (OER),open textbooks},
  file = {/Users/colin.madland/Zotero/storage/GFEWGDJX/fischerRatingQualityOpen2017.pdf;/Users/colin.madland/Zotero/storage/BYP6SRRY/4217.html}
}

@article{fitriyahOnlineAssessmentEffect2021,
  title = {Online {{Assessment Effect}} in {{EFL Classroom}}: {{An Investigation}} on {{Students}} and {{Teachers}}' {{Perceptions}}},
  author = {Fitriyah, Ima and Jannah, Miftahul},
  year = {2021},
  journal = {Indonesian Journal of English Language Teaching and Applied Linguistics},
  volume = {5},
  number = {2},
  pages = {265--284},
  issn = {ISSN-2527-6492},
  abstract = {The teaching and learning process changed into an online during the COVID19 outbreak, and thus online evaluation became a requirement. This research examines the positive and negative effects of online assessment on students' learning behaviour and how teachers prepare their teaching. This case study research included the result of questionnaire from thirty IC students followed by interview with three EFL teachers in the Intensive English Course (IC) program and six IC program students in one of Islamic University in Kediri. The small survey indicated that students have positive attitude toward the administration of online assessment. Furthermore, the outcomes of open-ended interviews showed that there were four themes for beneficial effects, including enhancing flexibility in assessment, improving evaluation versatility, building teachers and students' awareness of preparing evaluation and cultivating students' autonomous learning abilities. On the other hand, three themes for negative effects emerged from the online assessment, including complication of evaluation administration, reduced interaction between teachers and students, and anxiety in English test. The effects emerge from how teachers and students view the drawbacks of the online assessment itself. Positive effects lead to students' learning better are caused by lesson taken from conducting the test; however, the negatives should be treated as challenges that will improve the teaching and learning. Finally, both teachers and students are ready to face online assessment in the future.},
  langid = {english},
  keywords = {Barriers,College Students,Computer Assisted Testing,COVID-19,Distance Education,Educational Benefits,English (Second Language),Evaluation Methods,Foreign Countries,Independent Study,Intensive Language Courses,Islam,Language Teachers,Learning Processes,No DOI found,Online Courses,Pandemics,Second Language Instruction,Second Language Learning,Student Attitudes,Student Evaluation,Teacher Attitudes,Teacher Student Relationship,Teaching Methods,Test Preparation,Testing Problems}
}

@article{fitriyahOnlineAssessmentEffect2021a,
  title = {Online {{Assessment Effect}} in {{EFL Classroom}}: {{An Investigation}} on {{Students}} and {{Teachers}}' {{Perceptions}}},
  author = {Fitriyah, Ima and Jannah, Miftahul},
  year = {2021},
  month = jan,
  journal = {Indonesian Journal of English Language Teaching and Applied Linguistics},
  volume = {5},
  number = {2},
  pages = {265--284},
  publisher = {{Indonesian Journal of English Language Teaching and Applied Linguistics}},
  issn = {2527-6492},
  doi = {10.21093/ijeltal.v5i2.709},
  abstract = {The teaching and learning process changed into an online during the COVID19 outbreak, and thus online evaluation became a requirement. This research examines the positive and negative effects of online assessment on students' learning behaviour and how teachers prepare their teaching. This case study research included the result of questionnaire from thirty IC students followed by interview with three EFL teachers in the Intensive English Course (IC) program and six IC program students in one of Islamic University in Kediri. The small survey indicated that students have positive attitude toward the administration of online assessment. Furthermore, the outcomes of open-ended interviews showed that there were four themes for beneficial effects, including enhancing flexibility in assessment, improving evaluation versatility, building teachers and students' awareness of preparing evaluation and cultivating students' autonomous learning abilities. On the other hand, three themes for negative effects emerged from the online assessment, including complication of evaluation administration, reduced interaction between teachers and students, and anxiety in English test. The effects emerge from how teachers and students view the drawbacks of the online assessment itself. Positive effects lead to students' learning better are caused by lesson taken from conducting the test; however, the negatives should be treated as challenges that will improve the teaching and learning. Finally, both teachers and students are ready to face online assessment in the future.},
  keywords = {Barriers,College Students,Computer Assisted Testing,COVID-19,Distance Education,Educational Benefits,English (Second Language),Evaluation Methods,Foreign Countries,Independent Study,Indonesia,Intensive Language Courses,Islam,Language Teachers,Learning Processes,Online Courses,Pandemics,Second Language Instruction,Second Language Learning,Student Attitudes,Student Evaluation,Teacher Attitudes,Teacher Student Relationship,Teaching Methods,Test Preparation,Testing Problems},
  file = {/Users/colin.madland/Zotero/storage/PRSIB5FR/fitriyahOnlineAssessmentEffect2021a.pdf}
}

@book{FiveEffectiveOnline2010,
  title = {The {{Five P}}'s of {{Effective Online Instruction}}},
  year = {2010},
  volume = {2010}
}

@article{fivesNavigatingComplexCognitive2020,
  title = {Navigating the Complex Cognitive Task of Classroom Assessment},
  author = {Fives, Helenrose and Barnes, Nicole},
  year = {2020},
  journal = {Teaching and Teacher Education},
  volume = {92},
  pages = {103063},
  issn = {0742051X},
  doi = {10/gmbws5},
  urldate = {2021-07-27},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/2WBLZSMQ/fivesNavigatingComplexCognitive2020.pdf}
}

@article{fjortoftMultimodalDigitalClassroom2020,
  title = {Multimodal Digital Classroom Assessments},
  author = {Fjortoft, Henning},
  year = {2020},
  journal = {Computers and education},
  volume = {152},
  pages = {103892},
  publisher = {Elsevier Ltd},
  address = {OXFORD},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2020.103892},
  abstract = {Despite the widespread adoption of multimodal and digital modes of representation outside school settings, classroom assessment practices rely more on conventional print media and less on digital technologies. Stronger connections between the use of ICT in schools, contextual factors, and theoretical approaches are needed if teachers are to use digital tools effectively in the classroom. This study explores multimodal digital classroom assessments (MDCAs) as a subset of classroom assessments. Combining multimodal perspectives with performance assessment theory, the paper analyzes three examples of MDCAs developed in collaboration with practitioners as part of a formative experiment and discusses their affordances and potential relevance for practice. MDCAs may offer richer repertoires of modalities for students and teachers. However, implementing MDCAs requires continuous attention to validity, literacy demands, and management of the longitudinal nature of certain MDCAs. Therefore, to provide a meaningful picture of student learning, design processes should consider how evidence from MDCAs complements conventional assessment practices. {$\bullet$}This study explores multimodal digital classroom assessments (MDCAs).{$\bullet$}The paper analyzes three examples of MDCA practices designed by teachers.{$\bullet$}MDCAs may offer richer repertoires of modalities available for students and teachers.{$\bullet$}Implementing MDCAs requires attention to validity, literacy demands, and the longitudinal nature of certain MDCAs.},
  keywords = {Classroom assessment,Computer Science,Computer Science Interdisciplinary Applications,Education & Educational Research,Formative experiment,Literacy,Multimodality,Science & Technology,Social Sciences,Technology,Validity},
  file = {/Users/colin.madland/Zotero/storage/GMFAYB98/fjortoftMultimodalDigitalClassroom2020.pdf}
}

@article{fleischmannStudioPracticeOnline2019,
  title = {From {{Studio Practice}} to {{Online Design Education}}: {{Can We Teach Design Online}}?},
  author = {Fleischmann, Katja},
  year = {2019},
  journal = {Canadian Journal of Learning and Technology},
  volume = {45},
  number = {1},
  issn = {ISSN-1499-6677},
  doi = {10/gj2tsb},
  abstract = {Digital technology is reshaping the way higher education subjects are taught, including design. Various design disciplines use studio teaching as a pedagogy to educate students for professions in art and design. Studio teaching bases a high premium on face-to-face interactions which guide learning through dialogue and feedback on individual work. Many design educators believe it is difficult or even impossible to teach design online because of studio-based interactions. Is design one of those disciplines that cannot be taught online because of the studio culture? This study explores that question by investigating the effectiveness of teaching design subjects that employ a virtual classroom to manage peer-to-peer critiques, instructor feedback, and assignments. Twenty-eight first-year students participated in two online design subjects that required them to interact with fellow students and the design instructor via a Learning Management System. The experienced benefits and challenges of students and instructors are presented, and future research is highlighted.},
  langid = {english},
  keywords = {Assignments,Barriers,College Faculty,College Students,Computer Simulation,Course Descriptions,Design,Dialogs (Language),Educational Benefits,Feedback (Response),Foreign Countries,Instructional Effectiveness,Learning Activities,Management Systems,Online Courses,Peer Evaluation,Sense of Community,Studio Art,Teacher Attitudes,Teacher Student Relationship,Teaching Methods,Technological Literacy}
}

@article{fletcherFacultyStudentsConceptions2012,
  title = {Faculty and {{Students Conceptions}} of {{Assessment}} in {{Higher Education}}},
  author = {Fletcher, Richard B. and Meyer, Luanna H. and Anderson, Helen and Johnston, Patricia and Rees, Malcolm},
  year = {2012},
  month = jul,
  journal = {Higher Education},
  volume = {64},
  number = {1},
  pages = {119--133},
  issn = {0018-1560, 1573-174X},
  doi = {10/ctccpq},
  urldate = {2021-04-25},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/THKER7MT/fletcherFacultyStudentsConceptions2012.pdf}
}

@article{flickerImpactIndigenousYouth2019,
  title = {The {{Impact}} of {{Indigenous Youth Sharing Digital Stories About HIV Activism}}},
  author = {Flicker, Sarah and Wilson, Ciann and Monchalin, Ren{\'e}e and Restoule, Jean-Paul and Mitchell, Claudia and Larkin, June and Prentice, Tracey and Jackson, Randy and Oliver, Vanessa},
  year = {2019},
  journal = {Health Promotion Practice},
  issn = {1524-8399},
  doi = {10.1177/1524839918822268},
  urldate = {2019-03-13},
  abstract = {Introduction. This article reports on the micro-, meso-, and macro-level impacts of sharing digital stories created by Indigenous youth leaders about HIV prevention activism in Canada. Method. Eighteen participants created digital stories and hosted screenings in their own communities to foster dialogue. Data for this article are drawn from individual semistructured interviews with the youth leaders, audio-recordings of audience reflections, and research team member?s field notes collected between 2012 and 2015 across Canada. Data were coded using NVivo. A content analysis approach guided analysis. Results. The process of sharing their digital stories had a positive impact on the youth themselves and their communities. Stories also reached policymakers. They challenged conventional public health messaging by situating HIV in the context of Indigenous holistic conceptions of health. Discussion. The impact(s) of sharing digital stories were felt most strongly by their creators but rippled out to create waves of change for many touched by them. More research is warranted to examine the ways that the products of participatory visual methodologies can be powerful tools in creating social change and reducing health disparities.}
}

@article{floresPerceptionsEffectivenessFairness2015,
  title = {Perceptions of Effectiveness, Fairness and Feedback of Assessment Methods: A Study in Higher Education},
  shorttitle = {Perceptions of Effectiveness, Fairness and Feedback of Assessment Methods},
  author = {Flores, Maria Assun{\c c}{\~a}o and Veiga Sim{\~a}o, Ana Margarida and Barros, Alexandra and Pereira, Diana},
  year = {2015},
  month = oct,
  journal = {Studies in Higher Education},
  volume = {40},
  number = {9},
  pages = {1523--1534},
  issn = {0307-5079, 1470-174X},
  doi = {10/gfz39k},
  urldate = {2021-07-05},
  abstract = {This paper draws upon a broader piece of research aimed at investigating assessment in higher education. It focuses upon the perceptions of undergraduates about issues of effectiveness, fairness and feedback, particularly in regard to the so-called learner-centred methods. In total, 378 undergraduate students participated in the study at the University of Minho (254) and at the University of Lisbon (124). Data were collected through questionnaires. Findings suggest that the most frequent assessment methods are written tests, oral presentations in group and project work. Participants who are assessed by methods which require their active involvement view assessment as a fairer and more effective process than students who are assessed by more traditional methods such as examinations and written tests. However, the idea of conflict in assessment emerged as a key distinctive feature associated with learner-centred assessment methods such as project work and portfolios. Implications of the findings for developing learner-centred methods in higher education are discussed.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/PBDUUC72/floresPerceptionsEffectivenessFairness2015.pdf}
}

@article{floresPortugueseUniversityStudents2020,
  title = {Portuguese University Students' Conceptions of Assessment: Taking Responsibility for Achievement},
  shorttitle = {Portuguese University Students' Conceptions of Assessment},
  author = {Flores, Maria Assun{\c c}{\~a}o and Brown, Gavin and Pereira, Diana and Coutinho, Clara and Santos, Patr{\'i}cia and Pinheiro, Cl{\'a}udia},
  year = {2020},
  month = mar,
  journal = {Higher Education},
  volume = {79},
  number = {3},
  pages = {377--394},
  issn = {0018-1560, 1573-174X},
  doi = {10/gk4j65},
  urldate = {2021-07-05},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/XR2ZHI5P/floresPortugueseUniversityStudents2020.pdf}
}

@article{floresPortugueseUniversityStudents2020a,
  title = {Portuguese {{University Students}}' {{Conceptions}} of {{Assessment}}: {{Taking Responsibility}} for {{Achievement}}},
  author = {Flores, Maria Assun{\c c}{\~a}o and Brown, Gavin and Pereira, Diana and Coutinho, Clara and Santos, Patr{\'i}cia and Pinheiro, Cl{\'a}udia},
  year = {2020},
  month = mar,
  journal = {Higher Education: The International Journal of Higher Education Research},
  volume = {79},
  number = {3},
  pages = {377--394},
  publisher = {Higher Education: The International Journal of Higher Education Research},
  issn = {0018-1560},
  doi = {10.1007/s10734-019-00415-2},
  abstract = {After 20~years of the Bologna Declaration, Portuguese universities claim to be implementing student-centred and involved assessment practices. Student conceptions of assessment matter when innovations and reforms in assessment practices are being implemented. This study is part of a larger research project entitled "Assessment in higher education: the potential of alternative methods" funded by the Portuguese Foundation for Science and Technology (Government Funding Agency) (PTDC/MHCCED/2703/2014). This paper surveys a large sample (N = 5549) of Portuguese students in five public universities with a Portuguese version of the Students Conceptions of Assessment (SCoA-VI) inventory, previously validated in Brazil. Confirmatory factor analysis recovered the eight SCoA factors reported in the Brazilian context. Differences in mean score for the eight factors were trivial for institutional and student factors. Overall, students agreed that assessment for student improvement was not ignored. Scale inter-correlations revealed interesting inverse relations between improvement and irrelevance functions.},
  keywords = {College Students,Foreign Countries,Portugal,Scores,Student Attitudes,Student Evaluation,Student Improvement}
}

@misc{fnigcFirstNationsPrinciples2019,
  title = {The {{First Nations Principles}} of {{OCAP}}},
  author = {FNIGC},
  year = {2019},
  journal = {First Nations Information Governance Centre},
  urldate = {2019-04-06},
  howpublished = {http://fnigc.ca/ocapr.html},
  file = {/Users/colin.madland/Zotero/storage/2VK7H5F6/ocapr.html}
}

@book{fnigcOwnershipControlAccess2014,
  title = {Ownership, {{Control}}, {{Access}} and {{Possession}} ({{OCAP}}): {{The Path}} to {{First Nations Information Governance}}},
  shorttitle = {Ownership, {{Control}}, {{Access}} and {{Possession}} ({{OCAP}})},
  author = {FNIGC},
  year = {2014},
  urldate = {2019-04-06},
  isbn = {978-0-9879882-8-7},
  langid = {english},
  annotation = {OCLC: 1027689792}
}

@article{foltynekAcademicPlagiarismDetection2020,
  title = {Academic {{Plagiarism Detection}}: {{A Systematic Literature Review}}},
  shorttitle = {Academic {{Plagiarism Detection}}},
  author = {Folt{\'y}nek, Tom{\'a}{\v s} and Meuschke, Norman and Gipp, Bela},
  year = {2020},
  month = nov,
  journal = {ACM Computing Surveys},
  volume = {52},
  number = {6},
  pages = {1--42},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3345317},
  urldate = {2023-01-30},
  abstract = {This article summarizes the research on computational methods to detect academic plagiarism by systematically reviewing 239 research papers published between 2013 and 2018. To structure the presentation of the research contributions, we propose novel technically oriented typologies for plagiarism prevention and detection efforts, the forms of academic plagiarism, and computational plagiarism detection methods. We show that academic plagiarism detection is a highly active research field. Over the period we review, the field has seen major advances regarding the automated detection of strongly obfuscated and thus hard-to-identify forms of academic plagiarism. These improvements mainly originate from better semantic text analysis methods, the investigation of non-textual content features, and the application of machine learning. We identify a research gap in the lack of methodologically thorough performance evaluations of plagiarism detection systems. Concluding from our analysis, we see the integration of heterogeneous analysis methods for textual and non-textual content features using machine learning as the most promising area for future research contributions to improve the detection of academic plagiarism further.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/6AF76PKJ/foltynekAcademicPlagiarismDetection2020.pdf}
}

@article{foltynekTestingSupportTools2020,
  title = {Testing of Support Tools for Plagiarism Detection},
  author = {Folt{\'y}nek, Tom{\'a}{\v s} and Dlabolov{\'a}, Dita and {Anohina-Naumeca}, Alla and Raz{\i}, Salim and Kravjar, J{\'u}lius and Kamzola, Laima and {Guerrero-Dib}, Jean and {\c C}elik, {\"O}zg{\"u}r and {Weber-Wulff}, Debora},
  year = {2020},
  month = dec,
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {17},
  number = {1},
  issn = {2365-9440},
  doi = {10.1186/s41239-020-00192-4},
  urldate = {2020-12-11},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/DSPZXWD8/foltynekTestingSupportTools2020a.pdf}
}

@misc{fongAreWeAutomating2021,
  title = {Are We Automating Racism?},
  author = {Fong, Joss},
  year = {2021},
  month = mar,
  journal = {Vox},
  urldate = {2022-10-17},
  abstract = {Algorithms don't fail everyone equally.},
  howpublished = {https://www.vox.com/videos/2021/3/31/22348722/ai-bias-racial-machine-learning},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/Y7UIWSWT/ai-bias-racial-machine-learning.html}
}

@article{forde-leavesFrameworkUnderstandingAssessment2023,
  ids = {forde-leavesFrameworkUnderstandingAssessment2023a},
  title = {A Framework for Understanding Assessment Practice in Higher Education},
  author = {{Forde-Leaves}, Natalie and Walton, Jack and Tann, Ken},
  year = {2023},
  month = feb,
  journal = {Assessment \& Evaluation in Higher Education},
  pages = {1--16},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2023.2169659},
  urldate = {2023-03-20},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/2LBEQYDH/forde-leavesFrameworkUnderstandingAssessment2023.pdf}
}

@article{forkanVideoDLVideoBasedDigital2023,
  title = {{{VideoDL}}: {{Video-Based Digital Learning Framework Using AI Question Generation}} and {{Answer Assessment}}},
  author = {Forkan, Abdur Rahim Mohammad and Kang, Yong-Bin and Jayaraman, Prem Prakash and Du, Hung and Thomson, Steven and Kollias, Elizabeth and Wieland, Natalie},
  year = {2023},
  journal = {International journal of advanced corporate learning},
  volume = {16},
  number = {1},
  pages = {19--27},
  publisher = {International Association of Online Engineering (IAOE)},
  address = {Vienna},
  issn = {1867-5565},
  doi = {10.3991/ijac.v16i1.35207},
  abstract = {Assessing learners' understanding and competency in video-based digital learning is time-consuming and very difficult for educators, as it requires the generation of accurate and valid questions from pre-recorded learning videos. This paper demonstrates VideoDL, a video-based learning framework powered by Artificial Intelligence (AI) that supports automatic question generation and answer assessment from videos. VideoDL comprises of various AI algorithms, and an interactive web-based user interface (UI) developed using the principles of human-centred design. Our empirical evaluation using real-world videos from multiple domains demonstrates the effectiveness of VideoDL.},
  keywords = {Algorithms,Artificial intelligence,Design,Distance learning,Education,Keywords,Teachers,Teaching},
  file = {/Users/colin.madland/Zotero/storage/JL6ZTHST/forkanVideoDLVideoBasedDigital2023.pdf}
}

@article{forkosh-baruchReconsideringTeachersPedagogical2021,
  title = {Reconsidering {{Teachers}}' {{Pedagogical Reasoning}} and {{Decision Making}} for {{Technology Integration}} as an {{Agenda}} for {{Policy}}, {{Practice}} and {{Research}}},
  author = {{Forkosh-Baruch}, Alona and Phillips, Michael and Smits, Anneke},
  year = {2021},
  month = aug,
  journal = {Educational Technology Research and Development},
  volume = {69},
  number = {4},
  pages = {2209--2224},
  publisher = {{Educational Technology Research and Development}},
  issn = {1042-1629},
  doi = {10.1007/s11423-021-09966-7},
  abstract = {This article focuses on preservice and in-service teachers' pedagogical reasoning, decision making and action concerning technology integration for learning. We examine this topic in light of three contemporary barriers in policy, practice and research, namely: the lack of an integrative model that considers how teachers come to shape their reasoning and decisions on technology integration, the lack of practical-authentic experience for preservice teachers for technological pedagogical reasoning and decision-making, and the influence of software that automates classroom decisions and may reshape teacher reasoning. We offer three resulting opportunities: the introduction of an integrated epistemic and developmental model that explains how teachers' pedagogical reasoning and action (PR\&A) for technology integration are shaped, teaching approximations of core practices for technology integration, and promoting PR\&A and decision-making for simple adaptive Digital Formative Assessment Tools as an overall agenda to enhance policy, practice and research relating to teachers pedagogical reasoning, decision making and action in technology rich contexts. We conclude in proposing implications for policy, practice and research.},
  keywords = {Automation,Barriers,Decision Making,Educational Policy,Educational Practices,Educational Research,Formative Evaluation,Models,Preservice Teachers,Teaching Experience,Technology Integration,Thinking Skills}
}

@misc{ForProfitCompanyTrying2021,
  title = {'{{A For-Profit Company Is Trying}} to {{Privatize}} as {{Many Public Libraries}} as {{They Can}}'},
  year = {2021},
  month = dec,
  journal = {FAIR},
  urldate = {2022-01-06},
  abstract = {"There's just a lot of potential for the information loop to be a closed loop that's controlled by one company."},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/PX4B5CGQ/2021 - 'A For-Profit Company Is Trying to Privatize as Ma.html}
}

@article{forsterHowFeedbackProvided2018,
  title = {How Feedback Provided by Voluntary Electronic Quizzes Affects Learning Outcomes of University Students in Large Classes},
  author = {Forster, M and Weiser, C and Maur, A},
  year = {2018},
  journal = {Computers \& Education},
  volume = {121},
  pages = {100--114},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2018.02.012},
  abstract = {In view of the increasing number of university students attending large statistics classes as a requirement for their degree courses, the use of an online learning environment is indispensable for delivering immediate and frequent feedback. However, results of research on the value of technological tools and blended courses in various academic disciplines are not consistent and only point to minimal effects on academic achievement. To fill this gap, in this study, participation in optional electronic quizzes and its effects on exam grades in large statistics classes depending on gender and previous statistics- and mathematics-related abilities are investigated. Overall, participation in the electronic quizzes yielded a positive effect on final grades. However, particularly the groups who participated less in the electronic quizzes - i.e. poor performing students and males - benefitted more from quiz participation than high performing and female students. The large variability in effect sizes of feedback on performance suggests that additional moderators such as specific situation- and task-related characteristics and individual affective preconditions such as effort, motivation, and self-esteem should be analyzed in future research.},
  langid = {english},
  keywords = {ABILITY,Applications in subject areas,Business and economics statistics,COGNITIVE LOAD,Computer-mediated communication,Feedback,FORMATIVE ASSESSMENT,Gender studies,GENDER-DIFFERENCES,MATH,MOTIVATION,PERFORMANCE,Post-secondary education,STATISTICS,STEREOTYPE,Teaching/leaming strategies}
}

@techreport{ForumImpactOpen2002,
  title = {Forum on the {{Impact}} of {{Open Courseware}} for {{Higher Education}} in {{Developing Countries}}: {{Final Report}}},
  year = {2002},
  address = {Paris},
  institution = {UNESCO},
  urldate = {2018-12-01}
}

@book{fostatyyoungAssessmentLearningICE2000,
  title = {Assessment and Learning: The {{ICE}} Approach},
  shorttitle = {Assessment and Learning},
  author = {Fostaty Young, C. Susan and Wilson, Robert J},
  year = {2000},
  publisher = {Peguis},
  address = {Winnipeg},
  abstract = {Shows how to maximize learning potential through an improved understanding and appreciation of the learning process. ICE represents the three stages of learning: Ideas; Connections; and Extensions.},
  isbn = {978-1-894110-64-8},
  langid = {english},
  annotation = {OCLC: 44795816}
}

@book{frankolaWhyOnlineLearners2001,
  title = {Why {{Online Learners Drop Out}}},
  author = {Frankola, Karen},
  year = {2001},
  volume = {2010}
}

@article{frankTechnologymediatedPersonalizedLearning2020,
  title = {Against Technology-Mediated Personalized Learning: Resources from {{John William Miller}} and {{Henry Bugbee}} to Support Parental Resistance},
  author = {Frank, Jeff},
  year = {2020},
  journal = {Ethics and education},
  volume = {15},
  number = {1},
  pages = {98--112},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {1744-9642},
  doi = {10.1080/17449642.2019.1700445},
  abstract = {This paper aims to provide parents and others resources to resist technology-mediated personalized learning. To develop these resources and make the case against technology-mediated {\^A}~personalized learning, I turn to the work of American philosophers Henry Bugbee and John William Miller.},
  keywords = {Criticism,Education & Educational Research,Educational Change,Educational Philosophy,Elementary Secondary Education,Ethics,Henry Bugbee,Individualized Instruction,John William Miller,Lifelong learning,Parent Attitudes,personalized learning,philosophy of education,Social Sciences,Teaching Methods,technology and education,Technology Uses in Education},
  file = {/Users/colin.madland/Zotero/storage/YJBWMK5T/frankTechnologymediatedPersonalizedLearning2020.pdf}
}

@book{frantzSpeakSpell2014,
  title = {The {{Speak N Spell}}},
  author = {Frantz, Gene},
  year = {2014},
  publisher = {OpenStax CNX},
  file = {/Users/colin.madland/Zotero/storage/GPFIDEA5/frantzSpeakSpell2014.pdf}
}

@article{fredericksenNationalStudyOnline2017,
  title = {A {{National Study}} of {{Online Learning Leaders}} in {{US Higher Education}}},
  author = {Fredericksen, Eric E.},
  year = {2017},
  journal = {Online Learning},
  volume = {21},
  number = {2},
  issn = {ISSN-2472-5749},
  doi = {10/gmbv2q},
  abstract = {Online learning in US higher education continues to grow dramatically. The most recent estimates indicate that about 30\% of all students enroll in at least one online course (Allen \& Seamen, 2016). As this important type of academic offering has become increasingly important to institutions of higher education, Presidents and Provosts have frequently established leadership positions to coordinate and direct their efforts in this area. But what do we know about the leaders who have been charged with managing this academic transformation? This systematic national study, a first of its kind, sheds light on the leadership that is guiding this new teaching and learning environment.},
  langid = {english},
  keywords = {Administrative Organization,Administrator Characteristics,Administrator Surveys,Educational Change,Electronic Learning,Higher Education,Leadership,Transformational Leadership}
}

@book{freemanDistantRelationsHow2000,
  title = {Distant Relations: How My Ancestors Colonized {{North America}}},
  shorttitle = {Distant Relations},
  author = {Freeman, Victoria},
  year = {2000},
  publisher = {M \& S},
  address = {Toronto},
  abstract = {John Wheeler (1591-1670), son of Dominick Wheeler and Mercy Jelly, married Agnes Yeoman. They emigrated from England to Massachusetts in 1634. Descendants and relatives lived mainly in Massachusetts, Ontario and Maintoba.},
  isbn = {978-0-7710-3192-2 978-0-7710-3201-1},
  langid = {english},
  annotation = {OCLC: 50665453}
}

@book{freirePedagogyOppressed1990,
  title = {Pedagogy of the Oppressed},
  author = {Freire, Paulo},
  year = {1990},
  publisher = {Penguin},
  address = {Harmondworth},
  isbn = {978-0-14-013553-4},
  langid = {english},
  annotation = {OCLC: 865022627}
}

@book{freirePedagogyOppressed50th2018,
  title = {Pedagogy of the {{Oppressed}}: 50th {{Anniversary Edition}}},
  author = {Freire, Paulo},
  year = {2018},
  publisher = {Bloomsbury Academic},
  address = {New York}
}

@article{frenchReviewBenefitsDrawbacks2023,
  title = {A Review of the Benefits and Drawbacks of High-Stakes Final Examinations in Higher Education},
  author = {French, Sarah and Dickerson, Ashton and Mulder, Raoul A.},
  year = {2023},
  month = dec,
  journal = {Higher Education},
  issn = {1573-174X},
  doi = {10.1007/s10734-023-01148-z},
  abstract = {High-stakes examinations enjoy widespread use as summative assessments in higher education. We review the arguments for and against their use, across seven common themes: memory recall and knowledge retention; student motivation and learning; authenticity and real-world relevance; validity and reliability; academic misconduct and contract cheating; stress, anxiety and wellbeing; and fairness and equity. For each theme, we evaluate empirical evidence for the perceived pedagogical benefits and pedagogical drawbacks of high-stakes examinations. We find that relatively few of the perceived academic benefits of high-stakes examinations have a strong evidence base. Support for their use is largely rooted in opinion and pragmatism, rather than being justified by scientific evidence or pedagogical merit. By contrast, there is substantial evidence for pedagogical drawbacks of high-stakes summative examinations. We conclude that the current heavy reliance on high-stakes final examinations in many university subjects is poorly justified by the balance of empirical evidence.},
  file = {/Users/colin.madland/Zotero/storage/DYHNDW5K/frenchReviewBenefitsDrawbacks2023.pdf}
}

@misc{FrequentlyAskedQuestionsa,
  title = {Frequently {{Asked Questions About}} the {{LSAT}} {\textbar} {{The Law School Admission Council}}},
  urldate = {2022-03-12},
  howpublished = {https://www.lsac.org/lsat/frequently-asked-questions-about-lsat}
}

@article{freySAGEEncyclopediaEducational2020,
  title = {The {{SAGE Encyclopedia}} of {{Educational Research}}, {{Measurement}}, and {{Evaluation}}},
  author = {Frey, Bruce B.},
  year = {2020},
  address = {Thousand Oaks,, California},
  doi = {10/gft9f7}
}

@book{friesenPlaceClassroomSpace2011,
  title = {The {{Place}} of the {{Classroom}} and the {{Space}} of the {{Screen}}: {{Relational Pedagogy}} and {{Internet Technology}}},
  author = {Friesen, Norm},
  year = {2011},
  series = {New {{Literacies}} and {{Digital Technologies}}},
  volume = {50},
  publisher = {Peter Lang},
  address = {New York},
  abstract = {This book examines how common e-learning technologies open up compelling, if limited, experiential spaces for users, similar to the imaginary worlds opened up by works of fiction. However, these experiential worlds are markedly different from the <<real>> world of physical objects and embodied relations. This book shows these differences to be of central importance for teaching and learning.}
}

@article{frisbieReliabilityScoresTeacher1988,
  title = {Reliability of {{Scores From Teacher}}-{{Made Tests}}},
  author = {Frisbie, David A.},
  year = {1988},
  month = mar,
  journal = {Educational Measurement: Issues and Practice},
  volume = {7},
  number = {1},
  pages = {25--35},
  issn = {0731-1745, 1745-3992},
  doi = {10.1111/j.1745-3992.1988.tb00422.x},
  urldate = {2024-06-20},
  abstract = {Reliability is the property of a set of test scores that indicates the amount of measurement error associated with the scores. Teachers need to know about reliability so that they can use test scores to make appropriate decisions about their students. The level of consistency of a set of scores can he estimated by using the methods of internal analysis to compute a reliability coefficient. This coefficient, which can range between 0.0 and +1.0, usually has values around 0.50 for teacher-made tests and around 0.90 for commercially prepared standardized tests. Its magnitude can be affected by such factors as test length, test-item difficulty and discrimination, time limits, and certain characteristics of the group---extent of their testwiseness, level of student motivation, and homogeneity in the ability measured by the test.},
  langid = {english}
}

@article{frolovaDigitalizationHigherEducation2021,
  ids = {frolovaDigitalizationHigherEducation2021a},
  title = {Digitalization of {{Higher Education}}: {{Advantages}} and {{Disadvantages}} in {{Student Assessments}}},
  author = {Frolova, {\relax EV} and Rogach, {\relax OV}},
  year = {2021},
  journal = {European Journal of Contemporary Education},
  volume = {10},
  number = {3},
  pages = {616--625},
  issn = {2304-9650},
  doi = {10.13187/ejced.2021.3.616},
  abstract = {The authors analyze the assessments of Russian students in terms of digitalization of higher education, their attitude to the introduction of digital technologies in the educational process. The study was conducted in two stages. At the first stage (February-April 2020), a questionnaire survey of students of Russian universities was conducted (N = 1553). At the second stage (JanuaryFebruary 2021), two focus groups (N = 24) were conducted, which allowed us to refine the previously obtained data. The authors conclude that the attitude of students to the digitalization of education is determined by the experience of distance learning during the pandemic. According to the research, students' expectations are related to the content aspect of using digital technologies in the educational process: developing practical skills and maintaining interest in learning. However, young people are not fully focused on the consumption of educational content for the development of their competencies in the chosen field of study. The availability of educational materials, video recordings of lectures in the virtual educational space does not serve as a compensator for key dysfunctions: a decrease in the share of live communication, narrowing of communication channels, lack of motivation to learn, etc. This educational requirement determined the prospects for the transformation of the professional role of the teacher: from the "translator of knowledge" to the "moderator of the creative space".},
  langid = {english},
  keywords = {digital literacy,digital technologies,higher school,online education,pandemic,TECHNOLOGIES},
  file = {/Users/colin.madland/Zotero/storage/I2U9KWYH/frolovaDigitalizationHigherEducation2021.pdf}
}

@article{frolovaOnlineStudentEducation2021,
  title = {Online {{Student Education}} in a {{Pandemic}}: {{New Challenges}} and {{Risks}}},
  author = {Frolova, Elena V. and Rogach, Olga V. and Tyurikov, Alexander G. and Razov, Pavel V.},
  year = {2021},
  journal = {European Journal of Contemporary Education},
  volume = {10},
  number = {1},
  pages = {43--52},
  issn = {EISSN-2305-6746},
  abstract = {The epidemiological crisis made it necessary to transform the practice of higher education in the conditions of transition to remote mode. Online training has become an alternative to the face-to-face format of classes, which updates the analysis of key risks and problems of the educational process in the context of the pandemic. The leading research method was a questionnaire survey of students with online learning experience (N = 146 people). The survey was conducted in May 2020. For a deeper interpretation of a number of conclusions, the authors conducted a focus group in September 2020 (N = 12 people), which included students of 2-3 years of study at Russian universities. The authors set a goal to study the degree of adaptation of students to new learning conditions, the specifics of their perception of various aspects of learning in an online environment, problems and risks. The results of the study showed that every fourth student when switching to online mode could not successfully adapt to the new format of training. It is concluded that the key risks of online learning are associated with the lack of direct communication channels, the spread of the practice of imitating students' learning activities in the context of reducing the control function of the teacher. The lack of readiness of students to maintain the necessary level of self-organization led to a decrease in students' requirements for themselves as an active participant in the educational process, while increasing requirements for digital competencies and personal qualities of the teacher. In terms of online learning, students demonstrate the need for additional measures to maintain interest in learning: game context, network interaction in the "student-student" system, charismatic presentation of material.},
  langid = {english},
  keywords = {Access to Computers,College Students,COVID-19,Distance Education,Educational Change,Feedback (Response),Foreign Countries,No DOI found,Pandemics,Student Attitudes,Teacher Student Relationship,Web Based Instruction}
}

@article{FrontiersEducation,
  title = {Frontiers in {{Education}}}
}

@article{fuLearningDigitalPortfolios2022,
  title = {Learning with {{Digital Portfolios}}: {{Teacher Candidates Forming}} an {{Assessment Identity}}},
  author = {Fu, Hong and Hopper, Tim and Sanford, Kathy and Monk, David},
  year = {2022},
  journal = {The Canadian journal for the scholarship of teaching and learning},
  volume = {13},
  number = {1},
  pages = {1--20},
  publisher = {{Society for Teaching and Learning in Higher Education}},
  issn = {1918-2902},
  doi = {10.5206/cjsotlrcacea.2022.1.11108},
  abstract = {This study focuses on how the use of digital portfolios in teacher education can support teacher candidates to shift their understanding of assessment as they form their assessment identity. The study was in the context of a changing curriculum and assessment practices promoted in British Columbia. We draw on data from a cohort of teacher candidates in the first term of a 16-month post-degree teacher education program, where they created a digital portfolio across multiple courses as part of their final assessment to be used in an exit interview with instructors and teaching professionals from the field. Narratives of teacher candidates' experiences were collected to shed light on their changing understanding of assessment for learning practices and their emerging teacher identity as assessors promoted by the digital portfolio process. Significance of using digital portfolios to support their process of becoming teachers is focused in conclusion of the paper.},
  keywords = {assessment,digital portfolios,evaluation,identite en tant qu'enseignant ou enseignante,portfolios numeriques,teacher identity},
  file = {/Users/colin.madland/Zotero/storage/BA32B43G/fuLearningDigitalPortfolios2022.pdf}
}

@misc{FullCoverage,
  title = {Full Coverage},
  journal = {Google News},
  urldate = {2020-09-23},
  abstract = {See the latest updates, context and perspectives about this story.},
  howpublished = {https://news.google.com/stories/CAAqOQgKIjNDQklTSURvSmMzUnZjbmt0TXpZd1NoTUtFUWk5d083b2tJQU1FYno3LTRfTXlUWTRLQUFQAQ},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/ARRT4ZQD/CAAqOQgKIjNDQklTSURvSmMzUnZjbmt0TXpZd1NoTUtFUWk5d083b2tJQU1FYno3LTRfTXlUWTRLQUFQAQ.html}
}

@article{fullerEmpiricallyExploringHigher2016,
  title = {Empirically {{Exploring Higher Education Cultures}} of {{Assessment}}},
  author = {Fuller, Matthew B and Skidmore, Susan T and Bustamante, Rebecca M and Holzweiss, Peggy C},
  year = {2016},
  journal = {Review of higher education},
  volume = {39},
  number = {3},
  pages = {395--429},
  publisher = {Johns Hopkins University Press},
  address = {Baltimore},
  issn = {0162-5748},
  doi = {10.1353/rhe.2016.0022},
  abstract = {Although touted as beneficial to student learning, cultures of assessment have not been examined adequately using validated instruments. Using data collected from a stratified, random sample (N = 370) of U.S. institutional research and assessment directors, the models tested in this study provide empirical support for the value of using the Administrators' Survey of Assessment Cultures as an assessment tool. The resulting first order model provided good fit statistics and included five factors: a) Faculty Perceptions, b) Use of Data, c) Sharing, d) Compliance or Fear Motivators, and e) Normative Purposes for Assessment. Internal consistency estimates were also good (Cronbach's a = 0.792 to 0.922). Use of the Schmid-Leiman solution afforded further support for the higher order factor, Culture of Assessment. Predictive discriminant analysis correctly classified the majority of the respondents (80.7\%) as belonging to a student learning or accreditation group based on the linear classification scores. Implications for assessment leadership, practice, and future research are offered.},
  keywords = {Accountability,Administrator Surveys,Administrators,Attitude Measures,Classification,Compliance,Compliance (Psychology),Corporate culture,Cultural factors,Discriminant Analysis,Education Higher,Educational evaluation,Educational leadership,Evaluation,Evaluation Methods,Fear,Goodness of Fit,Higher Education,Institutional Characteristics,Learning,Learning outcomes,Prediction,Research Needs,Researchers,School Culture,Scores,Statistical Analysis,Studies,Test Construction,United States,Universities and colleges},
  file = {/Users/colin.madland/Zotero/storage/BW26ZPY5/fullerEmpiricallyExploringHigher2016.pdf}
}

@article{fullerEmpiricalStudyCultures2013,
  title = {An {{Empirical Study}} of {{Cultures}} of {{Assessment}} in {{Higher Education}}},
  author = {Fuller, Matthew},
  year = {2013},
  journal = {NCPEA Education Leadership Review},
  volume = {14},
  number = {1},
  abstract = {Higher education campus leaders face a complex state of affairs regarding the documentation of evidence of student learning. There is no shortage of technical guidance for conducting assessment (e.g. Allen, 2006; Bresciani, 2007; Bresciani, Zelna, \& Anderson, 2004; Lui, 2011; Maki, 2010; Suskie, 2009; Walvrood \& Anderson, 2010), and a great deal of energy and resources are expended gathering, analyzing, interpreting, disseminating, and using data generated through this methodological advice. Yet, the advancement of assessment methods has outpaced explorations of assessment's philosophy and discourses of how assessment and campus cultures are changed have been slow to emerge. In essence, the art and science of assessment are divided and, as Snow (1959) cautions, ``when those two senses have grown apart, then no society is going to be able to think with wisdom'' (p. 29). As higher education places greater emphasis on empirical data from standardized learning, research regarding why assessment is conducted, how it is leveraged for change, and the ramifications of assessment's purposes must be elevated to a more meaningful level. To this end a new instrument---The Survey of Assessment Culture {\copyright} --- was developed to explore factors and strategies influencing the cultivation of cultures of assessment. The Survey supports research and dialogue into cultures of assessment and how assessment emerges as an accepted institutional way of existence. This article reviews the methodological approaches used in the study, shares basic descriptive statistics, and concludes by discussing various implications for the study of assessment cultures and for administrative practice in higher education and educational administration preparation programs.},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/Q96DSH6Z/fullerEmpiricalStudyCultures2013.pdf}
}

@article{fullerExplorationFactorsInfluencing2014,
  title = {An Exploration of Factors Influencing Institutional Cultures of Assessment},
  author = {Fuller, Matthew B. and Skidmore, Susan Troncoso},
  year = {2014},
  month = jan,
  journal = {International Journal of Educational Research},
  volume = {65},
  pages = {9--21},
  issn = {0883-0355},
  doi = {10.1016/j.ijer.2014.01.001},
  abstract = {Theorisation about institutional cultures of assessment in higher education is hindered by an inability to measure the influence of institutional factors on assessment. The authors explore the factor structure of the Survey of Assessment Culture. A three factor model with strong reliability coefficients was developed and included the following factors fundamental to institutional cultures of assessment: (a) Clear Commitment, (b) Connection to Change, and (c) Vital to Institution. Future uses of the Survey of Assessment Culture and implications for research and practice are discussed.},
  keywords = {Commitment to Assessment,Culture of assessment,Institutional culture,Leadership,Measurement},
  file = {/Users/colin.madland/Zotero/storage/YGGPDPHR/fullerExplorationFactorsInfluencing2014.pdf}
}

@article{fullerLearningPeripheralParticipation2005,
  title = {Learning as Peripheral Participation in Communities of Practice: {{A}} Reassessment of Key Concepts in Workplace Learning},
  shorttitle = {Learning as Peripheral Participation in Communities of Practice: {{A}} Reassessment of Key Concepts in Workplace Learning},
  author = {Fuller, Alison and Hodkinson, Heather and Hodkinson, Phil and Unwin, Lorna},
  year = {2005},
  month = feb,
  journal = {British Educational Research Journal},
  volume = {31},
  pages = {49--68},
  issn = {0141-1926},
  doi = {10.1080/0141192052000310029},
  urldate = {2012-02-25},
  abstract = {This article explores the strengths and weaknesses of Lave and Wenger's concept of ?legitimate peripheral participation? as a means of understanding workplace learning. It draws on recent ESRC?funded research by the authors in contemporary workplace settings in the UK (manufacturing industry and secondary schools) to establish the extent to which Lave and Wenger's theories can adequately illuminate the nature and process of learning at work. The new research presented here, which was located in complex institutional settings, highlights the diverse nature of patterns and forms of participation. Case study evidence is used to identify individual and contextual factors which underpin and illuminate the ways in which employees learn. The paper argues that whilst Lave and Wenger's work continues to provide an important source of theoretical insight and inspiration for research in to learning at work, it has significant limitations. These limitations relate to the application of their perspective to contemporary workplaces in advanced industrial societies and to the institutional environments in which people work. These complex settings play a crucial role in the configuration of opportunities and barriers to learning that employees encounter.},
  annotation = {1}
}

@article{fullerTechnologyEnhancedAssessment2022,
  title = {Technology Enhanced Assessment: {{Ottawa}} Consensus Statement and Recommendations},
  author = {Fuller, R and Goddard, {\relax VCT} and Nadarajah, {\relax VD} and {Treasure-Jones}, T and Yeates, P and Scott, K and Webb, A and Valter, K and Pyorala, E},
  year = {2022},
  month = aug,
  journal = {Medical Teacher},
  volume = {44},
  number = {8},
  pages = {836--850},
  issn = {0142-159X},
  doi = {10.1080/0142159X.2022.2083489},
  abstract = {Introduction In 2011, a consensus report was produced on technology-enhanced assessment (TEA), its good practices, and future perspectives. Since then, technological advances have enabled innovative practices and tools that have revolutionised how learners are assessed. In this updated consensus, we bring together the potential of technology and the ultimate goals of assessment on learner attainment, faculty development, and improved healthcare practices. Methods As a material for the report, we used the scholarly publications on TEA in both HPE and general higher education, feedback from 2020 Ottawa Conference workshops, and scholarly publications on assessment technology practices during the Covid-19 pandemic. Results and conclusion The group identified areas of consensus that remained to be resolved and issues that arose in the evolution of TEA. We adopted a three-stage approach (readiness to adopt technology, application of assessment technology, and evaluation/dissemination). The application stage adopted an assessment 'lifecycle' approach and targeted five key foci: (1) Advancing authenticity of assessment, (2) Engaging learners with assessment, (3) Enhancing design and scheduling, (4) Optimising assessment delivery and recording learner achievement, and (5) Tracking learner progress and faculty activity and thereby supporting longitudinal learning and continuous assessment.},
  langid = {english},
  keywords = {Assessment,CLOSED-BOOK EXAMINATIONS,COMPARING OPEN-BOOK,curriculum,EXPERIENCES,FEEDBACK,GENERATION,HIGHER-EDUCATION,medical education research,MOBILE DEVICES,REFLECTION,STUDENTS,TIME},
  file = {/Users/colin.madland/Zotero/storage/RHIVYLLC/fullerTechnologyEnhancedAssessment2022.pdf}
}

@article{fulmerMultilevelModelContextual2015,
  title = {Multi-Level Model of Contextual Factors and Teachers' Assessment Practices: An Integrative Review of Research},
  shorttitle = {Multi-Level Model of Contextual Factors and Teachers' Assessment Practices},
  author = {Fulmer, Gavin W. and Lee, Iris C.H. and Tan, Kelvin H.K.},
  year = {2015},
  month = oct,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {22},
  number = {4},
  pages = {475--494},
  issn = {0969-594X, 1465-329X},
  doi = {10.1080/0969594X.2015.1017445},
  urldate = {2022-07-24},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/RFTSWNEW/fulmerMultilevelModelContextual2015.pdf}
}

@misc{FundamentalValuesAcademic2021,
  title = {Fundamental {{Values}} of {{Academic Integrity}} (3rd {{Ed}}.)},
  year = {2021},
  publisher = {International Center for Academic Integrity},
  urldate = {2024-10-24},
  copyright = {CC BY-NC-SA 4.0},
  isbn = {978-0-9914906-7-7},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/FundamentalValuesAcademic2021.pdf}
}

@article{funesWhenInclusionExcludes2018,
  title = {When Inclusion Excludes: A Counter Narrative of Open Online Education},
  author = {Funes, Mariana and Mackness, Jenny},
  year = {2018},
  journal = {Learning, Media and Technology},
  volume = {43},
  number = {2},
  pages = {119--138},
  issn = {1743-9884},
  doi = {10.1080/17439884.2018.1444638},
  abstract = {ABSTRACTOpen education aspires to democratize education, promote inclusion and effect change through social justice. These aspirations are difficult to realize in open, online environments, which enable multiple, and often conflicting, perspectives. This paper proposes a counter-narrative that surfaces certain operational norms of the internet and foregrounds their exclusionary nature. We offer an illustrative inventory of some social media interactional patterns to examine communication used in open online education communities. This examination leads us to conclude that language online is subject to a dialectical tension that both includes and excludes. We conclude that a different language is needed in open online educational environments; one that embraces exclusionary structures and strategic ambiguity, as well as the aspirations to further democratize education via digital means.}
}

@article{funkIndigenousAuthorshipOpen2020,
  title = {Indigenous {{Authorship}} on {{Open}} and {{Digital Platforms}}: {{Social Justice Processes}} and {{Potential}}},
  shorttitle = {Indigenous {{Authorship}} on {{Open}} and {{Digital Platforms}}},
  author = {Funk, Johanna and Guthadjaka, Kathy},
  year = {2020},
  month = may,
  journal = {Journal of Interactive Media in Education},
  volume = {2020},
  number = {1},
  pages = {6},
  issn = {1365-893X},
  doi = {10/gg5v58},
  urldate = {2020-07-24},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/BRJ53KXR/funkIndigenousAuthorshipOpen2020.pdf}
}

@article{funkPostingTraditionalEcological2015,
  title = {Posting {{Traditional Ecological Knowledge}} on {{Open Access Biodiversity Platforms}}: {{Implications}} for {{Learning Design}}},
  author = {Funk, Johanna and Guthadjaka, Kathy and Kong, Gary},
  year = {2015},
  journal = {The Australian Journal of Indigenous Education},
  volume = {44},
  number = {2},
  pages = {150--162},
  issn = {1326-0111},
  doi = {10.1017/jie.2015.25},
  abstract = {BowerBird is an open platform biodiversity website () and a nationally funded project under management of the Atlas of Living Australia (ALA) and Museum Victoria. Members post sightings and information about local species of plants and animals, and record other features of ecosystems. Charles Darwin University's Northern Institute Elder on Country researcher, Kathy Guthadjaka, has shared pictures and information about the biodiversity of her homelands in the Yol{\ng}u community of G{\"a}wa, on Elcho Island in north east Arnhem Land, Northern Territory. The extent to which this knowledge can be exposed in the same way as other open resources, can pose dilemmas about the level of `openness' that is appropriate. Open sharing of educational materials can be promoted as a basic human right. This paper will explore the extent to which traditional knowledge can be made openly available. What are the implications for sharing this knowledge in a westernised context that compartmentalises it, and how can a western academic perspective learn from this knowledge and engage functionally with it for the purposes of learning? The existence of this project on the interface between traditional knowledge and western technocratic information management also has implications for how information is presented and valued.},
  keywords = {biodiversity,instructional design,open educational practice,traditional Indigenous ecological knowledge}
}

@misc{gaertnerMethodologyClosure2018,
  title = {Towards a {{Methodology}} of {{Closure}}},
  author = {{gaertner}},
  year = {2018},
  month = sep,
  journal = {Novel Alliances},
  urldate = {2018-11-05},
  abstract = {The colonial gaze is characterized not only by scopophilia, a drive to look, but also by an urge to penetrate, to traverse, to know, to translate, to own and exploit. The attitude assumes that ever{\dots}},
  langid = {english},
  keywords = {closed,indigenous,open},
  file = {/Users/colin.madland/Zotero/storage/W8GL76DY/towards-a-pedagogy-of-closure.html}
}

@article{galantiEnrichingTPACKMathematics2021,
  title = {Enriching {{TPACK}} in {{Mathematics Education}}: {{Using Digital Interactive Notebooks}} in {{Synchronous Online Learning Environments}}},
  author = {Galanti, Terrie McLaughlin and Baker, Courtney Katharine and {Morrow-Leong}, Kimberly and Kraft, Tammy},
  year = {2021},
  month = jan,
  journal = {Interactive Technology and Smart Education},
  volume = {18},
  number = {3},
  pages = {345--361},
  publisher = {{Interactive Technology and Smart Education}},
  issn = {1741-5659},
  doi = {10.1108/ITSE-08-2020-0175},
  abstract = {Purpose: In spring 2020, educators throughout the world abruptly shifted to emergency remote teaching in response to an emerging pandemic. The instructors of a graduate-level synchronous online geometry and measurement course for practicing school teachers redesigned their summative assessments. Their goals were to reduce outside-of-class work and to model the integration of content, pedagogy and technology. This paper aims to describe the development of a digital interactive notebook (dINB) assignment using online presentation software, dynamic geometry tools and mathematical learning trajectories. Broader implications for dINBs as assessments in effective distance learning are presented. Design/methodology/approach: The qualitative analysis in this study consists of a sequence of first-cycle coding of mid-semester surveys and second-cycle thematic categorizations of mid-semester surveys and end-of-course reflections. Descriptive categorization counts along with select quotations from open-ended participant responses provided a window on evolving participant experiences with the dINB across the course. Findings: Modifications to the dINB design based on teacher mid-semester feedback created a flexible assessment tool aligned with the technological pedagogical content knowledge (TPACK) framework. The teachers also constructed their own visions for adapting the dINB for student-centered instructional technology integration in their own virtual classrooms. Originality/value: The development of the dINB enriched the TPACK understandings of the instructors in this study. It also positioned teachers to facilitate innovative synchronous and blended learning in their own school communities. Further analysis of dINB artifacts in future studies will test the hypothesis that practicing teachers' experiences as learners increased their TPACK knowledge.},
  keywords = {Blended Learning,Classification,College Faculty,COVID-19,Distance Education,Educational Change,Educational Technology,Elementary School Teachers,Geometry,Graduate Students,Inservice Teacher Education,Mathematics Instruction,Measurement,Online Courses,Outcomes of Education,Pandemics,Pedagogical Content Knowledge,Preschool Teachers,Secondary School Teachers,Student Centered Learning,Summative Evaluation,Synchronous Communication,Teacher Attitudes,Teacher Surveys,Teaching Methods,Technological Literacy,Technology Integration,Virtual Classrooms}
}

@article{GALIKYAN2019100692,
  title = {Students' Engagement in Asynchronous Online Discussion: {{The}} Relationship between Cognitive Presence, Learner Prominence, and Academic Performance},
  author = {Galikyan, Irena and Admiraal, Wilfried},
  year = {2019},
  journal = {The Internet and Higher Education},
  volume = {43},
  pages = {100692},
  issn = {1096-7516},
  doi = {10.1016/j.iheduc.2019.100692},
  abstract = {The growth of online learning environments entails understanding of how to promote collaborative knowledge construction processes and create learning environments that support meaningful student engagement and interactions. Asynchronous online discussion forums are intended to support knowledge construction and higher-order thinking and are becoming even more appealing for their predictive relationship with learning. This paper describes a study that explored the complex dynamics of knowledge construction in pre-service teacher education through examining student teachers' cognitive presence in online discussion forums and their academic performance. The results of multiple regression analysis showed that certain levels of cognitive presence were associated with students' academic performance. In addition, network analysis of discussion forums revealed that student centrality within their learning networks moderated the association between the highest level of cognitive presence and academic performance. The paper concludes with discussing the theoretical and practical implications of the findings.},
  keywords = {Cognitive engagement,Content analysis,Measures of prominence,Online learning,Social network analysis,Teacher education},
  file = {/Users/colin.madland/Zotero/storage/YS5K5MWE/GALIKYAN2019100692.pdf}
}

@article{galiliHeatmaplyPackageCreating2018,
  title = {Heatmaply: An {{R}} Package for Creating Interactive Cluster Heatmaps for Online Publishing},
  shorttitle = {Heatmaply},
  author = {Galili, Tal and O'Callaghan, Alan and Sidi, Jonathan and Sievert, Carson},
  editor = {Wren, Jonathan},
  year = {2018},
  month = may,
  journal = {Bioinformatics},
  volume = {34},
  number = {9},
  pages = {1600--1602},
  issn = {1367-4803, 1367-4811},
  doi = {10.1093/bioinformatics/btx657},
  urldate = {2024-04-08},
  abstract = {Abstract                            Summary               heatmaply is an R package for easily creating interactive cluster heatmaps that can be shared online as a stand-alone HTML file. Interactivity includes a tooltip display of values when hovering over cells, as well as the ability to zoom in to specific sections of the figure from the data matrix, the side dendrograms, or annotated labels. Thanks to the synergistic relationship between heatmaply and other R packages, the user is empowered by a refined control over the statistical and visual aspects of the heatmap layout.                                         Availability and implementation               The heatmaply package is available under the GPL-2 Open Source license. It comes with a detailed vignette, and is freely available from: http://cran.r-project.org/package=heatmaply.                                         Supplementary information               Supplementary data are available at Bioinformatics online.},
  copyright = {http://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/9UFJ5QBG/galiliHeatmaplyPackageCreating2018.pdf}
}

@misc{gallantDirtyWorkCleaning2022,
  title = {The {{Dirty Work}} of {{Cleaning Online Reputations}}},
  author = {Gallant, Paul},
  year = {2022},
  month = jan,
  urldate = {2022-01-12},
  abstract = {For a fee, companies will tackle damaging search results. But is the new economy of digital makeovers making things worse?},
  langid = {american},
  keywords = {archived},
  file = {/Users/colin.madland/Zotero/storage/Y969SKIS/clean-online-reputation.html}
}

@incollection{gallavanEnsuringEthicsEquity2017,
  title = {Ensuring {{Ethics}} and {{Equity With Classroom Assessments}} and {{Mobile Technology}}: {{Advancing Online Education}}},
  booktitle = {Empowering {{Learners With Mobile Open-Access Learning Initiatives}}},
  author = {Gallavan, {\relax NP} and Huffman, S and Shaw, {\relax EC}},
  editor = {Mills, M and Wake, D},
  year = {2017},
  pages = {220--241},
  doi = {10.4018/978-1-5225-2122-8.ch011},
  abstract = {As online education continues to grow in both K-12 and higher education environments, teachers are becoming more attentive to the presence and power of their classroom assessments via mobile technology to enhance their self-efficacy. In online education, classroom assessments change both the role of the teacher and the function of the assessments. Mobile technology offers more choices for conducting assessments and providing feedback, accommodating learners' lives and locations, and increasing democratic participation and social inclusion. However, prevalent across online education are ethics and equity: two essential elements that can be difficult to guarantee with many approaches to classroom assessment via mobile technology. This chapter examines the essential elements of ethics and equity with classroom assessments via mobile technology in online education with recommended guidelines for teachers to enhance their self-efficacy.},
  isbn = {2327-1892},
  langid = {english},
  keywords = {EFFICACY,ISSUES},
  file = {/Users/colin.madland/Zotero/storage/MW6NFYUD/gallavanEnsuringEthicsEquity2017.pdf}
}

@article{galvisSupportingDecisionmakingProcesses2018,
  title = {Supporting Decision-Making Processes on Blended Learning in Higher Education: Literature and Good Practices Review},
  author = {Galvis, {\'A}lvaro Hern{\'a}n},
  year = {2018},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {15},
  number = {1},
  pages = {1--38},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-018-0106-1},
  abstract = {This article seeks to support decision-making processes in higher education institutions interested in using blended learning (from now on bLearning) as a complement to other learning ecologies. It explores factors that could influence an institution's decision to implement bLearning and addresses questions that should be answered in this regard. It aims to serve as a framework to strategic and tactical decisions around bLearning as a complement to other learning modalities. Questions aimed at supporting the construction of multidimensional bLearning environments that transform educational practices are raised around themes requiring critical analysis to materialize the bLearning implementation strategy: educational, operational and business models. This work concludes with an analysis of how to achieve the institutional transformation process, including how to articulate the bLearning modality with existing pedagogical approaches such that bLearning innovations become institutionalized and sustainable.},
  keywords = {bLearning,bLearning educational model,Blended learning,Blended Learning in Higher Education: research findings,Business,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Decision making,Ecological effects,Educational Technology,Higher Education,Higher education institutions,Humanities,Hybrid learning,Information Systems Applications (incl.Internet),Law,Learning,Literature reviews,Review Article,Statistics for Social Sciences,Strategic thinking,Tactics},
  file = {/Users/colin.madland/Zotero/storage/IEX7IHMN/galvisSupportingDecisionmakingProcesses2018.pdf}
}

@article{gamageOnlineDeliveryAssessment2020,
  ids = {gamageOnlineDeliveryAssessment2020a,gamageOnlineDeliveryAssessment301},
  title = {Online {{Delivery}} and {{Assessment}} during {{COVID-19}}: {{Safeguarding Academic Integrity}}},
  shorttitle = {Online {{Delivery}} and {{Assessment}} during {{COVID-19}}},
  author = {Gamage, Kelum A.A. and {\noopsort{silva}}de Silva, Erandika K. and Gunawardhana, Nanda},
  year = {2020},
  month = oct,
  journal = {Education Sciences},
  volume = {10},
  number = {11},
  pages = {301},
  publisher = {Mdpi},
  address = {BASEL},
  issn = {2227-7102},
  doi = {10/gmbvx2},
  urldate = {2021-07-27},
  abstract = {Globally, the number of COVID-19 cases continues to rise daily despite strict measures being adopted by many countries. Consequently, universities closed down to minimise the face-to-face contacts, and the majority of the universities are now conducting degree programmes through online delivery. Remote online delivery and assessment are novel experiences for many universities, which presents many challenges, particularly when safeguarding academic integrity. For example, invigilated assessments, often considered as more secure, are not an option given the current situation and detecting any cheating would be significantly challenging. This paper reviews assessment security in the digital domain and critically evaluates the practices from different universities in safeguarding academic integrity, including associated challenges.},
  langid = {english},
  keywords = {academic integrity,Comparative Education,COVID-19,Distance Education,Education & Educational Research,Educational Policy,Electronic Learning,Evaluation Methods,Formative Evaluation,Higher Education,Integrity,No DOI found,Online Courses,Pandemics,Pass Fail Grading,remote learning and teaching,Social Sciences,Student Evaluation,Student Motivation,Summative Evaluation,Tests},
  file = {/Users/colin.madland/Zotero/storage/R2Q5S55G/gamageOnlineDeliveryAssessment2020.pdf}
}

@article{gamageRethinkingAssessmentFuture2022,
  title = {Rethinking {{Assessment}}: {{The Future}} of {{Examinations}} in {{Higher Education}}},
  author = {Gamage, Kelum A. A. and Pradeep, Roshan G. G. R. and {\noopsort{silva}}{de Silva}, Erandika K.},
  year = {2022},
  journal = {Sustainability},
  volume = {14},
  number = {6},
  pages = {3552},
  publisher = {Mdpi},
  address = {BASEL},
  issn = {2071-1050},
  doi = {10.3390/su14063552},
  abstract = {The global higher education landscape is significantly impacted as a result of the COVID-19 pandemic and the majority of the universities now follow an online or hybrid mode of delivery. This presents substantial challenges for universities, particularly to conduct examinations, as traditionally most exams were conducted physically on campus. During the first wave of the pandemic, many universities had no option and were forced to move online in a very short period of time, causing universities also to conduct exams online without transforming pedagogy and the structure/s of closed-book exams. Inevitably, in non-proctored and unregulated examinations, this allowed room for students to collaborate and share material during online exams without being noticed by an invigilator as in the case of physical exams. Online exams, also leave room for students to find information online which made preventing plagiarism a significant challenge. This paper investigates the practices used in both closed-book and open-book exams and identifies the challenges associated with the transition to online exams. It also identifies potential ways forward for future online exams, while minimizing opportunities for students to collaborate, plagiarise and use online material. The findings of this study reveal that online examinations affect teachers and students differently: while teachers have mixed feelings about online exams, students are anxious about their grades and the technical hassle they experience in online exams. While viva has emerged as a popular form of alternative assessment, students still feel the need of returning to physical exams. None of the teachers who participated in this study discussed a psychosocial approach to education and exams in this pandemic. We conclude this study on the note that there is a need for the collaboration of social scientists, psychologists, psychosocial specialists, educationists, and humanities scholars/humanists for better educational policy and pedagogical practices during the pandemic.},
  keywords = {Academic misconduct,assessments,CAI,closed-book exams,Colleges & universities,Computer assisted instruction,Coronaviruses,COVID-19,Curriculum development,Distance learning,Education,Educational objectives,Environmental Sciences,Environmental Sciences & Ecology,Environmental Studies,Green & Sustainable Science & Technology,Higher education,Hybrid modes,Internet,Life Sciences & Biomedicine,Memory,online exams,Online instruction,open-book exams,Pandemics,Pedagogy,Science & Technology,Science & Technology - Other Topics,Skills,Students,Taxonomy,Teachers,Teaching},
  file = {/Users/colin.madland/Zotero/storage/R68BYQQ4/gamageRethinkingAssessmentFuture2022.pdf}
}

@article{ganeMeasuringWhatMatters2018,
  title = {Measuring What Matters: {{Using}} Technology to Assess Multidimensional Learning},
  shorttitle = {Measuring What Matters},
  author = {Gane, Brian D. and Zaidi, Sania Z. and Pellegrino, James W.},
  year = {2018},
  month = jun,
  journal = {European Journal of Education},
  volume = {53},
  number = {2},
  pages = {176--187},
  issn = {01418211},
  doi = {10/ghv5ct},
  urldate = {2021-01-27},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/CU2DGX2N/ganeMeasuringWhatMatters2018.pdf;/Users/colin.madland/Zotero/storage/WYXHB4NR/ganeMeasuringWhatMatters2018.pdf}
}

@article{gaonaFeedbackAutomaticAssessment2018,
  title = {Feedback by Automatic Assessment Systems Used in Mathematics Homework in the Engineering Field},
  author = {Gaona, J and Reguant, M and Valdivia, I and Vasquez, M and {Sancho-Vinuesa}, T},
  year = {2018},
  journal = {Computer Applications in Engineering Education},
  volume = {26},
  number = {4},
  pages = {994--1007},
  issn = {1061-3773},
  doi = {10.1002/cae.21950},
  abstract = {This research presents the results of the teaching innovation Dynamic Online Assessment System in Mathematics, which is implemented in higher education to promote self-study by students outside the classroom. The WIRIS calculator was integrated into the Moodle platform to create questions with random elements, for example, students had access to different variants of the same question. The effect of the type of feedback (immediate or deferred) on the work of the students on the platform, measured by means of participation, time spent, and grades obtained, was evaluated. We used a quasi-experimental methodology for a population of 5,507 students, distributed in 229 courses on four campuses that learn Mathematics I in engineering programs. Immediate feedback exhibits better work of students on the platform, but this work is not necessarily more efficient in comparison with the work performed by students using assessments online assessment with deferred feedback.},
  langid = {english},
  keywords = {automatic assessment tools,DIGITAL TECHNOLOGIES,educational innovation,feedback,FORMATIVE ASSESSMENT,mathematics assessment,web-based homework,WEB-BASED HOMEWORK},
  file = {/Users/colin.madland/Zotero/storage/IXELAABI/gaonaFeedbackAutomaticAssessment2018.pdf}
}

@incollection{gaoNonparametricStatistics2010,
  title = {Nonparametric {{Statistics}}},
  booktitle = {Encyclopedia of {{Research Design}}},
  author = {Gao, Xin},
  editor = {Salkind, Neil},
  year = {2010},
  publisher = {SAGE Publications, Inc.},
  address = {2455 Teller Road,~Thousand Oaks~California~91320~United States},
  doi = {10.4135/9781412961288.n272},
  urldate = {2021-08-05},
  isbn = {978-1-4129-6127-1 978-1-4129-6128-8},
  file = {/Users/colin.madland/Zotero/storage/RC5FRG95/gaoNonparametricStatistics2010.pdf}
}

@article{garcia-albertiChallengesExperiencesOnline2021,
  title = {Challenges and {{Experiences}} of {{Online Evaluation}} in {{Courses}} of {{Civil Engineering}} during the {{Lockdown Learning Due}} to the {{COVID-19 Pandemic}}},
  author = {{Garcia-Alberti}, Marcos and Suarez, Fernando and Chiyon, Isabel and Mosquera Feijoo, Juan Carlos},
  year = {2021},
  journal = {Education sciences},
  volume = {11},
  number = {2},
  pages = {59},
  publisher = {Mdpi},
  address = {BASEL},
  issn = {2227-7102},
  doi = {10.3390/educsci11020059},
  abstract = {As a consequence of the global health emergency in early 2020, universities had to tackle a sudden shift in their teaching-learning strategies so that the preset competences could be fulfilled. This study presents the learning outcomes of the implemented tasks, student experiences, and feedback, as well as some reflections from the instructors with a holistic perspective of the courses due to the adopted measures and adaptations. Six courses taught at civil engineering degrees of three universities, two from Spain and one from Peru, were analyzed. The teaching and evaluation strategies are described, and some reflections are made by comparing the student's performance with the previous course. Though the shift to online learning had to be made from day to day, with no time for preparation, the experience has proved that online learning can be beneficial in some aspects and has probably come to stay, although some other aspects are difficult to replace with respect to face-to-face learning, especially students' engagement and motivation. The significance of this study relies on a description of the challenges that arose due to the global public health and an assessment of the results of the implemented strategies to account for both teaching and evaluation in modules of civil engineering. After the acquired experience, new questions have arisen, e.g., what type of content is (and what is not) adequate or suitable for online exams? What features have come to stay? Has higher education taken a step forward to tomorrow's education?},
  keywords = {Civil engineering,COVID-19,Distance learning,Education & Educational Research,Educational evaluation,evaluation,higher education,Online instruction,online learning,Social Sciences,Students,Teaching methods,Tests},
  file = {/Users/colin.madland/Zotero/storage/N83YD7LI/garcia-albertiChallengesExperiencesOnline2021.pdf}
}

@article{garcialopezUseTechnologyModel2016,
  title = {The {{Use}} of {{Technology}} in a {{Model}} of {{Formative Assessment}}},
  author = {Garc{\'i}a L{\'o}pez, Alfonsa and Garc{\'i}a Mazar{\'i}o, Francisco},
  year = {2016},
  month = jan,
  journal = {Journal of Technology and Science Education},
  volume = {6},
  number = {2},
  pages = {91--103},
  publisher = {{Journal of Technology and Science Education}},
  issn = {2014-5349},
  doi = {10.3926/jotse.190},
  abstract = {This work describes a formative assessment model for a Mathematical Analysis course taken by engineering students. It includes online quizzes with feedback, a portfolio with weekly assignments, exams involving the use of mathematical software and a project to be completed in small groups of two or three students. The model has been perfected since 2009, and during the 2014-15 academic year the creation of a pilot online learning community was added. Based on Google+, it has been used for a peer assessment experiment involving student projects, among other uses.},
  keywords = {Computer Software,Electronic Learning,Engineering Education,Feedback (Response),Foreign Countries,Formative Evaluation,Higher Education,Integrated Learning Systems,Mathematical Concepts,Mathematics Curriculum,Mathematics Instruction,Mathematics Skills,Models,Pilot Projects,Spain (Madrid),Technology Uses in Education,Tests},
  file = {/Users/colin.madland/Zotero/storage/9VQJADY3/garcialopezUseTechnologyModel2016.pdf}
}

@article{garciamendozaComparativeStudyComputer2014,
  title = {A Comparative Study of Computer and Mobile Phone-Mediated Collaboration: The Case of University Students in {{Japan}}},
  author = {Garcia Mendoza, Gibran Alejandro},
  year = {2014},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {11},
  number = {1},
  pages = {222--237},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.7238/rusc.v11i1.1898},
  abstract = {Web-based forums are the major form of asynchronous communication in online courses. They are considered suitable collaborative learning environments to conduct discussions among groups of learners (Lieblein, as cited in Lamb, 2004; Zhu, 2006; Swan, 2001; Palloff \& Pratt, 2005). However, despite their relevance, web-based forums have been reported to be lacking when measuring the productivity of participants' interaction. Although previous studies have suggested the use of Short Message Service in supporting online collaboration, little research has been conducted to understand whether mobile phones increase interaction in online discussions and how interacting via mobile phones differs from desktop computers. Thus, this exploratory case study examines online collaboration through Moodle forums on desktop computers and the LINE chat application on smartphones. First, this paper compares how these two types of media influence the participation, interaction and collaboration of students. Second, it inquires into the students' collaboration experiences, opinions, and difficulties they encountered during the online discussions. Finally, it explores the impact that these two types of media had on the students' final outcome. Based on a literature review, the results of the content analysis of the posts and the experiences shared by the participants, this study concludes that mobile phones have great potential to enhance interaction in online collaboration.},
  keywords = {CAI,Cellular telephones,Comparative studies,Computer Appl. in Social and Behavioral Sciences,Computer assisted instruction,Computer Science,Computers and Education,Content analysis,Dossier "Mobile Learning Applications in Higher Education",Educational Technology,Higher Education,Humanities,Information Systems Applications (incl.Internet),Law,Online instruction,Statistics for Social Sciences,Student participation,University students}
}

@article{garciaRacistMachineDisturbing2016,
  title = {Racist in the {{Machine}}: {{The Disturbing Implications}} of {{Algorithmic Bias}}},
  shorttitle = {Racist in the {{Machine}}},
  author = {Garcia, Megan},
  year = {2016},
  journal = {World Policy Journal},
  volume = {33},
  number = {4},
  pages = {111--117},
  issn = {0740-2775, 1936-0924},
  doi = {10.1215/07402775-3813015},
  urldate = {2022-03-15},
  langid = {english},
  keywords = {archived},
  annotation = {https://web.archive.org/web/20220315213839/https://read.dukeupress.edu/world-policy-journal/article-abstract/33/4/111/30942/Racist-in-the-MachineThe-Disturbing-Implications?redirectedFrom=fulltext}
}

@book{gardnerAssessmentEducation2015,
  ids = {gardnerAssessmentEducation2020},
  title = {Assessment in Education},
  author = {Gardner, John},
  year = {2015},
  publisher = {SAGE Publications},
  address = {London},
  doi = {10.4135/9781473915367},
  abstract = {This new work revisits the topic of assessment in education but shifts the focus to take a more detailed look at important aspects of the subject previously only touched upon, such as: assessment carried out by teachers; advances in technological approaches to assessment, most notably in computerised adaptive testing; our understanding of assessment for learning (including peer and self-assessment, formative assessment and feedback); ethical dimensions such as students' rights and entitlements},
  isbn = {978-1-4739-1546-6},
  langid = {english},
  annotation = {OCLC: 906008921}
}

@article{garetWhatMakesProfessional2001,
  title = {What {{Makes Professional Development Effective}}? {{Results From}} a {{National Sample}} of {{Teachers}}},
  author = {Garet, Michael S. and Porter, Andrew C and Desimone, Laura and Birman, Beatrice F and Yoon, Kwang Suk},
  year = {2001},
  journal = {American Educational Research Journal},
  volume = {38},
  number = {4},
  pages = {915--945},
  abstract = {This study uses a national probability sample of 1,027 mathematics and science teachers to provide the first large-scale empirical comparison of effects of different characteristics of professional development on teachers{\quotesinglbase}{\"A}{\^o} learning. Results, based on ordinary least squares regression, indicate three core features of professional development activities that have significant, positive effects on teachers{\quotesinglbase}{\"A}{\^o} self-reported increases in knowledge and skills and changes in classroom practice: (a) focus on content knowledge; (b) opportunities for active learning; and (c) coherence with other learning activities. It is primarily through these core features that the following structural features significantly affect teacher learning: (a) the form of the activity (e.g., workshop vs. study group); (b) collective participation of teachers from the same school, grade, or subject; and (c) the duration of the activity.}
}

@book{garrisonBlendedLearningHigher2008,
  title = {Blended Learning in Higher Education: Framework, Principles, and Guidelines},
  shorttitle = {Blended Learning in Higher Education},
  author = {Garrison, D. R and Vaughan, Norman D},
  year = {2008},
  publisher = {Jossey-Bass},
  address = {San Francisco},
  urldate = {2021-01-22},
  abstract = {"This groundbreaking book offers a down-to-earth resource for the practical application of blended learning in higher education as well as a comprehensive examination of the topic. Well-grounded in research, Blended Learning in Higher Education demonstrates how the blended learning approach embraces the traditional values of face-to-face teaching and integrates the best practices of online learning. This approach has proven to both enhance and expand the effectiveness and efficiency of teaching and learning in higher education across disciplines."--Jacket.},
  isbn = {978-1-118-18017-4 978-1-118-18018-1 978-1-118-26955-8 978-1-283-29505-5},
  langid = {english},
  annotation = {OCLC: 758384994}
}

@article{garrisonBlendedLearningUncovering2004,
  title = {Blended Learning: {{Uncovering}} Its Transformative Potential in Higher Education},
  author = {Garrison, D.Randy and Kanuka, Heather},
  year = {2004},
  journal = {The Internet and Higher Education},
  volume = {7},
  number = {2},
  pages = {95--105},
  issn = {1096-7516},
  doi = {10.1016/j.iheduc.2004.02.001},
  keywords = {Action plans,BLENDED learning,communities of inquiry,Higher Education,Higher-order learning,Leadership,Transformation}
}

@article{garrisonBlendedLearningUncovering2004a,
  title = {Blended Learning: {{Uncovering}} Its Transformative Potential in Higher Education},
  author = {Garrison, D.Randy and Kanuka, Heather},
  year = {2004},
  month = apr,
  journal = {The Internet and Higher Education},
  volume = {7},
  number = {2},
  pages = {95--105},
  issn = {1096-7516},
  doi = {10/b6g4vc},
  abstract = {The purpose of this paper is to provide a discussion of the transformative potential of blended learning in the context of the challenges facing higher education. Based upon a description of blended learning, its potential to support deep and meaningful learning is discussed. From here, a shift to the need to rethink and restructure the learning experience occurs and its transformative potential is analyzed. Finally, administrative and leadership issues are addressed and the outline of an action plan to implement blended learning approaches is presented. The conclusion is that blended learning is consistent with the values of traditional higher education institutions and has the proven potential to enhance both the effectiveness and efficiency of meaningful learning experiences.},
  keywords = {Action plans,Blended learning,Communities of inquiry,Higher education,Higher-order learning,Leadership,Transformation}
}

@book{garrisonCommunityInquiryModel2011,
  title = {Community of {{Inquiry Model}}},
  author = {Garrison, D. Randy},
  year = {2011},
  volume = {2012}
}

@article{garrisonCriticalInquiryTextbased2000,
  title = {Critical Inquiry in a Text-Based Environment: {{Computer}} Conferencing in Higher Education},
  shorttitle = {Critical Inquiry in a Text-Based Environment: {{Computer}} Conferencing in Higher Education},
  author = {Garrison, D. Randy and Anderson, Terry and Archer, Walter},
  year = {2000},
  journal = {The Internet and Higher Education},
  volume = {2},
  pages = {87--105},
  issn = {1096-7516},
  doi = {10.1016/S1096-7516(00)00016-6},
  abstract = {The purpose of this study is to provide conceptual order and a tool for the use of computermediated communication (CMC) and computer conferencing in supporting an educational experience. Central to the study introduced here is a model of community inquiry that constitutes three elements essential to an educational transaction{\DH}cognitive presence, social presence, and teaching presence. Indicators (key words/phrases) for each of the three elements emerged from the analysis of computer-conferencing transcripts. The indicators described represent a template or tool for researchers to analyze written transcripts, as well as a guide to educators for the optimal use of computer conferencing as a medium to facilitate an educational transaction. This research would suggest that computer conferencing has considerable potential to create a community of inquiry for educational purposes.},
  annotation = {2-3},
  file = {/Users/colin.madland/Zotero/storage/XQTQR4I4/garrisonCriticalInquiryTextbased2000.pdf}
}

@article{garrisonCriticalThinkingAdult1991,
  title = {Critical Thinking and Adult Education: A Conceptual Model for Developing Critical Thinking in Adult Learners},
  author = {Garrison, D. R.},
  year = {1991},
  journal = {International Journal of Lifelong Education},
  volume = {10},
  number = {4},
  pages = {287--303},
  abstract = {While critical thinking has been intimately associated with adult education, there is not always a consensus as to its meaning and how to develop it in adult learners. After analysing the concept of critical thinking, a model is suggested consisting of five phases, which attempts to incorporate aspects of problem solving and creative thinking. Next, the development of critical thinking and the central role it plays in adult education are explored. It is concluded that issues surrounding the development of critical thinking may be an important key to developing an understanding of the field of adult education.}
}

@article{garrisonCriticalThinkingCognitive2001,
  title = {Critical Thinking, Cognitive Presence, and Computer Conferencing in Distance Education},
  shorttitle = {Critical Thinking, Cognitive Presence, and Computer Conferencing in Distance Education},
  author = {Garrison, D. Randy and Anderson, Terry and Archer, Walter},
  year = {2001},
  month = jan,
  journal = {American Journal of Distance Education},
  volume = {15},
  pages = {7--23},
  issn = {0892-3647},
  doi = {10.1080/08923640109527071},
  urldate = {2012-03-01},
  abstract = {Abstract This article describes a practical approach to judging the nature and quality of critical discourse in a computer conference. A model of a critical community of inquiry frames the research. A core concept in defining a community of inquiry is cognitive presence. In turn, the practical inquiry model operationalizes cognitive presence for the purpose of developing a tool to assess critical discourse and reflection. The authors present encouraging empirical findings related to an attempt to create an efficient and reliable instrument to assess the nature and quality of critical discourse and thinking in a text?based educational context. Finally, the authors suggest that cognitive presence (i.e., critical, practical inquiry) can be created and supported in a computer?conference environment with appropriate teaching and social presence.},
  annotation = {1}
}

@article{garrisonDevelopmentMetacognitionConstruct2015,
  title = {Toward the Development of a Metacognition Construct for Communities of Inquiry},
  author = {Garrison, D.R. and Akyol, Zehra},
  year = {2015},
  month = jan,
  journal = {The Internet and Higher Education},
  volume = {24},
  pages = {66--71},
  issn = {10967516},
  doi = {10.1016/j.iheduc.2014.10.001},
  urldate = {2022-06-07},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/KJBE8IVD/garrisonDevelopmentMetacognitionConstruct2015.pdf}
}

@book{garrisonElearning21stCentury2011,
  title = {E-Learning in the 21st Century: {{A}} Framework for Research and Practice},
  author = {Garrison, D. Randy},
  year = {2011},
  edition = {2nd},
  publisher = {Routledge},
  address = {New York}
}

@article{garrisonFacilitatingCognitivePresence2005,
  title = {Facilitating Cognitive Presence in Online Learning: {{Interaction}} Is Not Enough},
  shorttitle = {Facilitating Cognitive Presence in Online Learning: {{Interaction}} Is Not Enough},
  author = {Garrison, D. Randy and {Cleveland-Innes}, Martha},
  year = {2005},
  journal = {American Journal of Distance Education},
  volume = {19},
  pages = {133--148},
  issn = {0892-3647},
  abstract = {This study assessed the depth of online learning, with a focus on the nature of online interaction in four distance education course designs. The Study Process Questionnaire was used to measure the shift in students' approach to learning from the beginning to the end of the courses. Design had a significant impact on the nature of the interaction and whether students approached learning in a deep and meaningful manner. Structure and leadership were found to be crucial for online learners to take a deep and meaningful approach to learning.},
  annotation = {3}
}

@incollection{garrisonMethodologicalIssuesPhilosophical1994,
  title = {Methodological {{Issues}}: {{Philosophical Differences}} and {{Complementary Methodologies}}},
  shorttitle = {Methodological {{Issues}}: {{Philosophical Differences}} and {{Complementary Methodologies}}},
  booktitle = {Research Persepectives in Adult Education},
  author = {Garrison, Randy and Shale, Doug},
  editor = {Garrison, Randy},
  year = {1994},
  pages = {17--37},
  publisher = {Krieger},
  address = {Florida}
}

@article{garrisonTheoreticalChallengesDistance2000,
  title = {Theoretical {{Challenges}} for {{Distance Education}} in the 21st {{Century}}: {{A Shift}} from {{Structural}} to {{Transactional Issues}}},
  shorttitle = {Theoretical {{Challenges}} for {{Distance Education}} in the 21st {{Century}}: {{A Shift}} from {{Structural}} to {{Transactional Issues}}},
  author = {Garrison, Randy},
  year = {2000},
  journal = {International Review of Research in Open and Distance Learning},
  volume = {1},
  abstract = {Randy Garrison Abstract The premise of this\&\#xa; article is that theoretical frameworks and models are essential to the long-term credibility and viability of a field of practice. In order to assess the theoretical challenges facing the field of distance education, the significant theoretical contributions to distance education in the last century are briefly reviewed. This review of distance education as a field of study reveals an early preoccupation with organizational and structural constraints. However, the review also reveals that the theoretical development of the field is progressing from organizational to transactional issues and assumptions. The question is whether distance education has the theoretical foundation to take it into the 21st century and whether distance education theory development will keep pace with innovations in technology and practice.},
  keywords = {Development,developments,frameworks,Models,theoretical,theoretical developments,theoretical frameworks,theoretical models,theory,theory development,transactional,transactional theory},
  annotation = {1}
}

@incollection{garrisonThinkingCollaborativelyEducational2015,
  title = {Thinking {{Collaboratively}} in {{Educational Environments}}: {{Shared Metacognition}} and {{Co-Regulation}} in {{Communities}} of {{Inquiry}}},
  shorttitle = {Thinking {{Collaboratively}} in {{Educational Environments}}},
  booktitle = {Educational {{Developments}}, {{Practices}} and {{Effectiveness}}},
  author = {Garrison, D. Randy and Akyol, Zehra},
  editor = {Lock, Jennifer and Redmond, Petrea and Danaher, Patrick Alan},
  year = {2015},
  pages = {39--52},
  publisher = {Palgrave Macmillan UK},
  address = {London},
  doi = {10.1057/9781137469939_3},
  urldate = {2022-06-08},
  isbn = {978-1-349-69180-7 978-1-137-46993-9},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/XWGD6XRB/garrisonThinkingCollaborativelyEducational2015.pdf}
}

@article{garveyMixedMethodExploration2021,
  title = {A Mixed Method Exploration of Student Perceptions of Assessment in Nursing and Biomedicine},
  author = {Garvey, Loretta and Hodgson, Yvonne and Tighe, Josephine},
  year = {2021},
  month = mar,
  journal = {Journal of Further and Higher Education},
  pages = {1--14},
  issn = {0309-877X, 1469-9486},
  doi = {10/gmb9k6},
  urldate = {2021-07-31},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/HE5CP8B4/garveyMixedMethodExploration2021.pdf}
}

@article{gasevicEmpoweringLearnersAge2023,
  title = {Empowering Learners for the Age of Artificial Intelligence},
  author = {Ga{\v s}evi{\'c}, Dragan and Siemens, George and Sadiq, Shazia},
  year = {2023},
  month = feb,
  journal = {Computers and Education: Artificial Intelligence},
  pages = {100130},
  issn = {2666-920X},
  doi = {10.1016/j.caeai.2023.100130},
  abstract = {Although studied for decades by the research community, artificial intelligence (AI) in education has recently sparked much public debate with the wide-spread popularity of systems such as ChatGPT and DALL-E. Existing literature offers a wealth of research on design, deploying and evaluating AI-driven systems in education. However, the challenges related to the growing influence of AI in the society, calls for revisiting research foundations of AI in education in order to inform decision-making in policy and guide future research. This special issue of Computers \& Education: Artificial Intelligence brings 11 papers that explore the theme of empowering learners for the age of AI. The contributions of these papers can be broadly grouped into seven main themes: intersection between AI and humans that looks at the space of coordination; assessment that explores challenges and opportunities afforded by the use of AI in educational assessment; explainability in AI as a critical need for humans in education to understand and trust AI; design for learning that offers principles for designing AI-driven systems and educational opportunities; conceptual AI and learning exploring the need for the development of new theories of learning and their connections with existing theoretical foundations in education; accurate predictions and their role in future education; and applications of AI in classrooms and educational systems. The findings of these studies highlight pressing research and policies challenges and opportunities that arise with the broad penetration of AI in education. They also emphasize the need for future research that addresses issues of ethics, bias and farness in the use of AI in education; challenges associated with data sources and ownership as the key fuel and enabler of present-day AI generation; AI literacies and competencies of stakeholders who use and are impacted by AI in education; identification of effective learning and teaching practices with the use of AI; and policy development to increase responsiveness of education systems to rapid changes driven by AI.},
  file = {/Users/colin.madland/Zotero/storage/W93HW5DW/gasevicEmpoweringLearnersAge2023.pdf}
}

@article{gatesOfficialEncouragementImmigration1934,
  title = {Official {{Encouragement}} to {{Immigration}} by the {{Province}} of {{Canada}}},
  author = {Gates, Paul W.},
  year = {1934},
  month = mar,
  journal = {Canadian Historical Review},
  volume = {15},
  number = {1},
  pages = {24--38},
  issn = {0008-3755, 1710-1093},
  doi = {10.3138/chr-015-01-02},
  urldate = {2024-05-12},
  langid = {english}
}

@article{gaudryDecolonizingMetisPedagogies2012,
  title = {Decolonizing {{M{\'e}tis Pedagogies}} in {{Post-Secondary Settings}}},
  author = {Gaudry, Adam and {Robert L A Hancock}},
  year = {2012},
  journal = {Canadian Journal of Native Education},
  volume = {35},
  number = {1},
  pages = {7},
  issn = {0710-1481},
  abstract = {This article asks how post-secondary education and scholarship can facilitate critical and engaged reclamations of M{\'e}tis knowledge through critical intellectual and experiential engagement. First, it explores dominant representations of Metis political and cultural experience in historical perspective, and considers these implications for Metis students and communities. This examination identifies a problem that we address by envisioning models of engaged pedagogy, based on insights from author bell hooks, which draw upon on a particular stream of thought in Michel Foucault's later work. It concludes with a discussion of the possibilities of decolonizing representations of Metis history and politics, through the exploration of relational land- and community-based pedagogies. [PUBLICATION ABSTRACT]},
  keywords = {Community,Education,Metis,Narratives,Pedagogy}
}

@incollection{geeGameLikeLearning2008,
  title = {Game-{{Like Learning}}},
  booktitle = {Assessment, {{Equity}}, and {{Opportunity}} to {{Learn}}},
  author = {Gee, James Paul},
  editor = {Pullin, Diana C. and Haertel, Edward H. and Gee, James Paul and Young, Lauren Jones and Moss, Pamela A.},
  year = {2008},
  series = {Learning in {{Doing}}: {{Social}}, {{Cognitive}} and {{Computational Perspectives}}},
  pages = {200--221},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9780511802157.010},
  abstract = {KNOWLEDGE: AS NOUN AND VERBThe theory of learning in many schools today is based on what I would call the ``content fetish'' (Gee 2004). The content fetish is the view that any academic area (whether physics, sociology, or history) is composed of a set of facts or a body of information and that the way learning should work is through teaching and testing such facts and information.However, for some current learning theorists, ``know'' is a verb before it is a noun, ``knowledge'' (Barsalou 1999a, 1999b; Bereiter and Scardamalia 1993; Clark 1997; Glenberg 1997; Glenberg and Robertson 1999; Lave and Wenger 1991; Rogoff 1990). Any actual domain of knowledge, academic or not, is first and foremost a set of activities (special ways of acting and interacting so as to produce and use knowledge) and experiences (special ways of seeing, valuing, and being in the world). Physicists do physics. They talk physics. And when they are being physicists, they see and value the world in a different way than do non-physicists. The same applies for good anthropologists, linguists, urban planners, army officers, doctors, artists, literary critics, historians, and so on (diSessa 2000; Lave 1996; Ochs, Gonzales, and Jacoby 1996; Shaffer 2004).Yet if much decontextualized, overt information and skill-and-drill on facts does not work as a theory of learning, neither does ``anything goes,'' ``just turn learners loose in rich environments,'' ``no need for teachers'' (Kirschner, Sweller, and Clark 2006).},
  isbn = {978-0-521-88045-9}
}

@incollection{geeSocioculturalPerspectiveOpportunity2008,
  title = {A {{Sociocultural Perspective}} on {{Opportunity}} to {{Learn}}},
  booktitle = {Assessment, {{Equity}}, and {{Opportunity}} to {{Learn}}},
  author = {Gee, James Paul},
  editor = {Pullin, Diana C. and Haertel, Edward H. and Gee, James Paul and Young, Lauren Jones and Moss, Pamela A.},
  year = {2008},
  series = {Learning in {{Doing}}: {{Social}}, {{Cognitive}} and {{Computational Perspectives}}},
  pages = {76--108},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9780511802157.006},
  abstract = {INTRODUCTIONThe field of psychometrics has been predominant in work on testing and assessment. For the most part, psychometrics has been strongly influenced by traditional psychological assumptions about the mind and learning. Work that takes a sociocultural perspective has played a much smaller role and has heretofore made little contact with psychometrics. This chapter discusses contributions such a sociocultural perspective has to make to issues of assessment and testing, with a focus on an expanded notion of opportunity to learn (OTL). Ensuring that all learners have had equal OTL is both an ethical prerequisite for fair assessment and a solid basis on which to think about educational reforms that will ensure that all children can succeed at school. It is also a point at which mutually informing discussion can occur between people working in psychometrics and those working on sociocultural approaches to learning.This section begins with a consideration of the traditional perspective in psychology, one that views knowledge and learning through the lens of mental representations in individuals' heads (Clancey 1997). Even in this traditional view, many of the types of issues that sociocultural perspectives emphasize also arise, although in a more backgrounded way. I will then turn to a more direct consideration of sociocultural perspectives, starting with the relationship between learners and their learning environments. In subsequent sections, I will spell out this relationship in terms of the connections between learning and learners' experiences in the world; how knowledge is distributed across people and their tools; the central importance of people's participation in shared talk and social practices; and the nature of the special varieties of language used in talk and participation when people learn in content areas in school -- areas like math, science, social studies, and literature.},
  isbn = {978-0-521-88045-9}
}

@article{geeWhatVideoGames2003,
  title = {What Video Games Have to Teach Us about Learning and Literacy},
  author = {Gee, James Paul},
  year = {2003},
  month = oct,
  journal = {Computers in Entertainment},
  volume = {1},
  number = {1},
  pages = {20--20},
  issn = {1544-3574},
  doi = {10.1145/950566.950595},
  urldate = {2023-08-05},
  abstract = {Good computer and video games like System Shock 2, Deus Ex, Pikmin, Rise of Nations, Neverwinter Nights, and Xenosaga: Episode 1 are learning machines. They get themselves learned and learned well, so that they get played long and hard by a great many people. This is how they and their designers survive and perpetuate themselves. If a game cannot be learned and even mastered at a certain level, it won't get played by enough people, and the company that makes it will go broke. Good learning in games is a capitalist-driven Darwinian process of selection of the fittest. Of course, game designers could have solved their learning problems by making games shorter and easier, by dumbing them down, so to speak. But most gamers don't want short and easy games. Thus, designers face and largely solve an intriguing educational dilemma, one also faced by schools and workplaces: how to get people, often young people, to learn and master something that is long and challenging--and enjoy it, to boot.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/X5YSGIUQ/geeWhatVideoGames2003.pdf}
}

@book{geisingerMakingSenseCollege1988,
  title = {Making {{Sense}} of {{College Grades}}: {{Why}} the {{Grading System Does Not Work}} and {{What Can Be Done}} about {{It}}},
  author = {Geisinger, Kurt F.},
  year = {1988},
  publisher = {JSTOR},
  isbn = {0022-0655}
}

@book{gereDevelopingWritersHigher2019,
  title = {Developing {{Writers}} in {{Higher Education}}: A Longitudinal Study},
  editor = {Gere, Anne Ruggles},
  year = {2019},
  publisher = {University of Michigan Press},
  address = {Ann Arbor}
}

@article{geringStrengthsBasedAnalysisStudent2018,
  title = {Strengths-{{Based Analysis}} of {{Student Success}} in {{Online Courses}}},
  author = {Gering, Carol S. and Sheppard, Dani K. and Adams, Barbara L. and Renes, Susan L. and Morotti, Allan A.},
  year = {2018},
  journal = {Online Learning},
  volume = {22},
  number = {3},
  pages = {55--85},
  issn = {ISSN-2472-5749},
  abstract = {Online courses today give a broad, diverse population access to higher education. Despite postsecondary institutions embracing this opportunity, scholarly literature reveals persistent concern over low retention rates in online courses. In response to this concern, an explanatory sequential, mixed methods study was conducted in three phases at a public research university to simultaneously explore personal, circumstantial, and course variables associated with student success from a strengths-based perspective. In Phase One, existing data on student enrollments across four years were analyzed. During Phase Two, a subset of Phase One students from a single semester was invited to complete an assessment of noncognitive attributes and personal perceptions, followed in Phase Three by interviews among a stratified sample of successful students from the previous phase to elaborate on factors impacting their success. Quantitative analyses identified seven individual variables with statistical and practical significance for online student success. Interestingly, the combination of factors classified as predictive of success changed with student academic standing. The impact of differential success factors across academic experience may explain mixed results in previous studies. The themes that emerged from the interviews with students were congruent with quantitative findings. A unique perspective was shared when students discussed "teaching themselves," providing additional insight into perceptions of teaching presence not formerly understood. The combination of a more contextual research approach, a strengths-based perspective, and insights from student perceptions yielded implications for educational practice.},
  langid = {english},
  keywords = {Academic Achievement,Enrollment,Graduate Students,No DOI found,Online Courses,Predictor Variables,Research Universities,Student Attitudes,Success,Undergraduate Students}
}

@article{gerritsen-vanleeuwenkampAssessmentQualityTertiary2017,
  title = {Assessment Quality in Tertiary Education: {{An}} Integrative Literature Review},
  shorttitle = {Assessment Quality in Tertiary Education},
  author = {{Gerritsen-van Leeuwenkamp}, Karin J. and {Joosten-ten Brinke}, Desir{\'e}e and Kester, Liesbeth},
  year = {2017},
  month = dec,
  journal = {Studies in Educational Evaluation},
  volume = {55},
  pages = {94--116},
  issn = {0191491X},
  doi = {10/ghjbhx},
  urldate = {2020-12-20},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/M433GHBQ/gerritsen-vanleeuwenkampAssessmentQualityTertiary2017.pdf}
}

@techreport{geserOpenEducationalPractices,
  title = {Open {{Educational Practices}} and {{Resources}}: {{OLCOS Roadmap}} 2012},
  editor = {Geser, Guntram},
  address = {Salzberg, Austria},
  institution = {Salzberg Research: EduMedia Group},
  urldate = {2018-11-04},
  keywords = {oep},
  file = {/Users/colin.madland/Zotero/storage/JS2AFYWN/olcos.org.html}
}

@article{getachewAssessmentPsychologicalCounseling2019,
  title = {Assessment of {{Psychological Counseling Service}} for {{Higher Education Institution Students}}},
  author = {Getachew, Abera},
  year = {2019},
  journal = {International Journal of Education and Literacy Studies},
  volume = {7},
  number = {4},
  pages = {53--61},
  issn = {EISSN-2202-9478},
  doi = {10/gmbvz5},
  abstract = {Guidance and counseling programs are effective in assisting young students in various aspects like academic achievement, study habits and choosing appropriate careers. A study was conducted in a public university in Ethiopia among 605 regular undergraduate students. Its objective was to investigate the students' awareness and use of Psychological Counseling Service at Higher Education Institutions. The study results show that demographic variables were strongly accounted for the variances in awareness of psychological counseling and use of the service. Majority of the male students (67.8\%) had not heard about the presence of psychological counseling service while 24.3\% of female students did not know about such a service. More than 60\% of the study participants gave top priority for psychological counseling service in higher education institutions. Students' year of study and place of residence were significantly associated with the students rating of crisis intervention and emergency services, ?[superscript 2] (9)=23.40, p{$<$}0.01. The importance given to psychological counseling services also varied based on the place of origin and academic year of the students. Students believed psychological counseling service contributed to their academic success. Implications are discussed.},
  langid = {english},
  keywords = {Academic Achievement,Counseling Services,Crisis Intervention,Foreign Countries,Gender Differences,Grade Point Average,Help Seeking,Instructional Program Divisions,Knowledge Level,Place of Residence,Psychological Services,Student Attitudes,Undergraduate Students}
}

@article{gettyJourneyWesternIndigenous2009,
  title = {The {{Journey Between Western}} and {{Indigenous Research Paradigms}}},
  author = {Getty, Grace A.},
  year = {2009},
  month = oct,
  journal = {Journal of Transcultural Nursing},
  volume = {21},
  number = {1},
  pages = {5--14},
  issn = {1043-6596},
  doi = {10.1177/1043659609349062},
  urldate = {2019-03-30},
  abstract = {This article is an account of the author?s journey as a White researcher preparing to do a community-based participatory action research study with Mi?kmaq men. In this article, a postcolonial approach is examined, interrogating the utility of this theoretical approach in research with Aboriginal people. Next, the foundations of an Indigenous worldview is identified, followed by a debate about the strengths and weaknesses of a critical social theory approach in light of an Indigenous worldview. Finally, lessons about an Indigenous research paradigm including the benefits of using a theoretical approach based on an Indigenous knowledge system are identified.},
  file = {/Users/colin.madland/Zotero/storage/QBQ437NB/gettyJourneyWesternIndigenous2009.pdf}
}

@article{ghaichaTheoreticalFrameworkEducational2016,
  title = {Theoretical {{Framework}} for {{Educational Assessment}}: {{A Synoptic Review}}},
  author = {Ghaicha, Abdullah},
  year = {2016},
  volume = {7},
  number = {24},
  pages = {212--231},
  abstract = {At this age of accountability, it is acknowledged that assessment is a powerful lever that can either boost or undermine students learning. Hitherto, much of the regular institutional and instructional practices show that assessments remain inhibitory or void rather than constructive as these lack the assessment formative aspect. This denotes that assessment is either not well understood or not done in a principled educational framework across all educational levels. This is due to some inherited dysfunction of the past, which calls for the urgency of a moratorium. The current article attempts to enhance the EFL practitioners' educational assessment practice as a form of expanding awareness. It attempts to establish a founded theoretical framework for the main concerns that might have been troubling novice and professional EFL practitioners with regard to understanding the working mechanisms of such a perplexing task that has long been delegated to them. Particular aspects of the current review target the definitions of the concept of assessment, the value, functions and purposes of assessment, levels where assessment occur, assessment research literature synopsis, and classroom assessment research (CAR). CAR presents detailed knowledge about the potency of assessment, research on classroom assessment practices, research on alternative assessment, research on formative assessment, and finally quality control criteria for effective classroom assessment. The article culminate in the pedagogical potency of formative assessment and some of its classroom procedural applications inspired from research into formative assessment and how that might contribute to the enhancement of pedagogic practice.},
  file = {/Users/colin.madland/Zotero/storage/35VKVQ6M/ghaichaTheoreticalFrameworkEducational2016.pdf}
}

@article{ghasemyThisFastCar2020,
  title = {This Fast Car Can Move Faster: A Review of {{PLS-SEM}} Application in Higher Education Research},
  shorttitle = {This Fast Car Can Move Faster},
  author = {Ghasemy, Majid and Teeroovengadum, Viraiyan and Becker, Jan-Michael and Ringle, Christian M.},
  year = {2020},
  month = dec,
  journal = {Higher Education},
  volume = {80},
  number = {6},
  pages = {1121--1152},
  issn = {0018-1560, 1573-174X},
  doi = {10.1007/s10734-020-00534-1},
  urldate = {2023-08-24},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/4PJ37XHZ/ghasemyThisFastCar2020.pdf}
}

@article{ghazaliDesigningOnlineClass2021,
  title = {Designing {{Online Class}} Using {{Discord}} Based on {{Community}} of {{Inquiry Framework}}},
  author = {Ghazali, Nurzal Effiyana},
  year = {2021},
  month = dec,
  journal = {Asean Journal of Engineering Education},
  volume = {5},
  number = {2},
  doi = {10.11113/ajee2021.5n2.73},
  urldate = {2024-08-16},
  abstract = {\&lt;p\&gt;COVID-19 pandemic changes the landscape of education, where online learning becomes very important and can not be avoided. Therefore, this article discusses how a gamer\&\#039;s platform, Discord can be used as an interactive online class. A comparison of Discord with other online platforms is spelled out in a tabular form. The principle used to design the online class using Discord is based on Community of Inquiry (CoI). CoI consists of three elements which are teaching presence, social presence, and cognitive presence for a better educational experience. The design discussed in this article are Discord features design for the online class and class activity using Discord in developing the three elements in CoI. Data collection is done using open-ended surveys. They are 58 respondents with engineering and non-engineering students. Most of the students are familiar with Discord and agreed that Discord can be adapted for an online class. Thematic analysis is conducted to analyze the open-ended questions. The themes that can be identified are parallel channels, structure, all-in-one platform, facilitation, and learning environment. Another analysis is message counts in each student group to show how active the students in online class using Discord. In conclusion, Discord is the best platform to make students active and construct knowledge with peers.\&lt;/p\&gt;},
  chapter = {Articles},
  file = {/Users/colin.madland/Zotero/storage/26BX23A7/ghazaliDesigningOnlineClass2021.pdf}
}

@article{gibbonsChasmCrossedClicker2017,
  title = {Chasm {{Crossed}}? {{Clicker Use}} in {{Postsecondary Chemistry Education}}},
  author = {Gibbons, Rebecca E and Laga, Emily E and Leon, Jessica and Villafa{\~n}e, Sachel M and Stains, Marilyne and Murphy, Kristen and Raker, Jeffrey R},
  year = {2017},
  journal = {Journal of chemical education},
  volume = {94},
  number = {5},
  pages = {549--557},
  publisher = {{American Chemical Society and Division of Chemical Education, Inc}},
  address = {WASHINGTON},
  issn = {0021-9584},
  doi = {10.1021/acs.jchemed.6b00799},
  abstract = {Research on classroom response systems (CRSs) in chemical education has primarily focused on the development of evidence-based strategies for implementation and novel practitioner uses of CRSs in instructional practice. Our national survey of postsecondary chemistry faculty extends these discussions, providing a broad-based understanding of the current state of CRS use in classrooms in the United States. Our results indicate a particular contextual profile for those who have adopted such technology. This profile indicates the unique environment in which faculty members are more likely to report using CRSs, specifically, large courses at the introductory or foundation course level. Some have suggested that CRSs will become universal in chemical education; we note that a niche market has been found.},
  keywords = {Audience Response Systems,Chemical Education Research,Chemistry,Chemistry Multidisciplinary,Chemistry teachers,Classroom management,Classrooms,College Faculty,College Science,Education,Education & Educational Research,Education Higher,Education Scientific Disciplines,Effect Size,Forecasts and trends,Higher education,Large Group Instruction,National Surveys,Physical Sciences,Science & Technology,Social Sciences,Statistical Analysis,Statistical Inference,Study and teaching,Surveys,Teacher Attitudes,Teacher Surveys,Teaching Methods,Technology application,Technology Uses in Education,Undergraduate Students,Use Studies}
}

@article{gibbsDoesAssessmentOpen2010,
  title = {Does Assessment in Open Learning Support Students?},
  author = {Gibbs, Graham},
  year = {2010},
  month = jun,
  journal = {Open Learning: The Journal of Open, Distance and e-Learning},
  volume = {25},
  number = {2},
  pages = {163--166},
  issn = {0268-0513, 1469-9958},
  doi = {10/cbhkth},
  urldate = {2020-12-21},
  langid = {english}
}

@book{gideonHandbookSurveyMethodology2012,
  title = {Handbook of {{Survey Methodology}} for the {{Social Sciences}}},
  editor = {Gideon, Lior},
  year = {2012},
  publisher = {Springer New York},
  address = {New York, NY},
  doi = {10.1007/978-1-4614-3876-2},
  urldate = {2023-03-13},
  isbn = {978-1-4614-3875-5 978-1-4614-3876-2},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/JNEBRV44/gideonHandbookSurveyMethodology2012.pdf}
}

@incollection{gierlRoleCognitiveModels2016,
  title = {The Role of Cognitive Models in Automatic Item Generation},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {Gierl, Mark J. and Lai, Hollis},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch6},
  pages = {124--145},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch6},
  abstract = {Summary Automatic item generation is the process of using models to generate test items with the aid of computer technology. The purpose of this chapter is to describe and illustrate the important role that cognitive models play in the item generation process. A cognitive model for automatic item generation is a representation that highlights the knowledge, skills, competencies, and/or content required to generate new test items. Two types of cognitive models are presented. The first is the logical structures cognitive model. It is used when a specific concept or a set of closely related concepts is operationalized as part of the generative process. This model is often used to implement a main idea, formula, algorithm, and/or logical outcome. The second is the key features cognitive model. It is used when the attributes or features of a task are systematically combined to produce meaningful outcomes across the item feature set. This model is most suitable for measuring students' ability to assemble and apply key features within a domain as well as to solve problems using these key features. An application of each model is presented using a practical example from K--12 science and medicine.},
  chapter = {6},
  isbn = {978-1-118-95658-8},
  keywords = {automatic item generation,cognitive modelling,model-based reasoning,technology and testing}
}

@incollection{gierlUsingComputerizedFormative2018,
  title = {Using {{Computerized Formative Testing}} to {{Support Personalized Learning}} in {{Higher Education}}: {{An Application}} of {{Two Assessment Technologies}}},
  booktitle = {Digital {{Technologies}} and {{Instructional Design}} for {{Personalized Learning}}},
  author = {Gierl, Mark and Bulut, Okan and Zhang, Xinxin},
  editor = {Zheng, Robert},
  year = {2018},
  pages = {99--119},
  publisher = {IGI Global},
  address = {Hershey, PA, USA},
  doi = {10.4018/978-1-5225-3940-7.ch005},
  abstract = {Computerized testing provides many benefits to support formative assessment in higher education. However, the advent of computerized formative testing has raised daunting new challenges, particularly in the areas of item development and test construction. Large numbers of items are required because they are continuously administered to students. Automatic item generation is a relatively new but rapidly evolving assessment technology that may be used to address this challenge. Once the items are generated, tests must be assembled that measure the same content areas with the same difficulty level using different sets of items. Automated test assembly is an assessment technology that may be used to address this challenge. To date, the use of automated methods for item development and test construction has been limited. The purpose of this chapter is to address these limitations by describing and illustrating how recent advances in the technology of assessment can be used to permit computerized formative testing to promote personalized learning.},
  isbn = {978-1-5225-3940-7},
  file = {/Users/colin.madland/Zotero/storage/THJHCFHY/gierlUsingComputerizedFormative2018.pdf}
}

@article{gikandiEnhancingELearningIntegration2021,
  title = {Enhancing {{E-Learning Through Integration}} of {{Online Formative Assessment}} and {{Teaching Presence}}},
  author = {Gikandi, {\relax JW}},
  year = {2021},
  journal = {International Journal of Online Pedagogy and Course Design},
  volume = {11},
  number = {2},
  pages = {48--61},
  issn = {2155-6873},
  doi = {10.4018/IJOPCD.2021040104},
  abstract = {The proliferation of information communication technologies (ICT) continues to increase opportunities for effective pedagogical approaches and online learning. This paper reports a study on integration of online formative assessment from a teaching presence perspective of the community of inquiry (CoI) framework. The effects of this integrative pedagogical approach on students' learning experiences are explored. The study was conducted in a post graduate online course. Case study research design was utilized. The study exemplified the core elements of formative assessment including integration of authentic assessment activities within teaching and learning processes, explicit learning goals, formative feedback, and documentation of evidence of learning. These elements were aligned to the functions of teaching presence, namely design, facilitation, and direct instruction. This approach enhanced meaningful engagement with critical learning experiences including interactive collaboration, critical thinking, reflective thinking, multi-dimensional perspectives, and self-regulation.},
  langid = {english},
  keywords = {EDUCATION,Embedded Assessment,FEEDBACK,Higher Education,Information Communication Technology,INQUIRY,Meaningful Learning,Online Learning,Pedagogical Strategy}
}

@article{gikandiOnlineFormativeAssessment2011,
  title = {Online Formative Assessment in Higher Education: {{A}} Review of the Literature},
  shorttitle = {Online Formative Assessment in Higher Education},
  author = {Gikandi, J.W. and Morrow, D. and Davis, N.E.},
  year = {2011},
  month = dec,
  journal = {Computers \& Education},
  volume = {57},
  number = {4},
  pages = {2333--2351},
  issn = {03601315},
  doi = {10/fbcmcg},
  urldate = {2021-07-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/IJGD23DN/gikandiOnlineFormativeAssessment2011.pdf}
}

@incollection{gikandiTheoryFormativeAssessment2015,
  title = {Towards a {{Theory}} of {{Formative Assessment}} in {{Online Higher Education}}},
  booktitle = {Handbook of {{Research}} on {{Educational Technology Integration}} and {{Active Learning}}},
  author = {Gikandi, Joyce},
  editor = {{Jared Keengwe}},
  year = {2015},
  pages = {292--316},
  publisher = {IGI Global},
  address = {Hershey, PA, USA},
  doi = {10.4018/978-1-4666-8363-1.ch014},
  abstract = {The affordances of online learning have coincided with increasing demand for higher education across disciplines. The need to provide appropriate learning support while fostering self-regulation in online higher education calls for formative assessment to facilitate meaningful learning. This chapter attempts to conceptually generalize the findings of a recent collective case study and develop a relevant theoretical framework for online formative assessment. The theoretical framework is intended to inform successful implementation of formative assessment in online learning contexts. The collective case study purposefully conceptualized formative assessment from a holistic pedagogical approach. Investigating application of formative assessment in the recent study explored multifaceted elements including provision of a variety of embedded authentic assessment activities. The theoretical framework advanced through this chapter is therefore an attempt to coherently unify the diverse elements and techniques from the collective case study, and explicate how this creates an effective pedagogical design to promote meaningful learning.},
  isbn = {978-1-4666-8363-1},
  file = {/Users/colin.madland/Zotero/storage/FNWXW7V9/gikandiTheoryFormativeAssessment2015.pdf}
}

@article{gil-jaurenaLearningOutcomesBased2022,
  title = {Learning Outcomes Based Assessment in Distance Higher Education. {{A}} Case Study},
  author = {{Gil-Jaurena}, In{\'e}s and {Dom{\'i}nguez-Figaredo}, Daniel and {Ballesteros-Vel{\'a}zquez}, Bel{\'e}n},
  year = {2022},
  journal = {Open learning},
  volume = {37},
  number = {2},
  pages = {193--208},
  publisher = {Routledge},
  address = {Harlow},
  issn = {0268-0513},
  doi = {10.1080/02680513.2020.1757419},
  abstract = {This study focuses on an analysis of assessment methods according to expected learning outcomes in courses taught at the Universidad Nacional de Educaci{\'o}n a Distancia (UNED) in Spain. Based on the European Higher Education Area and its learning-centred approach, the TALOE webtool has been used to analyse the internal coherence of 10 Bachelor's and Master's courses. The TALOE tool was developed in a European project and is free and publically available. The article gives a detailed explanation of how the courses' analysis has been carried out. The results indicate that, in general, the courses analysed are internally coherent. Nevertheless, we do indicate the mismatches in both the way the learning outcomes are written and the choice of assessment methods, conditioned by the mass character of certain courses. Finally, we give an example of improvements made in a course and we evaluate the utility of the TALOE tool in course design.},
  keywords = {Assessment,assessment method,Case studies,College Students,Distance Education,Distance learning,Educational objectives,Electronic Learning,Evaluation Methods,Foreign Countries,Higher education,learning outcomes,Outcome Based Education,Student Evaluation}
}

@article{gilbertHowStructureOnline2005,
  title = {How to Structure Online Discussions for Meaningful Discourse: A Case Study},
  shorttitle = {How to Structure Online Discussions for Meaningful Discourse: A Case Study},
  author = {Gilbert, P. K. and Dabbagh, N.},
  year = {2005},
  journal = {British Journal of Educational Technology},
  volume = {36},
  pages = {5--18},
  issn = {1467-8535},
  doi = {10.1111/j.1467-8535.2005.00434.x},
  abstract = {Abstract This study examined the impact of structuredness of asynchronous online discussion protocols and evaluation rubrics on meaningful discourse. Transcripts of twelve online discussions involving 87 participants from four sections of a graduate course entitled Instructional Technology Foundations and Learning Theory were analysed across four semesters. Protocols and evaluation rubrics guiding online discussions in this course ranged from minimal structure or loosely defined protocols in the first section, to high sructure or well defined and comprehensive protocols and evaluation criteria in the fourth section. The analyses revealed that some elements of structure had a significant impact on meaningful discourse. Particularly, guidelines that assisted the facilitation and evaluation of online discussions increased the cognitive quality of student postings promoting a deeper and more meaningful understanding of course content.},
  annotation = {1}
}

@incollection{gillaniIncorporatingInteractivityMultimedia1997,
  title = {Incorporating Interactivity and Multimedia into Web-Based Instruction},
  booktitle = {Web-Based Instruction},
  author = {Gillani, B B and Relan, A},
  editor = {Khan, B. H.},
  year = {1997},
  pages = {231--237},
  publisher = {Educational Technology Publications},
  address = {New Jersey}
}

@article{gillettMappingMazeAssessment2009,
  title = {Mapping the Maze of Assessment an Investigation into Practice},
  author = {Gillett, Andy and Hammond, Angela},
  year = {2009},
  journal = {Active Learning in Higher Education},
  doi = {10/b8st2p},
  abstract = {``The final, definitive version of this article has been published in the Journal, Active Learning in Higher Education, 10 (2) pp.120-137, 2009, copyright SAGE Publications Ltd. on SAGE Journals Online: http://online.sagepub.com/ "},
  pmcid = {null},
  pmid = {null}
}

@article{gillettMappingMazeAssessment2009a,
  title = {Mapping the Maze of Assessment an Investigation into Practice},
  author = {Gillett, Andy and Hammond, Angela},
  year = {2009},
  journal = {Active Learning in Higher Education},
  doi = {10/b8st2p},
  abstract = {``The final, definitive version of this article has been published in the Journal, Active Learning in Higher Education, 10 (2) pp.120-137, 2009, copyright SAGE Publications Ltd. on SAGE Journals Online: http://online.sagepub.com/ "},
  pmcid = {null},
  pmid = {null}
}

@article{gilliardAutomatedSurveillanceEducation2023,
  title = {Automated {{Surveillance}} in {{Education}}},
  author = {Gilliard, Chris and Selwyn, Neil},
  year = {2023},
  journal = {Postdigital science and education},
  volume = {5},
  number = {1},
  pages = {195--205},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2524-485X},
  doi = {10.1007/s42438-022-00295-3},
  keywords = {Education,Educational Philosophy,Educational Technology,Interviews,Technology and Digital Education},
  file = {/Users/colin.madland/Zotero/storage/8LQ3ZZ6A/gilliardAutomatedSurveillanceEducation2023.pdf}
}

@misc{gilliardDigitalRedliningAccess2016,
  title = {Digital {{Redlining}}, {{Access}}, and {{Privacy}}},
  author = {Gilliard, Chris and Culik, Hugh},
  year = {2016},
  month = may,
  journal = {Common Sense Education},
  urldate = {2018-11-29},
  abstract = {Common Sense Education provides educators and students with the resources they need to harness the power of technology for learning and life. Find a free K-12 Digital Citizenship curriculum, reviews of popular EdTech apps, and resources for protecting student privacy.},
  howpublished = {https://www.commonsense.org/education/privacy/blog/digital-redlining-access-privacy},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/4DE2UGJG/digital-redlining-access-privacy.html}
}

@misc{gilliardTaskForceFinancial2019,
  title = {Task {{Force}} on {{Financial Technology}}: {{Banking}} on {{Your Data}}: The {{Role}} of {{Big Data}} in {{Financial Services}}},
  shorttitle = {Task {{Force}} on {{Financial Technology}}},
  author = {Gilliard, Chris},
  year = {2019},
  address = {2128 Rayburn House Office Building, Washington, D.C.},
  urldate = {2019-11-21},
  abstract = {Task Force on Financial Technology: Banking on Your Data: the Role of Big Data in Financial Services},
  copyright = {Text is government work},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/Y6LTK4YV/gilliardTaskForceFinancial2019.pdf;/Users/colin.madland/Zotero/storage/FJINRDSC/110251.html}
}

@book{gillRethinkingSecondaryEducation2014,
  title = {Rethinking {{Secondary Education}}: {{A Human-Centred Approach}}},
  shorttitle = {Rethinking {{Secondary Education}}},
  author = {Gill, Scherto and Thomson, Garrett},
  year = {2014},
  month = jan,
  edition = {0},
  publisher = {Routledge},
  doi = {10.4324/9781315832999},
  urldate = {2023-05-10},
  isbn = {978-1-315-83299-9},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/VTVQNN38/gillRethinkingSecondaryEducation2014.pdf}
}

@article{gioiaSeekingQualitativeRigor2013,
  title = {Seeking {{Qualitative Rigor}} in {{Inductive Research}}: {{Notes}} on the {{Gioia Methodology}}},
  shorttitle = {Seeking {{Qualitative Rigor}} in {{Inductive Research}}},
  author = {Gioia, Dennis A. and Corley, Kevin G. and Hamilton, Aimee L.},
  year = {2013},
  month = jan,
  journal = {Organizational Research Methods},
  volume = {16},
  number = {1},
  pages = {15--31},
  issn = {1094-4281, 1552-7425},
  doi = {10/gcpz72},
  urldate = {2020-07-04},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/2UH5FCWL/gioiaSeekingQualitativeRigor2013.pdf}
}

@article{gleggRightMindedTeachers2005,
  title = {Right-minded Teachers: {{The}} Influence of the Socio-political Context on the Preparation of Teachers in {{British Columbia}}, 1872--2002},
  author = {Glegg, Alastair},
  year = {2005},
  month = apr,
  journal = {Journal of Educational Administration and History},
  volume = {37},
  number = {1},
  pages = {19--37},
  issn = {0022-0620},
  doi = {10.1080/0022062042000336055}
}

@article{glowatzAcademicEngagementTechnology2017,
  title = {Academic {{Engagement}} and {{Technology}}: {{Revisiting}} the {{Technological}}, {{Pedagogical}} and {{Content Knowledge Framework}} ({{TPACK}}) in {{Higher Education}} ({{HE}}): {{The Academics}}' {{Perspectives}}},
  shorttitle = {Academic {{Engagement}} and {{Technology}}},
  author = {Glowatz, Matt and O'Brien, Orna},
  year = {2017},
  month = aug,
  journal = {IAFOR Journal of Education},
  volume = {5},
  number = {SI},
  issn = {21870594},
  doi = {10.22492/ije.5.si.06},
  urldate = {2023-08-03},
  file = {/Users/colin.madland/Zotero/storage/WVJ2FP9V/glowatzAcademicEngagementTechnology2017.pdf}
}

@incollection{gobertDigitalAssessmentEnvironments2016,
  title = {Digital Assessment Environments for Scientific Inquiry Practices},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {Gobert, Janice D. and Sao Pedro, Michael A.},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch21},
  pages = {508--534},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch21},
  abstract = {Summary In this chapter, we provide an overview of the design, data-collection, and data-analysis efforts for a digital learning and assessment environment for scientific inquiry/science practices called Inq-ITS (Inquiry Intelligent Tutoring System). We first present a brief literature review on current science standards, learning sciences research on students' difficulties with scientific inquiry practices, and modern assessment design frameworks. We then describe how we used pilot data from four case studies with hands-on inquiry tasks for middle school students to better understand these difficulties and design various components of the Inq-ITS system to support students' inquiry accordingly. Lastly, we describe how we used key computational techniques from knowledge-engineering and educational data mining to analyze data from students' log files in this environment to (1) automatically score students' inquiry skills, (2) provide teachers with fine-grained, rich, classroom-based formative assessment data on these practices, and (3) react in real time to scaffold students as they engage in inquiry.},
  chapter = {21},
  isbn = {978-1-118-95658-8},
  keywords = {digital assessment environment,educational data mining,Inq-ITS,intelligent tutoring system,scientific inquiry practice}
}

@article{goertlerAssessmentOnlineGerman2018,
  title = {Assessment in {{Online German}}: {{Assessment Methods}} and {{Results}}},
  author = {Goertler, Senta and Gacs, Adam},
  year = {2018},
  journal = {Die Unterrichtspraxis},
  volume = {51},
  number = {2},
  pages = {156--174},
  publisher = {American Association of Teachers of German},
  address = {HOBOKEN},
  issn = {0042-062X},
  doi = {10.1111/tger.12071},
  abstract = {As online educational programs and courses increase (Allen \& Seaman, 2014), it is important to understand the benefits and limitations of this delivery format when assessing students and when comparing learning outcomes. This article addresses the following two questions: (1) What are some of the best practices in assessing language skills online and how do they differ from assessment in face-to-face (F2F) courses? (2) How do learning outcomes differ in online vs. F2F courses? Both questions are answered based on previous research and our own practices and results in second-year German. We found that the most effective online practices are too time-consuming and costly to implement. Poor computer literacy skills and test security can be further issues in online environments. The solution lies in frequent formal and informal assessments. When comparing online with F2F language learning, meta-analyses give online formats a slight advantage over F2F (Means, Toyama, Murphy, Bakia, \& Jones, 2009). In this study no significant differences were found between the F2F and online sections. Noteworthy, however, is that large differences in standard deviations and score ranges between online and F2F classes suggest that online language learning works well for some and not as well for others.},
  keywords = {Analysis,assessment (language),Best Practices,Comparative Analysis,Computer assisted language learning,Computer Assisted Testing,Computer Literacy,Computer Security,computer-assisted language testing,Costs,Curricula,Distance learning,Evaluation Methods,face-to-face interaction,German,German as a second language instruction,German as a second language learning,Language & Linguistics,Language assessment,Language instruction,language proficiency,Language Tests,Learning outcomes,Learning strategies,Linguistics,Meta Analysis,Methods,Michigan State University,Online Courses,Online instruction,Outcomes of Education,Scores,Second Language Instruction,Second Language Learning,Social Sciences,Student Evaluation,Teachers,Teaching,teaching of language,Test Format},
  file = {/Users/colin.madland/Zotero/storage/59YE7Q8J/goertlerAssessmentOnlineGerman2018.pdf}
}

@article{goffMaintainingAcademicStandards2020,
  title = {Maintaining {{Academic Standards}} and {{Integrity}} in {{Online Business Courses}}},
  author = {Goff, Delbert and Johnston, Jarrod and Bouboulis, Bryan S.},
  year = {2020},
  journal = {International Journal of Higher Education},
  volume = {9},
  number = {2},
  pages = {248--257},
  issn = {ISSN-1927-6044},
  doi = {10/ghw6m7},
  abstract = {As the number of online courses being offered at universities has increased dramatically over the past several years, the level of oversight has lagged and created an environment ripe for cheating. We find that students admit to higher levels of cheating in online classes and believe other students also cheat more relative to face-to-face classes. This is likely due to the lack of tools to combat online cheating and the lack of policy from universities. We know from previous studies that business colleges have a comparatively high level of cheating and the amount of cheating at universities has been rising. These trends threaten to create an unfair system where cheaters are rewarded with higher grades than non-cheaters, thereby encouraging otherwise honest students to cheat. This may result in declining and erratic knowledge among university graduates, diminishing the value of a university education.},
  langid = {english},
  keywords = {Business Administration Education,Business Schools,Cheating,College Students,Comparative Analysis,Conventional Instruction,Educational Trends,Ethics,Integrity,Majors (Students),Online Courses,Student Attitudes,Teaching Methods}
}

@article{goldbergPrimerNeuralNetwork2016,
  title = {A {{Primer}} on {{Neural Network Models}} for {{Natural Language Processing}}},
  author = {Goldberg, Yoav},
  year = {2016},
  month = nov,
  journal = {Journal of Artificial Intelligence Research},
  volume = {57},
  pages = {345--420},
  issn = {1076-9757},
  doi = {10.1613/jair.4992},
  urldate = {2023-01-08},
  abstract = {Over the past few years, neural networks have re-emerged as powerful machine-learning models, yielding state-of-the-art results in fields such as image recognition and speech processing. More recently, neural network models started to be applied also to textual natural language signals, again with very promising results. This tutorial surveys neural network models from the perspective of natural language processing research, in an attempt to bring natural-language researchers up to speed with the neural techniques. The tutorial covers input encoding for natural language tasks, feed-forward networks, convolutional networks, recurrent networks and recursive networks, as well as the computation graph abstraction for automatic gradient computation.},
  file = {/Users/colin.madland/Zotero/storage/C9T23R8X/goldbergPrimerNeuralNetwork2016.pdf}
}

@article{goldsteinResponseAssessmentLearning2017,
  title = {A {{Response}} to `{{Assessment}} and {{Learning}}: {{Fields Apart}}?'},
  shorttitle = {A {{Response}} to `{{Assessment}} and {{Learning}}},
  author = {Goldstein, Harvey},
  year = {2017},
  month = jul,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {24},
  number = {3},
  pages = {388--393},
  issn = {0969-594X, 1465-329X},
  doi = {10.1080/0969594X.2017.1319338},
  urldate = {2023-03-20},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/EF2FCUWS/goldsteinResponseAssessmentLearning2017.pdf}
}

@article{gomez-espinaAssessmentSocrativePlatform2019,
  title = {Assessment of the {{Socrative Platform}} as an {{Interactive}} and {{Didactic Tool}} in the {{Performance Improvement}} of {{STEM University Students}}},
  author = {{G{\'o}mez-Espina}, Roberto and {Rodriguez-Oroz}, Delia and Ch{\'a}vez, Manuel and Saavedra, Cristian and Bravo, Mar{\'i}a Jes{\'u}s},
  year = {2019},
  month = dec,
  journal = {Higher Learning Research Communications},
  volume = {9},
  number = {2},
  publisher = {Higher Learning Research Communications},
  issn = {2157-6254},
  doi = {10.18870/hlrc.v9i2.438},
  abstract = {This manuscript collects and analyzes students' academic results related to the change in teaching methodologies used in different subjects of different science and engineering university courses between 2013 and 2016 from traditional to active methodologies. Socrative, a platform that has been designed for the educational field, was introduced, allowing the use of personal mobile devices (laptops, smartphones, and tablets) consistent with the "Bring Your Own Device" methodology. The active methodology implemented allowed students to improve their academic results while learning and improving their passing rates.},
  keywords = {Active Learning,College Instruction,College Students,Computer Uses in Education,Engineering Education,Handheld Devices,Instructional Effectiveness,Science Education,STEM Education,Student Attitudes,Student Improvement},
  file = {/Users/colin.madland/Zotero/storage/ZRCY7UC3/gomez-espinaAssessmentSocrativePlatform2019.pdf}
}

@incollection{gonzalez-brenesBayesianNetworks2016,
  title = {Bayesian Networks},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {{Gonz{\'a}lez-Brenes}, Jos{\'e} P. and Behrens, John T. and Mislevy, Robert J. and Levy, Roy and DiCerbo, Kristen E.},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch14},
  pages = {328--353},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch14},
  abstract = {Summary Bayesian Networks or Bayes Nets (BNs) are a general-purpose computational and statistical framework. BNs allow modeling a broad range of phenomena by reasoning about collected evidence and by updating beliefs in light of new data. In the context of supporting assessment, BNs are interesting because they align with the perspective of evidence-centered assessment design. In this chapter, we discuss how BNs can be used to formalize substantively grounded reasoning processes, we describe the statistical formalism of BNs through some core equations, we illustrate the flexibility of BNs by providing various extensions in simple graphical representations, and we provide examples for modeling cognition across educational, psychological, and linguistic contexts.},
  chapter = {14},
  isbn = {978-1-118-95658-8},
  keywords = {Bayesian networks,cognitive models,evidence centered design,probability}
}

@article{gonzalez-calatayudArtificialIntelligenceStudent2021,
  title = {Artificial {{Intelligence}} for {{Student Assessment}}: {{A Systematic Review}}},
  shorttitle = {Artificial {{Intelligence}} for {{Student Assessment}}},
  author = {{Gonz{\'a}lez-Calatayud}, V{\'i}ctor and {Prendes-Espinosa}, Paz and {Roig-Vila}, Rosabel},
  year = {2021},
  month = jun,
  journal = {Applied Sciences},
  volume = {11},
  number = {12},
  pages = {5467},
  issn = {2076-3417},
  doi = {10.3390/app11125467},
  urldate = {2023-01-15},
  abstract = {Artificial Intelligence (AI) is being implemented in more and more fields, including education. The main uses of AI in education are related to tutoring and assessment. This paper analyzes the use of AI for student assessment based on a systematic review. For this purpose, a search was carried out in two databases: Scopus and Web of Science. A total of 454 papers were found and, after analyzing them according to the PRISMA Statement, a total of 22 papers were selected. It is clear from the studies analyzed that, in most of them, the pedagogy underlying the educational action is not reflected. Similarly, formative evaluation seems to be the main use of AI. Another of the main functionalities of AI in assessment is for the automatic grading of students. Several studies analyze the differences between the use of AI and its non-use. We discuss the results and conclude the need for teacher training and further research to understand the possibilities of AI in educational assessment, mainly in other educational levels than higher education. Moreover, it is necessary to increase the wealth of research which focuses on educational aspects more than technical development around AI.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/SE24GUAE/gonzalez-calatayudArtificialIntelligenceStudent2021.pdf}
}

@article{gonzalez-gomezExaminingEffectOnline2020,
  ids = {gonzalez-gomezExaminingEffectOnline2020a},
  title = {Examining the {{Effect}} of an {{Online Formative Assessment Tool}} ({{OFAT}}) of {{Students}}' {{Motivation}} and {{Achievement}} for a {{University Science Education}}},
  author = {{Gonz{\'a}lez-G{\'o}mez}, David and Jeong, Jin Su and {Ca{\~n}ada-Ca{\~n}ada}, Florentina},
  year = {2020},
  journal = {Journal of Baltic Science Education},
  volume = {19},
  number = {3},
  pages = {401--414},
  publisher = {Journal of Baltic Science Education},
  issn = {ISSN-1648-3898},
  doi = {10/gmbvz6},
  abstract = {Online formative assessment is still challenging although it is getting an increased attention as a significant tool for diagnosing and analysing students' motivation and achievement in various education domains. This research examines the effects of an online formative assessment tool (OFAT) about science motivation and achievement in second-year students' university education during four consecutive academic years, 2014 to 2018. A research on the basis of a randomized experimental design was conducted that assigned groups used an OFAT along with various assessments that students participated. A total of 311 students enrolled in the subject take part in the research, respectively 94, 89, 59 and 71 students. Particularly, the OFAT is offering feedback from students, feedback from lecturers and adaptive assignments. Here, data contained student motivation survey data, standardized achievement pre- and post-test data and students' log records. The results of multiple tier analyses exposed positive effects about students' motivation and achievement. Based on usage measurements, students' intensity offers the positive effects about students' motivation and achievement. Furthermore, along with overall students' improved performance, the effects of high-performing students' achievement were higher. Therefore, the results acquired meaningfully contribute to recover main drawbacks and difficulties of traditional science learning programs.},
  langid = {english},
  keywords = {Assignments,College Science,Educational Technology,Electronic Learning,Feedback (Response),Foreign Countries,Formative Evaluation,Internet,Science Achievement,Spain,Student Attitudes,Student Evaluation,Student Motivation,Undergraduate Students},
  file = {/Users/colin.madland/Zotero/storage/L7QJRU2V/gonzalez-gomezExaminingEffectOnline2020.pdf}
}

@article{goodfellowSupportingWritingAssessment2005,
  title = {Supporting Writing for Assessment in Online Learning},
  author = {Goodfellow, Robin and Lea, Mary R.},
  year = {2005},
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {30},
  number = {3},
  pages = {261--271},
  publisher = {{Taylor and Francis Ltd}},
  issn = {0260-2938},
  doi = {10/fg58w7},
  abstract = {This article explores some specific issues involved in online learning and assessment. It draws on data from a postgraduate course for professional educators, delivered globally online, and highlights the relationship between students' online discussion and their written assessed work, arguing that we need to focus on both of these in terms of the writing demands they make on students. In so doing it utilizes a theoretical framework which conceptualizes writing as contextualized social practice. The paper illustrates the complexity of the rhetorical demands being made on students in these new environments of teaching and learning and, in focusing on writing, complements present approaches to online learning which have, to date, tended towards collaborative and constructivist perspectives. The article highlights the relationship between pedagogy, technology and assessment. It concludes with a discussion of the design of an online writing resource to support student writers on this particular masters programme.},
  keywords = {Constructivism (Learning),Cooperation,Educational Technology,Evaluation Methods,Instructional Design,Masters Programs,Online Courses,Student Evaluation,Teaching Methods,Writing (Composition),Writing Instruction}
}

@article{goreRefiningAssessmentPractice2009,
  title = {Refining Assessment Practice in the Social Sciences},
  author = {Gore, Jennifer and Elsworth, Wendy and Griffiths, Tom G. and Parkes, Robert John and Ellis, Hywel},
  year = {2009},
  journal = {null},
  doi = {null},
  abstract = {N/A: no abstract available},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@article{goretzkoExploratoryFactorAnalysis2021,
  title = {Exploratory Factor Analysis: {{Current}} Use, Methodological Developments and Recommendations for Good Practice},
  author = {Goretzko, David and Pham, Trang Thien Huong and B{\"u}hner, Markus},
  year = {2021},
  month = jul,
  journal = {Current Psychology},
  volume = {40},
  number = {7},
  pages = {3510--3521},
  issn = {1936-4733},
  doi = {10.1007/s12144-019-00300-2},
  abstract = {Psychological research often relies on Exploratory Factor Analysis (EFA). As the outcome of the analysis highly depends on the chosen settings, there is a strong need for guidelines in this context. Therefore, we want to examine the recent methodological developments as well as the current practice in psychological research. We reviewed ten years of studies containing EFAs and contrasted them with new methodological options. We focused on four major issues: an adequate sample size, the extraction method, the rotation method and the factor retention criterion determining the number of factors. Finally, we present modified recommendations based on these reviewed empirical studies and practical considerations.},
  file = {/Users/colin.madland/Zotero/storage/8E5WYKWY/goretzkoExploratoryFactorAnalysis2021.pdf}
}

@article{gorgunPolytomousScoringApproach2021,
  title = {A {{Polytomous Scoring Approach}} to {{Handle Not-Reached Items}} in {{Low-Stakes Assessmentsa}}},
  author = {Gorgun, Guher and Bulut, Okan},
  year = {2021},
  month = feb,
  journal = {Educational and Psychological Measurement},
  pages = {001316442199121},
  issn = {0013-1644, 1552-3888},
  doi = {10/gjqs44},
  urldate = {2021-07-17},
  abstract = {In low-stakes assessments, some students may not reach the end of the test and leave some items unanswered due to various reasons (e.g., lack of test-taking motivation, poor time management, and test speededness). Not-reached items are often treated as incorrect or not-administered in the scoring process. However, when the proportion of not-reached items is high, these traditional approaches may yield biased scores and thereby threatening the validity of test results. In this study, we propose a polytomous scoring approach for handling not-reached items and compare its performance with those of the traditional scoring approaches. Real data from a low-stakes math assessment administered to second and third graders were used. The assessment consisted of 40 short-answer items focusing on addition and subtraction. The students were instructed to answer as many items as possible within 5 minutes. Using the traditional scoring approaches, students' responses for not-reached items were treated as either not-administered or incorrect in the scoring process. With the proposed scoring approach, students' nonmissing responses were scored polytomously based on how accurately and rapidly they responded to the items to reduce the impact of not-reached items on ability estimation. The traditional and polytomous scoring approaches were compared based on several evaluation criteria, such as model fit indices, test information function, and bias. The results indicated that the polytomous scoring approaches outperformed the traditional approaches. The complete case simulation corroborated our empirical findings that the scoring approach in which nonmissing items were scored polytomously and not-reached items were considered not-administered performed the best. Implications of the polytomous scoring approach for low-stakes assessments were discussed.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/4SCL48F9/gorgunPolytomousScoringApproach2021.pdf}
}

@article{gorskiGoodIntentionsAre2008,
  title = {Good Intentions Are Not Enough: A Decolonizing Intercultural Education},
  author = {Gorski, Paul C.},
  year = {2008},
  journal = {Intercultural Education},
  volume = {19},
  number = {6},
  pages = {515--525},
  issn = {1467-5986},
  doi = {10.1080/14675980802568319},
  abstract = {Despite unquestionably good intentions on the part of most people who call themselves intercultural educators, most intercultural education practice supports, rather than challenges, dominant hegemony, prevailing social hierarchies, and inequitable distributions of power and privilege. In this essay I describe a philosophy of decolonizing intercultural education--an intercultural education dedicated, first and foremost, to dismantling dominant hegemony, hierarchies, and concentrations of power and control. I argue that attaining such an intercultural education requires not only subtle shifts in practice and personal relationships, but also important shifts of consciousness that prepare us to see and react to the socio-political contexts that so heavily influence education theory and practice.},
  keywords = {Change Strategies,Critical Theory,Educational Change,Educational Practices,Instructional Design,intercultural dialogue,intercultural education,Multicultural Education,Political Influences,Shift Studies,Social Influences,social justice,Theory Practice Relationship}
}

@article{gotchSystematicReviewAssessment2014,
  title = {A Systematic Review of Assessment Literacy Measures},
  author = {Gotch, Chad and French, Brian F.},
  year = {2014},
  journal = {Educational Measurement: Issues and Practice},
  volume = {33},
  pages = {14--18},
  doi = {10/gcpg4p},
  abstract = {This work systematically reviews teacher assessment literacy measures within the context of contemporary teacher evaluation policy. In this study, the researchers collected objective tests of assessment knowledge, teacher self-reports, and rubrics to evaluate teachers' work in assessment literacy studies from 1991 to 2012. Then they evaluated the psychometric work from these measures against a set of claims related to score interpretation and use. Across the 36 measures reviewed, they found support for these claims was weak. This outcome highlights the need for increased work on assessment literacy measures in the educational measurement field. The authors conclude with recommendations and a resource to inform a research agenda focused on assessment literacy measurement to inform policy and practice.},
  file = {/Users/colin.madland/Zotero/storage/2Y4EGGAR/gotchSystematicReviewAssessment2014.pdf;/Users/colin.madland/Zotero/storage/KVD65NNP/gotchSystematicReviewAssessment2014.docx}
}

@article{gotchTeacherOutcomesStatewide2019,
  title = {Teacher Outcomes from a Statewide Initiative to Build Assessment Literacy},
  author = {Gotch, Chad M. and McLean, Cristen},
  year = {2019},
  journal = {Studies in Educational Evaluation},
  volume = {62},
  pages = {30--36},
  issn = {0191491X},
  doi = {10/ghjbnh},
  urldate = {2021-07-28},
  langid = {english}
}

@article{gouldPotentialUseClassroom2016,
  title = {Potential {{Use}} of {{Classroom Response Systems}} ({{CRS}}, {{Clickers}}) in {{Foods}}, {{Nutrition}}, and {{Dietetics Higher Education}}},
  author = {Gould, {\relax SM}},
  year = {2016},
  journal = {Journal of Nutrition Education and Behavior},
  volume = {48},
  number = {9},
  pages = {669-+},
  issn = {1499-4046},
  doi = {10.1016/j.jneb.2016.06.004},
  abstract = {Although hundreds of articles have been published about the use of classroom response systems (CRS, clickers) in higher education, few address the use in foods, nutrition, and dietetics courses, especially upper-division, major courses. This technology has the potential to increase student engagement, motivation, assessment, and, possibly, learning. Thoughtfully designed questions may stimulate discussions, especially about challenging nutrition topics. This article presents the viability and potential benefits for the use of CRS in foods, nutrition, and dietetics classes through a brief literature summary, overview of the author's experiences, and guidance for implementing this technology.},
  langid = {english},
  keywords = {BENEFITS,classroom response systems,dietetics education,educational technology,ENGAGEMENT,foods,INTERACTIVITY,LEARNING OUTCOMES,nutrition,PARTICIPATION,pedagogy,PERCEPTIONS,SCIENCE,STUDENTS,TECHNOLOGY}
}

@article{gourlayStudentEngagementTyranny2015,
  title = {`{{Student}} Engagement' and the Tyranny of Participation},
  author = {Gourlay, Lesley},
  year = {2015},
  month = may,
  journal = {Teaching in Higher Education},
  volume = {20},
  number = {4},
  pages = {402--411},
  issn = {1356-2517, 1470-1294},
  doi = {10/gfw6xz},
  urldate = {2021-02-12},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/RJQTI6LV/gourlayStudentEngagementTyranny2015.pdf}
}

@misc{governmentofcanadaDailyFinancialInformation2020,
  title = {The {{Daily}} --- {{Financial}} Information of Universities for the 2018/2019 School Year and Projected Impact of {{COVID}}--19 for 2020/2021},
  author = {{Government of Canada}, Statistics Canada},
  year = {2020},
  month = oct,
  urldate = {2020-10-14},
  abstract = {Canada's 147 public universities spent \$28.9 billion during the 2018/2019 academic year and had revenues of \$30.7 billion. To assess the potential financial impact of the pandemic on universities, projection scenarios were developed and indicate that they could be facing losses ranging from \$377 million (-0.8\%) to \$3.4 billion (-7.5\%) in 2020/2021.},
  howpublished = {https://www150.statcan.gc.ca/n1/daily-quotidien/201008/dq201008b-eng.htm},
  langid = {english},
  annotation = {Last Modified: 2020-10-08},
  file = {/Users/colin.madland/Zotero/storage/UFKPAW2H/governmentofcanadaDailyFinancialInformation2020.pdf}
}

@misc{governmentofcanadaIndigenousResearchDefinition2018,
  title = {Indigenous {{Research Definition}}},
  author = {{Government of Canada}, {\relax SSHRC}},
  year = {2018},
  urldate = {2019-03-27},
  abstract = {Social Sciences and Humanities Research Council},
  howpublished = {http://www.sshrc-crsh.gc.ca/funding-financement/programs-programmes/definitions-eng.aspx\#a11},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/EBW5UERP/definitions-eng.html}
}

@misc{governmentofcanadaSocialSciencesHumanities2018,
  title = {Social {{Sciences}} and {{Humanities Research Council}}},
  author = {{Government of Canada}, Social Sciences {and} Humanities Research Council},
  year = {2018},
  month = aug,
  urldate = {2019-03-25},
  abstract = {Social Sciences and Humanities Research Council},
  howpublished = {http://www.sshrc-crsh.gc.ca/society-societe/community-communite/ifca-iac/03-aboriginal\_peoples\_in\_Canada\_report-les\_peuples\_autochtones\_en\_Canada\_rapport-eng.aspx},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/P4GI8NQL/03-aboriginal_peoples_in_Canada_report-les_peuples_autochtones_en_Canada_rapport-eng.html}
}

@article{gowerLetThemEat2021,
  title = {Let {{Them Eat Cake}}: {{Why}} the {{Inherent Bias}} in {{Professor Grading Should Change}} to {{Individual Performance Assessments}}},
  shorttitle = {Let {{Them Eat Cake}}},
  author = {Gower, Kim},
  year = {2021},
  journal = {Journal of Organizational Psychology},
  volume = {21},
  number = {5},
  issn = {2158-3609, 2158-3609},
  doi = {10.33423/jop.v21i5.4724},
  urldate = {2024-09-26},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/gowerLetThemEat2021.pdf}
}

@article{gradisekInsightsLearningExamination2021,
  title = {Insights into Learning and Examination Experience of Higher Education Students during the {{Covid-19}} Pandemic},
  author = {Gradisek, P and Polak, A},
  year = {2021},
  journal = {Sodobna Pedagogika-Journal Of Contemporary Educational Studies},
  volume = {72},
  pages = {286--307},
  issn = {0038-0474},
  abstract = {The study process in higher education in Slovenia and worldwide was strongly affected by the Covid-19 pandemic, which began in the second semester of the 2019/2020 academic year. There was a sudden shift from face-to-face teaching and learning to virtual teaching and learning; this shift was facilitated by various digital platforms such as Moodle, Zoom and MS Teams and exam applications such as Exam.net. The process of student integration was affected, including formal and informal student interactions with peers, formal and informal teacher-student interactions and students' psychological needs of relatedness, competence and autonomy. In a sample of 110 students of the first year of different study programmes at the University of Ljubljana, Faculty of Education, we investigated how specific study methods and tasks contributed to the students' competence development and how demanding they were for the students during the Covid-19 pandemic. We also analysed the students' perceptions of the online exam process. The results showed a positive contribution of the chosen adapted teaching and learning methods and tasks to the students' competence development and that the students successfully mastered the new skills related to online exams. Furthermore, various study difficulties and examination challenges were mentioned and analysed. Although online teaching and learning is successful, it cannot replace the face-to-face experience, especially in pedagogical faculties where university teachers are important role models for future teachers.},
  langid = {english},
  keywords = {assessment,Covid-19 pandemic,higher education,learning,MOTIVATION,No DOI found,online learning,teaching}
}

@article{Grainger_2008,
  title = {Judging Quality through Substantive Conversations between Markers},
  author = {Grainger, Peter and Purnell, Ken and Zipf, Reyna},
  year = {2008},
  journal = {Assessment \& Evaluation in Higher Education},
  doi = {10/fwpdt3},
  abstract = {Decisions by markers about quality in student work remain confusing to most students and markers. This may in part be due to the relatively subjective nature of what constitutes a quality response to an assessment task. This paper reports on an experiment that documented the process of decision-making by multiple markers at a university who assessed the same written student assessment responses. The paper analyses the professional conversations between those markers around their conceptions of quality in the student assessment responses. It was found that the markers appeared to share common understandings of quality in the context of the marking criteria and standards across the achievement levels awarded. However, despite these apparently shared notions of quality, in some cases different levels of achievement were awarded to the same student assessment responses. This suggests that that there is a clear need for explicitly stated standard descriptors for each level of achievement and that this must be ...},
  mag_id = {2008234076},
  pmcid = {null},
  pmid = {null}
}

@article{grantUsingAssessmentStrategically2016,
  title = {Using Assessment Strategically to Gestate a Student Thesis Learning through Community},
  author = {Grant, Carolyn (Callie)},
  year = {2016},
  journal = {South African journal of higher education},
  doi = {10/ghp9cm},
  abstract = {In the context of higher education in South Africa and drawing on the author's experience as a lecturer in two higher education institutions (HEIs), this article presents her attempts to bring together - and into balance - teaching, supervision and research in an endeavour to offer a transformative learning experience for her post graduate students. It does this by foregrounding student assessment in the Master of Education (MEd) degree in the field of Educational Leadership and Management (ELM) where the development of a half thesis, underpinned by research, stands as the evidence of success. The author suggests that the MEd (ELM) degree be conceptualised differently in order that the half thesis be permitted to gestate over a two-year period. Within this conceptualisation, she argues that inspired teaching and meaningful research is best attained through a community of learning approach which seeks to foreground participatory learning, the advancement of scholarly discourse and the development of student agency. Through the use of a case study, the author provides evidence to suggest that a range of authentic assessment strategies which are purposeful and in alignment with the teaching strategies, the content and the intended outcomes of the qualification being taught are essential. She further argues that well-crafted, formative, recursive and sustainable feedback is an essential part of the gestation process.},
  pmcid = {null},
  pmid = {null}
}

@article{grantUsingAssessmentStrategically2016a,
  title = {Using Assessment Strategically to Gestate a Student Thesis Learning through Community},
  author = {Grant, Carolyn (Callie)},
  year = {2016},
  journal = {South African journal of higher education},
  doi = {10/ghp9cm},
  abstract = {In the context of higher education in South Africa and drawing on the author's experience as a lecturer in two higher education institutions (HEIs), this article presents her attempts to bring together - and into balance - teaching, supervision and research in an endeavour to offer a transformative learning experience for her post graduate students. It does this by foregrounding student assessment in the Master of Education (MEd) degree in the field of Educational Leadership and Management (ELM) where the development of a half thesis, underpinned by research, stands as the evidence of success. The author suggests that the MEd (ELM) degree be conceptualised differently in order that the half thesis be permitted to gestate over a two-year period. Within this conceptualisation, she argues that inspired teaching and meaningful research is best attained through a community of learning approach which seeks to foreground participatory learning, the advancement of scholarly discourse and the development of student agency. Through the use of a case study, the author provides evidence to suggest that a range of authentic assessment strategies which are purposeful and in alignment with the teaching strategies, the content and the intended outcomes of the qualification being taught are essential. She further argues that well-crafted, formative, recursive and sustainable feedback is an essential part of the gestation process.},
  pmcid = {null},
  pmid = {null}
}

@article{grantWritingCompanyOther2006,
  title = {Writing in the Company of Other Women. {{Exceeding}} the Boundaries.},
  author = {Grant, B},
  year = {2006},
  journal = {Studies in Higher Education},
  volume = {31},
  number = {4},
  pages = {483--495}
}

@article{gravettDifferentVoicesDifferent2022,
  title = {Different Voices, Different Bodies: Presence--Absence in the Digital University},
  shorttitle = {Different Voices, Different Bodies},
  author = {Gravett, Karen},
  year = {2022},
  month = nov,
  journal = {Learning, Media and Technology},
  pages = {1--13},
  issn = {1743-9884, 1743-9892},
  doi = {10.1080/17439884.2022.2150637},
  urldate = {2022-12-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/2CYMW6MM/gravettDifferentVoicesDifferent2022.pdf}
}

@inbook{greeneSelfRegulation2023,
  title = {Self-{{Regulation}}},
  booktitle = {Handbook of {{Educational Psychology}}},
  author = {Greene, Jeffrey A. and Bernacki, Matthew L. and Hadwin, Allyson F.},
  year = {2023},
  month = sep,
  edition = {4},
  pages = {314--334},
  publisher = {Routledge},
  address = {New York},
  doi = {10.4324/9780429433726-17},
  urldate = {2024-11-05},
  collaborator = {Schutz, Paul A. and Muis, Krista R.},
  isbn = {978-0-429-43372-6},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/greeneSelfRegulation2023.pdf}
}

@misc{greeneValerieIrvineColin,
  title = {Valerie {{Irvine}} and {{Colin Madland}}},
  author = {Greene, Terry},
  urldate = {2024-10-10},
  abstract = {Valerie Irvine (@\_valeriei) and Colin Madland (@colinmadland): The Open/Technology in Education, Society, and Scholarship Association (@otessa\_org) is being sim},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/V27X8JQY/valerie-irvine-and-colin-madland--23026170.html}
}

@article{greenleafServantLeadershipJourney1979,
  title = {Servant Leadership: {{A}} Journey into the Nature of Legitimate Power and Greatness},
  author = {Greenleaf, Robert K.},
  year = {1979},
  month = jun,
  journal = {Business Horizons},
  doi = {10.1016/0007-6813(79)90092-2},
  abstract = {A classic work on leadership for business men and women, government leaders and all persons in positions of authority.}
}

@incollection{greenoOpportunitiesLearnPractice2008,
  title = {Opportunities to {{Learn}} in {{Practice}} and {{Identity}}},
  booktitle = {Assessment, {{Equity}}, and {{Opportunity}} to {{Learn}}},
  author = {Greeno, James G. and Gresalfi, Melissa S.},
  editor = {Pullin, Diana C. and Haertel, Edward H. and Gee, James Paul and Young, Lauren Jones and Moss, Pamela A.},
  year = {2008},
  series = {Learning in {{Doing}}: {{Social}}, {{Cognitive}} and {{Computational Perspectives}}},
  pages = {170--199},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9780511802157.009},
  abstract = {Following Suchman, (1985), Lave, (1988), Lave and Wenger (1991), Hutchins, (1995a), Engestr{\"o}m, (1999), and others, we take a situative perspective in our research and, in this chapter, regarding opportunity to learn (OTL). Conducting analyses of learning with this perspective involves defining activity systems as the unit of analysis, which includes one or more persons interacting with each other and with material and informational resources that are present in the setting. The main emphasis of the situative perspective is on how learning by individuals and groups is accomplished through interaction between elements of an activity system. Of course there are changes in the participating individuals' mental structures, including schemata, but these are not the primary focus of our analyses. In this view, learning by an individual in a community is conceptualized as a trajectory of that person's participation in the community -- a path with a past and present, shaping possibilities for future participation. Learning by a group or community is also conceptualized as a trajectory -- a path that corresponds to change in the community's practices.A SITUATIVE PERSPECTIVE ON LEARNINGIndividuals Learning in a CommunityLave and Wenger (1991) outlined a situative framework on learning by considering the trajectories of individuals' participation as they become members of a community of practice. As individuals initially join a new activity, their involvement is limited to peripheral participation.},
  isbn = {978-0-521-88045-9}
}

@article{greenReconceptualisingHigherEducation2010,
  title = {Reconceptualising Higher Education Pedagogy in Online Learning},
  author = {Green, Nicole C. and Edwards, Helen and Wolodko, Brenda and Stewart, Cherry and Brooks, Margaret and Littledyke, Ros},
  year = {2010},
  journal = {Distance education},
  volume = {31},
  number = {3},
  pages = {257--273},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0158-7919},
  doi = {10.1080/01587919.2010.513951},
  abstract = {The purpose of this collaborative inquiry project was to examine teacher education practices in two early childhood degree programmes in a school of education at a regional university in Australia. All students are enrolled in these online courses as distance learners. The reconceptualised online pedagogy immersed students, peers and their lecturers in 'teaching through assessment' (Edwards, 2010) in a collaborative online environment that mirrors the complexity that students are experiencing in their workplaces. This article describes the pedagogical and conceptual underpinnings we used to reconceptualise our degree programmes. It also outlines our evolving conceptualisations of learning as knowledge creation (Hong \& Sullivan, 2009) in the context of our teaching and learning in online courses.},
  keywords = {Alignment (Education),Australia,Concept Formation,Cooperative learning,Curricula,Curriculum,Curriculum Development,Distance Education,Distance learning,Early Childhood Education,Education & Educational Research,Educational Practices,Electronic Learning,Foreign Countries,Formative evaluation,Higher education,Instructional Design,knowledge creation,Learning,Online Courses,Online learning,Online teaching,Postsecondary education,Preschool teachers,Program Descriptions,Social Sciences,sociocultural-historical theory,Student assessment,Teacher education,Teacher Education Curriculum,Teacher Education Programs,Teaching methods,Teaching process,teaching through assessment,Tertiary education,Transformative Learning,University of New England,University teaching}
}

@article{greenUsingElectronicResume2020,
  title = {Using an {{Electronic Resume Analyzer Portal}} ({{eRAP}}) to {{Improve College Graduates Employability}}},
  author = {Green, Nathan and Liu, Michelle and Murphy, Diane},
  year = {2020},
  month = jun,
  journal = {Information Systems Education Journal},
  volume = {18},
  number = {3},
  pages = {28--37},
  publisher = {Information Systems Education Journal},
  issn = {1545-679X},
  abstract = {Finding the first full-time, major-related job is a challenge faced by most college students, particularly those who have not gained much working experience before entering the job market. This challenge is amplified for the students majoring in Information Technology (IT), and cybersecurity in particular, due to the constantly changing technology landscape, intensively competitive markets, and increasingly high expectations from employers on their recruits. While the job demand is high in these fields, it is still difficult for recent college graduates to enter the field. This study shows the initial results of a tool called e-RAP which allows the students to submit their current resumes, obtain automatic feedback and a rating report, and consequently take actions to strengthen their portfolio. The authors employ machine learning and natural language processing (NLP) to create a resume analysis and reporting tool. The methodology section provides an overview of the e-RAP analysis process, followed by elaborations on data curation, data collection, and analysis techniques. Several visual examples of the reports generated by e-RAP illustrate the value of the tool in helping enhance students' resumes and eventually the skills areas they need to work on or highlight. A sample of more than 60 resumes were processed through e-RAP and the results were evaluated for potential resume improvements. The future direction includes systematic evaluation of the effectiveness of e-RAP and its impact on our student's ability to get high-quality positions. Diving deeper into the various types of cybersecurity positions is also planned.},
  keywords = {Career Readiness,College Graduates,Computer Security,Employment Potential,Feedback (Response),Information Technology,Job Applicants,Majors (Students),Natural Language Processing,No DOI found,Portfolio Assessment,Resumes (Personal)}
}

@article{grierFormativeAssessmentGameBased2021,
  title = {Formative {{Assessment}} with {{Game-Based Technology}}},
  author = {Grier, Donovon and Lindt, Suzanne F. and Miller, Stacia C.},
  year = {2021},
  month = jan,
  journal = {International Journal of Technology in Education and Science},
  volume = {5},
  number = {2},
  pages = {193--202},
  publisher = {{International Journal of Technology in Education and Science}},
  issn = {2651-5369},
  doi = {10.46328/ijtes.97},
  abstract = {The purpose of the current research was to determine the types of educational technology preferred by students and instructors, and to compare formative and summative scores within student classes. During a unit of study within a semester-long class, 44 volunteer student participants were administered four technology-based assessments designed to help them prepare for the summative exam. Following the summative assessment, students were asked to complete a feedback form to explain what type of technology assessment they felt was most helpful in providing them with feedback on their knowledge and which was most interesting to use. Instructors also provided feedback on ease of use and collected students' scores on formative and summative assessments. The results of this study suggest that technology-based formative feedback can be effective in helping students prepare for summative exams and that students mostly preferred competitive and fun tools that provide immediate feedback.},
  keywords = {College Students,Computer Assisted Testing,Educational Technology,Formative Evaluation,Game Based Learning,Student Attitudes,Summative Evaluation,Technology Uses in Education},
  file = {/Users/colin.madland/Zotero/storage/HU8P22MP/grierFormativeAssessmentGameBased2021.pdf}
}

@book{griffinAssessmentTeaching21st2015,
  title = {Assessment and {{Teaching}} of 21st {{Century Skills}}},
  editor = {Griffin, Patrick and Care, Esther},
  year = {2015},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-94-017-9395-7},
  urldate = {2020-12-20},
  isbn = {978-94-017-9394-0 978-94-017-9395-7},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/MXK5MV4F/griffinAssessmentTeaching21st2015.pdf}
}

@book{grolemundDataScience,
  title = {R for {{Data Science}}},
  author = {Grolemund, Garrett and Wickham, Hadley},
  urldate = {2020-01-09},
  abstract = {This book will teach you how to do data science with R: You'll learn how to get your data into R, get it into the most useful structure, transform it, visualise it and model it. In this book, you will find a practicum of skills for data science. Just as a chemist learns how to clean test tubes and stock a lab, you'll learn how to clean data and draw plots---and many other things besides. These are the skills that allow data science to happen, and here you will find the best practices for doing each of these things with R. You'll learn how to use the grammar of graphics, literate programming, and reproducible research to save time. You'll also learn how to manage cognitive resources to facilitate discoveries when wrangling, visualising, and exploring data.},
  file = {/Users/colin.madland/Zotero/storage/RC3NHWKT/r4ds.had.co.nz.html}
}

@book{grolemundHandsOnProgramming,
  title = {Hands-{{On Programming}} with {{R}}},
  author = {Grolemund, Garrett},
  urldate = {2020-01-09},
  abstract = {This book will teach you how to program in R, with hands-on examples. I wrote it for non-programmers to provide a friendly introduction to the R language. You'll learn how to load data, assemble and disassemble data objects, navigate R's environment system, write your own functions, and use all of R's programming tools. Throughout the book, you'll use your newfound skills to solve practical data science problems.},
  file = {/Users/colin.madland/Zotero/storage/XYJUSTM2/hopr.html}
}

@incollection{grolnickContextsSupportingSelfregulated2015,
  title = {Contexts Supporting Self-Regulated Learning at School Transitions.},
  booktitle = {Self-Regulated Learning Interventions with at-Risk Youth: {{Enhancing}} Adaptability, Performance, and Well-Being.},
  author = {Grolnick, Wendy S. and {Raftery-Helmer}, Jacquelyn N.},
  editor = {Cleary, Timothy},
  year = {2015},
  pages = {251--276},
  publisher = {American Psychological Association},
  address = {Washington},
  doi = {10.1037/14641-012},
  urldate = {2020-02-13},
  isbn = {978-1-4338-1987-2 978-1-4338-1988-9},
  langid = {english}
}

@article{grzedaTeamBuildingOnline2008,
  title = {Team {{Building}} in an {{Online Organizational Behavior Course}}.},
  author = {Grzeda, Maurice and Haq, Rana and LeBrasseur, Rolland},
  year = {2008},
  journal = {Journal of Education for Business},
  volume = {83},
  pages = {275--282},
  issn = {08832323},
  doi = {Article},
  abstract = {The authors describe the development and delivery of a team-building exercise in an online organizational behavior undergraduate course. Qualitative data of student perceptions, collected at the end of the course, revealed both positive and negative reactions to various aspects of the team-building exercise. Based on these reactions, the authors discuss needed improvements in the assignment. They conclude by considering how their experience with the team-building exercise contributes to ongoing discussions about teamwork in management education and team building for virtual teams. [ABSTRACT FROM AUTHOR] Copyright of Journal of Education for Business is the property of Taylor \& Francis Ltd and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
  keywords = {Educational programs,Group decision making,Learning ability,online,Online information services,Organizational change,Students,teaching,team building,Teams in the workplace,teamwork,Undergraduate programs,Universities & colleges},
  file = {/Users/colin.madland/Zotero/storage/SESTWBHS/grzedaTeamBuildingOnline05MayJun2008.pdf}
}

@article{guangulChallengesRemoteAssessment2020,
  title = {Challenges of Remote Assessment in Higher Education in the Context of {{COVID-19}}: A Case Study of {{Middle East College}}},
  author = {Guangul, Fiseha M. and Suhail, Adeel H. and Khalit, Muhammad I. and Khidhir, Basim A.},
  year = {2020},
  journal = {Educational assessment, evaluation and accountability},
  volume = {32},
  number = {4},
  pages = {519--535},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  issn = {1874-8597},
  doi = {10.1007/s11092-020-09340-w},
  abstract = {Due to the unprecedented COVID-19 incident, higher education institutions have faced different challenges in their teaching-learning activities. Particularly conducting assessments remotely during COVID-19 has posed extraordinary challenges for higher education institutions owing to lack of preparation superimposed with the inherent problems of remote assessment. In the current study, the challenges of remote assessment during COVID-19 incident in higher education institutions were investigated taking Middle East College as a case study. For the study, questionnaires were prepared and data from 50 faculties were collected and analyzed. The study focused on the challenges of remote assessment in general and academic dishonesty in particular. The main challenges identified in remote assessment were academic dishonesty, infrastructure, coverage of learning outcomes, and commitment of students to submit assessments. To minimize academic dishonesty, preparing different questions to each student was found to be the best approach. Online presentation was also found to be good option to control academic integrity violations. Combining various assessment methods, for instance report submission with online presentation, helps to minimize academic dishonesty since the examiner would have a chance to confirm whether the submitted work is the work of the student.},
  keywords = {Academic dishonesty,Assessment,Case studies,Cheating,College Students,COVID-19,Distance Education,Education,Education & Educational Research,Education Higher,Education parks,Evaluation Methods,Evaluation Problems,Foreign Countries,Learning strategies,Pandemics,Proctored exam,Remote assessment,School facilities,Social Sciences,Student Evaluation,Summative assessment and testing,Teaching,Testing and Evaluation},
  file = {/Users/colin.madland/Zotero/storage/AUK5T6PX/guangulChallengesRemoteAssessment2020.pdf}
}

@book{gubaFourthGenerationEvaluation1989,
  title = {Fourth Generation Evaluation},
  author = {Guba, E.G. and Lincoln, Y.S.},
  year = {1989},
  publisher = {SAGE Publications},
  isbn = {978-0-8039-3235-7},
  lccn = {lc89010426}
}

@book{gubaParadigmDialog1990,
  title = {The {{Paradigm}} Dialog},
  editor = {Guba, Egon G.},
  year = {1990},
  publisher = {Sage Publications},
  address = {Newbury Park, Calif},
  isbn = {978-0-8039-3822-9 978-0-8039-3823-6},
  lccn = {H61 .P29 1990},
  keywords = {Congresses,Methodology Congresses,Paradigms (Social sciences),Social sciences}
}

@article{gubermanStudentPerceptionsOnline2021,
  title = {Student {{Perceptions}} of an {{Online Ungraded Course}}},
  author = {Guberman, Daniel},
  year = {2021},
  journal = {Teaching \& Learning Inquiry},
  volume = {9},
  number = {1},
  pages = {86--98},
  issn = {ISSN-2167-4779},
  doi = {10/gkx28w},
  abstract = {What do grades mean? What purpose do they serve? What role do they play in the learning process? Teachers and scholars have recently begun to re-examine these questions central to our current grading system. As a result, many have started to re-assess how grades are assigned in their classes. In this case study, I examine the effectiveness of ungrading, an approach centered around students assigning their own grades through reflecting on the learning process. After contextualizing and describing the approach developed for this fully online, asynchronous history class, I share quantitative and qualitative data regarding student perceptions, motivation, and information usage to argue that systems such as ungrading have potential for contributing to the construction of highly effective and meaningful learning environments.},
  langid = {english},
  keywords = {Elective Courses,Grades (Scholastic),Grading,Higher Education,History Instruction,Online Courses,Self Determination,Self Evaluation (Individuals),Student Attitudes,Student Evaluation,Student Motivation}
}

@article{gudinoparedesRemoteProctoredExams2021,
  title = {Remote Proctored Exams: {{Integrity}} Assurance in Online Education?},
  author = {Gudi{\~n}o Paredes, Sandra and Jasso Pe{\~n}a, Felipe de Jes{\'u}s and {\noopsort{la fuente alcazar}}{de La Fuente Alcazar}, Juana Mar{\'i}a},
  year = {2021},
  journal = {Distance education},
  volume = {42},
  number = {2},
  pages = {200--218},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0158-7919},
  doi = {10.1080/01587919.2021.1910495},
  abstract = {After almost a year of COVID-19, distance education mediated by digital tools prevails as an ideal way to study given the flexibility, ubiquity, and a variety of tools that make the process more acceptable. Remote proctored exams have become an important tool to ensure integrity and academic honesty in distance education. This mixed methods study aimed at understanding to what extent remote proctored exams impacted the learning process of online graduate students and their academic integrity (ethics), besides the technological factor involved. Results revealed a significant impact of remote proctored exams as regards personal academic honesty because they minimized the possibility of performing acts of dishonesty. Students attributed this to a sense of obligation and the feeling of being watched, rather than internal motivation or a personal reflective process. Lack of privacy and anxiety emerged as aspects of concern for students.},
  keywords = {Artificial Intelligence,Cheating,College Students,Computer Assisted Testing,COVID-19,Distance Education,Distance learning,Education & Educational Research,educational innovation,Educational innovations,Electronic Learning,Graduate Students,Higher education,Integrity,integrity assurance,mobile learning,Online instruction,Pandemics,remote proctored exam (RPEs),Social Sciences,Student Attitudes,Student Evaluation,Supervision,Tests}
}

@misc{GuidelinesDissertationThree,
  title = {Guidelines for the {{Dissertation}} of {{Three Publishable Papers}}},
  journal = {Indiana University Richard M Fairbanks School of Public Health},
  urldate = {2022-01-20},
  howpublished = {https://fsph.iupui.edu/doc/student-portal/Guidelines\_for\_Dissertation\_of\_Three\_Papers.pdf},
  file = {/Users/colin.madland/Zotero/storage/SEHBZ4CP/GuidelinesDissertationThree.pdf}
}

@misc{GuideUseGenerative2023,
  title = {Guide on the Use of {{Generative AI}}},
  year = {2023},
  month = sep,
  urldate = {2023-09-22},
  howpublished = {https://www.canada.ca/en/government/system/digital-government/digital-government-innovations/responsible-use-ai/guide-use-generative-ai.html},
  langid = {english},
  annotation = {Last Modified: 2023-09-06},
  file = {/Users/colin.madland/Zotero/storage/PDGWLVQN/GuideUseGenerative2023.pdf;/Users/colin.madland/Zotero/storage/NVNQH7WM/guide-use-generative-ai.html}
}

@article{gulerUseWhatsAppHigher2017,
  title = {Use of {{WhatsApp}} in {{Higher Education}}: {{What}}'s {{Up With Assessing Peers Anonymously}}?},
  author = {Guler, Cetin},
  year = {2017},
  journal = {Journal of educational computing research},
  volume = {55},
  number = {2},
  pages = {272--289},
  publisher = {SAGE Publications},
  address = {Los Angeles, CA},
  issn = {0735-6331},
  doi = {10.1177/0735633116667359},
  abstract = {The aim of this study is to investigate the use of WhatsApp application in anonymous peer assessment in higher education. The mobile phone application WhatsApp was used as both an anonymous and nonanonymous peer assessment tool in a classroom environment. The participants of the study were the students of two classes (sophomores and juniors), half of which were assigned to the anonymous peer assessment group and the other half to the nonanonymous peer assessment group for each class. The members of the anonymous groups used the personal messaging function of WhatsApp for assessment, whereas the nonanonymous groups used the group chat function of the application. WhatsApp was confirmed to be a valid tool for peer assessment, and it was shown that the required anonymity of the method was appropriate for the task. The students' perceived attitudes toward the procedure were found to be rather high, with no significant difference identified between the sophomores and junior groups related to the procedure.},
  keywords = {Computer Mediated Communication,Computer Oriented Programs,Computer Uses in Education,Education & Educational Research,Evaluation Methods,Handheld Devices,Higher Education,Likert Scales,Mixed Methods Research,Peer Evaluation,Privacy,Questionnaires,Scoring Rubrics,Social Sciences,Student Attitudes,Technology Uses in Education,Undergraduate Students,Validity}
}

@article{gunasingheAdequacyUTAUT3Interpreting2019,
  title = {The Adequacy of {{UTAUT-3}} in Interpreting Academician's Adoption to e-{{Learning}} in Higher Education Environments},
  author = {Gunasinghe, Asanka and Hamid, Junainah Abd and Khatibi, Ali and Azam, S.M. Ferdous},
  year = {2019},
  month = nov,
  journal = {Interactive Technology and Smart Education},
  volume = {17},
  number = {1},
  pages = {86--106},
  issn = {1741-5659, 1741-5659},
  doi = {10.1108/ITSE-05-2019-0020},
  urldate = {2024-11-08},
  abstract = {Purpose               This study aims to assess the adequacy of unified theory of acceptance and use of technology-3 (UTAUT-3) model in understanding academician's adoption to e-Learning, with intent of getting more academicians to accept e-Learning in the Sri Lankan higher education context. Limited validity of the model in an educational context led to this study. The emergence of internet-based technology has changed the way people live, work and study. Technological platforms such as e-Learning have advanced educational systems by enhancing learner experience while benefiting teachers and educators in many ways.                                         Design/methodology/approach               The study used a deductive approach and quantitative methodology, in which a theoretical model was tested using hypotheses to assess causality between study variables. The simple random sampling was used to collect data using a self-administered questionnaire that was sent via Google Forms to targeted respondents. The final sample consisted of 441 academicians who responded to factors of e-Learning adoption on a seven-point Likert scale. Structured equation modelling was used for data analysis.                                         Findings               It was revealed that performance expectancy, effort expectancy, facilitating conditions, habit and hedonic motivation were significant influences of academician's adoption to e-Learning. However, social influence and personal innovativeness in IT were not significant predictors of e-Learning.                                         Research limitations/implications               Due to the scope of the study, the factors that determine e-Learning adoption were limited to UTAUT-3 variables. Additionally, the concept was tested from only an academician's perspective using quantitative methodology.                                         Practical implications               The findings are useful to higher education institute (HEI) administration, instructors and teaching assistants, policymakers to design and implement their online strategy as well as to make appropriate decisions in getting e-Learning accepted among a higher number of local HEI academicians. It is recommended for the decision-makers in the HEIs to consider the effect of the above findings in setting plans for higher e-Learning adoption. For instance, staff training catering to specific departmental needs, continuous awareness building, periodic reviewal of e-Learning system, e-Learning champions, introduction of policies and guidelines to encourage trial usage would be useful in this aspect.                                         Social implications               Successful use of e-Learning would help HEIs to overcome certain issues that exist in a traditional classroom. e-Learning facilitates education delivery beyond time and space while supporting enhanced performance monitoring and skill development which ultimately improve quality of output and institutional performance.                                         Originality/value               The study examined the adequacy of UTAUT-3 in understanding the adoptability to e-Learning. Second, it recognised a set of factors that affect the academic staff acceptance of e-Learning in higher education environments. A useful framework is provided to the HEI's administration to successfully implement e-Learning systems. This study contributes to the growing body of information system literature by examining the validity of UTAUT-3 framework in the use and acceptance of educational technology in a developing country.},
  copyright = {https://www.emerald.com/insight/site-policies},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/gunasingheAdequacyUTAUT3Interpreting2019.pdf}
}

@article{gunduzDesignProblemBasedOnline2016,
  title = {Design of a {{Problem-Based Online Learning Environment}} and {{Evaluation}} of {{Its Effectiveness}}},
  author = {G{\"u}nd{\"u}z, Abdullah Yasin and Alemdag, Ecenaz and Yasar, Sevil and Erdem, Mukaddes},
  year = {2016},
  month = jul,
  journal = {Turkish Online Journal of Educational Technology - TOJET},
  volume = {15},
  number = {3},
  pages = {49--57},
  publisher = {Turkish Online Journal of Educational Technology - TOJET},
  issn = {2146-7242},
  abstract = {Problem-based learning approach presents several advantages such as improving students' engagement in learning and fostering their higher-order thinking skills. Although there is a plethora of research regarding implementation of problem-based learning in classrooms, its design and application process for web-based environments need further investigation because of independent nature of online settings. This study developed a problem-based online learning environment based on constructivist learning design model proposed by Jonassen (1999) and evaluated its effectiveness. It was conducted in the spring 2014 semester with an intention to access to total population that is 1,417 students receiving distance education for Turkish II course at six university vocational schools. The online lesson was implemented in one week, and data were gathered through students' performance tasks and self-evaluation form. The research indicated that the problem-based online learning environment has a positive influence on learning. Moreover, it was revealed that dynamic nature of online environment affected learner's participation in the designed activities and collaboration among students could not be fostered. Several suggestions were proposed based on the results.},
  keywords = {Academic Achievement,Computer System Design,Constructivism (Learning),Courseware,Distance Education,Educational Environment,Foreign Countries,Instructional Development,No DOI found,Online Courses,Performance Based Assessment,Problem Based Learning,Program Effectiveness,Self Efficacy,Self Evaluation (Individuals),Turkey,Vocational Schools}
}

@article{gunkelCutCrapCritical2025,
  title = {Cut the Crap: A Critical Response to ``{{ChatGPT}} Is Bullshit''},
  author = {Gunkel, David and Coghlan, Simon},
  year = {2025},
  month = apr,
  journal = {Ethics and Information Technology},
  volume = {27},
  number = {2},
  pages = {23},
  issn = {1572-8439},
  doi = {10.1007/s10676-025-09828-3},
  abstract = {In a recent thought-provoking essay called ``ChatGPT is Bullshit,'' Hicks, Humphries and Slater call such large language models (LLMs) ``bullshitters'' and ``bullshit machines.'' Unlike the term ``bullshit,'' they argue, commonly used anthropomorphic terms such as ``hallucination'' and ``confabulation'' mispresent LLMs and sow confusion that could be socially harmful. This paper criticizes their essay in two steps. First, its reliance on Harry Frankfurt's classic characterization of bullshit as indifference to truth, though understandable and compelling in one sense, risks misrepresenting LLMs. Second, the argument is too quick to jettison anthropomorphic terms like hallucination and confabulation, which might prove useful metaphors for understanding generative AI. Exploring language to articulate good ways of understanding LLMs is indeed a socially important task, one benefitting from critical open-mindedness, some historical awareness, and a nuanced approach to how various words used to describe AI can operate. This paper attempts to contribute to this task by questioning the wisdom of categorically calling bullshit on ChatGPT.},
  file = {/Users/colin.madland/Zotero/storage/gunkelCutCrapCritical2025.pdf}
}

@article{gunningWhoEngagedTeambased2022,
  title = {Who Engaged in the Team-Based Assessment? {{Leveraging EdTech}} for a Self and Intra-Team Peer-Assessment Solution to Free-Riding},
  author = {Gunning, Tiffany K. and Conlan, Xavier A. and Collins, Paul K. and Bellgrove, Alecia and Antlej, Kaja and Cardilini, Adam P. A. and Fraser, Catherine L.},
  year = {2022},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {19},
  number = {1},
  pages = {1--22},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-022-00340-y},
  abstract = {A STEM-based faculty in an Australian university leveraged online educational technology to help address student and academic concerns associated with team-based assessment. When engagement and contribution of all team members cannot be assured, team-based assessment can become an unfair and inaccurate measure of student competency. This case study explores the design and capacity of an online self and intra-team peer-assessment of teamwork strategy to measure student engagement and enable peers to hold each other accountable during team-based assessments. Analysis of student interactions across 39 subjects that implemented the strategy in 2020, revealed that an average of 94.4\% of students completed the self and intra-team peer-assessment task when designed as part of a summative team-based assessment. The analysis also revealed that an average of 10.3\% of students were held accountable by their peers, receiving feedback indicating their teamwork skills and behaviours were below the required minimum standard. Furthermore, the strategy was successfully implemented in cohorts ranging from seven to over 700 students, demonstrating scalability. Thus, this online self and intra-team peer-assessment strategy provided teaching teams with evidence of student engagement in a team-based assessment while also enabling students to hold each other accountable for contributing to the team task. Lastly, as the online strategy pairs with any discipline-specific team-based assessment, it provided the faculty with a method that could be used consistently across its schools to support management and engagement in team-based assessments.},
  keywords = {Assessments,Colleges & universities,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,EdTech,Education & Educational Research,Educational evaluation,Educational Technology,Employability,Higher Education,Humanities,Information Systems Applications (incl.Internet),Law,Peers,Research Article,Self- and peer-assessment,Social Sciences,Statistics for Social Sciences,STEM,STEM education,Student participation,Students,Team-based assessment,Teams,Teamwork},
  file = {/Users/colin.madland/Zotero/storage/RQSWBJIU/gunningWhoEngagedTeambased2022.pdf}
}

@article{guptaAsynchronousEnvironmentAssessment2020,
  ids = {guptaAsynchronousEnvironmentAssessment2020a},
  title = {Asynchronous {{Environment Assessment}}: {{A Pertinent Option}} for {{Medical}} and {{Allied Health Profession Education During}} the {{COVID-19 Pandemic}}},
  author = {Gupta, Madan Mohan and Jankie, Satish and Pancholi, Shyam Sundar and Talukdar, Debjyoti and Sahu, Pradeep Kumar and Sa, Bidyadhar},
  year = {2020},
  journal = {Education sciences},
  volume = {10},
  number = {12},
  pages = {352},
  publisher = {Mdpi},
  address = {BASEL},
  issn = {2227-7102},
  doi = {10.3390/educsci10120352},
  abstract = {The emergence and global spread of COVID-19 has disrupted the traditional mechanisms of education throughout the world. Institutions of learning were caught unprepared and this jeopardised the face-to-face method of curriculum delivery and assessment. Teaching institutions have shifted to an asynchronous mode whilst attempting to preserve the principles of integrity, equity, inclusiveness, fairness, ethics, and safety. A framework of assessment that enables educators to utilise appropriate methods in measuring a student's progress is crucial for the success of teaching and learning, especially in health education that demands high standards and comprises consistent scientific content. Within such a framework, this paper aims to present a narrative review of the currently utilised methods of assessment in health education and recommend selected modalities that could be administered in an asynchronous mode during the COVID-19 pandemic. Assessment methods such as open-ended short answer questions, problem-based questions, oral exams, and recorded objective structured clinical exams (OSCE) would be appropriate for use in an asynchronous environment to assess the knowledge and competence of health professional students during COVID-19. Fairness and integrity can be ensured by using technological tools such as video and audio recording surveillance.},
  keywords = {asynchronous assessment,Coronaviruses,COVID-19,Distance learning,Education & Educational Research,Educational evaluation,eLearning,examination system,Health education,Learning,online classes,Online instruction,Social Sciences,Students,Teaching},
  file = {/Users/colin.madland/Zotero/storage/LUUZB9TU/guptaAsynchronousEnvironmentAssessment2020.pdf}
}

@article{guptaOnlineAssessmentTechniques2023,
  title = {Online Assessment Techniques Adopted by the University Teachers amidst {{COVID-19}} Pandemic: {{A}} Case Study},
  author = {Gupta, Tushar and Shree, Abha and Chanda, Prosari and Banerjee, Asmita},
  year = {2023},
  journal = {Social sciences \& humanities open},
  volume = {8},
  number = {1},
  pages = {100579--100579},
  publisher = {Elsevier Ltd},
  address = {England},
  issn = {2590-2911},
  doi = {10.1016/j.ssaho.2023.100579},
  abstract = {Assessing students' online learning is a vital constituent of the effective teaching-learning process in a virtual mode. This study addressed teachers' preparedness, challenges and effective practices for students' assessment in online learning during the COVID-19 pandemic. Online assessment at times of uncertainty has become arduous for university teachers as it is not in practice in Indian higher educational institutions (HEIs). This research reports a study of the Adamas University, teachers drawn-out through semi-structured interviews of individual teachers. The researchers employed a case study research method to attain the objectives of the study using thematic analysis for the qualitative data. Thirty-one faculty members were selected as a sample of the study. The study findings indicated that the University teachers used multiple online assessment techniques, some common, some extremely unique, viz. blogs and peer tutorial videos. The preparedness or readiness varied considerably as some were instead sceptical, whereas some were amusingly non-challant. The study found that teachers faced many problems while assessing students' performance during online classes, which were not just tech-based, but also due to their distressed state of mind. {$\bullet$}ICT-based problems, inappropriate environment, and mental well-being issues were the initial drawbacks of the online assessment.{$\bullet$}Teachers' mental readiness or preparedness affected online teaching and learning effectiveness.{$\bullet$}The university's LMS significantly impacted web-based learning during the COVID-19 pandemic.{$\bullet$}Online assessment strategies were: Quizzes, Peer-Tutorial Videos, Case Studies, HOTS-based questions, and Blogs \& Vlogs.},
  keywords = {Assessment tools,COVID-19 pandemic,Online assessment,Online learning,Regular,Thematic analysis},
  file = {/Users/colin.madland/Zotero/storage/TCK262TM/guptaOnlineAssessmentTechniques2023.pdf}
}

@article{gusevTechnologiesInteractiveLearning2016,
  title = {Technologies for Interactive Learning and Assessment Content Development},
  author = {Gusev, Marjan and Ristov, Sasko and Armenski, Goce},
  year = {2016},
  month = jan,
  journal = {International Journal of Distance Education Technologies},
  volume = {14},
  number = {1},
  pages = {22--43},
  publisher = {IGI Global},
  issn = {1539-3100},
  doi = {10.4018/IJDET.2016010102},
  abstract = {Recent technology trends evolved the student assessment from traditional ones ('pen-and-paper' and 'face-to-face') to modern e-Assessment system. These modern approaches allow the teachers to conduct and evaluate an exam with huge number of students in a short period of time. Even more important, both the teacher and the students achieve the evaluation results immediately after the assessment has finished. Although the e-Assessment system speeds up the evaluation, teachers face a huge challenge to prepare, organize and generate a huge set of questions. The questions must cover all learning objectives and their number should be as large as possible to prevent cheating by guessing or memorization of correct answers from previous exams. This paper presents several technologies that can efficiently realize strategies to develop a huge question database with minimal teacher efforts. It also describes the methodologies and strategies based on a specific technology. The technologies are categorized in two classes of e-Assessment systems that are used at the authors' faculty: the traditional e-Assessment system with usual multiple-choice answers and the newest e-Assessment system with interactive images. The question generation is based on defining the questions and answers as XML files (for more advanced users) and MS Word-based files (for users with basic IT background). The question database can be used both for efficient and effective e-Assessment and e-Learning. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {Click Test,E-Assessment,E-Learning,E-Testing,Evaluation,Interactive Images,Learning,Measurement,Teacher Student Interaction,Technology}
}

@article{guskeyCasePercentageGrades2013,
  title = {The {{Case Against Percentage Grades}}},
  author = {Guskey, Thomas R},
  year = {2013},
  journal = {Educational Leadership},
  abstract = {Assessment and grading have become a major focus in education reform. But one basic component of most present-day grading systems stands as a major impediment to making grades fairer, more accurate, and more meaningful. That component is percentage grades. Percentage grades are the foundation of many state grading policies. Nearly every online grading program available to educators calculates percentage grades. Yet despite their popularity, percentage grades are difficult to defend from a procedural, practical, or ethical perspective.},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/UPXSBWP3/guskeyCasePercentageGrades2013.pdf}
}

@article{guskeyComputerizedGradebooksMyth2002,
  title = {Computerized {{Gradebooks}} and the {{Myth}} of {{Objectivity}}},
  author = {Guskey, Thomas R.},
  year = {2002},
  month = jun,
  journal = {Phi Delta Kappan},
  volume = {83},
  number = {10},
  pages = {775--780},
  issn = {0031-7217, 1940-6487},
  doi = {10/ghhtnn},
  urldate = {2020-11-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/CL2AICUG/guskeyComputerizedGradebooksMyth2002.pdf}
}

@article{guskeyExploringFactorsTeachers2019,
  title = {Exploring the Factors Teachers Consider in Determining Students' Grades},
  author = {Guskey, Thomas R. and Link, Laura J.},
  year = {2019},
  month = may,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {26},
  number = {3},
  pages = {303--320},
  issn = {0969-594X, 1465-329X},
  doi = {10/ghg8j7},
  urldate = {2020-10-29},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/S8JW985J/guskeyExploringFactorsTeachers2019.pdf}
}

@article{guskeyImpactStandardsBasedLearning2020,
  title = {The {{Impact}} of {{Standards-Based Learning}}: {{Tracking High School Students}}' {{Transition}} to the {{University}}},
  shorttitle = {The {{Impact}} of {{Standards-Based Learning}}},
  author = {Guskey, Thomas R. and Townsley, Matt and Buckmiller, Thomas M.},
  year = {2020},
  month = dec,
  journal = {NASSP Bulletin},
  volume = {104},
  number = {4},
  pages = {257--269},
  issn = {0192-6365, 1930-1405},
  doi = {10/gh3wff},
  urldate = {2021-02-18},
  abstract = {This study sought to determine if the implementation of standards-based learning in high schools affects students' transition to learning in university courses. Surveys and interviews with 13 students who had graduated from high schools implementing standards-based learning and who had completed their first academic semester at a midsize, private, Midwest university revealed no detrimental effects. The most frequently mentioned transition difficulties related to social issues and time management. Implications for implementing high school grading reforms are discussed.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/BYZZJ7BV/guskeyImpactStandardsBasedLearning2020.pdf}
}

@article{guskeyStaffDevelopmentProcess1986,
  title = {Staff {{Development}} and the {{Process}} of {{Teacher Change}}},
  author = {Guskey, Thomas R.},
  year = {1986},
  month = may,
  journal = {Educational Researcher},
  volume = {15},
  number = {5},
  pages = {5--12},
  issn = {0013-189X, 1935-102X},
  doi = {10/c28fqd},
  urldate = {2021-05-24},
  abstract = {This article presents a model that describes the process of teacher change, particularly through staff development programs. The model suggests a temporal sequence of events that is hypothesized to typify the process front staff development to enduring change in teachers' perceptions and attitudes. Research evidence supporting the model is summarized and the conditions under which change might be facilitated are described. Several principles for enhancing the change process to improve staff development efforts are also outlined.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/Q8NGZDAK/guskeyStaffDevelopmentProcess1986.pdf}
}

@book{guskeyWhatWeKnow2019,
  title = {What We Know about Grading: What Works, What Doesn't, and What's Next},
  shorttitle = {What We Know about Grading},
  editor = {Guskey, Thomas R. and Brookhart, Susan M.},
  year = {2019},
  publisher = {ASCD},
  address = {Alexandria, VA},
  abstract = {"This comprehensive overview of grading research distills the evidence into meaningful findings and strategies that can be leveraged to improve grading policy and practice"--},
  isbn = {978-1-4166-2724-1},
  lccn = {LB3063},
  keywords = {Grading and marking (Students)}
}

@book{gutekHistoricalPhilosophicalFoundations2001,
  title = {Historical and Philosophical Foundations of Education : Selected Readings},
  author = {Gutek, Gerald Lee.},
  year = {2001},
  publisher = {Prentice Hall},
  address = {Upper Saddle River, N.J.},
  isbn = {0-13-012233-5 978-0-13-012233-9},
  langid = {english}
}

@incollection{gutekPauloFreireAdvocate2001,
  title = {Paulo {{Freire}}: {{Advocate}} of {{Liberation Pedagogy}}},
  booktitle = {Historical and {{Philosophical Foundations}} of {{Education}}: {{A Biographical Introduction}}},
  author = {Gutek, Gerald Lee.},
  year = {2001}
}

@misc{gutierrezWhatArePersonal,
  title = {What Are {{Personal Learning Networks}}?},
  author = {Gutierrez, Karla},
  urldate = {2021-12-23},
  abstract = {Personal Learning Networks is a concept that we hear around a lot these days, but what is it? and why is it important?},
  howpublished = {https://www.shiftelearning.com/blog/personal-learning-networks},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/QYIVVWIU/personal-learning-networks.html}
}

@article{gyamfiEffectsRubricsEvaluative2021,
  title = {The Effects of Rubrics on Evaluative Judgement: A Randomised Controlled Experiment},
  author = {Gyamfi, George and Hanna, Barbara E. and Khosravi, Hassan},
  year = {2021},
  journal = {Assessment \& Evaluation in Higher Education},
  doi = {10.1080/02602938.2021.1887081},
  litmapsid = {159564214}
}

@misc{haberlRecodingRelations,
  title = {Recoding {{Relations}}},
  author = {Haberl, Melissa and Schnell, Autumn},
  number = {1},
  urldate = {2019-09-23},
  abstract = {Recoding Relations is a 4-part podcast series on Indigenous new media and the politics and potentials of the digital humanities. Written and recorded by Autumn Schnell and Melissa Haberl, and produced by David Gaertner,  the series captures key themes and conversations from the 2018 Symposium for In},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/GZK4R4I2/www.recodingrelations.org.html}
}

@article{haberUsingFormativeSummative2017,
  title = {Using {{Formative}} \& {{Summative Assessment}} to {{Evaluate Library Instruction}} in an {{Online First Year Writing Course}}},
  author = {Haber, Natalie and Mitchell, Tiffany N.},
  year = {2017},
  journal = {Journal of library \& information services in distance learning},
  volume = {11},
  number = {3-4},
  pages = {300--313},
  publisher = {Routledge},
  address = {Binghamton},
  issn = {1533-290X},
  doi = {10.1080/1533290X.2017.1324549},
  abstract = {Ensuring quality library instruction in an online-exclusive First Year Writing (FYW) course is important and challenging. Assessing what the students learned and how is equally important. The authors collaborate and co-teach the information literacy portion of an online-exclusive second semester FYW course at the University of Tennessee at Chattanooga. To teach information literacy skills, the authors developed tutorial videos, worksheets, and a Librarian AMA (Ask Me Anything) discussion forum for the students. The authors completed formative and summative assessments to measure the efficacy of the activities. This article explores their assessment, findings, and recommendations.},
  keywords = {assessment,College Freshmen,Discussion Groups,distance learning,first year writing,Formative Evaluation,Freshman Composition,Information Literacy,Instructional Effectiveness,Library Instruction,Online Courses,Online library instruction,Student Evaluation,Student writing,Summative Evaluation,User training,Video Technology,Worksheets,Writing instruction}
}

@article{hadulloOnlineCompetencyBased2021,
  title = {Online {{Competency Based Education Framework}} Using {{Moodle LMS}}: {{A Case}} of {{HEIs}} in {{Kenya}}},
  author = {Hadullo, Kennedy},
  year = {2021},
  journal = {International Journal of Education and Development using Information and Communication Technology},
  volume = {17},
  number = {1},
  pages = {193--206},
  issn = {EISSN-1814-0556},
  abstract = {The purpose of this study was to develop a Framework that can be used to implement an online Competency-based education (CBE) program using a Learning Management system such as Moodle. CBE refers to a system of instruction, assessment, grading, and academic reporting that is based on students demonstrating that they have the knowledge and skills they are expected to learn as they progress through their educational path. However, little is known regarding how an online supported CBE program can be planned, designed, and implemented, to ensure learners complete activities and thus develop competency. This study advances theoretical perspectives of CBE as steps taken towards the development of an online CBE Framework suitable for Higher Education Institutions (HEIs) in Kenya. The study found that: Planning (Technology Infrastructure, organization and program design and development); Design (competency standards, instructional design, content development, LMS installation and customization); Implementation (learning activities, Moodle competency framework, assessments, and discussion forums); Improvement (Moodle Analytics) and Achieving (attainment of competency) were the most influential factors in determining the successful implementation of an Online CBE program in HEIs.},
  langid = {english},
  keywords = {Competency Based Education,Educational Technology,Electronic Learning,Foreign Countries,Higher Education,Integrated Learning Systems,No DOI found,Online Courses,Planning,Program Design,Program Development,Program Effectiveness,Program Implementation,Program Improvement}
}

@incollection{haertelIntroduction2008,
  title = {Introduction},
  booktitle = {Assessment, {{Equity}}, and {{Opportunity}} to {{Learn}}},
  author = {Haertel, Edward H. and Moss, Pamela A. and Pullin, Diana C. and Gee, James Paul},
  editor = {Pullin, Diana C. and Haertel, Edward H. and Gee, James Paul and Young, Lauren Jones and Moss, Pamela A.},
  year = {2008},
  series = {Learning in {{Doing}}: {{Social}}, {{Cognitive}} and {{Computational Perspectives}}},
  pages = {1--16},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9780511802157.003},
  abstract = {The most pressing issue facing U.S. education may be providing all students with a fair opportunity to learn (OTL). Although most would embrace the goal of enhancing OTL, there are fundamental disagreements about how best to accomplish this and different understandings of the meaning of ``opportunity to learn.'' Historically, conceptions of OTL have been closely tied to the practice of testing. OTL has been conceptualized as opportunity to learn what is tested, and test-based accountability has been widely implemented as a means of enhancing OTL. In the United States, policy makers have embraced test-based accountability as a means of somehow forcing schools to bring ``all children'' to a ``proficient'' level of achievement. By law, tests must be ``aligned'' to rigorous ``academic achievement standards.'' Thus, standardized tests are relied upon to provide both the definition of successful learning and the means to assure that OTL is extended to all learners. Against this vision, many have criticized the conception of learning underlying large-scale testing programs and have argued that test-based accountability has, in fact, undermined many students' opportunities to learn.It is rare to find any productive dialogue between the critics and the proponents of test-based accountability systems. By and large, testing advocates embrace a straightforward account of educational improvement. It is taken as a given that schools are doing a poor job -- the goal of schooling is to impart skills to students, and it is common knowledge that many students graduate without having acquired the skills they need.},
  isbn = {978-0-521-88045-9},
  file = {/Users/colin.madland/Zotero/storage/5IVQC8XS/haertelIntroduction2008.pdf}
}

@article{hagerBroadcasterJodyVance2021,
  title = {Broadcaster {{Jody Vance}} Says She Feels Relief after Suspect Arrested Following Years of Online Harassment},
  author = {Hager, Mike},
  year = {2021},
  month = oct,
  journal = {The Globe and Mail},
  urldate = {2022-01-15},
  abstract = {Broadcaster Jody Vance says she wants to promote public discussion, as journalists are being hit with an intensifying wave of hate on online platforms},
  langid = {canadian},
  keywords = {Crime & Tragedy,Social Issues}
}

@article{haiderJordanianUniversityInstructors2022,
  title = {Jordanian {{University Instructors}}' {{Practices}} and {{Perceptions}} of {{Online Testing}} in the {{COVID-19 Era}}},
  author = {Haider, Ahmad S. and Hussein, Riyad F. and Saed, Hadeel A.},
  year = {2022},
  journal = {Frontiers in education (Lausanne)},
  volume = {7},
  publisher = {Frontiers Media S.A},
  issn = {2504-284X},
  doi = {10.3389/feduc.2022.856129},
  abstract = {It is widely known that exceptional circumstances inevitably call for the use of matching procedures. As there has been a change in face-to-face teaching methods, there have also been parallel changes in student evaluation and assessment plans or strategies during the COVID-19 era. This study investigates how COVID-19 affected online testing in higher education institutions in Jordan. For this purpose, the researchers developed a five-construct Likert-type questionnaire with 20 items and distributed it to a sample of 426 university instructors. The constructs were the internet and technology, technical and logistic issues, types of questions, test design, and students' awareness. The results showed that the Internet and technology are essential to guarantee the successful performance of online testing. The study also showed that this type of testing affected the test design and types of questions in a way to eliminate or at least reduce the spread of online cheating. The study recommends that higher education institutions provide instructors with on-the-job training, not only in e-learning techniques and procedures but also in preparing and conducting online exams.},
  keywords = {cheating (education),exam security,internet,online testing,question types,test design},
  file = {/Users/colin.madland/Zotero/storage/X8SDT3V2/haiderJordanianUniversityInstructors2022.pdf}
}

@article{hains-wessonSTEMAcademicTeachers2020,
  title = {{{STEM}} Academic Teachers' Experiences of Undertaking Authentic Assessment-Led Reform: A Mixed Method Approach},
  author = {{Hains-Wesson}, Rachael and Pollard, Vikki and Kaider, Friederika and Young, Karen},
  year = {2020},
  journal = {Studies in higher education (Dorchester-on-Thames)},
  volume = {45},
  number = {9},
  pages = {1797--1808},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0307-5079},
  doi = {10/gfxb9s},
  abstract = {A large-scale investigation was conducted at an Australian University to document and analyze authentic work-related assessment types for a university-wide major course review (Kaider, F., and R. Hains-Wesson. 2016. "Enhancing Courses for Employability." Melbourne: Australian Collaborative Education Network. Report.). This study provides further insights into Science, Engineering, Technology and Mathematics (STEM) teachers' experiences in undertaking authentic assessment-led reform. STEM teachers participated in an online survey and a recorded interview to elicit their perceptions of authentic assessment-led activities. A mixed methods approach was used with two key themes emerging: (1) purpose and approach, which highlighted the importance of introducing a shared understanding for effective authentic assessment-led reform and (2) working with industry, which illustrated the requirement to provide teachers with additional support options when working with industry. In this paper, we discuss the implications of the findings along with the presentation of a set of key recommendations for supporting teachers when renewing STEM education.},
  keywords = {Approaches,Assessment,Assessment-led reform,authentic assessment,Authenticity,College Curriculum,College Faculty,Curriculum Development,Education & Educational Research,Employability,Experience,Foreign Countries,Mathematics,Performance Based Assessment,Reforms,School Business Relationship,Science and technology,Social Sciences,STEM Education,STEM education renewal,Teacher Attitudes,teacher perception,Teachers}
}

@article{haipingeRethinkingFrameworkContextualising2021,
  title = {Rethinking a {{Framework}} for {{Contextualising}} and {{Collaborating}} in {{MOOCs}} by {{Higher Education Institutions}} in {{Africa}}},
  author = {Haipinge, Erkkie and Kadhila, Ngepathimo},
  year = {2021},
  journal = {Journal of Learning for Development},
  volume = {8},
  number = {1},
  pages = {204--220},
  issn = {EISSN-2311-1550},
  abstract = {Massive Open Online Courses (MOOCs) are online courses that are open to anyone with Internet access. Pioneered in North America, they were developed for contexts with broader access to technology and wider access to the Internet. As globally networked learning environments (GNLEs), MOOCs foster collaborative communities and learning in ways not conceived as feasible until recently. The affordances of MOOCs, such as the ability to access learning beyond one's immediacy, exemplify their benefits for open and distance learning, especially in developing countries that continue to consume rather than produce online courses. However, the globality of MOOCs and their delivery mode pose a challenge of contextualising learning content to the local needs of educational institutions or individual students that choose to use the courses. This theoretical paper used a desk-research approach by revising literature to investigate and propose ways of contextualising MOOCs to the African higher education setting. It applied the principles of reuse and repurposing learning content, while suggesting the use of mobile learning as a technological delivery solution that is relevant to the local context. The paper also suggests a framework for inter-institutional collaboration for higher education institutions to guide future efforts in the creation and sharing of credit-bearing MOOCs.},
  langid = {english},
  keywords = {Culturally Relevant Education,Distance Education,Educational Technology,Electronic Learning,Foreign Countries,Handheld Devices,Higher Education,Institutional Cooperation,Large Group Instruction,No DOI found,Online Courses,Open Education,Open Educational Resources,Telecommunications}
}

@book{hairPartialLeastSquares2021,
  title = {Partial {{Least Squares Structural Equation Modeling}} ({{PLS-SEM}}) {{Using R}}: {{A Workbook}}},
  shorttitle = {Partial {{Least Squares Structural Equation Modeling}} ({{PLS-SEM}}) {{Using R}}},
  author = {Hair, Joseph and Hult, G. Tomas M. and Ringle, Christian M. and Sarstedt, Marko and Danks, Nicholas P. and Ray, Soumya},
  year = {2021},
  series = {Classroom {{Companion}}: {{Business}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-80519-7},
  urldate = {2023-08-24},
  isbn = {978-3-030-80518-0 978-3-030-80519-7},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/9BRAB9UL/hairPartialLeastSquares2021.pdf}
}

@article{hairPartialLeastSquares2022,
  title = {Partial {{Least Squares Structural Equation Modeling}} ({{PLS-SEM}}) in Second Language and Education Research: {{Guidelines}} Using an Applied Example},
  author = {Hair, Joseph and Alamer, Abdullah},
  year = {2022},
  month = dec,
  journal = {Research Methods in Applied Linguistics},
  volume = {1},
  number = {3},
  pages = {100027},
  issn = {2772-7661},
  doi = {10.1016/j.rmal.2022.100027},
  abstract = {Partial least squares structural equation modeling (PLS-SEM) is an alternative method to the historically more commonly used covariance-based SEM (CB-SEM) when analyzing the data using structural equation modeling (SEM). The article starts by introducing PLS-SEM to second language and education research, followed by a discussion of situations in which PLS-SEM should be the method of choice for structural equation modeling. It is argued that PLS-SEM is appropriate when complex models are analyzed, when prediction is the focus of the research -- particularly out-of-sample prediction to support external validity, when data do not meet normal distribution assumptions, when formative constructs are included, and when higher-order constructs facilitate better understanding of theoretical models. The most up-to-date guidelines for applying PLS-SEM are provided, and step-by-step guidance is offered on how to apply the method using an R statistical package (i.e., SEMinR) that is available. An example is provided that shows how the results of PLS-SEM are interpreted and reported. We also make the data publicly available for readers to start learning PLS-SEM by replicating our findings. The paper concludes with important considerations for the utilization of SEM, especially PLS-SEM, in future L2 research.},
  keywords = {Convergent validity,Covariance-based structural equation modeling (CB-SEM),Discriminant validity,Partial least squares structural equation modeling (PLS-SEM),Predictive power,Structural equation modeling (SEM)},
  file = {/Users/colin.madland/Zotero/storage/EZY5GXUL/hairPartialLeastSquares2022.pdf}
}

@article{hairPLSSEMIndeedSilver2011,
  title = {{{PLS-SEM}}: {{Indeed}} a {{Silver Bullet}}},
  author = {Hair, Joseph and Ringle, Christian M. and Sarstedt, Marko},
  year = {2011},
  journal = {Journal of marketing theory and practice},
  volume = {19},
  number = {2},
  pages = {139--152},
  publisher = {Routledge},
  address = {Abingdon},
  issn = {1069-6679},
  doi = {10.2753/MTP1069-6679190202},
  abstract = {Structural equation modeling (SEM) has become a quasi-standard in marketing and management research when it comes to analyzing the cause-effect relations between latent constructs. For most researchers, SEM is equivalent to carrying out covariance-based SEM (CB-SEM). While marketing researchers have a basic understanding of CB-SEM, most of them are only barely familiar with the other useful approach to SEM-partial least squares SEM (PLS-SEM). The current paper reviews PLS-SEM and its algorithm, and provides an overview of when it can be most appropriately applied, indicating its potential and limitations for future research. The authors conclude that PLS-SEM path modeling, if appropriately applied, is indeed a "silver bullet" for estimating causal models in many theoretical models and empirical data situations.},
  keywords = {Coefficients,Least squares,Marketing,Modeling,Principal components analysis,Research methods,Researchers,Sample size,Social sciences,Software,Statistical estimation,Statistical models,Statistical variance,Structural equation models,Studies,Variance analysis},
  file = {/Users/colin.madland/Zotero/storage/FZQRJV7C/hairPLSSEMIndeedSilver2011.pdf}
}

@article{hairWhenUseHow2019,
  title = {When to Use and How to Report the Results of {{PLS-SEM}}},
  author = {Hair, Joseph and Risher, Jeffrey J. and Sarstedt, Marko and Ringle, Christian M.},
  year = {2019},
  month = jan,
  journal = {European Business Review},
  volume = {31},
  number = {1},
  pages = {2--24},
  publisher = {Emerald Publishing Limited},
  issn = {0955-534X},
  doi = {10.1108/EBR-11-2018-0203},
  urldate = {2023-08-24},
  abstract = {Purpose The purpose of this paper is to provide a comprehensive, yet concise, overview of the considerations and metrics required for partial least squares structural equation modeling (PLS-SEM) analysis and result reporting. Preliminary considerations are summarized first, including reasons for choosing PLS-SEM, recommended sample size in selected contexts, distributional assumptions, use of secondary data, statistical power and the need for goodness-of-fit testing. Next, the metrics as well as the rules of thumb that should be applied to assess the PLS-SEM results are covered. Besides presenting established PLS-SEM evaluation criteria, the overview includes the following new guidelines: PLSpredict (i.e., a novel approach for assessing a model's out-of-sample prediction), metrics for model comparisons, and several complementary methods for checking the results' robustness. Design/methodology/approach This paper provides an overview of previously and recently proposed metrics as well as rules of thumb for evaluating the research results based on the application of PLS-SEM. Findings Most of the previously applied metrics for evaluating PLS-SEM results are still relevant. Nevertheless, scholars need to be knowledgeable about recently proposed metrics (e.g. model comparison criteria) and methods (e.g. endogeneity assessment, latent class analysis and PLSpredict), and when and how to apply them to extend their analyses. Research limitations/implications Methodological developments associated with PLS-SEM are rapidly emerging. The metrics reported in this paper are useful for current applications, but must always be up to date with the latest developments in the PLS-SEM method. Originality/value In light of more recent research and methodological developments in the PLS-SEM domain, guidelines for the method's use need to be continuously extended and updated. This paper is the most current and comprehensive summary of the PLS-SEM method and the metrics applied to assess its solutions.},
  file = {/Users/colin.madland/Zotero/storage/9I5IRCRP/hairWhenUseHow2019.pdf}
}

@article{haj-yahyaPreserviceTeachersExperiences2022,
  title = {Preservice Teachers' Experiences with Digital Formative Assessment in Mathematics},
  author = {{Haj-Yahya}, Aehsan and Olsher, Shai},
  year = {2022},
  journal = {International journal of mathematical education in science and technology},
  volume = {53},
  number = {7},
  pages = {1751--1769},
  publisher = {Taylor \& Francis},
  address = {London},
  issn = {0020-739X},
  doi = {10.1080/0020739X.2020.1842527},
  abstract = {This study investigated the experience of preservice mathematics teachers working with example-eliciting tasks (EET) on an online formative assessment platform. The study focused on the effect of working with EETs on the preservice teachers' (PSTs) professional noticing of learners' mathematical thinking. Participants included nine PSTs studying for their master's degree in a teacher education college in Israel. The PSTs were presented with their own responses and peer's responses about an angle bisector activity, and semi-structured interviews were conducted following the completion of course meetings. Qualitative methods were used to analyse the data. The findings show that the PSTs' experiences of engagement with EETs were reflected in their noticing skills: attending, interpreting and responding. The findings also show that PSTs paid special attention to the variance between submitted examples and noticed the differences between answers. Their experiences also affected their knowledge of content and teaching, namely the proper sequence of instruction and the choice of examples for use in the classroom to facilitate deeper understanding of concepts. Finally, the findings indicate that using EETs on an online formative assessment platform enhanced the noticing skills of PSTs.},
  keywords = {angle bisector examples space,Colleges & universities,digital formative assessment,Foreign Countries,geometry,Instructional Design,Mathematical analysis,Mathematics Curriculum,Mathematics education,Mathematics Teachers,Noticing of mathematical thinking,Online Systems,Preservice Teachers,preservice teachers' experiences as students,preservice teachers' knowledge,Qualitative analysis,Skills,Student Evaluation,Teacher education,Teachers},
  file = {/Users/colin.madland/Zotero/storage/GJSZ9QYV/haj-yahyaPreserviceTeachersExperiences2022.pdf}
}

@article{hajirasouliAugmentedRealityArchitecture2022,
  title = {Augmented Reality in Architecture and Construction Education: State of the Field and Opportunities},
  author = {Hajirasouli, Aso and Banihashemi, Saeed},
  year = {2022},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {19},
  number = {1},
  pages = {1--28},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-022-00343-9},
  abstract = {Over the past decade, the architecture and construction (AC) industries have been evolving from traditional practices into more current, interdisciplinary and technology integrated methods. Complex and intricate digital technologies and mobile computing such as simulation, computational design and immersive technologies, have been exploited for different purposes such as reducing cost and time, improving design and enhancing overall project efficiency. Immersive technologies and augmented reality (AR), in particular, have proven to be extremely beneficial in this field. However, the application and usage of these technologies and devices in higher education teaching and learning environments are yet to be fully explored and still scarce. More importantly, there is still a significant gap in developing pedagogies and teaching methods that embrace the usage of such technologies in the AC curricula. This study, therefore, aims to critically analyse the current state-of-the-art and present the developed and improved AR approaches in teaching and learning methods of AC, addressing the identified gap in the extant literature, while developing transformational frameworks to link the gaps to their future research agenda. The conducted analysis incorporates the critical role of the AR implications on the AC students' skillsets, pedagogical philosophies in AC curricula, techno-educational aspects and content domains in the design and implementation of AR environments for AC learning. The outcomes of this comprehensive study prepare trainers, instructors, and the future generation of AC workers for the rapid advancements in this industry.},
  keywords = {Architecture,Augmented reality,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Construction industry,Curricula,Design and architecture pedagogy,Digital pedagogy,Digital technology,Education,Educational Technology,Emerging technology,Higher Education,Humanities,Immersive pedagogy,Information Systems Applications (incl.Internet),Law,Learning,Mobile computing,Pedagogy,Review Article,Skills,Statistics for Social Sciences,Teaching methods},
  file = {/Users/colin.madland/Zotero/storage/7XJ5FU3C/hajirasouliAugmentedRealityArchitecture2022.pdf}
}

@article{hakimiEthicsUsingDigital2021,
  title = {The {{Ethics}} of {{Using Digital Trace Data}} in {{Education}}: {{A Thematic Review}} of the {{Research Landscape}}},
  shorttitle = {The {{Ethics}} of {{Using Digital Trace Data}} in {{Education}}},
  author = {Hakimi, Laura and Eynon, Rebecca and Murphy, Victoria A.},
  year = {2021},
  journal = {Review of Educational Research},
  volume = {91},
  number = {5},
  pages = {671--717},
  issn = {0034-6543, 1935-1046},
  doi = {10.3102/00346543211020116},
  urldate = {2024-09-23},
  abstract = {This article presents the findings of a systematic qualitative analysis of research in the ethics of digital trace data use in learning and education. From the resulting analysis of 77 peer-reviewed studies, we (1) map the characteristics of research by study type, academic community, institutional setting, and national context; (2) identify the primary ethical concerns and related responses; and (3) highlight the research gaps. Four areas of focus are identified in this emerging area: (1) privacy, informed consent, and data ownership; (2) validity and integrity; (3) ethical decision making; and (4) governance and accountability. We highlight the lack of evidence particularly for preschool and school-aged children and the disparate communities working in this domain, and we suggest a more cohesive approach, where the wider learning and educational ecosystem is recognized, explicit engagement with ethical theory is central, and mid- to long-term ethical issues are considered alongside immediate concerns.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/hakimiEthicsUsingDigital2021.pdf}
}

@article{halawehAreUniversitiesUsing2021,
  ids = {halawehAreUniversitiesUsing2020},
  title = {Are {{Universities Using}} the {{Right Assessment Tools}} during the {{Pandemic}} and {{Crisis Times}}?},
  author = {Halaweh, Mohanad},
  year = {2021},
  month = jan,
  journal = {Higher Learning Research Communications},
  volume = {11},
  pages = {1--9},
  publisher = {Higher Learning Research Communications},
  issn = {2157-6254},
  abstract = {All industries have been affected by the COVID-19 pandemic and have worked to develop alternative strategies and actions to survive and continue business operations; the education sector is no exception. University administrators and instructors have faced challenges in finding the appropriate mechanisms to manage the final examination process. This essay suggests that project-based learning (PBL) assessment could be an effective alternative to online examinations. It advocates the adoption of PBL by highlighting the challenges/pitfalls associated with online exams supported by proctoring software tools.},
  keywords = {Active Learning,College Faculty,Computer Assisted Testing,COVID-19,Distance Education,Evaluation Methods,No DOI found,Pandemics,Student Evaluation,Student Projects,Supervision},
  file = {/Users/colin.madland/Zotero/storage/ZW8NEH7Q/halawehAreUniversitiesUsing2021.pdf}
}

@article{hallLettingGoGrades2022,
  title = {Letting {{Go}} of {{Grades}}: {{Creating}} an {{Environment}} of {{Autonomy}} and a {{Focus}} on {{Learning}} for {{High Achieving Students}}},
  shorttitle = {Letting {{Go}} of {{Grades}}},
  author = {Hall, Eric and Meinking, Kristina},
  year = {2022},
  month = jun,
  journal = {Teaching and Learning Inquiry},
  volume = {10},
  issn = {2167-4787, 2167-4779},
  doi = {10.20343/teachlearninqu.10.21},
  urldate = {2022-06-16},
  abstract = {In this essay we discuss an iterative, reflective writing assignment (the ``learning charter'') as a way to understand how high-achieving students experienced an ungrading learning environment. Working with evidence from student written reflection and in-class conversations, we chronicle how students articulated their perspectives on this approach through the fifteen-week semester. Our findings indicate that despite initial uncertainty, students found the environment to be one that promoted learning for the sake of learning, cultivated mental wellness, and compelled them to pursue meaningful questions about their own educational goals and experience. While this development was not without feelings of conflict and struggle throughout the course, by the end of it, students reported a renewed focus on the value of learning. We suggest that the strategies employed in this course might be successfully adopted in or adapted to other courses for high-achieving students, as well as other student populations.},
  file = {/Users/colin.madland/Zotero/storage/BJCTK6RQ/hallLettingGoGrades2022.pdf}
}

@article{hallMarginsCenterDevelopment1992,
  title = {From {{Margins}} to {{Center}}? {{The Development}} and {{Purpose}} of {{Participatory Research}}},
  author = {Hall, Budd L.},
  year = {1992},
  journal = {The American Sociologist},
  volume = {23},
  number = {4},
  pages = {15--28},
  issn = {00031232, 19364784},
  abstract = {[This article documents the development of the libratory stream of participatory research as experienced through the activities and connections of one of the key figures in the early development and dissemination of these ideas. It traces the developments in Tanzania in the early 1970s, through the establishment of the original Participatory Research Network to the elaboration of theoretical and political debates. It highlights the formulation and elaboration of participatory research as a contribution to social change in a variety of settings. It includes discussions of the feminist advance, the question of voice and the relationship of power to knowledge in transformative practice. It contains an extensive and historically valuable bibliography.]}
}

@book{halpernThoughtKnowledgeIntroduction1989,
  title = {Thought and Knowledge: {{An}} Introduction to Critical Thinking},
  author = {Halpern, Diane F.},
  year = {1989},
  edition = {2nd},
  publisher = {Lawrence Erlbaum Associates},
  address = {Hillsdale, NJ}
}

@article{halvorsonRevealingTechnologicalIrresponsibility2011,
  title = {Revealing the {{Technological Irresponsibility}} in {{Curriculum Design}}},
  author = {Halvorson, Mark},
  year = {2011},
  month = jan,
  journal = {Curriculum Inquiry},
  volume = {41},
  number = {1},
  pages = {34--47},
  issn = {0362-6784, 1467-873X},
  doi = {10.1111/j.1467-873X.2010.00523.x},
  urldate = {2022-05-21},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/U35EXSSX/halvorsonRevealingTechnologicalIrresponsibility2011.pdf}
}

@article{Hambleton_1993,
  title = {An Ncme Instructional Module on Comparison of Classical Test Theory and Item Response Theory and Their Applications to Test Development},
  author = {Hambleton, Ronald K. and Jones, Russell W.},
  year = {1993},
  journal = {Educational Measurement: Issues and Practice},
  doi = {10/bqcgrb},
  abstract = {N/A: no abstract available},
  mag_id = {2901009437},
  pmcid = {null},
  pmid = {null}
}

@article{hambletonNCMEInstructionalModule2005,
  title = {An {{NCME Instructional Module}} on: {{Comparison}} of {{Classical Test Theory}} and {{Item Response Theory}} and {{Their Applications}} to {{Test Development}}},
  shorttitle = {An {{NCME Instructional Module}} On},
  author = {Hambleton, Ronald K. and Jones, Russell W.},
  year = {2005},
  month = oct,
  journal = {Educational Measurement: Issues and Practice},
  volume = {12},
  number = {3},
  pages = {38--47},
  issn = {07311745, 17453992},
  doi = {10/bqcgrb},
  urldate = {2020-10-22},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/Q2UVI9K7/hambletonNCMEInstructionalModule2005.pdf}
}

@article{hamdanalghamdiInstitutionalAcademicAssessment2020,
  title = {Institutional {{Academic Assessment}} and {{Effectiveness}} in {{Higher Education}}: {{A Saudi Arabia Case Study}}},
  author = {Hamdan Alghamdi, Amani K. and Alotaibi, Ghazi and Ibrahim, Osama},
  year = {2020},
  journal = {Research \& Practice in Assessment},
  volume = {15},
  number = {1},
  issn = {EISSN-2161-4210},
  abstract = {The "Vision 2030" agenda was recently adopted as a roadmap and methodology for developmental and economic action throughout the Kingdom of Saudi Arabia. "Vision 2030" includes support for universities' academic and administrative operations through the collection, rigorous analysis, and reporting of a wide range of data. Prefaced with an overview of the Saudi economic, policy, and educational landscape, the paper's main contribution is a case study of Imam Abdulrahman Bin Faisal University (IAU), chosen because of its recent attempt to institutionalize academic assessment protocols, procedures and culture. It institutionalized a directorate focused on academic assessment, launched a Decision Support Unit dashboard, and developed key performance indicators (KPIs) to assess students' academic performance, course performance and employability. The IAU has since become a regional leader in higher education assessment. Emulating their approach affords other Saudi higher education institutions the opportunity to increase Saudi graduates' ability to directly contribute to the country's economy, ultimately promoting economic growth, diversification, and development as envisioned in "Vision 2030." [Note: The issue number (2) shown on the PDF is incorrect. The correct issue number is 1.]},
  langid = {english},
  keywords = {Academic Achievement,Educational Indicators,Educational Policy,Employment Potential,Foreign Countries,Higher Education,No DOI found,School Effectiveness,Student Evaluation}
}

@article{hamidiAnalysisEssentialFactors2018,
  title = {Analysis of the Essential Factors for the Adoption of Mobile Learning in Higher Education: {{A}} Case Study of Students of the {{University}} of {{Technology}}},
  author = {Hamidi, Hodjat and Chavoshi, Amir},
  year = {2018},
  journal = {Telematics and informatics},
  volume = {35},
  number = {4},
  pages = {1053--1070},
  publisher = {Elsevier Ltd},
  address = {AMSTERDAM},
  issn = {0736-5853},
  doi = {10.1016/j.tele.2017.09.016},
  abstract = {{$\bullet$}This paper analyzed the adoption of using mobile learning in higher education.{$\bullet$}This paper, with a study of ``what is the impact of the mobile phone usage in education?'' provides approaches and theories of mobile learning in training.{$\bullet$}The factors related to adoption of mobile learning in higher education was classified into seven main categories as: ease of use, trust, characters and personal qualities, context, perceived usefulness of using, behavioral intention, and culture of using a research model. This paper analyzed the adoption of using mobile learning (m-learning) in higher education. Mobile Learning as a model of e-learning refers to the acquisition of knowledge, skills and attitudes by utilizing mobile technologies. With the increasing coverage of mobile networks, learning services can play the increasing and effective role in education at any time and place. Continuous access via mobile devices creates special facilities like sending and saving the learning content to learners etc, it is accompanied with continuous education. This paper, with a study of ``what is the impact of the mobile phone usage in education?'' provides approaches and theories of mobile learning in training. The paper aimed to evaluate the essential factors for the adoption and application of education information system that has been created by students. The survey was based on the history of technology adoption and covered students. Furthermore, a case study from students of K. N. Toosi University in Iran was presented to indicate the performance of this method in practice. The statistical society included 300 members from Information Technology students of Iran's K. N. Toosi University of Technology. The factors related to adoption of mobile learning in higher education was classified into seven main categories as: ease of use, trust, characters and personal qualities, context, perceived usefulness of using, behavioral intention, and culture of using a research model. From the results, mobile learning could be one of the promising educational technologies for development in educational environments and culture of using. The context of applications has a significant positive effect on the ease of use factor and usefulness and the ease of use has a positive effect on the usefulness factor. The trust factor has a positive and significant effect on the behavioral intention. The personal features and characters factor have a significant positive effect on the culture of using and the culture of using the application has a significant positive effect on the behavioral intention.},
  keywords = {Adoption of mobile learning,Analysis,Case studies,Cellular telephones,Colleges & universities,Culture,Culture of using,Distance learning,E-learning,Education,Educational technology,Electronic devices,Higher education,Information Science & Library Science,Information technology,Knowledge acquisition,Mobile communication systems,Mobile devices,Mobile learning,Online instruction,Science & Technology,Students,Technical institutes,Technology,Technology adoption,Technology assessment,Technology utilization,Wireless communication systems,Wireless networks}
}

@article{hamiltonAcademicIntegrityApproach2007,
  title = {An Academic Integrity Approach to Learning and Assessment Design},
  author = {Hamilton, Margaret and Richardson, Joan},
  year = {2007},
  month = feb,
  journal = {Journal of Learning Design},
  volume = {2},
  number = {1},
  pages = {37--51},
  issn = {1832-8342, 1832-8342},
  doi = {10.5204/jld.v2i1.27},
  urldate = {2022-07-11},
  file = {/Users/colin.madland/Zotero/storage/3GLVI64R/hamiltonAcademicIntegrityApproach2007.pdf}
}

@misc{hamiltonTwitterInvestigatingAnecdotal,
  title = {Twitter Is Investigating after Anecdotal Data Suggested Its Picture-Cropping Tool Favors White Faces},
  author = {Hamilton, Isobel Asher},
  journal = {Business Insider},
  urldate = {2020-09-23},
  abstract = {Users began to notice that the algorithm behind Twitter's automatic cropping tool appeared to be systematically favoring White faces.},
  howpublished = {https://www.businessinsider.com/twitter-investigating-picture-preview-algorithm-racial-bias-2020-9},
  file = {/Users/colin.madland/Zotero/storage/SAEF3CGF/twitter-investigating-picture-preview-algorithm-racial-bias-2020-9.html}
}

@book{hancockReviewerGuideQuantitative2019,
  title = {The Reviewer's Guide to Quantitative Methods in the Social Sciences},
  editor = {Hancock, Gregory R. and Stapleton, Laura M. and Mueller, Ralph O.},
  year = {2019},
  edition = {Second Edition},
  publisher = {Routledge, Taylor \& Francis Group},
  address = {New York},
  isbn = {978-1-315-75564-9},
  lccn = {H62},
  keywords = {Research Methodology,Social sciences,Statistical methods},
  file = {/Users/colin.madland/Zotero/storage/NDM69KWU/hancockReviewerGuideQuantitative2019.pdf}
}

@article{hanCombiningSelfreportedObservational2020,
  title = {Combining Self-Reported and Observational Measures to Assess University Student Academic Performance in Blended Course Designs},
  author = {Han, Feifei and Ellis, Robert},
  year = {2020},
  journal = {AUSTRALASIAN JOURNAL OF EDUCATIONAL TECHNOLOGY},
  volume = {36},
  number = {6},
  pages = {1--14},
  publisher = {Australasian Soc Computers Learning Tertiary Education-Ascilite},
  address = {TUGUN},
  issn = {1449-5554},
  doi = {10.14742/ajet.6369},
  abstract = {This study combined the methods from student approaches to learning and learning analytics research by using both self-reported and observational measures to examine the student learning experience. It investigated the extent to which reported approaches and perceptions and observed online interactions are related to each other and how they contribute to variation in academic performance in a blended course design. Correlation analyses showed significant pairwise associations between approaches and frequency of the online interaction. A cluster analysis identified two groupings of students with different reported learning orientations. Based on the reported learning orientations, one-way ANOVAs showed that students with understanding orientation reported deep approaches to and positive perceptions of learning. The students with understanding orientation also interacted more frequently with the online learning tasks and had higher marks than those with reproducing orientation, who reported surface approaches and negative perceptions. Regression analyses found that adding the observational measures increased 36\% of the variance in the academic performance in comparison with using self-reported measures alone (6\%). The findings suggest using the combined methods to explain students' academic performance in blended course designs not only triangulates the results but also strengthens the acuity of the analysis. [Author abstract]},
  keywords = {Academic Achievement,Blended Learning,Cluster analysis,College Freshmen,Computer Science Education,Correlation,Data Collection,Distance learning,Education & Educational Research,Electronic Learning,Foreign Countries,Higher education,Integrated Learning Systems,Interaction,Learning Analytics,Learning experience,Learning Strategies,Measurement Techniques,Observation,Online learning,Performance factors,Research Universities,Social Sciences,Student Evaluation,Students,University students,Young Adults},
  file = {/Users/colin.madland/Zotero/storage/U9RNTUH7/hanCombiningSelfreportedObservational2020.pdf}
}

@article{hanRelationsStudyApproach2025,
  title = {The Relations between Study Approach, Study Time, and Academic Performance in Flipped Classrooms by Questionnaire and Clickstream Data: {{To}} What Extent Are They Consistent?},
  shorttitle = {The Relations between Study Approach, Study Time, and Academic Performance in Flipped Classrooms by Questionnaire and Clickstream Data},
  author = {Han, Feifei},
  year = {2025},
  month = may,
  journal = {Journal of Computing in Higher Education},
  issn = {1042-1726, 1867-1233},
  doi = {10.1007/s12528-025-09443-7},
  urldate = {2025-05-20},
  abstract = {Abstract             This study used both questionnaire and clickstream data to examine the relations between study approach, study time, and academic performance in low-stake and high-stake assessments in flipped classrooms. The questionnaire data identified two clusters of students reporting deep and surface study approaches. Students who reported a deep study approach performed better than those who reported a surface study approach on both low-stake and high-stake assessments. The clickstream data detected two clusters of students using either preparation-oriented or assessment-oriented approaches. Students who adopted preparation-oriented approach achieved higher on both low-stake and high-stake assessments. Students' study time measured by both questionnaire data and clickstream data consistently contributed to both low-stake and high-stake assessments. However, the contributions of study approach to academic performance were not consistent across the two types of data, as self-reported study approach was only a significant predictor of high-stake but not low-stake assessment, suggesting that study approach measured by questionnaire data might not be sufficiently sensitive to detect variations in study approaches in flipped classrooms. Pedagogically, the results suggest that raising students' awareness of the importance of pre-lecture learning and aligning assessments and learning activities may foster quality flipped classroom learning. Methodologically, the study demonstrates the advantages of combining questionnaire and clickstream data to understand students' experiences of learning in flipped classrooms.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/hanRelationsStudyApproach2025.pdf}
}

@article{Hansen_1997,
  title = {Quality Multiple Choice Test Questions Item Writing Guidelines and an Analysis of Auditing Testbanks},
  author = {Hansen, James D. and Dexter, Lee},
  year = {1997},
  journal = {The Journal of Education for Business},
  doi = {10/drcczq},
  abstract = {Abstract In accounting classes, publisher testbanks can be an important source of multiple-choice test questions. There has been, however, some criticism that textbook testbanks may be of low quality (Baldwin, 1984). To determine if testbank questions are well constructed and follow general guidelines for writing multiple-choice items, we examined 10 audit testbanks. Our analysis revealed that across all published testbanks examined, 75\% of the questions had one or more guideline violations. Seventeen of the most cited rules for writing multiple-choice questions are given.},
  mag_id = {2082361605},
  pmcid = {null},
  pmid = {null}
}

@article{hansenAdoptionDiffusionWeb2001,
  title = {The {{Adoption}} and {{Diffusion}} of {{Web Technologies}} into {{Mainstream Teaching}}},
  author = {Hansen, Steve and Salter, Graeme},
  year = {2001},
  journal = {Journal of Interactive Learning Research},
  volume = {12},
  number = {2},
  pages = {281--299},
  abstract = {This article discusses various adoption and diffusion frame-works and methodologies to enhance the use of web technol-ogies by teaching staff. It covers a descriptive framework based heavily on work by Rogers (1995) and puts forward the use of adopter-based models for product development. A two-pronged approach is suggested, one making use of the adopter-based models for staff uptake and the other making use of the Rogers innovation-decision process. In particular, based on surveying and the subsequent development of an example web information system called PlatformWeb, the full integration of an educational institution's administration with its teaching delivery system is recommended.}
}

@article{hansonDesigningEContentTeaching2020,
  title = {Designing {{E-Content}} for {{Teaching Basic Analytical Chemistry}} in {{Higher Education}}: {{A Baseline Study}}},
  author = {Hanson, Ruby},
  year = {2020},
  journal = {Science Education International},
  volume = {31},
  number = {1},
  pages = {22--28},
  issn = {EISSN-2077-2327},
  doi = {10/gmbv23},
  abstract = {This study developed an e-resource for six topics and six activities for CHE 242 that could be implemented through the hybrid learning approach. The research employed the analysis, design, development, implementation, and evaluation model but particularly focused on the analysis phase only, in this study. One hundred and two students who enrolled in semester 1 of the 2016/2017 academic year chemistry major class participated in the study. The instrument for data collection was the basic analytical chemistry concept test. The results from the test showed that the participants were weak in answering conversion factor, computational, and stoichiometric problems. They also had challenges with fundamental conceptual problems such as understanding and applying principles about limiting reactants, percentage yield, and chemical reactions. These observed weaknesses were noted to be incorporated into building an e-content that would ensure that students have adequate electronic or online practice to overcome their challenges in learning basic analytical chemical concepts.},
  langid = {english},
  keywords = {Blended Learning,Chemistry,College Science,Concept Formation,Course Content,Electronic Learning,Instructional Design,Learning Problems,Majors (Students),Models,Needs Assessment,Science Instruction,Science Tests,Scientific Concepts,Teaching Methods,Undergraduate Students}
}

@book{hanssonJobRelatedTrainingBenefits,
  title = {Job-{{Related Training}} and {{Benefits}} for {{Individuals}}},
  author = {Hansson, B.},
  annotation = {{$<$}!--// //--{$>$}}
}

@article{hardwickDismantlingNarrativesSettler2015,
  title = {Dismantling {{Narratives}}: {{Settler Ignorance}}, {{Indigenous Literature}} and the {{Development}} of a {{Decolonizing Discourse}}},
  author = {Hardwick, J.},
  year = {2015},
  journal = {Topia-Canadian Journal of Cultural Studies},
  number = {33},
  pages = {99--118},
  issn = {1206-0143},
  abstract = {In an article for the Aboriginal Healing Foundation, Taiaiake Alfred argues that "[t]he complete ignorance of Canadian society about the facts of their relationship with Indigenous peoples and the willful denial of historical reality by Canadians detracts from the possibility of any meaningful.discussion on true reconciliation" (2009: 181). Alfred goes on: "Meal change will happen only when settlers are forced into a reckoning of who they are, what they have done, and what they have inherited" (184). Despite years of work by Canada's Truth and Reconciliation Commission, the reckoning Alfred speaks of seems a long way off. The majority of Canadians remain ignorant of the history of their country, and removed from colonialism's current manifestations and long-term implications. Some scholars consider the failure to engage in decolonization an act of denial-a choice on the part of beneficiaries who are unwilling to go through the uncomfortable process of decolonization. Others acknowledge the role of widespread ignorance, noting that few Canadians are educated about the history of colonization. Despite theorizing both ignorance and denial, scholars have not explored the connection between the two; as a result, ignorance and denial are often conflated in discussions of Canadian settler culture. In an attempt to better understand the relationship between settler ignorance and denial, this paper will explore the ways that knowledge conditioned by colonial frameworks can prevent settler Canadians from engaging in acts of decolonization. Twill analyze two Ontario Ministry of Education-approved secondary-school history books in relation to a study conducted at Queen's University in 2010 to argue that the Ontario education system strengthens settler ignorance and privileges colonial ideals. I will then analyze Thomas King's short story "Borders" (1993) from an assimilationist perspective in order to highlight how settler ignorance can lead to a denial of colonialism and a perpetuation of colonial ideals, even in the face of decolonizing narratives.},
  keywords = {Alfred Taiaiake,Canada,Colonialism,CULTURAL STUDIES,Decolonization,education,history,ignorance,Indigenous,literature,Native North Americans,pedagogy,settler culture}
}

@article{harlandAssessmentArmsRace2015,
  title = {An Assessment Arms Race and Its Fallout: High-Stakes Grading and the Case for Slow Scholarship},
  shorttitle = {An Assessment Arms Race and Its Fallout},
  author = {Harland, Tony and McLean, Angela and Wass, Rob and Miller, Ellen and Sim, Kwong Nui},
  year = {2015},
  month = may,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {40},
  number = {4},
  pages = {528--541},
  issn = {0260-2938, 1469-297X},
  doi = {10/gcpht6},
  urldate = {2021-04-04},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/EEU8UN3T/harlandAssessmentArmsRace2015.pdf}
}

@article{harlenSystematicReviewImpact2002,
  title = {A Systematic Review of the Impact of Summative Assessment and Tests on Students' Motivation for Learning},
  author = {Harlen, Wynne and Deakin Crick, Ruth},
  year = {2002},
  journal = {Research Evidence in Education Library},
  number = {1},
  pages = {151},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/3PQDK89U/harlenSystematicReviewImpact2002.pdf}
}

@incollection{harringLongitudinalModelsRepeated2016,
  title = {Longitudinal Models for Repeated Measures Data},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {Harring, Jeffrey R. and Houser, Ari},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch12},
  pages = {267--296},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch12},
  abstract = {Summary Recent years have seen an explosion of empirical longitudinal research. The importance that practitioners are placing on longitudinal designs and analyses signals a critical shift toward methods that enable a better understanding of developmental processes thought to underlie many human attributes and behaviors. To keep up with the convergence of complex data-analytic conditions and data types often found in practice, statistical methods have been extended in numerous ways to accommodate these nuances. Using reading comprehension and linguistic skills data, the focus of this chapter is to elucidate two families of models to illustrate how each can support the functionality of assessments as a research tool for refining theories of reading development.},
  chapter = {12},
  isbn = {978-1-118-95658-8},
  keywords = {discrete longitudinal models,growth mixture modeling,latent class analysis,latent growth modeling,longitudinal}
}

@incollection{harrisCateringDiversityDigital2020,
  title = {Catering for {{Diversity}} in the {{Digital Age}}: {{Reconsidering Equity}} in {{Assessment Practices}}},
  shorttitle = {Catering for {{Diversity}} in the {{Digital Age}}},
  booktitle = {Re-Imagining {{University Assessment}} in a {{Digital World}}},
  author = {Harris, Lois Ruth and Dargusch, Joanne},
  editor = {Bearman, Margaret and Dawson, Phillip and Ajjawi, Rola and Tai, Joanna and Boud, David},
  year = {2020},
  volume = {7},
  pages = {95--110},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-41956-1_8},
  urldate = {2022-03-19},
  isbn = {978-3-030-41955-4 978-3-030-41956-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/6DLK77GU/harrisCateringDiversityDigital2020.pdf}
}

@article{harrisDesigningKnowledgeUse2019,
  title = {Designing {{Knowledge}}-{{In}}-{{Use Assessments}} to {{Promote Deeper Learning}}},
  author = {Harris, Christopher J. and Krajcik, Joseph S. and Pellegrino, James W. and DeBarger, Angela Haydel},
  year = {2019},
  month = jun,
  journal = {Educational Measurement: Issues and Practice},
  volume = {38},
  number = {2},
  pages = {53--67},
  issn = {0731-1745, 1745-3992},
  doi = {10/gg8f5d},
  urldate = {2021-01-27},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/G9WT8Q66/harrisDesigningKnowledgeUse2019.pdf}
}

@article{harrisIndigeneityAlternativeWorldview2004,
  title = {Indigeneity, an Alternative Worldview: Four {{R}}'s (Relationship, Responsibility, Reciprocity, Redistribution) vs. Two {{P}}'s (Power and Profit). {{Sharing}} the Journey towards Conscious Evolution},
  shorttitle = {Indigeneity, an Alternative Worldview},
  author = {Harris, La Donna and Wasilewski, Jacqueline},
  year = {2004},
  month = sep,
  journal = {Systems Research and Behavioral Science},
  volume = {21},
  number = {5},
  pages = {489--503},
  issn = {1092-7026, 1099-1743},
  doi = {10.1002/sres.631},
  urldate = {2024-03-14},
  abstract = {Abstract                            La Donna Harris, founder of Americans for Indian Opportunity (AIO), discusses the two-decade-long collaboration between AIO and Alexander Christakis, President of ISSS, and other systems scientists. Structured dialogue processes have provided culturally resonant means through which Indigenous peoples have been able to identify and articulate their core values to broader audiences, especially the four R's (Relationship, Responsibility, Reciprocity and Redistribution). These Four R's form the core of an emerging concept,               Indigeneity               . The dynamic inclusivity of this value cluster has much to contribute to global discourse as we go about the task of constructing global               agoras               , the dialogic spaces of optimal mutual learning of the 21st century. Copyright {\copyright} 2004 John Wiley \& Sons, Ltd.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/5L49LL89/harrisIndigeneityAlternativeWorldview2004.pdf}
}

@article{harrisonCrossSectionalStudyDescribe2017,
  title = {A {{Cross-Sectional Study}} to {{Describe Academics}}' {{Confidence}}, {{Attitudes}}, and {{Experience}} of {{Online Distance Learning}} in {{Higher Education}}},
  author = {Harrison, Roger and Hutt, Ian and {Thomas-Varcoe}, Catherine and Motteram, Gary and Else, Kathryn and Rawlings, Barbara and Gemmell, Isla},
  year = {2017},
  journal = {Journal of Educators Online},
  volume = {14},
  number = {2},
  issn = {EISSN-1547-500X},
  doi = {10/gfph2s},
  abstract = {Previous research, mainly from North America and Asia, has highlighted how many academics in Higher Education Institutions (HEIs) are concerned about the academic integrity of online distance learning (ODL) compared with face-to-face-teaching and its impact on their work and the student learning experience. Far less is known about this topic for HEIs in the UK, which historically has been slow to adopt technology-enhanced learning overall. The aim of the current study was to determine the attitudes to and experiences of ODL amongst academics in a UK HEI from their own perspective, their students, and that of external stakeholders. The study was based in a long-established HEI in the north of England, UK. Data were collected using an anonymous, self-completion electronic questionnaire which was distributed to academics across the institution. The survey was completed by 531 academics from four of the different faculties. Most of the responders were confident using standard learning management systems for their online teaching, but few were using tools such as social media and web conferencing to engage with students. At least a third of responders expressed positive attitudes to ODL, both from their own and their students' perspectives, and they believed ODL was necessary to maintain student numbers in the future. Those not already doing so also expressed an interest in starting to teach on an ODL. However, not all academics supported ODL, and additional concerns extended to the perceptions of employers, professional organisations, and other countries towards this type of education. The attitudes and experiences of academics in a UK HEI towards ODL varied across a range of teaching-related topics. The results confirm that some academics are confident using online technology for teaching purposes and that they identify with benefits for their students' learning experience. A large proportion wanted to increase their involvement with ODL, and some believed that their faculty needed to increase the ODL provision to maintain the current number of registered students. There was a suggestion that an important number of employers, professional organisations, and even some countries did not believe qualifications awarded through ODL were at least equivalent to those from face-to-face teaching. Consequently, if the HEI is seeking to increase its ODL provision, then there could be benefits from showcasing examples of good practice to academics from within and outside of the HEI. This needs to coincide with demonstrating the effectiveness of ODL, as compared with face-to-face provision from the student, academic, and faculty perspective. Furthermore, this needs to be communicated to students' prospective future employers.},
  langid = {english},
  keywords = {Case Studies,College Faculty,College Students,Conventional Instruction,Distance Education,Foreign Countries,Higher Education,Instructional Effectiveness,Management Systems,Online Courses,Questionnaires,Social Media,Student Attitudes,Teacher Attitudes,Teacher Surveys,Teaching Methods,Technological Literacy,Technology Uses in Education,Videoconferencing}
}

@book{hartleyLearningStudyingResearch1998,
  title = {Learning and Studying: {{A}} Research Perspective},
  author = {Hartley, J},
  year = {1998},
  publisher = {Routledge},
  address = {London, UK}
}

@article{hartmannPoliticalIdeologyConversational2023,
  title = {The Political Ideology of Conversational {{AI}}: {{Converging}} Evidence on {{ChatGPT}}'s pro-Environmental, Left-Libertarian Orientation},
  shorttitle = {The Political Ideology of Conversational {{AI}}},
  author = {Hartmann, Jochen and Schwenzow, Jasper and Witte, Maximilian},
  year = {2023},
  journal = {SSRN Electronic Journal},
  issn = {1556-5068},
  doi = {10.2139/ssrn.4316084},
  urldate = {2023-01-08},
  langid = {english}
}

@unpublished{HarvardResumeGuide,
  title = {Harvard {{Resume Guide}}},
  urldate = {2022-12-31},
  file = {/Users/colin.madland/Zotero/storage/GVV2VIAN/HarvardResumeGuide.pdf}
}

@article{harwellWrongfullyArrestedMan2021,
  title = {Wrongfully Arrested Man Sues {{Detroit}} Police over False Facial Recognition Match},
  author = {Harwell, Drew},
  year = {2021},
  month = apr,
  journal = {Washington Post},
  issn = {0190-8286},
  urldate = {2022-03-16},
  abstract = {The case could fuel criticism of police investigators' use of a controversial technology that has been shown to perform worse on people of color.},
  langid = {american},
  keywords = {archived},
  annotation = {https://web.archive.org/web/20220316155123/https://www.washingtonpost.com/technology/2021/04/13/facial-recognition-false-arrest-lawsuit/},
  file = {/Users/colin.madland/Zotero/storage/L3UIIH25/facial-recognition-false-arrest-lawsuit.html}
}

@article{harwoodAssessingStudentLearning2020,
  title = {Assessing {{Student Learning}} in a {{Rapidly Changing Environment}}: {{Laboratories}} and {{Exams}}},
  author = {Harwood, Cynthia J and Meyer, Jeanne and Towns, Marcy H},
  year = {2020},
  journal = {Journal of chemical education},
  volume = {97},
  number = {9},
  pages = {3110--3113},
  publisher = {{American Chemical Society and Division of Chemical Education, Inc}},
  address = {WASHINGTON},
  issn = {0021-9584},
  doi = {10.1021/acs.jchemed.0c00651},
  abstract = {The purpose of this communication is to describe and document the challenges of delivering a general chemistry laboratory experience to students and of moving toward multiple small assessments and away from high-stakes examinations. By leveraging of activities that were already in place prior to the pivot to online learning, namely, an electronic laboratory notebook through bluedoorlabs and assessments that emphasized student reasoning, these challenges were addressed. Herein our approach to providing a meaningful laboratory experience and lower-stakes assessments is described. On the basis of our experiences in Spring 2020, we look forward to the fall semester, where the university is committed to reopening in a dedensified fashion with students in classrooms and laboratories.},
  keywords = {Assessments,Changing environments,Chemistry,Chemistry Multidisciplinary,Cognition & reasoning,College students,Colleges & universities,Education & Educational Research,Education Scientific Disciplines,Educational Change,High Stakes Tests,Laboratories,Learning,Learning Experience,Physical Sciences,Reasoning,Science & Technology,Science Activities,Science Laboratories,Science Tests,Social Sciences,Student Evaluation,Students}
}

@article{hastHigherEducationTimes2021,
  title = {Higher {{Education}} in {{Times}} of {{COVID-19}}: {{Giving Online Feedback Implementation Another Look}}},
  author = {Hast, Michael},
  year = {2021},
  journal = {Higher Education Studies},
  volume = {11},
  number = {1},
  pages = {1--7},
  issn = {ISSN-1925-4741},
  doi = {10/gmbvzm},
  abstract = {This short reflection piece seeks to examine the importance of online feedback in light of higher education student experiences during times of COVID-19. In doing so, it seeks to address how online approaches need to be harnessed further to minimise experiences of "missing out" of education. The review summarises key advantages provided by online feedback implementation at the university level. It then continues by outlining the main challenges in this domain -- challenges that will be even more pertinent in the current climate. Finally, the conclusion offers some thoughts on how student engagement with online feedback might be fostered further, in the hopes of mitigating the interference emphasised by the current global situation.},
  langid = {english},
  keywords = {College Students,Computer Mediated Communication,COVID-19,Educational Technology,Electronic Learning,Feedback (Response),Higher Education,Online Courses,Pandemics}
}

@incollection{hattieFeedbackSchools2011,
  title = {Feedback in Schools},
  booktitle = {Feedback: {{The}} Communication of Praise, Criticism, and Advice},
  author = {Hattie, John},
  editor = {Sutton, R and Hornsey, M.J. and Douglas, K.M.},
  year = {2011},
  publisher = {Peter Lang Publishing},
  address = {New York},
  urldate = {2014-08-14}
}

@article{hattiePowerFeedback2007,
  title = {The Power of Feedback},
  shorttitle = {The Power of Feedback},
  author = {Hattie, John and Timperley, Helen},
  year = {2007},
  month = mar,
  journal = {Review of Educational Research},
  volume = {77},
  pages = {81--112},
  doi = {10.3102/003465430298487},
  abstract = {Feedback is one of the most powerful influences on learning and achievement, but this impact can be either positive or negative. Its power is frequently mentioned in articles about learning and teaching, but surprisingly few recent studies have systematically investigated its meaning. This article provides a conceptual analysis of feedback and reviews the evidence related to its impact on learning and achievement. This evidence shows that although feedback is among the major influences, the type of feedback and the way it is given can be differentially effective. A model of feedback is then proposed that identifies the particular properties and circumstances that make it effective, and some typically thorny issues are discussed, including the timing of feedback and the effects of positive and negative feedback. Finally, this analysis is used to suggest ways in which feedback can be used to enhance its effectiveness in classrooms.},
  annotation = {1},
  file = {/Users/colin.madland/Zotero/storage/S6XSMHPJ/hattiePowerFeedback2007.pdf}
}

@book{hattieVisibleLearningSynthesis2010,
  title = {Visible Learning: A Synthesis of over 800 Meta-Analyses Relating to Achievement},
  shorttitle = {Visible Learning},
  author = {Hattie, John},
  year = {2010},
  edition = {Reprinted},
  publisher = {Routledge},
  address = {London},
  isbn = {978-0-203-88733-2 978-0-415-47618-8 978-0-415-47617-1},
  langid = {english}
}

@book{hattieVisibleLearningTeachers2011,
  title = {Visible Learning for Teachers: {{Maximizing}} Impact on Learning},
  shorttitle = {Visible Learning for Teachers: {{Maximizing}} Impact on Learning},
  author = {Hattie, John},
  year = {2011},
  publisher = {Routledge},
  address = {London},
  keywords = {Visual learning}
}

@incollection{hattieWhichStrategiesBest2011,
  title = {Which {{Strategies Best Enhance Teaching}} and {{Learning}} in {{Higher Education}}},
  author = {Hattie, John},
  year = {2011},
  series = {Empirical {{Research}} in {{Teaching}} and {{Learning}}},
  pages = {130--142},
  publisher = {Wiley-Blackwell},
  isbn = {978-1-4443-9534-1},
  keywords = {achievement continuum and reference point - best in higher education meta-analyses effect-sizes and data base,Boyer's four scholarships - scholarship of teaching and learning (SoTL),Hattie and Timperley's model - feedback reducing discrepancies between student understanding and learning intention,higher education three claims - student's learning 'Auvisible'Au key to successful teaching,strategies enhancing teaching and learning - in higher education,student learning 'Auvisible'Au to teacher - enhancing probability of student achievement increasing quality of teaching,the best teachers communication - clear learning intentions criteria for success,the best teachers using multiple teaching strategies - student perspectives in learning,three key strategies - teachers use for enhancing student achievement}
}

@article{hattinghEvaluationSimulationbasedHospital2018,
  title = {Evaluation of a Simulation-Based Hospital Pharmacy Training Package for Pharmacy Students},
  author = {Hattingh, H. Laetitia and Robinson, Denise and Kelly, Alison},
  year = {2018},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {15},
  number = {1},
  pages = {1--15},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-018-0120-3},
  abstract = {This study describes the process undertaken to develop, implement and evaluate a simulation-based training package focused on medication management and reconciliation processes for final year pharmacy students about a patient's hospital journey. A five module training package was developed following a literature review and consultation with stakeholders. The simulation-based package immersed students in a real-life scenario and was delivered to final year pharmacy students over a six-week period in 2016. Data on knowledge, skills and confidence was collected via a survey in the week preceding engagement with the online training package and 1 week post completion of the training. The mean score was compared across four student categories: three categories incorporated students who had not completed a hospital pharmacy placement and one category comprised students who had completed a hospital placement. Qualitative feedback was collected via an online survey at the conclusion of the training program. Of the 79 participants, 44 (55.7\%) completed both the pre and post- test surveys that showed the change in score was statistically significant. There was a significant positive change in mean test scores across all four student categories for the domains of skills, knowledge and confidence. Assessment of students' confidence according to 16 ranking statements also improved markedly post-training. Thirty-one students provided qualitative feedback that was generally positive. The positive outcomes reinforce the rationale to include online simulation-based methodologies as part of pharmacy education programs. The model provides a reproducible framework for online simulated learning activities that could be applied within various professions and educational environments.},
  keywords = {Categories,College students,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computer simulation,Computers and Education,Confidence,Consultation,Distance learning,Domains,Educational Technology,Feedback,Higher Education,Hospital pharmacy,Hospitals,Humanities,Information Systems Applications (incl.Internet),Law,Literature reviews,Medication management,Pharmacy,Pharmacy students,Placement,Qualitative reasoning,Research Article,Simulation,Skills,Statistics for Social Sciences,Students,Training,Training package},
  file = {/Users/colin.madland/Zotero/storage/YIAG6XQM/hattinghEvaluationSimulationbasedHospital2018.pdf}
}

@article{haughneyQualityFeedbackHigher2020,
  title = {Quality of {{Feedback}} in {{Higher Education}}: {{A Review}} of {{Literature}}},
  author = {Haughney, Kathryn and Wakeman, Shawnee and Hart, Laura},
  year = {2020},
  journal = {Education Sciences},
  volume = {10},
  issn = {EISSN-2227-7102},
  doi = {10/gmbv3t},
  abstract = {In raising the standards for professional educators, higher educators must be prepared to provide the highest quality feedback on student performance and work products toward improved outcomes. This review of the literature examined the major findings of 70 quantitative, mixed methods, or qualitative studies found in higher education journals across a range of disciplines. Multiple recommendations and results for feedback emerged which fall into the categories described by Susan Brookhart. This review found research for each of Brookhart's categories, with results indicating differences between the perceptions of adherence to sound feedback practices versus the reality of implementation, the potential for innovative tool use, and a disagreement about the effectiveness of peers for providing effective feedback. Indicators for quality within the research confirmed the importance of commonly accepted standards such as positivity, specificity, timeliness, and encouraging active student participation. Additionally, trends and themes indicated a need for the consistent implementation of the feedback exchange process and flexibility to account for student input/preferences. Greater consistency toward the application of these quality indicators should be undertaken when determining the quality of higher education feedback for preservice teachers prior to undertaking summative licensure assessments.},
  keywords = {College Faculty,College Students,Evaluation Methods,Feedback (Response),Higher Education,Preservice Teachers,Standards,Student Attitudes,Student Evaluation,Teacher Attitudes,Teacher Competencies}
}

@article{haughtStudentAwarenessUse2017,
  title = {Student {{Awareness}} and {{Use}} of {{Rubrics}} in {{Online Classes}}},
  author = {Haught, Patricia A. and Ahern, Terence C. and Ruberg, Laurie F.},
  year = {2017},
  journal = {Higher Education Studies},
  volume = {7},
  number = {1},
  pages = {69--77},
  issn = {ISSN-1925-4741},
  doi = {10/ggmttq},
  abstract = {The design, development and deployment of online instruction has become standard practice. The focus of the study was on student perceptions of course rubrics and not on the rubrics, themselves, or the instructors. In order to improve student engagement online we conducted an exploratory study of the awareness and perceptions of course rubrics. Fifty graduate students completed an online survey at the end of the semester about their awareness and perceptions of course rubrics. All students reported that they were aware that course rubrics existed. They indicated that they had learned about this information through the course syllabus, professor announcements via email and posts to LMS. Most students reported reviewing rubrics prior to submitting an assignment. One of the key findings from this study was that "students see rubrics" as a mechanism for scaffolding their performance, and thus, instructors need to focus more effort on designing rubrics to accomplish more than student assessment.},
  langid = {english},
  keywords = {Assignments,College Faculty,Course Descriptions,Distance Education,Electronic Mail,Graduate Students,Learner Engagement,Management Systems,Online Courses,Online Surveys,Scoring Rubrics,Student Attitudes,Student Surveys,Teacher Student Relationship}
}

@article{havilandComplianceUsingOrganizational2014,
  title = {Beyond {{Compliance}}: {{Using Organizational Theory}} to {{Unleash}} the {{Potential}} of {{Assessment}}},
  author = {Haviland, Don},
  year = {2014},
  month = sep,
  journal = {Community College Journal of Research and Practice},
  volume = {38},
  number = {9},
  pages = {755--765},
  publisher = {Routledge},
  issn = {1066-8926},
  doi = {10.1080/10668926.2012.711144},
  abstract = {This article illustrates how organizational theory can be used to support the development of authentic assessment practice among community college faculty, as well as guide research on implementation of assessment efforts. While many factors make implementing assessment difficult, the link between accreditation and assessment is a key element in distancing the practice from faculty. This dynamic arises not from the actions of accreditation agencies per se, but from the accountability narrative that has come to dominate both assessment and accreditation, the corresponding perception that assessment is ?done to? faculty rather than by them, and a reliance among institutional leaders to echo this message in an effort to get assessment started. The result is implementation of assessment for compliance rather than meaningful program improvement. Understanding assessment as an innovation, and using organizational theory to guide implementation, may help community college leaders transcend this challenge and develop assessment practice that is more faculty-owned and meaningful. However, the current literature says little about how to use organizational theory to implement such assessment efforts. This article integrates Bolman and Deal?s (2008) framework on leadership and organizational change with actual examples of practice to illustrate how their model might be used to recapture the potential of assessment as well as guide research on effective implementation.},
  file = {/Users/colin.madland/Zotero/storage/SB9QDJ9T/Beyond Compliance Using Organizational Theory to Unleash the Potential of Assessment.pdf}
}

@article{haydukSeeingPerfectlyFitting2014,
  title = {Seeing {{Perfectly Fitting Factor Models That Are Causally Misspecified}}: {{Understanding That Close-Fitting Models Can Be Worse}}},
  shorttitle = {Seeing {{Perfectly Fitting Factor Models That Are Causally Misspecified}}},
  author = {Hayduk, Leslie},
  year = {2014},
  month = dec,
  journal = {Educational and Psychological Measurement},
  volume = {74},
  number = {6},
  pages = {905--926},
  issn = {0013-1644, 1552-3888},
  doi = {10.1177/0013164414527449},
  urldate = {2024-07-24},
  abstract = {Researchers using factor analysis tend to dismiss the significant ill fit of factor models by presuming that if their factor model is close-to-fitting, it is probably close to being properly causally specified. Close fit may indeed result from a model being close to properly causally specified, but close-fitting factor models can also be seriously causally misspecified. This article illustrates a variety of nonfactor causal worlds that are perfectly, but inappropriately, fit by factor models. Seeing nonfactor worlds that are perfectly yet erroneously fit via factor models should help researchers understand that close-to-fitting factor models may seriously misrepresent the world's causal structure. Statistical cautions regarding the factor model's proclivity to fit when it ought not to fit have been insufficiently publicized and are rarely heeded. A research commitment to understanding the world's causal structure, combined with clear examples of factor mismodeling should spur diagnostic assessment of significant factor model failures---including reassessment of published failing factor models.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/YNFBQQQE/haydukSeeingPerfectlyFitting2014.pdf}
}

@article{haydukShouldResearchersUse2012,
  title = {Should Researchers Use Single Indicators, Best Indicators, or Multiple Indicators in Structural Equation Models?},
  author = {Hayduk, Leslie A. and Littvay, Levente},
  year = {2012},
  month = oct,
  journal = {BMC Medical Research Methodology},
  volume = {12},
  number = {1},
  pages = {159},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-12-159},
  abstract = {Structural equation modeling developed as a statistical melding of path analysis and factor analysis that obscured a fundamental tension between a factor preference for multiple indicators and path modeling's openness to fewer indicators.},
  file = {/Users/colin.madland/Zotero/storage/KGGAZDLE/haydukShouldResearchersUse2012.pdf}
}

@article{haydukTestingTestingOne2007,
  title = {Testing! Testing! One, Two, Three -- {{Testing}} the Theory in Structural Equation Models!},
  author = {Hayduk, Leslie and Cummings, Greta and Boadu, Kwame and {Pazderka-Robinson}, Hannah and Boulianne, Shelley},
  year = {2007},
  month = may,
  journal = {Personality and Individual Differences},
  volume = {42},
  number = {5},
  pages = {841--850},
  issn = {01918869},
  doi = {10.1016/j.paid.2006.10.001},
  urldate = {2024-07-23},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/C8DXZIEJ/haydukTestingTestingOne2007.pdf}
}

@article{hayMakingLearningVisible2008,
  title = {Making Learning Visible: The Role of Concept Mapping in Higher Education},
  shorttitle = {Making Learning Visible},
  author = {Hay, David and Kinchin, Ian and Lygo-Baker, Simon},
  year = {2008},
  month = jun,
  journal = {Studies in Higher Education},
  volume = {33},
  number = {3},
  pages = {295--311},
  issn = {0307-5079, 1470-174X},
  doi = {10.1080/03075070802049251},
  urldate = {2023-06-19},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/L9E4QRSP/hayMakingLearningVisible2008.pdf}
}

@article{haywardAssessmentLearningPreposition2015,
  title = {Assessment Is Learning: The Preposition Vanishes},
  shorttitle = {Assessment Is Learning},
  author = {Hayward, Louise},
  year = {2015},
  month = jan,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {22},
  number = {1},
  pages = {27--43},
  issn = {0969-594X, 1465-329X},
  doi = {10.1080/0969594X.2014.984656},
  urldate = {2022-04-08},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/CN7IJSJV/haywardAssessmentLearningPreposition2015.pdf}
}

@techreport{hbeethamOpenPracticesBriefing2012,
  type = {Briefing {{Paper}}},
  title = {Open {{Practices Briefing}}},
  author = {{H Beetham} and {I Falconer} and {L McGill} and {A Littlejohn}},
  year = {2012},
  urldate = {2018-11-04},
  keywords = {oep},
  file = {/Users/colin.madland/Zotero/storage/HTPKUT42/OpenPracticesBriefing.html}
}

@article{heathcoteFactorsAffectingUniversity2020,
  title = {Factors {{Affecting University Choice Behaviour}} in the {{UK Higher Education}}},
  author = {Heathcote, Dean and Savage, Simon and {Hosseinian-Far}, Amin},
  year = {2020},
  journal = {Education Sciences},
  volume = {10},
  issn = {EISSN-2227-7102},
  abstract = {Although regulations and established practices in academia have focused on a data-rich model of performance information, both to evidence operational capability and to support recruitment, it is considered that this approach has been largely ineffective in addressing student choice behaviour. Historical studies, business, psychology, and technology theories have pointed to the oversimplification that a data-led strategy can result in for mapping human behaviour. In this case, decision processes of students are understood to be nuanced by a vast range of factors with variable relevance for everyone. The effort of the study is to address how Systems Thinking, related policy development, and associated enabling techniques can be applied to the field to provide both a deeper understanding of the dictates of student behaviour and, by extension, the appropriate foci for data provision, enabling comparative business performance assessment of Higher Education Providers. This research has followed the Design Science Research (DSR) methodology; the developed model has been successfully evaluated against the understanding of education practitioners in an interview consultation process of the methodology. The analysis of interview feedback and the development and refinement of the proposed model generate the principle findings of the study. The model outlines the factors that might affect students' choices in the UK Higher Education.},
  keywords = {College Bound Students,College Choice,Decision Making,Foreign Countries,Influences,Institutional Characteristics,Models,No DOI found,Student Behavior,Student Characteristics,Student Recruitment}
}

@article{hebertOnlineRemoteProctoring2021,
  title = {Online {{Remote Proctoring Software}} in the {{Neoliberal Institution}}: {{Measurement}}, {{Accountability}}, and {{Testing Culture}}},
  shorttitle = {Online {{Remote Proctoring Software}} in the {{Neoliberal Institution}}},
  author = {H{\'e}bert, Cristyne},
  year = {2021},
  month = dec,
  journal = {in education},
  volume = {27},
  number = {1},
  pages = {23--40},
  issn = {1927-6117},
  doi = {10.37119/ojs2021.v27i1.507},
  urldate = {2022-05-29},
  abstract = {As COVID-19 spread in early 2020, a lockdown was implemented across Canadian provinces andterritories, resulting in the shuttering of physical post-secondary campuses. Universities quicklypivoted to remote learning, and faculty members adjusted their instructional and assessmentapproaches to align with virtual environments. Presumably to aid with this process, a number ofinstitutions acquired licenses to remote online proctoring services. This paper examines theresearch around online remote proctoring, examining the justification offered for the adoption ofonline remote proctoring, and contemporary research on assessment practices in higher education.Throughout the paper, I demonstrate a lack of research that speaks to the efficacy of this mode ofassessment while also acknowledging shifts in the testing environment, and an increase in studentanxiety. I argue that online remote proctoring is not only embedded within neoliberalism and auditculture, but supports a continued reliance on testing culture. It concludes with a discussion ofassessment culture, offering some alternative assessment approaches that might disrupt the veryneed for online remote proctoring.  Keywords: Online remote proctoring, assessment, testing},
  file = {/Users/colin.madland/Zotero/storage/CLQJJMHB/hebertOnlineRemoteProctoring2021.pdf}
}

@article{hedtrichUsingSoftwareTools2018,
  title = {Using {{Software Tools To Provide Students}} in {{Large Classes}} with {{Individualized Formative Feedback}}},
  author = {Hedtrich, Sebastian and Graulich, Nicole},
  year = {2018},
  journal = {Journal of chemical education},
  volume = {95},
  number = {12},
  pages = {2263--2267},
  publisher = {{American Chemical Society and Division of Chemical Education, Inc}},
  address = {WASHINGTON},
  issn = {0021-9584},
  doi = {10.1021/acs.jchemed.8b00173},
  abstract = {Students at the university level spend more and more time in learning management systems (LMSs), which support current teaching by offering online tutorials or units. These LMSs allow individual preparation for the students, especially in large classes. However, students' learning in these online systems is often not supported by detailed formative feedback, as the options for this in current LMSs are quite limited. Formative feedback should be connected with the learning objective or competencies of the course, but formative feedback in an LMS is limited to single tasks or tests and does not allow one to focus on competencies across tasks. We have developed two easy-to-use software tools that enable teachers to use data from the LMS to quickly create an automated formative feedback that can be sent to students. First evaluations of the average final exam scores of different classes show that this new type of formative feedback seems to have a medium-scale effect on students' final exam scores~according to Cohen.},
  keywords = {CAI,Chemistry,Chemistry Multidisciplinary,College Science,College students,Colleges & universities,Computer assisted instruction,Computer Software,Distance learning,Education & Educational Research,Education Scientific Disciplines,Educational Technology,Feedback,Feedback (Response),Formative Evaluation,Integrated Learning Systems,Learning management systems,Management systems,On-line systems,Online instruction,Physical Sciences,Scale effect,Science & Technology,Science Instruction,Social Sciences,Software,Software development tools,Student Evaluation,Students,Teachers,Technology Uses in Education,Undergraduate Study},
  file = {/Users/colin.madland/Zotero/storage/FWY5BHNG/hedtrichUsingSoftwareTools2018.pdf}
}

@article{hegartyAttributesOpenPedagogy2015,
  title = {Attributes of {{Open Pedagogy}}: {{A Model}} for {{Using Open Educational Resources}}},
  author = {Hegarty, Bronwyn},
  year = {2015},
  journal = {Educational Technology},
  volume = {55},
  number = {4},
  pages = {3--13},
  issn = {00131962},
  abstract = {[Open Educational Resources (OER) have swept in on a tide of digital information and brought sweeping changes to learning and teaching. In this article, the author establishes a rationale for the term open pedagogy, and, using current research, presents eight attributes of open pedagogy grounded in the concept of openness and Open Educational Practice (OEP). Participatory technologies present many challenges for educators, who may not know how to use them appropriately to effect change in the new culture of learning that is evolving. The question is, how can an open pedagogy benefit learners and teachers alike, and precipitate creative and inclusive communities in an OEPosphere?]}
}

@article{heHigherEducationChina2021,
  title = {Higher {{Education}} in {{China}}, a {{Paradigm Shift}} from {{Conventional}} to {{Online Teaching}}},
  author = {He, Wang and Wei, Gao},
  year = {2021},
  journal = {Higher Education Studies},
  volume = {11},
  number = {2},
  pages = {30--41},
  issn = {ISSN-1925-4741},
  doi = {10/gmbvzh},
  abstract = {The entire education system, from elementary school to higher education, distorted during the lockdown period. The latest 2019 coronavirus disease (COVID-19) is not only recorded in China, but also globally. This research is an account of the online teaching paradigm assumed in the teaching method by most of universities in China and subsequent tests over the course. It looks forward to offering resources rich in knowledge for future academic decision-making in any adversity. The aim of this research paper is to explain the prerequisites for online education and teaching during the COVID-19 pandemic and how to effectively turn formal education into online education through the use of virtual classrooms and other main online instruments in an ever-changing educational setting by leveraging existing educational tools. The paper uses both quantitative and qualitative research approaches to analyses the views of online teachers and students on the learning regime, with specific attention to the online learning regime implementation process. In the midst of the COVID-19 outbreak, the purpose of this article is to provide an in-depth overview of online learning. These activities took place during a time of isolation, including the creation of a link between the process of change management and the online learning process in the education system to tackle current issues of academic interference and, however, the re-establishment of educational practice and debate as a normal system of procedural education.},
  langid = {english},
  keywords = {College Faculty,College Students,COVID-19,Decision Making,Educational Change,Educational Planning,Educational Policy,Educational Practices,Foreign Countries,Futures (of Society),Higher Education,Learning Processes,Online Courses,Pandemics,Social Isolation,Student Attitudes,Teacher Attitudes,Teaching Methods,Virtual Classrooms}
}

@article{heilpornEngagementEtudiantsEchelle2021,
  title = {Engagement Des {\'E}tudiants : Une {\'E}chelle de Mesure Multidimensionnelle Appliqu{\'e}e {\`a} Des Modalit{\'e}s de Cours Hybrides Universitaires},
  shorttitle = {Engagement Des {\'E}tudiants},
  author = {Heilporn, G{\'e}raldine and Lakhal, Sawsen and B{\'e}lisle, Marilou and {St-Onge}, Christina},
  year = {2021},
  month = sep,
  journal = {Mesure et {\'e}valuation en {\'e}ducation},
  volume = {43},
  number = {2},
  pages = {1--34},
  issn = {2368-2000, 0823-3993},
  doi = {10.7202/1081043ar},
  urldate = {2022-06-16},
  abstract = {Les modalit{\'e}s de cours hybrides, qui combinent des activit{\'e}s synchrones (en classe ou virtuelles) et en ligne asynchrones, repr{\'e}sentent un terrain potentiel d'augmentation du niveau d'engagement des {\'e}tudiants dans leurs cours. L'{\'e}tude de l'engagement des {\'e}tudiants dans ces modalit{\'e}s n{\'e}cessite toutefois l'{\'e}laboration d'une {\'e}chelle de mesure, soit l'objectif de cet article. La nouvelle {\'E}chelle multidimensionnelle d'engagement des {\'e}tudiants dans des modalit{\'e}s de cours hybrides (EMEECH) vient outiller chercheurs et formateurs pour mesurer l'engagement des {\'e}tudiants dans ces modalit{\'e}s selon une perspective multidimensionnelle. Nous pr{\'e}sentons son {\'e}laboration ainsi que des preuves de validit{\'e} pour sa structure interne obtenues par analyses factorielles exploratoires et de coh{\'e}rence interne sur la base de donn{\'e}es diversifi{\'e}es provenant de trois institutions universitaires. Un premier {\'e}chantillon (n                                    1                                  ~=~234) a permis d'identifier trois dimensions de l'engagement des {\'e}tudiants~: {\'e}motionnelle-cognitive, sociale et comportementale. Un second {\'e}chantillon (n                                    2                                  ~=~231) a appuy{\'e} la structure interne de la nouvelle {\'e}chelle en confirmant sa structure factorielle et en pr{\'e}sentant une tr{\`e}s bonne coh{\'e}rence interne.                                       ,                                              Blended learning course environments combine synchronous activities (in face-to-face or virtual classrooms) with asynchronous online activities, and they represent a fertile ground for enhancing student engagement. However, studying student engagement in these environments requires the development of a measurement scale, which is the purpose of this paper. The new measurement scale {\'E}chelle multidimensionnelle d'engagement des {\'e}tudiants dans des modalit{\'e}s de cours hybrides (EMEECH) provides researchers and instructors with tools for assessing student engagement in blended courses (blended, blended online or blended synchronous) from a multidimensional perspective. Its elaboration is presented, accompanied by evidence of validity for its internal structure obtained through exploratory factor and internal consistency analyses based on diversified data from three academic institutions. A first sample (n                                    1                                  =234) allowed identifying three dimensions to student engagement: emotional-cognitive, social and behavioral. A second sample (n                                    2                                  =231) provided further evidence of the internal structure of the new scale by confirming its factorial structure and its very good internal consistency.                                       ,                                              As modalidades de cursos h{\'i}bridos, que combinam atividades s{\'i}ncronas (em sala de aula ou virtuais) e ass{\'i}ncronas online, representam um campo potencial para aumentar o n{\'i}vel de envolvimento dos estudantes nos seus cursos. O estudo do envolvimento dos estudantes nestas modalidades requer, em todo o caso, o desenvolvimento de uma escala de medi{\c c}{\~a}o, que {\'e} o objetivo deste artigo. A nova Escala Multidimensional para o Envolvimento dos estudantes em modalidades de cursos h{\'i}bridos (EMEECH) fornece um instrumento para investigadores e formadores medirem o envolvimento dos estudantes nestas modalidades a partir de uma perspetiva multidimensional. Apresentamos a sua elabora{\c c}{\~a}o, bem como as provas de validade da sua estrutura interna obtidas por an{\'a}lises fatoriais explorat{\'o}rias e coer{\^e}ncia interna, tendo por base diversos dados de tr{\^e}s institui{\c c}{\~o}es universit{\'a}rias. Uma primeira amostra (n                                    1                                  ~=~234) identificou tr{\^e}s dimens{\~o}es do envolvimento dos estudantes: emocional-cognitiva, social e comportamental. Uma segunda amostra (n                                    2                                  ~=~231) apoiou a estrutura interna da nova escala, confirmando a sua estrutura fatorial e apresentando uma coer{\^e}ncia interna muito boa.},
  file = {/Users/colin.madland/Zotero/storage/BREK7RX9/heilpornEngagementEtudiantsEchelle2021.pdf;/Users/colin.madland/Zotero/storage/LTB3C3MD/heilpornEngagementEtudiantsEchelle2021.pdf}
}

@article{heilpornInvestigatingReliabilityValidity2020,
  title = {Investigating the Reliability and Validity of the Community of Inquiry Framework: {{An}} Analysis of Categories within Each Presence},
  shorttitle = {Investigating the Reliability and Validity of the Community of Inquiry Framework},
  author = {Heilporn, G{\'e}raldine and Lakhal, Sawsen},
  year = {2020},
  month = feb,
  journal = {Computers \& Education},
  volume = {145},
  pages = {103712},
  issn = {03601315},
  doi = {10.1016/j.compedu.2019.103712},
  urldate = {2022-06-08},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/FKFSFUAA/heilpornInvestigatingReliabilityValidity2020.pdf}
}

@article{heinonenUniversityTeachersDevelopers2019,
  title = {University {{Teachers}} as {{Developers}} of {{Technology-Enhanced Teaching}}---{{Do Beliefs Matter}}?},
  author = {Heinonen, Kirsi and J{\"a}{\"a}skel{\"a}, P{\"a}ivikki and H{\"a}kkinen, P{\"a}ivi and Isom{\"a}ki, Hannakaisa and H{\"a}m{\"a}l{\"a}inen, Raija},
  year = {2019},
  month = apr,
  journal = {Journal of Research on Technology in Education},
  volume = {51},
  number = {2},
  pages = {135--151},
  issn = {1539-1523, 1945-0818},
  doi = {10.1080/15391523.2018.1564894},
  urldate = {2022-08-18},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/IVAP26CQ/heinonenUniversityTeachersDevelopers2019.pdf}
}

@article{heiserOnlineAccountingEducation2020,
  title = {Online {{Accounting Education}}: {{How}} to {{Improve Security}} and {{Integrity}} of {{Students}}' {{Performance Assessments}}},
  author = {Heiser, Robert S. and McArthur, David},
  year = {2020},
  journal = {Journal of Instructional Pedagogies},
  volume = {24},
  issn = {ISSN-2327-5324},
  abstract = {With an increase in online education, educators face the possibility of compromising convenience for the loss of security and integrity of students' course assessment. The purpose of this study is to seek and evaluate accounting faculty's opinions on improving online course assessment options. The results of this study are expected to impact not only students but also faculty, and accounting practitioners. Faculty will have to be more vigilant in planning their classes by incorporating measures that would improve the integrity and security of students' assessment of knowledge and performance. Accounting practitioners may feel more confident in considering candidates who have completed all or a portion of their degree online.},
  langid = {english},
  keywords = {Accounting,Accreditation (Institutions),Asynchronous Communication,Business Administration Education,Cheating,College Faculty,Educational Quality,Electronic Learning,Information Security,Instructional Design,Integrity,No DOI found,Online Courses,Student Evaluation,Synchronous Communication,Teacher Attitudes}
}

@article{heitinkSystematicReviewPrerequisites2016,
  title = {A Systematic Review of Prerequisites for Implementing Assessment for Learning in Classroom Practice},
  author = {Heitink, M.C. and {Van der Kleij}, F.M. and Veldkamp, B.P. and Schildkamp, K. and Kippers, W.B.},
  year = {2016},
  month = feb,
  journal = {Educational Research Review},
  volume = {17},
  pages = {50--62},
  issn = {1747938X},
  doi = {10/gf5z3k},
  urldate = {2021-03-21},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/FKLVLBWU/heitinkSystematicReviewPrerequisites2016.pdf}
}

@article{heldDecolonizingResearchParadigms2019,
  title = {Decolonizing {{Research Paradigms}} in the {{Context}} of {{Settler Colonialism}}: {{An Unsettling}}, {{Mutual}}, and {{Collaborative Effort}}},
  author = {Held, Mirjam B. E.},
  year = {2019},
  journal = {International Journal of Qualitative Methods},
  volume = {18},
  issn = {1609-4069},
  doi = {10.1177/1609406918821574},
  urldate = {2019-02-24},
  abstract = {All research is guided by a set of philosophical underpinnings. Indigenous methodologies are in line with an Indigenous paradigm, while critical and liberatory methodologies fit with the transformative paradigm. Yet Indigenous and transformative methodologies share an emancipatory and critical stance and thus are increasingly used in tandem by both Western and Indigenous scholars in an attempt to decolonize methodologies, research, and the academy as a whole. However, these multiparadigmatic spaces only superficially support decolonization which, in the Canadian context of settler colonialism, is a radical and unsettling prospect that is about land, resources, and sovereignty. Applying this definition of decolonization to the decolonization of research paradigms, this article suggests that such paradigms must be developed, from scratch, conjointly between Indigenous and Western researchers.},
  file = {/Users/colin.madland/Zotero/storage/LSAIJRU9/heldDecolonizingResearchParadigms2019.pdf}
}

@article{helenraptisBlurringBoundariesPolicy2015,
  title = {Blurring the {{Boundaries}} of {{Policy}} and {{Legislation}} in the {{Schooling}} of {{Indigenous Children}} in {{British Columbia}}, 1901-1951},
  author = {{Helen Raptis}},
  year = {2015},
  journal = {Historical Studies in Education / Revue d'histoire de l'{\'e}ducation},
  volume = {27},
  number = {2},
  urldate = {2018-11-05},
  abstract = {AbstractHistorical accounts of Indigenous education maintain that until the early 1950s settler and Indigenous children were educated in separate facilities regulated under separate legislation and overseen by separate authorities. This study illustrates that in British Columbia between 1901 and 1951, the dual system of schooling seemingly embodied in government policy was not implemented by federal or provincial authorities as strictly as historians have assumed. This article illuminates the ways that officials from both systems sometimes blurred the boundaries of policies and legislation that officially circumscribed students' lives in order to enhance youngsters' access to education.R{\'e}sum{\'e}Des r{\'e}cits de l'histoire de l'{\'e}ducation autochtone soutiennent que jusqu'au d{\'e}but des ann{\'e}es 1950, les enfants des colons et ceux des autochtones ont {\'e}t{\'e} instruits dans des institutions s{\'e}par{\'e}es, sous des r{\`e}glements et des autorit{\'e}s diff{\'e}rentes. Cette {\'e}tude d{\'e}montre qu'entre 1901 et 1951, en Colombie-Britannique, cette dualit{\'e} du syst{\`e}me d'{\'e}ducation pr{\^o}n{\'e}e par la l{\'e}gislation n'a pas {\'e}t{\'e} appliqu{\'e}e aussi strictement par les autorit{\'e}s f{\'e}d{\'e}rales ou provinciales que les historiens le laissent entendre. Notre {\'e}tude met en lumi{\`e}re les fa{\c c}ons dont certains officiels dans les deux syst{\`e}mes faisaient fi des politiques et des lois encadrant officiellement la vie des {\'e}l{\`e}ves afin de favoriser leur acc{\`e}s {\`a} l'{\'e}ducation.}
}

@article{hemmingStudentVoiceHigher2021,
  title = {Student '{{Voice}}' and {{Higher Education Assessment}}: {{Is It All}} about the {{Money}}?},
  author = {Hemming, Andrew and Power, Margaret},
  year = {2021},
  journal = {Journal of University Teaching and Learning Practice},
  volume = {18},
  number = {1},
  issn = {EISSN-1449-9789},
  abstract = {University administered Student Evaluation of Teaching surveys, while used primarily by educators and their managers to review and improve the quality of courses and teaching, can also be used by universities' marketing campaigns and websites as a means of stressing their institution's student friendliness and responsiveness to students' needs. Changes in assessment practices is one way that tertiary institutions are responding to students' preferences. However, there is a lack of understanding of the underlying factors that moderate decisions about assessment changes. The purpose of this paper is to examine whether or not a meaningful body of research concerning student 'choice' in higher education assessment exists, and how the extent of student 'choice' may change in the future. Emphasis has been placed on the assessment methods adopted in law and professional degrees in Australia. However, a broad review of international research from other relevant higher education discipline areas has also been undertaken in this paper.},
  langid = {english},
  keywords = {College Students,Evaluation Methods,Foreign Countries,Influences,No DOI found,Student Attitudes,Student College Relationship,Student Evaluation of Teacher Performance,Student Participation,Teacher Student Relationship}
}

@article{hendersonBarriersIncentivesBenefits2018,
  title = {Barriers, Incentives, and Benefits of the Open Educational Resources ({{OER}}) Movement: {{An}} Exploration into Instructor Perspectives},
  shorttitle = {Barriers, Incentives, and Benefits of the Open Educational Resources ({{OER}}) Movement},
  author = {Henderson, Serena and Ostashewski, Nathaniel},
  year = {2018},
  month = dec,
  journal = {First Monday},
  volume = {23},
  number = {12},
  issn = {13960466},
  doi = {10.5210/fm.v23i12.9172},
  urldate = {2018-12-01},
  abstract = {Open educational resource (OER) barriers, incentives, and benefits are at the forefront of educator and institution interests as global use of OER evolves. Research into OER use, perceptions, costs, and outcomes is becoming more prevalent; however, it is still in its infancy. Understanding barriers to full adoption, administration, and acceptance of OER is paramount to fully supporting its growth and success in education worldwide. The purpose of this research was to replicate and extend Kursun, Cagiltay, and Can's (2014) Turkish study to include international participants. Kursun, et al. surveyed OpenCourseWare (OCW) faculty on their perceptions of OER barriers, incentives, and benefits. Through replication, these findings provide a glimpse into the reality of the international educators' perceptions of barriers, incentives, and benefits of OER use to assist in the creation of practical solutions and actions for both policy makers and educators alike. The results of this replication study indicate that barriers to OER include institutional policy, lack of incentives, and a need for more support and education in the creating, using, and sharing of instructional materials. A major benefit to OER identified by educators is the continued collegial atmosphere of sharing and lifelong learning.},
  copyright = {Copyright (c) 2018 First Monday},
  langid = {english},
  keywords = {barriers,higher education,incentives,international,k12,OER,open educational resources,use},
  file = {/Users/colin.madland/Zotero/storage/83HDGXXK/9172.html}
}

@incollection{hendersonDesigningFeedbackImpact2019,
  title = {Designing {{Feedback}} for {{Impact}}},
  booktitle = {The {{Impact}} of {{Feedback}} in {{Higher Education}}},
  author = {Henderson, Michael and Molloy, Elizabeth and Ajjawi, Rola and Boud, David},
  editor = {Henderson, Michael and Ajjawi, Rola and Boud, David and Molloy, Elizabeth},
  year = {2019},
  pages = {267--285},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-25112-3_15},
  urldate = {2021-04-21},
  isbn = {978-3-030-25111-6 978-3-030-25112-3},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/KMYMNDU4/hendersonDesigningFeedbackImpact2019.pdf}
}

@article{hendersonWhatWorksWhy2017,
  title = {What Works and Why? {{Student}} Perceptions of `Useful' Digital Technology in University Teaching and Learning},
  shorttitle = {What Works and Why?},
  author = {Henderson, Michael and Selwyn, Neil and Aston, Rachel},
  year = {2017},
  month = aug,
  journal = {Studies in Higher Education},
  volume = {42},
  number = {8},
  pages = {1567--1579},
  issn = {0307-5079, 1470-174X},
  doi = {10.1080/03075079.2015.1007946},
  urldate = {2022-12-24},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/KMIA5KF4/What works and why Student perceptions of useful digital technology in university teaching and learning.pdf}
}

@article{hendricksAdoptionOpenTextbook2017,
  title = {The {{Adoption}} of an {{Open Textbook}} in a {{Large Physics Course}}: {{An Analysis}} of {{Cost}}, {{Outcomes}}, {{Use}}, and {{Perceptions}}},
  shorttitle = {The {{Adoption}} of an {{Open Textbook}} in a {{Large Physics Course}}},
  author = {Hendricks, Christina and Reinsberg, Stefan A. and Rieger, Georg W.},
  year = {2017},
  month = jun,
  journal = {The International Review of Research in Open and Distributed Learning},
  volume = {18},
  number = {4},
  issn = {1492-3831},
  urldate = {2018-07-07},
  copyright = {Copyright (c) 2017 Christina Hendricks, Stefan A. Reinsberg, Georg W Rieger},
  langid = {english},
  keywords = {online learning,open educational resources,open textbooks},
  file = {/Users/colin.madland/Zotero/storage/Z75XL4VA/hendricksAdoptionOpenTextbook2017.pdf;/Users/colin.madland/Zotero/storage/ZT7QPE8Y/4220.html}
}

@inproceedings{hendricksExperiencesPerceptionsOutcomes2016,
  title = {Experiences, Perceptions, and Outcomes of {{BC}} Students Using Open Textbooks: {{Research}} from the {{BC OER Research Fellows}}},
  booktitle = {{{BCcampus Festival}} of {{Learning}}},
  author = {Hendricks, Christina and Jhangiani, Rajiv and Madland, Colin},
  year = {2016},
  copyright = {All rights reserved}
}

@misc{hendricksOpenEducation60s2017,
  title = {Open {{Education}} in the 60s and 70s -- {{You}}'re the {{Teacher}}},
  author = {Hendricks, Christina},
  year = {2017},
  urldate = {2018-10-20},
  langid = {american},
  keywords = {history,OEP,open},
  file = {/Users/colin.madland/Zotero/storage/TAE4GNAJ/open-education-in-the-60s-and-70s.html}
}

@article{henryKaupapaMaoriLocating2001,
  title = {Kaupapa {{Maori}}: {{Locating Indigenous Ontology}}, {{Epistemology}} and {{Methodology}} in the {{Academy}}},
  author = {Henry, Ella and Pene, Hone},
  year = {2001},
  month = may,
  journal = {Organization},
  volume = {8},
  number = {2},
  pages = {234--242},
  issn = {1350-5084},
  doi = {10.1177/1350508401082009},
  urldate = {2019-03-30},
  file = {/Users/colin.madland/Zotero/storage/TUM9A4R7/henryKaupapaMaoriLocating2001.pdf}
}

@article{herbertCreatingMathematicsFormative2019,
  title = {Creating Mathematics Formative Assessments Using {{LaTeX}}, {{PDF}} Forms and Computer Algebra},
  author = {Herbert, K and Demskoi, D and Cullis, K},
  year = {2019},
  journal = {Australasian Journal of Educational Technology},
  volume = {35},
  number = {5},
  pages = {153--167},
  issn = {1449-3098},
  doi = {10.14742/ajet.4539},
  abstract = {Formative assessment benefits both students and teaching academics. In particular, formative assessment in mathematics subjects enables both students and teaching academics to assess individual performance and understanding through students' responses. Over the last decade, educational technologies and learning management systems (LMSs) are used to support formative assessment design. In mathematics, this is problematic because of the inflexibility of LMS and educational technology tools. Automating formative assessment generation and marking to support mathematics learning is made possible by utilising specific software and technologies in new ways. This paper proposes a new method of creating mathematics formative assessments using LaTeX and PDF forms in conjunction with a computer algebra system (e.g., Maple), independent of an LMS. This method is implemented in undergraduate mathematics subjects servicing non-mathematics-focused higher education courses. The method generates individualised assessments that are automatically marked. Results show that the method provides the teaching academic with a more efficient way of designing formative mathematics assessments without compromising the effectiveness of the assessment task. This study contributes to the growing research on mathematics in higher education. The implication is an increased understanding of how existing technology, implemented in new ways, can potentially benefit both mathematics students and teaching academics.},
  langid = {english},
  keywords = {ONLINE},
  file = {/Users/colin.madland/Zotero/storage/79ANBH5I/herbertCreatingMathematicsFormative2019.pdf}
}

@article{herboldGivingStudentChoice2011,
  title = {Giving {{Student Choice}} in {{Online Learning Environments}}: {{Addressing Adult Learner Needs}}.},
  author = {Herbold, Katy},
  year = {2011},
  journal = {International Journal of Technology, Knowledge \& Society},
  volume = {7},
  pages = {117--125},
  doi = {Article},
  abstract = {Establishing an engaging and interactive environment in the online classroom can be a challenge. Do student selected learning activities, real time interactive sessions and other tools make a difference? Feedback from graduate students in online classes who are themselves practicing educators provides helpful information for continuous improvement. One of the tools investigated is a 'build your own grade' syllabus structure that allows students to customize their learning based on knowledge level and learning activity preference. This structure is designed from and supports adult learning theory. This study reports findings on customizing student activities to support mature learners in the online learning environment. [ABSTRACT FROM AUTHOR] Copyright of International Journal of Technology, Knowledge \& Society is the property of Common Ground Publishing and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
  keywords = {Adult learning,Adult Learning,Adult students,Distance education,Education,Graduate students,Graduate Studies,Interactive learning,Internet in education,Online,Technology}
}

@article{heritageClassroomAssessmentLarge2019,
  title = {Classroom {{Assessment}} and {{Large}}-{{Scale Psychometrics}}: {{Shall}} the {{Twain Meet}}? ({{A Conversation With Margaret Heritage}} and {{Neal Kingston}})},
  shorttitle = {Classroom {{Assessment}} and {{Large}}-{{Scale Psychometrics}}},
  author = {Heritage, Margaret and Kingston, Neal M.},
  year = {2019},
  journal = {Journal of Educational Measurement},
  volume = {56},
  number = {4},
  pages = {670--685},
  issn = {0022-0655, 1745-3984},
  doi = {10/ghbwrg},
  urldate = {2020-09-17},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/2R8NUAV8/heritageClassroomAssessmentLarge2019.pdf}
}

@article{heritageMakingAssessmentWork2018,
  title = {Making {{Assessment Work}} for {{Teachers}}},
  author = {Heritage, Margaret},
  year = {2018},
  journal = {Educational Measurement: Issues and Practice},
  volume = {37},
  number = {1},
  pages = {39--41},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {0731-1745},
  doi = {10/gjn22g},
  urldate = {2021-04-08},
  file = {/Users/colin.madland/Zotero/storage/V43RS5U2/heritageMakingAssessmentWork2018.pdf}
}

@article{hermannsDevelopmentUseEvaluation2022,
  title = {The {{Development}}, {{Use}}, and {{Evaluation}} of {{Digital Games}} and {{Quizzes}} in an {{Introductory Course}} on {{Organic Chemistry}} for {{Preservice Chemistry Teachers}}},
  author = {Hermanns, Jolanda and Keller, David},
  year = {2022},
  journal = {Journal of chemical education},
  volume = {99},
  number = {4},
  pages = {1715--1724},
  publisher = {{American Chemical Society and Division of Chemical Education, Inc}},
  address = {Easton},
  issn = {0021-9584},
  doi = {10.1021/acs.jchemed.2c00058},
  abstract = {Due to the COVID pandemic, the introductory course on organic chemistry was developed and conducted as an online course. To ensure methodical variety in this course, educational games and quizzes have been developed, used, and evaluated. The attendance of the course, and therefore also the use of the quizzes and games, was voluntary. The quizzes' main goal was to give the students the opportunity to check whether they had memorized the knowledge needed in the course. Another goal was to make transparent which knowledge the students should memorize by rote. The evaluation shows that the students had not internalized all knowledge which they should apply in several tasks on organic chemistry. They answered multiselect questions in general less well than single-select questions. The games should combine fun with learning. The evaluation of the games shows that the students rated them very well. The students used those games again for their exam preparation, as the monitoring of accessing the games showed. Students' experiences with using electronic devices in general or for quizzes and games have also been evaluated, because their experience could influence the students' assessment of the quizzes and games used in our study. However, the students used electronic devices regularly and should therefore be technically competent to use our quizzes and games. The evaluation showed that the use of digital games for learning purposes is not very common, neither at school nor at university, although the students had worked with such tools before. The students are also very interested in using and developing such digital games not only for their own study, but also for their future work at school.},
  keywords = {Chemistry,College students,Colleges & universities,Computer & video games,COVID-19,Educational evaluation,Educational Games,Educational Technology,Electronic devices,Evaluation,Knowledge Level,Learning,Online Courses,Online instruction,Organic Chemistry,Pandemics,Preservice Teacher Education,Program Effectiveness,Questions,Science Instruction,Science Teachers,Student Attitudes,Students,Teacher education,Teaching aids & devices,Teaching Methods,Technology Uses in Education,Tests}
}

@misc{hernTwitterApologisesIts,
  title = {Twitter Apologises for Its `Racist' Image Cropping Algorithm},
  author = {Hern, Alex},
  journal = {The Irish Times},
  urldate = {2020-09-22},
  abstract = {Users highlight a feature that automatically focused on white faces over black ones},
  howpublished = {https://www.irishtimes.com/culture/tv-radio-web/twitter-apologises-for-its-racist-image-cropping-algorithm-1.4360598},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/RKNRHY44/twitter-apologises-for-its-racist-image-cropping-algorithm-1.html}
}

@misc{heroldTeacherAideSurveillance,
  title = {Teacher's {{Aide}} or {{Surveillance Nightmare}}? {{Alexa Hits}} the {{Classroom}}},
  shorttitle = {Teacher's {{Aide}} or {{Surveillance Nightmare}}?},
  author = {Herold, Benjamin},
  journal = {Education Week - Digital Education},
  urldate = {2018-06-28},
  abstract = {Some teachers are touting the classroom value of smart speakers and digital voice assistants, but concerns about privacy and instructional value abound.},
  howpublished = {http://blogs.edweek.org/edweek/DigitalEducation/2018/06/alexa\_in\_the\_classroom\_teachers\_surveillance.html?cmp=SOC-SHR-FB},
  keywords = {surveillance},
  file = {/Users/colin.madland/Zotero/storage/H76HEXB3/alexa_in_the_classroom_teachers_surveillance.html}
}

@article{herppichTeachersAssessmentCompetence2018,
  title = {Teachers' Assessment Competence: {{Integrating}} Knowledge-, Process-, and Product-Oriented Approaches into a Competence-Oriented Conceptual Model},
  shorttitle = {Teachers' Assessment Competence},
  author = {Herppich, Stephanie and Praetorius, Anna-Katharina and F{\"o}rster, Natalie and {Glogger-Frey}, Inga and Karst, Karina and Leutner, Detlev and Behrmann, Lars and B{\"o}hmer, Matthias and Ufer, Stefan and Klug, Julia and Hetmanek, Andreas and Ohle, Annika and B{\"o}hmer, Ines and Karing, Constance and Kaiser, Johanna and S{\"u}dkamp, Anna},
  year = {2018},
  month = nov,
  journal = {Teaching and Teacher Education},
  volume = {76},
  pages = {181--193},
  issn = {0742051X},
  doi = {10/gfjsvn},
  urldate = {2021-07-06},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/GCCPPD4I/herppichTeachersAssessmentCompetence2018.pdf}
}

@article{herreidSurveyCaseStudy2021,
  title = {Survey of Case Study Users during Pandemic Shift to Remote Instruction},
  author = {Herreid, Clyde Freeman and {Prud'homme-G{\'e}n{\'e}reux}, Annie and Wright, Carolyn and Schiller, Nancy and Herreid, Ky F.},
  year = {2021},
  month = sep,
  journal = {Advances in Physiology Education},
  volume = {45},
  number = {3},
  pages = {620--625},
  issn = {1043-4046, 1522-1229},
  doi = {10.1152/advan.00046.2021},
  urldate = {2023-01-15},
  abstract = {Before COVID-19, the use of case studies to learn science was well established in high school and postsecondary classrooms. Once the pandemic ensued, many faculty continued to use the method as a way to infuse elements of active learning remotely. The results of a survey taken by 600 faculty reveal how they accomplished this feat. Respondents to the survey found that the case method readily transferred to online learning. Most used a mixture of synchronous and asynchronous classrooms. Serious challenges were encountered, primarily due to the difficulty instructors had in keeping track of learner participation. Many obstacles were overcome by creative strategies such as using Google Forms. Some semblance of a normal classroom was achieved by using online conferencing tools and using small groups in synchronous breakout rooms. Cases were commonly broken into chunks and spread over several days. This worked especially well with cases that were already structured this way, including interrupted cases and problem-based learning exercises. Assessment of student performance largely followed the traditional path of exams, projects, and essays, although a third of the faculty attempted to evaluate participation. Classes conducted via an asynchronous approach were largely lecture based, with cases given to learners to complete as homework either individually or as groups. The greatest challenge in this setting was that answers to case questions were often readily available to learners on the internet. This was avoided by faculty modifying questions or creating their own.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/PSV6CR5G/herreidSurveyCaseStudy2021.pdf}
}

@misc{hewlettOpenEducationalResources,
  title = {Open {{Educational Resources Hewlett Foundation}}},
  author = {Hewlett, William},
  howpublished = {https://hewlett.org/strategy/open-educational-resources/}
}

@incollection{hibbertsCommonSurveySampling2012,
  title = {Common {{Survey Sampling Techniques}}},
  booktitle = {Handbook of {{Survey Methodology}} for the {{Social Sciences}}},
  author = {Hibberts, Mary and Burke Johnson, R. and Hudson, Kenneth},
  editor = {Gideon, Lior},
  year = {2012},
  pages = {53--74},
  publisher = {Springer New York},
  address = {New York, NY},
  doi = {10.1007/978-1-4614-3876-2_5},
  urldate = {2021-08-04},
  isbn = {978-1-4614-3875-5 978-1-4614-3876-2},
  langid = {english},
  annotation = {ZSCC: NoCitationData[s0]},
  file = {/Users/colin.madland/Zotero/storage/HGITLBYE/hibbertsCommonSurveySampling2012.pdf}
}

@article{hickeyExpansiveFramingPragmatic2020,
  title = {Expansive Framing as Pragmatic Theory for Online and Hybrid Instructional Design},
  author = {Hickey, Daniel T. and Chartrand, Grant T. and Andrews, Christopher D.},
  year = {2020},
  journal = {Educational Technology Research and Development},
  volume = {68},
  number = {2},
  pages = {751--782},
  issn = {1042-1629, 1556-6501},
  doi = {10/ghn5np},
  urldate = {2021-05-17},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/87VHISKG/hickeyExpansiveFramingPragmatic2020.pdf}
}

@article{hickeyGPortfoliosPragmaticApproach2020,
  title = {{{gPortfolios}}: A Pragmatic Approach to Online Asynchronous Assignments},
  shorttitle = {{{gPortfolios}}},
  author = {Hickey, Daniel and Duncan, Jody and Gaylord, Courtney and Hitchcock, Christine and Itow, Rebecca Chiyoko and Stephens, Shelby Elizabeth},
  year = {2020},
  month = jul,
  journal = {Information and Learning Sciences},
  volume = {121},
  number = {5/6},
  pages = {273--283},
  issn = {2398-5348, 2398-5348},
  doi = {10/ghn5nn},
  urldate = {2021-05-17},
  abstract = {Purpose               The purpose of this paper is sharing out basic guidelines and examples from an extended collaboration to move educators move online while avoiding synchronous meetings. ``gPortfolios'' are public (to the class) pages where students write responses to carefully constructed engagement routines. Students then discuss their work with instructors and peers in threaded comments. gPortfolios usually include engagement reflections, formative self-assessments and automated quizzes. These assessments support and document learning while avoiding instructor ``burnout'' from grading. gPortfolios can be implemented using Google Docs and Forms or any learning management system.                                         Design/methodology/approach               The authors report practical insights gained from design-based implementation research. This research explored the late Randi Engle's principles for productive disciplinary engagement and expansive framing. Engle used current theories of learning to foster student discussions that were both authentic to the academic discipline at hand and productive for learning. This research also used new approaches to assessment to support Engle's principles. This resulted in a comprehensive approach to online instruction and assessment that is effective and efficient for both students and teachers.                                         Findings               The approach ``frames'' (i.e. contextualizes) online engagement using each learners' own experiences, perspectives and goals. Writing this revealed how this was different in different courses. Secondary biology students framed each assignment independently. Secondary English and history students framed assignments as elements of a personalized capstone presentation; the history students further used a self-selected ``historical theme.'' Graduate students framed each assignment in an educational assessment course using a real or imagined curricular aim and context.                                         Originality/value               Engle's ideas have yet to be widely taken up in online education.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/RQSLR7TH/hickeyGPortfoliosPragmaticApproach2020.pdf}
}

@article{hickeyReimaginingOnlineGrading2021,
  title = {Reimagining Online Grading, Assessment, and Testing Using Situated Cognition},
  author = {Hickey, Daniel and Harris, Tripp},
  year = {2021},
  journal = {Distance Education},
  pages = {1--20},
  publisher = {Routledge},
  issn = {0158-7919},
  doi = {10/gjwp8z},
  abstract = {Increased online learning is helping many appreciate that online grading, formative assessment, and summative testing can cause instructor burnout and leave little time for more productive instructor interactions. We reimagined grading, assessment, and testing in an extended program of design-based research using situative theory to refine online courses in secondary, undergraduate, graduate, and technical contexts. This research minimized private instructor-student interactions (including grading and private formative feedback) while maximizing public interactions. We present 10 assessment design principles, including a new principle concerning diversity and equity. We assume that these principles will be new to many readers and counter-intuitive to some. These principles focus on assessment functions (rather than ostensible purposes) and align learning across increasingly formal levels. We argue that doing so can maximize formative and transformative assessment functions, position students as authors, rather than consumers, reposition minoritized students to empower them, and increase validity and credibility of evidence.},
  file = {/Users/colin.madland/Zotero/storage/56UT6K9V/hickeyReimaginingOnlineGrading2021.pdf}
}

@article{hicksChatGPTBullshit2024,
  title = {{{ChatGPT}} Is Bullshit},
  author = {Hicks, Michael Townsen and Humphries, James and Slater, Joe},
  year = {2024},
  month = jun,
  journal = {Ethics and Information Technology},
  volume = {26},
  number = {2},
  pages = {38},
  issn = {1572-8439},
  doi = {10.1007/s10676-024-09775-5},
  urldate = {2025-05-01},
  abstract = {Recently, there has been considerable interest in large language models: machine learning systems which produce human-like text and dialogue. Applications of these systems have been plagued by persistent inaccuracies in their output; these are often called ``AI hallucinations''. We argue that these falsehoods, and the overall activity of large language models, is better understood as bullshit in the sense explored by Frankfurt (On Bullshit, Princeton, 2005): the models are in an important way indifferent to the truth of their outputs. We distinguish two ways in which the models can be said to be bullshitters, and argue that they clearly meet at least one of these definitions. We further argue that describing AI misrepresentations as bullshit is both a more useful and more accurate way of predicting and discussing the behaviour of these systems.},
  langid = {english},
  keywords = {Artificial intelligence,Artificial Intelligence,Assertion,Bullshit,ChatGPT,Content,Frankfurt,Large language models,LLMs},
  file = {/Users/colin.madland/Zotero/storage/AI/hicksChatGPTBullshit2024.pdf}
}

@article{Higgins_2002,
  title = {The Conscientious Consumer Reconsidering the Role of Assessment Feedback in Student Learning},
  author = {Higgins, Richard and Hartley, Peter and Skelton, Alan},
  year = {2002},
  journal = {Studies in Higher Education},
  doi = {10/cvn9mv},
  abstract = {This article reports the initial findings of a 3-year research project investigating the meaning and impact of assessment feedback for students in higher education. Adopting aspects of a constructivist theory of learning, it is seen that formative assessment feedback is essential to encourage the kind of 'deep' learning desired by tutors. There are a number of barriers to the utility of feedback outside the sphere of control of individual students, including those relating to the quality, quantity and language of comments. But the students in the study seemed to read and value their tutors' comments. Their perceptions of feedback do not indicate that they are simply instrumental 'consumers' of education, driven solely by the extrinsic motivation of the mark and as such desire feedback which simply provides them with 'correct answers'. Rather, the situation is more complex. While recognising the importance of grades, many of the students in the study adopt a more 'conscientious' approach. They are motivate...},
  mag_id = {2133755076},
  pmcid = {null},
  pmid = {null},
  keywords = {guskey}
}

@article{hillerNoYouKnow2016,
  title = {"{{No}}, {{Do You Know What}} '{{Your}}' {{Treaty Rights Are}}?" {{Treaty Consciousness}} in a {{Decolonizing Frame}}},
  author = {Hiller, Chris},
  year = {2016},
  journal = {Review of Education, Pedagogy \& Cultural Studies},
  volume = {38},
  number = {4},
  pages = {381--408},
  issn = {1071-4413},
  doi = {10.1080/10714413.2016.1203684},
  abstract = {Idle No More represents a watershed moment of treaty education, with treaty-related teach-ins, direct actions, and information sharing happening in diverse public spaces across Canada and around the globe. Although unprecedented in scope, depth, and intensity, Idle No More rests in a centuries-old continuity of Indigenous treaty pedagogy: efforts on the part of Indigenous peoples, going back to the time of first contact, to educate newcomers to their territories regarding the principles, meanings, protocol, and implications of treaty relationships. Reprinted by permission of Routledge, Taylor \& Francis Ltd.;"Idle No More" represents a watershed moment of treaty education, with treaty-related teach-ins, direct actions, and information sharing happening in diverse public spaces across Canada and around the globe. Although unprecedented in scope, depth, and intensity, "Idle No More" rests in a centuries-old continuity of Indigenous treaty pedagogy: efforts on the part of Indigenous peoples, going back to the time of first contact, to educate newcomers to their territories regarding the principles, meanings, protocol, and implications of treaty relationships. Yet despite centuries of such efforts, as well as more recent efforts on the part of solidarity organizations and even mainstream educational institutions, treaty ignorance and denial remain rampant in Canada, and treaties themselves continue to constitute a lightning rod of contention and entrenched conflict between Indigenous and settler peoples. For critical educators committed to dismantling colonial mindsets, practices, and structures, then, the question remains: given the entrenched nature of this dominant treaty pedagogy, how might it be possible to prompt a "decolonizing treaty" (Sehdev 2011, 273) consciousness among non-Indigenous people? What kinds of critical praxis might disrupt mythologizing settler narratives and the colonial discourses and practices conducive of ignorance and denial? Further, given Tuck and Yang's (2012) admonition that "decolonization is not a metaphor", what forms of reflection and action might foster and support concrete efforts among settlers to bring about a full and just recognition of treaty rights, relationships, and responsibilities? To explore these questions, Chris Hiller begins by reflecting upon interviews with Euro-Canadian solidarity activists who have been engaged for at least two years in supporting Indigenous struggles over land, title, and sovereignty. For the purpose of this article, Hiller focuses on the narratives of five white settlers whose stories pivot on engagements with the meaning and implications of the treaties and treaty relationships. The article concludes with a discussion of what the narratives as a whole say about the role of situated forms of treaty praxis in processes of decolonizing settler attitudes, practices, and commitments.;},
  keywords = {Activism,Canada,Canada Natives,Civil Rights,Conflict,Decolonization,Education,Foreign Countries,Foreign Policy,Interviews,Native peoples,Pedagogy,Personal Narratives,Praxis,Treaties,Tribal Sovereignty,Whites}
}

@article{hilligerTrustworthyRemoteAssessments2022,
  title = {Trustworthy Remote Assessments: {{A}} Typology of Pedagogical and Technological Strategies},
  author = {Hilliger, Isabel and Ruip{\'e}rez-Valiente, Jos{\'e} A. and Alexandron, Giora and Ga{\v s}evi{\'c}, Dragan},
  year = {2022},
  month = nov,
  journal = {Journal of Computer Assisted Learning},
  publisher = {Wiley-Blackwell Publishing Ltd.},
  issn = {0266-4909},
  doi = {10.1111/jcal.12755},
  abstract = {Background Online learning has grown significantly during the past two decades, and COVID-19 pandemic has expedited this process. However, previous research has shown how academic dishonesty is more prevalent under these modalities. Therefore, there is the challenge of performing trustworthy remote assessments, in order to obtain valid and reliable measures of students' knowledge. Objectives The research question that drove this research was: what actions have been proposed in contemporary research to improve remote assessment trustworthiness from a technological and pedagogical perspective? Methods We analysed the papers accepted for the special issue titled `Trustworthy Assessment and Academic Integrity in Remote Learning' following a deductive qualitative category coding methodology to find the main approaches. Results and conclusions We identified eight approaches to improve trustworthiness in remote assessment: four for exams and high-stake tests, one exclusively for performance-based assessments, and three for any type of assessment. Our findings shift attention from academic dishonesty to trustworthy assessment, integrating recent findings of papers accepted to this special issue. Implications Our findings deepen current understanding of trustworthy remote assessments, inviting practitioners and researchers to explore different types of assessment methods and different moments related to assessing learning. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {academic dishonesty,No terms assigned,remote learning,technology-enhanced learning,trustworthy assessment,typology},
  file = {/Users/colin.madland/Zotero/storage/HYWXCAWQ/hilligerTrustworthyRemoteAssessments2022.pdf}
}

@article{hillmanBraveNewPlatforms2020,
  title = {Brave New Platforms: A Possible Platform Future for Highly Decentralised Schooling},
  author = {Hillman, Thomas and Rensfeldt, Annika Bergviken and Ivarsson, Jonas},
  year = {2020},
  journal = {Learning, Media and Technology},
  volume = {45},
  number = {1},
  pages = {7--16},
  publisher = {Routledge},
  issn = {1743-9884},
  doi = {10/ggj8ff}
}

@misc{hillMultiplePhasesHE,
  title = {Multiple {{Phases}} of {{HE Response}} to {{COVID-19}} -- {{MindWires Consulting}}},
  author = {Hill, Phil},
  journal = {MindWires Consulting},
  urldate = {2020-04-15},
  howpublished = {https://mindwires.com/multiple-phases-of-he-response-to-covid-19/},
  file = {/Users/colin.madland/Zotero/storage/R5DNSRRD/multiple-phases-of-he-response-to-covid-19.html}
}

@article{hillProfessionalDevelopmentResearch2013,
  title = {Professional {{Development Research}}: {{Consensus}}, {{Crossroads}}, and {{Challenges}}},
  author = {Hill, Heather C. and Beisiegel, Mary and Jacob, Robin},
  year = {2013},
  month = nov,
  journal = {Educational Researcher},
  doi = {10.3102/0013189X13512674},
  abstract = {Commentaries regarding appropriate methods for researching professional development have been a frequent topic in recent issues of Educational Researcher as well as other venues. In this article, the authors extend this discussion by observing that randomized trials of specific professional development programs have not enhanced our knowledge of effective program characteristics, leaving practitioners without guidance with regard to best practices. In response, the authors propose that scholars should execute more rigorous comparisons of professional development designs at the initial stages of program development and use information derived from these studies to build a professional knowledge base. The authors illustrate with examples of both a proposed study and reviews of evidence on key questions in the literature.}
}

@article{hillsAssessmentWorldsColliding2016,
  title = {Assessment {{Worlds Colliding}}? {{Negotiating}} between {{Discourses}} of {{Assessment}} on an {{Online Open Course}}},
  author = {Hills, Laura and Hughes, Jonathan},
  year = {2016},
  month = jan,
  journal = {Open Learning},
  volume = {31},
  number = {2},
  pages = {108--115},
  publisher = {Open Learning},
  issn = {0268-0513},
  doi = {10.1080/02680513.2016.1194747},
  abstract = {Using the badged open course, "Taking your first steps into Higher Education", this case study examines how assessment on online open courses draws on concepts of assessment used within formal and informal learning. Our experience was that assessment used within open courses, such as massive open online courses, is primarily determined by the requirements of quality assurance processes to award a digital badge or statement of participation as well as what is technologically possible. However, this disregards much recent work in universities that use assessment in support of learning. We suggest that designers of online open courses should pay greater attention to the relationship of assessment and learning to improve participant course completion.},
  keywords = {Academic Persistence,Case Studies,Correlation,Course Evaluation,Foreign Countries,Informal Education,Instructional Design,Mass Instruction,Online Courses,Open Universities,Skill Development,Study Habits,Taxonomy,United Kingdom},
  file = {/Users/colin.madland/Zotero/storage/Q6P8DTI8/hillsAssessmentWorldsColliding2016.pdf}
}

@article{hillsChineseWhispersInvestigating2018,
  ids = {hillsChineseWhispersInvestigating2018a},
  title = {Chinese {{Whispers}}? {{Investigating}} the {{Consistency}} of the {{Language}} of {{Assessment}} between a {{Distance Education Institution}}, {{Its Tutors}} and {{Students}}},
  author = {Hills, Laura and Clarke, Anactoria and Hughes, Jonathan and Butcher, John and Shelton, Isobel and McPherson, Elaine},
  year = {2018},
  month = jan,
  journal = {Open Learning},
  volume = {33},
  number = {3},
  pages = {238--249},
  publisher = {Open Learning},
  address = {ABINGDON},
  issn = {0268-0513},
  doi = {10.1080/02680513.2018.1500278},
  abstract = {Ensuring the fairness of assessment is important in all areas of higher education. It is particularly so in distance education, where the communication around assessment and feedback is a principal method of supporting learning, and even more so when the students are at the entry point into higher education. This research explores the nature of the language used in explaining the purpose and process of assessment on an access programme at The Open University, UK, from the perspective of the module team, the tutors and the students. It takes a qualitative approach to examine the clarity and consistency of assessment tasks, assessment guidance and TMGs. Analysis revealed inconsistencies in the language used in relation to assessment, which has led to a revision of how assessment tasks and guidance are communicated to students and tutors.},
  keywords = {access to higher education,Assessment,College Faculty,College Students,Computer Mediated Communication,Distance Education,Distance learning,Education & Educational Research,Educational Change,Educational evaluation,Evaluation Criteria,Feedback (Response),Foreign Countries,Formative Evaluation,Grading,Guidelines,Guides,Higher education,inclusive language,Language Usage,marking guidelines,Open Universities,Social Sciences,Student Attitudes,Student Evaluation,Teacher Attitudes,Teacher Student Relationship,United Kingdom,widening participation},
  file = {/Users/colin.madland/Zotero/storage/SJW2SF8M/hillsChineseWhispersInvestigating2018.pdf}
}

@misc{hillUnlikeliestScenarioFully2020,
  title = {The {{Unlikeliest Scenario}}: {{Fully}} Face-to-Face Programs in {{Fall}} 2020 - {{PhilOnEdTech}}},
  author = {Hill, Phil},
  year = {2020},
  month = apr,
  journal = {Phil on EdTech},
  urldate = {2020-04-15},
  howpublished = {https://philonedtech.com/the-unlikeliest-scenario-fully-face-to-face-programs-in-fall-2020}
}

@article{hiltonAdoptionOpenEducational2013,
  title = {The Adoption of Open Educational Resources by One Community College Math Department},
  author = {Hilton, John and Gaudet, Donna and Clark, Phil and Robinson, Jared and Wiley, David},
  year = {2013},
  month = sep,
  journal = {International Review of Research in Open and Distance Learning},
  volume = {14},
  abstract = {The high cost of textbooks is of concern not only to college students but also to society as a whole. Open textbooks promise the same educational benefits as traditional textbooks; however, their efficacy remains largely untested. We report on one community college's adoption of a collection of open resources across five different mathematics classes. During the 2012 fall semester, 2,043 students in five different courses used these open access resources. We present a comparison between the previous two years in terms of the number of students who withdrew from the courses and the number that completed the courses with a C grade or better. Our analysis suggests that while there was likely no change in these educational outcomes, students who have access to open access materials collectively saved a significant amount of money. Students and faculty were surveyed as to their perceptions of these materials and the results were generally favorable.},
  keywords = {electronic textbooks,open access,open educational resources,open textbooks,sustainability}
}

@article{hiltonOneCollegeUse2012,
  title = {One College's Use of an Open Psychology Textbook},
  author = {Hilton, John and Laman, Carol},
  year = {2012},
  journal = {Open Learning: The Journal of Open, Distance and e-Learning},
  volume = {27},
  pages = {265--272},
  issn = {0268-0513},
  doi = {10.1080/02680513.2012.716657},
  abstract = {doi: 10.1080/02680513.2012.716657 The high cost of textbooks is of concern not only to college students but also to society as a whole. Open textbooks promise the same educational benefits as traditional textbooks; however, their efficacy remains largely untested. We report on a case study about one community college?s adoption of a free online psychology textbook. During the fall semester 2011, 690 students used this book. Compared with students using a traditional text in the spring of 2011, students who used the free online textbook scored higher on departmental final examinations, had higher grade point averages in the class and had higher retention rates. The high cost of textbooks is of concern not only to college students but also to society as a whole. Open textbooks promise the same educational benefits as traditional textbooks; however, their efficacy remains largely untested. We report on a case study about one community college?s adoption of a free online psychology textbook. During the fall semester 2011, 690 students used this book. Compared with students using a traditional text in the spring of 2011, students who used the free online textbook scored higher on departmental final examinations, had higher grade point averages in the class and had higher retention rates.}
}

@book{hinchmanMemoryIdentityCommunity1997,
  title = {Memory, Identity, Community: The Idea of Narrative in the Human Sciences},
  author = {Hinchman, Lewis P. and Hinchman, 1950, Sandra},
  year = {1997},
  number = {Book, Whole},
  publisher = {State University of New York Press},
  address = {Albany, NY},
  isbn = {9780791433249;0791433242;},
  keywords = {Methodology,Narration (Rhetoric),Philosophy,Social sciences}
}

@incollection{hintonMannWhitneyTest2010,
  title = {Mann--{{Whitney U Test}}},
  booktitle = {Encyclopedia of {{Research Design}}},
  author = {Hinton, Perry R},
  editor = {Salkind, Neil},
  year = {2010},
  publisher = {SAGE Publications, Inc.},
  address = {2455 Teller Road,~Thousand Oaks~California~91320~United States},
  doi = {10.4135/9781412961288.n228},
  urldate = {2021-08-05},
  isbn = {978-1-4129-6127-1 978-1-4129-6128-8},
  file = {/Users/colin.madland/Zotero/storage/PIYRWYBC/hintonMannWhitneyTest2010.pdf}
}

@article{hinzoDigitalSurvivanceTrickster2019,
  title = {Digital Survivance and {{Trickster}} Humor: Exploring Visual and Digital {{Indigenous}} Epistemologies in the \#{{NoDAPL}} Movement},
  author = {Hinzo, Angel M. and Clark, Lynn Schofield},
  year = {2019},
  journal = {Information, Communication \& Society},
  volume = {22},
  number = {6},
  pages = {791--807},
  issn = {1369-118X},
  doi = {10.1080/1369118X.2019.1573911},
  abstract = {ABSTRACTThe decolonizing turn in the humanities and social sciences calls for scholarship that analyzes social media practices through the lens of Indigenous epistemologies. In this article, we model the ways that Indigenous epistemologies might contribute to theories of social media practices as we explore ways that the digital image can drive identification with and engagement in political acts. The article analyzes social media tropes circulated across various platforms among Indigenous communities and allies in relation to the \#NoDAPL movement. We argue that attempting to analyze Native American traditions through Western theory will only work towards colonizing these Indigenous texts. Thus, whereas we employ insights from digital and visual methods of analysis (Highfield, T., \& Leaver, T.~(2016). Instagrammatics and digital methods: Studying visual social media, from selfies and GIFs to memes and emoji. Communication Research and Practice, 2(1), 47?62), we also highlight the strategic use of humor in the visual materials shared through various social media platforms utilizing the framework of the Trickster. We argue that the visual and digital phenomena we studied might best be understood as a form of digital survivance, drawing upon Anishinaabe scholar Gerald Vizenor [(1994). Manifest manners: Postindian warriors of survivance. Hanover, CT: Wesleyan University Press]. term ?survivance? as a portmanteau that combines ?survival? and ?resistance? in its characterization of Indigenous storytelling traditions. Whereas centering the Indigenous figure of the Trickster might suggest that social media has failed to live up to its promises, this epistemological approach also explains the hope that Indigenous communities hold in uniting via social media for what has been and continues to be a long-term battle for sovereignty and for the protection of the earth and all of its beings.},
  file = {/Users/colin.madland/Zotero/storage/UWCVMEEH/hinzoDigitalSurvivanceTrickster2019.pdf}
}

@book{hipkinsTrendsAssessmentOverview2018,
  title = {Trends in Assessment: An Overview of Themes in the Literature},
  shorttitle = {Trends in Assessment},
  author = {Hipkins, Rosemary and Cameron, Marie and {New Zealand Council for Educational Research}},
  year = {2018},
  urldate = {2022-04-07},
  isbn = {978-1-988542-49-2},
  langid = {english},
  annotation = {OCLC: 1082561242},
  file = {/Users/colin.madland/Zotero/storage/KRNRWS2G/hipkinsTrendsAssessmentOverview2018.pdf}
}

@incollection{hirstPoliticalEconomyFake2018,
  title = {The {{Political Economy}} of {{Fake News}}},
  booktitle = {Navigating {{Social Journalism}}: {{A Handbook}} for {{Media Literacy}} and {{Citizen Journalism}}},
  author = {Hirst, Martin},
  year = {2018},
  month = oct,
  edition = {1},
  publisher = {Routledge},
  address = {New York : Routledge, 2019.},
  doi = {10.4324/9781315401263},
  urldate = {2021-12-23},
  isbn = {978-1-315-40126-3},
  langid = {english}
}

@article{hitchcockTweetTweetUsing2016,
  title = {Tweet, Tweet!: {{Using}} Live {{Twitter}} Chats in Social Work Education},
  author = {Hitchcock, Laurel Iverson and Young, Jimmy A.},
  year = {2016},
  month = may,
  journal = {Social Work Education},
  volume = {35},
  number = {4},
  pages = {457--468},
  publisher = {Taylor \& Francis},
  issn = {0261-5479},
  doi = {10.1080/02615479.2015.1136273},
  abstract = {This article focuses on the use of Twitter and how it can be used to help students develop professional social work skills through live chats. An overview of the literature on Twitter in education is provided along with a discussion on New Media Literacies. A description of a live Twitter chat assignment with social work students is provided along with results from a survey assessing learning outcomes from the experience. Implications for social work education and suggestions for future research are also provided. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {Literacy,new media literacies,Online Social Networks,social media,Social Media,Social Work Education,Twitter}
}

@article{hochEthicalAuthenticServant2018,
  title = {Do {{Ethical}}, {{Authentic}}, and {{Servant Leadership Explain Variance Above}} and {{Beyond Transformational Leadership}}? {{A Meta-Analysis}}},
  author = {Hoch, Julia E. and Bommer, W. and Dulebohn, James H. and Wu, Dongyuan},
  year = {2018},
  month = feb,
  doi = {10.1177/0149206316665461},
  abstract = {This study compares three emerging forms of positive leadership that emphasize ethical and moral behavior (i.e., authentic leadership, ethical leadership, and servant leadership) with transformational leadership in their associations with a wide range of organizationally relevant measures. While scholars have noted conceptual overlap between transformational leadership and these newer leadership forms, there has been inadequate investigation of the empirical relationships with transformational leadership and the ability (or lack thereof) of these leadership forms to explain incremental variance beyond transformational leadership. In response, we conducted a series of meta-analyses to provide a comprehensive assessment of these emerging leadership forms' relationships with variables evaluated in the extant literature. Second, we tested the relative performance of each of these leadership forms in explaining incremental variance, beyond transformational leadership, in nine outcomes. We also provide relative weights analyses to further evaluate the relative contributions of the emerging leadership forms versus transformational leadership. The high correlations between both authentic leadership and ethical leadership with transformational leadership coupled with their low amounts of incremental variance suggest that their utility is low unless they are being used to explore very specific outcomes. Servant leadership, however, showed more promise as a stand-alone leadership approach that is capable of helping leadership researchers and practitioners better explain a wide range of outcomes. Guidance regarding future research and the utility of these three ethical/moral values--based leadership forms is provided.}
}

@inproceedings{hodgkinson-williamscherylDegreesEaseAdoption2014,
  title = {Degrees of Ease: Adoption of {{OER}}, Open Textbooks and {{MOOCs}} in the {{Global South}}},
  booktitle = {Regional {{Symposium}} on {{Open Educational Resources}} (2nd : 2014 : {{Wawasan Open University}}, {{Malaysia}})},
  author = {{Hodgkinson-Williams, Cheryl}},
  year = {2014},
  publisher = {University of Cape Town},
  address = {Penang, Malaysia},
  urldate = {2018-11-04},
  abstract = {Internationally, education institutions are under a great deal of pressure to provide rising numbers of students with access to quality education in increasingly economically constrained environments. For some time now, the affordances provided by the internet have enabled a range of educational activities to be supported digitally or conducted online. Three fairly new forms of web-enabled activities that are receiving attention are Open Educational Resources (OER), Open Textbooks, and Massive Open Online Courses (MOOCs). OERs and Open Textbooks have been hailed as a response to the demand for provision of flexible and cost-effective learning materials, while MOOCs have been touted as an answer to the provision of up-to-date and cost-effective tuition for growing numbers of students in so-called `developing countries', or what I shall refer to as the Global South. This paper will offer a definition of these forms of teaching provision and learning support within the context of ``Open Education'' and identify the key activities underlying OER, Open Textbooks and MOOCs. It will interrogate the factors that seem to influence the ease with which educators and students in the Global South can contribute to or adapt existing materials and/or tuition to suit their contexts as a way to avoid any possible ``neo-colonization and one-way flow of content based on the massive amount of content published by those in richer nations'' (Amiel 2013: 127).}
}

@misc{hoffmannDataViolenceHow2018,
  title = {Data {{Violence}} and {{How Bad Engineering Choices Can Damage Society}}},
  author = {Hoffmann, Anna Lauren},
  year = {2018},
  month = apr,
  journal = {Medium},
  urldate = {2020-04-11},
  abstract = {Cultural harms can go well beyond search results --- which can be bad news for vulnerable communities},
  howpublished = {https://medium.com/s/story/data-violence-and-how-bad-engineering-choices-can-damage-society-39e44150e1d4},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/LDUTPQ8J/data-violence-and-how-bad-engineering-choices-can-damage-society-39e44150e1d4.html}
}

@article{hogueAboriginalWaysKnowing2016,
  title = {Aboriginal {{Ways}} of {{Knowing}} and {{Learning}}, 21st {{Century Learners}}, and {{STEM Success}}},
  author = {Hogue, Michelle M.},
  year = {2016},
  month = jun,
  journal = {in education},
  volume = {22},
  number = {1},
  pages = {161--172},
  issn = {1927-6117},
  urldate = {2018-11-08},
  abstract = {Aboriginal people are alarmingly under-represented in science, technology, engineering, and mathematics (STEM)-related careers. This under-representation is a direct result of the lack of academic success in science and mathematics, an issue that begins early in elementary and middle school and often escalates in secondary school with the majority consequently doing poorly, not completing these courses and often dropping out. This makes them ineligible to pursue STEM-related paths at the post-secondary level. The greatest challenges to success in these courses are the lack of relevancy for Aboriginal learners and, as importantly, how they are taught; impediments that are also paramount to the increasing lack of success for many non-Aboriginal students in STEM-related courses. This paper explores how Aboriginal ways of knowing and learning and those of the 21st century learners of today very closely parallel each other and illustrates how the creative multidisciplinary approach of a liberal education might be the way to enable early academic engagement, success and retention of Aboriginal learners in the sciences and mathematics.},
  copyright = {Copyright (c) 2016 Michelle M. Hogue},
  langid = {english},
  keywords = {21st century learning,Aboriginal,Aboriginal culture,Aboriginal ways of knowing and learning,awkl,bridging cultures,mathematics,science,STEM,Two-Eyed Seeing},
  file = {/Users/colin.madland/Zotero/storage/CKGQCLVC/hogueAboriginalWaysKnowing2016.pdf;/Users/colin.madland/Zotero/storage/9WH9N8VA/263.html}
}

@article{hollandEffectivePrinciplesInformal2019,
  title = {Effective Principles of Informal Online Learning Design: {{A}} Theory-Building Metasynthesis of Qualitative Research},
  author = {Holland, Alison Anderson},
  year = {2019},
  month = jan,
  journal = {Computers in Education},
  doi = {10.1016/J.COMPEDU.2018.09.026},
  abstract = {Abstract   Informal online learning is the unstructured learning that happens in daily life while people are accessing the internet. Research on the use and design of interactive Web 2.0 platforms for informal learning is minimal, and often platform-specific. This theory-building metasynthesis aims to identify what is known about how informal online learning can be effectively designed outside a formal online course structure. The study reviewed 22 articles that investigated learning that happened primarily online, was self-directed in nature, and had a primarily adult audience. The author brought together the findings of these individual studies to identified two effective principles of informal online learning design that research dissemination organizations can utilize when developing online outreach education programs for adult audiences: (a) interaction opportunities support knowledge construction and learner empowerment; and (b) segmented, titled, and tagged learning objects facilitate personalized learning. The principles identified in this study not only describe what is known about how adults learn informally online, but also provide the common language and goals to frame the interdisciplinary collaboration likely necessary to employ them.}
}

@article{holmbergEvolutionCharacterPractice1995,
  title = {The Evolution of the Character and Practice of Distance Education},
  author = {Holmberg, B{\"o}rje},
  year = {1995},
  month = jun,
  journal = {Open Learning: The Journal of Open, Distance and e-Learning},
  volume = {10},
  number = {2},
  pages = {47--53},
  issn = {0268-0513},
  doi = {10.1080/0268051950100207}
}

@misc{HomeFNIGC,
  title = {Home {\textbar} {{FNIGC}}},
  urldate = {2019-02-28},
  howpublished = {https://fnigc.ca/},
  file = {/Users/colin.madland/Zotero/storage/BR7YFD7D/fnigc.ca.html}
}

@article{hooglandComputerbasedAssessmentMathematics2018,
  title = {Computer-Based Assessment of Mathematics into the Twenty-First Century: Pressures and Tensions},
  author = {Hoogland, K and Tout, D},
  year = {2018},
  journal = {ZDM-Mathematics Education},
  volume = {50},
  number = {4},
  pages = {675--686},
  issn = {1863-9690},
  doi = {10.1007/s11858-018-0944-2},
  abstract = {In recent decades, technology has influenced various aspects of assessment in mathematics education: (1) supporting the assessment of higher-order thinking skills in mathematics, (2) representing authentic problems from the world around us to use and apply mathematical knowledge and skills, and (3) making the delivery of tests and the analysis of results through psychometric analysis more sophisticated. We argue that these developments are not pushing mathematics education in the same direction, however, which creates tensions. Mathematics education-so essential for educating young people to be creative and problem solving agents in the twenty-first century-is at risk of focusing too much on assessment of lower order goals, such as the reproduction of procedural, calculation based, knowledge and skills. While there is an availability of an increasing amount of sophisticated technology, the related advances in measurement, creation and delivery of automated assessments of mathematics are however being based on sequences of atomised test items. In this article several aspects of the use of technology in the assessment of mathematics education are exemplified and discussed, including in relation to the aforementioned tension. A way forward is suggested by the introduction of a framework for the categorisation of mathematical problem situations with an increasing sophistication of representing the problem situation using various aspects of technology. The framework could be used to reflect on and discuss mathematical assessment tasks, especially in relation to twenty-first century skills.},
  langid = {english},
  keywords = {21ST-CENTURY,Assessment framework,CBAM,Higher-order thinking,Mathematical assessment tasks,Mathematics assessment,NUMERACY,Technology,Twenty-first century skills}
}

@book{hooksTeachingTransgressEducation1994,
  title = {Teaching to Transgress: Education as the Practice of Freedom},
  author = {{hooks}, bell},
  year = {1994},
  publisher = {Routledge},
  address = {New York},
  abstract = {In this book, the author shares her philosophy of the classroom, offering ideas about teaching that fundamentally rethink democratic participation. She writes about a new kind of education, education as the practice of freedom. She advocates the process of teaching students to think critically and raises many concerns central to the field of critical pedagogy, linking them to feminist thought. In the process, these essays face squarely the problems of teachers who do not want to teach, of students who do not want to learn, of racism and sexism in the classroom. Teaching students to "transgress" against racial, sexual, and class boundaries in order to achieve the gift of freedom is, for the author, the teacher's most important goal. -- From back cover.},
  isbn = {0-415-90808-6},
  keywords = {Critical pedagogy,Critical thinking -- Study and teaching,Feminism and education,Teaching}
}

@article{hooshyarDevelopmentEvaluationGameBased2018,
  title = {Development and {{Evaluation}} of a {{Game-Based Bayesian Intelligent Tutoring System}} for {{Teaching Programming}}},
  author = {Hooshyar, D and Ahmad, {\relax RB} and Wang, {\relax MH} and Yousefi, M and Fathi, M and Lim, H},
  year = {2018},
  journal = {Journal of Educational Computing Research},
  volume = {56},
  number = {6},
  pages = {775--801},
  issn = {0735-6331},
  doi = {10.1177/0735633117731872},
  abstract = {Games with educational purposes usually follow a computer-assisted instruction concept that is predefined and rigid, offering no adaptability to each student. To overcome such problem, some ideas from Intelligent Tutoring Systems have been used in educational games such as teaching introductory programming. The objective of this study was to advance Online Game-based Bayesian Intelligent Tutoring System (OGITS) to enhance programming acquisition and online information searching skills, thus improving students' ability in web-based problem solving through board games. The study sample comprised 79 college students in introductory level Computer Science classes. Qualitative and quantitative data were then gathered. Results of this study revealed generally favorable opinions about OGITS. As OGITS targets individual knowledge acquisition of computer programming and web-based problem-solving skills, it offers a suitable learning environment for students both as a stand-alone course and as a supplement to traditional classroom settings.},
  langid = {english},
  keywords = {Bayesian network,COLLEGE-STUDENTS,computer programming,DIGITAL GAMES,ENVIRONMENTS,FORMATIVE ASSESSMENT,game-based environment,INSTRUCTION,intelligent tutoring system,INTERNET,online information searching,PERFORMANCE,PROBLEM-SOLVING SKILLS,ROLE-PLAYING GAMES,TEACHERS}
}

@book{hootsteinWearingFourPairs2012,
  title = {Wearing Four Pairs of Shoes: {{The}} Roles of e-Learning Facilitators},
  author = {Hootstein, Ed},
  year = {August 16, 2012 2002},
  publisher = {{American Society for Training and Development}},
  abstract = {The emergence of e-learning comes at a time when education and training are undergoing important transformations. The teacher-centered model that has dominated instruction for centuries is slowly giving way to a learner-centered model with instructors in the roles of facilitators or "guides on the side." E-learning is no exception. But e-learning's use doesn't preclude facilitators' responsibilities for structuring learning experiences. The effectiveness and success of e-learning programs are dependent on facilitators' roles in delivering and managing instruction. One of the leading conceptualizers in the field of distance learning, Zane Berge, broke down an instructor's role in computer conferencing into four separate parts. I propose a similar model, in which an e-learning facilitator "wears four pairs of shoes"--acting as instructor, social director, program manager, and technical assistant.}
}

@article{hopfenbeckBridgingGapAssessment2024,
  title = {Bridging the Gap: From Assessment Theory to Classroom Reality},
  shorttitle = {Bridging the Gap},
  author = {Hopfenbeck, Therese N.},
  year = {2024},
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {31},
  number = {3-4},
  pages = {185--188},
  issn = {0969-594X, 1465-329X},
  doi = {10.1080/0969594X.2024.2405227},
  urldate = {2024-09-24},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/hopfenbeckBridgingGapAssessment2024.pdf}
}

@article{hopster-denotterGeneralFrameworkValidation2019,
  title = {A {{General Framework}} for the {{Validation}} of {{Embedded Formative Assessment}}},
  author = {{Hopster-den Otter}, Dorien and Wools, Saskia and Eggen, Theo J. H. M. and Veldkamp, Bernard P.},
  year = {2019},
  journal = {Journal of Educational Measurement},
  volume = {56},
  number = {4},
  pages = {715--732},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {0022-0655},
  doi = {10/ghbwr7},
  urldate = {2020-09-17},
  abstract = {Abstract In educational practice, test results are used for several purposes. However, validity research is especially focused on the validity of summative assessment.~This article aimed to provide a general framework for validating formative assessment. The authors applied the argument-based approach to validation to the context of formative assessment. This resulted in a proposed interpretation and use argument consisting of a score interpretation and a score use. The former involves inferences linking specific task performance to an interpretation of a student's general performance. The latter involves inferences regarding decisions about actions and educational consequences. The validity argument should focus on critical claims regarding score interpretation and score use, since both are critical to the effectiveness of formative assessment. The proposed framework is illustrated by an operational example including a presentation of evidence that can be collected on the basis of the framework.},
  file = {/Users/colin.madland/Zotero/storage/44CV9LHY/hopster-denotterGeneralFrameworkValidation2019.pdf}
}

@article{hornRationaleTestNumber1965,
  title = {A Rationale and Test for the Number of Factors in Factor Analysis},
  author = {Horn, John L.},
  year = {1965},
  month = jun,
  journal = {Psychometrika},
  volume = {30},
  number = {2},
  pages = {179--185},
  issn = {1860-0980},
  doi = {10.1007/BF02289447},
  abstract = {It is suggested that if Guttman's latent-root-one lower bound estimate for the rank of a correlation matrix is accepted as a psychometric upper bound, following the proofs and arguments of Kaiser and Dickman, then the rank for a sample matrix should be estimated by subtracting out the component in the latent roots which can be attributed to sampling error, and least-squares ``capitalization'' on this error, in the calculation of the correlations and the roots. A procedure based on the generation of random variables is given for estimating the component which needs to be subtracted.},
  file = {/Users/colin.madland/Zotero/storage/5CJMN8SP/hornRationaleTestNumber1965.pdf}
}

@misc{HorribleExperimentAppears,
  title = {'{{Horrible}} Experiment' Appears to Show That {{Twitter}}'s Cropping Tool Is Racially Biased},
  journal = {Sky News},
  urldate = {2020-09-22},
  abstract = {A programmer who carried out a "horrible experiment" believes Twitter's automated tool favours the faces of white people.},
  howpublished = {https://news.sky.com/story/barack-obama-is-in-these-images-but-a-racially-biased-tool-on-twitter-cropped-him-out-12078397},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/6WB32KH2/barack-obama-is-in-these-images-but-a-racially-biased-tool-on-twitter-cropped-him-out-12078397.html}
}

@misc{HorribleExperimentReveals2020,
  title = {`{{Horrible}} Experiment' Reveals {{Twitter}} Bias},
  year = {2020},
  month = sep,
  journal = {NewsComAu},
  urldate = {2020-09-22},
  abstract = {Twitter is trying to fix the algorithm that automatically crops image previews on the site after several experiments exposed an apparent bias.},
  howpublished = {https://www.news.com.au/technology/online/social/twitter-accused-of-bias-over-barack-obama-mitch-mcconnell-photo/news-story/07e6c0150f7301c00232a317206fbbc9\#.57yqx},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/P7WJNH2M/07e6c0150f7301c00232a317206fbbc9.html}
}

@misc{HorribleExperimentShows,
  title = {'{{Horrible}} Experiment' Shows That {{Twitter}}'s Cropping Algorithm Is Racially Biased},
  urldate = {2020-09-24},
  abstract = {The `racist' nature of the algorithm was first noticed by PhD student Colin Madland Twitter said that they had tested he product. however, couldn't find any bias However, acknowledging the mistake it further vowed to investigate the issue},
  howpublished = {https://opoyi.com/horrible-experiment-show-that-twitters-cropping-algorithm-is-racially-biased},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/V3PFGU2U/horrible-experiment-show-that-twitters-cropping-algorithm-is-racially-biased.html}
}

@book{hortonWeMakeRoad1990,
  title = {We Make the Road by Walking: Conversations on Education and Social Change},
  author = {Horton, Myles and Freire, Paulo},
  editor = {Bell, Brenda and Gaventa, John and Peters, John},
  year = {1990},
  number = {Book, Whole},
  publisher = {Temple University Press},
  address = {Philadelphia},
  isbn = {9780877227717;0877227713;},
  keywords = {Adult education,Brazil,Education,Philosophy,Social aspects,Social change,United States}
}

@article{horvatValidationProcedureAssessment2020,
  title = {Validation of the {{Procedure}} for the {{Assessment}} of {{Cognitive Complexity}} of {{Chemical Technology Problem Tasks}}},
  author = {Horvat, Sa{\v s}a A. and Roncevic, Tamara N. and Arsenovic, Dragana Z. and Rodic, Du{\v s}ica D. and Segedinac, Mirjana D.},
  year = {2020},
  month = jan,
  journal = {Journal of Baltic Science Education},
  volume = {19},
  number = {1},
  pages = {64--75},
  publisher = {Journal of Baltic Science Education},
  issn = {1648-3898},
  doi = {10.33225/jbse/20.19.64},
  abstract = {The main problem in students' lower achievement lies in the cognitive complexity of the problem. The aim of this research was to create and validate the procedure for the assessment of the cognitive complexity of chemical technology problem tasks. The procedure included the creation of Tables for assessing the difficulty of concepts in chemical technology problems and their interactivity, assessment of the numerical rating of cognitive complexity of the analyzed tasks, and conducting of research. Research included 50 students. Data were collected with the test of knowledge which was used for the assessment of students{\textasciiacute} achievements and invested mental effort. The validity of this procedure was confirmed by a series of correlation analyses where statistically significant values of correlation coefficients were obtained among the examined variables: students' achievements, invested mental effort and cognitive complexity. The largest contribution of this procedure is that it is designed to show an objective value of the cognitive complexity of tasks in the domain of chemical technology. Good estimation of the numerical values of cognitive complexity can help teachers to better predict students' achievement, and at the same time to take care to avoid cognitive load.},
  keywords = {Chemistry,Cognitive Processes,College Students,Correlation,Difficulty Level,Foreign Countries,Problem Solving,Science Achievement,Science Education,Scientific Concepts,Serbia,Technology},
  file = {/Users/colin.madland/Zotero/storage/HA7NA3IG/horvatValidationProcedureAssessment2020.pdf}
}

@article{horwitzPsychologicalEffectsOpen1979,
  title = {Psychological {{Effects}} of the ``{{Open Classroom}}''},
  author = {Horwitz, Robert A.},
  year = {1979},
  month = mar,
  journal = {Review of Educational Research},
  volume = {49},
  number = {1},
  pages = {71--85},
  issn = {0034-6543},
  doi = {10.3102/00346543049001071},
  urldate = {2018-11-04}
}

@article{hosseinfarhadyCrossContextualPerspectiveEFL2019,
  title = {A {{Cross-Contextual Perspective}} on {{EFL Teachers}}' {{Assessment Knowledge}}},
  author = {{Hossein Farhady}},
  year = {2019},
  abstract = {The purpose of this paper is to report on the findings of research on EFL teachers' language assessment knowledge (LAK) and argue that consistent findings of research that teachers do not have sufficient LAK may not reflect a true picture of the state of affairs. Rather, the findings might have been due to the artifact of the framework suggested some thirty years ago upon which most LAK tests have been developed (AFT, NCME, \& NEA, 1990). I would also argue that such tests may no longer reflect the reality of language assessment today since they are generic and context independent. Following Gotch and French (2014), I would argue that the present treatment of LAK, which is based on summative normative principles, might not be construct valid anymore. I will conclude the paper with suggesting a cross contextual framework that will hopefully represent a clear picture of the complex dimensions of LAK and lead to further research in this direction.}
}

@article{houldenPosthumanistCritiqueFlexible2019,
  title = {A Posthumanist Critique of Flexible Online Learning and Its ``Anytime Anyplace'' Claims},
  author = {Houlden, Shandell and Veletsianos, George},
  year = {2019},
  journal = {British Journal of Educational Technology},
  volume = {0},
  number = {0},
  issn = {0007-1013},
  doi = {10.1111/bjet.12779},
  urldate = {2019-04-03},
  abstract = {Abstract Flexible approaches to online learning are gaining renewed interest in some part due to their capacity to address emergent opportunities and concerns facing higher education. Importantly, flexible approaches to online learning are purported to be democratizing and liberatory, broadening access to higher education and enabling learners to participate in educational endeavours at ?anytime? from ?anyplace.? In this paper, we critique such narratives by showing that flexibility is neither universal nor neutral. Using critical theory, we demonstrate how flexibility assumes imagined autonomous learners that are self-reliant and individualistic. Through relevant examples, we show how such a framing to flexibility is oppressive, and argue that a contextual, relative and relational understanding of flexibility may in fact be more liberatory. Such an approach to flexibility, for example, may involve contextual and relational efforts to relax prescribed curricula within courses or programmes of study.}
}

@article{howardEducationalDataJourneys2022,
  title = {Educational Data Journeys: {{Where}} Are We Going, What Are We Taking and Making for {{AI}}?},
  author = {Howard, Sarah K. and Swist, Teresa and Gasevic, Dragan and Bartimote, Kathryn and Knight, Simon and Gulson, Kalervo and Apps, Tiffani and Peloche, Juliana and Hutchinson, Nathanael and Selwyn, Neil},
  year = {2022},
  month = jan,
  journal = {Computers and Education: Artificial Intelligence},
  volume = {3},
  pages = {100073},
  issn = {2666-920X},
  doi = {10.1016/j.caeai.2022.100073},
  abstract = {Educational systems generate huge quantities of digital data. Digital educational data is captured and used at all points -- from classrooms and schools, to the level of educational departments. As growing trends in `data-driven instruction' suggest, all these data have great potential to support student, teacher and leadership practices, help guide work and learning decisions, and inform policy development. Moreover, an increasing focus is being placed on the development of artificial intelligence to automate and improve how data are used. Yet, stakeholder data practices remain invisible and little understood, which complicates how artificial intelligence can be embedded in this context. In this paper, we introduce an educational data journeys framework to frame dynamics of data power, data work, identities and literacies. This approach is employed to explore educational policy revealing data flows and frictions in school improvement and implications for the development of artificial intelligence in education.},
  keywords = {Data journeys,Data practices,Educational data,Educational policy,Infrastructure},
  file = {/Users/colin.madland/Zotero/storage/LPCVDG4W/howardEducationalDataJourneys2022.pdf}
}

@misc{HowAssessmentChanging2020,
  type = {Blog},
  title = {How {{Assessment}} Is {{Changing}} in {{The Digital Age}} - {{Five Guiding Principles}}},
  year = {2020},
  month = aug,
  journal = {Contact North},
  urldate = {2020-09-09}
}

@misc{HowCanadianHigherEd,
  title = {How {{Canadian HigherEd Moved}} to {{Distance Learning}}},
  journal = {LISTedTECH},
  urldate = {2020-04-01},
  abstract = {In just under three weeks, almost all Canadian institutions have decided to select distance learning as their unique mode of delivery},
  howpublished = {https://www.listedtech.com/blog/how-canadian-highered-moved-to-distance-learning},
  langid = {american},
  keywords = {pivot},
  file = {/Users/colin.madland/Zotero/storage/QI45ZTQB/how-canadian-highered-moved-to-distance-learning.html}
}

@misc{HowCanEducators,
  title = {How Can Educators Respond to Students Presenting {{AI-generated}} Content as Their Own? {\textbar} {{OpenAI Help Center}}},
  shorttitle = {How Can Educators Respond to Students Presenting {{AI-generated}} Content as Their Own?},
  urldate = {2023-09-22},
  howpublished = {https://help.openai.com/en/articles/8313351-how-can-educators-respond-to-students-presenting-ai-generated-content-as-their-own},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/KYG95GW2/HowCanEducators.pdf;/Users/colin.madland/Zotero/storage/75XXQQ3P/8313351-how-can-educators-respond-to-students-presenting-ai-generated-content-as-their-own.html}
}

@misc{HowCanEstimate,
  title = {How Can {{I}} Estimate a Multiple Group Latent Class Model (Knownclass)? {\textbar} {{Mplus FAQ}}},
  publisher = {UCLA: Statistical Consulting Group},
  urldate = {2021-06-17}
}

@misc{HowChatGPTCan2023,
  title = {How {{ChatGPT}} Can Help Disrupt Assessment Overload},
  year = {2023},
  month = apr,
  journal = {THE Campus Learn, Share, Connect},
  urldate = {2023-04-19},
  abstract = {Advances in AI are not necessarily the enemy -- in fact, they should prompt long overdue consideration of assessment types and frequency, says David Carless},
  howpublished = {https://www.timeshighereducation.com/campus/how-chatgpt-can-help-disrupt-assessment-overload},
  file = {/Users/colin.madland/Zotero/storage/EZ3G3LXG/how-chatgpt-can-help-disrupt-assessment-overload.html}
}

@misc{HowTwoPhotos2020,
  title = {How Two Photos Exposed a Massive Problem of Racism in Social Media Apps},
  year = {2020},
  month = sep,
  journal = {indy100},
  urldate = {2020-09-22},
  abstract = {Last week, Twitter users held an experiment and it went about as disastrously as you could imagine. Entrepreneur Tony Arcieri posted two photos, one with former president Barack Obama's headshot on top of senator Mitch McConnell's and vice versa. He captioned the images: ``Which will the Twitter algorithm pick? Mitch McConnell or Barack Obama?'' In both photos, Twitter's image},
  chapter = {/news},
  howpublished = {https://www.indy100.com/article/twitter-algorithm-racial-bias-explainer-9712791},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/MT76LXMS/twitter-algorithm-racial-bias-explainer-9712791.html}
}

@misc{HowUseGoogle2017,
  title = {How to {{Use Google Spreadsheets}} and {{GitHub}} to {{Manage Data}} ({{Journalism}}) {{Projects}}},
  year = {2017},
  month = jul,
  journal = {Education Technology Data Sets},
  urldate = {2018-10-22},
  abstract = {As part of the research for my Spencer Fellowship, I'm trying to track as many of the financial, political, and social networks in ed-tech as I can. (I'm casting the net wide at first, ...},
  howpublished = {http://data.hackeducation.com/2017/07/28/how-to},
  keywords = {data,github}
}

@article{hsiaEnhancingStudentsChoreography2021,
  title = {Enhancing {{Students}}' {{Choreography}} and {{Reflection}} in {{University Dance Courses}}: {{A Mobile Technology-Assisted Peer Assessment Approach}}},
  author = {Hsia, Lu-Ho and Hwang, Gwo-Jen},
  year = {2021},
  month = jan,
  journal = {British Journal of Educational Technology},
  volume = {52},
  number = {1},
  pages = {266--287},
  publisher = {British Journal of Educational Technology},
  issn = {0007-1013},
  doi = {10.1111/bjet.12986},
  abstract = {Choreography is an important and challenging educational objective in dance courses. However, most previous technology-enhanced learning studies for dance education mainly focused on students' dance skills, while the issue concerning the approaches to promoting students' choreographic performance has generally been ignored. To address this issue, the present study developed a mobile technology-assisted peer assessment approach based on social constructivism for use in a university general education dance routine choreography class. A total of 266 university students were divided into an experimental group and a control group. The experiment lasted for 15~weeks and involved two rounds of peer assessment. The results showed that mobile peer assessment could significantly enhance the innovative competence of dance routines and dance skills. In addition, according to the students' feedback, the dance routine choreography class was conducive to improving social skills, innovative competence, and intrinsic motivation, while mobile peer assessment could assist students in understanding accurate evaluation criteria, reflecting on their own in a more objective way, and broadening the aspects of appreciating the work.},
  keywords = {College Students,Dance Education,Electronic Learning,Evaluation Criteria,Interpersonal Competence,Peer Evaluation,Reflection,Student Motivation,Teaching Methods,Technology Integration}
}

@article{huangEducationalTechnologyPrimer2019,
  title = {Educational {{Technology}}: {{A Primer}} for the 21st {{Century}}. {{Lecture Notes}} in {{Educational Technology}}},
  author = {Huang, Ronghuai and Spector, J. Michael and Yang, Junfeng},
  year = {2019},
  journal = {Educational Technology A Primer for the 21st Century},
  publisher = {Springer},
  issn = {2196-4963},
  doi = {10.1007/978-981-13-6643-7},
  abstract = {The aim of this book is to prepare students with knowledge and skills to understand the organizational needs and requirements of educational technology. Students should be able to use and manage both existing and emerging technologies effectively and be able to apply associated pedagogies to suit the environment, but also evaluate and manage technological advances of future and the requisite pedagogical shifts to achieve efficiency and effectiveness. The demand of educational technology has been rising steadily, primarily due to the fact that e-learning is a huge and significantly expanding world-wide industry. Commercial e-learning companies, training departments in large companies and organizations, computer software companies and educational institutions the world over employ large numbers of educational technology specialists. There is a strong demand for technologists who understand educational theories and for instructional designers and teachers who understand technologies. This book is targeted towards those who are looking for career in educational technology, instructional design, or media and information systems, or may want to continue their studies in graduate programs in learning and instructional technology, and those who are interested in becoming teacher in K-12 setting but need background in educational technology. This book will also act as a valuable resource in teacher education programs where primary focus on mainstream education and requires an authentic resource in instructional design and educational technology. Keeping in mind the varied needs of the organizations, employees and potential students, this book adopts a competency approach to learning and assessment. The themes and topics take a multi-disciplinary approach, and are aimed at preparing students for competent and innovative educational technology professionals.},
  keywords = {Design,Educational Technology,Elementary Secondary Education,Higher Education,Instructional Design,Interdisciplinary Approach,Program Development,Social Development,Teacher Education,Teaching Methods,Technological Literacy,Technology Uses in Education},
  file = {/Users/colin.madland/Zotero/storage/YCD8IN4Y/huangEducationalTechnologyPrimer2019.pdf}
}

@article{huangSuccessesChallengesOnline2020,
  title = {Successes and {{Challenges}}: {{Online Teaching}} and {{Learning}} of {{Chemistry}} in {{Higher Education}} in {{China}} in the {{Time}} of {{COVID-19}}},
  author = {Huang, Jie},
  year = {2020},
  journal = {Journal of chemical education},
  volume = {97},
  number = {9},
  pages = {2810--2814},
  publisher = {{American Chemical Society and Division of Chemical Education, Inc}},
  address = {WASHINGTON},
  issn = {0021-9584},
  doi = {10.1021/acs.jchemed.0c00671},
  abstract = {The Coronavirus disease 2019 (COVID-19) pandemic in China has changed higher education dramatically, with a distinctive rise in online instruction. Here, we describe the major successes and challenges encountered during the full implementation of online chemistry instruction in higher education in China based on questionnaires answered by 56 teachers and 432 students in two universities. In addition to describing the impacts of online chemistry instruction on teachers, students, chemistry experiments, student assessments, and technology, our work seeks to provide insights into how teachers, students, and technologies rise to meet the challenges in this difficult time. Our survey indicates the common challenges for teachers and students that arise from no face-to-face interaction in online instruction. Apart from that, teachers have to be familiar with internet-based technologies and online teaching tools, adjust their teaching plans and teaching methods, and quickly adapt to the new situation. Teachers also need to improve their teacher--student interaction and maintain student interest and engagement during online teaching. To become a successful online learner, students need to be more proactive and self-disciplined. In addition, an effective online teaching method for chemistry experiments has been proposed. While teachers and students still prefer classroom education, the vast majority of them are satisfied with the online chemistry course with significant support from technologies and online platforms.},
  keywords = {CAI,Chemistry,Chemistry Multidisciplinary,Classroom communication,College Faculty,College Students,Colleges & universities,Computer assisted instruction,COVID-19,Distance Education,Education,Education & Educational Research,Education Scientific Disciplines,Educational Technology,Foreign Countries,Higher Education,Interaction,Internet,Learning,Online Courses,Online instruction,Pandemics,Physical Sciences,Science & Technology,Science education,Science Experiments,Social Sciences,Students,Teacher Student Relationship,Teachers,Teaching,Teaching Methods,Technological Literacy,Technology assessment,Viral diseases}
}

@misc{huangTimeNewLens2021,
  title = {Time for a New Lens: {{The}} Hidden Racism behind Photography},
  shorttitle = {Time for a New Lens},
  author = {Huang, Solaya},
  year = {2021},
  month = feb,
  journal = {Calgary Journal},
  urldate = {2022-10-17},
  abstract = {Calgary photographers Shenda Chimwaso and Samuel Obadero understand just how biased the camera can be. But with education, awareness and representation in front and behind the camera, the stories a{\dots}},
  howpublished = {https://calgaryjournal.ca/2021/02/28/time-for-a-new-lens-the-hidden-racism-behind-photography/},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/XPYJG89B/time-for-a-new-lens-the-hidden-racism-behind-photography.html}
}

@article{hubballScholarshipTeachingLearning2006,
  title = {The {{Scholarship}} of {{Teaching}} and {{Learning}}: {{Theory}}--{{Practice Integration}} in a {{Faculty Certificate Program}}},
  shorttitle = {The {{Scholarship}} of {{Teaching}} and {{Learning}}},
  author = {Hubball, Harry T. and Burt, Helen},
  year = {2006},
  month = mar,
  journal = {Innovative Higher Education},
  volume = {30},
  number = {5},
  pages = {327--344},
  issn = {0742-5627, 1573-1758},
  doi = {10.1007/s10755-005-9000-6},
  urldate = {2022-06-29},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/NH2X7Z8S/hubballScholarshipTeachingLearning2006.pdf}
}

@article{huberDoesCollegeTeach2015,
  title = {Does {{College Teach Critical Thinking}}? {{A Meta-Analysis}}},
  author = {Huber, Christopher R. and Kuncel, Nathan R.},
  year = {2015},
  journal = {Review of Educational Research},
  doi = {10.3102/0034654315605917},
  abstract = {Educators view critical thinking as an essential skill, yet it remains unclear how effectively it is being taught in college. This meta-analysis synthesizes research on gains in critical thinking skills and attitudinal dispositions over various time frames in college. The results suggest that both critical thinking skills and dispositions improve substantially over a normal college experience. Furthermore, analysis of curriculum-wide efforts to improve critical thinking indicates that they do not necessarily produce incremental long-term gains. We discuss implications for the future of critical thinking in education.},
  keywords = {critical thinking}
}

@article{huberNarrativeInquiryPedagogy2013,
  title = {Narrative {{Inquiry}} as {{Pedagogy}} in {{Education}}: {{The Extraordinary Potential}} of {{Living}}, {{Telling}}, {{Retelling}}, and {{Reliving Stories}} of {{Experience}}},
  author = {Huber, Janice and Caine, Vera and Huber, Marilyn and Steeves, Pam},
  year = {2013},
  month = mar,
  journal = {Review of Research in Education},
  volume = {37},
  number = {1},
  pages = {212--242},
  issn = {0091-732X},
  doi = {10.3102/0091732X12458885},
  urldate = {2019-02-09}
}

@article{hudaEAssessmentHigherEducation2020,
  ids = {hudaEAssessmentHigherEducation2020a},
  title = {E-{{Assessment}} in {{Higher Education}}: {{Students}}' {{Perspective}}},
  author = {Huda, S. S. M. and Kabir, Md and Siddiq, Tanvir},
  year = {2020},
  journal = {International Journal of Education and Development using Information and Communication Technology},
  volume = {16},
  number = {2},
  pages = {250--258},
  publisher = {{International Journal of Education and Development using Information and Communication Technology}},
  issn = {ISSN-1814-0556},
  abstract = {This paper aims to examine the effectiveness of e-assessment in higher education from the perspective of students, and it also examines the student's reaction to this method. There are many developing countries that have begun to explore technology-based assessment systems. The new assessment system has benefits to institutions and to students. The purpose of this paper is to understand the benefits students are receiving from e-assessment as well as the complications they are facing when institutions are adapting e-assessment and switching from traditional assessment. The paper is based on the views of a small sample of university students chosen randomly, which found mixed reactions to e-assessment. Although students appreciate the importance of e-assessment, they have some fears about technology-based examinations as all of them do not have an equal level of IT competence. Further research should be carried out to explore other aspects of e-assessment in the higher education context.},
  langid = {english},
  keywords = {Bangladesh,Computer Assisted Testing,Foreign Countries,Graduate Students,No DOI found,Program Effectiveness,Psychological Patterns,Reliability,Student Attitudes,Technological Literacy,Technology Uses in Education,Undergraduate Students,Validity}
}

@article{hudaEAssessmentHigherEducation2020a,
  title = {E-{{Assessment}} in {{Higher Education}}: {{Students}}' {{Perspective}}.},
  shorttitle = {E-{{Assessment}} in {{Higher Education}}},
  author = {Huda, S. S. M. and Kabir, M. D. and Siddiq, Tanvir},
  year = {2020},
  journal = {International Journal of Education and Development using Information and Communication Technology},
  volume = {16},
  number = {2},
  pages = {250--258},
  publisher = {ERIC},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/TFZFU8P3/hudaEAssessmentHigherEducation2020a.pdf;/Users/colin.madland/Zotero/storage/8ASDJ865/eric.ed.gov.html}
}

@inproceedings{hudginsInformalLearningCommunities2020,
  title = {Informal Learning Communities: {{The}} Other Massive Open Online '{{C}}'},
  booktitle = {Proceedings of the Seventh {{ACM}} Conference on Learning @ Scale},
  author = {Hudgins, Will and Lynch, Michael and Schmal, Ash and Sikka, Harsh and Swenson, Michael and Joyner, David A.},
  year = {2020},
  series = {L@{{S}} '20},
  pages = {91--101},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3386527.3405926},
  abstract = {While the literature on learning at scale has largely focused on MOOCs, online degree programs, and AI techniques for supporting scalable learning experiences, informal learning communities have been relatively underrepresented. None-theless, these massive open online learning communities regularly draw far more engaged users than the typical MOOC. Their informal structure, however, makes them significantly more difficult to study. In this work, we take a first step toward attempting to understand these communi-ties specifically from the perspective of scale. Taking a sample of 62 such communities, we develop a tagging sys-tem for understanding the specific features and how they relate to scale. For example, just as a MOOC cannot man-ually grade every assignment, so also an informal learning community cannot approve every contribution; and just as MOOCs therefore employ autograding, informal learning communities employ crowd-sourced moderation or plat-form-driven enforcement. Using these tags, we then select several communities for deeper case studies. We also use these tags to make sense of learning-based subreddits from the popular community site Reddit, which offers an API for programmatic analysis. Based on these techniques, we offer findings about the performance of informal learning communities at scale and issue a call to include these envi-ronments more fully in future research on learning at scale.},
  isbn = {978-1-4503-7951-9},
  keywords = {case studies,informal learning,informal learning communities,online learning,reddit},
  file = {/Users/colin.madland/Zotero/storage/HV3PBK8Q/hudginsInformalLearningCommunities2020.pdf}
}

@incollection{huffLargescaleStandardsbasedAssessments2016,
  title = {Large-Scale Standards-Based Assessments of Educational Achievement},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {Huff, Kristen and Warner, Zachary and Schweid, Jason},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch17},
  pages = {397--426},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch17},
  abstract = {Summary Models of cognition are used in various ways, both explicitly and implicitly, in the design an validation of educational achievement tests. In this chapter we identify the major challenges with the use of cognitive models in large-scale assessment and offer ways to mitigate those challenges. To illustrate these challenges and potential solutions, we evaluate four educational assessments (NAEP, PARCC, AP, and New York State Common Core tests) using the analytical framework provided by Leighton and Gierl's (2007) taxonomy of cognitive models in educational measurement. We conclude the chapter with specific recommendations for improving the design and validation of educational achievement tests through the more explicit use of cognitive models of learning.},
  chapter = {17},
  isbn = {978-1-118-95658-8},
  keywords = {Common Core,large-scale educational assessment,NAEP,PARCC,standards-based assessment,taxonomy of cognitive models}
}

@article{hugOpennessEducationClaims2017,
  title = {Openness in {{Education}}: {{Claims}}, {{Concepts}}, and {{Perspectives}} for {{Higher Education}}},
  author = {Hug, Theo},
  year = {2017},
  journal = {Seminar.net},
  volume = {13},
  number = {2},
  urldate = {2018-09-24},
  abstract = {Characteristics of openness can be found in many respects throughout the history of education. From Comenius' call for pedagogical reform to postmodern educational theory, requirements of access, social justice, creativity, knowledge sharing, innovation, and capacity building have been emphasized in various ways. The chapter provides an outline of different understandings and notions of openness in educational contexts as well a discussion of their relevance for openness towards academic knowledge cultures and different forms of knowledge. Finally, the contribution highlights organizational, methodological, and critical perspectives as three aspects which appear to be undervalued in current debates about openness in higher education.}
}

@book{huntRealitiesChangeHigher2006,
  title = {The {{Realities}} of {{Change}} in {{Higher Education}} : {{Interventions}} to {{Promote Learning}} and {{Teaching}}},
  author = {Hunt, Lynne and Bromage, Adrian and Tomkinson, Bland},
  year = {2006},
  publisher = {Taylor \& Francis Group},
  address = {Florence, UNITED STATES},
  isbn = {978-0-203-96965-6},
  keywords = {Education Higher.,Educational change.}
}

@incollection{hurstDevelopingTeamSkills2008,
  title = {Developing {{Team Skills}} and {{Accomplishing Team Projects Online}}},
  booktitle = {The {{Theory}} and {{Practice}} of {{Online Learning}}},
  author = {Hurst, Deborah and Thomas, Janice},
  editor = {Anderson, Terry},
  year = {2008},
  edition = {2nd},
  pages = {441--472},
  publisher = {AU Press},
  address = {Athabasca}
}

@article{husseinEvaluationOnlineProctoring2020,
  ids = {husseinEvaluationOnlineProctoring2020a},
  title = {An {{Evaluation}} of {{Online Proctoring Tools}}},
  author = {Hussein, Mohammed Juned and Yusuf, Javed and Deb, Arpana Sandhya and Fong, Letila and Naidu, Som},
  year = {2020},
  journal = {Open Praxis},
  volume = {12},
  number = {4},
  pages = {509--525},
  publisher = {Open Praxis},
  issn = {EISSN-2304-070X},
  doi = {10/gmbv3m},
  abstract = {COVID-19 is hastening the adoption of online learning and teaching worldwide, and across all levels of education. While many of the typical learning and teaching transactions such as lecturing and communicating are easily handled by contemporary online learning technologies, others, such as assessment of learning outcomes with closed book examinations are fraught with challenges. Among other issues to do with students and teachers, these challenges have to do with the ability of teachers and educational organizations to ensure academic integrity in the absence of a live proctor when an examination is being taken remotely and from a private location. A number of online proctoring tools are appearing on the market that portend to offer solutions to some of the major challenges. But for the moment, they too remain untried and tested on any large scale. This includes the cost of the service and their technical requirements. This paper reports on one of the first attempts to properly evaluate a selection of these tools and offer recommendations for educational institutions. This investigation, which was carried out at the University of the South Pacific, comprised a four-phased approach, starting with desk research that was followed with pilot testing by a group of experts as well as students. The elimination of a tool in every phase was based on the 'survival of the fittest' approach with each phase building upon the milestones and deliverables from the previous phase. This paper presents the results of this investigation and discusses its key findings.},
  langid = {english},
  keywords = {Automation,Cheating,College Students,Computer Assisted Testing,Computer Software Evaluation,Costs,COVID-19,Distance Education,Fiji,Foreign Countries,Information Security,Integrated Learning Systems,Integrity,Internet,Open Source Technology,Pandemics,Privacy,Student Attitudes,Supervision,Usability,Video Technology},
  file = {/Users/colin.madland/Zotero/storage/BNG3IJNE/husseinEvaluationOnlineProctoring2020.pdf}
}

@book{husserlIntroductionTranscendentalPhenomenology1929,
  title = {Introduction to Transcendental Phenomenology},
  author = {Husserl, Edmund},
  year = {1929},
  publisher = {Atcost Press},
  address = {Sackville, New Brunswick}
}

@article{husseyIfFirstYou2020,
  title = {If at {{First You Don}}'t {{Succeed}}, {{Try Closing Another Assessment Loop}}: {{Implementing Online Co-Curricular Assessment}}},
  author = {Hussey, Heather D. and Babcock, Ashley and Lehan, Tara J.},
  year = {2020},
  journal = {Open Praxis},
  volume = {12},
  number = {3},
  pages = {425--436},
  issn = {EISSN-2304-070X},
  doi = {10/gmbvzc},
  abstract = {Higher education institutions are commonly tasked with demonstrating student learning in and out of the classroom. Although academic and student affairs share a common goal of supporting student success, they frequently do not speak the same assessment language. This lack of alignment can lead to miscommunication and missed opportunities to collaboratively promote learning and achievement. Further, it can be a struggle to implement assessment protocols if institutional stakeholders do not value and believe in the importance of their role in the assessment process. In this paper, we discuss how professionals at an online academic success center used the Theory of Planned Behavior to inform and improve an assessment protocol as part of the institution's overall assessment plan. The steps and strategies used over multiple assessment loops are discussed to demonstrate the path taken to build a collaborative learning environment for students in and out of the online classroom.},
  langid = {english},
  keywords = {Alternative Assessment,Behavior Theories,Coaching (Performance),College Outcomes Assessment,Educational Improvement,Electronic Learning,Evaluation Methods,Graduate Students,Online Courses,Student Evaluation}
}

@article{hutchisonUsingWikiFacilitate2012,
  title = {Using a Wiki to Facilitate an Online Professional Learning Community for Induction and Mentoring Teachers},
  author = {Hutchison, Amy and Colwell, Jamie},
  year = {2012},
  journal = {Education and Information Technologies},
  volume = {17},
  number = {3},
  pages = {273--289},
  keywords = {community,Development,LEARNING,Online,PROFESSIONAL,Wiki}
}

@article{hyltonUtilizingWebcambasedProctoring2016,
  title = {Utilizing Webcam-Based Proctoring to Deter Misconduct in Online Exams},
  author = {Hylton, Kenrie and Levy, Yair and Dringus, Laurie P.},
  year = {2016},
  month = jan,
  journal = {Computers \& Education},
  volume = {92--93},
  pages = {53--63},
  issn = {03601315},
  doi = {10.1016/j.compedu.2015.10.002},
  urldate = {2022-02-04},
  langid = {english},
  keywords = {archived},
  annotation = {https://web.archive.org/web/20220204162856/https://www.sciencedirect.com/science/article/abs/pii/S0360131515300518?via\%3Dihub},
  file = {/Users/colin.madland/Zotero/storage/HPBNMH9Q/hyltonUtilizingWebcambasedProctoring2016.pdf}
}

@article{iannoneImpactHighStakes2020,
  title = {The Impact of High Stakes Oral Performance Assessment on Students' Approaches to Learning: A Case Study},
  shorttitle = {The Impact of High Stakes Oral Performance Assessment on Students' Approaches to Learning},
  author = {Iannone, Paola and Czichowsky, Christoph and Ruf, Johannes},
  year = {2020},
  month = mar,
  journal = {Educational Studies in Mathematics},
  volume = {103},
  number = {3},
  pages = {313--337},
  issn = {0013-1954, 1573-0816},
  doi = {10/gmcvbf},
  urldate = {2021-07-31},
  abstract = {Abstract             This paper presents findings from a case study on the impact of high stakes oral performance assessment on third year mathematics students' approaches to learning (Entwistle and Ramsden, Understanding student learning, 1983). We choose oral performance assessment as this mode of assessment differs substantially from written exams for its dialogic nature and because variation of assessment methods is seen to be very important in an otherwise very uniform assessment diet. We found that students perceived the assessment to require conceptual understanding over memory and were more likely to employ revision strategies conducive to deep learning (akin to conceptual understanding) when preparing for the oral performance assessment than when preparing for a written exam. Moreover, they reported to have engaged and interacted in lectures more than they would have otherwise, another characteristic conducive to deep learning approaches. We conclude by suggesting some implications for the summative assessment of mathematics at university level.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/RYZ2I349/iannoneImpactHighStakes2020.pdf}
}

@article{ibarra-saizFutureAssessmentHigher2020,
  ids = {ibarra-saizFutureAssessmentHigher2020a},
  title = {The Future of Assessment in {{Higher Education}}},
  author = {{Ibarra-Saiz}, M. S. and {Rodriguez-Gomez}, G. and Boud, D. and Rotsaert, T. and Brown, S. and {Salinas-Salazar}, M. L. and {Rodriguez-Gomez}, H. M.},
  year = {2020},
  journal = {Revista electr{\'o}nica de investigaci{\'o}n y evaluaci{\'o}n educativa},
  volume = {26},
  number = {1},
  publisher = {Asoc Interuniversitaria Investigacion Pedagogica},
  address = {VALENCIA},
  issn = {1134-4032},
  doi = {10.7203/relieve.26.1.17323},
  abstract = {The pending challenge of assessment in higher education, although also at other educational levels, continues to be its effective link with student learning. Students' strategic learning could and should be achieved by the assessment. This paper arises from the attempt to answer the question about what would be the future of assessment in higher education and it is presented under the form of a collaborative text that was elaborated by all the authors who sign it. This contribution offers a joint reflection by various authors from different contexts and regions on three essential aspects. First, the need for reflection and a change in assessment based on current trends that are demonstrating their timeliness and validity is highlighted. A second issue focuses on the value of technology for the changes that are taking place on assessment, but as long as it adapts to its principles and, therefore, does not imply a return to the last century under the dominance of models today widely overcome. Together with the use of technology-enhanced assessment, the interrelationship between assessment and learning implies to redesign assessment practices, to incorporate proposals from the fields of social justice and sustainable assessment, the design of authentic assessment tasks, to promote feedback and encourage students' participation. In brief, to collaborate to develop the students' evaluative judgment in order to achieve free, socially responsible and fair citizens.},
  keywords = {Assessment,Assessment as learning,Assessment tasks,Assessment tools,Collaboration,Education & Educational Research,Feedback,FEEDBACK,Higher education,Participation,Social Sciences,Sustainable assessment,Technology enhanced assessment},
  file = {/Users/colin.madland/Zotero/storage/2CA5W7MA/ibarra-saizFutureAssessmentHigher2020.pdf}
}

@article{ibarra-saizMethodsInstrumentsAssess2023,
  title = {Methods and Instruments to Assess Learning Outcomes in Master's Degrees. {{Analysis}} of Teachers' Perception of Their Evaluative Practice},
  author = {{Ibarra-Saiz}, Mari Soledad and {Rodriguez-Gomez}, Gregorio and {Lukas-Mujika}, Jose Francisco and {Santos-Berrondo}, Alaitz},
  year = {2023},
  journal = {Educaci{\'o}n XX1},
  volume = {26},
  number = {1},
  pages = {21--45},
  publisher = {Univ Nacional Educacion Distancia},
  address = {MADRID},
  issn = {1139-613X},
  doi = {10.5944/educxx1.33443},
  abstract = {Previous studies on the assessment methods and instruments used in higher education have revealed that the final exam has been widely used as the main source of assessment. Advances in knowledge of assessment processes have shown the need to have a greater breadth and diversity of methods and instruments that allow the collection of thorough and valid information on which to base judgments about the level of learning in students. Within the framework of the FLOASS Project, this study has been carried out in order to explore the perception that teachers have of their assessment practice. A mixed methodology has been used, through an exploratory sequential design, which has allowed to gather the perception of 416 professors from six universities belonging to different autonomous communities, who completed the RAPEVA questionnaire - Self-report of the teaching staff on their practice in the learning outcomes assessment. Among the most widely used methods, participation, problem solving tests, performance tests, digital objects or multimedia presentations and projects and rubrics or evaluative arguments are highlighted among the assessment instruments. The greatest differences were found depending on the university, the field of knowledge or the degree of security and satisfaction with the assessment system. In the case of gender or experience, differences are small or non-existent. Future lines of research that enable a better understanding of assessment practice in higher education are provided.},
  keywords = {Education & Educational Research,Educational evaluation,Educational objectives,Higher education,Information sources,Learning,Multimedia,Perceptions,Social Sciences,Students,Teaching},
  file = {/Users/colin.madland/Zotero/storage/XHVRGSFR/ibarra-saizMethodsInstrumentsAssess2023.pdf}
}

@article{ibarra-saizQualityAssessmentTasks2020,
  title = {The Quality of Assessment Tasks as a Determinant of Learning},
  author = {{Ibarra-S{\'a}iz}, Mar{\'i}a Soledad and {Rodr{\'i}guez-G{\'o}mez}, Gregorio and Boud, David},
  year = {2020},
  month = oct,
  journal = {Assessment \& Evaluation in Higher Education},
  pages = {1--13},
  issn = {0260-2938, 1469-297X},
  doi = {10/ghg5nx},
  urldate = {2020-10-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/D4XPQST6/ibarra-saizQualityAssessmentTasks2020.pdf}
}

@article{ibarra-saizQualityAssessmentTasks2021,
  title = {The Quality of Assessment Tasks as a Determinant of Learning},
  author = {{Ibarra-S{\'a}iz}, Mar{\'i}a Soledad and {Rodr{\'i}guez-G{\'o}mez}, Gregorio and Boud, David},
  year = {2021},
  month = aug,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {46},
  number = {6},
  pages = {943--955},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2020.1828268},
  urldate = {2023-09-19},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/Z8XLQ57Y/ibarra-saizQualityAssessmentTasks2021.pdf}
}

@book{ifenthalerDigitalKnowledgeMaps2014,
  title = {Digital {{Knowledge Maps}} in {{Education}}: {{Technology-Enhanced Support}} for {{Teachers}} and {{Learners}}},
  shorttitle = {Digital {{Knowledge Maps}} in {{Education}}},
  editor = {Ifenthaler, Dirk and Hanewald, Ria},
  year = {2014},
  publisher = {Springer New York},
  address = {New York, NY},
  doi = {10.1007/978-1-4614-3178-7},
  urldate = {2023-07-31},
  isbn = {978-1-4614-3177-0 978-1-4614-3178-7},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/U6W2A49U/ifenthalerDigitalKnowledgeMaps2014.pdf}
}

@incollection{ifenthalerMakingUseData2018,
  title = {Making {{Use}} of {{Data}} for {{Assessments}}: {{Harnessing Analytics}} and {{Data Science}}},
  booktitle = {Second {{Handbook}} of {{Information Technology}} in {{Primary}} and {{Secondary Education}}},
  author = {Ifenthaler, Dirk and Greiff, Samuel and Gibson, David},
  editor = {Voogt, Joke and Knezek, Gerald and Christensen, Rhonda and Lai, Kwok-Wing},
  year = {2018},
  pages = {649--663},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-71054-9_41},
  abstract = {The increased availability of vast and highly varied amounts of data from learners, teachers, learning environments, and administrative systems within educational settings is overwhelming. The focus of this chapter is on how data with a large number of records, of widely differing datatypes, and arriving rapidly from multiple sources can be harnessed for meaningful assessments and supporting learners in a wide variety of learning situations. Distinct features of analytics-driven assessments may include self-assessments, peer assessments, and semantic rich and personalized feedback as well as adaptive prompts for reflection. The chapter concludes with future directions in the broad area of analytics-driven assessments for teachers and educational researchers.},
  isbn = {978-3-319-71054-9},
  file = {/Users/colin.madland/Zotero/storage/I4WL5PMR/ifenthalerMakingUseData2018.pdf}
}

@article{iglesiasperezRoleSelfPeer2020,
  title = {The Role of Self and Peer Assessment in {{Higher Education}}},
  author = {Iglesias Perez, M. C. and {Vidal-Puga}, J. and Pino Juste, M. R.},
  year = {2020},
  journal = {Studies in higher education (Dorchester-on-Thames)},
  number = {Journal Article},
  pages = {1--10},
  publisher = {ROUTLEDGE JOURNALS, TAYLOR \& FRANCIS LTD},
  address = {ABINGDON},
  issn = {0307-5079},
  doi = {10/gmb8hr},
  abstract = {Self-assessment and peer assignment have clear advantages for the training of responsible, critical, and reflective professionals. In recent years, self and peer evaluation have also been shown to be even more effective than lecturer evaluation when we assure anonymity through online platforms learning tools. Therefore, self and peer assessments are to become a core aspect of student-centred evaluation processes in Higher Education. Besides, a high concordance with lecturer evaluation may allow lecturers to also benefit from self and peer evaluation without an increase in their workload. In the present work, we compare the formative evaluation from the lecturer with the self and peer assessments through a virtual learning environment. The subject of study if formed by assessments prepared by students in a first-year course in a Social Sciences degree at the Universidade de Vigo, Spain. We find a strong concordance between peer assessment and lecturer assignment, and a moderate agreement between self-assessment and lecturer assignment. These results show that students perform well as peer evaluators, with peer assignment being a procedure with high validity and reliability.},
  keywords = {Education & Educational Research,Social Sciences}
}

@article{illerisTransformativeLearningPerspective2004,
  title = {Transformative Learning the Perspective of a Comprehensive Learning Theory},
  author = {Illeris, k.},
  year = {2004},
  journal = {Jornal of Transformative Education},
  volume = {2},
  number = {2},
  pages = {79--89}
}

@misc{IndigenousPolicySilence2017,
  title = {Indigenous {{Policy}} and {{Silence}} at {{Confederation}}},
  year = {2017},
  month = jun,
  journal = {Borealia},
  urldate = {2019-12-11},
  abstract = {This essay is the first in a three-part series on Confederation that provides critical historical context for Canada's sesquicentennial anniversary. The other essays will appear on the 28th a{\dots}},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/H85WNUFI/indigenous-policy-and-silence-at-confederation.html}
}

@incollection{innamiStructuralEquationModeling2013,
  title = {Structural {{Equation Modeling}} in {{Educational Research}}: {{A Primer}}},
  shorttitle = {Structural {{Equation Modeling}} in {{Educational Research}}},
  booktitle = {Application of {{Structural Equation Modeling}} in {{Educational Research}} and {{Practice}}},
  author = {In'nami, Yo and Koizumi, Rie},
  editor = {Khine, Myint Swe},
  year = {2013},
  pages = {23--51},
  publisher = {SensePublishers},
  address = {Rotterdam},
  doi = {10.1007/978-94-6209-332-4_2},
  urldate = {2023-07-07},
  isbn = {978-94-6209-332-4},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/ZGD59ATB/innamiStructuralEquationModeling2013.pdf}
}

@book{inoueAntiracistWritingAssessment2015,
  title = {Antiracist Writing Assessment Ecologies: Teaching and Assessing Writing for a Socially Just Future},
  shorttitle = {Antiracist Writing Assessment Ecologies},
  author = {Inoue, Asao B.},
  year = {2015},
  series = {Perspectives on Writing},
  publisher = {The WAC Clearinghouse ; Parlor Press},
  address = {Fort Collins, Colorado : Anderson, South Carolina},
  isbn = {978-1-60235-773-0},
  lccn = {PE1404 .I47 2015},
  keywords = {Anti-racism,Discrimination in higher education,English language,Rhetoric Study and teaching (Higher) Evaluation,Rhetoric Study and teaching (Higher) Social aspects,Study and teaching,United States}
}

@misc{IntegratingGenerativeAI,
  title = {Integrating {{Generative AI}} into {{Higher Education}}: {{Considerations}}},
  shorttitle = {Integrating {{Generative AI}} into {{Higher Education}}},
  urldate = {2023-09-22},
  abstract = {Integrating AI into higher education is not a futuristic vision but an inevitability. Colleges and universities must adapt and prepare students, facul},
  howpublished = {https://er.educause.edu/articles/2023/8/integrating-generative-ai-into-higher-education-considerations},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/B8FBU6JD/IntegratingGenerativeAI.pdf;/Users/colin.madland/Zotero/storage/UMCMPTUG/integrating-generative-ai-into-higher-education-considerations.html}
}

@misc{IntegrativeAssessment,
  title = {Integrative {{Assessment}}},
  urldate = {2022-10-15},
  howpublished = {https://www.lancaster.ac.uk/od-and-ed/educational-development/assessment-practice/integrative-assessment/},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/MW9Y7764/integrative-assessment.html}
}

@misc{internationalChiefDesignOfficer,
  title = {Chief {{Design Officer}} at {{Twitter Apologizes For Company}}'s '{{Racist}}' {{Photo-Cropping Algorithm}}},
  author = {International, Max Gorbachev Sputnik},
  urldate = {2020-09-22},
  abstract = {This is not the first time that big tech companies have found themselves in hot water over political incorrectness. In July, Microsoft's artificial intelligence, put in...},
  howpublished = {https://sputniknews.com/us/202009201080519899-chief-design-officer-at-twitter-apologizes-for-companys-racist-photo-cropping-algorithm/},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/5MUBXKHR/202009201080519899-chief-design-officer-at-twitter-apologizes-for-companys-racist-photo-croppin.html}
}

@article{InternationalJournalEducational2010,
  title = {International Journal of Educational Technology in Higher Education.},
  year = {2010},
  journal = {International journal of educational technology in higher education.},
  publisher = {SpringerOpen},
  address = {Chaim},
  issn = {2365-9440},
  keywords = {Computer science -- Education (Higher),Education Higher,Educational technology,Electronic journals,Information technology,Periodicals}
}

@article{InternetHigherEducation1998,
  title = {Internet and Higher Education ({{Online}})},
  year = {1998},
  journal = {Internet and higher education (Online)},
  publisher = {Elsevier Science Pub. Co.},
  address = {New York, NY},
  issn = {1873-5525},
  keywords = {Computer-assisted instruction,Computer-assisted instruction -- Periodicals,Education Higher -- Data processing,Education Higher -- Effect of technological innovations on,Educational innovations -- Periodicals,Electronic journals,Enseignement -- Innovations -- Periodiques,Enseignement assiste par ordinateur,Enseignement assiste par ordinateur -- Periodiques,Enseignement superieur -- Effets des innovations sur,Enseignement superieur -- Informatique,Enseignement superieur -- Informatique -- Periodiques,Internet en education,Internet en education -- Periodiques,Internet in education,Internet in education -- Periodicals,Periodicals}
}

@techreport{iosadAssessmentRebooted2020,
  title = {Assessment Rebooted},
  author = {Iosad, Alexander and Pauli, Michelle and Attewell, Sue},
  year = {2020},
  number = {2},
  address = {Bristol},
  institution = {Jisc},
  urldate = {2021-07-06},
  abstract = {The higher education (HE) sector has adapted rapidly to new practices across its entire operations, from learning and teaching to partnerships, validation, student support and facilities. Higher education institutions have, in a very short time frame, had to adapt their assessment practices to fit online delivery. In doing so, they have needed to ensure that the assessment arrangements are robust, guarding against academic misconduct while also ensuring the fair treatment of students who have had to submit their work in challenging circumstances.},
  file = {/Users/colin.madland/Zotero/storage/P923B8KL/iosadAssessmentRebooted2020.pdf}
}

@inproceedings{irvineEmergenceChoiceMultiAccess2009,
  ids = {valerieirvineEmergenceChoiceMultiAccess2009},
  title = {The {{Emergence}} of {{Choice}} in ``{{Multi-Access}}'' {{Learning Environments}}: {{Transferring Locus}} of {{Control}} of {{Course Access}} to the {{Learner}}},
  booktitle = {{{EdMedia}} + {{Innovate Learning}} 2009},
  author = {Irvine, Valerie},
  editor = {Siemens, George and Fulford, Catherine},
  year = {2009},
  pages = {746--752},
  publisher = {Association for the Advancement of Computing in Education (AACE)},
  abstract = {This paper is based on the emerging research program that examines the mixture of various technologies and the role they play in supporting face-to-face, blended, and/or blended online learning environments. With the introduction of video conferencing and sophisticated recording and streaming servers, a model of choice has emerged to represent the role of the learner in designating the type of access to learning environments. This model is being suggested out of necessity as instructors attempt to balance between meeting the needs of on-campus students, remote cohorts who have access to full video conferencing rooms, distance students with common residential bandwidth, or even the isolated learner with access to high bandwidth desktop video conferencing.}
}

@article{irvineLandscapeMergingModalities2020,
  title = {The {{Landscape}} of Merging Modalities},
  author = {Irvine, Valerie},
  year = {2020},
  journal = {EDUCAUSE Review},
  volume = {2020},
  number = {4},
  pages = {40--58},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/YP7AXV79/irvineLandscapeMergingModalities2020.pdf}
}

@inproceedings{irvineMultiSectionOpenCourse2022,
  title = {Multi-{{Section Open Course Design}}: {{Design}} and {{Implications}} for {{Faculty}}, {{Sessional Instructors}}, and {{Learners}}},
  booktitle = {Proceedings of the {{Open}}/{{Technology}} in {{Education}}, {{Society}}, and {{Scholarship Association Conference}}},
  author = {Irvine, Valerie and Paskevicius, Michael and Madland, Colin and McCue, Rich and Roberts, Verena},
  year = {2022},
  pages = {1--3},
  address = {Online}
}

@article{irvineMultiSectionOpenCourse2022a,
  title = {Multi-{{Section Open Course Design}}: {{Design}} and {{Implications}} for {{Faculty}}, {{Sessional Instructors}}, and {{Learners}}},
  author = {Irvine, Valerie and Paskevicius, Michael and Madland, Colin and McCue, Rich and Roberts, Verena},
  year = {2022},
  journal = {Open Praxis}
}

@article{irvineRealigningHigherEducation2013,
  title = {Realigning Higher Education for the 21st-Century Learner through Multi-Access Learning},
  author = {Irvine, Valerie and Code, Jillianne and Richards, Luke},
  year = {2013},
  month = jun,
  journal = {Journal of Online Learning and Teaching},
  volume = {9},
  number = {2},
  urldate = {2014-04-26},
  abstract = {Twenty-first-century learners have expectations that are not met within the current model of higher education. With the introduction of online learning, the anytime/anywhere mantra taken up by many postsecondary institutions was a first step to meeting learner needs for flexibility; however, the choice and determination of delivery mode still resides with the institution and course instructors. Recently, the massive open online course (MOOC) movement has been introduced as an undeniable force in higher education, and the authors argue that it is distracting leadership from focusing on alternative options for supporting the needs of learners who demand both personalization and real access to learning opportunities. The key element to the MOOC movement is its openness that enables student access to education. In this article, the authors present the multi-access learning framework that envelops the MOOC phenomenon and merges course access modes enabling student choice and agency. The authors report results from a pilot study on one type of multi-access course, where students were able to choose their mode of access. In this case, remote students accessed the course via webcam and joined their on-campus classmates and instructor who were together face-to-face. Implications for multi-access learning in relation to the MOOC movement are discussed.},
  copyright = {CC-BY-NC-SA},
  keywords = {multi-access}
}

@inproceedings{irvineTeachingOpenSupporting2020,
  title = {Teaching in the {{Open}}: {{Supporting Open Access Designs}} for {{Social Justice}}},
  booktitle = {Let's {{Talk}} about {{Teaching}}},
  author = {Irvine, Valerie and James, Heidi and Madland, Colin and McCue, Rich},
  year = {2020},
  publisher = {University of Victoria},
  address = {Victoria, BC},
  abstract = {The Educational Technology program area has made a commitment to offering courses in an open access format to promote public access to educational resources, learner access to course resources beyond the term of the course, and the development of learning communities that persist beyond the course and even program. Among the benefits of open online course development are the support it may provide to instructors who may otherwise need to design from scratch and the standardization of course curriculum across multiple sections and collaboration between instructors working anywhere. Learners benefit from the shift from online courses being focused on the content and the instructor to emphasizing the learner blog posts and the discourse that develops around building a network of posts and comments on a particular topic. Supports for learners include the use of blog templates to bypass the learning curve when starting to blog and building-in sample posts, pages, and menus to get started.},
  copyright = {All rights reserved}
}

@phdthesis{irvineTechnologyEducationCanadian2006,
  title = {Technology Education in {{Canadian}} Faculties of Education: {{Structure}} and Support in Teacher Education Programs},
  author = {Irvine, Valerie Margit},
  year = {2006},
  journal = {ProQuest Dissertations and Theses},
  address = {Ann Arbor},
  abstract = {Technology has recently been making a tremendous impact on the K to 12 school system. A number of provincial initiatives have been introduced to incorporate information and communication technology (ICT) education in the K-12 school system. With the high cost of implementing technology programs and the knowledge that properly trained teachers make the difference between the success or failure of a technology plan (Collis, 1996), administrators must look to teacher training to ensure financial investments in education are preserved. Our research community, however, is lacking information regarding how our preservice teacher preparation programs are tackling this issue across Canada. The purpose of this dissertation is to investigate the current structure of ICT education in Canadian Faculties of Education. The first set of objectives is to explore the structure of and support for technology education in teacher education programs at Faculties of Education across Canada. The second is to explore the existence of K-12 ICT curriculum and funding within each province.},
  isbn = {978-0-494-23047-3},
  langid = {english},
  school = {University of Alberta (Canada)},
  keywords = {0530:Teacher education,0710:Educational technology,Education,Educational technology,Faculties of education,Information and communication technology,Teacher education,Technology education},
  annotation = {NR23047},
  file = {/Users/colin.madland/Zotero/storage/625BUIJT/irvineTechnologyEducationCanadian2006.pdf}
}

@phdthesis{irvineTechnologyEducationCanadian2007,
  title = {Technology Education in {{Canadian}} Faculties of Education: Structure and Support in Teacher Education Programs.},
  shorttitle = {Technology Education in {{Canadian}} Faculties of Education},
  author = {Irvine, Valerie Margit},
  year = {2007},
  address = {Ottawa},
  isbn = {9780494230473},
  langid = {english},
  school = {Library and Archives Canada = Biblioth{\`e}que et Archives Canada},
  annotation = {OCLC: 426219794},
  file = {/Users/colin.madland/Zotero/storage/RDPBR8FD/irvineTechnologyEducationCanadian2007.PDF}
}

@article{irwinExaminingIncreasedFlexibility2012,
  title = {Examining Increased Flexibility in Assessment Formats},
  author = {Irwin, Brian and Hepplestone, Stuart},
  year = {2012},
  journal = {Assessment \& Evaluation in Higher Education},
  doi = {10/ctxv8h},
  abstract = {There have been calls in the literature for changes to assessment practices in higher education, to increase flexibility and give learners more control over the assessment process. This article explores the possibilities of allowing student choice in the format used to present their work, as a starting point for changing assessment, based on recent studies and current examples of flexible assessment practice in higher education. The benefits of this flexible assessment format approach are highlighted, along with a discussion of classic assessment considerations such as validity, reliability and marking concerns. The role of technology in facilitating assessment method choice is considered, in terms of new opportunities for providing student choice in the way they evidence their learning and present their work. Considerations for implementing flexible assessment choices into the curriculum are presented, along with a call that further research into such practice is needed to develop a comprehensive set of ...},
  pmcid = {null},
  pmid = {null}
}

@article{irwinExaminingIncreasedFlexibility2012a,
  title = {Examining Increased Flexibility in Assessment Formats},
  author = {Irwin, Brian and Hepplestone, Stuart},
  year = {2012},
  journal = {Assessment \& Evaluation in Higher Education},
  doi = {10/ctxv8h},
  abstract = {There have been calls in the literature for changes to assessment practices in higher education, to increase flexibility and give learners more control over the assessment process. This article explores the possibilities of allowing student choice in the format used to present their work, as a starting point for changing assessment, based on recent studies and current examples of flexible assessment practice in higher education. The benefits of this flexible assessment format approach are highlighted, along with a discussion of classic assessment considerations such as validity, reliability and marking concerns. The role of technology in facilitating assessment method choice is considered, in terms of new opportunities for providing student choice in the way they evidence their learning and present their work. Considerations for implementing flexible assessment choices into the curriculum are presented, along with a call that further research into such practice is needed to develop a comprehensive set of ...},
  pmcid = {null},
  pmid = {null}
}

@article{iseke-barnesPedagogiesDecolonizing2008,
  title = {Pedagogies for {{Decolonizing}}},
  author = {{Iseke-Barnes}, Judy M.},
  year = {2008},
  journal = {Canadian Journal of Native Education},
  volume = {31},
  number = {1},
  pages = {123},
  issn = {0710-1481},
  abstract = {This article provides examples of introductory activities that engage students in initial steps in understanding the systemic structure of colonization. Examples of student group responses to the activities are provided. The understandings explored by students through these activities are then taken up through Indigenous literatures in university contexts in order to contribute to the ongoing decolonization of knowledge in the university and to explore indigenous understandings of pedagogies. The author explores various themes important to the decolonizing of educational practices through discussions of (a) colonizing and decolonizing agendas, (b) disrupting government ideology, (c) decolonizing government and reclaiming Indigenous governance, (e) decolonizing spirituality and ceremony, (f) disrupting colonizing ideologies and decolonizing minds, (g) reconnecting to land, (h) decolonizing history, and (i) community-based education and decolonizing education. Conclusions drawn include the importance of engaging students in Indigenous pedagogies so that they can find support for transforming understandings through Indigenous literatures and understand strategies and opportunities to decolonize education. [PUBLICATION ABSTRACT]},
  keywords = {Colleges & universities,Colonialism,Curricula,Education,Ideology,Linguistics,Native education,Teaching}
}

@article{ishaqExploringSummativeAssessment2020,
  title = {Exploring {{Summative Assessment}} and {{Effects}}: {{Primary}} to {{Higher Education}}},
  author = {Ishaq, Kashif and Rana, Abdul Majid Khan and Zin, Nor Azan Mat},
  year = {2020},
  journal = {Bulletin of Education and Research},
  volume = {42},
  number = {3},
  pages = {23--50},
  issn = {ISSN-0555-7747},
  abstract = {This research explored the structure of primary, elementary, secondary, and tertiary levels of education and assessment in the academia of Pakistan. The fundamental purpose of the study was to contextualize the assessment system from primary to higher institutions and an examination of recent changes by the educational authorities. It began with a quick history of the examination system, summative assessment, and explained the current education system and the evaluation process in education. The data obtained from the Punjab Examination Commission (PEC) of 5th and 8th grade, from the Board of Intermediate and Secondary Education (BISE) of 9th grade, and the Punjab University for the undergraduate level was used to evaluate the instructional and examination methods. Results showed poor performance, especially in English, as it was not taught by applying modern and effective teaching methods. The outdated evaluation process and inadequate curricula are factors for poor performance.},
  langid = {english},
  keywords = {Academic Achievement,College Students,Elementary School Students,English (Second Language),Evaluation Methods,Foreign Countries,Grade 5,Grade 8,Grade 9,Instructional Effectiveness,Low Achievement,No DOI found,Outcomes of Education,Second Language Instruction,Secondary School Students,Student Evaluation,Summative Evaluation,Teaching Methods}
}

@book{ismayGettingUsedRStudio,
  title = {Getting {{Used}} to {{R}}, {{RStudio}}, and {{R Markdown}}},
  author = {Ismay, Chester and Kennedy, Patrick C},
  urldate = {2020-01-13},
  abstract = {An introduction into using R, RStudio, and R Markdown for new users},
  file = {/Users/colin.madland/Zotero/storage/KQ9FCR98/rbasics.netlify.com.html}
}

@book{ismayStatisticalInferenceData,
  title = {Statistical {{Inference}} via {{Data Science}}: {{A ModernDive}} into {{R}} and the Tidyverse},
  author = {Ismay, Chester and Kim, Albert Y},
  series = {The {{R Series}}},
  publisher = {CRC Press},
  urldate = {2020-01-11},
  abstract = {An open-source and fully-reproducible electronic textbook for teaching statistical inference using tidyverse data science tools.},
  file = {/Users/colin.madland/Zotero/storage/EWCRBVC4/index.html}
}

@book{ismayStatisticalInferenceData2025,
  title = {Statistical {{Inference}} via {{Data Science}}: {{A ModernDive}} into {{R}} and the {{Tidyverse}}},
  shorttitle = {Statistical {{Inference}} via {{Data Science}}},
  author = {Ismay, Chester and Kim, Albert Y. and Valdivia, Arturo},
  year = {2025},
  month = mar,
  edition = {2},
  publisher = {{Chapman and Hall/CRC}},
  address = {Boca Raton},
  doi = {10.1201/9781032724546},
  urldate = {2025-05-17},
  isbn = {978-1-032-72454-6},
  langid = {english}
}

@article{ivankovaStudentsPersistenceDistributed2007,
  title = {Students' {{Persistence}} in a {{Distributed Doctoral Program}} in {{Educational Leadership}} in {{Higher Education}}: {{A Mixed Methods Study}}},
  shorttitle = {Students' {{Persistence}} in a {{Distributed Doctoral Program}} in {{Educational Leadership}} in {{Higher Education}}},
  author = {Ivankova, Nataliya V. and Stick, Sheldon L.},
  year = {2007},
  month = feb,
  journal = {Research in Higher Education},
  volume = {48},
  number = {1},
  pages = {93--135},
  issn = {0361-0365, 1573-188X},
  doi = {10.1007/s11162-006-9025-4},
  urldate = {2023-08-11},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/Z7WCUSM3/ivankovaStudentsPersistenceDistributed2007.pdf}
}

@article{ivankovaUsingMixedMethodsSequential2006,
  title = {Using {{Mixed-Methods Sequential Explanatory Design}}: {{From Theory}} to {{Practice}}},
  author = {Ivankova, Nataliya V. and Creswell, John W. and Stick, Sheldon L.},
  year = {2006},
  month = feb,
  journal = {Field Methods},
  volume = {18},
  number = {1},
  pages = {3--20},
  publisher = {SAGE Publications Inc},
  issn = {1525-822X},
  doi = {10.1177/1525822X05282260},
  urldate = {2023-08-16},
  abstract = {This article discusses some procedural issues related to the mixed-methods sequential explanatory design, which implies collecting and analyzing quantitative and then qualitative data in two consecutive phases within one study. Such issues include deciding on the priority or weight given to the quantitative and qualitative data collection and analysis in the study, the sequence of the data collection and analysis, and the stage/stages in the research process at which the quantitative and qualitative data are connected and the results are integrated. The article provides a methodological overview of priority, implementation, and mixing in the sequential explanatory design and offers some practical guidance in addressing those issues. It also outlines the steps for graphically representing the procedures in a mixed-methods study. A mixed-methods sequential explanatory study of doctoral students? persistence in a distance-learning program in educational leadership is used to illustrate the methodological discussion.},
  file = {/Users/colin.madland/Zotero/storage/4EDRVM8X/ivankovaUsingMixedMethodsSequential2006.pdf}
}

@article{jaamUsingAssessmentDesign2021,
  title = {Using {{Assessment Design Decision Framework}} in Understanding the Impact of Rapid Transition to Remote Education on Student Assessment in Health-Related Colleges: {{A}} Qualitative Study},
  author = {Jaam, Myriam and Nazar, Zachariah and Rainkie, Daniel C. and Hassan, Diana Alsayed and Hussain, Farhat Naz and Kassab, Salah Eldin and Agouni, Abdelali},
  year = {2021},
  journal = {PloS one},
  volume = {16},
  number = {7},
  publisher = {Public Library Science},
  address = {SAN FRANCISCO},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0254444},
  abstract = {Maintaining integrity and validity with online assessment is a significant issue that is well documented. Overt policies encouraging educators to adopt e-Learning and implement digital services coupled with the dramatic change in the education system in response to the challenges posed by COVID-19, has furthered the demand for evidence-based approaches for the planning and delivery of assessments. This study employed the Assessment Design Decision Framework (ADDF), a theoretical model that considers key aspects of assessment design, to retrospectively investigate from a multi-stakeholder perspective the assessments implemented following the rapid transition to remote learning during the COVID-19 pandemic. One-to-one semi-structured interviews were conducted with faculty and students from the Colleges of Pharmacy, Medicine and Health Sciences. After inductive and deductive thematic analysis three major themes were identified. These reflected on the impact of sudden transition on assessment design and assessment plan; changing assessment environment; and faculty-student assessment related interactions which included feedback. The use of a comprehensive validated framework such as ADDF, to plan assessments can improve validity and credibility of assessments. The strengths of this study lie in the innovative adoption of the ADDF to evaluate assessment design decisions from both an educator and student perspective. Further, the data yielded from this study offers novel validation of the use of ADDF in circumstances necessitating rapid transition, and additionally identifies a need for greater emphasis to be attributed to the significance of timeliness of the various activities that are advocated within the framework.},
  keywords = {Assessments,Biology and Life Sciences,Collaboration,Colleges & universities,Computer and Information Sciences,Confidentiality,Coronaviruses,COVID-19,Decision making,Decision theory,Dentistry,Design,Design analysis,Distance learning,Education,Engineering and Technology,Evaluation,Feedback,Health sciences,Interviews,Learning management systems,Medical research,Medicine,Medicine and Health Sciences,Multidisciplinary Sciences,Online education,Pandemics,Pharmaceutical sciences,Pharmacy,Public health,Qualitative research,Research and Analysis Methods,Research methodology,Science & Technology,Science & Technology - Other Topics,Social Sciences,Software,Students,Teams},
  file = {/Users/colin.madland/Zotero/storage/P79AJ6KS/jaamUsingAssessmentDesign2021.pdf}
}

@incollection{jacksonConversationbasedAssessment2016,
  title = {Conversation-Based Assessment},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {Jackson, G. Tanner and {Zapata-Rivera}, Diego},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch23},
  pages = {563--579},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch23},
  abstract = {Summary Conversation-based assessments (CBAs) represents a new type of performance-based assessment where students engage in an adaptive dialogue exchange with a computer with one or more virtual agents. This assessment approach leverages the open response format of human-to-human conversations -- similar to constructed response items -- in order to allow students to express their thoughts and ideas using their own words. Additionally, CBAs are highly interactive -- similar to simulations -- and contain automatically adapted dialogue structures. Both of these features allow for the collection of new types of explanatory evidence that potentially afford greater insight into student cognition and metacognition. In this chapter we discuss CBAs in more detail, provide an augmented framework to contrast CBAs and other kinds of assessment tasks, and illustrate the power of CBAs through two sub-tasks from a recently developed assessment prototype.},
  chapter = {23},
  isbn = {978-1-118-95658-8},
  keywords = {assessment formats,conversation-based assessment,formative assessment,performance assessment,student cognition}
}

@article{jacksonFacultyActionsThat2010,
  title = {Faculty Actions That Result in Student Satisfaction in Online Courses},
  shorttitle = {Faculty Actions That Result in Student Satisfaction in Online Courses},
  author = {Jackson, Lana C. and Jones, Stephanie J. and Rodriguez, Roy C.},
  year = {2010},
  journal = {Journal of Asynchronous Learning Networks},
  volume = {14},
  pages = {78--96},
  issn = {19395256},
  abstract = {This study identified faculty actions which positively influenced student satisfaction in the online classroom at the community college level. The escalating demand for Internet-based, distance education courses has been met by an increased inventory of them. However, while online education has been in existence for over a decade, standardized practices in the online classroom have not been fully identified, developed, and implemented. Data was collected from student evaluations of two web-based courses at two Texas community colleges. Descriptive statistics, bivariate correlations and multiple regressions were used to identify faculty behaviors which affected the satisfaction of students enrolled in these courses. The results of the study indicated that faculty actions within online courses appeared to impact student satisfaction. The identification of faculty actions which impact student satisfaction in online courses will greatly assist colleges and universities in strengthening their abilities to provide quality online experiences for their students. [ABSTRACT FROM AUTHOR] Copyright of Journal of Asynchronous Learning Networks is the property of Sloan Consortium and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
  keywords = {Asynchronous,Behaviors,Colleges,community,COMMUNITY colleges,Distance,distance education,Education,Environments,Faculty,Faculty Behaviors,Faculty Interactions,instruction,Interactions,LEARNING,Learning Environments,Online,Online learning,relationships,Satisfaction,Student,Student Satisfaction,TEACHER-student,TEACHER-student relationships,TEXAS,WEB-based,WEB-based instruction},
  annotation = {4}
}

@misc{jacksonForProfitCompanyTrying2021,
  title = {'{{A For-Profit Company Is Trying}} to {{Privatize}} as {{Many Public Libraries}} as {{They Can}}'},
  author = {Jackson, Janine},
  year = {2021},
  month = dec,
  journal = {FAIR},
  urldate = {2022-01-06},
  abstract = {"There's just a lot of potential for the information loop to be a closed loop that's controlled by one company."},
  chapter = {Featured Posts},
  langid = {american},
  keywords = {scantron}
}

@misc{jacksonIndianRemovalAct1830,
  title = {Indian {{Removal Act}}},
  author = {Jackson, Andrew},
  year = {1830},
  month = may,
  urldate = {2019-12-11},
  abstract = {An act to provide for an exchange of lands with the Indians residing in any of the states or territories, and for their removal west of the river Mississippi.},
  chapter = {CXLVIII}
}

@article{jaeEffectivenessClosedCaption2019,
  title = {The {{Effectiveness}} of {{Closed Caption Videos}} in {{Classrooms}}: {{Objective}} versus {{Subjective Assessments}}},
  author = {Jae, Haeran},
  year = {2019},
  month = may,
  journal = {Journal of Instructional Pedagogies},
  volume = {22},
  publisher = {Journal of Instructional Pedagogies},
  issn = {2327-5324},
  abstract = {The extant research has focused on investigating the effectiveness of the use of closed caption videos for hearing impaired or English as second language learners. Yet, the research about whether such usage can be beneficial for other students is limited. This paper explores the effectiveness of closed caption videos (same-language subtitles) in a college classroom. Results from objective and subjective assessments find that showing a closed caption video versus noncaption video in a classroom resulted in better understanding of video contents and higher positive attitudes toward viewing closed caption videos in class.},
  keywords = {Americans with Disabilities Act 1990,Assistive Technology,Civil Rights Legislation,Classroom Techniques,College Curriculum,College Faculty,College Students,Consumer Economics,Disabilities,Educational Media,Evaluation Methods,Federal Legislation,Foreign Countries,India,Instructional Effectiveness,Learning Processes,Marketing,Multimedia Instruction,No DOI found,Positive Attitudes,Student Experience,Video Technology}
}

@article{jaegerTimePressureScenariobased2017,
  title = {Time Pressure in Scenario-Based Online Construction Safety Quizzes and Its Effect on Students' Performance},
  author = {Jaeger, Martin and Adair, Desmond},
  year = {2017},
  journal = {European journal of engineering education},
  volume = {42},
  number = {3},
  pages = {241--251},
  publisher = {Taylor \& Francis},
  address = {ABINGDON},
  issn = {0304-3797},
  doi = {10.1080/03043797.2016.1153042},
  abstract = {Online quizzes have been shown to be effective learning and assessment approaches. However, if scenario-based online construction safety quizzes do not include time pressure similar to real-world situations, they reflect situations too ideally. The purpose of this paper is to compare engineering students' performance when carrying out an online construction safety quiz with time pressure versus an online construction safety quiz without time pressure. Two versions of an online construction safety quiz are developed and administered to randomly assigned engineering students based on a quasi-experimental post-test design. The findings contribute to scenario-based learning and assessment of construction safety in four ways. First, the results confirm earlier findings that 'intrinsic stress' does not seem to impair students' performance. Second, students who carry out the online construction safety quiz with time pressure are less likely to 'learn by trial and error'. Third, students exposed to time pressure appreciate that they become better prepared for real life. Finally, preparing students to work under time pressure is an important industry requirement. The results of this study should encourage engineering educators to explore and implement ways to include time pressure in scenario-based online quizzes and learning.},
  keywords = {Academic Achievement,Comparative Analysis,Computer Assisted Testing,Construction (Process),Construction accidents & safety,Construction Industry,Construction management,construction safety,Control Groups,Design engineering,Distance learning,Education & Educational Research,Engineering Education,Error analysis,Evaluation methods,Experimental Groups,Higher education,Occupational safety,Online assessment,Online quiz,Performance factors,Pretests Posttests,Quasiexperimental Design,Safety,Safety education,Scenario-based learning,Social Sciences,Statistical Analysis,Stress Management,Student assessment,Student Attitudes,Student Motivation,student performance,Students,Test Format,Test Results,Tests,Time Management,time pressure,Undergraduate Students,Vignettes}
}

@article{jaggarsHowOnlineCourse2016,
  title = {How Do Online Course Design Features Influence Student Performance?},
  author = {Jaggars, Shanna Smith and Xu, Di},
  year = {2016},
  month = apr,
  journal = {Computers \& Education},
  volume = {95},
  pages = {270--284},
  issn = {03601315},
  doi = {10/f8gdrc},
  urldate = {2020-10-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/YLS635M2/jaggarsHowOnlineCourse2016.pdf}
}

@article{jaggarsHowOnlineCourse2016a,
  title = {How Do Online Course Design Features Influence Student Performance?},
  author = {Jaggars, {\relax SS} and Xu, D},
  year = {2016},
  journal = {Computers \& Education},
  volume = {95},
  pages = {270--284},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2016.01.014},
  abstract = {Given the rapid growth in online coursework within higher education, it is important to establish and validate quality standards for these courses. While many online learning quality rubrics do exist, thus far there has been little empirical evidence establishing a clear link between specific course design features and concrete, student-level course outcomes. In the current study, the authors develop an online course design assessment rubric that includes four areas, and explore the impact of each area on student end-of semester performance in 23 online courses at two community colleges. The results indicate that the quality of interpersonal interaction within a course relates positively and significantly to student grades. Additional analyses based on course observation and interview data suggest that frequent and effective student instructor interaction creates an online environment that encourages students to commit themselves to the course and perform at a stronger academic level. (C) 2016 Elsevier Ltd. All rights reserved.},
  langid = {english},
  keywords = {COMMUNITY,Computer-mediated communication,DISTANCE EDUCATION,Distance education and telelearning,INSTRUCTION,Pedagogical issues,Postsecondary education,Teaching/learning strategies},
  file = {/Users/colin.madland/Zotero/storage/TANPN8MN/jaggarsHowOnlineCourse2016a.pdf}
}

@misc{jakubauskasHttpsTwitterCom2020,
  type = {Twitter},
  title = {{{https://twitter.com/Jakubaus/status/1283071222415347712?s=20}}},
  author = {Jakubauskas, Mark},
  year = {2020},
  month = jul
}

@incollection{jamesAssessmentLearning2008,
  title = {Assessment and Learning},
  booktitle = {Unlocking {{Assessment}}},
  author = {James, Mary},
  editor = {Swaffield, Sue},
  year = {2008},
  month = apr,
  publisher = {David Fulton Publishers},
  doi = {10.4324/9780203930939},
  urldate = {2022-04-17},
  isbn = {978-1-134-05401-5},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/T64IGBDP/jamesAssessmentLearning2008.pdf}
}

@inproceedings{jamesCoDesigningCoTeachingOnline2020,
  title = {Co-{{Designing}} and {{Co-Teaching}} an {{Online Course}}},
  booktitle = {Let's {{Talk}} about {{Teaching}}},
  author = {James, Heidi and Madland, Colin},
  year = {2020},
  publisher = {University of Victoria},
  address = {Victoria, BC},
  abstract = {In the summer of 2020, Colin and Heidi taught EDCI 335 using a shared WordPress site. Despite our radically different timelines (Heidi's cohort ran May 11-June 26, and Colin's ran May 4-July 28), we co-created the outline, activities, content, and community. In this podcast, Colin and Heidi will talk about what worked well for the course, what the challenges were as we went, and how this process resulted in the creation of a course hub legacy that will inform and support future instructors.},
  copyright = {All rights reserved}
}

@article{jamiesonLikertScalesHow2004,
  title = {Likert Scales: How to (Ab)Use Them},
  shorttitle = {Likert Scales},
  author = {Jamieson, Susan},
  year = {2004},
  month = dec,
  journal = {Medical Education},
  volume = {38},
  number = {12},
  pages = {1217--1218},
  issn = {0308-0110},
  doi = {10/b5gxwx},
  langid = {english},
  pmid = {15566531},
  keywords = {Attitude of Health Personnel,Bias,Data Interpretation Statistical,Education Medical Undergraduate,Humans,Reproducibility of Results,Research Design},
  file = {/Users/colin.madland/Zotero/storage/ZMQSUVSR/jamiesonLikertScalesHow2004.pdf}
}

@techreport{jankowskiAssessmentCrisisResponding2020,
  title = {Assessment {{During A Crisis}}: {{Responding}} to a {{Global Pandemic}}},
  author = {Jankowski, Natasha A.},
  year = {2020},
  address = {Urbana, IL},
  institution = {{University of Illinois and Indiana University, National Institute for Learning Outcomes Assessment}},
  file = {/Users/colin.madland/Zotero/storage/DDTGFR5X/jankowskiAssessmentCrisisResponding2020.pdf}
}

@techreport{jankowskiPandemicInsightsShape2022,
  title = {Pandemic {{Insights}} to {{Shape}} a {{Better Future}}: {{Assessment}} for {{Teaching}}, {{Learning}}, {{Equity}}, and {{Student Success}}},
  author = {Jankowski, Natasha A. and Bheda, Divya},
  year = {2022},
  institution = {{National Institute for Learning Outcomes Assessment and ExamSoft}},
  abstract = {Teaching and learning throughout the pandemic has been filled with constant shifts and changes---to educational mediums, learning environments, policies and protocols, and relationships within education. While there was social distance, there was a shared experience throughout higher education---of adaptation and pivoting--- to continue the teaching and learning endeavor. At the end of September 2021 through October 2021, a survey was conducted by Dr. Natasha Jankowski, former executive director of the National Institute for Learning Outcomes Assessment (NILOA) and Dr. Divya Bheda of ExamSoft Worldwide LLC, in partnership with Dr. Gianina Baker of NILOA. The purpose of the survey was to explore what could be learned from the various shifts and changes to assessment-related processes and practices undertaken in response to COVID-19 in order to inform the future of assessment. Higher education colleagues were invited to share their experiences and help imagine the future of assessment. Over 800 responses were collected and analyzed. Respondents spanned all roles in higher education---students, staff, faculty, administrators and leaders of various capacities including assessment---as well as all institutional types. This report provides insights as well as ideas to explore as higher education moves forward and the future of assessment is shaped. Our report serves two functions. First, it serves as a means to share high-level findings and responses to the survey. Second, it serves as a guide to planning and ideation around the future of teaching, learning, and assessment; informed by the responses and what was learned from the findings. As such, it is divided into two main sections: findings and imagining a new future. Throughout 2022, readers are invited to participate in a series of discussions and thought papers on the ideas presented in the report.},
  annotation = {https://examsoft.com/resources/webinar-pandemic-insights-to-shape-a-better-future/},
  file = {/Users/colin.madland/Zotero/storage/562NVWXD/jankowskiPandemicInsightsShape2022.pdf}
}

@book{jankowskiStudentFocusedLearningAssessment2020,
  title = {Student-{{Focused Learning}} and {{Assessment}}},
  editor = {Jankowski, Natasha A. and Baker, Gianina R. and Montenegro, Erick and {Brown-Tess}, Karie},
  year = {2020},
  month = jan,
  publisher = {Peter Lang US},
  doi = {10.3726/b16909},
  urldate = {2021-04-06},
  isbn = {978-1-4331-8051-4 978-1-4331-8050-7 978-1-4331-8052-1 978-1-4331-8006-4},
  file = {/Users/colin.madland/Zotero/storage/6HDGRPV5/jankowskiStudentFocusedLearningAssessment2020.pdf}
}

@incollection{jankowskiStudentPerceptionsInvolvement2020,
  title = {Student {{Perceptions}} of and {{Involvement}} with {{Assessment}} in {{Higher Education}}},
  booktitle = {Student-{{Focused Learning}} and {{Assessment}}},
  author = {Jankowski, Natasha A. and Teitelbaum, Emily},
  editor = {Jankowski, Natasha A. and Baker, Gianina R. and {Brown-Tess}, Karie and Montenegro, Erick},
  year = {2020},
  publisher = {Peter Lang Publishing},
  abstract = {Students who enter higher education have vast prior experiences with assess- ment of learning, particularly in the United States, where under the auspices of the No Child Left Behind (NCLB) federal legislation they have been annually tested in high-stakes standardized tests with implications for the sec- ondary schools they attend. Understanding students' experiences with and perceptions of assessment is vital to ensure that a meaningful assessment pro- cess is undertaken that provides valid results in a course, within a program, or across an institution. But it also speaks to the realization that students come to higher education with perceptions of different assessment practices that are meaningful (or not) to their learning process. In short, the way a student per- ceives assessment impacts how that student approaches it and their learning.}
}

@article{jansevanrensburgDevelopingDigitalCreativity2022,
  title = {Developing Digital Creativity through Authentic Assessment},
  author = {{Janse van Rensburg}, Cecile and Coetzee, Stephen A. and Schmulian, Astrid},
  year = {2022},
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {47},
  number = {6},
  pages = {857--877},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0260-2938},
  doi = {10.1080/02602938.2021.1968791},
  abstract = {Digital creativity, the use of digital tools and technologies to explore creative ideas and new ways of displaying your ideas, research or work, is emerging as an important competency for graduates across many disciplines. The development of digital creativity competency in domains traditionally perceived as being less creative, including the accounting profession, has yet to be explored. This study reports on the use of an authentic assessment for learning to develop students' digital creativity in an undergraduate competency-based accounting course. It documents the design and development of the assessment and analyses the students' digital creative outputs as well as lived experiences. Although many of the outputs were at a lower level of digital creativity, most of the students appear to have experienced the process positively and gained insight into their course material and need for digital creativity in accounting. The design of the authentic assessment can inform the development of similar assessments in other disciplinary settings.},
  keywords = {Authentic assessment,College students,competency-based education,Creativity,digital creativity,Education & Educational Research,Educational evaluation,Higher education,social constructivism,Social Sciences}
}

@incollection{januszewskiDefinition2013,
  title = {Definition},
  booktitle = {Educational {{Technology}}},
  editor = {Januszewski, Al and Molenda, Michael},
  year = {2013},
  publisher = {Routledge},
  urldate = {2024-10-09},
  isbn = {978-1-136-50327-6},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/januszewskiDefinition2013.pdf}
}

@book{januszewskiEducationalTechnology2013,
  title = {Educational {{Technology}}},
  editor = {Januszewski, Al and Molenda, Michael},
  year = {2013},
  edition = {0},
  publisher = {Routledge},
  doi = {10.4324/9780203054000},
  urldate = {2024-10-09},
  isbn = {978-1-136-50327-6},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/januszewskiEducationalTechnology2013.pdf}
}

@phdthesis{jarrEducationPractitionersInterpretation2012,
  type = {Doctor of {{Philosophy}}},
  title = {Education Practitioners' Interpretation and Use of Assessment Results},
  author = {Jarr, Karoline Ann},
  year = {2012},
  month = jul,
  doi = {10.17077/etd.35vh2oc1},
  urldate = {2021-07-29},
  langid = {english},
  school = {University of Iowa},
  file = {/Users/colin.madland/Zotero/storage/M2ASAEV2/jarrEducationPractitionersInterpretation2012.pdf}
}

@article{jarvelaExploringSociallyShared2013,
  title = {Exploring Socially Shared Regulation in the Context of Collaboration},
  author = {J{\"a}rvel{\"a}, Sanna and J{\"a}rvenoja, Hanna and Malmberg, Jonna and Hadwin, Allyson F},
  year = {2013},
  journal = {Journal of Cognitive Education and Psychology},
  volume = {12},
  number = {3},
  pages = {267--286},
  issn = {19458959},
  abstract = {Socially shared regulation of learning refers to processes by which group members regulate their collective activity. Successful individuals regulate their motivational, cognitive, and metacognitive engagement. Our hypothesis is that successful groups also share in regulating group processes. Following our earlier conceptual and empirical work on the social aspect of motivating and regulating learning (Hadwin \& J{\"a}rvel{\"a}, 2011; J{\"a}rvenoja \& J{\"a}rvel{\"a}, 2009; J{\"a}rvel{\"a}, Volet, \& J{\"a}rvenoja, 2010), our research questions are as follows: (a) What challenges do individuals and groups report experiencing during collaborative group work? (b) How do students collectively regulate these challenges at the time, and in future collaborations? (c) How do collaborative learning outcomes compare between groups with varying degrees of emerging shared regulation? We present an empirical study in which 18 graduate students worked in collaborative teams of 3-4 over an 8-week period. The nStudy (Winne, Hadwin, \& Beaudoin, 2010) software was used for collaborative planning and work, as well as face-to-face and online collaboration between team members. Data included individual and collaborative statements about collaborative challenges, collaborative statements about contextual and future regulation strategies, collaborative learning performance, and log file traces of students' contributions to collaborative chat discussions and planning activities. Findings indicated that the students expressed multiple challenges resulting in 3 kinds of regulation over time profiles: strong, progressive, and weak shared regulation. We also conclude that successful collaboration not only requires self-regulation but also allows each team member to support fellow team members to successfully regulate their learning and the team to come together to collectively regulate learning. [PUBLICATION ABSTRACT]},
  langid = {english},
  keywords = {Behavior,Collaboration,Emotions,motivation,psychology,Studies}
}

@article{jarvelaNewFrontiersRegulating2013,
  title = {New {{Frontiers}}: {{Regulating Learning}} in {{CSCL}}},
  shorttitle = {New {{Frontiers}}},
  author = {J{\"a}rvel{\"a}, Sanna and Hadwin, Allyson F.},
  year = {2013},
  month = jan,
  journal = {Educational Psychologist},
  volume = {48},
  number = {1},
  pages = {25--39},
  issn = {0046-1520, 1532-6985},
  doi = {10/gf2qnr},
  urldate = {2021-03-09},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/2CEAVPIP/jarvelaNewFrontiersRegulating2013.pdf}
}

@article{jarvelaSociallySharedRegulation2016,
  title = {Socially Shared Regulation of Learning in {{CSCL}}: {{Understanding}} and Prompting Individual- and Group-Level Shared Regulatory Activities},
  author = {J{\"a}rvel{\"a}, Sanna and Kirschner, Paul A and Hadwin, Allyson and J{\"a}rvenoja, Hanna and Malmberg, Jonna and Miller, Mariel and Laru, Jari},
  year = {2016},
  journal = {International journal of computer-supported collaborative learning},
  volume = {11},
  number = {3},
  pages = {263--280},
  publisher = {Springer US},
  address = {New York},
  issn = {1556-1607},
  doi = {10.1007/s11412-016-9238-2},
  abstract = {The field of computer supported collaborative learning (CSCL) is progressing instrumentally and theoretically. Nevertheless, few studies examine the effectiveness and efficiency of CSCL with respect to cognitive, motivational, emotional, and social issues, despite the fact that the role of regulatory processes is critical for the quality of students' engagement in collaborative learning settings. We review the four earlier lines in developing support in CSCL and show how there has been a lack of work to support individuals in groups to engage in, sustain, and productively regulate their own and the group's collaborative processes. Our aim is to discuss how our conceptual work in socially shared regulation of learning (SSRL) contributes to effective and efficient CSCL, what tools are presently available, and what the implications of research on these tools are for future tool development.},
  keywords = {CAI,Cognitive Processes,Cognitive Psychology,Collaboration,Collaborative virtual environments,Computer aided instruction,Computer Assisted Instruction,Computer supported collaborative learning,Computers and Education,Control,Cooperative Learning,Distance learning,Education,Educational Technology,Efficiency,Emotional Response,Government regulations,Group work in education,Independent study,Laws regulations and rules,Learner dashboards,Learner Engagement,Learning,Learning and Instruction,Motivation,Program Effectiveness,Prompting,Self-regulated learning,Self-regulation tools,Social Influences,Teaching Methods,Team learning approach in education,User Interfaces and Human Computer Interaction},
  file = {/Users/colin.madland/Zotero/storage/98X4VEV8/jarvelaSociallySharedRegulation2016.pdf}
}

@phdthesis{jarvenojaSociallySharedRegulation2010,
  title = {{Socially shared regulation of motivation and emotions in collaborative learning}},
  author = {J{\"a}rvenoja, Hanna},
  year = {2010},
  address = {Oulu},
  urldate = {2022-01-13},
  langid = {In English; with summary in Finnish},
  school = {University of Oulu},
  keywords = {archived},
  annotation = {OCLC: 847384380; https://web.archive.org/web/20200608005725/http://jultika.oulu.fi/Record/isbn978-951-42-6330-9},
  file = {/Users/colin.madland/Zotero/storage/PLTQCBVX/jarvenojaSociallySharedRegulation2010.pdf}
}

@incollection{jarvisActionResearch1999,
  title = {Action Research},
  booktitle = {The Practitioner-Researcher: {{Developing}} Theory from Practice},
  author = {Jarvis, P.},
  editor = {Jarvis, P.},
  year = {1999},
  pages = {89--101},
  publisher = {Jossey-Bass},
  address = {San Francisco}
}

@incollection{jarvisPracticeTheory1999,
  title = {From Practice to Theory?},
  booktitle = {The Practitioner-Researcher: {{Developing}} Theory from Practice},
  author = {Jarvis, P.},
  editor = {Jarvis, P.},
  year = {1999},
  pages = {149--155},
  publisher = {Jossey-Bass},
  address = {San Francisco}
}

@misc{jasonmlodge[@jasonmlodge]ChatGPTConsistentlyFails2023,
  type = {Tweet},
  title = {{{ChatGPT}} Consistently Fails (Most Parts of) the Assessment Tasks {{I}} Assign My Students. {{Here}} Are Some Reflections on Why {{I}} Think It Struggles with Certain Bits. {{https://t.co/jLkOLdjdGo}}},
  author = {{Jason M Lodge [@jasonmlodge]}},
  year = {2023},
  month = jan,
  journal = {Twitter},
  urldate = {2023-01-30},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/9FIDWUM8/1619862547569729536.html}
}

@article{jawedDigitalProfessionalIdentity2019,
  title = {Digital Professional Identity: {{Dear Internet}}! {{Who}} Am {{I}}?},
  shorttitle = {Digital Professional Identity},
  author = {Jawed, Saira and Mahboob, Usman and Yasmeen, Rahila},
  year = {2019},
  journal = {Education for Health},
  volume = {32},
  number = {1},
  pages = {33},
  issn = {1357-6283},
  doi = {10.4103/efh.EfH_232_17},
  urldate = {2021-12-23},
  langid = {english}
}

@article{jeongSustainableFlippedSTEM2020,
  title = {Sustainable and {{Flipped STEM Education}}: {{Formative Assessment Online Interface}} for {{Observing Pre-Service Teachers}}' {{Performance}} and {{Motivation}}},
  author = {Jeong, Jin Su and {Gonz{\'a}lez-G{\'o}mez}, David and Yllana Prieto, F{\'e}lix},
  year = {2020},
  journal = {Education Sciences},
  volume = {10},
  issn = {EISSN-2227-7102},
  abstract = {Sustainable science, technology, engineering, and mathematics (STEM) education involves lifelong education in various domains. Active learning strategies are receiving increased attention as an important tool, and particularly online-based formative assessment interfaces, although challenges to their use remain in sustainable and flipped STEM education. In this research, we observed pre-service teachers' (PSTs') performance and motivation in a university STEM course that was planned as a randomized examination of 71 students during a 2017/2018 course with an online interface for sustainable and flipped formative assessment. In terms of PSTs' standardized performance and the motivation effect survey, we gathered and examined the data to observe pre- and post-test results on adaptive assignments. Additionally, feedback from/to instructors and their log records were recorded by the proposed interface. The results demonstrate the PSTs' positive performance and motivation, and the feedback and log records reiterate its positive influence with 98.6\% participation in the sustainable and flipped online formative assessment interface. Consequently, the foremost drawbacks and challenges that current and traditional STEM education are facing are meaningfully reflected by the results obtained. Thus, the platform allows PSTs to be more involved in experimental contexts and validates learning performance, and the motivations effect survey provides a sustainable and active learning methodology for their future profession.},
  keywords = {Active Learning,College Faculty,Computer Assisted Testing,Electronic Learning,Evaluation Methods,Feedback (Response),Foreign Countries,Formative Evaluation,No DOI found,Online Courses,Performance,Preservice Teachers,STEM Education,Student Attitudes,Student Motivation,Sustainability}
}

@article{jerrimPISA2015How2018,
  title = {{{PISA}} 2015: How Big Is the `Mode Effect' and What Has Been Done about It?},
  shorttitle = {{{PISA}} 2015},
  author = {Jerrim, John and Micklewright, John and Heine, Jorg-Henrik and Salzer, Christine and McKeown, Caroline},
  year = {2018},
  month = jul,
  journal = {Oxford Review of Education},
  volume = {44},
  number = {4},
  pages = {476--493},
  issn = {0305-4985, 1465-3915},
  doi = {10.1080/03054985.2018.1430025},
  urldate = {2022-12-16},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/NQ57S6G7/jerrimPISA2015How2018.pdf}
}

@article{jessopImplicationsProgrammeAssessment2017,
  title = {The Implications of Programme Assessment Patterns for Student Learning},
  author = {Jessop, Tansy and Tomas, Carmen},
  year = {2017},
  month = aug,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {42},
  number = {6},
  pages = {990--999},
  issn = {0260-2938, 1469-297X},
  doi = {10/gdqbzp},
  urldate = {2021-04-04},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/9LVHBDT6/jessopImplicationsProgrammeAssessment2017.pdf}
}

@article{jhangianiInvestigatingPerceptionsUse2017,
  title = {Investigating the {{Perceptions}}, {{Use}}, and {{Impact}} of {{Open Textbooks}}: {{A}} Survey of {{Post-Secondary Students}} in {{British Columbia}}},
  author = {Jhangiani, Rajiv Sunil and Jhangiani, Surita},
  year = {2017},
  journal = {The International Review of Research in Open and Distributed Learning; Vol 18, No 4 (2017): Special Issue: Outcomes of Openness: Empirical Reports on the Implementation of OER},
  abstract = {Unrelenting increases in the price of college textbooks have prompted the development and adoption of open textbooks, educational resources that are openly licensed and available to students free of cost. Although several studies have investigated U.S. students' perceptions and use of open textbooks, there are no published studies of this kind in Canada. Similarly, although the negative impact of commercial textbook costs on student outcomes is well documented within the United States, it is unknown whether these trends generalize to the Canadian post-secondary context. The present study involves a survey of 320 post-secondary students in British Columbia enrolled in courses using an open textbook during the Spring 2015, Summer 2015, and Fall 2015 semesters. The survey investigates students' textbook purchasing behaviours, including whether, where, and in what format(s) they purchase and access their required textbooks; the negative impact of textbook costs on their course enrolment, persistence, and performance; how they access and use their open textbook, including their format preferences and study habits; and their perceptions of their open textbook, including its quality and what features they like and dislike. The study's strengths and limitations are discussed, along with recommendations for future research.},
  keywords = {Canada,higher education,open educational resources,open textbooks,perceptions,textbooks}
}

@article{jiaoWhatHathCoronavirus2020,
  ids = {jiaoWhatHathCoronavirus2020a},
  title = {What {{Hath}} the {{Coronavirus Brought}} to {{Assessment}}? {{Unprecedented Challenges}} in {{Educational Assessment}} in 2020 and {{Years}} to {{Come}}},
  author = {Jiao, Hong and Lissitz, Robert W.},
  year = {2020},
  journal = {Educational measurement, issues and practice},
  volume = {39},
  number = {3},
  pages = {45--48},
  publisher = {Wiley},
  address = {HOBOKEN},
  issn = {0731-1745},
  doi = {10.1111/emip.12363},
  abstract = {This paper discusses the unprecedented challenges and possible directions in which the field of educational assessment is going after the outbreak of COVID-19. Though the pandemic leads to a lot of pressure related to instruction, learning, and assessment, it also provides opportunities that are likely to require changes to the current theories and practices as well as the assumptions that are no longer justified. It is hoped that the challenges will motivate our field and the instructional experts to work closely together with the learning and instruction process so that assessment will be better integrated and can provide data-driven insights related to the sequence and content of instruction based on the diagnosis of students' strengths and weaknesses from assessment data. We expect that the integration of assessment in learning and instruction will definitely exert significant positive impact on learning outcomes. We believe the field will become aware of the assessment issues that teaching at a distance presents and will come up with innovative solutions to the many emerging problems when the world of instruction and learning undergoes significant changes from social distancing. This paper provides comments, and predictions about what the challenges and directions in educational assessment will be.},
  keywords = {at-home testing,Coronaviruses,COVID-19,distance assessment,Distance Education,Distance learning,Education & Educational Research,Educational Assessment,Educational Change,Educational evaluation,Educational Innovation,Educational tests & measurements,eductional assessment,Impact of COVID19 on Educational Measurement,individualized learning,instruction and assessment,Online instruction,Pandemics,Psychology,Psychology Educational,Social Sciences,Special Section,Student Evaluation,virtual testing},
  file = {/Users/colin.madland/Zotero/storage/GTK28EZR/jiaoWhatHathCoronavirus2020.pdf}
}

@article{jickMixingQualitativeQuantitative1979,
  title = {Mixing {{Qualitative}} and {{Quantitative Methods}}: {{Triangulation}} in {{Action}}.},
  author = {Jick, Todd D.},
  year = {1979},
  month = dec,
  journal = {Administrative Science Quarterly},
  volume = {24},
  number = {4},
  pages = {602--611},
  issn = {00018392},
  abstract = {The article presents an exploration into the methodological triangulation of qualitative and quantitative research in social and organizational research. A broad overview of research methodology is given, outlining the multiple-method strategy of using both sets for separate validation or cross-disciplinary application. It is further asserted that within single research studies both qualitative and quantitative methods can be synthesized to form a more effective experimental design. Suggestions are given in order to assist single-method practitioners to open to the data sets frequently omitted and embraced by their opposites.},
  keywords = {EXPERIMENTAL design,Methodology,ORGANIZATIONAL research,QUALITATIVE research,QUANTITATIVE research,Research,TRIANGULATION}
}

@book{jinFactorAnalysis2020,
  title = {Factor {{Analysis}}},
  author = {Jin, Wang and Kim, Jae-On and Kim, Sanghag},
  year = {2020},
  address = {London},
  file = {/Users/colin.madland/Zotero/storage/K535DQMH/jinFactorAnalysis2020.pdf}
}

@techreport{jiscFutureAssessmentFive2020,
  title = {The Future of Assessment: Five Principles, Five Targets for 2025},
  author = {JISC},
  year = {2020},
  institution = {JISC},
  abstract = {Assessment is crucial to the educational process. Done properly, it drives improvement, shapes learner behaviour and provides accountability to employers and others.},
  file = {/Users/colin.madland/Zotero/storage/QNMKWNMH/jiscFutureAssessmentFive2020.pdf}
}

@article{jitananDevelopmentFriendHeart2021,
  title = {The {{Development}} of "{{Friend}} from {{Heart}}" {{Application Based}} on {{Line System}} to {{Promote Well-Being}} of {{Undergraduate Students}} of {{Faculty}} of {{Education}}, {{Kasetsart University}}},
  author = {Jitanan, Manatee and Somanandana, Varangkana and Jitanan, Sutasinee and Lalitpasan, Usanee and {Kham-in}, Sumalee},
  year = {2021},
  journal = {Higher Education Studies},
  volume = {11},
  number = {2},
  pages = {215--223},
  issn = {ISSN-1925-4741},
  doi = {10/gmbvx5},
  abstract = {Depression and suicide rates among youths tended to increase. From reviews, many applications and online counseling could reduce depression and anxiety to promote well-being of youths and university students effectively. This study was conducted to develop "Friend from heart" application based on LINE system to promote well-being for undergraduate students of faculty of education, Kasetsart University. The research method included the survey of basic data for developing the application and evaluation of the application by specialists. A total of 72 voluntary students were invited to join an online survey. It was found that most of the students (81.94\%) wanted applications that provide physical health information such as exercise, eating healthy food, and health care. However, about 16.66\% of students needed an application that can speak or listen problems with video calls. Then, researchers took the services that students were interested more than 50\% to develop the applications. It worked through the application, consisting of chatbot, physical health, mental health, and appointment with counselor. The index of item-objective congruence was 0.66-1.00 with additional specialists commenting that the application had an interesting design with good structure to help students. For ethical approval, it was obtained from the Kasetsart University Research Ethics Committee.},
  langid = {english},
  keywords = {Computer Mediated Communication,Computer Oriented Programs,Counseling Services,Eating Habits,Exercise,Foreign Countries,Friendship,Health Promotion,Health Services,Help Seeking,Mental Health,Mental Health Programs,Physical Health,Scheduling,Schools of Education,Undergraduate Students,Well Being}
}

@article{johinkeSocialProductionAuthentic2020,
  title = {Social {{Production}} as {{Authentic Assessment}}: {{Wikipedia}}, {{Digital Writing}}, and {{Hope Labour}}},
  author = {Johinke, Rebecca},
  year = {2020},
  month = jan,
  journal = {Studies in Higher Education},
  volume = {45},
  number = {5},
  pages = {1015--1025},
  publisher = {Studies in Higher Education},
  issn = {0307-5079},
  doi = {10.1080/03075079.2020.1750192},
  abstract = {This paper locates digital social production (or unpaid participation on the Web) within a broader discussion about demonstrating job readiness in a wired world. It does not assume that the recruitment marketplace is a level playing field for graduates. Nor does it assume that a single additional graduate attribute, in the form of contributing to Wikipedia, will guarantee employment. However, it makes a case that digital social production as a graduate attribute could be positioned within the body of scholarly literature that is emerging about the merits of using Wikipedia in the higher education classroom. If fewer opportunities exist for work placement and institutionally-organised internships for students taking non-vocational more generalist degrees, then students and educators must be more creative about the kinds of authentic assessment tasks and extra-curriculum activities that are on offer to shape a narrative of employability for graduates. A case is made that, following Deuze (2007), a 'networked reputation' has value in an ethical economy but potentially it could also have value in the graduate recruitment marketplace. Following Kuehn and Corrigan (2013), this paper makes a case that volunteering one's time in an unpaid internship or editing Wikipedia entries online could be categorised as 'hope labour'.},
  keywords = {Career Readiness,Collaborative Writing,College Students,Electronic Publishing,Employment Potential,Encyclopedias,Performance Based Assessment,Student Characteristics,Technology Uses in Education,Web 2.0 Technologies,Web Sites}
}

@book{johnsonCooperativeLearningClassroom1994,
  title = {Cooperative Learning in the Classroom},
  shorttitle = {Cooperative Learning in the Classroom},
  author = {Johnson, David W. and Johnson, Roger and Holubec, Edythe J},
  year = {1994},
  publisher = {{Association for Supervision and Curriculum Development}},
  address = {Alexandria, VA},
  abstract = {This book provides specific strategies for the classroom teacher beginning to use cooperative learning or improving the use of cooprative learning. It explains conceptually what cooperative learning is and what makes it work. Cooperative learning is presented as a technique that helps raise the achievement of all students; helps build positive relationships among students; and gives students experiences necessary for healthy social, psychological, and cognitive development. Cooperative learning replaces the mass-production, competitive organizational structure of most classrooms and schools with a team-based, high-performance organizational structure. In most classrooms, it is recommended that cooperative learning be used 60 to 80 percent of the time. The teacher's role in implementing cooperative learning includes: (1) pre-instructional decisions (selecting instructional materials and objectives, assigning students to groups, arranging the classroom, and assigning roles); (2) taskwork and teamwork (explaining the academic task, structuring positive interdependence, and specifying desired behaviors); (3) executing the cooperative lesson, which includes monitoring students' behavior and providing closure; and (4) post-lesson activities (evaluating the quality and quantity of learning, and analyzing group effectiveness). (Contains 23 references.) (JDD)},
  isbn = {ISBN-0-87120-239-5},
  keywords = {Classroom,Classroom Techniques,Cooperative,Cooperative Learning,Education,EDUCATIONAL,Educational Strategies,Effectiveness,Elementary,Elementary Secondary Education,Higher,Higher Education,Instructional,Instructional Effectiveness,LEARNING,Methods,Role,Secondary,Strategies,Teacher,Teacher Role,Teaching,Teaching Methods,Techniques}
}

@article{johnsonCooperativeLearningImproving2014,
  title = {Cooperative Learning: {{Improving}} University Instruction by Basing Practice on Validated Theory},
  author = {Johnson, David W. and Johnson, Roger and Smith, Karl},
  year = {2014},
  journal = {Journal on Excellence in College Teaching},
  volume = {25},
  pages = {85--118},
  abstract = {Cooperative learning is an example of how theory validated by research may be applied to instructional practice. The major theoretical base for cooperative learning is social interdependence theory. It provides clear definitions of cooperative, competitive, and individualistic learning. Hundreds of research studies have validated its basic propositions and demonstrated that cooperative learning (compared with competitive and individualistic learning) increases students' efforts to achieve, encourages positive relationships with classmates and faculty, and improves psychological health and well being. Operational procedures have been derived from the validated theory to implement cooperative learning in university classes, including those needed to implement formal cooperative learning, informal cooperative learning, and cooperative base groups.}
}

@article{johnsonCooperativeLearningMethods2000,
  title = {Cooperative Learning Methods: {{A}} Meta-Analysis},
  shorttitle = {Cooperative Learning Methods: {{A}} Meta-Analysis},
  author = {Johnson, David W. and Johnson, Roger and Stanne, Mary Beth},
  year = {2000},
  pages = {17},
  abstract = {Cooperative learning is one of the most widespread and fruitful areas of theory, research, and practice in education. Reviews of the research, however, have focused either on the entire literature which includes research conducted in non-educational settings or have included only a partial set of studies that may or may not validly represent the whole literature. There has never been a comprehensive review of the research on the effectiveness in increasing achievement of the methods of cooperative learning used in schools. An extensive search found 164 studies investigating eight cooperative learning methods. The studies yielded 194 independent effect sizes representing academic achievement. All eight cooperative learning methods had a significant positive impact on student achievement. When the impact of cooperative learning was compared with competitive learning, Learning Together (LT) promoted the greatest effect, followed by Academic Controversy (AC), Student-Team-Achievement-Divisions (STAD), Teams-Games-Tournaments (TGT), Group Investigation (GI), Jigsaw, Teams-Assisted-Individualization (TAI), and finally Cooperative Integrated Reading and Composition (CIRC). When the impact of cooperative lessons was compared with individualistic learning, LT promotes the greatest effect, followed by AC, GI, TGT, TAI, STAD, Jigsaw, and CIRC. The consistency of the results and the diversity of the cooperative learning methods provide strong validation for its effectiveness.},
  file = {/Users/colin.madland/Zotero/storage/BQKBCF5F/Coop Learning Meta-Analysis - Johnson2.pdf}
}

@article{johnsonCooperativeLearningReturns1998,
  title = {Cooperative Learning Returns to College},
  shorttitle = {Cooperative Learning Returns to College},
  author = {Johnson, David W. and Johnson, Roger T. and Smith, Karl A.},
  year = {1998},
  journal = {Change},
  volume = {30},
  pages = {26},
  issn = {00091383},
  abstract = {Discusses cooperative learning in colleges. Definition of cooperative learning; Theoretical roots of cooperative learning; Difference among theories of cooperative learning; Information on the internal dynamics that make up cooperative learning; Ways to use cooperative learning.},
  keywords = {Colleges,Education,GROUP,GROUP work in education,in,LEARNING,universities,UNIVERSITIES & colleges,work}
}

@article{johnsonDefinitionMixedMethods2007,
  title = {Toward a Definition of Mixed Methods Research},
  shorttitle = {Toward a Definition of Mixed Methods Research},
  author = {Johnson, R. Burke and Onwuegbuzie, Anthony J. and Turner, Lisa A.},
  year = {2007},
  month = apr,
  journal = {Journal of Mixed Methods Research},
  volume = {1},
  pages = {112--133},
  doi = {10.1177/1558689806298224},
  abstract = {The purpose of this article is to examine how the field of mixed methods currently is being defined. The authors asked many of the current leaders in mixed methods research how they define mixed methods research. The authors provide the leaders' definitions and discuss the content found as they searched for the criteria of demarcation. The authors provide a current answer to the question, What is mixed methods research? They also briefly summarize the recent history of mixed methods and list several issues that need additional work as the field continues to advance. They argue that mixed methods research is one of the three major {\quotesinglbase}{\"A}{\'u}research paradigms{\quotesinglbase}{\"A}{\`u} (quantitative research, qualitative research, and mixed methods research). The authors hope this article will contribute to the ongoing dialogue about how mixed methods research is defined and conceptualized by its practitioners.},
  annotation = {2},
  file = {/Users/colin.madland/Zotero/storage/Q6XP2QVT/johnsonDefinitionMixedMethods2007.pdf}
}

@article{johnsonEducationalPsychologySuccess2009,
  title = {An Educational Psychology Success Story: {{Social}} Interdependence Theory and Cooperative Learning},
  author = {Johnson, David W. and Johnson, Roger T.},
  year = {2009},
  journal = {Educational Researcher},
  volume = {38},
  number = {5},
  pages = {365--379},
  abstract = {The widespread and increasing use of cooperative learning is one of the great success stories of social and educational psychology. Its success largely rests on the relationships among theory, research, and practice. Social interdependence theory provides a foundation on which cooperative learning is built. More than 1,200 research studies have been conducted in the past 11 decades on cooperative, competitive, and individualistic efforts. Findings from these studies have validated, modified, refined, and extended the theory. From the theory, procedures for the teacher{\quotesinglbase}{\"A}{\^o}s role in using formal and informal cooperative learning and cooperative base groups have been operationalized. Those procedures are widely used by educators throughout the world. The applications have resulted in revisions of the theory and the generation of new research.},
  keywords = {collaborationcooperative learninginstructional practices},
  file = {/Users/colin.madland/Zotero/storage/RB69JNX6/johnsonEducationalPsychologySuccess2009.pdf}
}

@book{johnsonEducationalResearchQuantitative2017,
  title = {Educational Research: {{Quantitative}}, Qualitative and Mixed Approaches},
  author = {Johnson, R. Burke and Christensen, Larry},
  year = {2017},
  edition = {6},
  publisher = {Sage Publications},
  address = {Thousand Oaks, CA},
  file = {/Users/colin.madland/Zotero/storage/27LCCNBA/johnsonEducationalResearchQuantitative2017.pdf}
}

@misc{johnsonExamSoftRemoteBar2020,
  title = {{{ExamSoft}}'s Remote Bar Exam Sparks Privacy and Facial Recognition Concerns},
  author = {Johnson, Khari},
  year = {2020},
  month = sep,
  journal = {VentureBeat},
  urldate = {2022-02-16},
  abstract = {To administer bar exams in 20 different states next week, ExamSoft is using facial recognition and collecting the biometric data of legal professionals.},
  langid = {american},
  keywords = {archived},
  annotation = {https://web.archive.org/web/20220214184855/https://venturebeat.com/2020/09/29/examsofts-remote-bar-exam-sparks-privacy-and-facial-recognition-concerns/},
  file = {/Users/colin.madland/Zotero/storage/8FYFQ5D5/examsofts-remote-bar-exam-sparks-privacy-and-facial-recognition-concerns.html;/Users/colin.madland/Zotero/storage/NMDP2HS4/examsofts-remote-bar-exam-sparks-privacy-and-facial-recognition-concerns.html}
}

@article{johnsonImpactGoalResource1989,
  title = {Impact of Goal and Resource Interdependence on Problem-Solving Success},
  shorttitle = {Impact of Goal and Resource Interdependence on Problem-Solving Success},
  author = {Johnson, David W. and Johnson, Roger T. and Stanne, Mary Beth},
  year = {1989},
  journal = {Journal of Social Psychology},
  volume = {129},
  pages = {621},
  issn = {00224545},
  abstract = {Despite the considerable evidence that cooperation promotes higher individual achievement and greater group productivity than do competitive or individualistic situations, there are conditions under which the opposite may be true. The relative impact of positive goal interdependence and positive resource interdependence on individual achievement and group productivity in a computer-assisted problem-solving task was investigated. Forty-four Black American high school seniors and college freshmen, stratified for ability, sex, and urban or rural background, were randomly assigned to conditions. Positive goal interdependence promoted higher individual achievement and group productivity than did no goal interdependence. The combination of positive goal and resource interdependence promoted higher individual achievement and group productivity than did any of the other conditions, indicating that two sources of positive interdependence are more powerful than one. When used in isolation from positive goal interdependence, positive resource interdependence produced the lowest individual achievement and problem-solving success. [ABSTRACT FROM AUTHOR] Copyright of Journal of Social Psychology is the property of Taylor \& Francis Ltd and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
  keywords = {ACHIEVEMENT,AMBITION,College,COLLEGE freshmen,COLLEGE students,freshmen,of,Problem,PROBLEM solving,PRODUCTS,PRODUCTS of subgroups,Solving,STUDENTS,subgroups},
  annotation = {5}
}

@article{johnsonImpactPositiveGoal1991,
  title = {The Impact of Positive Goal and Resource Interdependence on Achievement, Interaction, and Attitudes},
  shorttitle = {The Impact of Positive Goal and Resource Interdependence on Achievement, Interaction, and Attitudes},
  author = {Johnson, David W. and Johnson, Roger T.},
  year = {1991},
  journal = {Journal of General Psychology},
  volume = {118},
  pages = {341},
  issn = {00221309},
  abstract = {Compares the effects of positive goal attitudes and resource interdependence on achievements, interaction and attitudes of undergraduates in the United States. Types of interdependence; Effects of goal interdependence on dependence to group members.},
  keywords = {Attitudes,College,COLLEGE students -- Attitudes,GOAL,GOAL (Psychology),Psychology,States,STUDENTS,United,UNITED States},
  annotation = {4}
}

@article{johnsonKeyEffectiveInservice1980,
  title = {The Key to Effective Inservice: {{Building}} Teacher-Teacher Collaboration},
  shorttitle = {The Key to Effective Inservice: {{Building}} Teacher-Teacher Collaboration},
  author = {Johnson, David W. and Johnson, Roger T.},
  year = {1980},
  month = feb,
  journal = {The Developer},
  pages = {1--16},
  abstract = {To be successful, inservice programs need to utilize cooperative learning activities and create collaborative support groups to assist implementation efforts after the inservice program has ended. Placing teachers in small, cooperative groups to discuss the material being presented in the inservice program provide the structure and mechanisms for them to give each other support and assistance while the material is tried out and integrated into their instructional activities. Cooperative learning experiences promote more positive attitudes toward the knowledge and skills being learned than do competitive and individualistic learning experiences. There is evidence that cooperative learning promotes higher levels of motivation and personal efficacy, and results in more positive peer relationships. The implications of using cooperative learning activities goes beyond the successful implementation of a new set of teaching strategies. As teachers and administrators become more skillful in interacting with each other in collaborative activities, their interactions with students and parents will become more constructive and effective.},
  keywords = {Attitude Change,Group Dynamics,Helping Relationship,Inservice Teacher Education,Interaction,Interpersonal Competence,Peer Relationship,Postsecondary Education,Program Development,Small Group Instruction,Teacher Attitudes,Teacher Behavior,Teacher Motivation,Teaching Methods}
}

@book{johnsonLearningTogetherAlone1999,
  title = {Learning Together and Alone: {{Cooperative}}, Competitive, and Individualistic Learning},
  author = {Johnson, David W. and Johnson, Roger T.},
  year = {1999},
  edition = {5th},
  publisher = {{Allyn and Bacon}},
  address = {Boston}
}

@article{johnsonLearningTogetherAlone2002,
  title = {Learning Together and Alone: {{Overview}} and Meta-Analysis},
  shorttitle = {Learning Together and Alone: {{Overview}} and Meta-Analysis},
  author = {Johnson, David W. and Johnson, Roger T.},
  year = {2002},
  month = jan,
  journal = {Asia Pacific Journal of Education},
  volume = {22},
  pages = {95--105},
  issn = {0218-8791},
  doi = {10.1080/0218879020220110},
  urldate = {2012-08-16},
  annotation = {1}
}

@article{johnsonMakingCooperativeLearning1999,
  title = {Making Cooperative Learning Work},
  shorttitle = {Making Cooperative Learning Work},
  author = {Johnson, David W. and Johnson, Roger T.},
  year = {1999},
  month = mar,
  journal = {Theory Into Practice},
  volume = {38},
  pages = {67--73},
  issn = {0040-5841},
  doi = {10.1080/00405849909543834}
}

@article{johnsonMixedMethodsResearch2004,
  title = {Mixed {{Methods Research}}: {{A Research Paradigm Whose Time Has Come}}},
  shorttitle = {Mixed {{Methods Research}}},
  author = {Johnson, R. Burke and Onwuegbuzie, Anthony J.},
  year = {2004},
  month = oct,
  journal = {Educational Researcher},
  volume = {33},
  number = {7},
  pages = {14--26},
  issn = {0013-189X, 1935-102X},
  doi = {10/cg679w},
  urldate = {2021-05-14},
  abstract = {The purposes of this article are to position mixed methods research ( mixed research is a synonym) as the natural complement to traditional qualitative and quantitative research, to present pragmatism as offering an attractive philosophical partner for mixed methods research, and to provide a framework for designing and conducting mixed methods research. In doing this, we briefly review the paradigm ``wars'' and incompatibility thesis, we show some commonalities between quantitative and qualitative research, we explain the tenets of pragmatism, we explain the fundamental principle of mixed research and how to apply it, we provide specific sets of designs for the two major types of mixed methods research ( mixed-model designs and mixed-method designs), and, finally, we explain mixed methods research as following (recursively) an eight-step process. A key feature of mixed methods research is its methodological pluralism or eclecticism, which frequently results in superior research (compared to monomethod research). Mixed methods research will be successful as more investigators study and help advance its concepts and as they regularly practice it.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/7I8TB992/johnsonMixedMethodsResearch2004.pdf}
}

@article{johnsonOutTheirHeads2021,
  title = {Out of Their Heads: Using Concept Maps to Elicit Teacher-Examiners' Assessment Knowledge},
  shorttitle = {Out of Their Heads},
  author = {Johnson, Martin and Coleman, Victoria},
  year = {2021},
  month = may,
  journal = {International Journal of Research \& Method in Education},
  volume = {44},
  number = {3},
  pages = {257--272},
  issn = {1743-727X, 1743-7288},
  doi = {10/gk33v3},
  urldate = {2021-07-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/5SDPCZL8/johnsonOutTheirHeads2021.pdf}
}

@article{johnsonReliabilityHighstakesTeacher2013,
  title = {On the Reliability of High-Stakes Teacher Assessment},
  author = {Johnson, Sandra},
  year = {2013},
  month = feb,
  journal = {Research Papers in Education},
  volume = {28},
  number = {1},
  pages = {91--105},
  publisher = {Routledge},
  issn = {0267-1522},
  doi = {10/ggsc7r},
  abstract = {For a number of reasons, increasing reliance is being placed on teacher assessment in high-stakes contexts in many countries around the world. Simultaneously, countries that have for some time relied to greater or lesser degrees on teacher assessment for high-stakes purposes are in the process of questioning the validity of that reliance. In principle, teacher assessment has an important role to play in increasing assessment validity by complementing testing to cover subject domains more comprehensively than otherwise would be possible. But what is the evidence regarding the reliability of teacher assessment in high-stakes contexts? The answer is that the evidence is limited and often ambiguous. Research has revealed that teachers can be influenced by a number of construct-irrelevant factors as they work towards their judgements, factors such as gender, socio-economic background, effort and behaviour, that risk biasing their assessments. And when considering construct-relevant achievement evidence teachers are often expected to use verbal or semi-verbal sets of criteria, such as level descriptions, which typically require a degree of subjective interpretation in application and so are themselves a source of unwanted variation in judging standards. Arguably the most effective strategy for addressing these issues is participation in consensus moderation. Yet there have been few attempts to provide evidence of the effectiveness of moderation in practice. The potential value of, and the growing reliance upon, teacher assessment in high-stakes applications demand that evaluation of consensus moderation become a built-in part of the process.},
  file = {/Users/colin.madland/Zotero/storage/LX9H8XZD/johnsonReliabilityHighstakesTeacher2013.pdf}
}

@misc{johnsonWhatCooperativeLearning,
  title = {What Is {{Cooperative Learning}}?},
  author = {Johnson, David W. and Johnson, Roger},
  journal = {Cooperative Learning Institute},
  urldate = {2018-07-03},
  abstract = {The Cooperative Learning Institute is dedicated to increasing the use and study of cooperation in the classroom.},
  howpublished = {http://www.co-operation.org/what-is-cooperative-learning/},
  langid = {american},
  keywords = {cooperative learning},
  file = {/Users/colin.madland/Zotero/storage/AHP8PSTP/what-is-cooperative-learning.html}
}

@article{johnstonAssessmentTeachingLearning1995,
  title = {Assessment of Teaching and Learning in ``Literature-Based'' Classrooms},
  author = {Johnston, Peter and Guice, Sherry and Baker, Kim and Malone, Joan and Michelson, Nancy},
  year = {1995},
  month = jul,
  journal = {Teaching and Teacher Education},
  volume = {11},
  number = {4},
  pages = {359--371},
  issn = {0742051X},
  doi = {10/dtjzn8},
  urldate = {2020-11-01},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/7REJVQT9/Johnston et al_1995_Assessment of teaching and learning in literature-based classrooms.pdf}
}

@article{johnstonInterdisciplinaryCollaborativeResearch2020,
  title = {Interdisciplinary {{Collaborative Research}} for {{Professional Academic Development}} in {{Higher Education}}},
  author = {Johnston, Elizabeth and Burleigh, Cheryl and Wilson, Andrea},
  year = {2020},
  journal = {Higher Learning Research Communications},
  volume = {10},
  number = {1},
  pages = {62--77},
  issn = {EISSN-2157-6254},
  abstract = {Although faculties are more diverse, decentralized, and increasingly isolated in technology-supported modern universities, effective technology use can also foster faculty professional academic development and collegiality. This scoping literature review applied Cooper's systemic review model and a categorical content analysis technique targeting decentralized collaborative research teams in higher education. Findings indicate technology supports formal and informal university and nonuniversity networks, as well as various collaborative research structures; all contributing to professional academic development. Shared attributes of successful collaborative online teams include a sense of social presence, accountability, institutional and team leadership. Collaborative teams are integral to research and allow more faculty members to contribute and benefit from professional academic development through scholarship. Collaborative team research should be investigated further to understand and promote cross-discipline and cultural collaboration potential for research and professional academic development possibilities with special attention given to opportunities for women, online, and adjunct faculty.},
  langid = {english},
  keywords = {Adjunct Faculty,College Faculty,Cooperation,Educational Research,Faculty Development,Interdisciplinary Approach,No DOI found,Research,Technology Uses in Education}
}

@techreport{jointadvisorycommitteePrinciplesFairStudent1993,
  title = {Principles for {{Fair Student Assessment Practices}} for {{Education}} in {{Canada}}},
  author = {Joint Advisory Committee},
  year = {1993},
  address = {Edmonton, AB},
  institution = {University Of Alberta},
  urldate = {2021-06-13},
  file = {/Users/colin.madland/Zotero/storage/FRPEUTMD/jointadvisorycommitteePrinciplesFairStudent1993.pdf}
}

@article{jonassenInstructionalDesignModels1997,
  title = {Instructional Design Models for Well-Structured and {{III-structured}} Problem-Solving Learning Outcomes},
  author = {Jonassen, David},
  year = {1997},
  journal = {Educational Technology Research and Development},
  volume = {45},
  number = {1},
  pages = {65--94},
  abstract = {Although problem solving is regarded by most educators as among the most important learning outcomes, few instructional design prescriptions are available for designing problem-solving instruction and engaging learners. This paper distinguishes between well-structured problems and ill-structured problems. Well-structured problems are constrained problems with convergent solutions that engage the application of a limited number of rules and principles within well-defined parameters. Ill-structured problems possess multiple solutions, solution paths, fewer parameters which are less manipulable, and contain uncertainty about which concepts, rules, and principles are necessary for the solution or how they are organized and which solution is best. For both types of problems, this paper presents models for how learners solve them and models for designing instruction to support problem-solving skill development. The model for solving well-structured problems is based on information processing theories of learning, while the model for solving ill-structured problems relies on an emerging theory of ill-structured problem solving and on constructivist and situated cognition approaches to learning.},
  keywords = {Humanities,Social Sciences and Law}
}

@incollection{jonesIntroductionHigherEducation2014,
  title = {An Introduction to Higher Education in {{Canada}}},
  booktitle = {Higher Education across Nations},
  author = {Jones, Glen A},
  editor = {Joshi, {\relax KM} and Paivandi, Saee},
  year = {2014},
  volume = {1},
  publisher = {B.R. Publishing},
  address = {Delhi},
  abstract = {The Canadian ``system'' of higher education is highly decentralized; responsibility for higher education is delegated to the provinces under Canada's constitutional federation. While the federal government has played a major role in supporting university research and student funding, the story of Canadian higher education is the tale of ten quite different provincial systems, with different institutional structures and regulatory arrangements. However it is also the story of a highly accessible public system since Canada boasts among the highest participation rates in the world, and has one of the most educated populations. This paper will analyze the success (and failings) of this highly decentralized, largely uncoordinated network of provincial systems, and review current trends and issues.},
  file = {/Users/colin.madland/Zotero/storage/9YFMFKUF/jonesIntroductionHigherEducation2014.pdf}
}

@article{jonesLearningStylesOnline2018,
  title = {Learning {{Styles}}, {{Online Courses}}, {{Gender}}, and {{Academic Achievement}} of {{Hispanic Students}} in {{Higher Education}}},
  author = {Jones, Irma S. and Blankenship, Dianna},
  year = {2018},
  journal = {Research in Higher Education Journal},
  volume = {35},
  issn = {EISSN-1941-3432},
  abstract = {This study aims at identifying learning styles of two groups of online students enrolled inLegal Studies and Corporate Training courses and comparing learning styles and academicachievements in those courses. The learning styles questionnaire was adapted from a learningstyles questionnaire in College Study Strategies (Laskey \& Gibson, pp. 52-53, 1997) and is acontinuation of previous research by the authors. In the fall 2017, the authors administered theadapted questionnaire to undergraduate corporate training and legal studies online students in aSouthern Hispanic serving institution. The questionnaire allowed students to identify whethertheir preferred method of learning was field dependent or field independent. Results of thelearning styles questionnaires were compared with academic achievement. A discussion of fielddependent and independent learning styles for Hispanic online learners will be presented. Recentresearch and the evidentiary rationale for attempting to predict academic achievement fromspecific learning styles will be explored.},
  langid = {english},
  keywords = {Academic Achievement,Cognitive Style,Gender Differences,Hispanic American Students,Legal Education (Professions),No DOI found,Online Courses,Undergraduate Students}
}

@article{jonesMakingCooperativeLearning2008,
  title = {Making {{Cooperative Learning Work}} in the {{College Classroom}}: {{An Application}} of the "{{Five Pillars}}" of {{Cooperative Learning}} to {{Post-Secondary Instruction}}},
  author = {Jones, Karrie A. and Jones, Jennifer L.},
  year = {2008},
  journal = {Journal of Effective Teaching},
  volume = {8},
  pages = {61--76},
  issn = {1935-7869},
  abstract = {Cooperative learning is viable yet generally underutilized method of instruction at the college level (Paulsen and Faust, 2008). This paper highlights the work of teacher educator Dr. Paul J. Vermette in his implementation of cooperative learning based practices in a graduate level Multicultural education course. In analyzing the "Five Pillars" of cooperative learning as outlined by Johnson, Johnson \& Smith (1991), this article will highlight Vermette's implementation of cooperative learning structures to this theoretical framework. Through narratives of Vermette's actual teaching, the authors will provide suggestions for implementing cooperative learning in the college classroom.},
  keywords = {Academic Achievement,Accountability,Classroom Environment,Classroom Techniques,College Environment,Cooperative Learning,Curriculum Implementation,Educational Practices,Educational Strategies,Group Dynamics,Instructional Effectiveness,Interaction,Interpersonal Competence,Multicultural Education,New York,Postsecondary Education,Preservice Teachers,Teacher Education Programs,Teacher Educators,Teaching Methods,Teaching Styles}
}

@article{jonesStudentPerceptionsOnline2017,
  title = {Student {{Perceptions}} of {{Online Courses}}},
  author = {Jones, Irma S. and Blankenship, Dianna},
  year = {2017},
  journal = {Research in Higher Education Journal},
  volume = {32},
  issn = {EISSN-1941-3432},
  abstract = {Presently, at the post-secondary level, digital or online education is offered in addition to traditional face-to-face courses and the number of online course offerings is rapidly growing. The "Occupational Outlook Handbook" reveals that employment in" computer and information technology" occupations is projected to grow 12 percent between the years 2014 to 2024, faster than the average for all other occupations. This is directly related to an emphasis on cloud computing, the collection, storage and connectivity of data to the Internet and the continued demand for mobile computing (Online Learning Consortium, 2015). This survey will describe online student perceptions and their preferences with regard to taking online courses and their concerns with these online courses.},
  langid = {english},
  keywords = {Computer Science Education,Demand Occupations,Intermode Differences,Learning Experience,National Surveys,No DOI found,Online Courses,Postsecondary Education,Preferences,Student Attitudes,Teaching Methods,Undergraduate Students}
}

@article{jonesStudentWellbeingAssessment2021,
  ids = {jonesStudentWellbeingAssessment2021a},
  title = {Student Wellbeing and Assessment in Higher Education: The Balancing Act},
  shorttitle = {Student Wellbeing and Assessment in Higher Education},
  author = {Jones, Emma and Priestley, Michael and Brewster, Liz and Wilbraham, Susan J. and Hughes, Gareth and Spanner, Leigh},
  year = {2021},
  month = apr,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {46},
  number = {3},
  pages = {438--450},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0260-2938, 1469-297X},
  doi = {10/gk36pd},
  urldate = {2021-07-04},
  langid = {english},
  keywords = {Assessment,Collaboration,College students,Education & Educational Research,Educational evaluation,Feedback,Higher education,Learning,mental health,Social Sciences,wellbeing,whole university approach},
  file = {/Users/colin.madland/Zotero/storage/7ZWS2RHM/jonesStudentWellbeingAssessment2021.pdf;/Users/colin.madland/Zotero/storage/SC7U5SBE/jonesStudentWellbeingAssessment2021a.epub}
}

@book{joosten-tenbrinkeTechnologyEnhancedAssessment2017,
  title = {Technology {{Enhanced Assessment}} 19th {{International Conference}}, {{TEA}} 2016, {{Tallinn}}, {{Estonia}}, {{October}} 5-6, 2016, {{Revised Selected Papers}}},
  author = {{Joosten-ten Brinke}, {\relax Desir{\'e}e}. and Laanpere, {\relax Mart}.},
  year = {2017},
  series = {Communications in {{Computer}} and {{Information Science}}, 653},
  edition = {1st ed. 2017.},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-57744-9},
  abstract = {This book constitutes the proceedings of the 19th International Conference on Technology Enhanced Assessment, TEA 2016, held in Tallinn, Estonia, in October 2016. The 16 full papers presented were carefully selected from 38 submissions. They are centered around topics like measurement of higher order skills; collaborative problem solving or presentation skills; the development of guidelines for authentication control; the role of self-assessment.},
  isbn = {3-319-57744-1},
  keywords = {Application software,Computer Applications,Computers and Education,Education-Data processing,Educational technology,Educational Technology,Electronic books,Information Systems Applications (incl. Internet)},
  file = {/Users/colin.madland/Zotero/storage/WXH5WIAW/joosten-tenbrinkeTechnologyEnhancedAssessment2017.pdf}
}

@article{joppCaseStudyTechnology2020,
  ids = {joppCaseStudyTechnology2020a},
  title = {A Case Study of a Technology Enhanced Learning Initiative That Supports Authentic Assessment},
  author = {Jopp, Ryan},
  year = {2020},
  journal = {Teaching in Higher Education},
  volume = {25},
  number = {8},
  pages = {942--958},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {1356-2517},
  doi = {10.1080/13562517.2019.1613637},
  abstract = {The promotion and adoption of Authentic Assessment (AA) in Higher Education has expanded dramatically over the past decade, as universities try to engage with increasingly preoccupied student cohorts, whilst simultaneously meeting the employability needs of industry and the academic requirements of regulatory authorities. This article focuses on the necessity, challenge and opportunity, to develop a shared understanding of AA by exploring its value and intent, in terms of student learning outcomes and employability skills. A case-study is presented which demonstrates the challenge of designing, developing and implementing AA, in the form of a digital walking tour assessment. Evidence from this study shows that AA has the potential to increase student engagement, deepen levels of understanding, increase creativity, and reduce plagiarism. Given growing pressure to demonstrate links to industry and so-called employability skills, effective implementation of AA presents significant challenges for those in the Higher Education sector.},
  keywords = {Australia,Authentic assessment,Education & Educational Research,Education Work Relationship,Educational evaluation,Educational technology,employability skills,Employment,Employment Potential,Foreign Countries,Higher education,Industry,industry engagement,Learner Engagement,learning outcomes,Outcomes of Education,Performance Based Assessment,Social Sciences,student engagement,Student Evaluation,Student participation,technology enhanced learning,Technology Uses in Education,Undergraduate Students},
  file = {/Users/colin.madland/Zotero/storage/DMT6Y3RM/joppCaseStudyTechnology2020.pdf}
}

@article{joppChooseYourOwn2020,
  title = {Choose Your Own Assessment - Assessment Choice for Students in Online Higher Education},
  author = {Jopp, Ryan and Cohen, Jay},
  year = {2020},
  journal = {Teaching in Higher Education},
  number = {Journal Article},
  pages = {1--18},
  publisher = {ROUTLEDGE JOURNALS, TAYLOR \& FRANCIS LTD},
  address = {ABINGDON},
  issn = {1356-2517},
  doi = {10/gmb8hn},
  abstract = {On the back of recent assessment choice projects this study seeks to reimagine higher education assessment as a means of shifting the 'locus of control' from the teacher to the student. Central to this shift is the belief that a flexible assessment approach will promote self-regulation in learners, increased self-efficacy and, subsequently academic engagement and performance. This paper details the design, setup and configuration of assessment choice for students studying an online business subject. Details are provided outlining the assessment choices made by students and the impact on student satisfaction and the student success rates. Overall students demonstrated receptiveness towards the provision of assessment choice. This was evidenced by positive feedback from students, as well as improved subject satisfaction. While further research is required, the findings presented here provide a case for greater assessment flexibility and the broader adoption of an assessment choice approach in higher education.},
  keywords = {Education & Educational Research,Social Sciences}
}

@book{jordanJordanWeller20172017,
  title = {Jordan, {{K}}. \& {{Weller}}, {{M}}. (2017) {{Openness}} and {{Education}}: {{A}} Beginners' Guide.},
  author = {Jordan, Katy and Weller, Martin},
  year = {2017},
  publisher = {Global OER Graduate Network}
}

@inbook{jordanSAGEEncyclopediaAction2019,
  title = {The {{SAGE Encyclopedia}} of {{Action Research}}},
  author = {Jordan, Steve},
  year = {2019},
  publisher = {SAGE Publications Ltd},
  address = {Thousand Oaks,},
  doi = {10.4135/9781446294406},
  collaborator = {{pages 437-439}}
}

@article{jormTimeUniversityEducators2019,
  title = {Time for {{University Educators}} to {{Embrace Student Videography}}},
  author = {Jorm, Christine and Roberts, Chris and Gordon, Christopher and Nisbet, Gillian and Roper, Lucinda},
  year = {2019},
  month = jan,
  journal = {Cambridge Journal of Education},
  volume = {49},
  number = {6},
  pages = {673--693},
  publisher = {Cambridge Journal of Education},
  issn = {0305-764X},
  doi = {10.1080/0305764X.2019.1590528},
  abstract = {The authors provide an interdisciplinary investigation of student videography for assessment in higher education. Video is becoming a dominant communication modality in our world; school students are taught to create and critique it and educators employ it on-line. Yet the opportunity to include appropriate video-based assessments that capture integrated graduate attributes has been largely missed in higher education. The authors reflect on a health professional student case study which illustrates how video enables students to powerfully demonstrate achievement against learning outcomes: they used filmic techniques to display empathy, patient centred collaboration and interprofessional communication. They also reflect on the barriers to video-based assessment raised by academics. Finally, they call upon leaders in higher education to recognise the utility of multi-media approaches to assessment of complex but critical graduate skills such as communication, digital literacy and interdisciplinarity, in addition to demonstrating the application of disciplinary knowledge to relevant and authentic problems.},
  keywords = {Affordances,College Faculty,College Graduates,Communication Skills,Cooperative Learning,Empathy,Evaluation Methods,Film Production,Interprofessional Relationship,Medical Education,Outcomes of Education,Physician Patient Relationship,Skill Development,Teacher Attitudes,Teamwork,Technological Literacy,Video Technology},
  file = {/Users/colin.madland/Zotero/storage/659ZXQQN/jormTimeUniversityEducators2019.pdf}
}

@incollection{jorredestjorreSharingAchievementDigital2020,
  title = {Sharing {{Achievement Through Digital Credentials}}: {{Are Universities Ready}} for the {{Transparency Afforded}} by a {{Digital World}}?},
  shorttitle = {Sharing {{Achievement Through Digital Credentials}}},
  booktitle = {Re-Imagining {{University Assessment}} in a {{Digital World}}},
  author = {{Jorre de St Jorre}, Trina},
  editor = {Bearman, Margaret and Dawson, Phillip and Ajjawi, Rola and Tai, Joanna and Boud, David},
  year = {2020},
  volume = {7},
  pages = {277--288},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-41956-1_19},
  urldate = {2022-03-19},
  isbn = {978-3-030-41955-4 978-3-030-41956-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/62JG2YWY/JorreDeStJorre2020_Chapter_SharingAchievementThroughDigit.pdf}
}

@article{joshiOnlineTeachingAmidst2020,
  title = {Online {{Teaching}} amidst {{COVID-19}} in {{India}}: {{An Outlook}}},
  author = {Joshi, Amit and Vinay, Muddu and Bhaskar, Preeti},
  year = {2020},
  journal = {Asian Journal of Distance Education},
  volume = {15},
  number = {2},
  pages = {105--111},
  issn = {ISSN-1347-9008},
  abstract = {The lockdown imposed in India on 25 March 2020 resulted in the indefinite closure of education institutes all across the country. The government and educational institutes were quick to respond, they shifted teaching from offline to online mode. This article aims to identify the approaches made by the higher education institutions for continues imparting of education amidst lockdown. The article also identifies the challenges faced by teachers in online teaching from their homes. The study is descriptive and analytical in nature and data has been collected from secondary sources like reports, news articles, blogs, interview videos, magazines, social media, and journals to achieve the objective of the paper. Based on the secondary sources' information, the article also advocates the learning curve for the future to deal with any such crisis impact on the education system of India. The findings revealed that higher education institutions (HEIs) have taken many initiatives in this pandemic situation for imparting education. But these initiatives have not been very successful from the teacher's perspective. Teachers faced may issue in online teaching such as lack of technical facilities, family interruption, lack of training, lack of clarity \& direction, lack of technical knowledge. The learning curve of the article facilitates the HEIs to help them to execute the online educative in an effective manner.},
  langid = {english},
  keywords = {Access to Computers,Barriers,College Faculty,COVID-19,Distance Education,Educational Practices,Electronic Learning,Family Influence,Foreign Countries,Higher Education,Internet,No DOI found,Online Courses,Pandemics,School Closing,Teacher Attitudes,Teaching Methods,Technological Literacy}
}

@book{joughinAssessmentLearningJudgement2009,
  title = {Assessment, {{Learning}} and {{Judgement}} in {{Higher Education}}},
  editor = {Joughin, Gordon},
  year = {2009},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-1-4020-8905-3},
  urldate = {2021-04-25},
  isbn = {978-1-4020-8904-6 978-1-4020-8905-3},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/H394369U/joughinAssessmentLearningJudgement2009a.pdf}
}

@incollection{joughinAssessmentLearningJudgement2009a,
  title = {Assessment, {{Learning}} and {{Judgement}} in {{Higher Education}}: {{A Critical Review}}},
  shorttitle = {Assessment, {{Learning}} and {{Judgement}} in {{Higher Education}}},
  booktitle = {Assessment, {{Learning}} and {{Judgement}} in {{Higher Education}}},
  author = {Joughin, Gordon},
  editor = {Joughin, Gordon},
  year = {2009},
  pages = {1--15},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-1-4020-8905-3_2},
  urldate = {2021-04-25},
  isbn = {978-1-4020-8904-6 978-1-4020-8905-3},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/M9UIPYZN/joughinAssessmentLearningJudgement2009.pdf}
}

@article{joughinImprovingAssessmentTasks2017,
  title = {Improving Assessment Tasks through Addressing Our Unconscious Limits to Change},
  author = {Joughin, Gordon and Dawson, Phillip and Boud, David},
  year = {2017},
  month = nov,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {42},
  number = {8},
  pages = {1221--1232},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2016.1257689},
  urldate = {2022-11-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/Y4J7YLVG/joughinImprovingAssessmentTasks2017.pdf}
}

@article{JournalComputerAssisted1985,
  title = {Journal of Computer Assisted Learning ({{Online}})},
  year = {1985},
  journal = {Journal of computer assisted learning (Online)},
  publisher = {Blackwell Science},
  address = {Oxford, England},
  issn = {1365-2729},
  keywords = {Computer-assisted instruction,Computer-Assisted Instruction,Electronic journals,Enseignement assiste par ordinateur,Periodicals}
}

@article{JournalResearchTechnology2001,
  title = {Journal of Research on Technology in Education ({{Online}})},
  year = {2001},
  journal = {Journal of research on technology in education (Online)},
  publisher = {International Society for Technology in Education},
  address = {Eugene, OR},
  issn = {1945-0818},
  keywords = {Computer-assisted instruction,Distance education,Education,Education - General,Educational technology,Electronic journals,Enseignement a distance,Enseignement assiste par ordinateur,Formation par Internet,Internet in education,Periodicals,Recherche en education,Technologie educative}
}

@article{Jzefowicz_2002,
  title = {The Quality of in House Medical School Examinations},
  author = {J{\'o}zefowicz, Ralph F. and Koeppen, Bruce M. and Sm, Case and Galbraith, Robert M. and Swanson, David B. and Glew, Robert H.},
  year = {2002},
  journal = {Academic Medicine},
  doi = {10/cd3b34},
  abstract = {ABSTRACTPurposeMost medical schools test their students throughout the curriculum using in-house examinations written by the faculty who teach the courses. The authors assessed the quality of in-house examinations used in three U.S. medical schools.MethodIn 1998, nine basic science examinations from},
  mag_id = {1968331228},
  pmcid = {null},
  pmid = {11841981}
}

@article{julienStudentsTransitionFace2020,
  title = {Students' {{Transition}} from {{Face}} to {{Face Learning}} to {{Online Learning}} at {{Higher Education}}: {{A Case Study}} in {{Trinidad}} and {{Tobago}}},
  author = {Julien, Gabriel and Dookwah, Rhonda},
  year = {2020},
  journal = {Educational Research and Reviews},
  volume = {15},
  number = {8},
  pages = {487--494},
  issn = {EISSN-1990-3839},
  abstract = {This action research highlights the experiences of undergraduate students as they transit from face to face learning to online learning at a higher education institution in Trinidad and Tobago. A review of the existing literature within the local context indicated that there exists a dearth of information about the experiences of these students. It is imperative that policy makers pay more attention and consideration to the voices of these students especially when they are formulating policies that pertain to online learning. Consequently, a case study was conducted to carefully ascertain students' experiences during this transition. Fifteen undergraduates participated in this study. Informal structured interviews and semi-structured questionnaires were employed. Data were analyzed with the use of three major thematic headings: Online learning (ONL) is a possible instructional option, Face to Face learning (F2F) is essential for Mathematics and Face to Face learning (F2F) is necessary for human interaction. Recommendations for the use of more ONL education were offered.},
  langid = {english},
  keywords = {Conventional Instruction,Educational Policy,Electronic Learning,Foreign Countries,Mathematics Instruction,No DOI found,Online Courses,Peer Relationship,Student Adjustment,Student Attitudes,Student Experience,Undergraduate Students}
}

@article{jungHigherEducationFaculty2017,
  title = {Higher {{Education Faculty Perceptions}} of {{Open Textbook Adoption}}},
  author = {Jung, Eulho and Bauer, Christine and Heaps, Allan},
  year = {2017},
  month = jun,
  journal = {The International Review of Research in Open and Distributed Learning},
  volume = {18},
  number = {4},
  issn = {1492-3831},
  urldate = {2018-07-07},
  copyright = {Copyright (c) 2017 Eulho Jung, Christine Bauer, Allan Heaps},
  langid = {english},
  keywords = {OER,open textbooks,OpenStax,perception of open textbooks},
  file = {/Users/colin.madland/Zotero/storage/YFZCE9V9/jungHigherEducationFaculty2017.pdf;/Users/colin.madland/Zotero/storage/7VKT48XN/4218.html}
}

@article{jungRegularizedCommonFactor2008,
  title = {Regularized Common Factor Analysis},
  author = {Jung, Sunho and Takane, Yoshio},
  year = {2008},
  journal = {New trends in psychometrics},
  pages = {141--149},
  publisher = {University Academic Press Tokyo},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/CP2FS5VU/jungRegularizedCommonFactor2008.pdf}
}

@article{jurado-navasScrumMethodologyHigher2017,
  title = {Scrum {{Methodology}} in {{Higher Education}}: {{Innovation}} in {{Teaching}}, {{Learning}} and {{Assessment}}},
  author = {{Jurado-Navas}, Antonio and {Munoz-Luna}, Rosa},
  year = {2017},
  journal = {International Journal of Higher Education},
  volume = {6},
  number = {6},
  pages = {1--18},
  issn = {ISSN-1927-6044},
  doi = {10/gmbv4b},
  abstract = {The present paper aims to detail the experience developed in a classroom of English Studies from the Spanish University of M{\'a}laga, where an alternative project-based learning methodology has been implemented. Such methodology is inspired by scrum sessions widely extended in technological companies where staff members work in teams and are assigned tasks within long-termed projects. Students were initially reluctant and afraid to work in teams but, as the experience advanced, their point of view was changing. Thus they positively stated that this methodology encouraged themselves to participate and to change ideas, with a deeper feeling of empathy, self-organisation and self-knowledge. At the end, most of the students declared they would participate again in a similar activity. Hence, considering the opinions from the students (and also from the teachers), and after observing the whole experience and analyzing the documents generated in an electronic portfolio, we think this method can be considered as a good proposal to accomplish a teaching-learning process of high quality at universities for three main reasons: first, it improves the capacity of using the knowledge in a disciplined, critical and creative way; second, it promotes the coexistence in heterogeneous human groups; and third, it develops the capacity of thinking, living and acting with complete autonomy.},
  langid = {english},
  keywords = {Active Learning,Attitude Change,Capacity Building,Case Studies,Constructivism (Learning),Cooperative Learning,Electronic Publishing,Foreign Countries,Group Experience,Heterogeneous Grouping,Higher Education,Humanities Instruction,Instructional Innovation,Interviews,Learner Engagement,Learning Processes,Observation,Personal Autonomy,Portfolios (Background Materials),Qualitative Research,Questionnaires,Self Efficacy,Self Management,Skill Development,Student Attitudes,Student Projects,Teaching Methods,Teamwork,Thinking Skills,Time Management,Undergraduate Students}
}

@book{kainzHegelPhenomenology1976,
  title = {Hegel's {{Phenomenology}}.},
  author = {Kainz, Howard P.},
  year = {1976},
  publisher = {University of Alabama Press},
  address = {University, Ala.},
  isbn = {0-8173-6617-2 978-0-8173-6617-9},
  langid = {english}
}

@article{kandampullyDevelopingPeopletechnologyHybrids2016,
  title = {Developing a People-Technology Hybrids Model to Unleash Innovation and Creativity: {{The}} New Hospitality Frontier},
  author = {Kandampully, Jay and Bilgihan, Anil and Zhang, Tingting (Christina},
  year = {2016},
  journal = {Journal of Hospitality and Tourism Management},
  volume = {29},
  pages = {154--164},
  issn = {1447-6770},
  abstract = {The purpose of this study is to propose a theoretical framework to harness creativity and innovation through people and technology. This study is grounded based on an extensive synthesis of previous scientific research and industry practices. It undertakes a detailed review of the literature to derive a framework and detail research and practical guidelines for both scholars and practitioners in the hospitality discipline. Advancements in computer and communications technologies is creating many unanticipated changes in how employees and customers interact, how service work is done, and how hospitality businesses succeed. This study investigates such changes. It also extends the present body of knowledge in the hospitality management by providing numerous directions for hospitality executives and researchers to understand how the combined resources of people (employees and customers) and technology will act as key sources of creative innovation and the firm's subsequent market leadership.}
}

@article{kangHeterogeneityLearnersBehavioral2020,
  title = {Heterogeneity of {{Learners}}' {{Behavioral Patterns}} of {{Watching Videos}} and {{Completing Assessments}} in {{Massive Open Online Courses}} ({{MOOCs}}): {{A Latent Class Analysis}}},
  author = {Kang, In Gu},
  year = {2020},
  journal = {International Review of Research in Open and Distributed Learning},
  volume = {21},
  number = {4},
  pages = {221--237},
  issn = {EISSN-1492-3831},
  abstract = {Massive open online courses (MOOCs) have been touted as an effective way to make higher education accessible for free or for only a small fee, thus addressing the problem of unequal access and providing new opportunities to young people in middle and low income groups. However, many critiques of MOOCs have indicated that low completion rates are a major concern. Using a latent class analysis (LCA), a more advanced methodology to identify latent subgroups, this study examined the heterogeneity of learners' behavioral patterns in a MOOC, categorized them into distinctive subgroups, and ultimately determined the optimal number of latent subgroups in a MOOC. The five subgroups identified in this study were: "completing" (6.6\%); "disengaging" (4.8\%); "auditing" (4.6\%); "sampling" (21.1\%); and "enrolling" (62.8\%). Results indicated this was the optimal number of subgroups. Given the characteristics of the three at-risk subgroups (disengaging, sampling, and enrolling), tailored instructional strategies and interventions to improve behavioral engagement are discussed.},
  langid = {english},
  keywords = {Academic Persistence,At Risk Students,Dropouts,Educational Technology,Enrollment,Higher Education,Intervention,Large Group Instruction,Learner Engagement,No DOI found,Online Courses,Student Behavior,Student Characteristics,Teaching Methods,Technology Uses in Education,Video Technology}
}

@article{kangLearningTheoryClassroom2021,
  title = {Learning {{Theory}}, {{Classroom Assessment}}, and {{Equity}}},
  author = {Kang, Hosun and Furtak, Erin M.},
  year = {2021},
  month = mar,
  journal = {Educational Measurement: Issues and Practice},
  pages = {emip.12423},
  issn = {0731-1745, 1745-3992},
  doi = {10/gjn2zn},
  urldate = {2021-04-08},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/BZNQGLIF/kangLearningTheoryClassroom2021.pdf}
}

@article{kanuDecolonizingIndigenousEducation2005,
  title = {Decolonizing {{Indigenous Education}}: {{Beyond Culturalism}}: {{Toward Post-cultural}} Strategies},
  author = {Kanu, Yatta},
  year = {2005},
  journal = {Canadian and International Education},
  volume = {34},
  number = {2},
  pages = {1},
  issn = {0315-1409},
  keywords = {Curricula,Education,Effectiveness,Integrated approach,Native culture,Native North Americans,Teaching methods}
}

@article{kanukaCognitivePresenceOnline2004,
  title = {Cognitive Presence in Online Learning},
  author = {Kanuka, Heather and Garrison, D.Randy},
  year = {2004},
  month = mar,
  journal = {Journal of Computing in Higher Education},
  volume = {15},
  number = {2},
  pages = {21--39},
  issn = {1042-1726},
  doi = {10.1007/BF02940928},
  langid = {english},
  keywords = {community of inquiry,critical thinking,higher levels of learning,methodological constructs,Online learning}
}

@article{kanukaExplorationFacilitatingHigher2005,
  title = {An Exploration into Facilitating Higher Levels of Learning in a Text-Based Internet Learning Environment Using Diverse Instructional Strategies},
  shorttitle = {An Exploration into Facilitating Higher Levels of Learning in a Text-Based Internet Learning Environment Using Diverse Instructional Strategies},
  author = {Kanuka, Heather},
  year = {2005},
  month = mar,
  journal = {Journal of Computer-Mediated Communication},
  volume = {10},
  pages = {Article 8},
  abstract = {The purpose of this action-research study was to explore how well various instructional strategies translate to a text-based Internet learning environment and facilitate higher levels of learning. The participants were 19 adult learners enrolled in an online degree program at a Western Canadian research university. The results of the study provide support for the position that text-based Internet communication technologies can facilitate effective learning environments through the use of certain instructional strategies, resulting in the ability to facilitate higher levels of learning. The outcomes may be useful to those involved in the design and/or instruction of online learning in postsecondary settings.},
  annotation = {3}
}

@article{kanukaGuidingPrinciplesFacilitating2002,
  title = {Guiding Principles for Facilitating Higher Levels of Web-Based Distance Teaching and Learning in Post-Secondary Settings},
  shorttitle = {Guiding Principles for Facilitating Higher Levels of Web-Based Distance Teaching and Learning in Post-Secondary Settings},
  author = {Kanuka, Heather},
  year = {2002},
  journal = {Distance Education},
  volume = {23},
  pages = {163--182},
  issn = {01587919},
  doi = {10.1080/0158791022000009187},
  abstract = {The purpose of this study was to develop guiding principles to encourage higher levels of teaching and learning in Web-based distance education. The research framework used Zetterberg's (1962) model for change. Data from semi-structured interviews with university instructors who had experience in teaching Web-based distance education courses, a focus group interview with educational technologists, a review of related literature, and my own reflective journal, provided insights for the development of teaching and learning principles. A validation process was then conducted from experts and scholars in the field through a consensus survey. The outcome was the development of a model with nine principles that facilitate higher levels of teaching and learning in Web-based distance education. [ABSTRACT FROM AUTHOR] Copyright of Distance Education is the property of Routledge and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
  keywords = {Distance,distance education,Education,Teaching},
  annotation = {2}
}

@article{kanukaInfluenceInstructionalMethods2007,
  title = {The Influence of Instructional Methods on the Quality of Online Discussion},
  shorttitle = {The Influence of Instructional Methods on the Quality of Online Discussion},
  author = {Kanuka, Heather and Rourke, Liam and Laflamme, Elaine},
  year = {2007},
  journal = {British Journal of Educational Technology},
  volume = {38},
  pages = {260--271},
  issn = {1467-8535},
  doi = {10.1111/j.1467-8535.2006.00620.x},
  abstract = {In this case study, we examined the influence of five groups of communication activities on the quality of students' contributions to online discussion. The activities were the nominal group technique, debate, invited expert, WebQuest and reflective deliberation. Quality of discussion was operationalised as cognitive presence, a construct developed to investigate the role of critical discourse in higher, distance education contexts. Using the quantitative content analysis technique, the postings of 19 students in an undergraduate university course were assigned to one of the four categories of cognitive presence. Across the five activities, the proportion and number of contributions categorised in the highest phases of cognitive presence was low (20.21\%), but was highest during the Webquest and debate activities. There are three advantageous qualities of these two activities, we argue: * 1They were well structured. * 2They provided clearly defined roles and responsibilities for the students. * 3They provoked the students to explicitly confront others' opinions.},
  annotation = {2}
}

@article{kanukaInteractionOnlineDistance2011,
  title = {Interaction and the Online Distance Classroom: {{Do}} Instructional Methods Effect the Quality of Interaction?},
  author = {Kanuka, Heather},
  year = {2011},
  month = dec,
  journal = {Journal of Computing in Higher Education},
  volume = {23},
  number = {2},
  pages = {143--156},
  issn = {1867-1233},
  doi = {10.1007/s12528-011-9049-4},
  abstract = {In this special issue, I bring together two studies to provide a comprehensive overview on diverse and interactive instructional methods aimed to facilitate higher levels of learning. One study explored the effects of group interaction using different instructional strategies focusing on the learning process using the Community of Inquiry framework. The other study investigated the effects of group interaction using different instructional strategies focusing on learning products using the SOLO taxonomy. The outcomes of both studies were consistent in revealing that certain kinds of instructional strategies have more effective interactions, resulting in facilitating higher levels of learning.}
}

@article{kanukaUsingConstructivismTechnologymediated1999,
  title = {Using Constructivism in Technology-Mediated Learning: {{Constructing}} Order out of the Chaos in the Literature},
  shorttitle = {Using Constructivism in Technology-Mediated Learning: {{Constructing}} Order out of the Chaos in the Literature},
  author = {Kanuka, Heather and Anderson, Terry},
  year = {1999},
  journal = {Radical Pedagogy},
  volume = {1},
  annotation = {2}
}

@article{karadagAssessmentEvaluationMega2020,
  title = {Assessment and {{Evaluation}} in {{Mega Universities}}},
  author = {Karadag, Nejdet and {\"O}zg{\"u}r, Aydin Ziya},
  year = {2020},
  month = oct,
  journal = {Turkish Online Journal of Educational Technology - TOJET},
  volume = {19},
  number = {4},
  pages = {35--49},
  publisher = {Turkish Online Journal of Educational Technology - TOJET},
  issn = {2146-7242},
  abstract = {The study examines assessment and evaluation procedures in mega universities. Within the scope of the study, the literature focusing on mega universities offering open and distance education and their assessment and evaluation systems were examined first. Later, the results of the questionnaire administered in the study-specific mega universities to support the findings obtained from the literature were presented. The results of the study showed that assessment tools used by mega universities to determine the achievement levels of learners considerably vary and the most frequently applied assessment tool was found to be multiple-choice tests. Finally, the study also revealed that the number of the learners and raters was the main determinant factor affecting the choice of assessment tools used in these institutions.},
  keywords = {Distance Education,Educational Assessment,Evaluation Methods,Institutional Characteristics,Institutional Evaluation,No DOI found,Open Education,Open Universities}
}

@article{karademirChallengesHigherEducation2020,
  title = {Challenges of {{Higher Education Institutions}} against {{COVID-19}}: {{The Case}} of {{Turkey}}},
  author = {Karademir, Abdulhamit and Yaman, Fatih and Saat{\c c}ioglu, {\"O}zkan},
  year = {2020},
  month = jan,
  journal = {Journal of Pedagogical Research},
  volume = {4},
  number = {4},
  pages = {453--474},
  publisher = {Journal of Pedagogical Research},
  issn = {2602-3717},
  doi = {10.33902/JPR.2020063574},
  abstract = {The global COVID-19 outbreak has caused an anxious situation in every part of society and forced many countries to implement distance education programs without even knowing the fundamental components involved in the processes and the consequences of their decisions. Likewise, in Turkey, it is still uncertain as to what will be taught, what instructional technologies will be employed, how infrastructural inequalities will be addressed, and how assessment and evaluation activities will be conducted. In this context, the purpose of this study was (a) to examine the experiences and opinions of academics, Distance Education Center managers, students, and parents and (b) offer solutions to emerging issues. In doing so, a qualitative research approach was employed, and the study was designed as a phenomenology. The data were collected from 175 individuals from 20 universities through Google Forms. The second cycle coding methods were employed in the analysis. The results indicated that COVID-19 had mostly psychological effects on individuals, and it affected every level of education at varying degrees. The pandemic reminded us how hopelessly we are dependent on traditional means of instruction by rendering us unable to use them. Since the beginning of the outbreak, many higher education institutions have been trying to implement distance education; however, the quality of instruction is rather questionable. This situation threatens the quality of learning outcomes and if not approached with due diligence, results could be catastrophic. Also, this mandatory transition to distance education has made the difference between the experienced and inexperienced academics more apparent. In light of the results, recommendations were provided for national and international policymakers. As long as the recommendations were implemented, all higher education stakeholders could attain the required knowledge and skills, and, in return, the adverse effects of the COVID-19 pandemic could be alleviated.},
  keywords = {Access to Computers,Administrator Attitudes,College Faculty,College Students,Coping,COVID-19,Distance Education,Educational Quality,Educational Technology,Evaluation Methods,Foreign Countries,Higher Education,Online Courses,Pandemics,Parent Attitudes,School Closing,Student Attitudes,Teacher Attitudes,Teaching Methods,Technology Uses in Education,Turkey},
  file = {/Users/colin.madland/Zotero/storage/F6VUBCAV/karademirChallengesHigherEducation2020.pdf}
}

@article{karimHybridOnlineSynchronous2021,
  ids = {karimHybridOnlineSynchronous2021a},
  title = {Hybrid and {{Online Synchronous Delivery}} of {{Environmental Engineering}} during {{COVID-19 Pandemic}}: {{A Comparative Study}} on {{Perception}}, {{Attitude}}, and {{Assessment}}},
  author = {Karim, M. A.},
  year = {2021},
  journal = {European Journal of STEM Education},
  volume = {6},
  number = {1},
  publisher = {European Journal of STEM Education},
  issn = {EISSN-2468-4368},
  doi = {10/gmbv26},
  abstract = {Hybrid and online synchronous delivery of courses is a time-demanding approach to teaching and learning systems that is designed to engage students in investigations of authentic concepts or problems without coming to the pre-assigned classrooms two or three times a week. This study presents perceptions and attitudes of students that attended a hybrid course in environmental engineering that suddenly converted to an online synchronous delivery due to COVID-19. It also presents an assessment of the hybrid and online synchronous delivery approach on the final exam scores as well as the final grades of the same course. The course, 'Introduction to Environmental Engineering', was developed as an online course for Civil and Environmental Engineering program students and delivered with hybrid and online synchronous options due to COVID-19 pandemic for several semesters to test the concept. In the hybrid delivery set up, all the quizzes and homework assignments were online while the midterm and final exams were in-class. For Spring 2020 the final exam was online and for Summer 2020 both the midterm and final exams were online due to COVID-19 adjustment. At the very end of the semesters, an online anonymous survey was conducted with five questions to understand the students' perception and attitude on exam taking options and learning environment. Students' perceptions and attitudes about online synchronous delivery approach compared to hybrid delivery approach, as well as the learning outcomes, appeared at face value not to be favorable. However, statistical analysis revealed that differences between online synchronous delivery and the Pre-COVID-19 hybrid delivery were not significant, indicating that, at least for these engineering students, online synchronous delivery is a justifiable option.},
  langid = {english},
  keywords = {Blended Learning,College Students,Computer Assisted Testing,Conservation (Environment),COVID-19,Educational Technology,Engineering Education,Grades (Scholastic),Online Courses,Pandemics,Scores,Student Attitudes,Synchronous Communication,Teaching Methods,Technology Uses in Education,Tests},
  file = {/Users/colin.madland/Zotero/storage/FQM2ILXV/karimHybridOnlineSynchronous2021.pdf}
}

@article{kartalRelationshipStudentsPerformance2016,
  title = {The {{Relationship}} between {{Students}}' {{Performance}} on {{Conventional Standardized Mathematics Assessments}} and {{Complex Mathematical Modeling Problems}}},
  author = {Kartal, Ozgul and Dunya, Beyza Aksu and {Diefes-Dux}, Heidi A. and Zawojewski, Judith S.},
  year = {2016},
  month = dec,
  journal = {International Journal of Research in Education and Science},
  volume = {2},
  number = {1},
  pages = {239--252},
  publisher = {{International Journal of Research in Education and Science}},
  issn = {2148-9955},
  doi = {10.21890/ijres.07616},
  abstract = {Critical to many science, technology, engineering, and mathematics (STEM) career paths is mathematical modeling--specifically, the creation and adaptation of mathematical models to solve problems in complex settings. Conventional standardized measures of mathematics achievement are not structured to directly assess this type of mathematical modeling. Therefore, a major question is whether a conventional standardized test can serve as a reliable "predictor" of students' potential to mathematical modeling performance. To investigate this question, a study was designed to find the relation between students' conventional standardized measures of mathematics achievement and their performance on mathematical modeling problems. Students' (N = 1656) SAT (Scholastic Aptitude Test) mathematics scores were used as a conventional standardized measure of achievement and students' scores on two model-creation problems based on complex settings were used to capture mathematical modeling performance to answer the question whether standardized achievement tests function well in predicting their mathematical modeling performance.},
  keywords = {Achievement Tests,ACT Assessment,Calculus,College Entrance Examinations,College Students,Comparative Analysis,Correlation,Data Collection,Denmark,Engineering,Foreign Countries,Higher Education,Indiana,Mathematical Models,Mathematics,Mathematics Achievement,Mathematics Activities,Mathematics Education,Mathematics Instruction,Mathematics Skills,Predictor Variables,Pretests Posttests,Regression (Statistics),SAT (College Admission Test),Scores,Standardized Tests,Statistical Analysis,STEM Education,Teaching Methods}
}

@misc{katsarosReconsideringTweetsIntervening2021,
  title = {Reconsidering Tweets: {{Intervening}} during Tweet Creation Decreases Offensive Content},
  author = {Katsaros, Matthew and Yang, Kathy and Fratamico, Lauren},
  year = {2021},
  eprint = {2112.00773},
  primaryclass = {cs.SI},
  archiveprefix = {arXiv},
  file = {/Users/colin.madland/Zotero/storage/RP55F362/katsarosReconsideringTweetsIntervening2021.pdf}
}

@article{katsarouEffectsComputerAnxiety2021,
  title = {The {{Effects}} of {{Computer Anxiety}} and {{Self-Efficacy}} on {{L2 Learners}}' {{Self-Perceived Digital Competence}} and {{Satisfaction}} in {{Higher Education}}},
  author = {Katsarou, Eirene},
  year = {2021},
  journal = {Journal of Education and e-Learning Research},
  volume = {8},
  number = {2},
  pages = {158--172},
  issn = {ISSN-2518-0169},
  doi = {10/gmbv2w},
  abstract = {Low computer anxiety (CA) and high computer self-efficacy (CSE) levels are important affective factors that promote students' academic success in the current digital era. In an effort to understand their role in successful and effective participation in online learning environments for language learning purposes, the study investigated their effect on 331 undergraduate L2 learners' self-reported assessments of their digital literacy skills and on the level of satisfaction they express with the online component of their English for Specific Purposes course in higher education in Greece. Data were gathered via four survey questionnaires that elicited relevant information on participants' digital literacy level, learner satisfaction, computer anxiety and self-efficacy respectively. Statistical analysis of the results revealed an overall adequate level of students' digital literacy skills and a high level of satisfaction with all aspects of the online module of the blended learning course. Females reported a lower level of CA and a higher level of CSE. CA was found to be the strongest predictor of learners' digital literacy skills assessments and CSE of learner satisfaction perceptions, resulting in overall higher IT use and positive attitudes to the course.},
  langid = {english},
  keywords = {Agricultural Education,Anxiety,Blended Learning,Computer Attitudes,Computer Literacy,Electronic Learning,English for Special Purposes,Foreign Countries,Forestry,Gender Differences,Predictor Variables,Second Language Instruction,Second Language Learning,Self Efficacy,Student Participation,Student Satisfaction,Undergraduate Students,Young Adults}
}

@article{kaufmannReflectionBenefitsGamification2018,
  title = {Reflection: {{Benefits}} of {{Gamification}} in {{Online Higher Education}}},
  author = {Kaufmann, Daniel A.},
  year = {2018},
  journal = {Journal of Instructional Research},
  volume = {7},
  pages = {125--132},
  issn = {ISSN-2159-0281},
  doi = {10/gmbvzj},
  abstract = {This article presents a reflective account of how gamification can help students overcome complex academic challenges, such as those involved in the dissertation process and other elements of higher learning. Gamification has been shown across multiple levels of academic instruction to have a positive impact on task completion by augmenting the experiential elements encountered by students who are engaging in the learning process. When a task becomes mundane, it typically lacks a positive feedback loop, which results in it becoming easier for a person to put off their intended task and forget to return to the activity prior to deadline. Many online learners participate in their degree programs in the midst of highly involved personal schedules, which can lead to lapses in organization and reduced performance as a student. Many applications have promise for improving the levels of fun, engagement, motivation, and task completion in various areas of daily life. Online faculty, can integrate these applications with existing online curricula to help students bridge the gap between passive stagnation in a course and active engagement with the course material to increase their grades earned and course-wide satisfaction.},
  langid = {english},
  keywords = {College Students,Computer Oriented Programs,Doctoral Dissertations,Educational Benefits,Electronic Learning,Games,Higher Education,Learner Engagement,Learning Motivation,Online Courses}
}

@article{kauppilaServingHelpHelping2021,
  title = {Serving to {{Help}} and {{Helping}} to {{Serve}}: {{Using Servant Leadership}} to {{Influence Beyond Supervisory Relationships}}},
  author = {Kauppila, Olli-Pekka and Ehrnrooth, Mats and M{\"a}kel{\"a}, K. and Smale, Adam and Sumelius, Jennie and Vuorenmaa, Hertta},
  year = {2021},
  month = mar,
  journal = {Journal of Management},
  doi = {10.1177/0149206321994173},
  abstract = {This study provides a new perspective on servant leadership research by examining the social influence of the servant leadership of individuals who are not in a supervisory position. Drawing on servant leadership and social learning theories, we examine how the servant leadership of managers in support roles can initiate a social learning process that shapes the leadership style of line managers and thereby influences employee outcomes throughout the organization. To facilitate the integration between servant leadership and social learning theories, we also examine the role of efficacy beliefs in enhancing the effectiveness of the social learning process. Using nested, time-lagged data from 667 store managers, 121 line managers, and 23 human resource managers (i.e., support managers), we find that support managers' servant leadership positively influences organizational members' perceptions of overall justice and leader-member exchange through line manager servant leadership. In turn, employees' favorable perceptions stemming from line manager servant leadership enhance the employees' organizational commitment and job satisfaction. The results also indicate that high leadership self-efficacy augments line managers' effectiveness in emulating servant leadership behaviors from support managers and reinforces the indirect effects on organizational members' favorable perceptions.},
  file = {/Users/colin.madland/Zotero/storage/U65RH6II/kauppilaServingHelpHelping2021.pdf}
}

@article{kaya-capocciFrameworkSupportImplementation2022,
  title = {Towards a {{Framework}} to {{Support}} the {{Implementation}} of {{Digital Formative Assessment}} in {{Higher Education}}},
  author = {{Kaya-Capocci}, Sila and O'Leary, M. and Costello, E.},
  year = {2022},
  month = nov,
  journal = {Education sciences},
  doi = {10.3390/EDUCSCI12110823},
  abstract = {This paper proposes a framework to support the use of digital formative assessment in higher education. The framework is informed by key principles and approaches underpinning effective formative assessment and, more specifically, by approaches to formative assessment that leverage the functionalities of technology. The overall aim is to provide a structured conceptualisation of digital formative assessment that supports the planning of lectures and other teaching and learning activities in higher education classrooms. At the heart of the framework, as presented in this paper, is a 12-cell grid comprising 4 key formative assessment strategies (sharing learning intentions and success criteria, questioning and discussion, feedback, and peer- and self-assessment) crossed with 3 functionalities of technology (sending and displaying, processing and analysing, and interactive environments). These functionalities of technologies are used as the basis to integrate digital tools into formative assessment for effective teaching and learning processes. For each cell in the grid, an exemplary digital formative assessment practice is described. This paper highlights the framework's potential for enhancing the practice of digital formative assessment and its significance in light of the ongoing digital transformation. This paper concludes with suggesting a programme of research that might be undertaken to evaluate its utility and impact in higher education contexts.},
  file = {/Users/colin.madland/Zotero/storage/9RWJP44N/kaya-capocciFrameworkSupportImplementation2022.pdf}
}

@article{kayEnhancingLearningOpen2022,
  title = {Enhancing Learning by {{Open Learner Model}} ({{OLM}}) Driven Data Design},
  author = {Kay, Judy and Bartimote, Kathryn and Kitto, Kirsty and Kummerfeld, Bob and Liu, Danny and Reimann, Peter},
  year = {2022},
  month = jan,
  journal = {Computers and Education: Artificial Intelligence},
  volume = {3},
  pages = {100069},
  issn = {2666-920X},
  doi = {10.1016/j.caeai.2022.100069},
  abstract = {There is a huge and growing amount of data that is already captured in the many, diverse digital tools that support learning. Additionally, learning data is often inaccessible to teachers or served in a manner that fails to support or inform their teaching and design practice. We need systematic, learner-centred ways for teachers to design learning data that supports them. Drawing on decades of Artificial Intelligence in Education (AIED) research, we show how to make use of important AIED concepts: (1) learner models; (2) Open Learner Models (OLMs); (3) scrutability and (4) Ontologies. We show how these concepts can be used in the design of OLMs, interfaces that enable a learner to see and interact with an externalised representation of their learning progress. We extend this important work by demonstrating how OLMs can also drive a learner-centred design process of learning data. We draw on the work of Biggs on constructive alignment (Biggs, 1996, 1999, 2011), which has been so influential in education. Like Biggs, we propose a way for teachers to design the learning data in their subjects and we illustrate the approach with case studies. We show how teachers can use this approach today, essentially integrating the design of learning data along with the learning design for their subjects. We outline a research agenda for designing the collection of richer learning data. There are three core contributions of this paper. First, we present the terms OLM, learner model, scrutability and ontologies, as thinking tools for systematic design of learning data. Second, we show how to integrate this into the design and refinement of a subject. Finally, we present a research agenda for making this process both easier and more powerful.},
  keywords = {Learner models,Learning analytics,Ontologies,Open Learner Models (OLMs),Scrutability,Self-regulated learning,Student models},
  file = {/Users/colin.madland/Zotero/storage/GZS4FKKZ/kayEnhancingLearningOpen2022.pdf}
}

@incollection{keehnerDevelopingValidatingCognitive2016,
  title = {Developing and Validating Cognitive Models in Assessment},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {Keehner, Madeleine and Gorin, Joanna S. and Feng, Gary and Katz, Irvin R.},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch4},
  pages = {75--101},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch4},
  abstract = {Summary In this chapter, we first attempt to characterize cognitive models in ways that are useful to the assessment domain and provide a rationale for developing and validating cognitive models for the applied goals in this field. Having clarified the value of cognitive models for assessment, we introduce different forms of evidence that have promise and practical use for validating cognitive models in this domain. We divide these into off-line evidence (which can be collected in studies devised and implemented after or before the assessment task has been administered) and online evidence (which is gathered directly from test-takers or research participants while they are completing assessment tasks). Finally, we describe an instance where we combined multiple forms of evidence in the development phases of a large-scale testing program, in order to illustrate how different evidence types can be collected and combined during assessment development and analyzed for insights into student cognition.},
  chapter = {4},
  isbn = {978-1-118-95658-8},
  keywords = {cognitive models,educational assessment,eye tracking,interactive tasks,log file data,process data,think-aloud,validity,verbal protocols,virtual performance assessments}
}

@article{kelleyGoodPracticeConduct2003,
  title = {Good Practice in the Conduct and Reporting of Survey Research},
  author = {Kelley, K.},
  year = {2003},
  month = may,
  journal = {International Journal for Quality in Health Care},
  volume = {15},
  number = {3},
  pages = {261--266},
  issn = {13534505, 14643677},
  doi = {10.1093/intqhc/mzg031},
  urldate = {2024-01-16},
  file = {/Users/colin.madland/Zotero/storage/CFAEUZYT/kelleyGoodPracticeConduct2003.pdf}
}

@article{kellyExploringDimensionalitySelfperceived2020,
  title = {Exploring the Dimensionality of Self-Perceived Performance Assessment Literacy ({{PAL}})},
  author = {Kelly, Michael P. and Feistman, Richard and Dodge, Emily and St. Rose, Andresse and {Littenberg-Tobias}, Josh},
  year = {2020},
  journal = {Educational Assessment, Evaluation and Accountability},
  volume = {32},
  number = {4},
  pages = {499--517},
  issn = {1874-8597, 1874-8600},
  doi = {10/gk5btg},
  urldate = {2021-07-08},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/5RUC57KA/kellyExploringDimensionalitySelfperceived2020.pdf}
}

@book{kemmisActionResearchPlanner2014,
  title = {The Action Research Planner: Doing Critical Participatory Action Research},
  shorttitle = {The Action Research Planner},
  author = {Kemmis, Stephen and McTaggart, Robin and Nixon, Rhonda},
  year = {2014},
  publisher = {Springer},
  address = {Singapore Heidelberg New York Dordrecht London},
  isbn = {978-981-4560-67-2 978-981-4560-66-5},
  langid = {english},
  annotation = {OCLC: 862761763},
  file = {/Users/colin.madland/Zotero/storage/HZEHN4GT/kemmisActionResearchPlanner2014.pdf}
}

@book{kennedyHandbookResearchK122018,
  title = {Handbook of Research on {{K-12}} Online and Blending Learning},
  editor = {Kennedy, Kathryn and Ferdig, Richard E},
  year = {2018},
  urldate = {2020-07-10},
  abstract = {"The Handbook of Research on K-12 Online and Blended Learning is an edited collection of chapters that sets out to present the current state of research in K-12 online and blended learning. The chapters describe where we have been, what we currently know, and where we hope to go with research in multiple areas."--Book home page.},
  isbn = {978-1-387-73335-4},
  langid = {english},
  annotation = {OCLC: 1031715034}
}

@article{kennedyHandbookResearchK122018a,
  title = {Handbook of {{Research}} on {{K-12 Online}} and {{Blended Learning}} ({{Second Edition}})},
  author = {Kennedy, Kathryn},
  year = {2018},
  pages = {45993853 Bytes},
  publisher = {Figshare},
  doi = {10/gg3brs},
  urldate = {2020-06-26},
  abstract = {The Handbook of Research on K-12 Online and Blended Learning is an edited collection of chapters that sets out to present the current state of research in K-12 online and blended learning. The chapters describe where we have been, what we currently know, and where we hope to go with research in multiple areas.},
  copyright = {CC BY 3.0},
  keywords = {120304 Digital and Interaction Design},
  file = {/Users/colin.madland/Zotero/storage/5W9CR7H6/kennedyHandbookResearchK122018.pdf}
}

@article{kentInteractivityOnlineDiscussions2016,
  title = {Interactivity in Online Discussions and Learning Outcomes},
  author = {Kent, Carmel and Laslo, Esther and Rafaeli, Sheizaf},
  year = {2016},
  month = jun,
  journal = {Computers \& Education},
  volume = {97},
  pages = {116--128},
  publisher = {Elsevier Science},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2016.03.002},
  abstract = {The increased use of online discussions in learning environments both formal and informal, positions the construct of interactivity as central to learning. Interactivity in learning communities' online discourse is viewed in this study as a socio-constructivist process. It is the network of interactions among content items and participants which drives a collective knowledge construction process. Conceptualizing interactivity in the literature is still unclear and not enough is known about its role in knowledge construction and about its relationship to learning outcomes. In addition, assessing learning outcomes using analytics has not matured fully and is still subject to intense development. This study thus sets out to investigate the role of interactivity as a process of knowledge construction within online discussions, and in particular, its association with learning outcomes, as measured by formal assessment tasks. We present significant positive correlations between various interactivity measures, taken from various learning communities, and a set of well-known learning assessments. We suggest that patterns of interactivity among learners can be measured, and teach us, not just about group dynamics and collaboration, but also about the actual individual learning process. (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
  keywords = {Collaborative Learning,Computer-mediated communication,Cooperative/collaborative learning,Electronic Communication,Evaluation methodologies,Interactive learning environments,Knowledge Management,Learning communities,Learning Environment,Social Interaction,Teaching Methods}
}

@article{keppellPeerLearningLearningoriented2006,
  title = {Peer Learning and Learning-Oriented Assessment in Technology-Enhanced Environments},
  author = {Keppell, Mike and Au, Eliza and Ma, Ada and Chan, Christine},
  year = {2006},
  journal = {Assessment and evaluation in higher education},
  volume = {31},
  number = {4},
  pages = {453--464},
  publisher = {Routledge},
  address = {Abingdon},
  issn = {0260-2938},
  doi = {10.1080/02602930600679159},
  abstract = {Group work, group projects and collaborative learning encourage students to learn from other students as well as from the lecturer. Peer learning may involve cooperation, communication and the giving and receiving of peer feedback. In addition peer learning emphasises the sharing of knowledge and ideas between students in a reciprocal partnership. However, some educators ask individual students to formally assess each other within the context of a group project which may inhibit the very process of peer learning that they are attempting to promote. This paper, through the voices of three lecturers and their students, has attempted to reinforce the importance of learning-oriented peer assessment within technology-enhanced environments. This paper advocates the concept of learning-oriented peer assessment strategies to enhance student learning.},
  keywords = {Cooperative learning,Feedback,Group dynamics,Interpersonal communication,Learning,Peers,Technology},
  file = {/Users/colin.madland/Zotero/storage/JA4PXCPH/keppellPeerLearningLearningoriented2006.pdf}
}

@article{kerriganPostCOVIDChangesAssessment2022,
  title = {Post-{{COVID Changes}} to {{Assessment Practices}}: {{A Case Study}} of {{Undergraduate STEM Recitations}}},
  author = {Kerrigan, John and Cochran, Geraldine and Tabanli, Sheila and Charnley, Matt and Mulvey, Sally},
  year = {2022},
  journal = {Journal of educational technology systems},
  volume = {51},
  number = {2},
  pages = {192--201},
  publisher = {SAGE Publications},
  address = {Los Angeles, CA},
  issn = {0047-2395},
  doi = {10.1177/00472395221118392},
  abstract = {As a result of the COVID-19 pandemic, faculty members transitioned their courses online. This paper describes how assessment practices were altered in online ``active learning'' STEM recitations at a large research university. Survey data collected for this study included aspects of the in-person recitation that were retained, lost, or modified due to emergency remote teaching. Findings indicate that assessment practices were altered from the traditional in-person recitation model. Many of these practices will continue to exist even when recitations are offered in person again. This study collates the perspectives of faculty to provide a window into assessment practices.},
  keywords = {Active Learning,College Faculty,COVID-19,Educational Practices,Electronic Learning,Evaluation Methods,Pandemics,STEM Education,Student Evaluation,Student Participation,Tests,Undergraduate Study}
}

@incollection{kerrIntaskAssessmentFramework2016,
  title = {The In-Task Assessment Framework for Behavioral Data},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {Kerr, Deirdre and Andrews, Jessica J. and Mislevy, Robert J.},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch20},
  pages = {472--507},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch20},
  abstract = {Summary In educational games and simulations, game play itself can provide a novel source of assessment data as it can offer rich observations of student learning behaviors, which can support diagnostic claims about students' learning processes. However, the nature of the data produced by these environments makes using in-task behavioral data for assessment purposes difficult. We introduce the in-task assessment framework as an innovative approach for identifying the measurable components of the domain of interest, which is a process for feature extraction that operationalizes the concepts of interest at the same grain-size as contained in the log data and articulates chains-of-evidence that link the extracted features to applicable concepts in an ontology. This process transforms low-level log data into a set of action set labels that can be utilized in a number of different measurement models so that proficiency can be assessed solely from in-task behavioral data.},
  chapter = {20},
  isbn = {978-1-118-95658-8},
  keywords = {assessment,assessment framework,behavioral data,collaborative problem solving,educational games,evidence-centered design,feature extraction,measurement,process data,simulations}
}

@article{kertonAssessmentOnlineLearning2014,
  title = {Assessment in {{Online Learning}}---{{It}}'s a {{Matter}} of {{Time}}},
  author = {Kerton, Charles and Cervato, Cinzia},
  year = {2014},
  journal = {Journal of College Science Teaching},
  volume = {43},
  number = {4},
  pages = {20--25},
  publisher = {National Science Teachers Association},
  address = {Washington},
  issn = {0047-231X},
  doi = {10/ggrgxf},
  abstract = {Taking online courses is becoming a more common part of the college experience, but very little is known about student behaviors and strategies related to online assessment. This article reviews how students in an online Earth and Space Science course interact with various online assessments. Our two main findings are that our students do not use self-assessment tools effectively, and time spent on online exams is surprisingly short. We discuss how the use of selfassessment tools can probably be improved through careful online course design, but the short time spent on online exams is partially due to the nature of the online environment itself. We make a number of design suggestions that can encourage good test-taking strategies in the online environment. [PUBLICATION ABSTRACT];Taking online courses is becoming a more common part of the college experience, but very little is known about student behaviors and strategies related to online assessment. This article reviews how students in an online Earth and Space Science course interact with various online assessments. Our two main findings are that our students do not use self-assessment tools effectively, and time spent on online exams is surprisingly short. We discuss how the use of self-assessment tools can probably be improved through careful online course design, but the short time spent on online exams is partially due to the nature of the online environment itself. We make a number of design suggestions that can encourage good test-taking strategies in the online environment.;},
  keywords = {College science,College students,Computer Assisted Testing,Distance education,Distance learning,Earth Science,Educational Assessment,Educational evaluation,Educational tests,Forecasts and trends,Formative assessment,Learning,Methods,Online courses,Online education,Online instruction,Online learning,Self evaluation,Self Evaluation (Individuals),Space Sciences,Standardized tests,Standards,Student behavior,Test Wiseness}
}

@article{ketchumImpactVideoFeedback2022,
  title = {The {{Impact}} of {{Video Feedback}} on {{Student Assessments}} and {{Performance}}},
  author = {Ketchum, Cheri and Phompheng, Elaine and Yeats, Chelsey and LaFave, Daria and Hardy, James},
  year = {2022},
  journal = {The American journal of distance education},
  volume = {36},
  number = {4},
  pages = {288--301},
  publisher = {Routledge},
  address = {Philadelphia},
  issn = {0892-3647},
  doi = {10.1080/08923647.2022.2073113},
  abstract = {This study explores the impact video feedback (VF) has on student evaluations of feedback and instructors as well as the grades students receive on written assignments in a five-week online course. The goal is to discover if VF improves student attitudes about instructors and their performance. The results showed no significant links between using videos and improvement in either area. These findings suggest that before an institution or individual instructor focuses on the feedback delivery channel, there should be a solid understanding of students' willingness and ability to understand, process, and utilize feedback.},
  keywords = {Academic achievement,Distance learning,Educational evaluation,Online instruction,Student attitudes,Teacher evaluations,Video}
}

@article{ketonenAssessmentDesignsInstructional2023,
  title = {Assessment Designs of Instructional Labs: {{A}} Literature Review and a Design Model},
  author = {Ketonen, Laura and Lehtinen, Antti and Koskinen, Pekka},
  year = {2023},
  journal = {Physical review. Physics education research},
  volume = {19},
  number = {2},
  pages = {020601},
  publisher = {Amer Physical Soc},
  address = {COLLEGE PK},
  issn = {2469-9896},
  doi = {10.1103/PhysRevPhysEducRes.19.020601},
  abstract = {[This paper is part of the Focused Collection on Instructional labs: Improving traditions and new directions.] In recent years, physics instructional labs have been under considerable research and development. However, there seems to be no shared understanding of how the assessment of instructional labs should be arranged to best serve students' learning and development of expertise. This literature review intends to fill this gap by reviewing the research on classroom assessment of instructional labs from the perspectives of different objectives, purposes, and agents of assessment. The review reveals that classroom assessment in instructional labs has mostly focused on summative assessment, leaving the possibilities of formative assessment understudied. Further, assessment has been conducted mostly by teachers and teaching assistants, and the possibilities for students' participation in assessment remain unutilized. Two major gaps in the research on instructional labs were identified. The first gap concerns students' active participation in assessment. Given the active role that students have in the laboratory, their agency in assessment appears to be narrow. The second gap concerns the inclusion of metaskills and perspectives on lifelong learning and work life in assessment. We summarize our findings into a research-based model that assists in the consideration and balancing of different objectives, purposes, and agents in the design of classroom assessment of instructional labs.},
  keywords = {Education & Educational Research,Education Scientific Disciplines,Social Sciences},
  file = {/Users/colin.madland/Zotero/storage/5ILR866T/ketonenAssessmentDesignsInstructional2023.pdf}
}

@incollection{ketterlin-gellerUnderstandingImprovingAccessibility2016,
  title = {Understanding and Improving Accessibility for Special Populations},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {{Ketterlin-Geller}, Leanne R.},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch9},
  pages = {198--225},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch9},
  abstract = {Summary Integrating theories of learning in the test development process may improve accessibility of educational assessments for students in special populations. Cognitive models of learning can help specify the construct relevancy of the assessed knowledge, skills, and abilities. Cognitive models of performance can help guide item and test design specifications to promote alignment with the purpose of the assessment. Improving the accessibility of educational assessments may allow students in special populations to interact meaningfully with the material and generate responses that accurately reflect their construct-relevant understanding, thereby leading to comparable score-based interpretations for all students.},
  chapter = {9},
  isbn = {978-1-118-95658-8},
  keywords = {access skills,accessibility,cognitive model of learning,cognitive model of performance,construct-irrelevant variance,test accommodations,universal design for assessment}
}

@article{khajelooChallengesAccomplishmentsPracticing2022,
  title = {Challenges and {{Accomplishments}} of {{Practicing Formative Assessment}}: A {{Case Study}} of {{College Biology Instructors}}' {{Classrooms}}},
  author = {Khajeloo, Mojtaba and Birt, Julie A. and Kenderes, Elizabeth M. and Siegel, Marcelle A. and Nguyen, Hai and Ngo, Linh T. and Mordhorst, Bethany R. and Cummings, Keala},
  year = {2022},
  journal = {International journal of science and mathematics education},
  volume = {20},
  number = {2},
  pages = {237--254},
  publisher = {Springer Singapore},
  address = {Singapore},
  issn = {1571-0068},
  doi = {10.1007/s10763-020-10149-8},
  abstract = {This study presents a glimpse into the private classrooms of biology instructors and the way they practice formative assessments within a college context. Drawing on the personal practice assessment theory model from Box, Skoog and Dabbs (2015), we carried out a multiple case study to investigate two biology instructors' theories in enacting formative assessment practices. Data collected included classroom observations, instructor interviews, course artifacts, and student focus groups. Qualitative data analysis revealed that each instructor's core personal practical assessment theories affected implementation of formative assessment. Tasha's core assessment theories led her to believe that assessment should be a carefully planned motivational and learning opportunity for students. Meanwhile, Jack viewed assessment as a diverse and stress-free student learning experiment. Cross-case analysis revealed that the teachers' reasoning and decision-making differences were based on the interaction of their personal practical assessment theories and contextual elements. Overall, this study provides insights into the practice of formative assessment in higher education and identifies some challenges and opportunities such assessment presents.},
  keywords = {Analysis,Biology,Case studies,Classrooms,College Faculty,College Science,College Students,Colleges & universities,Context Effect,Data analysis,Decision analysis,Decision making,Differences,Education,Education & Educational Research,Education Higher,Educational Practices,Formative Evaluation,Information management,Learning,Mathematics Education,Qualitative analysis,Science Education,Sciences education,Social Sciences,Student Evaluation,Teachers,Teaching,Theories}
}

@article{khajelooConceptMapTool2022,
  title = {Concept Map as a Tool to Assess and Enhance Students' System Thinking Skills},
  author = {Khajeloo, Mojtaba and Siegel, Marcelle A.},
  year = {2022},
  journal = {Instructional science},
  volume = {50},
  number = {4},
  pages = {571--597},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  issn = {0020-4277},
  doi = {10.1007/s11251-022-09586-5},
  abstract = {Concept map (CM) is introduced as a useful tool for studying students' system thinking (ST). However, it is more known to represent students' knowledge of system components and organization and less recognized as a tool to examine and enhance students' understanding about the underlying causal mechanisms in complex systems. In this study, through a mixed method approach, we investigated the potential of CM in demonstrating undergraduate students' (n\,=\,173) ST. We also conducted a comparative analysis to examine the effects of different scaffolding on developing students' ST skills. Through a theoretical framework of causal patterns, we present a new perspective on what CM reveals about students' ST and what are its limitations in showing system complexities. The results indicated that CM can provide a platform for students to practice causal mechanisms such as domino, mutual, relational, and cyclic causalities, and accordingly, work as a tool for teachers to examine students' knowledge of such mechanisms. The results also showed that students improved in demonstrating ST by CM when they were scaffolded for showing causal mechanisms and building CM. Eventually, this study concludes that the CM is a highly relevant tool to increase and examine students' ST skills. To this end, we found it is important to explicitly teach students about causal patterns and guide them to construct CM with an emphasis on showing the interconnection among concepts.},
  keywords = {Causal Models,College students,Comparative Analysis,Concept Formation,Concept Mapping,Education,Education & Educational Research,Educational Psychology,Learning and Instruction,Original Research,Pedagogic Psychology,Psychology,Psychology Educational,Scaffolding (Teaching Technique),Skill Development,Social Sciences,Student Evaluation,Students,Systems Approach,Teachers,Thinking Skills,Undergraduate Students}
}

@article{khalafIntroducingComprehensiveHighstake2020,
  title = {Introducing a Comprehensive High-Stake Online Exam to Final-Year Dental Students during the {{COVID-19}} Pandemic and Evaluation of Its Effectiveness},
  author = {Khalaf, K and {El-Kishawi}, M and Moufti, {\relax MA} and Al Kawas, S},
  year = {2020},
  journal = {Medical Education Online},
  volume = {25},
  number = {1},
  issn = {1087-2981},
  doi = {10.1080/10872981.2020.1826861},
  abstract = {Background Dental education involves teaching and assessing the acquisition of verifiable domains that require superior psychomotor, communication, and cognitive skills. Evolving technologies and methods of assessment could enhance student learning environment and improve tutor assessment experience. Objective The aim of this study was to introduce the application of a comprehensive high-stakes online exam to final-year dental students during the COVID-19 pandemic and evaluate its effectiveness. Design A high-stakes exam was introduced and implemented online to the final-year dental students prior to their graduation. The exam consisted of four components: MEQs, MCQs, OSCE and an oral exam. The exam and invigilation were conducted using Blackboard and MS Teams programs. Stakeholders' views of the exam were obtained using two tailored surveys, one for students and another for faculty; both included closed- and open-ended questions. Results The exam was run successfully without untoward events. Both students and staff were satisfied with the online exam with the latter being more satisfied than the former. Students with previous experience in online learning system were more satisfied with the online exam compared with those with less experience (p{$<$} 0.05). The main issues raised by students' satisfaction with the exam were: inadequacy of time for the MEQ part, prevention of back tracking in the MCQ part and minor technological issues, whereas those raised by faculty members were increased time required to complete the exam setup and grading compared to the paper-based exam and minor technological issues. Conclusions A newly introduced, multi-format, online high-stakes exam was implemented successfully to final-year dental students with minor technological issues and good satisfaction by students and staff alike.},
  langid = {english},
  keywords = {blackboard,computer-mediated assessment,dental education,FORMATIVE ASSESSMENT,higher education,HIGHER-EDUCATION,MEDICAL-EDUCATION,Online assessment,PROGRAMMATIC ASSESSMENT,summative assessment,SUMMATIVE ASSESSMENT,TEST ANXIETY,WRITTEN},
  file = {/Users/colin.madland/Zotero/storage/QNVQRRGY/khalafIntroducingComprehensiveHighstake2020.pdf}
}

@article{khanBuildingEffectiveAutomated2022,
  title = {Building an {{Effective Automated Assessment System}} for {{C}}/{{C}}++ {{Introductory Programming Courses}} in {{ODL Environment}}},
  author = {Khan, Muhammad Salman and Ahmad, Adnan and Humayoun, Muhammad},
  year = {2022},
  journal = {arXiv.org},
  publisher = {Cornell University Library, arXiv.org},
  address = {Ithaca},
  issn = {2331-8422},
  abstract = {Assessments help in evaluating the knowledge gained by a learner at any specific point as well as in continuous improvement of the curriculum design and the whole learning process. However, with the increase in students' enrollment at University level in either conventional or distance education environment, traditional ways of assessing students' work are becoming insufficient in terms of both time and effort. In distance education environment, such assessments become additionally more challenging in terms of hefty remuneration for hiring large number of tutors. The availability of automated tools to assist the evaluation of students' work and providing students with appropriate and timely feedback can really help in overcoming these problems. We believe that building such tools for assessing students' work for all kinds of courses in not yet possible. However, courses that involve some formal language of expression can be automated, such as, programming courses in Computer Science (CS) discipline. Instructors provide various practical exercises to students as assignments to build these skills. Usually, instructors manually grade and provide feedbacks on these assignments. Although in literature, various tools have been reported to automate this process, but most of these tools have been developed by the host institutions themselves for their own use. We at COMSATS Institute of Information Technology, Lahore are conducting a pioneer effort in Pakistan to automate the marking of assignments of introductory programming courses that involve C or C++ languages with the capability of associating appropriate feedbacks for students. In this paper, we basically identify different components that we believe are necessary in building an effective automated assessment system in the context of introductory programming courses that involve C/C++ programming.},
  keywords = {Assessments,Automation,C plus plus,C++ (programming language),Colleges & universities,Continuous improvement,Curricula,Distance learning,Evaluation,No DOI found,Programming,Students,Teachers}
}

@article{khanLearnersPerspectiveEExams2021,
  title = {Learners' {{Perspective}} towards {{E-Exams}} during {{COVID-19 Outbreak}}: {{Evidence}} from {{Higher Educational Institutions}} of {{India}} and {{Saudi Arabia}}},
  author = {Khan, Mohammed Arshad and Vivek, Vivek and Khojah, Maysoon and Nabi, Mohammed Kamalun and Paul, Mohinder and Minhaj, Syed Mohd},
  year = {2021},
  journal = {International journal of environmental research and public health},
  volume = {18},
  number = {12},
  pages = {6534},
  publisher = {Mdpi},
  address = {BASEL},
  issn = {1660-4601},
  doi = {10.3390/ijerph18126534},
  abstract = {Online examinations, commonly referred to as e-exams (electronic examinations), underwent a considerable progression, getting adapted ubiquitously among higher education institutions worldwide. Their preferment was rapid due to the emergence of the COVID-19 pandemic. The process of conducting exams online is being opted as the appropriate way of assessment, ensuring the students' safety and well-being. According to Warts et al., this form of examination has been pretty effective in the past when blended with the conventional assessment. However, at present, implemented as the singular way of assessment, e-exams have shown a more significant promise in being beneficial to the learners. As a matter of fact, a comprehensive analysis on understanding the learners' perception towards the e-exams was not done earlier, particularly in the developing nations. Thus, it was pertinent to examine the pre-requisites of e-exams to promote it as a useful tool for the smooth conduct of exams in the aforesaid nations. Against such a backdrop, this study was conducted during January to March 2021 on 207 students enrolled in four universities, three situated in the National Capital Territory (NCT) of Delhi, India: Delhi University (DU), Jamia Millia Islamia (JMI), and Jawaharlal Nehru University (JNU), and one situated in Saudi Arabia, namely Saudi Electronic University (SEU). A quantitative approach was employed for the study, with the responses recorded via web questionnaires. Confirmatory -factor analysis (CFA) was applied in the study to examine whether the process of conducting online examinations is being chosen as the appropriate form of assessment, ensuring the safety and well-being of students through AMOS (version 24) software. For determining the reliability of the two latent constructs, namely "Perceptions of students towards E-exams (PSE)" and "Pre-requisites of E-exams (POE)," Cronbach's alpha was used through SPSS (version 25) software in the study, and the results reveal that the strong internal consistency exists between all the measured variables. In addition, the mean and standard deviation were used by the researchers to find out the pre-requisites of the online examination system. The participants expressed their insights on the relative benefits of online examination. Their perception was based on pedagogy, validity and reliability, affective factors, practicality, and security. From their insights, it was concluded that online examination is more advantageous than conventional paper-based exams. The outcome also applies to the authenticity of grading and the overall efficiency concerning the time, effort, and expenditure on conducting the examination. Contrarily, the participating students also recognized numerous hurdles in implementing e-exams concerning security, validity, and impartiality. The conclusion further revealed that online examination is especially relevant for formative assessment of learning instead of summative assessment, provided authenticity, security, and flexibility are used as fundamental tenants in the proper implementation of e-exams. The outcome of the present study will facilitate higher education institutions and policymakers in taking the electronic examination system to the next level.},
  keywords = {Authenticity,Cheating,Colleges & universities,Computer programs,Computers,COVID-19,Developing countries,Education,Environmental Sciences,Environmental Sciences & Ecology,Factor analysis,formative assessment,Higher education,Higher education institutions,Institutions,Internet,Intranets,LDCs,learners' perception,Learning,Life Sciences & Biomedicine,Methods,online examinations,Pandemics,Perception,Public Environmental & Occupational Health,Questionnaires,Reliability aspects,Safety,Science & Technology,Security,Software,Software reliability,Students,summative assessment,Warts},
  file = {/Users/colin.madland/Zotero/storage/P56DJTTX/khanLearnersPerspectiveEExams2021.pdf}
}

@article{khanOnlineAssessmentsExploring2019,
  title = {Online Assessments: {{Exploring}} Perspectives of University Students},
  shorttitle = {Online Assessments},
  author = {Khan, Sarah and Khan, Rashid Azim},
  year = {2019},
  journal = {Education and Information Technologies},
  volume = {24},
  number = {1},
  pages = {661--677},
  issn = {1360-2357, 1573-7608},
  doi = {10/gkpz6g},
  urldate = {2021-08-01},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/GL5U92DS/khanOnlineAssessmentsExploring2019.pdf}
}

@article{khanOnlineInstructionCOVID192021,
  title = {Online {{Instruction}} during {{COVID-19}} at {{Public Universities}} in {{Bangladesh}}: {{Teacher}} and {{Student Voices}}},
  author = {Khan, Rubina and Basu, Bijoy Lal and Bashir, Ahmed and Uddin, Md. Elias},
  year = {2021},
  month = may,
  journal = {TESL-EJ},
  volume = {25},
  number = {1},
  publisher = {TESL-EJ},
  issn = {1072-4303},
  abstract = {In the context of the COVID-19 pandemic, which disrupted face-to-face teaching globally, educational institutions in Bangladesh adopted online instruction as the best available alternative. Since teachers and students were not quite familiar with remote teaching, it was deemed necessary to gauge their level of preparedness for online instruction. This study investigated the perceptions of teachers and students of public universities, and examined their views of online pedagogy, assessment and the major challenges faced. Data were collected from 158 teachers and 1468 students through survey questionnaires and Focus Group Discussions. Results indicate that participants had favourable attitudes towards online classes, but they expressed concern for students who they thought were marginalized due to lack of digital devices and poor internet connectivity. Inadequate teacher preparation, lack of familiarity with online pedagogy, limited know-how of online assessment and issues of affordability and equity were reported to be the major threats. Initial insights highlight the need for supporting the disadvantaged students as well as training teachers to employ appropriate tools and techniques for teaching and assessing online.},
  keywords = {Access to Computers,Access to Education,Bangladesh,Barriers,College Faculty,College Students,COVID-19,Disadvantaged,Distance Education,Electronic Learning,Emergency Programs,Equal Education,Foreign Countries,Internet,No DOI found,Online Courses,Pandemics,Public Colleges,Readiness,Student Attitudes,Student Evaluation,Teacher Attitudes,Technological Literacy}
}

@article{khanServantLeadershipFollowers2022,
  title = {Servant {{Leadership}} and {{Followers Prosocial Rule-Breaking}}: {{The Mediating Role}} of {{Public Service Motivation}}},
  author = {Khan, Naqi and Zada, M. and Ullah, Asad and Khattak, Afraseyab and Han, Heesup and {Ariza-Montes}, Antonio and {Araya-Castilo}, Luis},
  year = {2022},
  month = jul,
  journal = {Frontiers in Psychology},
  doi = {10.3389/FPSYG.2022.848531},
  abstract = {This research explores the effect of servant leadership on prosocial rule-breaking (PSRB) and the mediating mechanism of public service motivation (PSM) between the association of servant leadership and PSRB. The said phenomenon is examined in the civil service context of Pakistan during the continuing crises of the COVID-19 pandemic, a situation where the traditional civil service policy and rule system has become highly complicated for passionate employees' service performance and efficiency, and where servant leadership has received greater attention for inspiring the attitudinal and behavioral outcomes of frontline workers during the pandemic. Data were collected from 546 frontline workers of the corona relief tiger force. The findings of the study revealed that servant leadership has a significant effect on PSRB and PSM, and that PSM significantly promotes PSRB. The results also revealed that servant leadership has a significant impact on PSRB via engendering PSM.}
}

@article{khanTechnologyEnhancedAssessment2020,
  title = {Technology {{Enhanced Assessment}} ({{TEA}}) in {{COVID}} 19 {{Pandemic}}},
  author = {Khan, Rehan Ahmed and Jawaid, Masood},
  year = {2020},
  journal = {Pakistan journal of medical sciences},
  volume = {36},
  number = {4},
  pages = {S108-S110},
  publisher = {Professional Medical Publications},
  address = {SADDAR},
  issn = {1682-024X},
  doi = {10.12669/pjms.36.COVID19-S4.2795},
  abstract = {Online teaching and learning is not a new phenomenon. For the last many years, it has been mainly used as a part of face to face teaching. Assessment is an essential part of teaching and learning, as it establishes the achievement of course learning outcomes by the students. Computer-based assessment is in place for a long time now, however, online assessments have been less practiced. This is because of the issues of validity, reliability and dishonesty. During the COVID 19 pandemic, the educational environment has taken a paradigm shift in many medical schools, both nationally and internationally. This situation demands a method of assessment that is safe, valid, reliable, acceptable, feasible and fair. This paper describes the different formats of online assessment and their application in formative and summative assessments during and after the COVID 19 pandemic.},
  keywords = {COVID 19,General & Internal Medicine,Life Sciences & Biomedicine,Medicine General & Internal,Online assessment,Pandemic,Science & Technology,Short Communication,Technology enhanced assessment},
  file = {/Users/colin.madland/Zotero/storage/5V5D4NDG/khanTechnologyEnhancedAssessment2020.pdf}
}

@article{khokharTeachingCOVID19Pandemic2022,
  title = {Teaching during {{COVID-19 Pandemic}}: {{Students}}' {{Experiences}}, {{Perceptions}} and {{Lessons}} for {{Higher Education Institutes}}},
  author = {Khokhar, {\relax AJ}},
  year = {2022},
  journal = {International Journal of Educational Sciences},
  volume = {38},
  number = {1-3},
  pages = {24--33},
  issn = {0975-1122},
  doi = {10.31901/24566322.2022/38.1-3.1233},
  abstract = {A sudden shift to complete online teaching and learning due to the COVID-19 pandemic created many challenges for educational institutes, their administrators, teachers and students. This study investigated students' online teaching experiences with the intention to shape higher education institutes' (HEI) Information and Communication Technology (ICT) integration policies and practices. A mixed-method research approach was used to collect data. The quantitative data were collected using a survey questionnaire and focus group discussion method was used to gather qualitative data. The students' views of their instructors' online instructional and assessment strategies revealed that teachers confined themselves to the university guidelines and used the recommended learning management system (LMS) and digital tools but lacked the training to utilise many of the features available in the recommended LMS and digital tools that could be integrated with the LMS due to poor knowledge and ICT skills. This study suggests that HEIs should invest in research to understand students' choices of digital tools and train teachers to maximise the use of the LMS.},
  langid = {english},
  keywords = {COVID-19 Pandemic,Digital Tools,English Course,Higher Education Institute,Learning Management System,Online Teaching,TECHNOLOGY}
}

@article{khosraviExplainableArtificialIntelligence2022,
  title = {Explainable {{Artificial Intelligence}} in Education},
  author = {Khosravi, Hassan and Shum, Simon Buckingham and Chen, Guanliang and Conati, Cristina and Tsai, Yi-Shan and Kay, Judy and Knight, Simon and {Martinez-Maldonado}, Roberto and Sadiq, Shazia and Ga{\v s}evi{\'c}, Dragan},
  year = {2022},
  month = jan,
  journal = {Computers and Education: Artificial Intelligence},
  volume = {3},
  pages = {100074},
  issn = {2666-920X},
  doi = {10.1016/j.caeai.2022.100074},
  abstract = {There are emerging concerns about the Fairness, Accountability, Transparency, and Ethics (FATE) of educational interventions supported by the use of Artificial Intelligence (AI) algorithms. One of the emerging methods for increasing trust in AI systems is to use eXplainable AI (XAI), which promotes the use of methods that produce transparent explanations and reasons for decisions AI systems make. Considering the existing literature on XAI, this paper argues that XAI in education has commonalities with the broader use of AI but also has distinctive needs. Accordingly, we first present a framework, referred to as XAI-ED, that considers six key aspects in relation to explainability for studying, designing and developing educational AI tools. These key aspects focus on the stakeholders, benefits, approaches for presenting explanations, widely used classes of AI models, human-centred designs of the AI interfaces and potential pitfalls of providing explanations within education. We then present four comprehensive case studies that illustrate the application of XAI-ED in four different educational AI tools. The paper concludes by discussing opportunities, challenges and future research needs for the effective incorporation of XAI in education.},
  keywords = {AI in Education,Explainable AI,Open learner models},
  file = {/Users/colin.madland/Zotero/storage/M5F3PPAN/khosraviExplainableArtificialIntelligence2022.pdf}
}

@article{khosraviTopicDependencyModels2018,
  title = {Topic {{Dependency Models}}: {{Graph-Based Visual Analytics}} for {{Communicating Assessment Data}}},
  author = {Khosravi, Hassan and Cooper, Kendra M. L.},
  year = {2018},
  month = jan,
  journal = {Journal of Learning Analytics},
  volume = {5},
  number = {3},
  pages = {136--153},
  publisher = {Journal of Learning Analytics},
  issn = {1929-7750},
  abstract = {Educational environments continue to evolve rapidly to address the needs of diverse, growing student populations while embracing advances in pedagogy and technology. In this changing landscape, ensuring consistency among the assessments for different offerings of a course (within or across terms), providing meaningful feedback about student achievements, and tracking student progress over time are all challenging tasks, particularly at scale. Here, a collection of visual Topic Dependency Models (TDMs) is proposed to help address these challenges. It uses statistical models to determine and visualize student achievements on one or more topics and their dependencies at a course level reference TDM (e.g., CS 100) as well as assessment data at the classroom level (e.g., students in CS 100 Term 1 2016 Section 001), both at one point in time (static) and over time (dynamic). The collection of TDMs share a common two-weighted graph foundation. Exemplar algorithms are presented for the creation of the course reference and selected class (static and dynamic) TDMs; the algorithms are illustrated using a common symbolic example. Studies on the application of the TDM collection on datasets from two university courses are presented; these case studies utilize the open-source, proof of concept tool under development.},
  keywords = {Academic Achievement,Computer Science Education,Graphs,Models,No DOI found,Statistical Analysis,Student Evaluation,Undergraduate Students}
}

@article{kilisMetacognitionCommunitiesInquiry2018,
  title = {Metacognition within a {{Communities}} of {{Inquiry Questionnaire}}: {{Validity}} and {{Reliability Study}} of {{Turkish Adaptation}}},
  author = {Kilis, Selcan and Y{\i}ld{\i}r{\i}m, Zahide},
  year = {2018},
  journal = {KEFAD},
  volume = {19},
  number = {1},
  pages = {14},
  abstract = {This study aims to translate metacognition within a Communities of Inquiry questionnaire into Turkish and administer its validity and reliability issues. Translation of the 26 items was completed by eight experts separately and back-translated by two language experts. For pilot testing, data was collected from 304 students enrolled in fully-online associate degree programs at a well-known public university in Turkey. The data was analyzed using IBM SPSS AMOS version 21.0 via confirmatory factor analysis for its validity, and internal consistency values via Cronbach alpha values for its reliability. Confirmatory factor analysis indicated acceptable fit indices regarding validity, and Cronbach alpha values indicated a high level reliability. Therefore, the Turkish Metacognition Within CoI Questionnaire may be used to measure learners' metacognitive skills in collaborative communities of inquiry. This study therefore fills a gap in the literature with the Turkish Metacognition Within CoI Questionnaire for the use of Turkish researchers and educators in their studies and learning environment.},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/GF49WLET/kilisMetacognitionCommunitiesInquiry2018.pdf}
}

@book{killePEEROBSERVATIONONLINE2015,
  title = {{{PEER OBSERVATION IN THE ONLINE LEARNING ENVIRONMENT The Case}} of {{Aviation Higher Education}}},
  author = {Kille, T and Bates, P and Murray, {\relax PS}},
  editor = {Klopper, C and Drew, S},
  year = {2015},
  series = {{{TEACHING FOR LEARNING AND LEARNING FOR TEACHING}}: {{PEER REVIEW OF TEACHING IN HIGHER EDUCATION}}},
  volume = {19},
  pages = {97},
  doi = {10.1007/978-94-6300-289-9},
  isbn = {978-94-6300-287-5},
  langid = {english},
  keywords = {DISTANCE,FORMATIVE ASSESSMENT,TECHNOLOGY}
}

@incollection{kimberDesigningNextGenerationAssessment2014,
  title = {Designing {{Next-Generation Assessment}}},
  booktitle = {Designing {{Assessment}} for {{Quality Learning}}},
  author = {Kimber, Kay and {Wyatt-Smith}, Claire},
  editor = {{Wyatt-Smith}, Claire and Klenowski, Valentina and Colbert, Peta},
  year = {2014},
  volume = {1},
  pages = {357--371},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-94-007-5902-2_22},
  urldate = {2022-05-07},
  isbn = {978-94-007-5901-5 978-94-007-5902-2},
  file = {/Users/colin.madland/Zotero/storage/Z4Y79ICN/kimberDesigningNextGenerationAssessment2014.pdf}
}

@article{kimmonsEducationScholarsEvolving2016,
  title = {Education Scholars' Evolving Uses of Twitter as a Conference Backchannel and Social Commentary Platform: {{Twitter}} Backchannel Use},
  shorttitle = {Education Scholars' Evolving Uses of Twitter as a Conference Backchannel and Social Commentary Platform},
  author = {Kimmons, Royce and Veletsianos, George},
  year = {2016},
  month = may,
  journal = {British Journal of Educational Technology},
  volume = {47},
  number = {3},
  pages = {445--464},
  issn = {00071013},
  doi = {10.1111/bjet.12428},
  urldate = {2022-05-24},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/HXILQ4Z9/kimmonsEducationScholarsEvolving2016.pdf}
}

@incollection{kimReimaginingAssessmentPlay2020,
  title = {Reimagining {{Assessment Through Play}}: {{A Case Study}} of {{MetaRubric}}},
  shorttitle = {Reimagining {{Assessment Through Play}}},
  booktitle = {Re-Imagining {{University Assessment}} in a {{Digital World}}},
  author = {Kim, Yoon Jeon and Rosenheck, Louisa},
  editor = {Bearman, Margaret and Dawson, Phillip and Ajjawi, Rola and Tai, Joanna and Boud, David},
  year = {2020},
  volume = {7},
  pages = {263--276},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-41956-1_18},
  urldate = {2022-03-19},
  isbn = {978-3-030-41955-4 978-3-030-41956-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/LQ5UG28Y/kimReimaginingAssessmentPlay2020.pdf}
}

@article{kimStudentsAcademicUse2020,
  title = {Students' {{Academic Use}} of {{Mobile Technology}} and {{Higher-Order Thinking Skills}}: {{The Role}} of {{Active Engagement}}},
  author = {Kim, Hye Jeong and Yi, Pilnam and Hong, Ji In},
  year = {2020},
  journal = {Education Sciences},
  volume = {10},
  issn = {EISSN-2227-7102},
  doi = {10/gmbvx4},
  abstract = {The academic use of mobile technology engages students beyond traditional classroom contexts. Over the past few years, higher education institutions have promoted students' learning and growth by supporting their use of mobile technology. Mobile technology offers educational possibilities that can enhance students' growth in higher education. The aim of this study is to examine the relationship between college students' academic use of mobile technology and higher-order thinking skills through their active engagement and learning effort. The sample consisted of 456 students at a university in South Korea, and the data were analyzed using partial least squares structural equation modeling. The results suggest that the academic use of mobile technology influences students' higher-order thinking skills directly, in addition to their learning effort and active engagement in courses. These findings provide valuable information for higher education institutions that seek to introduce interactive and technology-integrated environments.},
  keywords = {Academic Achievement,College Students,Foreign Countries,Handheld Devices,Learner Engagement,Technology Uses in Education,Thinking Skills}
}

@article{kimSupplementaryDiscourseForming2023,
  title = {Supplementary {{Discourse}} - {{Forming}} an {{Online Learning Community}} with {{Asynchronous Discussions}}},
  author = {Kim, Yongbeom and Wijaya Ong, Christoper Ivan and Fung, Fun Man},
  year = {2023},
  month = feb,
  journal = {Journal of Chemical Education},
  volume = {100},
  number = {2},
  pages = {496--506},
  publisher = {American Chemical Society},
  issn = {0021-9584},
  doi = {10.1021/acs.jchemed.2c00553},
  abstract = {The use of social media platforms to promote social interaction in a digital classroom is a common approach used by many educators. However, implementing such a platform is met with many challenges, the biggest being student shyness and reluctance in participating publicly. In this paper, we introduce the Supplementary Discourse (SD) model, inspired by the Supplementary Instruction (SI) model, where the goal is to promote student--student interactions in an online space. The SD model is also applied in an introductory organic chemistry course using Discord, a channel-based social media platform. By engaging students with tutors and discussion questions, we successfully catalyzed the formation of a student learning community, with the Discord server accumulating an average of 86 messages per week in a 13-week period, with students commenting that they felt less intimidated to ask questions in the server.},
  file = {/Users/colin.madland/Zotero/storage/SN2IKKXS/kimSupplementaryDiscourseForming2023.pdf}
}

@article{kimTechnologyEnhancedFeedbackStudent2018,
  title = {Technology-{{Enhanced Feedback}} on {{Student Writing}} in the {{English-Medium Instruction Classroom}}},
  author = {Kim, Victoria},
  year = {2018},
  month = dec,
  journal = {English Teaching},
  volume = {73},
  number = {4},
  pages = {29--53},
  publisher = {English Teaching},
  issn = {1017-7108},
  abstract = {High quality and timely assessment feedback is central to student learning in higher education; however, written feedback has many limitations. One of the innovative approaches to delivering feedback to EFL learners is individualized audio-visual feedback (AVF) using screencast technology. Previous research on AVF has been extensively descriptive and mostly focused on student preferences for feedback and evaluation of various screencast software. The present study employed a mixed-method design using pre-post writing tasks and pre-post questionnaires to investigate what particularly beneficial affordances this type of media-rich feedback might offer for writers in the English-Medium Instruction (EMI) classroom, to identify the effects of AVF on changes in learners' motivation, and to explore students' perceptions towards screencast feedback. The results suggest that AVF is positively received by EFL learners and that simultaneous visual cues and detailed explanations promote better understanding, engagement, and active listening. In addition, AVF significantly improves learners' writing performance and academic motivation. The paper concludes with practical implications and suggestions for further research.},
  keywords = {Affordances,Audiovisual Instruction,Business Communication,Business English,Feedback (Response),Foreign Countries,Formative Evaluation,Language of Instruction,Listening Skills,Motivated Strategies for Learning Questionnaire,Multiple DOI,Second Language Learning,Self Efficacy,South Korea,Student Motivation,Technology Integration,Undergraduate Students,Value Judgment,Writing Achievement}
}

@article{kimValidationFitnessSwitching2023,
  title = {Validation of {{Fitness Switching Costs Scale}} ({{FSCS}}): {{Examining}} the {{Factor Structure}} and {{Measurement Precision}}},
  shorttitle = {Validation of {{Fitness Switching Costs Scale}} ({{FSCS}})},
  author = {Kim, Kyungyeol (Anthony) and Lee, Senyung},
  year = {2023},
  month = jul,
  journal = {Measurement in Physical Education and Exercise Science},
  volume = {27},
  number = {3},
  pages = {257--268},
  issn = {1091-367X, 1532-7841},
  doi = {10.1080/1091367X.2023.2171294},
  urldate = {2024-02-22},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/K6LSDDQC/kimValidationFitnessSwitching2023.pdf}
}

@misc{kimWritingTimeChatGPT2024,
  title = {Writing in the {{Time}} of {{ChatGPT}}},
  author = {Kim, Jane E.},
  year = {2024},
  journal = {Christian Scholar's Review},
  urldate = {2024-01-18},
  abstract = {It seems that every day brings news of a development in AI technology, whether advances in the medical or tech fields, new threats to (cyber)security, or concerns for industries that...},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/SL6BXZJ8/writing-in-the-time-of-chatgpt.html}
}

@article{kingConversationArtificialIntelligence2023,
  title = {A {{Conversation}} on {{Artificial Intelligence}}, {{Chatbots}}, and {{Plagiarism}} in {{Higher Education}}},
  author = {King, Michael R. and {chatGPT}},
  year = {2023},
  month = jan,
  journal = {Cellular and Molecular Bioengineering},
  pages = {s12195-022-00754-8},
  issn = {1865-5025, 1865-5033},
  doi = {10.1007/s12195-022-00754-8},
  urldate = {2023-01-08},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/PZC7N6RR/kingConversationArtificialIntelligence2023.pdf}
}

@phdthesis{kingRealistEvaluationEducational2017,
  title = {The Realist Evaluation of Educational Technology},
  author = {King, Melanie},
  year = {2017},
  abstract = {Purpose - This thesis considers the best way to address the challenges faced by educators, institutions and funding bodies trying to not only develop and implement educational technology successfully but tackle the challenge of understanding and evidencing what works (and what does not) and why. The aim of the research was to find and validate an evaluation method that provided usable and useful evidence.},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/ZWULMRJV/kingRealistEvaluationEducational2017.pdf}
}

@article{kingTeachingPartialIntervalRecording2021,
  title = {Teaching {{Partial-Interval Recording}} of {{Problem Behavior}} with {{Virtual Reality}}},
  author = {King, Seth A. and Dzenga, Chaidamoyo and Burch, Taneal and Kennedy, Krystal},
  year = {2021},
  month = jun,
  journal = {Journal of Behavioral Education},
  volume = {30},
  number = {2},
  pages = {202--225},
  publisher = {Journal of Behavioral Education},
  issn = {1053-0819},
  doi = {10.1007/s10864-019-09363-4},
  abstract = {Virtual reality (VR) places individuals within a simulated experience using an array of visual, auditory, and tactile interfaces. Research suggests VR, which facilitates the rehearsal of actual job duties and performance assessment during training, may improve professional development across a range of disciplines. Although studies incorporating technology into professional development for educators are increasingly common, few have examined the potential for VR as a training tool. Direct observation represents a fundamental skill for professionals involved in behavior change. The present study evaluated the effectiveness of an automated simulation in teaching graduate and undergraduate students (N = 31) to collect partial-interval recording data pertaining to inappropriate behavior. Participants were randomly assigned to either a control condition or intervention condition consisting of a brief simulated observation of a student exhibiting problem behavior. Results suggest participants who used VR were more confident in their ability to collect data; however, evidence for improved outcomes related to data collection was not identified. These mixed findings provide tentative support for further research in this area.},
  keywords = {Behavior Change,Behavior Problems,College Students,Computer Simulation,Data Collection,Intervention,Program Effectiveness,Self Efficacy,Student Behavior,Teacher Education Programs,Training}
}

@article{kirknessFirstNationsHigher1991,
  title = {First {{Nations}} and {{Higher Education}}: {{The Four R}}'s-- {{Respect}}, {{Relevance}}, {{Reciprocity}}, {{Responsibility}}.},
  author = {Kirkness, Verna J. and Barnhardt, Ray},
  year = {1991},
  month = may,
  journal = {Journal of American Indian Education},
  volume = {30},
  number = {3},
  pages = {1--15},
  abstract = {AMERICAN INDIAN/FIRST NATIONS/NATIVE PEOPLE have been historically under-represented in the ranks of college and university graduates in Canada and the United States. From an institutional perspective, the problem has been typically defined in terms of low achievement, high attrition, poor retention, weak persistence, etc., thus placing the onus for adjustment on the student. From the perspective of the Indian student, however, the problem is often cast in more human terms, with an emphasis on the need for a higher educational system that respects them for who they are, that is relevant to their view of the world, that offers reciprocity in their relationships with others, and that helps them exercise responsibility over their own lives. This paper examines the implications of these differences in perspective and identifies ways in which initiatives within and outside of existing institutions are transforming the landscape of higher education for First Nations/American Indian people in both Canada and the United States.},
  keywords = {BARNHARDT Ray 1939-,FIRST Nations & Higher the Four Rs: Respect Relevance Reciprocity Responsibility (Book),KIRKNESS Verna J.},
  file = {/Users/colin.madland/Zotero/storage/FFUAC6LA/kirknessFirstNationsHigher1991.pdf}
}

@article{kirkwoodMissingEvidenceScholarly2013,
  title = {Missing: Evidence of a Scholarly Approach to Teaching and Learning with Technology in Higher Education},
  author = {Kirkwood, Adrian and Price, Linda},
  year = {2013},
  journal = {Teaching in Higher Education},
  volume = {18},
  number = {3},
  pages = {327--337},
  publisher = {Taylor \& Francis Group},
  address = {Abingdon},
  issn = {1356-2517},
  doi = {10.1080/13562517.2013.773419},
  abstract = {As technology is increasingly being used for teaching and learning in higher education, it is important to scrutinise what tangible educational gains are being attained. Are claims about technology transforming learning and teaching in higher education borne out by actual practices? This paper draws upon a critical analysis of recent research literature concerning Technology Enhanced Learning (TEL). It argues that few published accounts of TEL practices show evidence of a scholarly approach to university teaching. Frequently, TEL interventions appear to be technology-led rather than responding to identified teaching and learning issues. The crucial role of teachers' differing conceptions of teaching and of the purpose of professional development activities is often ignored. We argue that developing a more scholarly approach among university teachers is more essential than providing technical training if practices are to be improved to maximise the effectiveness of TEL.},
  keywords = {Higher education,scholarship of teaching and learning,student learning,Teaching,teaching in higher education,technological determinism,technology enhanced learning},
  file = {/Users/colin.madland/Zotero/storage/FGKCANUR/kirkwoodMissingEvidenceScholarly2013.pdf}
}

@article{kirkwoodTechnologyenhancedLearningTeaching2014,
  title = {Technology-Enhanced Learning and Teaching in Higher Education: What Is `Enhanced' and How Do We Know? {{A}} Critical Literature Review},
  shorttitle = {Technology-Enhanced Learning and Teaching in Higher Education},
  author = {Kirkwood, Adrian and Price, Linda},
  year = {2014},
  month = jan,
  journal = {Learning, Media and Technology},
  volume = {39},
  number = {1},
  pages = {6--36},
  issn = {1743-9884, 1743-9892},
  doi = {10.1080/17439884.2013.770404},
  urldate = {2022-07-07},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/XD59LH3I/kirkwoodTechnologyenhancedLearningTeaching2014.pdf}
}

@book{kirschenbaumWadJaGetGradingGame2020,
  title = {Wad-{{Ja-Get}}?: {{The Grading Game}} in {{American Education}}, 50th {{Anniversary Edition}}},
  shorttitle = {Wad-{{Ja-Get}}?},
  author = {Kirschenbaum, Howard and Napier, Rodney and Simon, Sidney and Fishman, Barry},
  year = {2020},
  publisher = {Maize Books},
  address = {Ann Arbor, MI},
  doi = {10.3998/mpub.11900733},
  urldate = {2021-01-30},
  isbn = {978-1-60785-679-5 978-1-60785-681-8},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/I3CA5BXR/kirschenbaumWadJaGetGradingGame2020.pdf}
}

@article{kirschnerAwarenessCognitiveSocial2015,
  title = {Awareness of Cognitive and Social Behaviour in a {{CSCL}} Environment},
  author = {Kirschner, P. A. and Kreijns, K. and Phielix, C. and Fransen, J.},
  year = {2015},
  month = feb,
  journal = {Journal of Computer Assisted Learning},
  volume = {31},
  pages = {59--77},
  issn = {1365-2729},
  doi = {10.1111/jcal.12084},
  abstract = {Most distributed and virtual online environments for and pedagogies of computer-supported collaborative learning (CSCL) neglect the social and social-emotional aspects underlying the group dynamics of learning and working in a CSCL group. These group dynamics often determine whether the group will develop into a well-performing team and whether a sound social space emerges. Using a theory-based CSCL framework, two studies evaluated whether two tools, Radar and Reflector, supported cognitive, social and socio-emotional aspects of team development, encouraging promotive interaction and group processing in the teams. While not affecting product quality, tool use did lead to groups who perceived their team as being better developed, as having higher levels of group satisfaction and lower levels of conflicts. The results support that promotive interaction and group processing was increased by using Radar and Reflector.},
  keywords = {CSCL,group processing,promotive interaction,social interaction,social space}
}

@article{kirschnerCognitiveLoadApproach2009,
  title = {A {{Cognitive Load Approach}} to {{Collaborative Learning}}: {{United Brains}} for {{Complex Tasks}}},
  author = {Kirschner, Femke and Paas, Fred and Kirschner, Paul},
  year = {2009},
  journal = {Educational Psychology Review},
  volume = {21},
  number = {1},
  pages = {31--42},
  abstract = {This article presents a review of research comparing the effectiveness of individual learning environments with collaborative learning environments. In reviewing the literature, it was determined that there is no clear and unequivocal picture of how, when, and why the effectiveness of these two approaches to learning differ, a result which may be due to differing complexities of the learning tasks used in the research and the concomitant load imposed on the learner{\quotesinglbase}{\"A}{\^o}s cognitive system. Based upon cognitive load theory, it is argued that learning by an individual becomes less effective and efficient than learning by a group of individuals as task complexity increases. Dividing the processing of information across individuals is useful when the cognitive load is high because it allows information to be divided across a larger reservoir of cognitive capacity. Although such division requires that information be recombined and that processing be coordinated, under high load conditions, these costs are minimal compared to the gain achieved by this division of labor. In contrast, under low load conditions, an individual can adequately carry out the required processing activities, and the costs of recombination and coordination are relatively more substantial. Implications of these ideas for research and practice of collaborative learning are discussed.},
  keywords = {Behavioral,Science}
}

@article{kitchenhamIndigenousLearningPreferences2017,
  title = {Indigenous {{Learning Preferences}} and {{Interactive Technologies}}},
  author = {Kitchenham, Andrew},
  year = {2017},
  journal = {Australian Journal of Indigenous Education},
  volume = {46},
  number = {1},
  pages = {71--79},
  issn = {1326-0111},
  doi = {10.1017/jie.2016.12},
  abstract = {This three-year research study examined the influence of interactive technologies on the math achievement of Indigenous students in Years 4, 5, 6 and 7 technology-equipped classrooms in a rural elementary school in British Columbia, Canada. Using a mixed-methods approach, the researcher conducted semistructured interviews and collected math achievement data (reported elsewhere) over a three-year span, and distributed a survey to the teachers in the second year of the study. All data sources revealed that interactive technologies such as SMARTBoards, student response systems and document cameras influence positively Indigenous students' math achievement over a three-year period.},
  keywords = {Cognitive style,Data Collection,Educational Technology,Elementary School Mathematics,Elementary School Students,Foreign Countries,Grade 3,Grade 4,Grade 5,Grade 6,Indigenous Populations,Interaction,Learning,Mathematics Achievement,Mathematics Instruction,Mixed Methods Research,Preferences,Rural Schools,Semi Structured Interviews,Students,Studies}
}

@article{kivunjaDistinguishingTheoryTheoretical2018,
  title = {Distinguishing between {{Theory}}, {{Theoretical Framework}}, and {{Conceptual Framework}}: {{A Systematic Review}} of {{Lessons}} from the {{Field}}},
  shorttitle = {Distinguishing between {{Theory}}, {{Theoretical Framework}}, and {{Conceptual Framework}}},
  author = {Kivunja, Charles},
  year = {2018},
  month = dec,
  journal = {International Journal of Higher Education},
  volume = {7},
  number = {6},
  pages = {44},
  issn = {1927-6052, 1927-6044},
  doi = {10/ggwrx2},
  urldate = {2021-06-29},
  abstract = {Across many years of teaching Research Methods and assessing many applications for admission into higher degree studies which require an understanding of theories, principles, strategies and skills needed to complete a higher degree such as a Masters or a PhD, one of the things I have found problematic for many students is the inability to articulate differences between theory, theoretical framework and a conceptual framework for a proposed research project. This paper uses experiential methodology to draw upon my experience in practice, and systematic literature review methodology to draw upon supporting scholarly literature by leaders in the field, to contribute to existing knowledge on the meaning of each of these concepts, and more importantly to distinguish between them in a study of Research Methods, and in particular as they relate to designing a research proposal and a thesis for a higher degree. The primary aim is to help the reader develop a firm grasp of the meaning of these concepts and how they should be used in academic research discourses. The review answers five questions. 1. What does each of these terms mean? 2. When and how should each be used? 3. What purposes does a theoretical framework serve? 4. How do you develop a theoretical framework for your research proposal or thesis? 5. What does a good theoretical framework look like?},
  file = {/Users/colin.madland/Zotero/storage/XSGG4Z5R/kivunjaDistinguishingTheoryTheoretical2018.pdf}
}

@article{kizilcecScalingBehavioralScience2020,
  title = {Scaling up Behavioral Science Interventions in Online Education},
  author = {Kizilcec, Ren{\'e} F. and Reich, Justin and Yeomans, Michael and Dann, Christoph and Brunskill, Emma and Lopez, Glenn and Turkay, Selen and Williams, Joseph Jay and Tingley, Dustin},
  year = {2020},
  month = jun,
  journal = {Proceedings of the National Academy of Sciences},
  pages = {201921417},
  issn = {0027-8424, 1091-6490},
  doi = {10/gg2c6t},
  urldate = {2020-06-17},
  abstract = {Online education is rapidly expanding in response to rising demand for higher and continuing education, but many online students struggle to achieve their educational goals. Several behavioral science interventions have shown promise in raising student persistence and completion rates in a handful of courses, but evidence of their effectiveness across diverse educational contexts is limited. In this study, we test a set of established interventions over 2.5 y, with one-quarter million students, from nearly every country, across 247 online courses offered by Harvard, the Massachusetts Institute of Technology, and Stanford. We hypothesized that the interventions would produce medium-to-large effects as in prior studies, but this is not supported by our results. Instead, using an iterative scientific process of cyclically preregistering new hypotheses in between waves of data collection, we identified individual, contextual, and temporal conditions under which the interventions benefit students. Self-regulation interventions raised student engagement in the first few weeks but not final completion rates. Value-relevance interventions raised completion rates in developing countries to close the global achievement gap, but only in courses with a global gap. We found minimal evidence that state-of-the-art machine learning methods can forecast the occurrence of a global gap or learn effective individualized intervention policies. Scaling behavioral science interventions across various online learning contexts can reduce their average effectiveness by an order-of-magnitude. However, iterative scientific investigations can uncover what works where for whom.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/7SATXRUG/kizilcecScalingBehavioralScience2020.pdf}
}

@book{kizlikHowWriteLearning2010,
  title = {How to Write Learning Objectives That Meet Demanding Behavioral Criteria},
  author = {Kizlik, Bob},
  year = {2010},
  volume = {2010}
}

@article{kleinCollegiateLearningAssessment2007,
  title = {The {{Collegiate Learning Assessment}}: {{Facts}} and {{Fantasies}}},
  author = {Klein, Stephen and Benjamin, Roger and Shavelson, Richard and Bolus, Roger},
  year = {2007},
  journal = {Evaluation review},
  volume = {31},
  number = {5},
  pages = {415--439},
  publisher = {SAGE Publications},
  address = {Los Angeles, CA},
  issn = {0193-841X},
  doi = {10.1177/0193841X07303318},
  abstract = {The Collegiate Learning Assessment (CLA) is a computer administered, open-ended (as opposed to multiple-choice) test of analytic reasoning, critical thinking, problem solving, and written communication skills. Because the CLA has been endorsed by several national higher education commissions, it has come under intense scrutiny by faculty members, college administrators, testing experts, legislators, and others. This article describes the CLA's measures and what they do and do not assess, how dependably they measure what they claim to measure, and how CLA scores differ from those on other direct and indirect measures of college student learning. For instance, analyses are conducted at the school rather than the student level and results are adjusted for input to assess whether the progress students are making at their school is better or worse than what would be expected given the progress of ``similarly situated'' students (in terms of incoming ability) at other colleges.},
  keywords = {Academic achievement,Academic success,Adolescent,Adult,Analysis,Automatic Data Processing,College Faculty,College Students,Communication,Communication Skills,Critical Thinking,Education Higher,Educational Assessment,Educational evaluation,Educational Measurement - methods,Educational Measurement - standards,Educational Status,Evaluation,Evaluation Methods,Experts,Health technology assessment,Higher Education,Humans,Learning,Legislators,Logical Thinking,Measurement Techniques,Numerical Analysis Computer-Assisted,Performance Tests,Problem Solving,Program Evaluation - methods,Program Evaluation - standards,Reliability,Scores,Scrutiny,Social Sciences,Social Sciences - Other Topics,Social Sciences Interdisciplinary,Students,Students - psychology,Test design,Thinking,U.S.A,United States,Universities - standards,Writing Skills},
  file = {/Users/colin.madland/Zotero/storage/ZME287IJ/kleinCollegiateLearningAssessment2007.pdf}
}

@article{kleinStudyingPhysicsCOVID192021,
  title = {Studying Physics during the {{COVID-19}} Pandemic: {{Student}} Assessments of Learning Achievement, Perceived Effectiveness of Online Recitations, and Online Laboratories},
  author = {Klein, P. and Ivanjek, L. and Dahlkemper, M. N. and Jeli{\v c}i{\'c}, K. and Geyer, M.-A. and K{\"u}chemann, S. and Susac, A.},
  year = {2021},
  month = mar,
  journal = {Physical Review Physics Education Research},
  volume = {17},
  number = {1},
  pages = {010117},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevPhysEducRes.17.010117},
  abstract = {The COVID-19 pandemic has significantly affected the education system worldwide, which was forced to respond with a sudden shift to distance learning. While successful distance teaching requires careful thinking, planning, and the development of technological and human resources, there was no time for preparation in the current situation. Various physics courses, including lectures, tutorials, and laboratory courses, had to be transferred to online formats, resulting in a variety of simultaneous, asynchronous, and mixed activities. To investigate how physics students perceived the sudden shift to online learning, we developed a questionnaire and gathered data from N {$\frac{1}{4}$} 578 physics students from five universities in Germany, Austria, and Croatia. In this article, we report how the problem-solving sessions (recitations) and laboratories were adapted, how students judge the different formats of the courses, and how useful and effective they perceived them. The results are correlated with the students' self-efficacy ratings and other behavioral measures (such as self-regulated learning skills). This study is descriptive in nature, and a survey study design was implemented to examine the relationships among the variables. We found that good communication abilities (r {$\frac{1}{4}$} 0.48, p{$<$}0.001) and self-organization skills (r {$\frac{1}{4}$} 0.63, p{$<$}0.001) are positively correlated with perceived learning achievement. Furthermore, the previous duration of studies had a significant impact on several self-reported achievement measures, resulting in consistently lower scores of students in their first academic year compared with students who were further along academically. We draw conclusions and suggest implications for future online classes on the instructor and faculty level. Suggestions include (i) focusing on first-year courses with on-campus teaching when facing limited lecture hall capacities, (ii) offering special courses for promoting self-regulated learning skills, (iii) emphasizing the positive aspects of distance learning, and (iv) installing networking services for supporting student communication.},
  file = {/Users/colin.madland/Zotero/storage/SBDSPBZC/kleinStudyingPhysicsCOVID192021.pdf}
}

@book{klingerClassroomAssessmentStandards2015,
  title = {Classroom {{Assessment Standards}} for {{PreK-12 Teachers}}},
  author = {Klinger, Don and McDivitt, Patricia and Howard, Barbara and Rogers, Todd and Munoz, Marco and Wylie, Caroline},
  year = {2015},
  publisher = {Joint Committee on Standards for Educational Evaluation},
  abstract = {The Joint Committee on Standards for Educational Evaluation follow a rigorous process of review to develop and disseminate the only educational standards certified by the American National Standards Institute (ANSI). The Classroom Assessment Standards are intended to provide classroom teachers in pre-kindergarten through high school with research-based principles and guidelines for effective assessment of student learning. These standards do not apply to state or district mandated tests as these are not under the control of the classroom teacher. The purpose of these standards is to guide teachers in their daily practice of evaluating student progress to improve instruction. The intended audience include the following: pre-service and in-service classroom teachers; their supervisors or administrators; staff developers; and faculty in teacher preparation programs and colleges of education. This is an excellent resource for those engaged in professional learning communities who desire to enhance their teaching practice as well as for administrators charged with evaluating that practice. The principles and guidelines contained in this book offer sound research-based practices designed to increase effective classroom instruction.},
  annotation = {Kindle}
}

@article{kliscUsePostasynchronousOnline2017,
  title = {Use of a Post-Asynchronous Online Discussion Assessment to Enhance Student Critical Thinking},
  author = {Klisc, Chris and McGill, Tanya and Hobbs, Valerie},
  year = {2017},
  journal = {Australasian Journal of Educational Technology},
  volume = {33},
  number = {5},
  pages = {63--76},
  publisher = {Charles Sturt Univ},
  address = {WAGGA WAGGA},
  issn = {1449-5554},
  doi = {10.14742/ajet.3030},
  abstract = {Asynchronous online discussion (AOD) is used in many tertiary education courses, and assessing it has been shown to enhance critical thinking outcomes. There has, however, been debate on what should be assessed and how the assessment should be implemented. The most common form of assessment involves grading the individual discussion contributions, but it has been suggested that employing a culminating task based on the AOD may be effective. This preliminary study compared the effect on student critical thinking of two approaches to AOD assessment: using a post-AOD assessment, and assessing the discussion contributions themselves. The results, though tentative, showed that while both assessment approaches resulted in significant improvements in student critical thinking, there was no difference in the impact on critical thinking skills between using the post-AOD assessment and assessing the discussion contributions. This result suggests that the form of assessment used in an AOD may be less important than the fact that assessment is included. Interviews with students also provided some insight into ways in which they perceived the discussion environment had contributed to their critical thinking skills. The findings of this study pave the way for further research in this important area. [Author abstract]},
  keywords = {Asynchronous Communication,Cognitive skills,College Freshmen,Comparative Analysis,Computer Mediated Communication,Critical Thinking,Discussion (Teaching technique),Discussion groups,Education & Educational Research,Evaluation criteria,Evaluation methods,Foreign Countries,Grading,Group discussion,Higher education,Hypothesis Testing,Information Technology,Interviews,Introductory Courses,Learning experience,Likert Scales,Mixed Methods Research,Online discussion groups,Online learning,Postsecondary education,Pretests Posttests,Quasiexperimental Design,Questionnaires,Skill Development,Social Sciences,Statistical Analysis,Student assessment,Student Evaluation,Student Participation,Student perceptions,Summative Evaluation,Task Analysis,University students},
  file = {/Users/colin.madland/Zotero/storage/TZAEKJ3A/kliscUsePostasynchronousOnline2017.pdf}
}

@article{kloppersYourFeedbackProcedure2023,
  title = {Your Feedback Procedure, My Inspiration: {{Enhancing}} Student Achievement through Assessment},
  author = {Kloppers, Magda and Potgieter, Erika},
  year = {2023},
  journal = {South African journal of education},
  volume = {43},
  number = {1},
  pages = {1--11},
  publisher = {Sabinet Online},
  address = {Bloemfontein},
  issn = {0256-0100},
  doi = {10.15700/saje.v43n1a2124},
  abstract = {Lecturers often claim that time constraints cause tension regarding feedback on students' assessment opportunities. Assessment strategies for effective feedback procedures can lead to early identification of problem areas in student performance. Numerous students at higher education institutions (HEIs) do not complete their qualifications or take up to 6 years to complete a 3-year qualification. Situations like these may be avoided if lecturers provide informative feedback fostering self-directed learning, overall enhancing student achievement. In the quantitative, non-experimental descriptive research study reported on here, a set of questions was used to determine the following: (i) feedback procedures; (ii) feedback inspiration; and (iii) reflection on feedback. The data were collected from undergraduate and postgraduate students at a South African university. The 3 categories above revealed 3 tiers that form part of a metacognitive methodology which indicates that feedback procedures do play a role in student achievement. This study contributes to the body of knowledge on assessment and feedback as well as the implications for feedback on current practices of university lecturers and students' future learning endeavours.},
  keywords = {Academic achievement,College students,Education & Educational Research,Education parks,Education Scientific Disciplines,Educational evaluation,Evaluation,Feedback,Graduate students,Higher education,Independent study,Inspiration,Learning,Learning strategies,Metacognition,School facilities,Selfdirected learning}
}

@incollection{knapperChangingTeachingPractice2010,
  title = {Changing Teaching Practice: {{Barriers}} and Strategies},
  booktitle = {Taking Stock: {{Research}} on Teaching and Learning in Higher Education},
  author = {Knapper, Christopher},
  editor = {Christensen Hughes, Julia and Mighty, Joy},
  year = {2010},
  pages = {229--242},
  publisher = {McGill-Queens University Press},
  address = {Kingston, Ont},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/NNRD36JE/knapperChangingTeachingPractice2010.pdf}
}

@book{knightAssessmentLearningHigher1995,
  title = {Assessment for Learning in Higher Education},
  author = {Knight, 1950, Peter},
  year = {1995},
  number = {Book, Whole},
  publisher = {Kogan Page},
  address = {London},
  isbn = {9781136352683;1136352686;},
  langid = {english},
  keywords = {Education Higher,Educational evaluation,Educational Measurement,Electronic books,Evaluation,Great Britain}
}

@incollection{knightAugmentingAssessmentLearning2020,
  title = {Augmenting {{Assessment}} with {{Learning Analytics}}},
  booktitle = {Re-Imagining {{University Assessment}} in a {{Digital World}}},
  author = {Knight, Simon},
  editor = {Bearman, Margaret and Dawson, Phillip and Ajjawi, Rola and Tai, Joanna and Boud, David},
  year = {2020},
  volume = {7},
  pages = {129--145},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-41956-1_10},
  urldate = {2022-03-19},
  isbn = {978-3-030-41955-4 978-3-030-41956-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/2IINFRQ8/knightAugmentingAssessmentLearning2020.pdf}
}

@article{knightFutureHigherEducation2020,
  ids = {knightFutureHigherEducation2020a},
  title = {The Future of Higher Education ({{HE}}) Hangs on Innovating Our Assessment - but Are We Ready, Willing and Able?},
  author = {Knight, G. L. and Drysdale, T. D.},
  year = {2020},
  journal = {Higher education pedagogies},
  volume = {5},
  number = {1},
  pages = {57--60},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {2375-2696},
  doi = {10.1080/23752696.2020.1771610},
  abstract = {Graduates are entering a sociotechnological world, with teaching and assessment needing to reflect that, by shifting from a 'recall-on-paper' to 'do-it-for-real'. With increasing student numbers, it is not feasible to have staff-student ratios and round-the-clock availability required to provide instant feedback and ever-more interactive teaching sessions, so digital solutions are the only option. There is already growing comfort with using computers in formal assessment; however, more work is required to extend beyond performance indicators enabling digital assessments, to addressing how students apply their learning to relevant work-based scenarios. This opinion piece discusses the issues HE currently face to ensure students develop the employability skills that equip them to be proficient in the skills directly related to their degree subject but also transferable to other graduate careers. It raises possible solutions to current technological problems in developing more computer-based assessment, to enable academics to design assessments that develop the capabilities students need.},
  keywords = {assessment diversity,College Graduates,Computer Assisted Testing,digital solutions,Education & Educational Research,Educational Trends,Employability skills,Employment Potential,Higher Education,Job Skills,Skill Development,Social Sciences,STEM Education},
  file = {/Users/colin.madland/Zotero/storage/7JM5HWTG/knightFutureHigherEducation2020.pdf}
}

@article{knightSummativeAssessmentHigher2002,
  ids = {knightSummativeAssessmentHigher2002b},
  title = {Summative {{Assessment}} in {{Higher Education}}: {{Practices}} in Disarray},
  shorttitle = {Summative {{Assessment}} in {{Higher Education}}},
  author = {Knight, Peter T.},
  year = {2002},
  month = aug,
  journal = {Studies in Higher Education},
  volume = {27},
  number = {3},
  pages = {275--286},
  issn = {0307-5079, 1470-174X},
  doi = {10/b25nb2},
  urldate = {2020-12-20},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/8AVQN6LP/knightSummativeAssessmentHigher2002.pdf}
}

@phdthesis{knowlesIdeologyEducationThreearticle2015,
  title = {Ideology and Education : A Three-Article Dissertation Exploring Implications for Democracy},
  shorttitle = {Ideology and Education},
  author = {Knowles, Ryan},
  year = {2015},
  month = may,
  doi = {10.32469/10355/46870},
  urldate = {2022-02-05},
  abstract = {The proposed dissertation follows a three article format. The articles represent distinct but interrelated strands of research; the first article focuses on developing a scale measuring teachers' orientation to social studies as citizenship education, among teachers in Missouri. The second and third explore larger theoretical questions relating to citizenship and democracy from an international context through secondary analysis. All three pieces address issues of democracy, citizenship, and education.},
  collaborator = {Castro, Antonio},
  langid = {english},
  school = {University of Missouri--Columbia},
  file = {/Users/colin.madland/Zotero/storage/6RWRFMEP/knowlesIdeologyEducationThreearticle2015.pdf}
}

@article{knoxFiveCritiquesOpen2013,
  title = {Five Critiques of the Open Educational Resources Movement},
  author = {Knox, Jeremy},
  year = {2013},
  month = nov,
  journal = {Teaching in Higher Education},
  volume = {18},
  number = {8},
  pages = {821--832},
  issn = {1356-2517},
  doi = {10.1080/13562517.2013.774354},
  abstract = {This paper will review existing literature on Open Educational Resources (OER). It is intended to examine and critique the theories which underpin the promotion of OER in higher education, not provide guidance on their implementation. (1) I will introduce the concepts of positive and negative liberty to suggest an under-theorisation of the term ?open?. (2) OER literature will be shown to endorse a two-tiered system, in which the institution is both maintained and disaggregated. (3) I will highlight a diminishing of the role of pedagogy within the OER vision and the promotion of a learner-centred model for education. (4) This stance will be aligned with humanistic assumptions of unproblematic self-direction and autonomy. (5) I will discuss the extent to which the OER movement aligns itself with economically orientated models of the university. I offer these critiques as a framework for the OER movement to develop as a theoretically rigorous area of scholarship.}
}

@article{knoxMachineBehaviourismFuture2020,
  title = {Machine Behaviourism: Future Visions of `Learnification' and `Datafication' across Humans and Digital Technologies},
  author = {Knox, Jeremy and Williamson, Ben and Bayne, Sian},
  year = {2020},
  journal = {Learning, Media and Technology},
  volume = {45},
  number = {1},
  pages = {31--45},
  publisher = {Routledge},
  issn = {1743-9884},
  doi = {10/gg9b8k}
}

@article{koenkaMetaanalysisImpactGrades2019,
  title = {A Meta-Analysis on the Impact of Grades and Comments on Academic Motivation and Achievement: A Case for Written Feedback},
  author = {Koenka, Alison C. and {Linnenbrink-Garcia}, Lisa and Moshontz, Hannah and Atkinson, Kayla M. and Sanchez, Carmen E. and Cooper, Harris},
  year = {2019},
  journal = {Educational Psychology},
  pages = {1--22},
  publisher = {Routledge},
  issn = {0144-3410},
  doi = {10/ggs2xx},
  abstract = {AbstractThis research synthesis examined the impact of grades, comments, and no performance feedback on academic motivation and achievement in elementary and secondary school. Four meta-analyses were conducted, with two each exploring the impact of (a) grades versus no performance feedback and (b) grades versus comments on academic motivation and achievement, respectively. Overall results indicated that grades positively influenced achievement but negatively influenced motivation compared to no feedback. However, compared to those who received comments, students receiving grades had poorer achievement and less optimal motivation. Moderator analyses generally suggested that overall effects varied as a function of the type of motivation (i.e. the specific construct, internal vs. external motivation), context (e.g. academic subject; comment type), student characteristics (e.g. achievement level), and methodology (i.e. grade anticipation versus receipt), though it was not possible to test these moderators in all analyses. Theoretical and methodological contributions and implications for education practice are discussed.},
  file = {/Users/colin.madland/Zotero/storage/UBIX2ANE/koenkaMetaanalysisImpactGrades2019.pdf}
}

@article{koganSparkingChangeHow2020,
  title = {Sparking {{Change}}: {{How}} a {{Shift}} to {{Step}} 1 {{Pass}}/{{Fail Scoring Could Promote}} the {{Educational}} and {{Catalytic Effects}} of {{Assessment}} in {{Medical Education}}},
  shorttitle = {Sparking {{Change}}},
  author = {Kogan, Jennifer R. and Hauer, Karen E.},
  year = {2020},
  month = sep,
  journal = {Academic Medicine},
  volume = {95},
  number = {9},
  pages = {1315--1317},
  issn = {1040-2446},
  doi = {10/ghd93c},
  urldate = {2020-10-10},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/ZYXVIIZX/koganSparkingChangeHow2020.pdf}
}

@article{kohImprovingTeachersAssessment2011,
  title = {Improving Teachers' Assessment Literacy through Professional Development},
  author = {Koh, Kim H.},
  year = {2011},
  month = sep,
  journal = {Teaching Education},
  volume = {22},
  number = {3},
  pages = {255--276},
  issn = {1047-6210, 1470-1286},
  doi = {10.1080/10476210.2011.593164},
  urldate = {2021-10-20},
  langid = {english}
}

@article{kohShiftingOnlineCOVID192022,
  title = {Shifting Online during {{COVID-19}}: {{A}} Systematic Review of Teaching and Learning Strategies and Their Outcomes},
  author = {Koh, Joyce Hwee Ling and Daniel, Ben Kei},
  year = {2022},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {19},
  number = {1},
  pages = {56--56},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-022-00361-7},
  abstract = {This systematic literature review of 36 peer-reviewed empirical articles outlines eight strategies used by higher education lecturers and students to maintain educational continuity during the COVID-19 pandemic since January 2020. The findings show that students' online access and positive coping strategies could not eradicate their infrastructure and home environment challenges. Lecturers' learning access equity strategies made learning resources available asynchronously, but having access did not imply that students could effectively self-direct learning. Lecturers designed classroom replication, online practical skills training, online assessment integrity, and student engagement strategies to boost online learning quality, but students who used ineffective online participation strategies had poor engagement. These findings indicate that lecturers and students need to develop more dexterity for adapting and manoeuvring their online strategies across different online teaching and learning modalities. How these online competencies could be developed in higher education are discussed.},
  keywords = {CAI,Computer Appl. in Social and Behavioral Sciences,Computer assisted instruction,Computer Science,Computers and Education,COVID-19,Distance learning,E-learning,Educational Technology,Emergency response teaching,Higher Education,Humanities,Information Systems Applications (incl.Internet),Law,Literature reviews,Online dexterity,Online instruction,Online learning,Online pedagogy,Pedagogy,Review,Review Article,Statistics for Social Sciences,Students},
  file = {/Users/colin.madland/Zotero/storage/75QF3S8R/kohShiftingOnlineCOVID192022.pdf}
}

@article{koneruExploringMoodleFunctionality2017,
  title = {Exploring {{Moodle Functionality For Managing Open Distance Learning E-Assessments}}},
  author = {Koneru, Indira},
  year = {2017},
  journal = {The Turkish online journal of distance education},
  volume = {18},
  number = {4},
  pages = {129--141},
  publisher = {Anadolu Univ},
  address = {ESKISEHIR},
  issn = {1302-6488},
  doi = {10.17718/tojde.340402},
  abstract = {Current and emerging technologies enable Open Distance Learning (ODL) institutions integrate e-Learning in innovative ways and add value to the existing teaching-learning and assessment processes. ODL e-Assessment systems have evolved from Computer Assisted / Aided Assessment (CAA) systems through intelligent assessment and feedback systems. E-Assessment (electronic assessment) connotes using electronic technology and tools to design and administer assessments, collect and store students' assessment evidences, grade performance, provide feedback and generate reports. The widely recognized advantages of e-Assessment over traditional, paper-based assessment include: lower long term costs, instant feedback to students, greater flexibility with respect to location and timing, improved reliability with machine marking, improved impartiality, and enhanced question styles that incorporate interactivity and multimedia. The advent of Learning Management Systems (LMS), such as Moodle (Modular Object-Oriented Dynamic Learning Environment) paved the way for integrated advanced services for: interactive dialogue, controlling knowledge at different stages of distance process and e-Assessment systems. Moodle provides the complete integrated environment for handling all aspects of e-Assessment from authoring questions through to reports for course teams (Butcher, 2008). This study explores how Moodle functionality: supports diagnostic, formative, summative and competency-based assessments and facilitates ODL institutions design, administer and manage e-Assessments.},
  keywords = {Education & Educational Research,Social Sciences},
  file = {/Users/colin.madland/Zotero/storage/AWEXI8W9/koneruExploringMoodleFunctionality2017.pdf}
}

@article{kontosEffectsRestConcussion2023,
  title = {The {{Effects}} of {{Rest}} on {{Concussion Symptom Resolution}} and {{Recovery Time}}: {{A Meta-analytic Review}} and {{Subgroup Analysis}} of 4329 {{Patients}}},
  author = {Kontos, Anthony P. and Eagle, Shawn R. and Braithwaite, Rock and Preszler, Jonathan and Manderino, Lisa and Turner, Rose L. and Jennings, Sabrina and Trbovich, Alicia and Hickey, Robert W. and Collins, Michael W. and McCrea, Michael and Nelson, Lindsay D. and Root, Jeremy and Thomas, Danny G.},
  year = {2023},
  month = feb,
  journal = {The American Journal of Sports Medicine},
  pages = {03635465221150214},
  publisher = {SAGE Publications Inc STM},
  issn = {0363-5465},
  doi = {10.1177/03635465221150214},
  urldate = {2023-03-15},
  abstract = {Background:Numerous individual studies suggest that rest may have a negative effect on outcomes following concussion.Purpose:To perform a systematic meta-analysis of the effects of prescribed rest compared with active interventions after concussion.Study Design:Meta-analysis; Level of evidence, 4.Methods:A meta-analysis (using the Hedges g) of randomized controlled trials and cohort studies was conducted to evaluate the effects of prescribed rest on symptoms and recovery time after concussion. Subgroup analyses were performed for methodological, study, and sample characteristics. Data sources were obtained from systematic search of key terms using Ovid Medline, Embase, Cochrane Database of Systematic Reviews, APA PsycINFO, Web of Science, SPORTDiscus, and ProQuest dissertations and theses through May 28, 2021. Eligible studies were those that (1) assessed concussion or mild traumatic brain injury; (2) included symptoms or days to recovery for {$\geq$}2 time points; (3) included 2 groups with 1 group assigned to rest; and (4) were written in the English language.Results:In total, 19 studies involving 4239 participants met criteria. Prescribed rest had a significant negative effect on symptoms (k = 15; g = ?0.27; SE = 0.11; 95\% CI, ?0.48 to ?0.05; P = .04) but not on recovery time (k = 8; g = ?0.16; SE = 0.21; 95\% CI, ?0.57 to 0.26; P = .03). Subgroup analyses suggested that studies with shorter duration ({$<$}28 days) (g = ?0.46; k = 5), studies involving youth (g = ?0.33; k = 12), and studies focused on sport-related concussion (g = ?0.38; k = 8) reported higher effect sizes.Conclusion:The findings support a small negative effect for prescribed rest on symptoms after concussion. Younger age and sport-related mechanisms of injury were associated with a greater negative effect size. However, the lack of support for an effect for recovery time and the relatively small overall numbers of eligible studies highlight ongoing concerns regarding the quantity and rigor of clinical trials in concussion.Registration:CRD42021253060 (PROSPERO).}
}

@incollection{kooleModelFramingMobile2009,
  title = {A {{Model}} for {{Framing Mobile Learning}}},
  booktitle = {Mobile {{Learning}}: {{Transforming}} the {{Delivery}} of {{Education}} and {{Training}}},
  author = {Koole, Marguerite L},
  editor = {Ally, Mohamed},
  year = {2009},
  publisher = {AU Press},
  address = {Athabasca}
}

@article{koraneekijStudentsBeliefsRegarding2019,
  title = {Students' {{Beliefs Regarding}} the {{Use}} of {{E-portfolio}} to {{Enhance Cognitive Skills}} in a {{Blended Learning}}},
  author = {Koraneekij, P and Khlaisang, J},
  year = {2019},
  journal = {International Journal of Emerging Technologies In Learning},
  volume = {14},
  number = {2},
  pages = {85--104},
  issn = {1863-0383},
  doi = {10.3991/ijet.v14i02.8288},
  abstract = {This paper reports on a quantitative study on ICT readiness among undergraduate students in Thailand, students' beliefs about use of e-portfolios in the Blended Learning Environment (BLE), and students' beliefs about using e-portfolios to enhance their cognitive skills in the BLE. The sample group comprised 360 undergraduate students, divided by study fields. The data collection tool was a questionnaire of students' beliefs. The reliability value of the questionnaire was 0.889. Data was analyzed using statistical analysis and f-test. The beliefs and needs were ranked by PNI modified. The research found that every student had a computer connected to the Internet. The analysis results of students' beliefs about the use of e-portfolios in the BLE were positive and the top five results were: (1) learning by creating work, (2) enhancing creativity, (3) enhancing the problem solving skill, (4) enhancing critical thinking, and (5) enhancing authentic assessment. The current state of using e-portfolios to enhance cognitive skills in the BLE was at average level, while the needs were at the high level.},
  langid = {english},
  keywords = {Belief,Blended Learning,Cognitive skills,CRITICAL THINKING,E-portfolio,ENVIRONMENT,HIGHER-EDUCATION,PERFORMANCE,PRESERVICE TEACHERS BELIEFS,PROGRAM,SELF-EFFICACY,SUPPORT,TECHNOLOGY},
  file = {/Users/colin.madland/Zotero/storage/C6FMKUAX/koraneekijStudentsBeliefsRegarding2019.pdf}
}

@article{koretskyAligningClassroomAssessment2022,
  title = {Aligning Classroom Assessment with Engineering Practice: {{A}} Design-Based Research Study of a Two-Stage Exam with Authentic Assessment},
  author = {Koretsky, {\relax MD} and McColley, {\relax CJ} and Gugel, {\relax JL} and Ekstedt, {\relax TW}},
  year = {2022},
  journal = {Journal of Engineering Education},
  volume = {111},
  number = {1},
  pages = {185--213},
  issn = {1069-4730},
  doi = {10.1002/jee.20436},
  abstract = {Background Authentic assessment and two-stage exams have recently received attention; however, they are rarely used together. We reimagine assessment by integrating an authentic, computer-based assessment into the structure of a two-stage exam in a large engineering class. Purpose We seek to identify ways that such assessment extends classroom testing to better align with engineering practice by examining the ways teams negotiate uncertainty to make engineering decisions. We also identify differing students' reactions to increased uncertainty during tests. Design/Method Using the methodical framework of design-based research, we analyze performance and reflection data for 117 student teams through two design iterations to explore four design and theoretical conjectures. Results Teams chose multiple solution paths to this authentic task, an aspect that aligns with the characteristics of engineering practice that we seek to assess. In addition, the technology tool allows the evaluation of procedural accuracy for many of the teams' chosen paths. The teams' decision-making performances correlate; however, decision-making and traditional assessments do not correlate, suggesting they measure different competencies. The computer-based second stage provides a holistic assessment that shifts the messages that students implicitly receive about valued practices in the classroom. However, not all students took up the authentic group assessment in desired ways. Conclusions Technology-based two-stage exams with authentic assessment show promise to shift testing practices in large engineering classes to include decision-making. Such assessments better align with engineering practices that are valued in the profession, but more work is needed to develop systems for widespread implementation.},
  langid = {english},
  keywords = {CHALLENGES,chemical engineering,design-based research,GAMES,higher education,HIGHER-EDUCATION,learning technology,MODELS,problem-solving,PRODUCTIVE DISCIPLINARY ENGAGEMENT,SCIENCE,student assessment,STUDENTS,TECHNOLOGY,UNCERTAINTY}
}

@article{korhonenVocationalStudentTeachers2020,
  title = {Vocational {{Student Teachers}}' {{Self-Reported Experiences}} in {{Creating ePortfolios}}},
  author = {Korhonen, Anne-Maria and Ruhalahti, Sanna and Lakkala, Minna and Veermans, Marjaana},
  year = {2020},
  month = jan,
  journal = {International Journal for Research in Vocational Education and Training},
  volume = {7},
  number = {3},
  pages = {278--301},
  publisher = {{International Journal for Research in Vocational Education and Training}},
  issn = {2197-8646},
  abstract = {Context: The context of this study is vocational teacher education and the participants are vocational student teachers studying part-time in a blended learning setting. They represent several disciplines of vocational education and training. The vocational teacher studies take one year and are 60 credits. The study relates to the discussion of vocational education and training and teachers' competencies which they are transferring to their students by sharing their knowledge of their subject area and working practices. This study is an exploration of one of these working practices making competences visible in a digital format. Approach: Student teachers' descriptions of their practices and recommendations of supportive methods for composing an ePortfolio are reviewed and their motivation to compose an ePortfolio is studied as a part of the Personal Learning Environment (PLE) philosophy. Findings: The data revealed some typical practices, such as creating an ePortfolio (the most popular ways of doing this were recording reflections in a learning diary and using digital tools to document artefacts) and demonstrating vocational teachers' competence in an ePortfolio (understanding the difference between workspace and showcase portfolios and what kinds of competences to document). The recommendations mentioned by participants were supportive methods of composing an ePortfolio (collaborative learning processes with peers, lecturers' feedback and assessment and clear instructions) as well as methods of displaying vocational teachers' competence (e.g. orientation to ePortfolio work using learning objectives and assessment criteria for ePortfolios). Participating student teachers were motivated to work with ePortfolios in various ways and expressed an intrinsic motivation to pursue personal growth and become a vocational teacher. Conclusions: The study revealed vocational student teachers' perceptions of scaffolding and motivational orientations to make their competences visible through ePortfolios. These can be used to design scaffolding methods to support students' ePortfolio activities. ePortfolios are used as a study method to promote student teachers' career development and personal growth and to help them acquire teacher competencies.},
  keywords = {Blended Learning,Electronic Publishing,Finland,Foreign Countries,Measurement Techniques,No DOI found,Portfolios (Background Materials),Scaffolding (Teaching Technique),Student Attitudes,Student Experience,Student Motivation,Student Teachers,Teacher Competencies,Vocational Education Teachers}
}

@misc{kornGeorgeMartinJodi2023,
  title = {George {{R}}. {{R}}. {{Martin}}, {{Jodi Picoult}} and Other Famous Writers Join {{Authors Guild}} in Class Action Lawsuit against {{OpenAI}} {\textbar} {{CNN Business}}},
  author = {Korn, Jennifer},
  year = {2023},
  month = sep,
  journal = {CNN},
  urldate = {2023-09-22},
  abstract = {A group of famous fiction writers joined the Authors Guild in filing a class action suit against OpenAI on Wednesday, alleging the company's technology is illegally using their copyrighted work.},
  howpublished = {https://www.cnn.com/2023/09/20/tech/authors-guild-openai-lawsuit/index.html},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/THNLRDQX/index.html}
}

@article{korpiPortfolioProjectSummative2019,
  title = {Portfolio {{Project}} as {{Summative Language Assessment}}: {{Engaging Learners Online}}},
  author = {Korpi, Sarah},
  year = {2019},
  journal = {International Journal of E-Learning \& Distance Education},
  volume = {34},
  number = {2},
  issn = {EISSN-2292-8588},
  abstract = {High stakes mid-course and final exams have long been a dominant assessment model. But exam performance does not necessarily correlate with learning or students' ability to apply learning to real-life scenarios outside the classroom. Reliance on such high-stakes assessments can result in elevated learner stress during exam times and lack of learner engagement during non-exam times. Active learning requires ongoing student engagement, and assessments of student work completed in such activities are authentic archetypes of student learning that demonstrate student ability to apply their learning to authentic situations, problems, and issues. This article argues that assessment practices based on multiple, low-stakes, iterative assessments within an active learning environment provide more targeted feedback and engage students in their own learning as active participants, which leads to increased student success. The case study presented in this article is specific to foreign-language courses offered through online education. Combining best practices of learner engagement in the online environment and assessment in the communicative language classroom, language faculty in an open enrollment program developed an assessment model for asynchronous, introductory language courses that relies on multiple low-stakes assessments that culminate in a final, summative portfolio project. This article will offer examples of how the portfolio project is situated in the course and an overview of portfolio project topics. Example instructions and assessment rubrics will be provided. Data from the first full year of implementation will be analyzed to begin to assess the impact and effectiveness of this portfolio assessment.},
  langid = {english},
  keywords = {Active Learning,Case Studies,College Students,Communicative Competence (Languages),Correlation,Feedback (Response),High Stakes Tests,Introductory Courses,Language Teachers,Language Tests,Learner Engagement,No DOI found,Online Courses,Portfolio Assessment,Scoring Rubrics,Second Language Instruction,Second Language Learning,Stress Variables,Summative Evaluation}
}

@book{koseogluExploratoryLiteratureReview2018,
  title = {An Exploratory Literature Review on Open Educational Practices},
  author = {Koseoglu, Suzan and Bozkurt, Aras},
  year = {2018},
  doi = {10.1080/01587919.2018.1520042}
}

@article{koumiMediaComparisonDeployment1994,
  title = {Media Comparison and Deployment: A Practitioner's View},
  author = {Koumi, Jack},
  year = {1994},
  month = jan,
  journal = {British Journal of Educational Technology},
  volume = {25},
  number = {1},
  pages = {41--57},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {0007-1013},
  doi = {10.1111/j.1467-8535.1994.tb00088.x},
  urldate = {2024-10-30},
  abstract = {Abstract Research on comparative efficacy of media has been flawed, giving a false impression of equipotentiality between media. Consequently, the need for workable criteria for optimal media deployment has been underestimated. A framework is proposed to help course developers design such media selection procedures. This has two ingredients: a broad categorisation of comparative merits of different media and a finer-grained inventory of media-distinctive techniques and teaching functions. Five media are considered in depth: radio and TV (broadcast), audio and video (cassette, with complementary notes) and print. These are then compared briefly with computer-based media. The analysis considers six types of media characteristics: symbol system, access, controllability, student reactivity, interactivity, adaptivity. The framework was developed collaboratively over several years, with the help of theorists and practitioners in international seminars and workshops.},
  file = {/Users/colin.madland/Zotero/storage/koumiMediaComparisonDeployment1994.pdf;/Users/colin.madland/Zotero/storage/WXIZIEDA/pericles_1467853525.ris}
}

@article{kozmaLearningMedia1991,
  title = {Learning with {{Media}}},
  author = {Kozma, Robert B.},
  year = {1991},
  journal = {Review of Educational Research},
  volume = {61},
  number = {2},
  pages = {179--211},
  issn = {00346543, 19351046},
  doi = {10.2307/1170534},
  abstract = {This article describes learning with media as a complementary process within which representations are constructed and procedures performed, sometimes by the learner and sometimes by the medium. It reviews research on learning with books, television, computers, and multimedia environments. These media are distinguished by cognitively relevant characteristics of their technologies, symbol systems, and processing capabilities. Studies are examined that illustrate how these characteristics, and the instructional designs that employ them, interact with learner and task characteristics to influence the structure of mental representations and cognitive processes. Of specific interest is the effect of media characteristics on the structure, formation, and modification of mental models. Implications for research and practice are discussed.},
  file = {/Users/colin.madland/Zotero/storage/F3IBGSKH/kozmaLearningMedia1991.pdf}
}

@article{kozmaWillMediaInfluence1994,
  title = {Will Media Influence Learning? {{Reframing}} the Debate},
  shorttitle = {Will Media Influence Learning?},
  author = {Kozma, Robert B.},
  year = {1994},
  month = jun,
  journal = {Educational Technology Research and Development},
  volume = {42},
  number = {2},
  pages = {7--19},
  issn = {1042-1629, 1556-6501},
  doi = {10.1007/BF02299087},
  urldate = {2023-08-05},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/WSBN32R2/kozmaWillMediaInfluence1994.pdf}
}

@incollection{kozulinPsychologicalToolsMediated2003,
  title = {Psychological {{Tools}} and {{Mediated Learning}}},
  booktitle = {Vygotsky's {{Educational Theory}} in {{Cultural Context}}},
  author = {Kozulin, Alex},
  editor = {Kozulin, Alex and Gindis, Boris and Ageyev, Vladimir S. and Miller, Suzanne M.},
  year = {2003},
  series = {Learning in {{Doing}}: {{Social}}, {{Cognitive}} and {{Computational Perspectives}}},
  pages = {15--38},
  publisher = {Cambridge University Press},
  address = {Cambridge}
}

@book{kozulinVygotskyEducationalTheory2003,
  title = {Vygotsky's {{Educational Theory}} in {{Cultural Context}}},
  shorttitle = {Vygotsky's {{Educational Theory}} in {{Cultural Context}}},
  author = {Kozulin, Alex and Gindis, Boris and Ageyev, Vladimir S and Miller, Suzanne M},
  editor = {Brown, John Seely},
  year = {2003},
  series = {Learning in {{Doing}}: {{Social}}. {{Cognitive}}, and {{Computational Perspectives}}},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  isbn = {0-521-52883-6}
}

@article{kraglund-gauthierTeacherEducationOnline2010,
  title = {Teacher {{Education}} in {{Online Classrooms}}: {{An Inquiry}} into {{Instructors}}' {{Lived Experiences}}},
  author = {{Kraglund-Gauthier}, Wendy L and Chareka, Ottila and Murray Orr, Anne and Foran, Andrew},
  year = {2010},
  journal = {The Canadian Journal for the Scholarship of Teaching and Learning},
  volume = {1},
  number = {2},
  abstract = {Across Canada and around the world, online technologies are becoming widely used and accepted as effective modes of learning. This essay traces the initial forays into teaching online classes by three Faculty of Education professors at one small Canadian university and an instructional designer / teacher who joined part-way through the research journey. Included are our understandings of how our teaching practices evolved amidst initial uncertainties and expanding abilities, our renewed awareness of the importance of collegial support and encouragement, and the implications for future online teaching experiences. Our essay provides an intimate window into our online teaching journeys and captures specific moments we experienced at various stages in the development of our e-instructional practices. The account of our processes of becoming online teacher educators is supported by an interweaving of historical and current literature on pedagogy and e-learning, and serves to address the dearth of research into the processes educators undergo when engaged in online teaching.},
  keywords = {E-learning,instructional design,Pedagogy,teacher education}
}

@article{kramerComparingTwoConstructs2021,
  title = {Comparing Two Constructs for Describing and Analyzing Teachers' Diagnostic Processes},
  author = {Kramer, Maria and {Christian F{\"o}rtsch} and {Tina Seidel} and {Birgit J. Neuhaus}},
  year = {2021},
  journal = {Studies in Educational Evaluation},
  doi = {10/gmgbpw}
}

@article{krausePeasPodStrategy2021,
  title = {Like {{Peas}} in a {{Pod}}: {{A Strategy}} for {{Creatively Transposing Interaction-Based Classes}} into an {{Online Learning Environment}}},
  author = {Krause, Andrea and Goering, Elizabeth M.},
  year = {2021},
  journal = {Journal of Teaching and Learning with Technology},
  volume = {10},
  pages = {279--293},
  issn = {EISSN-2165-2554},
  abstract = {The sudden shift to online learning thrust upon universities worldwide by the 2019 coronavirus disease (COVID-19) crisis created unique challenges related to effective online education. Challenges were most acute for highly interactive classes that were forced to move to asynchronous online learning environments. In response to these challenges, we developed an instructional model, rooted in group communication theories and concepts, designed to promote meaningful online learner-to-learner interaction. We provide an analytical assessment of our communication-based "Learning Pod" model, which was implemented in five English classes taught in the Department of English and American Studies at a German university during the COVID-19 shutdown. In Part 1 we describe the model, its development, and its implementation. In Part 2 we analyze learners' perceptions of the model's effectiveness using a mixed-methods approach. Results demonstrate the viability of the model, indicating that it is possible to provide meaningful interaction in asynchronous online classes, even in the midst of a pandemic, if communication goals are clearly articulated and strategically implemented.},
  langid = {english},
  keywords = {Computer Mediated Communication,Cooperative Learning,COVID-19,Educational Technology,English (Second Language),Foreign Countries,Group Activities,Higher Education,Interaction,No DOI found,Online Courses,Pandemics,School Closing,Second Language Instruction,Student Attitudes,Teaching Methods}
}

@misc{krausTwitterInvestigateApparent,
  title = {Twitter to Investigate Apparent Racial Bias in Photo Previews},
  author = {Kraus, Rachel},
  journal = {Mashable},
  urldate = {2020-09-22},
  abstract = {The company responds to the sleuths finding potential algorithmic bias.},
  howpublished = {https://mashable.com/article/twitter-photo-preview-algorithmic-racial-bias/},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/XQZDZFTV/twitter-photo-preview-algorithmic-racial-bias.html}
}

@article{kravaritiApplyingHigherEducation2018,
  title = {Applying the {{Higher Education Academy Framework}} for {{Partnership}} in {{Learning}} and {{Teaching}} in {{Higher Education}} to {{Online Partnership Learning Communities}}: {{A Case Study}} and an {{Extended Model}}},
  author = {Kravariti, Eugenia and Gillespie, Amy and Diederen, Kelly and Smart, Sophie and Mayberry, Caroline and Meehan, Alan and Bream, Danielle and Musiat, Peter and Vitoraou, Silia and Stahl, Daniel and Dyer, Kyle and Sukhwinder, Sukhi and Coate, Kelly and Yiend, Jenny},
  year = {2018},
  journal = {Teaching \& Learning Inquiry},
  volume = {6},
  number = {2},
  pages = {143--164},
  issn = {ISSN-2167-4779},
  doi = {10/gmbv25},
  abstract = {As internet access and use increase exponentially, pedagogical practice becomes increasingly embedded in online platforms. We report on an online initiative of engaged student learning, the peer-led, staff-assisted e-helpdesk for research methods and statistics, which we evaluated and redeveloped using the lens and guiding principles of the framework for partnership in learning and teaching of the Higher Education Academy (HEA). The aim of the redevelopment was to steer the initiative towards a more integrative and sustainable implementation, as manifest in the applied construct of an online partnership learning community. Our evolving experience of the e-helpdesk highlighted the central role of the facilitator in engineering and maintaining social presence in the online community. We propose an extended model for building an online partnership learning community, whereby partnership encapsulates all the essential elements of student and staff partnership as outlined in the HEA framework, but is also critically defined by similar parameters of partnership between users and facilitators. In this model, the facilitator's role becomes more involved in instructional teaching as disciplinary expertise increases, but descending levels of disciplinary expertise can foster ascending levels of independent learning and shared discovery for both users and facilitators.},
  langid = {english},
  keywords = {Case Studies,College Faculty,Communities of Practice,Curriculum Design,Expertise,Graduate Students,Help Seeking,Higher Education,Information Sources,Intellectual Disciplines,Models,Online Courses,Partnerships in Education,Sustainability,Teaching Methods,Trust (Psychology),Volunteers}
}

@misc{krinskyAltGradingPhysical,
  title = {Alt {{Grading}} in {{Physical Education}}, {{Canadian Grading Reforms}}, and {{Technology-Integrated Assessment}}: {{An Interview}} with {{Colin Madland}}},
  author = {Krinsky, Sharona and Bosley, Robert},
  number = {65},
  urldate = {2024-10-08},
  langid = {english}
}

@article{kristantoTechnologyEnhancedPreInstructionalPeer2018,
  title = {Technology-{{Enhanced Pre-Instructional Peer Assessment}}: {{Exploring Students}}' {{Perceptions}} in a {{Statistical Methods Course}}},
  author = {Kristanto, Yosep Dwi},
  year = {2018},
  month = jan,
  journal = {Online Submission},
  volume = {4},
  number = {2},
  pages = {105--116},
  publisher = {Online Submission},
  issn = {2460-6995},
  doi = {10.21831/reid.v4i2.20951},
  abstract = {There has been strong interest among higher education institution in implementing technology-enhanced peer assessment as a tool for enhancing students' learning. However, little is known on how to use the peer assessment system in pre-instructional activities. This study aims to explore how technology-enhanced peer assessment can be embedded into pre-instructional activities to enhance students' learning. Therefore, the present study was an explorative descriptive study that used the qualitative approach to attain the research aim. This study used a questionnaire, students' reflections, and interview in collecting student's perceptions toward the interventions. The results suggest that the technology-enhanced pre-instructional peer assessment helps students to prepare the new content acquisition and become a source of students' motivation in improving their learning performance for the following main body of the lesson. A set of practical suggestions is also proposed for designing and implementing technology-enhanced pre-instructional peer assessment.},
  keywords = {College Students,Educational Technology,Foreign Countries,Indonesia,Intervention,Peer Evaluation,Statistical Analysis,Student Attitudes,Technology Uses in Education},
  file = {/Users/colin.madland/Zotero/storage/KH4RF5XI/kristantoTechnologyEnhancedPreInstructionalPeer2018.pdf}
}

@article{Kronberg_2015,
  title = {Piecing Together the Puzzle the Formative Assessment Activity in a Grade 8 Philosophy Class},
  author = {Kronberg, Carla},
  year = {2015},
  journal = {null},
  doi = {null},
  abstract = {N/A: no abstract available},
  mag_id = {2190740909},
  pmcid = {null},
  pmid = {null},
  keywords = {guskey,Invalid DOI}
}

@article{krutkaDonBeEvil2021,
  title = {Don't {{Be Evil}}: {{Should We Use Google}} in {{Schools}}?},
  shorttitle = {Don't {{Be Evil}}},
  author = {Krutka, Daniel G. and Smits, Ryan M. and Willhelm, Troy A.},
  year = {2021},
  month = mar,
  journal = {TechTrends},
  issn = {8756-3894, 1559-7075},
  doi = {10/gjjvtq},
  urldate = {2021-03-25},
  langid = {english}
}

@article{kuhAssessingWhatReally2001,
  title = {Assessing What Really Matters to Student Learning},
  shorttitle = {Assessing What Really Matters to Student Learning},
  author = {Kuh, George D.},
  year = {2001},
  journal = {Change},
  volume = {33},
  pages = {10},
  issn = {00091383},
  abstract = {Describes the National Survey of Student Engagement (NSSE), an initiative which aimed to assess student learning and improve the quality of undergraduate education. Origins and purposes of NSSE; Issues and dilemmas in designing and implementing NSSE; Side effect of NSSE.},
  keywords = {LEARNING,SURVEYS},
  annotation = {3}
}

@techreport{kuhKnowingWhatStudents2014,
  title = {Knowing {{What Students Know}} and {{Can Do The Current State}} of {{Student Learning Outcomes Assessment}} in {{U}}.{{S}}. {{Colleges}} and {{Universities}}},
  author = {Kuh, George D and Jankowski, Natasha A. and Ikenberry, Stanley O and Kinzie, Jillian},
  year = {2014},
  pages = {19},
  institution = {National Institute for Learning Outcomes Assessment},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/3JLBMIKX/kuhKnowingWhatStudents2014.pdf}
}

@article{kulikEffectivenessMasteryLearning1990,
  title = {Effectiveness of {{Mastery Learning Programs}}: {{A Meta-Analysis}}},
  shorttitle = {Effectiveness of {{Mastery Learning Programs}}},
  author = {Kulik, Chen-Lin C. and Kulik, James A. and {Bangert-Drowns}, Robert L.},
  year = {1990},
  journal = {Review of Educational Research},
  volume = {60},
  number = {2},
  pages = {265--299},
  issn = {0034-6543, 1935-1046},
  doi = {10.3102/00346543060002265},
  urldate = {2024-06-20},
  abstract = {A meta-analysis of findings from 108 controlled evaluations showed that mastery learning programs have positive effects on the examination performance of students in colleges, high schools, and the upper grades in elementary schools. The effects appear to be stronger on the weaker students in a class, and they also vary as a function of mastery procedures used, experimental designs of studies, and course content. Mastery programs have positive effects on student attitudes toward course content and instruction but may increase student time on instructional tasks. In addition, self-paced mastery programs often reduce the completion rates in college classes.},
  copyright = {http://journals.sagepub.com/page/policies/text-and-data-mining-license},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/84EWYBAL/kulikEffectivenessMasteryLearning1990.pdf}
}

@article{kumarAssessingHigherEducation2020,
  ids = {kumarAssessingHigherEducation2020a},
  title = {Assessing {{Higher Education}} in the {{COVID-19 Era}}},
  author = {Kumar, Rahul},
  year = {2020},
  journal = {Brock Education: A Journal of Educational Research and Practice},
  volume = {29},
  number = {2},
  pages = {37--41},
  publisher = {{Brock Education: A Journal of Educational Research and Practice}},
  issn = {EISSN-1183-1189},
  abstract = {COVID-19 has changed how universities operate. The changes are in all spheres and caused by demands of social distancing rules predominantly mediated by various digital technologies. Applying Bauman's (1993) ethics of technology on newly initiated assessment practices, this article raises ethical concerns of relying on solutions solely manufactured by technology companies without professors' and students' input, various considerations of privacy, and overall ethical concerns that the use of any new technology raises. The article concludes by beseeching all stakeholders to collaborate to construct the tools for tomorrow that meet pedagogical needs without compromising Bauman's ethical concerns.},
  langid = {english},
  keywords = {COVID-19,Disease Control,Educational Change,Educational Technology,Ethics,Higher Education,No DOI found,Online Courses,Pandemics,Privacy,School Closing,Technology Uses in Education},
  file = {/Users/colin.madland/Zotero/storage/KQ43BWSX/kumarAssessingHigherEducation2020.pdf}
}

@article{kumarExplainableAutomatedEssay2020,
  title = {Explainable {{Automated Essay Scoring}}: {{Deep Learning Really Has Pedagogical Value}}},
  shorttitle = {Explainable {{Automated Essay Scoring}}},
  author = {Kumar, Vivekanandan and Boulanger, David},
  year = {2020},
  month = oct,
  journal = {Frontiers in Education},
  volume = {5},
  pages = {572367},
  issn = {2504-284X},
  doi = {10/gk75n9},
  urldate = {2021-07-17},
  file = {/Users/colin.madland/Zotero/storage/8QFZ42EL/kumarExplainableAutomatedEssay2020.pdf}
}

@article{kuoIntegratedModelDesigning2013,
  title = {Toward an Integrated Model for Designing Assessment Systems: {{An}} Analysis of the Current Status of Computer-Based Assessments in Science},
  shorttitle = {Toward an Integrated Model for Designing Assessment Systems},
  author = {Kuo, Che-Yu and Wu, Hsin-Kai},
  year = {2013},
  month = oct,
  journal = {Computers \& Education},
  volume = {68},
  pages = {388--403},
  issn = {03601315},
  doi = {10/f49t9w},
  urldate = {2021-03-21},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/ISYV96U5/kuoIntegratedModelDesigning2013.pdf}
}

@article{kurtzIndigenousMethodologiesTraversing2013,
  title = {Indigenous {{Methodologies}}: {{Traversing Indigenous}} and {{Western}} Worldviews in Research},
  author = {Kurtz, Donna L. M.},
  year = {2013},
  month = sep,
  journal = {AlterNative: An International Journal of Indigenous Peoples},
  volume = {9},
  number = {3},
  pages = {217--229},
  issn = {1177-1801},
  doi = {10.1177/117718011300900303},
  urldate = {2019-03-14},
  abstract = {Using Indigenous methodologies to guide a doctoral study honouring cultural traditions and protocols was integral in working with the local community. Traditional talking circles were used to create a culturally safe environment for urban Aboriginal women to talk about their health care experiences and recommend strategies for change. The methodological research process was guided and shaped by Elders and community members sharing their knowledge and stories. This fluid non-linearity and unpredictability, common in Indigenous methodologies, challenged the researcher to stay true to the methodology while simultaneously respecting cultural protocols and traditions. The successes and challenges of embracing Indigenous methodologies in the midst of academia without losing sight of respect, commitment and accountability to Indigenous peoples and the institution are offered.},
  file = {/Users/colin.madland/Zotero/storage/UGQFXW6T/kurtzIndigenousMethodologiesTraversing2013.pdf}
}

@article{kusumawatiRedesigningFacetoFaceOnline2020,
  title = {Redesigning {{Face-to-Face}} into {{Online Learning}} for {{Speaking Competence}} during {{COVID-19}}: {{ESP}} for {{Higher Education}} in {{Indonesia}}},
  author = {Kusumawati, Anggara Jatu},
  year = {2020},
  journal = {International Journal of Language Education},
  volume = {4},
  number = {2},
  pages = {276--288},
  issn = {ISSN-2548-8457},
  doi = {10/gh4njr},
  abstract = {During the time of COVID-19, students should study at home and class is conducted fully online. However, classes in higher education are mostly planned for Face-to-Face (F2F) learning. To deal with the situation, educators seek an alternative learning design to be implemented and it is expected to have either comparable or improved learning outcome. This study describes Online Learning (OL) design which assesses speaking performance in ESP classes. The participants of the study were students year 2019 (N=118) and students year 2020 (N=96) joining English for Electrical Engineering (EEE) which has the same syllabus and learning goal. A proposed Gagne's Nine Events of Instruction is analyzed, planned, implemented, and assessed its effectiveness of speaking activities which were done in the former-year-class (using F2F method) then applied in current class (using OL method). The result of F2F and Online Learning (OL) outcome were compared. To complete the analysis, a sequence of questionnaire was given to the students. The results indicates that using Gagne's Nine Events of Instruction, speaking activity in online learning classroom, achieved satisfactory result. Designing OL both synchronous and asynchronous method for speaking is as effective as F2F. This study may open another research prospect on barriers in OL, how to assess speaking performance via online platform, or others.},
  langid = {english},
  keywords = {Asynchronous Communication,College Students,Conventional Instruction,COVID-19,Electronic Learning,Engineering Education,English for Special Purposes,Foreign Countries,Higher Education,Instructional Effectiveness,Language Proficiency,Online Courses,Pandemics,Pronunciation,Public Speaking,Second Language Instruction,Self Efficacy,Speech Communication,Student Attitudes,Synchronous Communication,Teacher Student Relationship}
}

@article{kuUfolioConceptualDesign2011,
  title = {Ufolio a Conceptual Design Framework for a Learning Platform and Assessment System},
  author = {Ku, David Tawei and {Wen-Chih}, Chang},
  year = {2011},
  journal = {null},
  doi = {null},
  abstract = {In recent years, using e-portfolios to assess student learning has become more popular. From the perspective of education, portfolios should encourage students to collect, reflect on, and present their own works to enhance learning. Yet, currently available e-portfolios seem to function mainly as repositories of artifacts without connecting to the real learning process. As a result, although e-portfolios create a much more convenient environment through their technology, they are still unable to fulfill the initial purpose of portfolios. This paper presents a conceptual framework for the design of uFolio, an idea for an all-purpose portfolio system that has never been introduced previously. Based on the core value of portfolio and the technologies of a visual object-oriented platform and ubiquitous communications system, the design framework lays out an innovative system that establishes three major components --- MyFolio, MyClass and MyLog --- and an instant awareness notification tool, uAware, to integrate an e-portfolio, a learning management system (LMS) and a multidimensional assessment system into one. This paper presents the design steps taken so far and indicates the development tasks and related studies that still need to be carried out.},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@article{kuUfolioConceptualDesign2011a,
  title = {Ufolio a Conceptual Design Framework for a Learning Platform and Assessment System},
  author = {Ku, David Tawei and {Wen-Chih}, Chang},
  year = {2011},
  journal = {null},
  doi = {null},
  abstract = {In recent years, using e-portfolios to assess student learning has become more popular. From the perspective of education, portfolios should encourage students to collect, reflect on, and present their own works to enhance learning. Yet, currently available e-portfolios seem to function mainly as repositories of artifacts without connecting to the real learning process. As a result, although e-portfolios create a much more convenient environment through their technology, they are still unable to fulfill the initial purpose of portfolios. This paper presents a conceptual framework for the design of uFolio, an idea for an all-purpose portfolio system that has never been introduced previously. Based on the core value of portfolio and the technologies of a visual object-oriented platform and ubiquitous communications system, the design framework lays out an innovative system that establishes three major components --- MyFolio, MyClass and MyLog --- and an instant awareness notification tool, uAware, to integrate an e-portfolio, a learning management system (LMS) and a multidimensional assessment system into one. This paper presents the design steps taken so far and indicates the development tasks and related studies that still need to be carried out.},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@article{kwetDigitalColonialismUS2019,
  title = {Digital Colonialism: {{US}} Empire and the New Imperialism in the {{Global South}}},
  author = {Kwet, Michael},
  year = {2019},
  journal = {Race \& Class},
  pages = {0306396818823172},
  issn = {0306-3968},
  doi = {10.1177/0306396818823172},
  urldate = {2019-02-28},
  abstract = {This article proposes a conceptual framework of how the United States is reinventing colonialism in the Global South through the domination of digital technology. Using South Africa as a case study, it argues that US multinationals exercise imperial control at the architecture level of the digital ecosystem: software, hardware and network connectivity, which then gives rise to related forms of domination. The monopoly power of multinational corporations is used for resource extraction through rent and surveillance ? economic domination. By controlling the digital ecosystem, Big Tech corporations control computer-mediated experiences, giving them direct power over political, economic and cultural domains of life ? imperial control. The centrepiece of surveillance capitalism, Big Data, violates the sanctity of privacy and concentrates economic power in the hands of US corporations ? a system of global surveillance capitalism. As a feature of surveillance capitalism, Global North intelligence agencies partner with their own corporations to conduct mass and targeted surveillance in the Global South ? which intensifies imperial state surveillance. US elites have persuaded people that society must proceed according to its ruling class conceptions of the digital world, setting the foundation for tech hegemony. The author argues for a different ecosystem that decentralises technology by placing control directly into the hands of the people to counter the rapidly advancing frontier of digital empire.}
}

@incollection{kyllonenSocioemotionalSelfmanagementVariables2016,
  title = {Socio-Emotional and Self-Management Variables in Learning and Assessment},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {Kyllonen, Patrick C.},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch8},
  pages = {174--197},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch8},
  abstract = {Summary In this chapter I explore the relationship between cognitive assessment and noncognitive skills in several ways. First, I propose a comprehensive framework of noncognitive skills that includes (1) factors associated with the Big 5 model of personality, (2) additional constructs in the realm of attitudes, values, worldviews, beliefs, and perceived norms, (3) quasi-cognitive factors, and (4) momentary mood and emotional variables. Next, I document the role such variables play in test-taking motivation, item-position effects, test anxiety, and responses to formative feedback. Finally, I briefly review measurement approaches, pointing out some improvements to the commonly used self-assessment scale, including forced-choice and anchoring vignettes as well as performance measures such as situational judgment tests and collaborative problem-solving measures.},
  chapter = {8},
  isbn = {978-1-118-95658-8},
  keywords = {Big 5,noncognitive skills,personality variables,self-assessment,soft skills}
}

@article{lachhebRoleDesignEthics2023,
  title = {The Role of Design Ethics in Maintaining Students' Privacy: {{A}} Call to Action to Learning Designers in Higher Education},
  shorttitle = {The Role of Design Ethics in Maintaining Students' Privacy},
  author = {Lachheb, Ahmed and Abramenka-Lachheb, Victoria and Moore, Stephanie and Gray, Colin},
  year = {2023},
  month = nov,
  journal = {British Journal of Educational Technology},
  volume = {54},
  number = {6},
  pages = {1653--1670},
  issn = {0007-1013, 1467-8535},
  doi = {10.1111/bjet.13382},
  urldate = {2024-07-16},
  abstract = {Abstract                                           Maintaining students' privacy in higher education, an integral aspect of learning design and technology integration, is not only a matter of policy and law but also a matter of design ethics. Similar to faculty educators, learning designers in higher education play a vital role in maintaining students' privacy by designing learning experiences that rely on online technology integration. Like other professional designers, they need to care for the humans they design for by not producing designs that infringe on their privacy, thus, not causing harm. Recognizing that widely used instructional design models are silent on the topic and do not address ethical considerations such as privacy, we focus this paper on how design ethics can be leveraged by learning designers in higher education in a practical manner, illustrated through authentic examples. We highlight where the ethical responsibility of learning designers comes into the foreground when maintaining students' privacy and well-being, especially in online settings. We outline an existing ethical decision-making framework and show how learning designers can use it as a call to action to protect the students they design for, strengthening their ethical design capacity.                                                                                                                 Practitioner notes                                                           What is already known about this topic                                                                     Existing codes of ethical standards from well-known learning design organizations call upon learning designers to protect students' privacy without clear guidance on how to do so.                                                                       Design ethics within learning design is often discussed in abstract ways with principles that are difficult to apply.                                                                       Most, if not all, design models that learning design professionals have learned are either silent on design ethics and/or do not consider ethics as a valid dimension, thus, making design ethics mostly excluded from learning design graduate programs.                                                                       Practical means for engaging in ethical design practice are scarce in the field.                                                                                                       What this paper adds                                                                     A call for learning designers in higher education to maintain and protect students' privacy and well-being, strengthening their ethical design capacity.                                                                       A demonstration of how to use a practical ethical decision-making framework as a designerly tool in designing for learning to maintain and protect students' privacy and well-being.                                                                       Authentic examples---in the form of vignettes---of ethical dilemmas/issues that learning designers in higher education could face, focused on students' privacy.                                                                       Methods---using a practical ethical decision-making framework---for learning design professionals in higher education, grounded in the philosophy of designers as the guarantors of designs, to be employed to detect situations where students' privacy and best interests are at risk.                                                                       A demonstration of how learning designers could make stellar design decisions in service to the students they design for and not to the priorities of other design stakeholders.                                                                                                       Implications for practice and/or policy                                                                     Higher education programs/institutions that prepare/employ learning designers ought to treat the topics of the designer's responsibility and design ethics more explicitly and practically as one of the means to maintain and protect students' privacy, in addition to law and policies.                                                                       Learning designers in higher education ought to hold a powerful position in their professional practice to maintain and protect students' privacy and well-being, as an important aspect of their ethical design responsibilities.                                                                       Learning designers in higher education ought to adopt a design thinking mindset in order to protect students' privacy by (1) challenging ideas and assumptions regarding technology integration in general and (2) detecting what is known in User Experience (UX) design as ``dark patterns'' in online course design.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/X6HR6FIF/lachhebRoleDesignEthics2023.pdf}
}

@article{laiHowUseTechnology2019,
  title = {How Is the Use of Technology in Education Evaluated? {{A}} Systematic Review},
  shorttitle = {How Is the Use of Technology in Education Evaluated?},
  author = {Lai, Jennifer W.M. and Bower, Matt},
  year = {2019},
  month = may,
  journal = {Computers \& Education},
  volume = {133},
  pages = {27--42},
  issn = {03601315},
  doi = {10.1016/j.compedu.2019.01.010},
  urldate = {2022-10-27},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/DQIN8KH6/laiHowUseTechnology2019.pdf}
}

@article{laiPotentialDigitalTeaching2016,
  title = {Potential of Digital Teaching Portfolios for Establishing a Professional Learning Community in Higher Education},
  author = {Lai, Ming and Lim, Cher-Ping and Wang, Lixun},
  year = {2016},
  journal = {Australasian Journal of Educational Technology},
  volume = {32},
  number = {2},
  pages = {1--14},
  publisher = {Australasian Soc Computers Learning Tertiary Education-Ascilite},
  address = {TUGUN},
  issn = {1449-5554},
  doi = {10.14742/ajet.2572},
  abstract = {Digital teaching portfolios (DTPs) are increasingly adopted in higher education for various purposes such as assessment, learning, and showcasing. This paper reports on a collective case study of four teaching staff who have developed DTPs with an emphasis on building a professional learning community at a higher education institution. A number of themes emerged from the cross-case data analysis: the teaching staff used DTPs for both personal and social benefits; they found it important to link their DTPs with students' learning; they developed DTPs at different levels (individual and group level); they aligned their DTPs with their underlying teaching and learning beliefs; and they found that technical and conceptual supports, as well as opportunities to discuss and share with colleagues, were necessary for the successful implementation of DTPs. The study suggests that DTPs could significantly enhance higher education teaching and learning, and through sharing of DTPs, teaching staff could build a professional learning community that enhances their capacity for teaching and professional learning. [Author abstract]},
  keywords = {Assessment portfolios,Case Studies,College Faculty,Communities of Practice,Digital literacy,Digital technology,Education & Educational Research,Electronic portfolios,Electronic Publishing,Faculty Development,Foreign Countries,Higher Education,Hong Kong,Interviews,Learning communities,Learning processes,Portfolios (Background Materials),Postsecondary education,Professional continuing education,Professional development,Questionnaires,Semi Structured Interviews,Social Sciences,Student assessment,Teacher Attitudes,Teacher beliefs,Teacher improvement,Teaching effectiveness,Teaching methods,Technology Uses in Education,University students,University teaching},
  file = {/Users/colin.madland/Zotero/storage/GNGRSJD7/laiPotentialDigitalTeaching2016.pdf}
}

@book{lakeFacilitatingOnlineLearning2021,
  title = {Facilitating Online Learning with the {{5R}}'s},
  author = {Lake, Joanna and Atkins, Hayley},
  year = {2021},
  month = apr,
  publisher = {BCcampus},
  urldate = {2023-09-29},
  abstract = {This project is a collection of resources for educators and instructors within the K-12 and post-secondary systems to support the adoption of Indigenous pedagogies in online learning environments. The 5R's of Indigenous pedagogy are relationship, respect, relevance, responsibility, and reciprocity. These 5R's serve as important reminders for course designers in K-12 and post-secondary educators and benefit all learners. Our resources and reflections address how the 5R's of Indigenous education and research can be used as best practice to enrich online teaching platforms and remote learning. The positive effect of reciprocal communication, relationship building, and embracing Indigenous knowledge pedagogies in online learning environments extends out into the community and beyond.},
  langid = {canadian}
}

@article{lalaScenariosVirtualLearning2017,
  title = {Scenarios in Virtual Learning Environments for One-to-One Communication Skills Training},
  author = {Lala, R and Jeuring, J.T and Dortmont, Jordy{\textasciitilde}van and {\noopsort{geest}}{van Geest}, Marcell and {Sub Softw.Techn. for Learning and Teach} and {Dep Informatica} and {Software Technology for Learning and Teaching}},
  year = {2017},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {14},
  number = {1},
  pages = {1--15},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-017-0054-1},
  abstract = {A scenario is a description of a series of interactions between a player and a virtual character for one-to-one communication skills training, where at each step the player is faced with a choice between statements. In this paper, we analyse the characteristics of scenarios and provide a classification to represent such scenarios. The analysis is performed through a literature review and by comparing virtual learning environments for scenario based training. Using this analysis we specify requirements for describing communication scenarios related to their: structure (linear, branching, interleaving), properties (static information stored per scenario like situation, background, which virtual character to show), and parameters (characteristics of a scenario that can be modified per statement like a score on a learning goal and an emotional effect in a virtual character). We define a schema for representing such communication scenarios and present an authoring tool to create a scenario.},
  keywords = {Authoring,Authoring Tool,CAI,Communication,Communication Skill,Communication skills,Computer Appl. in Social and Behavioral Sciences,Computer assisted instruction,Computer Science,Computers and Education,Directed Acyclic Graph,Educational Technology,Games and Simulation in Higher Education,Higher Education,Humanities,Information Systems Applications (incl.Internet),Law,Learning,Learning management systems,Literature reviews,Parameter modification,Research Article,Skills,Statement Choice,Statistics for Social Sciences,Training,Virtual Character,Virtual environments},
  file = {/Users/colin.madland/Zotero/storage/S2IY63IL/lalaScenariosVirtualLearning2017.pdf}
}

@misc{lalondeNetworkLearningMoment2018,
  title = {A Network Learning Moment for an \#{{RRUMALAT}} Learner},
  author = {Lalonde, Clint},
  year = {2018},
  month = sep,
  journal = {EdTech Factotum},
  urldate = {2018-11-02},
  abstract = {Catching up on some blog reading yesterday and came across a post from Audrey Watters where she referenced the work of one of the students in the RRU MALAT program. More formally, one of George Vel{\dots}},
  langid = {english},
  keywords = {network,open},
  file = {/Users/colin.madland/Zotero/storage/2AQJ32SJ/a-network-learning-moment-for-an-rrumalat-learner.html}
}

@article{lambertChangingOurDis2018,
  title = {Changing Our ({{Dis}}){{Course}}: {{A Distinctive Social Justice Aligned Definition}} of {{Open Education}}},
  shorttitle = {Changing Our ({{Dis}}){{Course}}},
  author = {Lambert, Sarah Roslyn},
  year = {2018},
  month = nov,
  journal = {Journal of Learning for Development - JL4D},
  volume = {5},
  number = {3},
  issn = {2311-1550},
  urldate = {2018-12-01},
  abstract = {This paper investigates the degree to which recent digital Open Education literature is aligned to social justice principles, starting with the first UNESCO definition of Open Educational Resources (OER). A critical analysis of 19 texts was undertaken to track dominant and alternative ideas shaping the development of Open Education since 2002 as it broadened and developed from OER to Open Educational Practices (OEP). The paper begins by outlining the method of texts selection, including defining the three principles of social justice (redistributive, recognitive and representational justice) used as an analytical lens. Next the paper sets out findings which show where and how the principles of social justice became lost within the details of texts, or in other digital agendas and technological determinist debates. Finally, a new social justice aligned definition for Open Education is offered. The aim of the new definition is to provide new language and a strong theoretical framework for equitable education, as well as to clearly distinguish the field of Open Education from mainstream constructivist eLearning.},
  copyright = {Copyright (c) 2018 Journal of Learning for Development - JL4D},
  langid = {english},
  keywords = {critical theory,definition,OEP,Open Education,Open Educational Practices,Open Educational Resources,social justice},
  file = {/Users/colin.madland/Zotero/storage/U5RH8YMN/lambertChangingOurDis2018.pdf;/Users/colin.madland/Zotero/storage/L2E2LH8R/290.html}
}

@techreport{lambKeySkills21st2017,
  type = {Analytical {{Report}}},
  title = {Key {{Skills}} for the 21st {{Century}}: An Evidence-Based Review},
  author = {Lamb, Stephen and Maire, Quentin and Doecke, Esther},
  year = {2017},
  pages = {71},
  address = {Melbourne, AU},
  institution = {Victoria University},
  urldate = {2022-09-15},
  abstract = {Recent analysis examining trends in technology, the economy and the labour force shows that the world of work is changing. Based on an analysis of trends in the work of Australians each year, a new study has predicted that `as technology reduces the need for workers to complete routine, manual tasks they will spend more time focusing on people, solving more strategic problems and thinking creatively' (FYA, 2017). This has led some to the view that as well as deep and broad knowledge in key disciplines, students will need a range of skills and capabilities, including creative and critical thinking and problem solving, in order to thrive in the future world. But, what are the skills future generations will need? Have they found their way yet into teaching and learning in schools? How can we make sure that schools are able to teach and transmit them? This report considers the implications of these crucial questions for Australia, and it does so recognising that while there is a lot of discussion around the topic of key skills for the 21st century, there is little agreement yet about what the skills actually are, let alone whether they can be taught, measured or assessed. The reflections in this report, therefore, are somewhat speculative and need to be viewed as adding to the ongoing discussion around the skills our education system needs to consider in building courses and curricula for better preparing young people for their future lives. Its aims are modest: to bring together some of the current thinking around this topic and also to consider some of the work on the teaching and assessment of the skills future generations will need.},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/NFEBKJ37/lambKeySkills21st2017.pdf}
}

@article{lancasterContractCheatingSTEM2021a,
  title = {Contract {{Cheating}} by {{STEM Students}} through a {{File Sharing Website}}: {{A COVID-19 Pandemic Perspective}}},
  author = {Lancaster, Thomas and Cotarlan, Codrin},
  year = {2021},
  month = jan,
  journal = {International Journal for Educational Integrity},
  volume = {17},
  publisher = {International Journal for Educational Integrity},
  issn = {1833-2595},
  abstract = {Students are using file sharing sites to breach academic integrity in light of the COVID-19 pandemic. This paper analyses the use of one such site, Chegg, which offers "homework help" and other academic services to students. Chegg is often presented as a file sharing site in the academic literature, but that is just one of many ways in which it can be used. As this paper demonstrates, Chegg can and is used for contract cheating. This is despite the apparent existence of an Honour Code on Chegg which asks students not to breach academic integrity. With pandemic led safety considerations leading to increased online teaching and assessment, the paper analyses data relating to how Chegg is used by students in five STEM subjects, namely Computer Science, Mechanical Engineering, Electrical Engineering, Physics and Chemistry. The results show that students are using Chegg to request exam style questions. They demonstrate that contract cheating requests can be put live and answered within the short duration of an examination. The number of student requests posted for these five subjects increased by 196.25\% comparing the time period April 2019 to August 2019 with the period April 2020 to August 2020. This increase corresponds with the time when many courses moved to be delivered and assessed online. The growing number of requests indicates that students are using Chegg for assessment and exam help frequently and in a way that is not considered permissible by universities. The paper concludes by recommending that academic institutions put interventions in place to minimise the risk to educational standards posed by sites such as Chegg, particularly since increased online teaching and assessment may continue after the pandemic.},
  keywords = {Academic Standards,Cheating,College Students,Contracts,COVID-19,Educational Technology,Integrity,No DOI found,Online Courses,Pandemics,STEM Education,Test Items,Web Sites}
}

@article{landiMetacognitiveAssessmentsUndergraduate2022,
  title = {Metacognitive Assessments for Undergraduate Mathematics Courses in the Time of Covid-19},
  author = {Landi, Amanda K. and Minden, Kaethe},
  year = {2022},
  month = sep,
  journal = {PRIMUS: Problems, Resources, and Issues in Mathematics Undergraduate Studies},
  publisher = {Taylor \& Francis},
  issn = {1051-1970},
  doi = {10.1080/10511970.2022.2106603},
  abstract = {ABSTRACT In this paper, we assess the pedagogical approaches we employ in our US-based undergraduate mathematics courses during the COVID-19 pandemic. Our goal is to share anecdotal evidence on the use of math journals, oral exams, and learning portfolios in the synchronous online mathematics classroom. We reflect on our experience using artifacts of student materials, feedback, and dialogues. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {COVID-19,early college,learning portfolio,math journal,No terms assigned,oral exam,Student assessment,undergraduate mathematics,virtual classroom}
}

@misc{LandOpportunityGreat,
  title = {Land of {{Opportunity}} - {{The Great Migration}} - {{Norwegian Settlements}} in {{Alberta}}},
  urldate = {2019-12-04},
  howpublished = {https://www.collectionscanada.gc.ca/eppp-archive/100/200/301/ic/can\_digital\_collections/pasttopresent/opportunity/norwegian\_settlers.html},
  file = {/Users/colin.madland/Zotero/storage/89Z9P9HC/norwegian_settlers.html}
}

@article{laneImpactOpennessBridging2009,
  title = {The {{Impact}} of {{Openness}} on {{Bridging Educational Digital Divides}}},
  author = {Lane, Andy},
  year = {2009},
  month = nov,
  journal = {The International Review of Research in Open and Distributed Learning},
  volume = {10},
  number = {5},
  issn = {1492-3831},
  doi = {10.19173/irrodl.v10i5.637},
  urldate = {2018-11-05},
  abstract = {Openness has been a feature of higher education for many decades, particularly through the establishment of open universities, although there remain debates about what openness means in practice. Digital technologies, some based on open principles, and digital content, aided by open licences, have both contributed recently to an extension of what is deemed possible under the heading of openness. Nevertheless, while in principle there may be greater degrees of openness available in higher education it does not mean in practice that many people can still readily avail themselves of these new opportunities to learn, not just because they do not have access to digital technologies but personal circumstances mean they also lack the necessary skills and the confidence to use such technologies in general or for education in particular. In fact it can be argued that this new openness, characterised mainly through the open educational resources movement, may actually widen rather than bridge the digital and educational divides between groups, both within and across national boundaries, through the increasing sophistication in technologies and the competencies expected of learners. This paper reviews some of the evidence supporting these different areas of interest and attempts to provide a synthesis of them. It then argues that actions may be required by many inter-mediaries to help to reduce the diverse social and cultural digital divides within education, including through the mediated use of open educational resources between teachers and learners.},
  copyright = {Copyright (c) 2009 Andy Lane},
  langid = {english},
  keywords = {e-learning,higher education,oer,open learning,openness},
  file = {/Users/colin.madland/Zotero/storage/2MCHH4KM/laneImpactOpennessBridging2009.pdf;/Users/colin.madland/Zotero/storage/688AE8S3/637.html}
}

@article{langenfeldDigitalfirstLearningAssessment2022,
  title = {Digital-First Learning and Assessment Systems for the 21st Century},
  author = {Langenfeld, Thomas and Burstein, Jill and {\noopsort{davier}}{von Davier}, Alina A.},
  year = {2022},
  journal = {Frontiers in Education},
  doi = {10.3389/feduc.2022.857604},
  abstract = {In the past few years, our lives have changed due to the COVID-19 pandemic; many of these changes resulted in pivoting our activities to a virtual environment, forcing many of us out of traditional face-to-face activities into digital environments. Digital-first learning and assessment systems (LAS) are delivered online, anytime, and anywhere at scale, contributing to greater access and more equitable educational opportunities. These systems focus on the learner or test-taker experience while adhering to the psychometric, pedagogical, and validity standards for high-stakes learning and assessment systems. Digital-first LAS leverage human-in-the-loop artificial intelligence to enable personalized experience, feedback, and adaptation; automated content generation; and automated scoring of text, speech, and video. Digital-first LAS are a product of an ecosystem of integrated theoretical learning and assessment frameworks that align theory and application of design and measurement practices with technology and data management, while being end-to-end digital. To illustrate, we present two examples---a digital-first learning tool with an embedded assessment, the Holistic Educational Resources and Assessment (HERA) Science , and a digital-first assessment, the Duolingo English Test .},
  mag_id = {4229373792},
  pmcid = {null},
  pmid = {null},
  file = {/Users/colin.madland/Zotero/storage/KC67YMBI/langenfeldDigitalfirstLearningAssessment2022.pdf}
}

@article{lantermanPreserviceTeachersBeliefs2018,
  title = {Pre-Service {{Teachers}}' {{Beliefs}}: {{Impact}} of {{Training}} in {{Universal Design}} for {{Learning}}},
  shorttitle = {Pre-Service {{Teachers}}' {{Beliefs}}},
  author = {Lanterman, Christopher S. and Applequist, Karen},
  year = {2018},
  month = dec,
  journal = {Exceptionality Education International},
  volume = {28},
  number = {3},
  issn = {1918-5227},
  doi = {10.5206/eei.v28i3.7774},
  urldate = {2022-03-18},
  abstract = {Seventy-seven pre-service teachers enrolled in an introductory special education course completed a questionnaire on their beliefs about learning, teaching, and disability, before and after completing one of two randomly assigned training modules on Universal Design for Learning (UDL). Module A presented UDL as a strategy for meeting the specific needs of students with disabilities in a general education setting. Module B presented UDL as a framework to support all learners in the general education classroom through the creation of communities of learners. The Beliefs About Learning, Teaching, and Disability Questionnaire (BLTDQ) was administered with five subscales rated on a 6-point Likert-type scale that measure pre-service teachers' beliefs about learning and teaching, as representative of their epistemological beliefs, beliefs about disability (from pathognomonic to interventionist) and the role of the teacher in the general education classroom. Analyses of these results suggest that a significant change toward interventionist beliefs about learning, teaching, and disability occurred for participants who completed either module on UDL. Additionally, a small to moderate, positive relationship was identified between pre-service teachers' beliefs about disability and their epistemological beliefs, with the strength of this relationship increasing following their training in UDL. These findings suggest that training in UDL can have a powerful and positive impact on pre-service teachers' interventionist epistemological beliefs and beliefs about disability. Shifts toward interventionist beliefs are more likely to result in teaching practices that are more supportive of students with disabilities in general education classrooms. Implications for teacher preparation and study limitations are also discussed.},
  keywords = {archived},
  annotation = {https://web.archive.org/web/20220318184231/https://ojs.lib.uwo.ca/index.php/eei/article/view/7774},
  file = {/Users/colin.madland/Zotero/storage/DN8SYAME/lantermanPreserviceTeachersBeliefs2018.pdf}
}

@article{lapena-maneroOpenSourceSystemGenerating2022,
  title = {An {{Open-Source System}} for {{Generating}} and {{Computer Grading Traditional Non-Coding Assignments}}},
  author = {{Lapena-Manero}, Pablo and {Garcia-Casuso}, Carmen and {Miguel Montenegro-Cooper}, Jose and King, Robert W. and Behrens, Edwin M.},
  year = {2022},
  journal = {Electronics (Basel)},
  volume = {11},
  number = {6},
  pages = {917},
  publisher = {Mdpi},
  address = {BASEL},
  issn = {2079-9292},
  doi = {10.3390/electronics11060917},
  abstract = {One of the most time-consuming activities in higher education is reviewing and grading student evaluations. Rapid and effective feedback of evaluations, along with an appropriate assessment strategy, can significantly improve students' performance. Furthermore, academic dishonesty is a major issue in higher education that has been aggravated by the limitations derived from the COVID-19 pandemic. One of the possible ways to mitigate this issue is to give different evaluations to each student, with the negative cost of increasing reviewing time. In this work, an open-source system developed in Python to automatically create and correct evaluations is presented. Using Jupyter Notebook as the graphical user interface, the system allows the creation of individual student question sheets, with the same structure and different parameter values, to send them to students, grade them, and send the final score back to the students. The proposed system requires little programming knowledge for the instructors to use it. The system was applied in Civil Engineering and Geological Engineering programs at the Universidad Catolica de la Santisima Concepcion, drastically reducing grading time while improving students' performance.},
  keywords = {Academic misconduct,assessment,automatic grading,Cheating,Civil engineering,computer grading,Computer Science,Computer Science Information Systems,COVID-19,Dishonesty,Distance learning,Education,Engineering,Engineering education,Engineering Electrical & Electronic,Graphical user interface,Higher education,open source,Physical Sciences,Physics,Physics Applied,Programming languages,Reviewing,Science & Technology,Software,Students,Teachers,Technology,User interface},
  file = {/Users/colin.madland/Zotero/storage/WDAN3JU8/lapena-maneroOpenSourceSystemGenerating2022.pdf}
}

@article{larmuseauMultimodalLearningAnalytics2020,
  title = {Multimodal Learning Analytics to Investigate Cognitive Load during Online Problem Solving},
  author = {Larmuseau, Charlotte and Cornelis, Jan and Lancieri, Luigi and Desmet, Piet and Depaepe, Fien},
  year = {2020},
  month = sep,
  journal = {British Journal of Educational Technology},
  volume = {51},
  number = {5},
  pages = {1548--1562},
  issn = {0007-1013, 1467-8535},
  doi = {10.1111/bjet.12958},
  urldate = {2021-12-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/THB3SQTM/larmuseauMultimodalLearningAnalytics2020.pdf}
}

@article{lashleyCultivatingTextbookAlternatives2017,
  title = {Cultivating {{Textbook Alternatives From}} the {{Ground Up}}: {{One Public University}}'s {{Sustainable Model}} for {{Open}} and {{Alternative Educational Resource Proliferation}}},
  shorttitle = {Cultivating {{Textbook Alternatives From}} the {{Ground Up}}},
  author = {Lashley, Jonathan and {Cummings-Sauls}, Rebel and Bennett, Andrew B. and Lindshield, Brian L.},
  year = {2017},
  month = jun,
  journal = {The International Review of Research in Open and Distributed Learning},
  volume = {18},
  number = {4},
  issn = {1492-3831},
  urldate = {2018-07-07},
  copyright = {Copyright (c) 2017 Jonathan Lashley, Rebel Cummings-Sauls, Andrew B. Bennett, Brian L. Lindshield},
  langid = {english},
  keywords = {higher education,K-State,Kansas State University,OAER,OER,open educational resources,Open/Alternative Resources,sustainable initiatives},
  file = {/Users/colin.madland/Zotero/storage/SYMKX8RY/lashleyCultivatingTextbookAlternatives2017.pdf;/Users/colin.madland/Zotero/storage/35PR83BW/4212.html}
}

@misc{LatentClassAnalysis,
  title = {Latent {{Class Analysis}} {\textbar} {{Mplus Data Analysis Examples}}},
  publisher = {UCLA: Statistical Consulting Group},
  urldate = {2021-06-17}
}

@article{latifTeacherBeliefsPersonal2022,
  title = {Teacher Beliefs, Personal Theories and Conceptions of Assessment Literacy---a Tertiary {{EFL}} Perspective},
  author = {Latif, Muhammad Wasim and Wasim, Arzoo},
  year = {2022},
  journal = {Language Testing in Asia},
  volume = {12},
  number = {1},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1186/s40468-022-00158-5},
  abstract = {The purpose of this study was to pursue an enhanced understanding of teacher assessment literacy by investigating tertiary EFL practitioners' assessment-related personal theories, conceptions and beliefs. The study was based on sociocultural theory as a theoretical framework and informed by interpretivism philosophical underpinnings. Twelve teachers from three tertiary educational institutions in the Eastern province of Saudi Arabia participated in semi-structured interviews. The data were analysed employing a thematic analysis approach. The findings revealed diversity, complexity and uncertainty in teacher beliefs and personal theories related to various aspects of assessment and testing. The findings also provided deeper insights into the role of contextual and institutional dynamics that influence teachers' assessment-related decision-making process. These findings have implications for teacher education and professional development programmes in terms of assessment policy, procedures and practice.},
  langid = {english},
  keywords = {Assessment,Beliefs,Education,Education policy,English as a second language instruction,Language Assessment Literacy,Language Education,Literacy,Research,Second language teachers,Sociocultural theory,Teacher attitudes,Teacher education,Teachers,Testing and Evaluation}
}

@article{lauBenchmarkingHigherEducation2018,
  title = {Benchmarking Higher Education Programs through Alignment Analysis Based on the Revised {{Bloom}}'s Taxonomy},
  author = {Lau, Kwok Hung and Lam, Tri Khai and Kam, Booi Hon and Nkhoma, Mathews and Richardson, Joan},
  year = {2018},
  month = nov,
  journal = {Benchmarking: An International Journal},
  volume = {25},
  number = {8},
  pages = {2828--2849},
  issn = {1463-5771},
  doi = {10.1108/BIJ-10-2017-0286},
  urldate = {2023-03-02},
  abstract = {Purpose               The purpose of this paper is to propose a scalable quantitative approach to evaluate alignment within and between courses and programs in higher education for benchmarking purpose.                                         Design/methodology/approach                                The revised Bloom's taxonomy, which combines a cognitive process dimension and a knowledge dimension, is used as a basis for categorizing national standards, program and course learning outcomes (CLOs) and assessment methods. Alignments between programs and national standards, programs and courses and assessment tasks and courses are then measured using a series of Cohen's                 {$\kappa$}                 statistics. Two undergraduate business programs offered at an Australian university were used as examples to demonstrate the proposed method as an alignment evaluation tool.                                                        Findings               The findings reveal that the two sample programs are better aligned with national standards than with their respective constituent courses. The degree of alignment between CLOs and assessment methods varies from course to course within the programs. This might be related to the lack of clarity of some learning outcome statements and the complexity of certain assessment methods.                                         Research limitations/implications               This study lends insight into the use of an alignment mapping for benchmarking academic programs in higher education. To serve mainly as an illustration of the proposed approach, the case study is limited to two undergraduate business programs offered at the same university.                                         Practical implications               Universities can use the proposed approach to benchmark their academic programs against the national standards and similar programs offered by other competing educational institutions. The alignment indices can also serve as yardsticks to continuously improve the consistencies within and among academic programs to ensure quality.                                         Originality/value               The proposed method offers a consistent basis to compare the degrees of alignment of different higher education programs with national standards and their respective constituent courses, hence enabling benchmarking for continuous improvement. It also reveals how the alignment between different parameters in teaching and learning can be improved, thereby facilitating incremental learning and enhancing student performance.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/QN5MEIJL/lauBenchmarkingHigherEducation2018.pdf}
}

@article{laurentFTP4ANKIDigital2023,
  title = {{{FTP4}}.5 {{ANKI}} Digital Flashcards: An Effective Tool for Undergraduate Musculoskeletal Revision},
  author = {Laurent, Edward and Ensor, David and Vusirikala, Anuhya and Phillips, Staton},
  year = {2023},
  journal = {British journal of surgery},
  volume = {110},
  number = {Supplement\_6},
  issn = {0007-1323},
  doi = {10.1093/bjs/znad241.369},
  abstract = {Abstract Introduction ANKI is a programme that allows users to produce digital flashcards consisting of text, pictures and/or videos. It is based on the principle of active recall and spaced repetition creating an effective revision tool. This study investigated the benefits of ANKI digital flashcards used by 2nd year medical students when revising their musculoskeletal (MSK) module. Method A prospective study of 121 2nd year medical students at the Anglia Ruskin University. Learning objectives were stated at the start of each MSK lecture. Each student created ANKI flashcards for the learning objective assigned to them. These flashcards were combined to create a crowdsourced complete MSK deck available to the entire cohort. Anonymised student feedback was obtained at the beginning and end of the module. Results The mean value of a Likert scoring system (1least -- 5most) from both surveys was used. Pre-assignment questions assessing students' familiarity and aspiration towards ANKI: Use cards as part of revision =3.24; Comfort with IT systems=3.82; Familiar with ANKI system=4.04, Interest in using ANKI =3.88. Post assignment questions to assess the outcome success: Would you use ANKI for revision =4.55, Use ANKI in other modules =3.95. Free text responses included praise towards communal effort, manageable workload and creation of a revision resource. Conclusion ANKI provided an additional useful digital resource learning and revision for medical students. The cards created by students, for students, provided autonomy. However, this effected the quality of some slides. Overall, the feedback was positive with this assignment expanded to other modules.},
  file = {/Users/colin.madland/Zotero/storage/8RY5N6P2/laurentFTP4ANKIDigital2023.pdf}
}

@unpublished{laurillardDigitalTechnologiesTheir2008,
  title = {Digital Technologies and Their Role in Achieving Our Ambitions for Education},
  author = {Laurillard, Diana},
  year = {2008},
  address = {London Knowledge Lab},
  urldate = {2022-11-15},
  abstract = {Educational policy aims are very ambitious: from pre-school to lifelong learning they demand improvements in both quantity and quality, which are multiplicative in their effects on teaching workload. It is difficult, therefore, to achieve these aims effectively without rethinking our approach to teaching and learning. Our essentially nineteenth century model of educational institutions does not scale up to the requirements of a twenty-first century society. Despite their potential to contribute to a rethink, digital technologies have usually been used in a technology-driven way to upgrade our existing educational models. There is an alternative: an education-driven approach to the use of digital technologies to achieve our ambitions for education.},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/JGJA6YRN/laurillardDigitalTechnologiesTheir2008.pdf}
}

@misc{LavaanProject,
  title = {The Lavaan {{Project}}},
  urldate = {2022-05-09},
  howpublished = {https://lavaan.ugent.be/start.html},
  file = {/Users/colin.madland/Zotero/storage/GA89FAZL/start.html}
}

@book{laveaultAssessmentLearningMeeting2016,
  title = {Assessment for {{Learning}}: {{Meeting}} the {{Challenge}} of {{Implementation}}},
  shorttitle = {Assessment for {{Learning}}},
  editor = {Laveault, Dany and Allal, Linda},
  year = {2016},
  series = {The {{Enabling Power}} of {{Assessment}}},
  volume = {4},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-39211-0},
  urldate = {2022-05-07},
  isbn = {978-3-319-39209-7 978-3-319-39211-0},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/E79JHFRN/laveaultAssessmentLearningMeeting2016.pdf}
}

@book{laveSituatedLearningLegitimate2003,
  title = {Situated Learning: {{Legitimate}} Peripheral Participation},
  shorttitle = {Situtated Learning: {{Legitimate}} Peripheral Participation},
  author = {Lave, Jean and Wenger, Etienne},
  year = {2003},
  publisher = {Cambridge University Press},
  address = {Cambrige, UK}
}

@book{lavrakasEncyclopediaSurveyResearch2008,
  title = {Encyclopedia of {{Survey Research Methods}}},
  author = {Lavrakas, Paul},
  year = {2008},
  publisher = {Sage Publications, Inc.},
  address = {2455 Teller Road,~Thousand Oaks~California~91320~United States of America},
  doi = {10.4135/9781412963947},
  urldate = {2024-02-16},
  isbn = {978-1-4129-1808-4 978-1-4129-6394-7}
}

@article{lawImprovingStudentSuccess2020,
  ids = {lawImprovingStudentSuccess2020a},
  title = {Improving {{Student Success}} by {{Incorporating Instant-Feedback Questions}} and {{Increased Proctoring}} in {{Online Science}} and {{Mathematics Courses}}},
  author = {Law, Yu Kay and Tobin, Ryan Wesley and Wilson, Neena R. and Brandon, Lora Ann},
  year = {2020},
  month = jan,
  journal = {Journal of Teaching and Learning with Technology},
  volume = {9},
  pages = {64--78},
  publisher = {{Journal of Teaching and Learning with Technology}},
  issn = {2165-2554},
  abstract = {Introductory courses in mathematics and physical sciences are challenging for students and often have lower success rates than other comparable courses. In online courses, this is compounded by students employing surface learning strategies. Furthermore, it has been shown that students often do not utilize learning materials that are provided in the structured course modules, such as lecture videos. To combat this problem, we have implemented two different solutions to improve student engagement and retention of knowledge in courses in general chemistry and precalculus. First, using the Quick Check tool in our learning management system (LMS), we have incorporated auto-graded questions that students answer directly after viewing the course materials. These aim to promote the viewing of course materials beyond homework and quizzes, including engagement with course lecture videos. Second, using an online proctoring option integrated into our LMS, we have moved to increase the extent to which exams are proctored. This encourages students to engage in more frequent reinforcement prior to exams as they will not be able to access external information sources. We show that these measures led to greater improvement in student performance between the midterm and final exam, particularly on application questions. However, the incorporation of Quick Check questions reduced student performance on formative assessments particularly on more challenging topics. The implications are discussed in terms of cognitive load theory.},
  keywords = {Academic Achievement,College Mathematics,College Science,College Students,Computer Assisted Instruction,Difficulty Level,Feedback (Response),Formative Evaluation,Indiana,Integrated Learning Systems,Introductory Courses,Learner Engagement,Learning Strategies,No DOI found,Online Courses,Performance Factors,Scores,State Universities,Supervision,Testing},
  file = {/Users/colin.madland/Zotero/storage/F3HNX9HU/lawImprovingStudentSuccess2020.pdf}
}

@article{lawleyFactorAnalysisStatistical1962,
  title = {Factor {{Analysis}} as a {{Statistical Method}}},
  author = {Lawley, D. N. and Maxwell, A. E.},
  year = {1962},
  journal = {The Statistician},
  volume = {12},
  number = {3},
  eprint = {10.2307/2986915},
  eprinttype = {jstor},
  pages = {209},
  issn = {00390526},
  doi = {10.2307/2986915},
  urldate = {2025-03-23},
  file = {/Users/colin.madland/Zotero/storage/lawleyFactorAnalysisStatistical1962.pdf}
}

@misc{lawschooladmissioncouncilFrequentlyAskedQuestionsND,
  title = {Frequently {{Asked Questions About}} the {{LSAT}} {\textbar} {{The Law School Admission Council}}},
  author = {Law School Admission Council},
  year = {ND},
  urldate = {2022-03-12},
  howpublished = {https://www.lsac.org/lsat/frequently-asked-questions-about-lsat}
}

@misc{lawsonAreSchoolsForcing,
  title = {Are {{Schools Forcing Students To Install Spyware That Invades Their Privacy As A Result Of The Coronavirus Lockdown}}?},
  author = {Lawson, Sean},
  journal = {Forbes},
  urldate = {2020-04-25},
  abstract = {As schools move online because of the coronavirus pandemic, students are being asked to install exam proctoring software that some say is privacy invasive spyware.},
  chapter = {Innovation},
  howpublished = {https://www.forbes.com/sites/seanlawson/2020/04/24/are-schools-forcing-students-to-install-spyware-that-invades-their-privacy-as-a-result-of-the-coronavirus-lockdown/},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/AVNANVII/are-schools-forcing-students-to-install-spyware-that-invades-their-privacy-as-a-result-of-the-c.html}
}

@article{lawUsingDigitalTools2019,
  title = {Using {{Digital Tools}} to {{Assess}} and {{Improve College Student Writing}}},
  author = {Law, Sweety},
  year = {2019},
  month = jan,
  journal = {Higher Education Studies},
  volume = {9},
  number = {2},
  pages = {117--123},
  publisher = {Higher Education Studies},
  issn = {1925-4741},
  doi = {10.5539/hes.v9n2p117},
  abstract = {Employers have continually indicated that writing instruction is much needed in higher education across all majors. It has become more imperative now than before to better prepare our graduates for professional success in an age of increasing writing necessity, data analytics and reporting, and technical sophistication. Writing assessment in a class setting has learning goals and needs to be differentiated from a mass testing evaluation context. When learning to write well, especially relating to subject-specific content, feedback is necessary. Performing analysis and evaluation, then providing explanation and recommendations takes time. Newer digital tools can provide formative feedback; and therefore transparency about grading as well. Among teaching tasks, grading assignments consumes the majority of online faculty time. This study identifies what type of online grading could take up the majority of faculty time and specifies estimates of time needed for such grading. Faculty workload is high in adopting an optimal combined formative and summative assessment model. Results of the study might help develop more sound policies of academic support. Faculty might use the study?s information for better curricula planning and improved utilization of student assistants.},
  keywords = {Educational Technology,Essays,Evaluation Methods,Grading,Graduate Students,Integrated Learning Systems,Student Evaluation,Teaching Assistants,Technology Uses in Education,Time,Writing Assignments,Writing Evaluation,Writing Skills},
  file = {/Users/colin.madland/Zotero/storage/8F7VYNKC/lawUsingDigitalTools2019.pdf}
}

@article{LeadCanadaOffering2012,
  title = {B.{{C}}. to Lead {{Canada}} in Offering Students Free, Open Textbooks},
  year = {2012},
  month = oct,
  keywords = {oer open textbook bccampus}
}

@article{leadermanHumanizingAssessmentProcess2019,
  title = {Humanizing the {{Assessment Process}}: {{How}} the {{RARE Model Informs Best Practices}}},
  author = {Leaderman, Emilie Clucas and Polychronopoulos, Gina B},
  year = {2019},
  journal = {Research \& Practice in Assessment},
  volume = {14},
  abstract = {This paper introduces a conceptual framework for overcoming common assessment challenges and supporting a positive assessment culture in higher education through fostering collaborative relationships with faculty and staff. By using a lens that integrates concepts from person-centered and solution-focused counseling, positive psychology, and motivational interviewing, assessment practitioners can better understand what guides the cultivation of inclusive and participatory relationships in assessment. The RARE model provides a common set of strategies for implementing principles of effective assessment practice, developed by two assessment professionals from universities located in different accrediting regions: WASC (Western Senior College and University Commission) and SACSCOC (Southern Association of Colleges and Schools Commission on Colleges). In calling attention to the influence of their practitioner training and background, this model also highlights the benefit of exploring the disciplinary diversity that exists within the assessment field. Through exploration of this reflexive, strengths-based approach to assessment practice, the authors contribute to the discourse about professional identity in higher education assessment.},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/4DRIFZL9/leadermanHumanizingAssessmentProcess2019.pdf}
}

@article{leal-sotoThreefactorStructureEpistemic2017,
  title = {Three-Factor Structure for {{Epistemic Belief Inventory}}: {{A}} Cross-Validation Study},
  shorttitle = {Three-Factor Structure for {{Epistemic Belief Inventory}}},
  author = {{Leal-Soto}, Francisco and {Ferrer-Urbina}, Rodrigo},
  editor = {Lozano, Sergi},
  year = {2017},
  journal = {PLOS ONE},
  volume = {12},
  number = {3},
  pages = {1--16},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0173295},
  urldate = {2024-05-31},
  abstract = {Research on epistemic beliefs has been hampered by lack of validated models and measurement instruments. The most widely used instrument is the Epistemological Questionnaire, which has been criticized for validity, and it has been proposed a new instrument based in the Epistemological Questionnaire: the Epistemic Belief Inventory. The Spanishlanguage version of Epistemic Belief Inventory was applied to 1,785 Chilean high school students. Exploratory and confirmatory factor analyses in independent subsamples were performed. A three factor structure emerged and was confirmed. Reliability was comparable to other studies, and the factor structure was invariant among randomized subsamples. The structure that was found does not replicate the one proposed originally, but results are interpreted in light of embedded systemic model of epistemological beliefs.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/TMB3IMSI/leal-sotoThreefactorStructureEpistemic2017.pdf}
}

@article{LearningMediaTechnology2005,
  title = {Learning, Media and Technology ({{Online}})},
  year = {2005},
  journal = {Learning, media and technology (Online)},
  publisher = {Carfax},
  address = {London] ;},
  issn = {1743-9892},
  keywords = {Distance education,Educational technology,Electronic journals,Enseignement a distance,Internet en education,Internet in education,Materiel didactique,Periodicals,Teaching -- Aids and devices,Technologie educative,Television en education,Television in education,Theory & Practice of Education}
}

@phdthesis{learyLivedFacultyExperience2017,
  title = {The {{Lived Faculty Experience}} with {{Formalized Assessment Initiatives}}: {{An Interpretive Phenomenological Analysis}}},
  author = {Leary, IV, Thomas D.},
  year = {2017},
  journal = {ProQuest LLC},
  abstract = {Institutions of higher education both value and need student assessment data. Faculty, as seen in numerous studies, however, have generally negatively received the formalization and reporting of student assessments to gather this assessment data. If we could better understand faculty experiences and perceptions of student assessment data within institutions of higher education, we might then be better able to serve the students enrolled. Therefore, the purpose of this interpretive phenomenological analysis was to understand faculty experiences with and perceptions of student assessment data for the betterment of student learning. Using Brown's (2004, 2008) Conception of Assessment (CoA) theory, this study sought to answer the following research question: What are the lived experiences of faculty interacting with formalized assessment practices? Interviews with faculty working within higher education found four key beliefs: first, they perceived formalized assessment as accountability in the classroom as ineffective; second, they perceived formalized assessment as accountability to accreditors as positive in theory; third, they positive perceived the potential of formalized assessment to improve the education experience; and fourth, they perceived that formalized assessment must be faculty-driven, purposeful, and scholarly. Implications for practice and future research are discussed. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]},
  isbn = {1369715706;9781369715705;},
  langid = {english},
  school = {ProQuest LLC},
  keywords = {Accountability,Accreditation (Institutions),College Faculty,College Students,Data Collection,Educational Assessment,Educational Experience,Interviews,Phenomenology,Program Effectiveness,Student Evaluation,Teacher Attitudes,Teacher Role},
  annotation = {Dissertation/Thesis}
}

@book{leavyOxfordHandbookQualitative2014,
  title = {The {{Oxford Handbook}} of {{Qualitative Research}}},
  author = {Leavy, Patricia},
  year = {2014},
  series = {Oxford {{Library}} of {{Psychology}}},
  publisher = {Oxford University Press},
  address = {Oxford},
  abstract = {The Oxford Handbook of Qualitative Research presents a comprehensive overview of the field of qualitative research. It is intended for students of all levels, faculty, and researchers across the social sciences. The contributors represent some of the most influential and innovative researchers in the field as well as emerging scholars. This handbook provides a broad introduction to the field of qualitative research to those with little to no background in the subject, while simultaneously providing substantive contributions to the field that will be of interest to even the most experienced researchers. It serves as a user-friendly teaching tool suitable for a range of undergraduate or graduate courses, as well as individuals working on their thesis or other research projects. With a focus on methodological instruction, this volume offers both a retrospective and prospective view of the field. The first two sections explore the history of the field, ethics, and philosophical/theoretical approaches. The next three sections focus on the major methods of qualitative practice as well as newer approaches (such as arts-based research and internet research); area studies often excluded (such as museum studies and disaster studies); and mixed methods and participatory methods (such as community-based research). The next section covers key issues including data analysis, interpretation, writing and assessment. The final section offers a commentary about politics and research and the move towards public scholarship.},
  isbn = {978-0-19-981175-5},
  langid = {english},
  keywords = {PSYCHOLOGY / Social Psychology,Qualitative research--Methodology,Social sciences--Research}
}

@article{leckartStanfordEducationExperiment,
  title = {The {{Stanford Education Experiment Could Change Higher Learning Forever}}},
  author = {Leckart, Steven},
  journal = {Wired},
  issn = {1059-1028},
  urldate = {2022-10-01},
  abstract = {Wired correspondent Steven Leckart and 160,000 others around the globe sign on when two professors let the public take their AI course online for free.},
  chapter = {tags},
  langid = {american},
  keywords = {ai,biotech,wired magazine},
  file = {/Users/colin.madland/Zotero/storage/VECTL5MD/ff-aiclass.html}
}

@article{ledermanWhatTheoreticalFramework2015,
  title = {What {{Is A Theoretical Framework}}? {{A Practical Answer}}},
  author = {Lederman, Norman G. and Lederman, Judith S.},
  year = {2015},
  journal = {Journal of Science Teacher Education},
  volume = {26},
  number = {7},
  pages = {593--597},
  issn = {1573-1847},
  doi = {10.1007/s10972-015-9443-2}
}

@article{Lee_2020,
  title = {The Effectiveness and Features of Formative Assessment in Us k 12 Education a Systematic Review},
  author = {Lee, Hansol and Chung, Huy Q. and Zhang, Yu and Abedi, Jamal and Warschauer, Mark},
  year = {2020},
  journal = {Applied Measurement in Education},
  doi = {10/ghhtsq},
  abstract = {ABSTRACTIn the present article, we present a systematical review of previous empirical studies that conducted formative assessment interventions to improve student learning. Previous meta-analysis ...},
  mag_id = {3010246167},
  pmcid = {null},
  pmid = {null},
  keywords = {guskey}
}

@article{leeAutoethnographyAuthenticLearning2020,
  title = {Autoethnography as an {{Authentic Learning Activity}} in {{Online Doctoral Education}}: An {{Integrated Approach}} to {{Authentic Learning}}},
  author = {Lee, Kyungmee},
  year = {2020},
  month = jul,
  journal = {TechTrends},
  volume = {64},
  number = {4},
  pages = {570--580},
  issn = {1559-7075},
  doi = {10.1007/s11528-020-00508-1},
  abstract = {Under the constructivist learning paradigm, which emphasises authenticity as a required condition for learning, distance educators have been striving to create authentic learning environments that reflect the real world. However, it is inevitably challenging to make an online learning environment authentic for learners when it is ultimately separated from their real-life contexts. Particularly, in online doctoral education, given the diversity among online learners, even defining ``what is real and to whom'' is a difficult task. This paper argues that the epistemological approach to authentic learning, based on the constructivist learning paradigm, is not sufficient to make online learning ``authentically'' meaningful. The paper introduces an alternative, ontological approach stemming from the transformative learning paradigm, and suggests autoethnography as one authentic learning activity that can effectively integrate the epistemological and ontological approaches to authentic learning in online doctoral education. Such a comprehensive conceptualisation of authentic learning, as an integrated process of both knowing and becoming, allows each doctoral student to become a more authentic self across their learning and living environments.},
  file = {/Users/colin.madland/Zotero/storage/7QYCNQQV/leeAutoethnographyAuthenticLearning2020.pdf}
}

@incollection{leeCulturalModelingOpportunity2008,
  title = {Cultural {{Modeling}} as {{Opportunity}} to {{Learn}}},
  booktitle = {Assessment, {{Equity}}, and {{Opportunity}} to {{Learn}}},
  author = {Lee, Carol D.},
  editor = {Pullin, Diana C. and Haertel, Edward H. and Gee, James Paul and Young, Lauren Jones and Moss, Pamela A.},
  year = {2008},
  series = {Learning in {{Doing}}: {{Social}}, {{Cognitive}} and {{Computational Perspectives}}},
  pages = {136--169},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9780511802157.008},
  abstract = {The cornerstone of assessment is localized in the face-to-face interactions in daily classroom instruction. Daily instruction involves understanding how learning inside disciplines should be organized to respond to the needs of particular learners. This chapter examines how opportunity to learn (OTL) can be structured in classrooms serving culturally diverse students in ways that (1) build on fundamental propositions in cognition; (2) focus on generative topics, concepts, and forms of problem solving within subject matters; and (3) scaffold forms of knowledge and ways of using language emerging from students' everyday experiences in families and communities. The basic argument is that reconceptualizing forms of assessment in the absence of reconceptualizing instruction will yield few results.In this chapter, OTL means students have a right to rigorous instruction that:1) is organized in ways to build on and expand forms of prior knowledge they construct from their experiences outside school and across their years of schooling;2) provides them with models of expertise (e.g., models of more expert problem solving) and in-time feedback on the progress of their learning in ways that are usable and motivating; and3) focuses on powerful and generative topics, concepts, and problem-solving strategies within academic subject matters and across their years of schooling in ways that help them make sense of how their learning is useful in the world.In order for these opportunities to take root, several important issues must be addressed. First, we must have good operational definitions and illustrations of learning within subject matters from a developmental perspective.},
  isbn = {978-0-521-88045-9}
}

@article{leeDesignedLearnerInteractions2011,
  title = {Designed Learner Interactions in Blended Course Delivery},
  shorttitle = {Designed Learner Interactions in Blended Course Delivery},
  author = {Lee, Reba-Anna and Dashew, Brian},
  year = {2011},
  journal = {Journal of Asynchronous Learning Networks},
  volume = {15},
  pages = {72--80},
  issn = {19395256},
  abstract = {In transitioning to a hybrid delivery model, faculty are presented with an opportunity to engage in a systematic instructional design process which can bring coursework in line with pedagogical best practices that may not exist in traditional face-to-face classes. This paper presents a model whereby Marist College Academic Technology \& eLearning staff focuses faculty attention on designing effective student interactions with content, the instructor, and other students. These interactions promote deeper levels of engagement in student learning. [ABSTRACT FROM AUTHOR] Copyright of Journal of Asynchronous Learning Networks is the property of Sloan Consortium and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
  keywords = {blended,BLENDED learning,Colleges,Design,Distance,distance education,Education,Hybrid,in,Instructional,instructional design,INSTRUCTIONAL systems design,Interaction,Internet,INTERNET in education,LEARNING,Systems,universities,VIRTUAL,VIRTUAL universities & colleges},
  annotation = {1}
}

@article{leeEffectivenessLearnerdirectedModel2016,
  title = {Effectiveness of a Learner-Directed Model for e-Learning},
  author = {Lee, Stella and Barker, Trevor and Kumar, Vivekanandan Suresh},
  year = {2016},
  month = jul,
  journal = {Journal of Educational Technology \& Society},
  volume = {19},
  number = {3},
  pages = {221--233},
  publisher = {International Forum of Educational Technology \& Society},
  issn = {1176-3647},
  abstract = {It is a hard task to strike a balance between extents of control a learner exercises and the amount of guidance, active or passive, afforded by the learning environment to guide, support, and motivate the learner. Adaptive systems strive to find the right balance in a spectrum that spans between self-control and system-guidance. They also concern a smoother shifting of the balance point during learning episodes in light of competing requirements from learning goals, learner capacity, instructional affordances, and educational theories, among others. This research investigates one of the extremes of this spectrum, where learners actively assume control and take responsibility for their own learning, while catering to individual preferences with little or no guidance from the e-learning environment. In this study, one unit material from an online Introduction to Java Programming course has been redesigned based on the proposed Learner-Directed Model for the experimental design study. The model is developed based on the exploration of two educational theories---Experiential-Learning Theory (ELT) and Self-Regulated Learning (SRL) Theory. The study involved a total of 35 participants (N = 35) divided randomly into one Experimental Group and one Control Group. They were assigned to either a Learner-Directed Model (Experimental Group) or a linear model (Control Group). Pre/post tests, survey, follow-up interview as well as log file analysis were instruments used for assessing students' domain knowledge, meta-knowledge, and their attitudes for their overall learning experience. The results of the study have revealed that there is a statistically significant higher level of overall learning experience and better learning attitudes compared to Control Group students who studied with e-learning components that are linear in nature and are without explicit associations with educational theories. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Electronic Learning,Instructional design,Learner-directed model,Learning design,Learning preferences,No DOI found,Self-regulated learning,Self-Regulated Learning,Teaching}
}

@article{leeHumanCentricAutomatedEssay2023,
  title = {A {{Human-Centric Automated Essay Scoring}} and {{Feedback System}} for the {{Development}} of {{Ethical Reasoning}}},
  author = {Lee, Alwyn Vwen Yen and Luco, Andr{\'e}s Carlos and Tan, Seng Chee},
  year = {2023},
  journal = {Educational technology \& society},
  volume = {26},
  number = {1},
  pages = {147--159},
  publisher = {International Forum of Educational Technology  Society},
  address = {Taipei City},
  issn = {1176-3647},
  doi = {10.30191/ETS.202301_26(1).0011},
  abstract = {Although artificial Intelligence (AI) is prevalent and impacts facets of daily life, there is limited research on responsible and humanistic design, implementation, and evaluation of AI, especially in the field of education. Afterall, learning is inherently a social endeavor involving human interactions, rendering the need for AI designs to be approached from a humanistic perspective, or human-centered AI (HAI). This study focuses on the use of essays as a principal means for assessing learning outcomes, through students' writing in subjects that require arguments and justifications, such as ethics and moral reasoning. We considered AI with a human and student-centric design for formative assessment, using an automated essay scoring (AES) and feedback system to address issues of running an online course with large enrolment and to provide efficient feedback to students with substantial time savings for the instructor. The development of the AES system occurred over four phases as part of an iterative design cycle. A mixed-method approach was used, allowing instructors to qualitatively code subsets of data for training a machine learning model based on the Random Forest algorithm. This model was subsequently used to automatically score more essays at scale. Findings show substantial agreement on inter-rater reliability before model training was conducted with acceptable training accuracy. The AES system's performance was slightly less accurate than human raters but is improvable over multiple iterations of the iterative design cycle. This system has allowed instructors to provide formative feedback, which was not possible in previous runs of the course.},
  keywords = {Artificial intelligence,automated essay grading,Education & Educational Research,Educational objectives,Educational technology,Essay,Essays,Ethics,ethics education,Feedback,formative feedback,Grading and marking (Students),human-centric ai,Machine learning,Moral education,Social Sciences,Special Issue Articles,Study and teaching,Technology application}
}

@misc{leeJargonfreeExplanationHow2023,
  title = {A Jargon-Free Explanation of How {{AI}} Large Language Models Work},
  author = {Lee, Timothy B.},
  year = {2023},
  month = jul,
  journal = {Ars Technica},
  urldate = {2023-09-22},
  abstract = {Want to really understand large language models? Here's a gentle primer.},
  howpublished = {https://arstechnica.com/science/2023/07/a-jargon-free-explanation-of-how-ai-large-language-models-work/},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/296UKCDI/leeJargonfreeExplanationHow2023.pdf;/Users/colin.madland/Zotero/storage/NKBB2LNX/a-jargon-free-explanation-of-how-ai-large-language-models-work.html}
}

@article{leeLearnerPerceptionsTechnology2019,
  title = {Learner Perceptions versus Technology Usage: {{A}} Study of Adolescent {{English}} Learners in {{Hong Kong}} Secondary Schools},
  author = {Lee, Cynthia and Yeung, Alexander Seeshing and Cheung, Kwok Wai},
  year = {2019},
  month = may,
  journal = {Computers \& Education},
  volume = {133},
  pages = {13--26},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2019.01.005},
  abstract = {There is a wealth of research investigating the predictive power of learners' attitudes towards technology, perceived usefulness of technology and efficacy. However, the associations between these learner factors and the actual application of technology for individualized and collaborative school-related learning activities in a specific domain and in the Asian context are not adequately discussed. This paper contributes to the literature by attempting to investigate such correlations, and treating individualized and collaborative applications as separate entities, with particular reference to Chinese adolescent learners of English in Hong Kong. An analysis of 193 questionnaires completed by adolescent English learners aged 13--16 in three Hong Kong secondary schools supported the differentiation of actual application for individualized and collaborative school-related English learning activities. While the adolescents' attitudes, self-efficacy (familiarity with technology) and perceptions towards technology use were positive, attitude was related to use of technology for individualized learning purposes, and self-efficacy was related to perceived usefulness of technology for English learning. Their perceived usefulness of technology and actual application behavior for school-related learning tasks were not commensurate with each other. Older adolescent learners tended to favor more technology as a useful tool for English learning. Gender effects, however, were negligible. The study points to the significance of understanding both learner perceptions and relations with actual application of technology use for school-related English learning activities.},
  keywords = {Adolescents,Attitude,Chinese English learners,Efficacy,Learner factors,Technology adoption}
}

@article{leeRethinkingOnlineAssessment2022,
  title = {Rethinking Online Assessment from University Students' Perspective in {{COVID-19}} Pandemic},
  author = {Lee, {\relax VWY} and Lam, {\relax PLC} and Lo, {\relax JTS} and Lee, {\relax JLF} and Li, {\relax JTS}},
  year = {2022},
  month = dec,
  journal = {Cogent Education},
  volume = {9},
  number = {1},
  issn = {2331-186X},
  doi = {10.1080/2331186X.2022.2082079},
  abstract = {The recent COVID-19 pandemic prompted the implementation of online teaching and online assessment. Online assessment can be challenging to both teachers and students due to technical, academic, and ethical issues. In this survey, we adopted both qualitative and quantitative approaches to evaluate (1) the perceived effectiveness of online assessment; (2) barriers and problems of using online assessment; and (3) suggestions for improvement. The online survey was conducted in May 2020, 752 full-time undergraduate and postgraduate students had completed the questionnaires. Forty-three undergraduate students attended an individual interview between May and June 2020. A total of 739 (98.3\%) students had the experience of taking online assessment during COVID-19 outbreak. The survey results revealed that only 16.6\% of students were satisfied with their online assessment arrangements. The major difficulty that students encountered was technical problems (52.6\%). Majority of students (72.6\%) agreed that online assessments were more affected by computer problems and internet connection when compared with traditional examination. Students expressed that teachers' feedback was essential for their learning, and they wished to receive timely and detailed feedback on their performance. Students suggested that technical support should be provided, and standardized measures should be taken to ensure academic honesty.},
  langid = {english},
  keywords = {COVID-19,formative and summative assessment,FORMATIVE ASSESSMENT,HIGHER-EDUCATION,Online assessment,online teaching and learning,PERCEPTIONS,PERFORMANCE},
  file = {/Users/colin.madland/Zotero/storage/6N5KKJAW/leeRethinkingOnlineAssessment2022.pdf}
}

@article{leeServantLeadershipMetaanalytic2020,
  title = {Servant Leadership: {{A}} Meta-Analytic Examination of Incremental Contribution, Moderation, and Mediation},
  author = {Lee, Allan and Lyubovnikova, Joanne and Tian, A. and Knight, Caroline},
  year = {2020},
  month = mar,
  journal = {Journal of Occupational and Organizational Psychology},
  doi = {10.1111/JOOP.12265},
  abstract = {Research suggests that when leaders, as servant leaders, focus on their followers' needs, this can have a positive effect on organizational functioning. Yet results are inconsistent in establishing the strength of the relationships, limiting understanding of the theoretical impact and practical reach of the servant leadership (SL ) construct. Using a quantitative meta-analysis based on 130 independent studies, the current research provides evidence that SL has incremental predictive validity over transformational, authentic, and ethical leadership. Further, the link between SL and a range of individual- and team-level behavioural outcomes can be partially explained by trust in the leader, procedural justice, and leader--member exchange. The paper also explores moderators to better establish SL 's criterion-related validity and to clarify the magnitude of effects across boundary conditions, such as research design, national culture, and industry.}
}

@article{leeStudentsExperiencesPerceptions2021,
  title = {Students' {{Experiences}} and {{Perceptions}} of {{Online Collaborative Learning}} in {{Higher Education}} of {{Korea}} and the {{UAE}}},
  author = {Lee, Jieun and Osman, Gihan},
  year = {2021},
  journal = {Turkish Online Journal of Distance Education},
  volume = {22},
  number = {1},
  pages = {1--18},
  issn = {EISSN-1302-6488},
  doi = {10/gmbvx6},
  abstract = {The purpose of this study was to compare the experiences and perceptions of UAE and Korean students in campus-based universities of online collaborative learning (OCL). 262 college students participated in online surveys. Their experiences in terms of frequency, assessment, barriers, support, and attitude for OCL in each country were examined. With Importance-Performance Analysis, the perceived importance of OCL activities was compared with actual frequency. Both countries' students experienced group projects and group presentations the most frequently, while online collaborative writing and online group exams were rarely used. As barriers to OCL, UAE students pointed out language, gender, and privacy as the major barriers while Korean students mentioned students' attitude and language. UAE students had more frequent experiences of and more positive attitudes toward OCL than did Korean students, although the two countries have similar cultural propensities.},
  langid = {english},
  keywords = {Barriers,College Students,Comparative Education,Computer Mediated Communication,Cooperative Learning,Cultural Differences,Electronic Learning,Foreign Countries,Gender Differences,Language Proficiency,Peer Relationship,Prior Learning,Privacy,Student Attitudes,Student Evaluation,Student Experience,Student Projects,Teacher Role,Teamwork,Technical Support,Technological Literacy}
}

@article{leeSupportingStudentsGeneration2023,
  title = {Supporting Students' Generation of Feedback in Large-Scale Online Course with Artificial Intelligence-Enabled Evaluation},
  author = {Lee, Alwyn Vwen Yen},
  year = {2023},
  journal = {Studies in educational evaluation},
  volume = {77},
  pages = {101250},
  publisher = {Elsevier Ltd},
  address = {AMSTERDAM},
  issn = {0191-491X},
  doi = {10.1016/j.stueduc.2023.101250},
  abstract = {Educators in large-scale online courses tend to lack the necessary resources to generate and provide adequate feedback for all students, especially when students' learning outcomes are evaluated through student writing. As a result, students welcome peer feedback and sometimes generate self-feedback to widen their perspectives and obtain feedback, but often lack the support to do so. This study, as part of a larger project, sought to address this prevalent problem in large-scale courses by allowing students to write essays as an expression of their opinions and response to others, conduct peer and self-evaluation, using provided rubric and Artificial Intelligence (AI)-enabled evaluation to aid the giving and receiving of feedback. A total of 605 undergraduate students were part of a large-scale online course and contributed over 2500 short essays during a semester. The research design uses a mixed-methods approach, consisting qualitative measures used during essay coding, and quantitative methods from the application of machine learning algorithms. With limited instructors and resources, students first use instructor-developed rubric to conduct peer and self-assessment, while instructors qualitatively code a subset of essays that are used as inputs for training a machine learning model, which is subsequently used to provide automated scores and an accuracy rate for the remaining essays. With AI-enabled evaluation, the provision of feedback can become a sustainable process with students receiving and using meaningful feedback for their work, entailing shared responsibility from teachers and students, and becoming more effective. {$\bullet$}Educators lack resources to provide adequate student assessment feedback.{$\bullet$}Students need support for peer and self-evaluations to be sustainable.{$\bullet$}Prototype essay scoring system with AI supports students' generated feedback.{$\bullet$}Shared responsibility between educators and students critical for sustainability.{$\bullet$}Inception in undergraduate course shows feasibility and scalability.},
  keywords = {Artificial intelligence,Education & Educational Research,Formative assessment,Machine learning,Online course,Peer and self-feedback,Psychology,Psychology Educational,Social Sciences}
}

@article{leeuwenkampAssessmentQualityTertiary2017,
  title = {Assessment Quality in Tertiary Education an Integrative Literature Review},
  author = {Leeuwenkamp, Karin J. Gerritsen-van and Brinke, Desir{\'e}e Joosten-ten and Kester, Liesbeth},
  year = {2017},
  journal = {Studies in Educational Evaluation},
  doi = {10/ghjbhx},
  abstract = {Abstract In tertiary education, inferior assessment quality is a problem that has serious consequences for students, teachers, government, and society. A lack of a clear and overarching conceptualisation of assessment quality can cause difficulties in guaranteeing assessment quality. Thus, the aim of this study is to conceptualise assessment quality in tertiary education by providing an overview of the assessment quality criteria, their influences, the evaluation of the assessment quality criteria, and the perspectives that should be considered when evaluating assessment quality. This study aggregated 78 peer-reviewed journal articles in a framework using MAXQDA, and a text analysis was performed using Leximancer. The results identified validity, transparency, and reliability as assessment quality criteria; standardisation, stakeholders, clarity, and construct irrelevant variance as influences on the assessment quality criteria; validation and statistical data analyses to evaluate assessment quality; and students, staff, government, and experts as perspectives that should be considered when evaluating assessment quality. These insights are important for teachers, educational advisors, and managers who can use this information to determine what assessment quality means for their educational organisation and what they should consider when guaranteeing assessment quality. Moreover, the study provides researchers with insight into the current state of scientific evidence.},
  pmcid = {null},
  pmid = {null}
}

@misc{leeuwenkampHome,
  title = {{Home}},
  author = {Leeuwenkamp, Karin Gerritsen-van},
  journal = {www.assessmentquality.com},
  urldate = {2020-12-21},
  abstract = {Assessment quality In tertiary education, inferior assessment quality is a problem that has serious consequences for students, teachers, government, and society. Inferior asssessment quality impacts the learning, selection and certification, and accountability purposes of assessment. It is the obligation of tertiary institutions to make assessment trustworthy. It is not easy to guarantee assessment quality, since a},
  langid = {dutch},
  file = {/Users/colin.madland/Zotero/storage/M7EUCSXB/assessmentquality.com.html}
}

@techreport{LegalAnalysisGenocide2019,
  title = {A {{Legal Analysis}} of {{Genocide}}},
  year = {2019},
  institution = {{National Inquiry into Missing and Murdered Indigenous Women and Girls}},
  urldate = {2020-08-27},
  file = {/Users/colin.madland/Zotero/storage/ZJVHPBFA/LegalAnalysisGenocide2019.pdf}
}

@article{lehmanPedagogicalIntersectionsEPortfolio2021,
  title = {Pedagogical {{Intersections}}: {{ePortfolio Practice}} and {{Essential Learning Outcomes}} for 21st {{Century Success}}},
  author = {Lehman, Regina M. and Mills, Michele D. and Gupta, Richa and Calderon, Olga},
  year = {2021},
  month = jun,
  journal = {New Directions for Teaching and Learning},
  number = {166},
  pages = {59--91},
  publisher = {{New Directions for Teaching and Learning}},
  issn = {0271-0633},
  doi = {10.1002/tl.20452},
  abstract = {ePortfolio practice and assessment of essential learning outcomes (ELOs) are well established at LaGuardia Community College (LAGCC). The way in which these practices intersect is via the assessment of authentic student artifacts generated from assignments aligned with ELOs. Student artifacts are deposited into the Core ePortfolio for college-wide assessment. Benchmark reading data is used to inform ePortfolio practice and pedagogy at the college-wide and programmatic levels. General Education Core Competencies and Communication Abilities are established across the College and are an integral part of curricular frameworks in all majors. The Core Competencies--Inquiry and Problem Solving, Integrative Learning, and Global Learning--are expressed through the Oral, Written, and Digital Communication Abilities. ePortfolio practice lends itself to the examination of Integrative Learning and Digital Communication. Recognizing ePortfolio as a high-impact practice, LAGCC developed the Core ePortfolio as a platform for student active engagement in self-directed learning and reflection about themselves as learners over their entire curricular and co-curricular experience. Faculty gain a deepened understanding of the student experience and the process of integrative learning.},
  keywords = {Communication Skills,Community Colleges,Competence,Electronic Publishing,Independent Study,Integrated Activities,Portfolio Assessment,Portfolios (Background Materials),Problem Solving,Two Year College Students}
}

@article{lehuedeElementalEthicsArtificial2024,
  title = {An Elemental Ethics for Artificial Intelligence: Water as Resistance within {{AI}}'s Value Chain},
  shorttitle = {An Elemental Ethics for Artificial Intelligence},
  author = {Lehued{\'e}, Sebasti{\'a}n},
  year = {2024},
  month = apr,
  journal = {AI \& SOCIETY},
  issn = {0951-5666, 1435-5655},
  doi = {10.1007/s00146-024-01922-2},
  urldate = {2024-04-30},
  abstract = {Abstract             Research and activism have increasingly denounced the problematic environmental record of the infrastructure and value chain underpinning artificial intelligence (AI). Water-intensive data centres, polluting mineral extraction and e-waste dumping are incontrovertibly part of AI's footprint. In this article, I turn to areas affected by AI-fuelled environmental harm and identify an ethics of resistance emerging from local activists, which I term `elemental ethics'. Elemental ethics interrogates the AI value chain's problematic relationship with the elements that make up the world, critiques the undermining of local and ancestral approaches to nature and reveals the vital and quotidian harms engendered by so-called intelligent systems. While this ethics is emerging from grassroots and Indigenous groups, it echoes recent calls from environmental philosophy to reconnect with the environment via the elements. In empirical terms, this article looks at groups in Chile resisting a Google data centre project in Santiago and lithium extraction (used for rechargeable batteries) in Lickan Antay Indigenous territory, Atacama Desert. As I show, elemental ethics can complement top-down, utilitarian and quantitative approaches to AI ethics and sustainable AI as well as interrogate whose lived experience and well-being counts in debates on AI extinction.},
  langid = {english}
}

@article{leiDevelopingMetadiscourseReflective2018,
  title = {Developing Metadiscourse through Reflective Assessment in Knowledge Building Environments},
  author = {Lei, {\relax CL} and Chan, {\relax CKK}},
  year = {2018},
  journal = {Computers \& Education},
  volume = {126},
  pages = {153--169},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2018.07.006},
  abstract = {This study examined how reflective assessment supported by principles facilitated metadiscourse for knowledge advances mediated by Knowledge Forum(center dot) (KF). Participants were 60 tertiary students in two classes engaging in knowledge building and reflecting on their collaborative knowledge building using e-portfolios; one class was a principle-based knowledge-building environment (KBP, n = 30), and the other a regular knowledge-building environment (KBR, n = 30). The KF embedded assessment tools, the Analytical Toolkit and Applet, showed increased KF participation and connectedness during the year. Regression analysis showed that KF participation predicted conceptual understanding for both classes. Analyses of e-portfolios revealed that the students adopted nine reflective strategies in knowledge building, and that reflective metadiscourse strategies involving metacognitive and collective processes were related with deeper conceptual understanding. Analyses of online discourse threads further showed that metadiscourse involving collective processes was associated with higher levels of knowledge advances. Both classes showed improvement and the KBP class outperformed the KBR class on KF participation, metadiscourse processes and conceptual understanding. This study has theoretical implications advancing the idea of metadiscourse, discourse about discourse, for enriching research on knowledge building and computer-supported collaborative learning (CSCL). There are also design implications for using principle-based e-portfolios to facilitate collective reflection and metadiscourse to address issues of fragmented online discussion, and for promoting sustained inquiry.},
  langid = {english},
  keywords = {ASYNCHRONOUS ONLINE,Collaborative learning,Computer-mediated communication,CONSTRUCTION,DISCOURSE,E-Portfolio assessment,INQUIRY,Knowledge building,LEARNING ENVIRONMENTS,PARTICIPATION,Post-secondary education,STUDENTS,WORK},
  file = {/Users/colin.madland/Zotero/storage/LWNGYL2W/leiDevelopingMetadiscourseReflective2018.pdf}
}

@incollection{leightonConclusionHandbook2016,
  title = {Conclusion to Handbook},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {Leighton, Jacqueline P. and Rupp, Andr{\'e} A.},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch24},
  pages = {580--587},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch24},
  chapter = {24},
  isbn = {978-1-118-95658-8}
}

@article{leightonStudentsInterpretationFormative2019,
  title = {Students' {{Interpretation}} of {{Formative Assessment Feedback}}: {{Three Claims}} for {{Why We Know So Little About Something So Important}}},
  author = {Leighton, Jacqueline P.},
  year = {2019},
  journal = {Journal of Educational Measurement},
  volume = {56},
  number = {4},
  pages = {793--814},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {0022-0655},
  doi = {10/ghbwr8},
  urldate = {2020-09-17},
  abstract = {Abstract If K-12 students are to be fully integrated as active participants in their own learning, understanding how they interpret formative assessment feedback is needed. The objective of this article is to advance three claims about why teachers and assessment scholars/specialists may have little understanding of students? interpretation of formative assessment feedback. The three claims are as follows. First, there is little systematic research of K-12 students? interpretations of feedback. Systematic research requires gathering substantive evidence of students? cognitive and emotional processes using psychological methods and tools. Second, there is an overemphasis on the external assessment process at the expense of uncovering learners? internal reasoning and emotional processes. This overemphasis may be due to vestiges of behavioral approaches and lack of training in social cognitive methods. Third, there are psychological tools such as the clinical interview, pioneered by Piaget and used by psychologists to ?enter the child's mind,? which may be helpful in uncovering students? interpretation of feedback and associated behavioral responses. If the purpose of formative assessment is to change student learning, and feedback is delivered as a conduit to help with this long-term change, understanding students? interpretation of feedback plays a central role in the validity of the process.},
  file = {/Users/colin.madland/Zotero/storage/RGVHGJ3A/leightonStudentsInterpretationFormative2019.pdf}
}

@article{leInteractionPatternsPandemicinitiated2022,
  title = {The Interaction Patterns of Pandemic-Initiated Online Teaching: {{How}} Teachers Adapted},
  shorttitle = {The Interaction Patterns of Pandemic-Initiated Online Teaching},
  author = {Le, Van Thinh and Nguyen, Ngan Ha and Tran, Tran Le Nghi and Nguyen, Thanh Luan and Nguyen, Anh Thi and Nguyen, Minh Trang},
  year = {2022},
  journal = {System},
  pages = {102755},
  issn = {0346251X},
  doi = {10/gpbz4f},
  urldate = {2022-02-01},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/LDJN8U8R/leInteractionPatternsPandemicinitiated2022.pdf}
}

@article{lenchukTappingBloomTaxonomy2021,
  title = {Tapping into {{Bloom Taxonomy}}'s {{Higher-Order Cognitive Processes}}: {{The Case}} for {{Multiple Choice Questions}} as a {{Valid Assessment Tool}} in the {{ESP Classroom}}},
  author = {Lenchuk, Iryna and Ahmed, Amer},
  year = {2021},
  month = apr,
  journal = {Arab World English Journal},
  pages = {160--171},
  publisher = {Arab World English Journal},
  issn = {2229-9327},
  abstract = {This article describes the results of Action Research conducted in an ESP classroom of Dhofar University located in Oman. Following the call of Oman Vision 2040 to emphasize educational practices that promote the development of higher-order cognitive processes, this study raises the following question: Can an online multiple choice question (MCQ) quiz tap into the higher-order cognitive skills of "apply," "analyze" and "evaluate?" This question was also critical at the time of the COVID-19 pandemic when Omani universities switched to the online learning mode. The researchers administered an online MCQ quiz to 35 undergraduate students enrolled in an ESP course for Engineering and Sciences. The results showed that MCQ quizzes could be developed to tap into higher-order thinking skills when the stem of the MSQ is developed as a task or a scenario. The study also revealed that students performed better on MCQs that tap into low-level cognitive skills. This result can be attributed to the prevalent practice in Oman to develop assessment tools that tap only into a level of Bloom's taxonomy, which involves the cognitive process of retrieving memorized information. The significance of the study lies in its pedagogical applications. The study calls for the use of teaching and assessment practices that target the development of higher-order thinking skills, which is aligned with the country's strategic direction reflected in Oman vision 2040.},
  keywords = {Cognitive Processes,Computer Assisted Testing,COVID-19,Electronic Learning,Engineering Education,English for Special Purposes,Evaluation Methods,Foreign Countries,Multiple Choice Tests,No DOI found,Oman,Pandemics,Student Evaluation,Taxonomy,Test Construction,Test Validity,Thinking Skills,Undergraduate Students}
}

@article{lenertIncorporationQualityAttributes2017,
  title = {The {{Incorporation}} of {{Quality Attributes}} into {{Online Course Design}} in {{Higher Education}}},
  author = {Lenert, Kathleen Anne and Janes, Diane P.},
  year = {2017},
  journal = {International Journal of E-Learning \& Distance Education},
  volume = {33},
  number = {1},
  issn = {EISSN-2292-8588},
  abstract = {A survey was designed incorporating questions on 28 attributes (compiled through a literature review) and considered to be quality features in online academic courses in higher education. This study sought to investigate the ongoing practice of instructional designers and instructors in the United States with respect to their incorporation of these quality best practices into their design process and course content. Although most respondents indicated they included the majority of the quality attributes in courses they designed or taught, a significant number rarely or never included some of the generally accepted features shown to result in positive learner outcomes.},
  langid = {english},
  keywords = {Best Practices,Comparative Analysis,Course Content,Educational Improvement,Educational Quality,Higher Education,Instructional Design,Likert Scales,No DOI found,Online Courses,Statistical Analysis,Surveys}
}

@article{leongFacialRecognitionFuture2019,
  title = {Facial Recognition and the Future of Privacy: {{I}} Always Feel like {\dots} Somebody's Watching Me},
  shorttitle = {Facial Recognition and the Future of Privacy},
  author = {Leong, Brenda},
  year = {2019},
  month = may,
  journal = {Bulletin of the Atomic Scientists},
  volume = {75},
  number = {3},
  pages = {109--115},
  issn = {0096-3402, 1938-3282},
  doi = {10.1080/00963402.2019.1604886},
  urldate = {2022-03-20},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/AAS3WVET/leongFacialRecognitionFuture2019.pdf}
}

@article{leppisaariSearchingEffectivePeer2018,
  title = {Searching for {{Effective Peer Assessment Models}} for {{Improving Online Learning}} in {{HE}} -- {{Do-It-Yourself}} ({{DIY}}) {{Case}}},
  author = {Leppisaari, Irja and Peltoniemi, Janne and Hohenthal, Tuula and Im, Yeonwook},
  year = {2018},
  journal = {Journal of Interactive Learning Research},
  volume = {29},
  number = {4},
  pages = {507},
  publisher = {Association for the Advancement of Computing in Education},
  issn = {1093-023X},
  abstract = {Peer assessment brings new affordances to the implementation of meaningful assessment on online courses (e.g. MOOCs) by using technological solutions to automate the assessment process. For this reason, teachers need digital pedagogic skills for planning, implementing and developing effective peer assessment models. In this paper we apply the criteria of a good peer assessment task to peer review the Do-It-Yourself (DIY) automatic evaluation path (peer assessment case) designed by one of the authors. Our collegial review employs a set of criteria teachers can use to develop peer assessment tasks in their teaching. The peer review describes the strengths and development needs of the DIY case. The case indicates that a successful peer assessment task also requires teachers to recognize changes in their role in a learning activity. Based on the peer review, the potential for the DIY model to provide automated peer assessment practices in game-oriented learning processes is acknowledged.},
  keywords = {Automation,College Instruction,College Students,Educational Games,Evaluation Criteria,Evaluation Methods,Foreign Countries,Individualized Instruction,Models,No DOI found,Online Courses,Pacing,Peer Evaluation}
}

@article{leslieIndianActHistorical2002,
  title = {The {{Indian Act}}: {{An Historical Perspective}}},
  author = {Leslie, John F},
  year = {2002},
  journal = {Canadian Parliamentary Review},
  volume = {25},
  number = {2},
  urldate = {2024-05-12},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/VQZSUS7P/25n2_02e_Leslie.pdf;/Users/colin.madland/Zotero/storage/8HZH8TX4/issue.html}
}

@article{lester-smithAboriginalHealthRoundtable2010,
  title = {Aboriginal Health Roundtable Discussions: "{{Why}} We Accept Your Invitation to Join You"},
  author = {{Lester-Smith}, Donna and Price, Roberta},
  year = {2010},
  journal = {Canadian Journal of Native Education},
  volume = {33},
  number = {1},
  pages = {46--62, 155},
  urldate = {2019-03-17}
}

@article{letonVideoPodcastIllustrated2018,
  title = {Video Podcast and Illustrated Text Feedback in a Web-Based Formative Assessment Environment},
  author = {Leton, E and {Molanes-Lopez}, {\relax EM} and Luque, M and Conejo, R},
  year = {2018},
  journal = {Computer Applications in Engineering Education},
  volume = {26},
  number = {2},
  pages = {187--202},
  issn = {1061-3773},
  doi = {10.1002/cae.21869},
  abstract = {It is well known that computer-based formative assessment and timely feedback enhance effective student learning but there is still a debate about what type of feedback should be given, being the text-based the most used feedback in practice. Although the use of video content as a learning resource has recently increased in both educational and non-educational contexts, there is very little research on its effectiveness as assessment feedback and the existing results are contradictory. For that reason, we have combined in this work the use of a web-based formative assessment system (Siette) where we have integrated a specific type of video podcast (modular teaching mini-videos: MTMs) and equivalent illustrated text. We have carried out two experiments with a twofold purpose, first to compare the effect of video feedback versus correct response feedback alone and secondly to compare the effect of video feedback versus equivalent illustrated text feedback. In the context of our research, a Statistic Course at university level, our results show, as expected, that there is a statistically significant positive effect in favor of video feedback over correct response feedback alone. Surprisingly, in contrast to our expectations, based on our context of acquisition of procedural knowledge, there is a statistically non-significant effect of video feedback versus equivalent illustrated text feedback. From the students' satisfaction survey, there is not statistically significant differences in the overall score of the activity based on video podcast feedback or equivalent illustrated text, which is an indication that we have really obtained equivalent feedback materials.},
  langid = {english},
  keywords = {AUDIO,CHANNEL,COMPUTER-BASED ASSESSMENT,EFFICACY,formative assessment,HIGHER-EDUCATION,illustrated text feedback,learning effectiveness,media in education,MEMORY,MULTIMEDIA,STUDENT,SYSTEM,video feedback,WRITTEN}
}

@book{levyHowTechnologyChanges,
  title = {How {{Technology Changes Demands}} for {{Human Skills}}},
  author = {Levy, F.},
  annotation = {{$<$}!--// //--{$>$}}
}

@book{lewisQualitativeResearchPractice2003,
  title = {Qualitative Research Practice: A Guide for Social Science Students and Researchers},
  author = {Lewis, 1962, Jane and Ritchie, Jane},
  year = {2003},
  number = {Book, Whole},
  publisher = {Sage Publications},
  address = {London;Thousand Oaks, Calif;},
  isbn = {0761971092;9780761971092;9780761971108;0761971106;},
  keywords = {Methodology,Qualitative analysis,Qualitative research,Research,Research methods,Social science research,Social sciences,Sociology}
}

@article{lewPositiveInterdependenceAcademic1986,
  title = {Positive Interdependence, Academic and Collaborative-Skills Group Contingencies, and Isolated Students},
  shorttitle = {Positive Interdependence, Academic and Collaborative-Skills Group Contingencies, and Isolated Students},
  author = {Lew, Marvin and Mesch, Debra and Johnson, David W. and Johnson, Roger},
  year = {1986},
  month = sep,
  journal = {American Educational Research Journal},
  volume = {23},
  pages = {476--488},
  doi = {10.3102/00028312023003476},
  abstract = {The effects of (a) opportunity to interact with classmates, (b) positive goal interdependence, (c) positive goal and positive reward interdependence, and (d) positive goal and reward interdependence with an added contingency for the use of collaborative skills were investigated. The dependent measures were achievement, interpersonal attraction, and the voluntary use of collaborative skills by socially withdrawn and isolated students. Four socially isolated and withdrawn sixth-grade students (two male and two female) were studied in a reading class. The results indicate that both positive goal and reward interdependence are needed to maximize student achievement and the interpersonal attraction between socially withdrawn and nonhandicapped students. The specific reinforcement for engaging in collaborative skills was required to maximize the voluntary engagement in the skills by socially withdrawn and isolated students.},
  annotation = {3}
}

@article{liDoesPeerAssessment2020,
  ids = {liDoesPeerAssessment2020a},
  title = {Does Peer Assessment Promote Student Learning? {{A}} Meta-Analysis},
  shorttitle = {Does Peer Assessment Promote Student Learning?},
  author = {Li, Hongli and Xiong, Yao and Hunter, Charles Vincent and Guo, Xiuyan and Tywoniw, Rurik},
  year = {2020},
  month = feb,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {45},
  number = {2},
  pages = {193--211},
  publisher = {Assessment \& Evaluation in Higher Education},
  issn = {0260-2938, 1469-297X},
  doi = {10/ghwk2w},
  urldate = {2021-07-03},
  langid = {english},
  keywords = {Computer Uses in Education,Effect Size,Elementary Secondary Education,Higher Education,Influences,Learning,Peer Evaluation,Student Role,Training},
  file = {/Users/colin.madland/Zotero/storage/QF2577ZP/liDoesPeerAssessment2020.pdf}
}

@article{liEvaluationMobileLearning2019,
  title = {Evaluation of Mobile Learning for the Clinical Practicum in Nursing Education: Application of the {{FRAME}} Model},
  author = {Li, Kam Cheong and Lee, Linda Yin-king and Wong, Suet-lai and Yau, Ivy Sui-yu and Wong, Billy Tak-ming},
  year = {2019},
  journal = {Journal of computing in higher education},
  volume = {31},
  number = {2},
  pages = {290--310},
  publisher = {Springer US},
  address = {New York},
  issn = {1042-1726},
  doi = {10.1007/s12528-019-09213-2},
  abstract = {This paper presents an evaluation of mobile learning practice for the clinical practicum in nursing education. Nursing students need to practise nursing skills and follow specific clinical procedures in wards. In this study, they were provided with a mobile device for learning purposes, with mobile apps preinstalled for watching nursing videos and conducting clinical assessments. The evaluation was conducted following the Framework for the Rational Analysis of Mobile Education (FRAME). It included a questionnaire survey involving 265 nursing students and focus group interviews with 20 nursing students, the course coordinator of the clinical practicum and the instructional designer of the mobile apps. The participants shared their views, perceptions and experiences of mobile learning for studying nursing skills and conducting clinical assessment in the practicum context. The results showed the participants' overall satisfaction with the mobile learning practice. They gave positive feedback on the use of the mobile apps in terms of enabling ubiquitous access to materials for situated learning in wards, and offering effective support for teachers to keep track of students' learning progress. They also suggested areas for improvements, which emphasised the hardware capacity of devices, training on the use of apps and institutional support for the maintenance of devices. The results of factor analysis showed a composition of underlying factors different from that of the original FRAME model, which suggests contextual variation in the application of the model.},
  keywords = {Applications programs,Computer Oriented Programs,Education,Education & Educational Research,Educational Technology,Factor analysis,Handheld Devices,Higher Education,Job Skills,Learning,Learning and Instruction,Medical research,Medicine Experimental,Mobile applications,Mobile communication systems,Mobile computing,Mobile devices,Nursing,Nursing Education,Nursing Students,Positive feedback,Postsecondary Education,Practicums,Program Effectiveness,Skill Development,Skills,Social Sciences,Student Satisfaction,Students,Technology Uses in Education,Telecommunications}
}

@article{lilleyRemoteLiveInvigilation2016,
  title = {Remote {{Live Invigilation}}: {{A Pilot Study}}},
  author = {Lilley, Mariana and Meere, Jonathan and Barker, Trevor},
  year = {2016},
  month = jan,
  journal = {Journal of Interactive Media in Education},
  volume = {2016},
  number = {1},
  publisher = {Journal of Interactive Media in Education},
  issn = {1365-893X},
  abstract = {There has been a growth in online distance learning programmes in Higher Education. This has led to an increased interest in different approaches to the assessment of online distance learners, including how to enhance student authentication and reduce the potential for cheating in online tests. One potential solution for this is the use of remote live invigilation. This work reports on a small scale pilot study where a group of 17 online distance learning Computer Science students from 7 different countries (Egypt, Kenya, Saudi Arabia, Slovakia, Trinidad \& Tobago, United Kingdom, Zambia) took part in an online test using remote live invigilation. Some examinees expressed concerns about data security and privacy. Furthermore, some examinees expressed concerns about the extent to which the remote live invigilation process would be intrusive, and impact negatively on their online assessment experience. Overall, findings from this study suggest that the remote live invigilation did not affect the assessment experience of the examinees in any way, with some examinees reporting that knowing that a live proctor was present gave them "peace of mind" in case technical problems occurred during the online test. Additionally, examinees suggested that remote live invigilation should be used more widely in online distance learning programmes as a means to enhance credibility.},
  keywords = {Cheating,College Students,Computer Assisted Testing,Computer Science Education,Distance Education,Egypt,Electronic Learning,Foreign Countries,Formative Evaluation,Information Security,Kenya,No DOI found,Online Courses,Pilot Projects,Privacy,Program Evaluation,Saudi Arabia,Slovakia,Student Attitudes,Student Evaluation,Summative Evaluation,Supervision,Trinidad and Tobago,United Kingdom,Zambia}
}

@article{linAssessingLearningTechnologyrich2020,
  title = {Assessing Learning in Technology-Rich Maker Activities: {{A}} Systematic Review of Empirical Research},
  author = {Lin, Qiao and Yin, Yue and Tang, Xiaodan and Hadad, Roxana and Zhai, Xiaoming},
  year = {2020},
  month = nov,
  journal = {Computers \& Education},
  volume = {157},
  publisher = {Elsevier Science},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2020.103944},
  abstract = {Maker activities are drawing increasing attention in the field of science, technology, engineering and mathematics (STEM) education. Researchers have developed various assessments for maker activities to examine students' learning outcomes. However, a systematic review of research on such assessments is lacking. To fill this gap, we reviewed empirical studies on maker-based assessments in education. We systematically examined 60 studies regarding the overall features of the maker activities, the learning outcomes that were measured, the assessment formats, and the psychometric evidence of the assessments. Our review results indicate that more than 20 types of maker platforms have been employed in the activities, with e-textiles and LilyPad Arduino being the most popular. Five types of assessment tools have been used prevalently to examine students' diverse learning outcomes, specifically artifact assessments, tests, surveys, interviews, and observations. Most assessments are used in STEM-related maker activities, especially technology-centric activities, to measure STEM-related learning outcomes. Only 15\% of the studies provide psychometric evidence of reliability and validity for the assessments. Based on the findings, we provide suggestions for future research which include developing more low-tech maker activities for students in lower-grades and with lower technology proficiency. In addition, future studies should improve rubrics for artifact assessment and explore more assessment tools for non-STEM subjects. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  keywords = {Computer Assisted Instruction,Digital Technology,Education,Educational Measurement,Evaluation methodologies,Interdisciplinary projects,Learning,Learning communities,Maker activities,School Learning,STEM,Teaching Methods,Teaching/learning strategies}
}

@article{lindsayNarrativeInquiryExperience2016,
  title = {Narrative {{Inquiry}}: {{Experience}} Matters},
  author = {Lindsay, Gail M. and Schwind, Jasna K.},
  year = {2016},
  journal = {Canadian Journal of Nursing Research},
  volume = {48},
  number = {1},
  pages = {14--20},
  issn = {0844-5621},
  doi = {10.1177/0844562116652230},
  urldate = {2019-02-09},
  abstract = {Narrative Inquiry is a research methodology that we adapted over the past two decades from Canadian higher education and curriculum studies to nursing research, education, and health-care practice. The Narrative Inquiry we use originated from Connelly and Clandinin in the 1990s, and rests on John Dewey?s philosophy that experience is relational, temporal, and situational, and as such, if intentionally explored, has the potential to be educational. More specifically, it is only when experience is reflected upon and reconstructed that it has the potential to reveal the construction of identity, knowledge, and the humanness of care. Congruent with the expectation that nurses are reflective practitioners and knowledge-makers, Narrative Inquiry provides a means to enhance, not only quality of care, but quality of experience of those in our care: in education, our students, and in practice, our patients. In this article, we explicate how Narrative Inquiry may be lived in health-care education and practice, with a primary focus on nursing. We illuminate how we support our graduate students, the next generation of narrative inquirers, through a Narrative Inquiry Works-in-Progress group.}
}

@article{linkTeachersPerceptionsGrading,
  title = {Teachers' {{Perceptions}} of {{Grading Practices}}: {{How Pre-Service Training Makes}} a {{Difference}}},
  author = {Link, Laura},
  volume = {28},
  number = {1},
  pages = {30},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/SB2MU2XA/linkTeachersPerceptionsGrading.pdf}
}

@article{linReviewUsingPartial2020,
  title = {A Review of Using Partial Least Square Structural Equation Modeling in E-learning Research},
  author = {Lin, Hung-Ming and Lee, Min-Hsien and Liang, Jyh-Chong and Chang, Hsin-Yi and Huang, Pinchi and Tsai, Chin-Chung},
  year = {2020},
  month = jul,
  journal = {British Journal of Educational Technology},
  volume = {51},
  number = {4},
  pages = {1354--1372},
  issn = {0007-1013, 1467-8535},
  doi = {10.1111/bjet.12890},
  urldate = {2023-08-24},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/C36NC5S6/linReviewUsingPartial2020.pdf}
}

@article{linStudentViewsHybrid2008,
  title = {Student {{Views}} of {{Hybrid Learning}}: {{A One-Year Exploratory Study}}},
  shorttitle = {Student {{Views}} of {{Hybrid Learning}}},
  author = {Lin, Oiuyun},
  year = {2008},
  month = dec,
  journal = {Journal of Computing in Teacher Education},
  volume = {25},
  number = {2},
  pages = {57--66},
  issn = {1040-2454, 2332-7421},
  doi = {10/ghwf6p},
  urldate = {2021-01-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/JVGYKRXR/linStudentViewsHybrid2008.pdf}
}

@article{linzerPoLCAPackagePolytomous2011,
  title = {{{poLCA}}: {{An R Package}} for {{Polytomous Variable Latent Class Analysis}}},
  shorttitle = {{{{\textbf{poLCA}}}}},
  author = {Linzer, Drew A. and Lewis, Jeffrey B.},
  year = {2011},
  journal = {Journal of Statistical Software},
  volume = {42},
  number = {10},
  issn = {1548-7660},
  doi = {10/gfv9m9},
  urldate = {2021-06-21},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/GVFBAV35/linzerPoLCAPackagePolytomous2011.pdf}
}

@article{liPeerAssessmentDigital2016,
  title = {Peer {{Assessment}} in the {{Digital Age}}: {{A Meta-Analysis Comparing Peer}} and {{Teacher Ratings}}},
  author = {Li, Hongli and Xiong, Yao and Zang, Xiaojiao and Kornhaber, Mindy L. and Lyu, Youngsun and Chung, Kyung Sun and Suen, Hoi K.},
  year = {2016},
  month = jan,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {41},
  number = {2},
  pages = {245--264},
  publisher = {Assessment \& Evaluation in Higher Education},
  issn = {0260-2938},
  doi = {10.1080/02602938.2014.999746},
  abstract = {Given the wide use of peer assessment, especially in higher education, the relative accuracy of peer ratings compared to teacher ratings is a major concern for both educators and researchers. This concern has grown with the increase of peer assessment in digital platforms. In this meta-analysis, using a variance-known hierarchical linear modelling approach, we synthesise findings from studies on peer assessment since 1999 when computer-assisted peer assessment started to proliferate. The estimated average Pearson correlation between peer and teacher ratings is found to be 0.63, which is moderately strong. This correlation is significantly higher when: (a) the peer assessment is paper-based rather than computer-assisted; (b) the subject area is not medical/clinical; (c) the course is graduate level rather than undergraduate or K-12; (d) individual work instead of group work is assessed; (e) the assessors and assessees are matched at random; (f) the peer assessment is voluntary instead of compulsory; (g) the peer assessment is non-anonymous; (h) peer raters provide both scores and qualitative comments instead of only scores; and (i) peer raters are involved in developing the rating criteria. The findings are expected to inform practitioners regarding peer assessment practices that are more likely to exhibit better agreement with teacher assessment.},
  keywords = {Comparative Analysis,Correlation,Elementary Secondary Education,Graduate Study,Hierarchical Linear Modeling,Literature Reviews,Meta Analysis,Peer Evaluation,Student Evaluation,Undergraduate Study}
}

@misc{lipenkovaChoosingRightLanguage2022,
  title = {Choosing the Right Language Model for Your {{NLP}} Use Case},
  author = {Lipenkova, Janna},
  year = {2022},
  month = sep,
  journal = {Medium},
  urldate = {2023-01-08},
  abstract = {A guide to understanding, selecting and deploying Large Language Models},
  howpublished = {https://towardsdatascience.com/choosing-the-right-language-model-for-your-nlp-use-case-1288ef3c4929},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/JIY9BRF2/choosing-the-right-language-model-for-your-nlp-use-case-1288ef3c4929.html}
}

@misc{lipmanowiczLiberatingStructures124All,
  title = {Liberating {{Structures}} - 1. 1-2-4-{{All}}},
  author = {Lipmanowicz, Henri and McCandless, Keith},
  urldate = {2019-11-17},
  howpublished = {http://www.liberatingstructures.com/1-1-2-4-all/},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/V2SAHWMX/1-1-2-4-all.html}
}

@article{lipnevichWhatGradesMean2020,
  title = {What Do Grades Mean? {{Variation}} in Grading Criteria in {{American}} College and University Courses},
  shorttitle = {What Do Grades Mean?},
  author = {Lipnevich, Anastasiya A. and Guskey, Thomas R. and Murano, Dana M. and Smith, Jeffrey K.},
  year = {2020},
  month = sep,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {27},
  number = {5},
  pages = {480--500},
  issn = {0969-594X, 1465-329X},
  doi = {10/ghjw3k},
  urldate = {2021-01-02},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/4YVJ7YZT/lipnevichWhatGradesMean2020.pdf}
}

@article{lipnevichWhatSyllabusAnalysis2021,
  title = {What's on the Syllabus? {{An}} Analysis of Assessment Criteria in First Year Courses across {{US}} and {{Spanish}} Universities},
  shorttitle = {What's on the Syllabus?},
  author = {Lipnevich, Anastasiya A. and Panadero, Ernesto and Gjicali, Kalina and Fraile, Juan},
  year = {2021},
  journal = {Educational Assessment, Evaluation and Accountability},
  volume = {33},
  number = {4},
  pages = {675--699},
  issn = {1874-8597, 1874-8600},
  doi = {10.1007/s11092-021-09357-9},
  urldate = {2022-11-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/B3KC8RDH/lipnevichWhatSyllabusAnalysis2021.pdf}
}

@article{listerAssessmentLifeCircumstances2023,
  title = {Assessment, Life Circumstances, Curriculum and Skills: {{Barriers}} and Enablers to Student Mental Wellbeing in Distance Learning},
  shorttitle = {Assessment, Life Circumstances, Curriculum and Skills},
  author = {Lister, Kate and Andrews, Kyle and Buxton, Jo and Douce, Chris and Seale, Jane},
  year = {2023},
  month = feb,
  journal = {Frontiers in Psychology},
  volume = {14},
  pages = {1076985},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2023.1076985},
  urldate = {2024-01-15},
  abstract = {Student mental wellbeing is increasingly a priority for universities, and this is particularly critical in a distance learning context. Studies have found that studying, academic pressure, university culture and systems can affect students' mental health. There are increasing calls for universities to take a compassionate, holistic approach to supporting student wellbeing, and identify the barriers that are created by university cultures, systems, pedagogies, curricula, tuition and assessment practices. This study aimed to identify barriers and enablers to student mental wellbeing in distance learning, and students' recommendations for changes to be made. Using a student survey (N\,=\,584), we identified that assessment and life circumstances were the most significant barriers, while the greatest enablers were building study skills, the people in students' lives, and curriculum and module content. The study revealed significant demographic differences in how students experience barriers and enablers, and how likely they feel they are to benefit from solutions. Students with disclosed mental health difficulties were consistently more likely to experience barriers than students without a disclosure, while enablers were experienced by all demographic groups. The study concludes that assessment should be prioritised as an area for action.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/YHRPHVCD/listerAssessmentLifeCircumstances2023.pdf}
}

@article{listerMentalHealthDistance2021,
  title = {Mental {{Health}} in {{Distance Learning}}: {{A Taxonomy}} of {{Barriers}} and {{Enablers}} to {{Student Mental Wellbeing}}},
  author = {Lister, Kate and {Tai-Seale}, Ming and Douce, Christopher},
  year = {2021},
  journal = {Open Learning the Journal of Open Distance and E-Learning},
  doi = {10.1080/02680513.2021.1899907},
  file = {/Users/colin.madland/Zotero/storage/N7K44DIB/listerMentalHealthDistance2021.pdf}
}

@article{littlejohnLearningDigitalFrontier2012,
  title = {Learning at the Digital Frontier: A Review of Digital Literacies in Theory and Practice},
  author = {Littlejohn, A. and Beetham, H. and McGill, L.},
  year = {2012},
  journal = {Journal of computer assisted learning},
  edition = {Accepted: 30 November 2011},
  volume = {28},
  number = {6},
  pages = {547--556},
  publisher = {Blackwell Publishing Ltd},
  address = {Oxford, UK},
  issn = {0266-4909},
  doi = {10.1111/j.1365-2729.2011.00474.x},
  abstract = {This paper describes a literature review, institutional audit and analysis of practice in the area of digital literacy provision, based on research across the UK Higher Education sector. It concludes that institutions need to place greater value on `literacies of the digital', and better prepare their students and their own organizational processes to thrive in an age of digital knowledge practices. It extends the debate about individual entitlement and provision to ask whether digital literacy offers an opportunity for the academy to redefine its relationship to knowledge in society.},
  keywords = {Age,Analysis,Applied psychology,Audits (Verification),Biological and medical sciences,Computer Literacy,Content Analysis,Digital,digital literacies,digital scholarship,Education,Educational Practices,Foreign Countries,Fundamental and applied biological sciences. Psychology,Higher Education,Information Literacy,Information Skills,Learning,literacies,Literacy,Literacy programs,Literature Reviews,Minimum Competencies,Miscellaneous,Position Papers,Program Descriptions,Psychology. Psychoanalysis. Psychiatry,Psychology. Psychophysiology,Skill Analysis,Students,technology enhanced learning,Theory,Theory Practice Relationship,United Kingdom},
  file = {/Users/colin.madland/Zotero/storage/NF6E8KJ6/littlejohnLearningDigitalFrontier2012.pdf}
}

@incollection{littlejohnSystemTheory1996,
  title = {System {{Theory}}},
  booktitle = {Theories of Human Communication},
  author = {Littlejohn, S},
  editor = {Littlejohn, S.},
  year = {1996},
  publisher = {Thomson Learning Global Rights Group},
  address = {Belmont, CA},
  annotation = {MDDE603 Course Readings}
}

@article{litvakNoExamAssessment2022,
  title = {No Exam: Assessment of Third-Year Engineering Students on the Basis of Self-Generated {{Statistics}} Cases},
  author = {Litvak, Nelly and Kula, Fulya},
  year = {2022},
  journal = {International journal of mathematical education in science and technology},
  volume = {53},
  number = {3},
  pages = {647--655},
  publisher = {Taylor \& Francis},
  address = {London},
  issn = {0020-739X},
  doi = {10.1080/0020739X.2021.1982041},
  abstract = {Through the global pandemic, the single greatest challenge at universities has been the move towards digital assessment. In this classroom note, we describe our new no-exam assessment setup in a Statistics course for third-year bachelor Mechanical Engineering students. The main idea is to assess the students based on self-generated problems. Crucially, we supported students by providing a very clear structure of the course material, learning objectives, and requirements. At the same time, we left sufficient space for the students to tune the final assignment to their interests, creativity, and mathematical skills. In our experience, this setup makes assessment meaningful and enjoyable for both the students and the teacher and does not need to demand excessive time investment on the teacher's side. We strongly believe that approaches like ours will have potential lasting effects on the diversity of assessment, quality of learning, and, last but not least, the appeal of Statistics for future engineers.},
  keywords = {assessment,Assignments,Colleges & universities,Course Content,Educational Assessment,Educational Objectives,Engineering Education,Learning,Mechanical engineering,Quality assessment,remote assessment,Statistics,Statistics assessment,Statistics assessment in engineering,Statistics Education,Student Educational Objectives,Student Evaluation,Students,Teachers,tertiary education,Undergraduate Students},
  file = {/Users/colin.madland/Zotero/storage/HP3U4E4Z/litvakNoExamAssessment2022.pdf}
}

@inproceedings{liuAssessingMeasurementInvariance2008,
  title = {Assessing {{Measurement Invariance}} of the {{Teachers}}' {{Perceptions}} of {{Grading Practices Scale}} across {{Cultures}}},
  booktitle = {{{NERA Conference Proceedings}} 2008},
  author = {Liu, Xing},
  year = {2008},
  pages = {28},
  publisher = {Northeastern Educational Research Association},
  address = {Rocky Hill, CT},
  urldate = {2020-12-30},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/26BKQUWY/liuAssessingMeasurementInvariance2008.pdf}
}

@article{liuAutomatingStudentAssessment2023,
  title = {Automating Student Assessment Using Digital Data to Improve Education Management Effectiveness in Higher Education Institutions},
  author = {Liu, Chun},
  year = {2023},
  journal = {Education and information technologies},
  publisher = {Springer Nature},
  address = {NEW YORK},
  issn = {1360-2357},
  doi = {10.1007/s10639-023-11898-z},
  abstract = {The objectives of this work are to investigate the impact of automating the student assessment process using the Schoology web-based learning management system as an example and determine its effectiveness and usability by performing a comparative analysis between the survey results of educators and students. The research methodology is based on an exploratory survey using a data collection questionnaire composed of closed-ended questions. The respondents are 630 students and 159 faculty members from three Chinese higher education institutions. The data analysis enables the conclusion that the overall student and faculty satisfaction with Schoology is high (83.4\% and 55\%, respectively). The students and educators indicate that with the introduction of Schoology, learning and teaching became easier (82.5\% and 53.4\%, respectively). In line with this, the analysis of the effect of the automated performance assessment implementation on student academic performance find that learners are more prone to better learning outcomes after this system's launching. The practical significance of this paper is that it demonstrates the positive influence of the Schoology system on educational process effectiveness.},
  keywords = {Education & Educational Research,Social Sciences}
}

@article{liuBayesianMixedEffects2021,
  ids = {liuBayesianMixedEffects2021a},
  title = {Bayesian {{Mixed Effects Model}} and {{Data Visualization}} for {{Understanding Item Response Time}} and {{Response Order}} in {{Open Online Assessment}}},
  author = {Liu, Yan and Beliveau, Audrey and Besche, Henrike and Wu, Amery D. and Zhang, Xingyu and Stefan, Melanie and Gutlerner, Johanna and Kim, Chanmin},
  year = {2021},
  journal = {Frontiers in education (Lausanne)},
  volume = {5},
  publisher = {Frontiers Media Sa},
  address = {LAUSANNE},
  issn = {2504-284X},
  doi = {10.3389/feduc.2020.607260},
  abstract = {Open (open-book) online assessment has become a great tool in higher education, which is frequently used for monitoring learning progress and teaching effectiveness. It has been gaining popularity because it is flexible to use and makes response behavior data available for researchers to study response processes. However, some challenges are encountered in analyzing these data, such as how to handle outlying response time, how to make use of the information from item response order, how item response time, response order and item scores are related, and how to help classroom teachers quickly check whether student responses are aligned with the design of the assessment. The purposes of this study are 3-fold: (1) to provide a solution for handling outlying response times due to the design of open online formative assessments (i.e., ample or unrestricted testing time), (2) to propose a new measure for investigating the item response order, and (3) to discuss two analytical approaches that are useful for studying response behaviors-data visualization and the Bayesian generalized linear mixed effects model (B-GLMM). An application of these two approaches is illustrated using open online quiz data. Our findings obtained from B-GLMM showed that item response order was related to item response time, but not to item scores; and item response time was related to item scores, but its effects were moderated by the cognitive level. Additionally, the findings from both B-GLMM and data visualization were consistent, which assisted instructors to see the alignment of student responses with the assessment design.},
  keywords = {Bayesian generalized linear mixed effects model (B-GLMM),classroom assessment,Education & Educational Research,open online assessment,open-book online assessment,response order,response time,Social Sciences},
  file = {/Users/colin.madland/Zotero/storage/JMQGTHLA/liuBayesianMixedEffects2021.pdf}
}

@article{liuCoLearningNewModel2020,
  title = {Co-{{Learning}} as a {{New Model}} of {{Learning}} in a {{Digital Environment}}: {{Learning Effectiveness}} and {{Collaboration}}},
  author = {Liu, {\relax ZQ} and Dorozhkin, E and Davydova, N and Sadovnikova, N},
  year = {2020},
  journal = {INTERNATIONAL JOURNAL OF EMERGING TECHNOLOGIES IN LEARNING},
  volume = {15},
  number = {13},
  pages = {34--48},
  issn = {1863-0383},
  doi = {10.3991/ijet.v15i13.14667},
  abstract = {During the last decade, co-learning techniques have been widely used for the formation of an effective open society. Co-learning allows increasing the skills of social adaptation and joint work of representatives of inhomogeneous groups. The purpose of this study was to determine educational effectiveness, as well as danger, the effectiveness of the digital environment in developing social skills and achieving learning quality in a new generation. The study was conducted in the form of a survey among 60 students from Gulin Tourism University and Moscow State Pedagogical University; they were divided into two groups, the methods of cooperative and collaborative co-education with immersion in a digital environment were used. A control group consisted of at least 30 students. The real effectiveness of training was tested both by the solution of task and by independent testing that was obtained in the process of solving. A separate survey was conducted to establish a subjective assessment by students of the social skills and interaction. The survey was conducted according to the methods that have been developed over the past 6 years by different groups of researchers. Consequently, it was found out that co-learning technologies do not influence the quality of training and the assimilation, and students immersed in a digital environment showed even better results. The number of students with most correct answers for the test was 46.67\% and 23.33\% in study groups, and only 10\% - in control group. Generally, the results of a subjective assessment of social skills coincides with similar data obtained by other researchers and shows an improvement of collaboration in inhomogeneous groups, slighter leadership in common problems solving, and very low conflict indicators. Generally, the results of a subjective assessment of social skills coincides with similar data obtained by other researchers and shows an improvement of collaboration in inhomogeneous groups, slighter leadership in common problems solving, and very low conflict indicators.},
  langid = {english},
  keywords = {Collaborative learning,cooperative learning,digital environment,EDUCATION,emerging technologies}
}

@incollection{liuDevelopmentValidationEnglish2013,
  title = {Development and {{Validation}} of an {{English Classroom Learning Environment Inventory}} and Its {{Application}} in {{China}}},
  booktitle = {Application of {{Structural Equation Modeling}} in {{Educational Research}} and {{Practice}}},
  author = {Liu, Liyan and Fraser, Barry J.},
  editor = {Khine, Myint Swe},
  year = {2013},
  pages = {75--89},
  publisher = {SensePublishers},
  address = {Rotterdam},
  doi = {10.1007/978-94-6209-332-4_4},
  urldate = {2023-07-07},
  isbn = {978-94-6209-332-4},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/744P3QAU/liuDevelopmentValidationEnglish2013.pdf}
}

@article{liuOnlineAssessmentHigher2024,
  title = {Online Assessment in Higher Education: A Mapping Review and Narrative Synthesis},
  shorttitle = {Online Assessment in Higher Education},
  author = {Liu, Qian and Hu, Anjin and Daniel, Ben},
  year = {2024},
  month = may,
  journal = {Research and Practice in Technology Enhanced Learning},
  volume = {20},
  pages = {007},
  issn = {1793-7078},
  doi = {10.58459/rptel.2025.20007},
  urldate = {2024-06-26},
  abstract = {Online assessment takes many forms. While there have been reviews on a particular online assessment approach (e.g., online examinations or tests), there has not been a knowledge synthesis that considers online assessment research as a whole. A holistic understanding of online assessment research is important, as it recognizes differences in assessment approaches and the role of technologies in assessment. This understanding helps researchers navigate the heterogeneous body of research and allows educators to make research-informed improvements. To establish such an understanding, we analyzed 235 articles, following a mapping review and a narrative synthesis method. The findings revealed tests, assignments and skills assessments are major online assessment approaches. While research into tests reported using online technologies mainly to substitute or augment existing assessment, research into assignments and skills assessments was more likely to report using online technologies to modify or redefine assessment. Further, we identified disparities across the three approaches regarding academic misconduct, assessment validity, and reliability. We also identified a dearth of comparative research and a reliance on overall satisfaction and short-term self-reported impact measures as indicators of success. We discuss the implications of this review to provide insights for institutions and educators seeking to improve online assessment practices.},
  copyright = {http://creativecommons.org/licenses/by-nc-nd/4.0},
  file = {/Users/colin.madland/Zotero/storage/7V8G3XPQ/liuOnlineAssessmentHigher2024.pdf}
}

@article{lizcanoBlockchainbasedApproachCreate2020,
  title = {Blockchain-Based Approach to Create a Model of Trust in Open and Ubiquitous Higher Education},
  author = {Lizcano, David and Lara, Juan A. and White, Bebo and Aljawarneh, Shadi},
  year = {2020},
  journal = {Journal of Computing in Higher Education},
  volume = {32},
  number = {1},
  pages = {109--134},
  issn = {1042-1726, 1867-1233},
  doi = {10.1007/s12528-019-09209-y},
  urldate = {2022-11-05},
  abstract = {Currently, the training of the future work force presents challenging problems to higher education. This training, in the form of practical and theoretical knowledge can come from multiple platforms, channels and means, both formal and informal. In addition, it is quite difficult to assess the knowledge skill level that a student has acquired to optimize their chances for future employability. This, together with the need to still manage academic curricula on paper, the problems of confidence when validating these documents and contrasting them with real knowledge, etc., means that management in higher education requires revolutionary new tools. This work evaluates the benefits of the blockchain (or distributed ledger) technology and advocates a decentralised model of confidence for transactions based on an academic crypto currency. In this approach blockchain is used to manage transactions of content, teaching and competencies, assessed by consensus by students, trainers and employers, to eliminate once and for all the ``gap'' between the academic world and the working world. This paper aims to address the current challenges of an increasingly dispersed, open and ubiquitous higher education. The proposed model can be implemented in any training institution to adapt its teaching to the specific needs of professional profiles validated by employers in the sector. This model has been validated by means of a prototype with more than acceptable results.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/Z97FJ3LE/lizcanoBlockchainbasedApproachCreate2020.pdf}
}

@article{lnenickaBigOpenLinked2020,
  title = {Big and Open Linked Data Analytics: A Study on Changing Roles and Skills in the Higher Educational Process},
  author = {Lnenicka, Martin and Kopackova, Hana and Machova, Renata and Komarkova, Jitka},
  year = {2020},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {17},
  number = {1},
  pages = {1--30},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-020-00208-z},
  abstract = {The concept of openness and information sharing (linking) together with increasing amounts of data available significantly affect the current educational system. Institutions as well as other stakeholders are facing challenges how to successfully deal with them and potentially profit from them. In this regard, this paper explores opportunities of big and open linked data analytics in the educational process intended to develop the new set of skills. A comprehensive literature review resulted in a framework of relevant skills, namely soft, hard, and data analytics skills. Their importance was evaluated using a Delphi method. In order to determine the relationships between involved stakeholders, their roles and requirements, a stakeholder theory is utilized. It resulted in the identification of current and emerging roles of stakeholders in the data analytics ecosystem. A structural classification of stakeholders' influences and impacts then represents a necessary background for establishing strategies for the development of the right skills needed to gain the value from these data. This paper provides a comprehensive view on big and open linked data analytics in the educational context, defines and interlinks data-related with current roles as well as the skills required to perform data analytics.},
  keywords = {Analytics,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Data analysis,Delphi method,Education,Educational Technology,Framework,Higher Education,Humanities,Information Systems Applications (incl.Internet),Law,Linked Data,Literature reviews,Mathematical analysis,Research Article,Skills,Stakeholder theory,Statistics for Social Sciences},
  file = {/Users/colin.madland/Zotero/storage/V5K2N9CB/lnenickaBigOpenLinked2020.pdf}
}

@article{lockCreatingTechnologyEnabled2021,
  title = {Creating Technology-enabled Lifelong Learning: {{A}} Heutagogical Approach},
  shorttitle = {Creating Technology-enabled Lifelong Learning},
  author = {Lock, Jennifer and Lakhal, Sawsen and Cleveland-Innes, Martha and Arancibia, Paula and Dell, Debra and De Silva, Noeleen},
  year = {2021},
  month = jul,
  journal = {British Journal of Educational Technology},
  volume = {52},
  number = {4},
  pages = {1646--1662},
  issn = {0007-1013, 1467-8535},
  doi = {10.1111/bjet.13122},
  urldate = {2022-10-01},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/3RBVXGV2/lockCreatingTechnologyEnabled2021.pdf}
}

@article{lockmanOnlineInstructionHigher2020,
  title = {Online {{Instruction}} in {{Higher Education}}: {{Promising}}, {{Research-Based}}, and {{Evidence-Based Practices}}},
  author = {Lockman, Alison S. and Schirmer, Barbara R.},
  year = {2020},
  journal = {Journal of Education and e-Learning Research},
  volume = {7},
  number = {2},
  pages = {130--152},
  issn = {ISSN-2518-0169},
  doi = {10/gmbvzx},
  abstract = {The purpose of this study was to review the research literature on online learning to identify effective instructional practices. We narrowed our scope to empirical studies published 2013-2019 given that studies earlier than 2013 had become quickly outdated because of changes in online pedagogies and technologies. We also limited our search to studies with undergraduate and graduate students, application of an empirical methodological design, and descriptions of methodology, data analysis, and results with sufficient detail to assure verifiability of data collection and analysis. Our analysis of the patterns and trends in the corpus of 104 research studies led to identification of five themes: course design factors, student support, faculty pedagogy, student engagement, and student success factors. Most of the strategies with promising effectiveness in the online environment are the same ones that are considered to be effective in face-to-face classrooms including the use of multiple pedagogies and learning resources to address different student learning needs, high instructor presence, quality of faculty-student interaction, academic support outside of class, and promotion of classroom cohesion and trust. Unique to the online environment are user-friendly technology tools, orientation to online instruction, opportunities for synchronous class sessions, and incorporation of social media. Given the few studies utilizing methodological designs from which claims of causality can be made or meta-analyses could be conducted, we identified only faculty feedback as an evidence-based practice and no specific intervention that we could identify as research-based in online instruction.},
  langid = {english},
  keywords = {Academic Support Services,Classroom Environment,College Faculty,College Students,Curriculum Design,Discussion (Teaching Technique),Educational Resources,Educational Technology,Evidence Based Practice,Feedback (Response),Instructional Effectiveness,Learner Engagement,Online Courses,Orientation,Self Efficacy,Social Media,Student Needs,Success,Synchronous Communication,Teacher Student Relationship,Teaching Methods,Trust (Psychology),Video Technology}
}

@article{lockNavigatingTensionsInnovative2018,
  title = {Navigating the {{Tensions}} of {{Innovative Assessment}} and {{Pedagogy}} in {{Higher Education}}},
  author = {Lock, J and Kim, B and Koh, K and Wilcox, G},
  year = {2018},
  journal = {Canadian Journal for the Scholarship of Teaching and Learning},
  volume = {9},
  number = {1},
  issn = {1918-2902},
  doi = {10.5206/cjsotl-rcacea.2018.1.8},
  abstract = {Innovative practice in a classroom adds challenges and tensions to programs and institutional structures in higher education. With the recent emphasis on curricula reform, there is a great focus on assessment and pedagogical practices to support student learning. To illustrate the tensions arising from these efforts, we present four pedagogical and assessment innovation approaches using both Shulman's (2005) Signature Pedagogies and Tatar's (2007) Design Tensions frameworks. The four approaches include problem-based learning, game-based learning, case-based learning, and technology-enhanced learning. A narrative for each approach examines and addresses tensions using Shulman's (2005) surface, deep and implicit structures. We argue that there is an interconnected complexity and conflicting visions among the micro- (e.g., classroom or practicum), meso- (e.g., program), and macro- (e.g., institution) levels. We acknowledge that dynamic tensions continually exist and needs to be thoughtfully navigated in support of innovative assessment and pedagogies in higher education.},
  langid = {english},
  keywords = {assessment,Case Method (Teaching Technique),COMPETENCE,DESIGN,design tensions,Educational Games,Educational Innovation,Educational Technology,Evaluation Methods,Foreign Countries,FORMATIVE ASSESSMENT,higher education,Higher Education,Problem Based Learning,school psychologist,SCHOOLS,signature pedagogy,SINGAPORE,teachers,Teaching Methods,Technology Uses in Education},
  file = {/Users/colin.madland/Zotero/storage/D964QYWR/lockNavigatingTensionsInnovative2018a.pdf}
}

@article{lockTriangulatingAssessmentOnline2015,
  title = {Triangulating {{Assessment}} of {{Online Collaborative Learning}}},
  author = {Lock, Jennifer and Johnson, Carol},
  year = {2015},
  journal = {Quarterly Review of Distance Education},
  volume = {16},
  number = {4},
  pages = {61},
  publisher = {IAP - Information Age Publishing, Inc},
  address = {Charlotte},
  issn = {1528-3518},
  abstract = {Collaboration plays an integral role in the construction of knowledge in online learning environments. A supportive foundation for learning can be created through the intentional design of formative and summative assessments that embrace self-, peer-, and instructor assessment practices. The purpose of this article is to: (1) examine current assessment practices of online collaborative learning, and (2) present a model of interconnected components: assessment design, assessment transactions, and assessment for knowledge construction. When implemented, these strategic interconnections advance student learning through assessment that informs learning processes and practices.;Collaboration plays an integral role in the construction of knowledge in online learning environments. A supportive foundation for learning can be created through the intentional design of formative and summative assessments that embrace self-, peer-, and instructor assessment practices. The purpose of this article is to: (1) examine current assessment practices of online collaborative learning, and (2) present a model of interconnected components: assessment design, assessment transactions, and assessment for knowledge construction. When implemented, these strategic interconnections advance student learning through assessment that informs learning processes and practices.;},
  keywords = {Active learning,Analysis,Collaborative learning,Cooperation,Cooperative Learning,Design,Distance learning,Educational evaluation,Electronic Learning,Formative Evaluation,Group work in education,Information sharing,Methods,No DOI found,Online Courses,Online education,Peers,Summative Evaluation,Team learning approach in education}
}

@techreport{lodgeAssessmentReformAge2023,
  title = {Assessment Reform for the Age of Artificial Intelligence},
  author = {Lodge, Jason M and Howard, Sarah and Bearman, Margaret and Dawson, Phillip and Agostinho, Shirley and {Associates}},
  year = {2023},
  institution = {TEQSA},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/UU7WXGEC/lodgeAssessmentReformAge.pdf}
}

@misc{lofgreenGettingOutScylla2022,
  title = {Getting {{Out From Between Scylla}} and  {{Charybdis}}: {{Using Philosophy}} of {{Science}} to {{See SoTL}} as Its {{Own Form}} of {{Inquiry}}.},
  author = {L{\"o}fgreen, Jennifer},
  year = {2022},
  month = nov,
  address = {Kelowna, BC},
  abstract = {When you think of what SoTL inquiry is, as inquiry, how do you conceptualize it? What assumptions do you make, and where do those assumptions come from? I have a sneaking suspicion that we have devoted far too little attention to the basic underlying assumptions that we hold about scholarly inquiry, and that these assumptions are exerting problematic influence on SoTL. In this presentation, I will critically examine the way we conceptualize SoTL in the literature, in order to suggest a better way of approaching it. I will start by problematizing the common idea of situating SoTL in relation to the disciplines and educational research, arguing that this way of conceptualizing SoTL leads to disciplinary ideas of research exerting problematic influence on SoTL. This puts SoTL between the mythological monster Scylla (disciplinary research) and the deadly whirlpool Charybdis (educational research): Scylla's many heads would fragment SoTL, whereas Charybdis' vortex would consume it completely. To avoid this, a fundamental paradigm view of inquiry, decoupled from the disciplines, would be more suitable for SoTL. As a way of approaching this paradigm view of SoTL, I use the concept of knowledge-constitutive interests from the early work of German critical theorist J{\quotesinglbase}rgen Habermas (1971). I outline a more fundamental starting point for conceptualizing SoTL that allows SoTL to be its own form of inquiry with its own nature, rather than a twisted offshoot of disciplinary research, some sort of interdisciplinary mutt, or the poor cousin of educational research. Finally, I use this new way of conceptualizing SoTL to propose an approach that recognizes the special nature of SoTL and has the potential to simply eliminate many of the conflicts that seem to pervade the conceptual literature on SoTL.}
}

@article{lohrPowerpointersClickerersDigital2021,
  title = {On Powerpointers, Clickerers, and Digital Pros: {{Investigating}} the Initiation of Digital Learning Activities by Teachers in Higher Education},
  author = {Lohr, Anne and Stadler, Matthias and {Schultz-Pernice}, Florian and Chernikova, Olga and Sailer, Maximilian and Fischer, Frank and Sailer, Michael},
  year = {2021},
  journal = {Computers in human behavior},
  volume = {119},
  pages = {106715},
  publisher = {Elsevier Ltd},
  address = {OXFORD},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2021.106715},
  abstract = {This study investigated the initiation of digitally supported learning activities and personal and institutional factors associated with them in different higher education courses, based on the C{$\flat$}-model. The C{$\flat$}-model is a theoretical framework that systematizes contextual factors, which influence students` learning activities as the most important facilitator of students' learning success. Using a self-assessment instrument with anchored scenarios in a sample of 1625 higher education teachers, we were able to identify three levels at which higher education teachers initiated digital learning activities: a low level (powerpointers), a moderate level (clickerers), and a high level (digital pros). The findings also support the relevance of the contextual factors specified in the C{$\flat$}-model for initiating a high level of digital learning activities, namely digitalization policy and commitment of university administration, institutional equipment, technical and educational support, self-assessed basic digital skills, and self-assessed technology-related teaching skills. All of these factors explain a substantial amount of variance in the level of initiated digital learning activities. We conclude that a comprehensive approach rather than isolated measures might contribute to successful teaching and learning in higher education. {$\bullet$}Investigation of learning activities involving digital technology initiated by higher education teachers.{$\bullet$}Teachers initiated learning activities on a low (powerpointers), a moderate (clickerers), or a high level (digital pros).{$\bullet$}Investigation of factors relating to the level of initiated digital learning activities based on the C{$\flat$}-model.{$\bullet$}Institutional factors and teachers' skills related positively to the level of initiated digital learning activities.{$\bullet$}Results support the relevance of contextual factors proposed by the C{$\flat$}-model.},
  keywords = {Activity programs in education,Analysis,College teachers,Colleges & universities,Digital learning activities,Digital technologies,Digitization,Education,Education Higher,Educational technology,Higher education,Institutional factors,Investigations,Learning,Low level,Organizational aspects,Psychology,Psychology Experimental,Psychology Multidisciplinary,Skills,Social Sciences,Structural equation modeling,Students,Teachers,Teachers' skills,Teaching,Technology assessment},
  file = {/Users/colin.madland/Zotero/storage/YC7RWZWZ/lohrPowerpointersClickerersDigital2021.pdf}
}

@article{looneyDigitalFormativeAssessment2019,
  title = {Digital {{Formative Assessment}}: {{A}} Review of the Literature},
  author = {Looney, Janet},
  year = {2019},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/DDFNEB3W/Looney - Digital Formative Assessment A review of the lite.pdf}
}

@article{looneyReconceptualisingRoleTeachers2017,
  title = {Reconceptualising the Role of Teachers as Assessors: Teacher Assessment Identity},
  author = {Looney, A. and Cumming, J. and {\noopsort{kleij}}{van der Kleij}, Fabienne M. and Harris, K.},
  year = {2017},
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {25},
  pages = {442--467},
  doi = {10/gfkfk6},
  abstract = {Abstract Teachers' capabilities to conduct classroom assessment and use assessment evidence are central to quality assessment practice, traditionally conceptualised as assessment literacy. In this paper we present, firstly, an expanded conceptualisation of teachers' assessment work. Drawing on research on teacher identity, we posit that teachers' identity as professionals, beliefs about assessment, disposition towards enacting assessment, and perceptions of their role as assessors are all significant for their assessment work. We term this reconceptualisation Teacher Assessment Identity (TAI). Secondly, in support of this conceptual work, we present findings from a systematic review of self-report scales on teacher assessment literacy and teacher identity related to assessment. The findings demonstrate that such scales and previous research exploring teacher assessment practices have paid limited attention to what we identify as essential and broader dimensions of TAI. We share our reconceptualisation and analyses to encourage others to consider teacher assessment work more broadly in their research.},
  file = {/Users/colin.madland/Zotero/storage/3D3VBZCL/looneyReconceptualisingRoleTeachers2017.pdf}
}

@article{lopez-zambranoEarlyPredictionStudent2021,
  title = {Early Prediction of Student Learning Performance through Data Mining: {{A}} Systematic Review},
  author = {{L{\'o}pez-Zambrano}, Javier and Lara Torralbo, Juan Alfonso and Romero, Crist{\'o}bal},
  year = {2021},
  journal = {Psicothema},
  volume = {33},
  number = {3},
  pages = {456--465},
  publisher = {Colegio Oficial de Psic{\'o}logos del Principado de Asturias},
  issn = {0214-9915},
  abstract = {Background: Early prediction of students' learning performance using data mining techniques is an important topic these days. The purpose of this literature review is to provide an overview of the current state of research in that area. Method: We conducted a literature review following a two-step procedure, looking for papers using the major search engines and selection based on certain criteria. Results: The document search process yielded 133 results, 82 of which were selected in order to answer some essential research questions in the area. The selected papers were grouped and described by the type of educational systems, the data mining techniques applied, the variables or features used, and how early accurate prediction was possible. Conclusions: Most of the papers analyzed were about online learning systems and traditional face-to-face learning in secondary and tertiary education; the most commonly-used predictive algorithms were J48, Random Forest, SVM, and Naive Bayes (classification), and logistic and linear regression (regression). The most important factors in early prediction were related to student assessment and data obtained from student interaction with Learning Management Systems. Finally, how early it was possible to make predictions depended on the type of educational system. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {Academic Achievement Prediction,Algorithms,At Risk Populations,Bayes Theorem,Computer Searching,Data Mining,Detection of students at-risk of Dropping-out.,Early prediction of academic performance,Early Warning Systems,Educational Data Mining,Humans,Learning,Learning Analytics,No DOI found,Predictability (Measurement),Prediction,School Learning,Students}
}

@article{lopezriosComprehensiveStatisticalAssessment2020,
  title = {A Comprehensive Statistical Assessment Framework to Measure the Impact of Immersive Environments on Skills of Higher Education Students: A Case Study},
  author = {Lopez Rios, Olga and Lechuga Lopez, Leopoldo Julian and Lechuga Lopez, Gisela},
  year = {2020},
  journal = {International journal on interactive design and manufacturing},
  volume = {14},
  number = {4},
  pages = {1395--1410},
  publisher = {Springer Paris},
  address = {Paris},
  issn = {1955-2513},
  doi = {10.1007/s12008-020-00698-1},
  abstract = {Universities are facing the challenge of updating the contents of their current study programs and adopting novel education strategies in order to prepare the next generation of engineers who can adapt to the highly competitive labor market of Industry 4.0. This new industrial era requires skills and competencies in state-of-the-art technologies which are constantly and rapidly evolving. This research presents an alternative approach to the current teaching--learning methodologies, focusing on the use of Virtual Reality (VR) as an educational tool and its contribution towards the upcoming industrial challenges, via what we call interactive education for future engineers (IE). Our IE strategy is supported by interactive simulation using the latest VR technologies, currently being Facebook's Oculus Rift hardware and software. With this approach, we seek to enhance the ``know-how'' of our students by training them in the practical skills they will need for the technological innovations of the evolving labor market. Our work has been implemented in engineering courses at Tecnologico de Monterrey in Mexico, aligning with the university's educational model ``TEC21'' which aims to increase the students' self-learning capabilities using interactive teaching and hands-on practical work to develop new abilities and competencies in an expanded variety of domains. So far, our results have shown that the use of IE not only improves the way professors teach, but reinforces skills, competencies, enhances creativity and strongly motivates the students in their daily learning.},
  keywords = {Analysis,CAE) and Design,Case studies,Colleges & universities,Computer-Aided Engineering (CAD,Education,Electronics and Microelectronics,Engineering,Engineering Design,Engineering education,Engineering Manufacturing,Engineers,Environmental impact,Evolution,Industrial Design,Instrumentation,Labor,Labor market,Learning,Mechanical Engineering,Original Paper,Science & Technology,Skills,Students,Teaching,Technology,Virtual reality}
}

@article{lortieOpenSesameData2017,
  title = {Open {{Sesame}}: {{R}} for {{Data Science}} Is {{Open Science}}},
  shorttitle = {Open {{Sesame}}},
  author = {Lortie, Christopher},
  year = {2017},
  journal = {Ideas in Ecology and Evolution},
  volume = {10},
  issn = {19183178},
  doi = {10/gghgh4},
  urldate = {2020-01-12},
  file = {/Users/colin.madland/Zotero/storage/QCTPJ8FB/lortieOpenSesameData2017.pdf}
}

@article{louieSocialMediaSexual2017,
  title = {Social {{Media}} and the {{Sexual Exploitation}} of {{Indigenous Girls}}},
  author = {Louie, Dustin William},
  year = {2017},
  journal = {Girlhood Studies},
  volume = {10},
  number = {2},
  pages = {97},
  issn = {1938-8209},
  doi = {10.3167/ghs.2017.100208},
  abstract = {In this article, based on research I conducted in Western Canada, I discuss the significance of the emerging influence of social media on the overrepresentation of Indigenous girls in sexually exploitative situations. In interviews I conducted with Indigenous sexual exploitation survivors and intervention staff I found that social media is being used to recruit Indigenous girls and keep them exploited in three distinct ways: targeting girls in reserve communities and luring them to the city; setting up so-called dates to keep them off the streets; and facilitating constant communication between the victim and victimizer, thus ensuring that girls are perpetually active and reachable. I respond to these by outlining educational possibilities in order to combat the exposure of these girls to predators on social media sites.},
  keywords = {Children & youth,Crimes against,Demographic aspects,Drug abuse,Education,Emergency communications systems,Exploitation,Families & family life,Gangs,Girls,Human trafficking,Internet access,Literacy,Native peoples,Native women,Nonviolence,Prevention,Sex crimes,Sex industry,Sexual exploitation,Social justice,Social media,Social networks,Social research,Studies,Technology application,Usage}
}

@article{loweCrossNationalComparisonsCanadian2021,
  title = {Cross-{{National Comparisons}} between {{Canadian}} and {{US Higher Education Students}} on a {{New}}, {{Brief}}, {{Multidimensional Measure}} of {{Test Anxiety}}},
  author = {Lowe, Patricia A.},
  year = {2021},
  month = may,
  journal = {Journal of Psychoeducational Assessment},
  pages = {073428292110169},
  issn = {0734-2829, 1557-5144},
  doi = {10/gksqs2},
  urldate = {2021-06-23},
  abstract = {Cross-cultural equivalence, country and gender differences, and external relations with other measures were examined on a new, brief measure of test anxiety, the Test Anxiety Measure for College Students-Short Form (TAMC-SF), in a sample of Canadian and US higher education students. The sample of 1204 students completed the TAMC-SF and other measures online. The results of tests of invariance found support for partial scalar invariance across country and gender on the TAMC-SF. In addition, results of a multivariate analysis of variance (MANOVA) and analysis of variances (ANOVAs) found country and gender differences on the TAMC-SF scales. Furthermore, validity evidence for the TAMC-SF scores with the scores of external measures was found. Overall, the findings support the use of the same test score interpretation for Canadian and US higher education students on the TAMC-SF and the use of the TAMC-SF in Canadian higher education students.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/77KPAPWB/loweCrossNationalComparisonsCanadian2021.pdf}
}

@article{lucasUse3DModeling2021,
  title = {The {{Use}} of 3-{{D Modeling}} and {{Printing}} to {{Teach}} the {{Central Dogma}} of {{Molecular Biology}}},
  author = {Lucas, Krista L.},
  year = {2021},
  month = jan,
  journal = {Science Activities: Projects and Curriculum Ideas in STEM Classrooms},
  volume = {58},
  number = {2},
  pages = {70--76},
  publisher = {{Science Activities: Projects and Curriculum Ideas in STEM Classrooms}},
  issn = {0036-8121},
  doi = {10.1080/00368121.2021.1918048},
  abstract = {Molecular processes are highly complex, and are frequently difficult for high school and college students to comprehend. Because of the importance of visualization in learning, along with formative assessment of student understanding, utilization of 3D modeling software aids both educators and students alike. The activity described below required non-science majors in a college-level general education biology class to build a model of the central dogma of molecular biology and the relationships between DNA, RNA, and protein using the TinkerCad website, and describe their model in relation to the cellular processes. Examples of student work are included, along with a discussion of the application to high school students, connections to the NGSS, and future directions for the activity.},
  keywords = {College Science,Computer Software,Concept Formation,Genetics,Geometric Concepts,High School Students,Models,Molecular Biology,Molecular Structure,Printed Materials,Science Instruction,Scientific Concepts,Secondary School Science,Spatial Ability,Teaching Methods,Technology Uses in Education,Undergraduate Study,Visualization},
  file = {/Users/colin.madland/Zotero/storage/JIA9B3L7/lucasUse3DModeling2021.pdf}
}

@article{luckinEmpoweringEducatorsBe2022,
  title = {Empowering Educators to Be {{AI-ready}}},
  author = {Luckin, Rosemary and Cukurova, Mutlu and Kent, Carmel and {\noopsort{boulay}}{du Boulay}, Benedict},
  year = {2022},
  month = jan,
  journal = {Computers and Education: Artificial Intelligence},
  volume = {3},
  pages = {100076},
  issn = {2666-920X},
  doi = {10.1016/j.caeai.2022.100076},
  abstract = {In this paper, we present the concept of AI Readiness, along with a framework for developing AI Readiness training. `AI Readiness' can be framed as a contextualised way of helping people to understand AI, in particular, data-driven AI. The nature of AI Readiness training is not the same as merely learning about AI. Rather, AI Readiness recognises the diversity of the professions, workplaces and sectors for whom AI has a potential impact. For example, AI Readiness for lawyers may be based on the same principles as AI Readiness for Educators. However, the details will be contextualised differently. AI Readiness recognises that such contextualisation is not an option: it is essential due to the multiple intricacies, sensitivities and variations between different sectors and their settings, which all impact the application of AI. To embrace such contextualisation, AI Readiness needs to be an active, participatory training process and aims to empower people to be more able to leverage AI to meet their needs. The text that follows focuses on AI Readiness within the Education and Training sector and starts with a discussion of the current state of AI within education and training, and the need for AI Readiness. We then problematize the concept of AI Readiness, why AI Readiness is needed, and what it means. We expand upon the nature of AI Readiness through a discussion of the difference between human and Artificial Intelligence, before presenting a 7-step framework for helping people to become AI Ready. Finally, we use an example of AI Readiness in action within Higher Education to exemplify AI Readiness.},
  file = {/Users/colin.madland/Zotero/storage/IGKYVHZ2/luckinEmpoweringEducatorsBe2022.pdf}
}

@article{luckinUsingTeacherInquiry2017,
  title = {Using Teacher Inquiry to Support Technology-Enhanced Formative Assessment: A Review of the Literature to Inform a New Method},
  author = {Luckin, R and Clark, W and Avramides, K and Hunter, J and Oliver, M},
  year = {2017},
  journal = {Interactive Learning Environments},
  volume = {25},
  number = {1},
  pages = {85--97},
  issn = {1049-4820},
  doi = {10.1080/10494820.2015.1121152},
  abstract = {In this paper we review the literature on teacher inquiry (TI) to explore the possibility that this process can equip teachers to investigate students' learning as a step towards the process of formative assessment. We draw a distinction between formative assessment and summative forms of assessment [CRELL. (2009). The transition to computer-based assessment: New approaches to skills assessment and implications for large-scale testing. In F. Scheuermann \& J. Bjornsson (Eds.), JRC Scientific and technical reports. Ispra: Author; Webb, M. (2010). Beginning teacher education and collaborative formative e-assessment. Assessment \& Evaluation in Higher Education, 35, 597-618; EACEA. (2009). National testing of pupils in Europe: Objectives, organisation and use of results. Brussels: Eurydice; OECD. (2010b). Assessing the effects of ICT in education (F. Scheuermann \& E. Pedro, Eds.). Paris: JRC, OECD]. Our review of TI is combined with a review of the research concerning the way that practices with technology can support the assessment process. We conclude with a comparison of TI and teacher design research from which we extract the characteristics for a method of TI that can be used to develop technology-enhanced formative assessment: teacher inquiry into student learning. In this review, our primary focus is upon enabling teachers to use technology effectively to inquire about their students' learning progress.},
  langid = {english},
  keywords = {design research,Formative assessment,learning,teacher inquiry,technology-enhanced learning},
  file = {/Users/colin.madland/Zotero/storage/XBLDKF2M/luckinUsingTeacherInquiry2017.pdf}
}

@article{luckinYesAICould2023,
  ids = {YesAICould2023a},
  title = {Yes, {{AI}} Could Profoundly Disrupt Education. {{But}} Maybe That's Not a Bad Thing},
  author = {Luckin, Rose},
  year = {2023},
  month = jul,
  journal = {The Guardian},
  issn = {0261-3077},
  urldate = {2023-08-04},
  abstract = {Humans need to excel at things AI can't do -- and that means more creativity and critical thinking and less memorisation, says academic Rose Luckin},
  chapter = {Opinion},
  langid = {british},
  keywords = {Artificial intelligence (AI),Computing,Education,Technology,World news},
  file = {/Users/colin.madland/Zotero/storage/TTT23DTX/ai-artificial-intelligence-disrupt-education-creativity-critical-thinking.html}
}

@article{ludeckeEasystatsFrameworkEasy2022,
  title = {Easystats: {{Framework}} for Easy Statistical Modeling, Visualization, and Reporting},
  author = {L{\"u}decke, Daniel and {Ben-Shachar}, Mattan S. and Patil, Indrajeet and Wiernik, Brenton M. and Bacher, Etienne and Th{\'e}riault, R{\'e}mi and Makowski, Dominique},
  year = {2022},
  journal = {CRAN},
  doi = {10.32614/CRAN.package.easystats}
}

@incollection{luechtProfessionalCertificationLicensure2016,
  title = {Professional Certification and Licensure Examinations},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {Luecht, Richard M.},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch19},
  pages = {446--471},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch19},
  abstract = {Summary Many professions have one or more certification or licensure tests as part of their entry-level qualification process. This chapter describes the development and use of cognitively oriented assessment engineering design components and procedures -- including the use of task modeling, task design templates and strong statistical quality control mechanisms -- as an integral and important part of the process for developing formal test specifications, building item banks, and assembling test forms that optimize professional knowledge and/or skill mastery decisions. Practical examples are provided.},
  chapter = {19},
  isbn = {978-1-118-95658-8},
  keywords = {assessment engineering,automated test assembly,certification testing,decision accuracy,licensure testing,mastery testing,practice analysis,principled assessment design,task model grammar,task modeling,test information}
}

@misc{LumenLearningCom,
  title = {{{LumenLearning}}.Com},
  urldate = {2018-11-05},
  abstract = {Lumen Learning creates digital course materials that replace expensive textbooks in high-enrollment college courses and save students millions every term.},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/23P3QGFE/www.lumenlearning.com.html}
}

@article{lumpkinExplicatingSynergiesSelf2018,
  title = {Explicating the Synergies of Self-determination Theory, Ethical Leadership, Servant Leadership, and Emotional Intelligence},
  author = {Lumpkin, Angela and Achen, Rebecca M.},
  year = {2018},
  journal = {Journal of Leadership Studies},
  volume = {12},
  number = {1},
  pages = {6--20},
  publisher = {John Wiley \& Sons},
  issn = {1935-2611},
  doi = {10.1002/jls.21554},
  abstract = {Using self-determination theory as a foundation, the current study examined ethical leadership, servant leadership, and emotional intelligence to ascertain any shared characteristics contributing to effective leadership. Self-determination theory espouses the centrality of autonomy, competence, and relatedness to human motivation. Servant leadership emphasizes serving and caring for others. Ethical leaders consistently make morally reasoned decisions. Emotionally intelligent leaders are self-aware and self-regulating, nurture motivation, and stress empathy and social skill. An analysis of the literature revealed 10 shared characteristics connecting the three components of self-determination theory, including awareness, empathy, fairness, integrity, moral values, motivation, trust, relationship management, respect, and self-management. Synergies among ethical leadership, servant leadership, and emotional intelligence to leadership in a variety of settings emerged. Effective leaders use awareness, empathy, fairness, integrity, moral values, motivation, trust, relationship management, respect, and self-management contributing to needs satisfaction in followers' autonomy, competence, and relatedness. In conclusion, leadership effectiveness can increase when leaders demonstrate integrity, trust, and respect, serve others with empathy and fairness, and are personally and socially competent. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {emotional intelligence,Emotional Intelligence,ethical leadership,ethics,Ethics,human motivation,Leadership,Leadership Style,Motivation,organizations,Self-Determination,self-determination theory}
}

@incollection{lundquistAvoidingBiasSocial2020,
  title = {From {{Avoiding Bias}} to {{Social Justice}}: {{A Continuum}} of {{Assessment Practices}} to {{Advance Diversity}}, {{Equity}}, and {{Inclusion}}},
  shorttitle = {From {{Avoiding Bias}} to {{Social Justice}}},
  booktitle = {Advances in {{Educational Marketing}}, {{Administration}}, and {{Leadership}}},
  author = {Lundquist, Anne E. and Henning, Gavin},
  editor = {{Spicer-Runnels}, Ashley D. and Simpson, Teresa E.},
  year = {2020},
  pages = {47--61},
  publisher = {IGI Global},
  doi = {10.4018/978-1-7998-4108-1.ch004},
  urldate = {2024-07-08},
  abstract = {The demographics of U.S. colleges and universities continue to evolve and higher education is being called to reinvent itself in order to ensure that all students have high quality learning experiences. An equity-minded approach to assessment helps determine the effectiveness of diversity, equity, and inclusion initiatives and programs as well as embodies practices and procedures that themselves are socially just. This text share many research-based practices that value, prioritize, and develop diversity, intercultural fluency, and equity in campus specific settings. This chapter describes the higher education and cultural context in which the equitable assessment conversation is taking place; reviews how research paradigms, methods, and culture impact assessment decisions and methods; describes a socially just assessment continuum; and offers tips for implementing equity-minded assessment.},
  isbn = {978-1-7998-4108-1 978-1-7998-4109-8},
  file = {/Users/colin.madland/Zotero/storage/RSWDAXWE/lundquistAvoidingBiasSocial2020.pdf}
}

@article{luoDevelopingEvaluativeJudgement2021,
  title = {Developing Evaluative Judgement in Higher Education: Assessment for Knowing and Producing Quality Work},
  shorttitle = {Developing Evaluative Judgement in Higher Education},
  author = {Luo, Jiahui},
  year = {2021},
  month = sep,
  journal = {Educational Review},
  volume = {73},
  number = {5},
  pages = {662--662},
  issn = {0013-1911, 1465-3397},
  doi = {10.1080/00131911.2020.1842644},
  urldate = {2022-05-04},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/KENJZ4J7/luoDevelopingEvaluativeJudgement2021.pdf}
}

@book{luptonDigitalAcademicCritical2018,
  title = {The Digital Academic: Critical Perspectives on Digital Technologies in Higher Education},
  author = {Lupton, Deborah and Mewburn, Inger and Thomson, 1948, Pat},
  year = {2018},
  number = {Book, Whole},
  publisher = {Routledge},
  address = {Abingdon, Oxon;New York, NY;},
  abstract = {"Academic work, like many other professional occupations, has increasingly become digitized. This book brings together leading scholars who examine the impacts, possibilities, politics and drawbacks of working in the contemporary university, using digital technologies. Contributors take a critical perspective in identifying the implications of digitization for the future of higher education, academic publishing protocols and platforms and academic employment conditions, the ways in which academics engage in their everyday work and as public scholars and relationships with students and other academics. The book includes accounts of using digital media and technologies as part of academic practice across teaching, research administration and scholarship endeavours, as well as theoretical perspectives. The contributors span the spectrum of early to established career academics and are based in education, research administration, sociology, digital humanities, media and communication."--Provided by publisher.},
  isbn = {9781315473598;1315473593;},
  langid = {english},
  keywords = {Education Higher,Educational technology,Effect of technological innovations on},
  file = {/Users/colin.madland/Zotero/storage/3W9PX3SV/luptonDigitalAcademicCritical2018.pdf}
}

@article{luScopingReviewComputational2022,
  title = {A Scoping Review of Computational Thinking Assessments in Higher Education},
  author = {Lu, Chang and Macdonald, Rob and Odell, Bryce and Kokhan, Vasyl and Demmans Epp, Carrie and Cutumisu, Maria},
  year = {2022},
  journal = {Journal of computing in higher education},
  volume = {34},
  number = {2},
  pages = {416--461},
  publisher = {Springer US},
  address = {New York},
  issn = {1042-1726},
  doi = {10.1007/s12528-021-09305-y},
  abstract = {The field of computational thinking (CT) is developing rapidly, reflecting its importance in the global economy. However, most empirical studies have targeted CT in K-12, thus, little attention has been paid to CT in higher education. The present scoping review identifies and summarizes existing empirical studies on CT assessments in post-secondary education, aiming to reveal the current trends of empirical research in this domain and key features of recent CT assessment instruments. It examines 33 peer-reviewed journal articles published between 2013 and 2019 from six databases. Results show that most assessment tools are designed for computing science and engineering undergraduates or pre-service and in-service teachers in these subjects. Most tools involve in-class interventions to promote CT skills. Several assessment formats were adopted in the selected studies, including selected-response questions, constructed-response questions, Likert scales, interviews, programming artefacts, observations, and interviews. Finally, most assessment instruments attempt to measure skills from a combination of dimensions including CT Concepts, Practices, and Perspectives from a hybrid-competency framework. More specifically, the skills assessed in most studies are algorithmic thinking, problem solving, data, logic and logical thinking, and abstraction. Findings may help instructors to select CT assessments for higher education and researchers to focus on less explored research areas.},
  keywords = {College teachers,Education,Education & Educational Research,Education Higher,Educational evaluation,Educational Technology,Global economy,Higher Education,Learning and Instruction,Periodical publishing,Physical instruments,Problem solving,Questions,Skills,Social Sciences,Software,Systematic review,Teachers},
  file = {/Users/colin.madland/Zotero/storage/ZS9AY282/luScopingReviewComputational2022.pdf}
}

@article{luthfiyyahTechnologyenhancedFormativeAssessment2021,
  title = {Technology-Enhanced Formative Assessment in Higher Education: {{A}} Voice from {{Indonesian EFL}} Teachers},
  author = {Luthfiyyah, Roghibatul and Aisyah, Aisyah and Sulistyo, Gunadi Harry},
  year = {2021},
  journal = {Edulite (Online)},
  volume = {6},
  number = {1},
  pages = {42--54},
  publisher = {Universitas Islam Sultan Agung, Semarang},
  issn = {2477-5304},
  doi = {10.30659/e.6.1.42-54},
  abstract = {The integration of information communication and technology in language teaching has been intensely examined in literature works. However, the study which explicitly investigates the advancement of technology for language assessment in higher education level is still underexplored, particularly in a formative assessment area. To fill that gap, the present study aims at investigating the perceptions of EFL teachers towards technology-enhanced formative assessment and how they implement it in the classroom. This study employs a qualitative case study approach. Of three participants from different universities were voluntarily participated in a semi-structured interview. The interview seeks to investigate the perceptions of teachers towards technology-enhanced assessment, the roles of technology in formative assessment, and the impact of technology on language learning. The findings reveal that EFL teachers view formative assessment as well as technology in a positive perception. They admit that technology is a practical tool that has multiple roles and it is deemed as useful and meaningful platform for assessing students. Finally, technology-enhanced formative assessment gives an impact on students performance, particularly on language accuracy. The further implications are discussed in this paper.},
  keywords = {formative assessment,higher education,teachers' voice,technology-enhanced formative assessment},
  file = {/Users/colin.madland/Zotero/storage/V73M8U29/luthfiyyahTechnologyenhancedFormativeAssessment2021.pdf}
}

@article{lynchHeutagogicalApproachAssessment2021,
  title = {A Heutagogical Approach for the Assessment of {{Internet Communication Technology}} ({{ICT}}) Assignments in Higher Education},
  author = {Lynch, Michael and Sage, Todd and Hitchcock, Laurel Iverson and Sage, Melanie},
  year = {2021},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {18},
  number = {1},
  pages = {55--55},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-021-00290-x},
  abstract = {Pedagogical foundations exist for incorporating technology in instruction; however, these foundations have not kept pace with technology's evolution. Through the use of Information Communication Technologies (ICTs), students now can share content directed at external audiences, i.e., audiences other than the instructor. These audiences are referred to as authentic audiences as they are public-facing and exist outside of the classroom. The existing literature offers evidence of student satisfaction with assignments directed at appealing to external audiences, however, the literature provides no comprehensive pedagogical rationale for assignments directed at authentic audiences wherein the goals are self-determined. The authors discuss the theory of heutagogy, the study of self-determined learning, as an approach for assessing assignments that utilize ICTs and are directed at authentic audiences. Finally, the authors offer an approach for the assessment of these assignments, including a rubric.},
  keywords = {Assessment,Assignments,Authentic audiences,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Education & Educational Research,Educational evaluation,Educational Objectives,Educational Technology,Evaluation,Heutagogy,Higher Education,Humanities,Independent Study,Information Dissemination,Information Systems Applications (incl.Internet),Information Technology,Internet,Internet Communication Technologies (ICT),Law,Pedagogy,Review Article,Scoring Rubrics,Self Determination,Self-directed learning,Social Sciences,Statistics for Social Sciences,Student Evaluation,Student Satisfaction},
  file = {/Users/colin.madland/Zotero/storage/EW37WKK5/lynchHeutagogicalApproachAssessment2021.pdf}
}

@article{lynchHeutagogicalApproachAssessment2021a,
  title = {A Heutagogical Approach for the Assessment of {{Internet Communication Technology}} ({{ICT}}) Assignments in Higher Education},
  author = {Lynch, Michael and Sage, Todd and Hitchcock, Laurel Iverson and Sage, Melanie},
  year = {2021},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {18},
  number = {1},
  pages = {55--55},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-021-00290-x},
  abstract = {Pedagogical foundations exist for incorporating technology in instruction; however, these foundations have not kept pace with technology's evolution. Through the use of Information Communication Technologies (ICTs), students now can share content directed at external audiences, i.e., audiences other than the instructor. These audiences are referred to as authentic audiences as they are public-facing and exist outside of the classroom. The existing literature offers evidence of student satisfaction with assignments directed at appealing to external audiences, however, the literature provides no comprehensive pedagogical rationale for assignments directed at authentic audiences wherein the goals are self-determined. The authors discuss the theory of heutagogy, the study of self-determined learning, as an approach for assessing assignments that utilize ICTs and are directed at authentic audiences. Finally, the authors offer an approach for the assessment of these assignments, including a rubric.},
  keywords = {Assessment,Assignments,Authentic audiences,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Educational evaluation,Educational Objectives,Educational Technology,Evaluation,Heutagogy,Higher Education,Humanities,Independent Study,Information Dissemination,Information Systems Applications (incl.Internet),Information Technology,Internet,Internet Communication Technologies (ICT),Law,Pedagogy,Review,Review Article,Scoring Rubrics,Self Determination,Self-directed learning,Statistics for Social Sciences,Student Evaluation,Student Satisfaction},
  file = {/Users/colin.madland/Zotero/storage/JSX6LBLD/lynchHeutagogicalApproachAssessment2021a.pdf}
}

@article{lynchPromotingDeepLearning2012,
  title = {Promoting Deep Learning in a Teacher Education Programme through Self and Peer Assessment and Feedback},
  author = {Lynch, Raymond and McNamara, Patricia Mannix and Seery, Niall},
  year = {2012},
  journal = {European Journal of Teacher Education},
  doi = {10/fzjptp},
  abstract = {The incorporation of self- and peer-assessment and feedback has significant potential as a pedagogical strategy to promote deep learning in project based coursework. This study examined the impact of a deeper approach to learning on pre-service teachers' critical thinking and metacognitive skills. It also examined the impact on student learning outcomes within a project based module with a significant design element. Forty-seven students participated in the pilot of an online peer feedback system. Results suggest that the quality of students' reflections through peer feedback and overall satisfaction with the module remained high despite students' citing a preference for instructor feedback. The data also indicate that the incorporation of self- and peer-assessment and feedback resulted in higher quality learning outcomes and enhanced critical thinking skills.},
  pmcid = {null},
  pmid = {null}
}

@article{lynchPromotingDeepLearning2012a,
  title = {Promoting Deep Learning in a Teacher Education Programme through Self and Peer Assessment and Feedback},
  author = {Lynch, Raymond and McNamara, Patricia Mannix and Seery, Niall},
  year = {2012},
  journal = {European Journal of Teacher Education},
  doi = {10/fzjptp},
  abstract = {The incorporation of self- and peer-assessment and feedback has significant potential as a pedagogical strategy to promote deep learning in project based coursework. This study examined the impact of a deeper approach to learning on pre-service teachers' critical thinking and metacognitive skills. It also examined the impact on student learning outcomes within a project based module with a significant design element. Forty-seven students participated in the pilot of an online peer feedback system. Results suggest that the quality of students' reflections through peer feedback and overall satisfaction with the module remained high despite students' citing a preference for instructor feedback. The data also indicate that the incorporation of self- and peer-assessment and feedback resulted in higher quality learning outcomes and enhanced critical thinking skills.},
  pmcid = {null},
  pmid = {null}
}

@article{lynchQualityMattersImpact2020,
  title = {Quality {{Matters Impact}} on {{Student Outcomes}} in an {{Online Program}}},
  author = {Lynch, Susan and Gaston, Teresa},
  year = {2020},
  journal = {Journal of Educators Online},
  volume = {17},
  number = {2},
  issn = {EISSN-1547-500X},
  abstract = {The purpose of this study was to evaluate the impact of courses redesigned using Quality Matters (QM) on student learning in an online program at a large university in the southeastern United States. The QM Rubric for course design is widely used in higher education. However, research about its use in nursing education is understudied. This pilot project compared 100\% online courses--two courses redesigned to meet QM standards and two traditionally designed courses by faculty. Student outcomes such as quality of online discussion forums, student end of course evaluations, and end-of-course grades, were measured and analyzed. The data analysis included descriptive statistics and parametric group comparisons. Results showed that all indicators, although not statistically significant, were more positive in the QM-redesigned courses. As online education programs continue to explode, assurance of quality in course design is a key factor in meeting student needs.},
  langid = {english},
  keywords = {College Curriculum,Curriculum Design,Educational Quality,No DOI found,Nursing Education,Nursing Students,Online Courses,Outcomes of Education,Program Effectiveness}
}

@misc{lyonsTwitterLookingWhy2020,
  title = {Twitter Is Looking into Why Its Photo Preview Appears to Favor White Faces over {{Black}} Faces},
  author = {Lyons, Kim},
  year = {2020},
  month = sep,
  journal = {The Verge},
  urldate = {2020-09-22},
  abstract = {Twitter's preview showed the white faces more often},
  howpublished = {https://www.theverge.com/2020/9/20/21447998/twitter-photo-preview-white-black-faces},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/I4ZTKCWZ/twitter-photo-preview-white-black-faces.html}
}

@article{lytrasTechnologyenhancedLearningResearch2020,
  ids = {lytrasTechnologyenhancedLearningResearch2020a},
  title = {Technology-Enhanced Learning Research in Higher Education: {{A}} Transformative Education Primer},
  author = {Lytras, Miltiadis and Sarirete, Akila and Damiani, Ernesto},
  year = {2020},
  journal = {Computers in human behavior},
  volume = {109},
  pages = {106350},
  publisher = {Elsevier Ltd},
  address = {OXFORD},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2020.106350},
  abstract = {The evolution of humanized computing and the latest developments of psychological and educational theories have resulted to a new era of human-centric technology-enhanced learning interventions in higher education. New ideas, conceptual models and educational strategies promote novel approaches for competence-based learning models. Transformative education is a new capability and strategy aiming to re-design higher education in a holistic way focusing on total quality management of human resources. Cyber-physical systems, sentiment management and ubiquitous learning delivery beyond time and space limitations are promoted. The contribution of this special issues is twofold: On the one hand it communicates high quality research on complementary aspects of technology enhanced learning in higher education . On the other hand it delivers the basic aspects f transformative education.},
  keywords = {Cyber-physical systems,Education,Higher education,Human resources,Learning,Psychology,Psychology Experimental,Psychology Multidisciplinary,Resource management,Social Sciences,Total quality management},
  file = {/Users/colin.madland/Zotero/storage/94BMILRI/lytrasTechnologyenhancedLearningResearch2020.pdf}
}

@article{maboeOnlineAssessmentsCOVID192023,
  title = {Online Assessments and {{COVID-19}}: {{A}} Qualitative Study of Undergraduate Nursing Students in {{Southern Africa}}},
  author = {Maboe, Kefiloe A. and Tomas, Nestor},
  year = {2023},
  journal = {International journal of Africa nursing sciences},
  volume = {19},
  pages = {100590},
  publisher = {Elsevier Ltd},
  issn = {2214-1391},
  doi = {10.1016/j.ijans.2023.100590},
  abstract = {During the COVID-19 pandemic lockdown, universities were required to swiftly alter their approaches to assessing students. A number of countries around the world, especially those in resource-constrained environments, faced significant challenges in implementing successful online assessments amidst the COVID-19 pandemic. Nevertheless, there is a noticeable dearth of research about the experiences of students in Southern Africa on online assessments. This study explores and describe undergraduate nursing students' experiences with regards to online assessment amidst the COVID-19 pandemic in Southern Africa. A qualitative explorative study was employed on 17 undergraduate nursing students recruited via purposive sampling. Data was acquired through a semi-structured interview guide for individual telephonic interviews. Data was analysed thematically using Tesch's eight-steps method. The research study identified three key topics: (1) positive experiences of online assessments; (2) challenges encountered with online assessments; and (3) suggested methods for enhancing online assessments. The results demonstrate that students from both universities encountered more difficulties and obstacles than advantages while completing their online assessments. The study participants expressed stress associated with several factors, including insufficient technical know-how, unreliable internet connectivity, and power outages. Insufficient technical expertise posed a challenge to participants in the completion of the online assessment, thereby impeding their success. It is imperative that universities provide ongoing technical training to enable the effective integration of technology both in present and future pandemics. It is suggested that future research focus on devising approaches for implementing online assessment.},
  keywords = {COVID-19,Experiences,Lockdown,Nursing students,Online assessment,Qualitative study,Southern Africa},
  file = {/Users/colin.madland/Zotero/storage/LBQQYJUX/maboeOnlineAssessmentsCOVID192023.pdf}
}

@article{macallanDevelopingTheologyCapstone2021,
  title = {Developing a {{Theology Capstone Unit}} through the {{Teaching}} and {{Learning Nexus}}},
  author = {Macallan, Brian Claude},
  year = {2021},
  month = sep,
  journal = {Teaching Theology \& Religion},
  volume = {24},
  number = {3},
  pages = {175--182},
  publisher = {Teaching Theology \& Religion},
  issn = {1368-4868},
  doi = {10.1111/teth.12590},
  abstract = {The challenge of integrating best practice for teaching and learning is perennial. Within an Australian context, despite increases in student satisfaction over the decades, challenges remain concerning student classroom engagement, peer collaboration and the value and use of technology. Within my own religious and theological university environment, I have sought to address some of these challenges in the development of a Doing Theology Capstone Unit. This paper outlines the key subject information of the unit, followed by five key areas that informed the development. It is argued that by taking seriously the teaching and learning nexus, requires paying attention to these five key areas. The discussion section of this paper, therefore, explores demographics and diversity, active learning, constructive alignment, assessment and technology. These five areas are explored in relation to the developed curriculum for the Doing Theology unit. It is argued that by paying attention to these areas we can enable greater student engagement and peer-to-peer participation.},
  keywords = {Australia,Best Practices,Capstone Experiences,Curriculum Development,Foreign Countries,Learner Engagement,Peer Relationship,Student Participation,Theological Education}
}

@incollection{macdonaldChangingAssessmentHigher2009,
  title = {Changing {{Assessment}} in {{Higher Education}}: {{A Model}} in {{Support}} of {{Institution-Wide Improvement}}},
  shorttitle = {Changing {{Assessment}} in {{Higher Education}}},
  booktitle = {Assessment, {{Learning}} and {{Judgement}} in {{Higher Education}}},
  author = {Macdonald, Ranald and Joughin, Gordon},
  editor = {Joughin, Gordon},
  year = {2009},
  pages = {1--21},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-1-4020-8905-3_11},
  urldate = {2021-04-25},
  isbn = {978-1-4020-8904-6 978-1-4020-8905-3},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/C76XFX2M/macdonaldChangingAssessmentHigher2009.pdf}
}

@article{macdonaldDemonstratingOnlineTeaching2012,
  title = {Demonstrating Online Teaching in the Disciplines. {{A}} Systematic Approach to Activity Design for Online Synchronous Tuition},
  author = {Macdonald, Janet and Campbell, Anne},
  year = {2012},
  journal = {British Journal of Educational Technology},
  volume = {43},
  number = {6},
  pages = {883--891}
}

@article{macfarlaneMorphingAcademicPractice2011,
  title = {The {{Morphing}} of {{Academic Practice}}: {{Unbundling}} and the {{Rise}} of the {{Para-academic}}},
  shorttitle = {The {{Morphing}} of {{Academic Practice}}},
  author = {Macfarlane, Bruce},
  year = {2011},
  month = jan,
  journal = {Higher Education Quarterly},
  volume = {65},
  number = {1},
  pages = {59--73},
  issn = {09515224},
  doi = {10/ftdjwp},
  urldate = {2021-04-24},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/BCNYEFN3/macfarlaneMorphingAcademicPractice2011.pdf}
}

@article{macgilchristCruelOptimismEdtech2019,
  title = {Cruel Optimism in Edtech: When the Digital Data Practices of Educational Technology Providers Inadvertently Hinder Educational Equity},
  shorttitle = {Cruel Optimism in Edtech},
  author = {Macgilchrist, Felicitas},
  year = {2019},
  journal = {Learning, Media and Technology},
  volume = {44},
  number = {1},
  pages = {77--86},
  issn = {1743-9884, 1743-9892},
  doi = {10.1080/17439884.2018.1556217},
  urldate = {2024-09-24},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/macgilchristCruelOptimismEdtech2019.pdf}
}

@article{macgilchristStudentsSociety2020s2020,
  title = {Students and Society in the 2020s. {{Three}} Future `Histories' of Education and Technology},
  author = {Macgilchrist, Felicitas and Allert, Heidrun and Bruch, Anne},
  year = {2020},
  journal = {Learning, Media and Technology},
  volume = {45},
  number = {1},
  pages = {76--89},
  publisher = {Routledge},
  issn = {1743-9884},
  doi = {10/ggj8fd}
}

@article{machadoConceptMappingBenefits2020,
  title = {Concept {{Mapping}}: {{Benefits}} and {{Challenges}} in {{Higher Education}}},
  shorttitle = {Concept {{Mapping}}},
  author = {Machado, Cristiane Tolentino and Carvalho, Ana Am{\'e}lia},
  year = {2020},
  month = jan,
  journal = {The Journal of Continuing Higher Education},
  volume = {68},
  number = {1},
  pages = {38--53},
  issn = {0737-7363, 1948-4801},
  doi = {10.1080/07377363.2020.1712579},
  urldate = {2023-06-19},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/DF7DRKLE/machadoConceptMappingBenefits2020.pdf}
}

@article{machadoCOVID19ImpactAssessment2023,
  title = {{{COVID-19}} Impact on the Assessment Methodology of Undergraduate Medical Students: A Systematic Review of the Lessons Learned},
  author = {Machado, Maria Helena and Paredes, S{\'i}lvia and Ribeiro, Laura},
  year = {2023},
  journal = {Frontiers in Education},
  volume = {8},
  issn = {2504-284X},
  doi = {10.3389/feduc.2023.1304596},
  abstract = {The COVID-19 pandemic had a substantial social, economic, political, and educational impact worldwide. Due to the social contact restrictions, areas such as medical education were highly affected. Assessment in medical education, was already a sensitive topic, and it proved to be even more challenging as different teaching and learning contexts required huge adaptations in a short period. This systematic review provides an overview of the impact of COVID-19 on the assessment of medical students and can serve as a reference to improve this area. We conducted the review based on the PRISMA tool and searched in PubMed, EBSCO, and ScienceDirect. Studies describing the assessment methodologies used during the pandemic were included. Of the 501 initial articles, 18 were included in this review. Collected data was based on the regime, subject, teaching/assessment methodologies, platforms used, grades, students' and teachers' perceptions, and measures to prevent academic dishonesty. The results suggest that technology played a central role during the pandemic, and universities were concerned about the transition to online learning regarding teaching and assessment, but students and teachers should be prepared for it. Formative assessment methodologies and feedback were emphasized, and summative tools were adapted to prevent fraud. Students and teachers were generally satisfied with online learning and assessment, which had no significant difference in the examination scores, but they preferred conventional teaching. The COVID-19 pandemic brought an opportunity to analyze and rethink the medical curriculum. Thus, further investigations are needed on combining traditional and online teaching strategies and emphasis on the assessment.},
  file = {/Users/colin.madland/Zotero/storage/3W8B9DE5/machadoCOVID19ImpactAssessment2023.pdf}
}

@article{mackinnonFutureNowReport2015,
  title = {The {{Future}} Is {{Now}}: {{Report}} of the {{Presidential Task Force}} on {{Sustainability}}},
  author = {MacKinnon, Peter},
  year = {2015}
}

@article{macleodParadoxFacultyAttitudes2020,
  title = {The {{Paradox}} of {{Faculty Attitudes}} toward {{Student Violations}} of {{Academic Integrity}}},
  author = {MacLeod, Paul Douglas and Eaton, Sarah Elaine},
  year = {2020},
  month = dec,
  journal = {Journal of Academic Ethics},
  volume = {18},
  number = {4},
  pages = {347--362},
  issn = {1570-1727, 1572-8544},
  doi = {10.1007/s10805-020-09363-4},
  urldate = {2023-04-17},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/NXE6GUS3/macleodParadoxFacultyAttitudes2020.pdf}
}

@article{macquarieuniversityPreserviceTeacherReflection2021,
  title = {Pre-Service {{Teacher Reflection}} and {{Feedback Using}} an {{Online Video Platform During Professional Experience}}},
  author = {{Macquarie University} and Cavanagh, Michael},
  year = {2021},
  journal = {Australian Journal of Teacher Education},
  volume = {46},
  number = {2},
  pages = {72--85},
  issn = {1835517X},
  doi = {10.14221/ajte.2021v46n2.5},
  urldate = {2023-01-15},
  abstract = {This paper presents the results of a pilot study in which 11 triads comprising a pre-service teacher, a supervising teacher and a university supervisor used a video platform for pre-service teacher self-reflection and for the provision of feedback. Pre-service teachers made video recordings of one lesson each week during a four-week professional experience placement. They annotated the videos using time-stamped comments and shared them with their supervisors who added comments to provide feedback. The annotations were investigated through questionnaires and interviews that were analysed for their depth of reflection and participants' views about the video reflection process. Results indicate that the video process only marginally supported the provision of targeted feedback and pre-service teacher reflection. Factors which contributed to these outcomes are discussed.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/J9WM5B4W/macquarieuniversityPreserviceTeacherReflection2021.pdf}
}

@inproceedings{madlandBuildingTrustCommunity2016,
  title = {Building {{Trust}} and {{Community}} with {{Initiative Tasks}}},
  booktitle = {Teaching {{Practices Colloquium}}},
  author = {Madland, Colin},
  year = {2016},
  publisher = {Thompson Rivers University},
  address = {Kamloops, BC},
  copyright = {All rights reserved}
}

@inproceedings{madlandCommunitiesInquiryIgnite2016,
  title = {Communities of {{Inquiry}} to {{Ignite Learning}}},
  booktitle = {Teaching {{Practices Colloquium}}},
  author = {Madland, Colin},
  year = {2016},
  publisher = {Thompson Rivers University},
  address = {Kamloops, BC},
  copyright = {All rights reserved}
}

@misc{madlandCriticalFamilyHistory2019,
  type = {Blog},
  title = {Critical {{Family History}}},
  author = {Madland, Colin},
  year = {2019},
  journal = {Colin M. Madland},
  copyright = {All rights reserved}
}

@article{madlandDevelopingTechnologyIntegratedAssessment2024,
  title = {Developing the {{Technology-Integrated Assessment Framework}}},
  author = {Madland, Colin and Irvine, Valerie and DeLuca, Chris and Bulut, Okan},
  year = {2024},
  month = may,
  journal = {The Open/Technology in Education, Society, and Scholarship Association Journal},
  volume = {4},
  number = {1},
  pages = {1--19},
  issn = {2564-4726},
  doi = {10.18357/otessaj.2024.4.1.63},
  urldate = {2024-05-02},
  abstract = {The purpose of this paper is to describe the development of a new framework for understanding technology-integrated assessment in higher education based on a review of the literature using the assessment design in a digital world framework (Bearman et al., 2022) as a lens. Our review (Madland et al., 2024) revealed both congruities and incongruities between the literature and the framework, leading to the need for further work to accurately conceptualize technology-integrated assessment. In this article, we contribute to the literature on technology-integrated assessment in higher education by proposing the technology-integrated assessment framework. This paper marks an important step in extending our understanding of the factors influencing instructors who integrate technology into their assessment practice and promoting ethical and equitable approaches to technology-integrated assessment in higher education.},
  copyright = {https://creativecommons.org/licenses/by/4.0},
  file = {/Users/colin.madland/Zotero/storage/madlandDevelopingTechnologyIntegratedAssessment2024.pdf}
}

@inproceedings{madlandDigitalPlatformsAlgorithmic2022,
  title = {Digital {{Platforms}} and {{Algorithmic Erasure}}: {{What}} Are the {{Implications}}?},
  booktitle = {{{OTESSA Conference}} 2022},
  author = {Madland, Colin and Ofosuhene, Maxwell and Adkins, Jennifer},
  year = {2022},
  publisher = {{Open/Technology in Education Society and Scholarship Association}},
  address = {Online},
  doi = {10.18357/otessac.2022.2.1.137},
  abstract = {As technology advances, people of colour often fall victim to algorithm racial bias. This paper focuses on the problem of digital tools that misidentify, fail to recognize, or erase people of colour. On a spectrum, these issues can range from the annoyance of making people of colour invisible during online meetings, to the endangerment of falsely identifying people of colour of crimes that they did not commit. We encountered the former challenge in September 2020, during a faculty Zoom meeting. Our Zoom erasure experience and subsequent Twitter crop experience raised questions for our investigation: why do people of colour experience erasure on zoom and other digital platforms? Is this problem new? What are the outcomes of our experience? How could the problem be fixed? How is it that biases in technology seem to emulate those found in social life? In this paper we aim to raise awareness through sharing our experience and recommending the interrogation of algorithmic tools released for market, the creation of government policy and laws to hold software companies accountable, and the education about biases for IT professionals, educators, and students in the field.},
  keywords = {No DOI found}
}

@inproceedings{madlandEncouragingDeeperApproaches2014,
  title = {Encouraging {{Deeper Approaches}} to {{Learning}}},
  booktitle = {Open {{Learning Faculty Members Workshop}}},
  author = {Madland, Colin},
  year = {2014},
  month = may,
  publisher = {Thompson Rivers University},
  address = {Kamloops, BC},
  copyright = {All rights reserved}
}

@inproceedings{madlandEngagingStudentsVideo2012,
  title = {Engaging {{Students}} with {{Video}}},
  booktitle = {Teaching {{Practices Colloquium}}},
  author = {Madland, Colin},
  year = {2012},
  month = feb,
  publisher = {Thompson Rivers University},
  address = {Kamloops, BC},
  copyright = {All rights reserved}
}

@inproceedings{madlandEnhancingLearningOER2016,
  title = {Enhancing {{Learning}} through {{OER}} and {{Open Platforms}}},
  booktitle = {{{OER16}}},
  author = {Madland, Colin},
  year = {2016},
  month = apr,
  publisher = {Association for Learning Technologies},
  address = {Edinburgh, Scotland},
  copyright = {All rights reserved}
}

@article{madlandEnhancingStudentStudentOnline2016,
  title = {Enhancing {{Student-Student Online Interaction}}: {{Exploring}} the {{Study Buddy Peer Review Activity}}},
  author = {Madland, Colin and Richards, Griff},
  year = {2016},
  month = apr,
  journal = {International Review of Research in Open and Distance Learning},
  volume = {17},
  number = {3},
  doi = {10.19173/irrodl.v17i3.2179},
  abstract = {The study buddy is a learning strategy employed in a graduate distance course to promote informal peer reviewing of assignments before submission. This strategy promotes student-student interaction and helps break the social isolation of distance learning. Given the concern by Arum and Roksa (2011) that student-student interaction may be distracting from instead of contributing to academic achievement it was felt important to examine the way peer interaction can contribute to learning in a well-structured collaborative learning activity. This mixed-methods study (n=31) examined both quantitative and qualitative aspects of student perceptions of the study buddy activity. While quantitative findings regarding depth of processing were inconclusive due to the small and homogeneous sample, qualitative analysis showed very high levels of learner support for the activity as well as evidence that the activity encouraged learners to approach their learning with greater depth. 88\% of study buddies said they found the activity well worth their time, and would recommend it for other graduate courses. It is thought with greater scaffolding, the quality of buddy feedback might be improved. The few who did not appreciate the activity felt let down by a lack of buddy commitment to the process.},
  copyright = {Creative Commons Attribution 4.0 International License.},
  keywords = {interaction cooperative learning critical thinking study buddy approaches to learning learning design}
}

@inproceedings{madlandEvolvingOurUnderstanding2024,
  title = {Evolving Our Understanding of Technology-Integrated Assessment: A Review of the Literature and Development of a New Framework},
  booktitle = {Open/{{Technology}} in {{Education}}, {{Society}}, and {{Scholarship Association}}},
  author = {Madland, Colin and Irvine, Valerie and DeLuca, Christopher and Bulut, Okan},
  year = {2024},
  month = jun,
  address = {Montreal, QC, CA},
  abstract = {In this session, we will a) review the literature on technology in assessment in higher education and b) compare how the literature fits with the Assessment in a Digital World Framework [@bearman2022] which was chosen for its recency in the literature and the visibility of its authors as members of a well-known team of assessment researchers and authors. We found themes in the literature that were not present in the framework (e.g., academic integrity and faculty workload), and constructs in the framework not evident in the literature (e.g., future self and future activities), and c) we considered other gaps that appear in both the framework and the literature, but are evident in day-to-day practices and government legislation or mandates, such as considering legal or ethical aspects of duty of care and also the integration of Indigenous worldviews. We then developed the technology-integrated assessment framework to help instructors and administrators consider a broader range of constructs when planning assessment strategies in technology-integrated learning environments and to serve as a basis for further investigation into how the different constructs within the model contribute to how we design, implement, and teach about assessment in digital learning environments today. We will present an introduction of this technology-integrated assessment framework, invite feedback from the OTESSA community, and discuss future research goals and opportunities.}
}

@misc{madlandEvolvingOurUnderstanding2024a,
  title = {Evolving Our Understanding of Technology-Integrated Assessment: A Review of the Literature and Development of a New Framework},
  author = {Madland, Colin and Irvine, Valerie and DeLuca, Christopher and Bulut, Okan},
  year = {2024},
  month = jun,
  address = {Montreal, QC, CA},
  abstract = {In this session, we will a) review the literature on technology in assessment in higher education and b) compare how the literature fits with the Assessment in a Digital World Framework [@bearman2022] which was chosen for its recency in the literature and the visibility of its authors as members of a well-known team of assessment researchers and authors. We found themes in the literature that were not present in the framework (e.g., academic integrity and faculty workload), and constructs in the framework not evident in the literature (e.g., future self and future activities), and c) we considered other gaps that appear in both the framework and the literature, but are evident in day-to-day practices and government legislation or mandates, such as considering legal or ethical aspects of duty of care and also the integration of Indigenous worldviews. We then developed the technology-integrated assessment framework to help instructors and administrators consider a broader range of constructs when planning assessment strategies in technology-integrated learning environments and to serve as a basis for further investigation into how the different constructs within the model contribute to how we design, implement, and teach about assessment in digital learning environments today. We will present an introduction of this technology-integrated assessment framework, invite feedback from the OTESSA community, and discuss future research goals and opportunities.}
}

@misc{madlandExperiencingCognitiveApprenticeship2021,
  title = {Experiencing a Cognitive Apprenticeship in the Context of Co-Designing and Co-Teaching an Undergraduate Course},
  author = {Madland, Colin and James, Heidi},
  year = {2021},
  month = jun,
  address = {Online},
  abstract = {The process of earning a doctoral degree is arduous and challenging and has been described as a cognitive apprenticeship whereby experienced researchers provide mentorship and coaching for their students. This presentation will show how two doctoral students and their supervisor formed a rich community of practice in the context of designing and teaching an undergraduate course. Implications for online learning for both doctoral students in their programs and also in the online design and delivery of undergraduate courses are discussed.},
  copyright = {All rights reserved}
}

@misc{madlandExploringAssessmentPostSecondary2022,
  title = {Exploring {{Assessment}} in {{B}}.{{C}}. {{Post-Secondary}} -- {{BCcampus}}},
  author = {Madland, Colin},
  year = {2022},
  month = oct,
  urldate = {2023-11-21},
  copyright = {All rights reserved},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/K3NQ8WIK/exploring-assessment-in-b-c-post-secondary.html}
}

@inproceedings{madlandExploringRemixHypothesis2016,
  title = {Exploring the {{Remix Hypothesis}}},
  booktitle = {Open {{Education Global Conference}}},
  author = {Madland, Colin},
  year = {2016},
  month = apr,
  publisher = {Open Education Global},
  address = {Krakow, Poland},
  copyright = {All rights reserved}
}

@inproceedings{madlandFlexibleInfrastructureSupport2017,
  title = {Flexible {{Infrastructure}} to {{Support}} the {{Design}} and {{Delivery}} of {{Online Learning}}},
  booktitle = {{{ICDE World Conference}} for {{Online Learning}}},
  author = {Madland, Colin},
  year = {2017},
  publisher = {{International Council for Open and Distance Education}},
  address = {Toronto},
  copyright = {All rights reserved}
}

@misc{madlandFlippedImageTwitter2020,
  type = {Tweet},
  title = {Flipped the Image....@{{Twitter}} Is Trash. {{https://t.co/GxlNIEryFD}}},
  author = {Madland, Colin [@colinmadland]},
  year = {2020},
  month = sep,
  journal = {Twitter},
  urldate = {2022-10-24},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/9AGEPIBS/1307130447671984129.html}
}

@inproceedings{madlandHumanizingAssessmentOnline2021,
  title = {Humanizing {{Assessment}} in {{Online Higher Education}}},
  booktitle = {{{OTESSA}} 2021},
  author = {Madland, Colin},
  year = {2021},
  abstract = {Assessment practices in online higher education are potent drivers of student learning, yet evidence suggests that there is a significant reliance on potentially unreliable and invalid summative assessments that inhibit student learning. Compounding this is the massive increase in the use of digital surveillance technologies, purportedly to `catch cheaters' and to `save faculty time'. This combination of factors, harms all learners, and harms students who have darker skin colour, or are neuro-divergent much more significantly than others.   This review of the literature on assessment in higher education shows that there are significant problems associated with this reliance of summative assessments and that encouraging a move towards more formative, human-centred assessment models will require sustained and pan-institutional effort to change deeply rooted ways of thinking about teaching, learning, and assessment.},
  copyright = {All rights reserved}
}

@misc{madlandIndigenousDigitalSelfDetermination,
  title = {Indigenous {{Digital Self-Determination}}},
  author = {Madland, Colin},
  address = {Online},
  abstract = {There is a pressing need, as outlined in the recommendations of the Truth and Reconciliation Commission of Canada, to promote success for Indigenous learners in higher education. One pathway towards greater participation and success may be to empower Indigenous learners to engage with open source digital tools and platforms that promote digital self-determination. This review of the literature will explore the concept of digital self-determination through examples of Indigenous communities claiming control over the infrastructure that serves their homes.},
  copyright = {All rights reserved}
}

@inproceedings{madlandIndigenousDigitalSelfDetermination2020,
  title = {Indigenous {{Digital Self-Determination}}},
  booktitle = {{{OTESSA Conference}}},
  author = {Madland, Colin},
  year = {2020},
  publisher = {{Open/Technology in Education Society and Scholarship Association}},
  address = {Online},
  copyright = {All rights reserved},
  keywords = {No DOI found}
}

@inproceedings{madlandIndigenousOpenEducation2019,
  title = {Indigenous and {{Open Education}}: {{A}} Contradiction?},
  booktitle = {{{CSSHE Conference}}},
  author = {Madland, Colin},
  year = {2019},
  publisher = {Canadian Society for Scholarship in Higher Education},
  address = {Vancouver, BC},
  copyright = {All rights reserved}
}

@inproceedings{madlandOnlineFacultyDevelopment2012,
  title = {Online {{Faculty Development}}},
  booktitle = {Southern {{Alberta Institute}} of {{Technology Faculty Showcase}}},
  author = {Madland, Colin},
  year = {2012},
  month = may,
  publisher = {Southern Alberta Institute of Technology},
  address = {Calgary, AB},
  copyright = {All rights reserved}
}

@inproceedings{madlandOpenAdvantage2016,
  title = {The {{Open Advantage}}},
  booktitle = {Open {{Education}}},
  author = {Madland, Colin},
  year = {2016},
  address = {Richmond, VA},
  copyright = {All rights reserved}
}

@inproceedings{madlandOpenConnectedFaculty2015,
  title = {Open and {{Connected Faculty Development}}},
  booktitle = {Open {{Education}}},
  author = {Madland, Colin},
  year = {2015},
  address = {Vancouver, BC},
  copyright = {All rights reserved}
}

@inproceedings{madlandOutsideBoxFeedback2012,
  title = {Outside the {{Box Feedback}} with {{Adobe Acrobat}}},
  booktitle = {Open {{Learning Faculty Members Workshop}}},
  author = {Madland, Colin},
  year = {2012},
  month = may,
  publisher = {Thompson Rivers University},
  address = {Kamloops, BC},
  copyright = {All rights reserved}
}

@inproceedings{madlandSelfDeterminationIndigenousOnline2020,
  title = {Self-{{Determination}} in {{Indigenous Online Education}} [{{Roundtable Session}}]},
  booktitle = {{{AERA Annual Meeting}}},
  author = {Madland, Colin and Irvine, Valerie},
  year = {2020},
  publisher = {American Educational Research Association},
  address = {San Francisco, CA},
  abstract = {This conceptual paper will argue that, while there may be points of tension between online education and Indigenous education, educators have many choices with respect to choosing open source technologies as platforms for learning environments. When Indigenous learners are empowered to control their online persona and data, they are also choosing to exercise digital self-determination.},
  copyright = {All rights reserved}
}

@article{madlandSelfDeterminationIndigenousOnline2021,
  title = {Self-{{Determination}} in {{Indigenous Online Education}}},
  author = {Madland, Colin and Restoule, Jean-Paul},
  year = {2021},
  month = dec,
  journal = {The Open/Technology in Education, Society, and Scholarship Association Conference},
  volume = {1},
  number = {1},
  pages = {1--7},
  issn = {2816-2021},
  doi = {10.18357/otessac.2021.1.1.147},
  urldate = {2022-03-05},
  abstract = {There is a pressing need, as outlined in the recommendations of the Truth and Reconciliation Commission of Canada, to promote success for Indigenous learners in higher education. One pathway towards greater participation and success may be to empower Indigenous learners to engage with open source digital tools and platforms that promote digital self-determination. This review of the literature will explore the concept of digital self-determination through examples of Indigenous communities claiming control over the infrastructure that serves their homes.},
  copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
  keywords = {archived},
  annotation = {https://web.archive.org/web/20220305221249/https://conference.otessa.org/index.php/conference/article/view/147},
  file = {/Users/colin.madland/Zotero/storage/KFEPJM3W/madlandSelfDeterminationIndigenousOnline2021.pdf}
}

@mastersthesis{madlandStructuredStudentInteractions2014,
  title = {Structured Student Interactions in Online Distance Learning: {{Exploring}} the Study Buddy Activity},
  author = {Madland, Colin},
  year = {2014},
  abstract = {This mixed methods study explored the characteristics of a cooperative learning activity, the ``Study Buddy'', implemented in a graduate-level online course in instructional design. The study explored whether students (n=25) who participated in the Study Buddy activity took deeper approaches to their learning than those who did not participate (n=6), what value students received from participating in the activity, and whether the structure of the activity was appropriate to support deeper approaches to learning.Quantitative and qualitative results were merged to form conclusions that suggest that participants could be encouraged to take deeper approaches by faculty providing sample questions for students to use to evaluate their partners' work. Results suggest that the study buddy activity can be used to encourage social connections and to provide participants with opportunities to consider alternate opinions. Findings related to the ideal structure of the activity were inconclusive.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  school = {Athabasca University},
  keywords = {Cooperative Learning,Critical Thinking,Interaction,Student Approach to Learning},
  file = {/Users/colin.madland/Zotero/storage/BT3LS6TI/madlandStructuredStudentInteractions2014.pdf}
}

@inproceedings{madlandStructuredStudentInteractions2014a,
  title = {Structured {{Student Interactions}}},
  booktitle = {{{CNIE Conference}}},
  author = {Madland, Colin},
  year = {2014},
  month = may,
  publisher = {Canadian Network for Innovation in Education},
  address = {Kamloops, BC},
  copyright = {All rights reserved}
}

@inproceedings{madlandStructuredStudentInteractions2014b,
  title = {Structured {{Student Interactions}}},
  booktitle = {Teaching {{Practices Colloquium}}},
  author = {Madland, Colin},
  year = {2014},
  month = feb,
  publisher = {Thompson Rivers University},
  address = {Kamloops, BC},
  copyright = {All rights reserved}
}

@inproceedings{madlandStructuringStudentInteractions2013,
  title = {Structuring {{Student Interactions}} in {{Online Distance Learning}}: {{Exploring}} the {{Study Buddy Activity}}},
  booktitle = {Athabasca {{University Graduate Students}}' {{Conference}}},
  author = {Madland, Colin},
  year = {2013},
  month = sep,
  publisher = {Athabasca University Graduate Students' Association},
  address = {Edmonton, AB}
}

@misc{madlandTechnologyIntegratedAssessmentHigher2024,
  title = {Technology-{{Integrated Assessment}} in {{B}}.{{C}}. {{Higher Education}} -- {{BCcampus}}},
  author = {Madland, Colin},
  year = {2024},
  month = may,
  urldate = {2024-08-12},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/HJBEE4QF/technology-integrated-assessment-in-b-c-higher-education.html}
}

@article{madlandTechnologyIntegratedAssessmentLiterature2024,
  title = {Technology-{{Integrated Assessment}}: {{A Literature Review}}},
  shorttitle = {Technology-{{Integrated Assessment}}},
  author = {Madland, Colin and Irvine, Valerie and DeLuca, Chris and Bulut, Okan},
  year = {2024},
  month = may,
  journal = {The Open/Technology in Education, Society, and Scholarship Association Journal},
  volume = {4},
  number = {1},
  pages = {1--48},
  issn = {2564-4726},
  doi = {10.18357/otessaj.2024.4.1.57},
  urldate = {2024-05-02},
  abstract = {The purpose of this paper is to explore the nature of the scholarly literature between 2016 and 2023 on the impact of classroom technology on higher education instructors' assessment practices through the lens of the assessment design in a digital world framework (Bearman et al., 2022). Specifically, the paper focuses on (a) describing the assessment design in a digital world framework, (b) identifying the scope and breadth of the literature relating to technology-integrated assessment, and (c) highlighting any gaps between the Bearman et al.~model and the literature. This paper marks an important step in extending our understanding of the factors influencing instructors who integrate technology into their assessment practice and promoting ethical and equitable approaches to technology-integrated assessment in higher education.},
  file = {/Users/colin.madland/Zotero/storage/madlandTechnologyIntegratedAssessmentLiterature2024.pdf}
}

@inproceedings{madlandThinkingBoxDesigning2011,
  title = {Thinking {{Despite}} the {{Box}}: {{Designing Interaction}} in {{Blackboard}}},
  booktitle = {Teaching with {{Technology Series}}},
  author = {Madland, Colin},
  year = {2011},
  month = oct,
  publisher = {{TRU Centre for Teaching and Learning}},
  address = {Kamloops, BC},
  copyright = {All rights reserved}
}

@inproceedings{madlandTwitterHigherEducation2010,
  title = {Twitter in {{Higher Education}}},
  booktitle = {Teaching with {{Technology Series}}},
  author = {Madland, Colin},
  year = {2010},
  month = oct,
  publisher = {{TRU Centre for Teaching and Learning}},
  address = {Kamloops, BC},
  copyright = {All rights reserved}
}

@article{madlandValidatingTechnologyIntegratedAssessment2024,
  title = {Validating the {{Technology-Integrated Assessment Framework}}},
  author = {Madland, Colin},
  year = {2024},
  abstract = {The purpose of this investigation is to seek validity evidence regarding a conceptual model of technology-integrated assessment in higher education. Assessment in higher education has been shown to be a complex and idiosyncratic process with multiple factors influencing instruc- tors' decisions (Massey et al., 2020) . Further, advances in digital technology continue to press instructors and higher education institutions to incorporate digital technology into curricula and assessment, leading to further complexity and lack of clarity. The Technology-Integrated Assessment Framework provides a conceptual model allowing instructors and institutions to frame their assessment practices in alignment with four factors: (1) the purposes of assessment, (2) duty of care, (3) technology adoption, and (4) assessment design. 3},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/ALTXDH9D/index.pdf}
}

@article{maeleEAssessmentLearningGaining2013,
  title = {E-{{Assessment}} for {{Learning}}: {{Gaining Insight}} in {{Language Learning}} with {{Online Assessment Environments}}},
  author = {Maele, Jan and Rajagopal, Kamakshi and Baten, Lut and Beaven, Ana},
  year = {2013},
  journal = {Computer-Assisted Foreign Language Teaching and Learning : Technological Advances},
  number = {Generic},
  pages = {245--261},
  doi = {10/ggrgxs}
}

@article{mafenyaStudyStudentsExperiences2016,
  title = {A {{Study}} of {{Students}}' {{Experiences}} of {{Formative}} and {{Summative Assessment}} in {{Open Distance Learning}}: {{Insights}} from {{Meta-synthesis}}},
  author = {Mafenya, Patrick Nkhangweleni},
  year = {2016},
  journal = {International Journal of Educational Sciences},
  volume = {15},
  number = {3},
  pages = {529--537},
  doi = {10.1080/09751122.2016.11890563},
  abstract = {This paper reports on the analysis of students' experiences of formative and summative assessment in order to articulate new insights relating to the most efficient and effective means of assessing students in distance education contexts. Relatively little research appears to have been carried out to ascertain students' experiences and beliefs regarding formative and summative assessments, and yet this is fundamental knowledge if one is serious about making changes in practice. This systematic document analysis purports to fill the gap in this area and confines itself to students at the University of South Africa (Unisa), a dedicated distance education university. The paper qualitatively surveyed the literature from 2005-2016. This paper was underpinned by the research question: What are students' experiences of formative and summative assessments in open distance learning? The analysis produced results that could be used to improve student learning and motivation.},
  langid = {english},
  keywords = {Analysis,Assessment of Learning,College students,Distance Education,Distance learning,E-learning,Formative assessment,Motivation,Multiple DOI,Social Constructivism,Technology Enhanced Assessment},
  file = {/Users/colin.madland/Zotero/storage/Z7W4WLVQ/Mafenya - A Study of Students Experiences of Formative and .pdf}
}

@article{magalhaesReconfiguringPowerPortuguese2018,
  title = {Reconfiguring {{Power}} in {{Portuguese Higher Education}}},
  author = {Magalh{\~a}es, Ant{\'o}nio and Veiga, Am{\'e}lia and Videira, Pedro},
  year = {2018},
  journal = {Education Policy Analysis Archives},
  volume = {26},
  number = {135},
  issn = {EISSN-1068-2341},
  abstract = {This paper aims to analyse the shift in the internal power balance between managerial and academic self-governance as reflected in the perceptions of teaching and non-teaching staff on the tendencies, decision-making processes and actor's roles in these processes. The empirical data used in this paper were gathered on the basis of an on-line survey, distributed throughout 2014 and 2015 in all Portuguese higher education institutions. Responses were interpreted taking into account the influence of governance narratives on the development of boardism, i.e., a decrease of academic self-governance reflecting the decline of the power of teaching staff in HEIs' governance; an increase of managerial governance as reflected in the reinforcement of hierarchies and organisational top-down decision-making; and the influence of external stakeholders. The analysis contributes to dig into the complexity of the governance arrangements challenging the prevailing influence of the NPM governance narrative while underlining the internal dynamics of HEIs, where Portuguese teaching staff continue to play a key role.},
  langid = {english},
  keywords = {College Administration,College Faculty,Decision Making,Foreign Countries,Governance,Higher Education,No DOI found,Power Structure,Professional Personnel,Role,Vertical Organization}
}

@book{magerPreparingInstructionalObjectives1984,
  title = {Preparing Instructional Objectives},
  author = {Mager, R. F.},
  year = {1984},
  edition = {2nd},
  publisher = {Fearon-Pittman},
  address = {Belmont, CA}
}

@techreport{magnapublicationsStudentCollaborationOnlinen.d,
  title = {Student {{Collaboration}} in the {{Online Classroom}}},
  author = {MagnaPublications},
  year = {n.d}
}

@article{mahabeerConnectingAssessmentFeedback2021,
  title = {Connecting Assessment and Feedback: {{A}} Customised and Personalised Experience for Knowledge-Building},
  author = {Mahabeer, P and Akoo, {\relax FF}},
  year = {2021},
  journal = {Journal of Education},
  number = {83},
  pages = {87--110},
  issn = {0259-479X},
  doi = {10.17159/2520-9868/i83a05},
  abstract = {Formative assessment coupled with effectual feedback is instrumental in enhancing student-learning experience and contributing to knowledge-building. However, feedback does not always translate into the desired outcomes for students receiving feedback and this compromises educational experiences and goals. In this small-scale empirical study, we worked with five postgraduate Honours students at a university in South Africa to explore their experiences of feedback on formative assessments in the learning space. We focused in a nuanced way on innovative opportunities and practices of feedback in the digital age. The data collected from the semi-structured interviews revealed that participants understood the value of quality formative assessment and feedback. Most participants reacted negatively to assessment grids and feedback received from lecturers. Some were unaccustomed to digital formative assessment and feedback as a developmental tool. They recommended a discipline-specific blended feedback approach that incorporates face-to-face feedback to make the digital feedback provided to them more meaningful. This would provide useful feedback that would create a customised and personalised learning experience for students in collaborative knowledge-building.},
  langid = {english},
  keywords = {feedback,formative assessment (FA),HIGHER-EDUCATION,knowledge-building,PAPER,STUDENT PERCEPTIONS,students' experiences},
  file = {/Users/colin.madland/Zotero/storage/QDEELUTM/mahabeerConnectingAssessmentFeedback2021.pdf}
}

@article{mahandeMotivationalFactorsUnderlying2021,
  title = {Motivational {{Factors Underlying}} the {{Use}} of {{Online Learning System}} in {{Higher Education}}: {{An Analysis}} of {{Measurement Model}}},
  author = {Mahande, Ridwan Daud and Akram},
  year = {2021},
  journal = {Turkish Online Journal of Distance Education},
  volume = {22},
  number = {1},
  pages = {89--105},
  issn = {EISSN-1302-6488},
  doi = {10/gmbvz7},
  abstract = {Online learning is a flexible and distributed distance learning system. The motivation of lecturers and students is one of key factors determining the acceptance and use of online learning in higher education. This research is aimed at empirically developing and testing a measurement model of several motivational constructs with the assumptions of indicators that build it. This research proposes a theoretical model which can be integrated into three motivational theories: ARCS, McClelland's needs, and Self-Determinant Theory (SDT). The construct indicators were developed and then validated empirically at two universities in Makassar, Indonesia. A quantitative method with survey approach was used. The research sample consisted of 71 lecturers and 210 students selected purposively. The analysis of measurement models used partial least square (PLS). The results show that the construct of motivation with indicators that built it met validity and reliability requirements. The results of this research present two alternative instruments for explaining the relationship between motivational factors including the indicators that influence the use of online learning systems in tertiary institutions.},
  langid = {english},
  keywords = {Adoption (Ideas),Attention,College Faculty,College Students,Competence,Distance Education,Electronic Learning,Foreign Countries,Interpersonal Relationship,Personal Autonomy,Psychological Needs,Relevance (Education),Satisfaction,Self Efficacy,Student Motivation,Teacher Motivation,Technology Integration,Theories}
}

@article{mahapatraOnlineFormativeAssessment2021,
  title = {Online {{Formative Assessment}} and {{Feedback Practices}} of {{ESL Teachers}} in {{India}}, {{Bangladesh}} and {{Nepal}}: {{A Multiple Case Study}}},
  author = {Mahapatra, Santosh Kumar},
  year = {2021},
  journal = {The Asia-Pacific education researcher},
  volume = {30},
  number = {6},
  pages = {519--530},
  publisher = {Springer Singapore},
  address = {Singapore},
  issn = {0119-5646},
  doi = {10.1007/s40299-021-00603-8},
  abstract = {ESL/EFL teachers, especially those working in higher education, across the world were required to teach online after the spread on COVID-19. Many empirical studies have been conducted in the last 1~year to investigate various aspects of online teaching and learning of languages. However, online ESL teaching in South Asian contexts remains almost unexplored. This paper reports a multiple case study that aimed to bridge this gap and explore online formative assessment (FA) and feedback practices of three ESL teachers working in three universities in India, Bangladesh and Nepal. Data were collected through classroom observations, interviews and document analysis. The results indicate that all three teachers actively engaged their students in a variety of FA practices, although they did not use the obtained information from assessments properly and there remained many areas of improvement. Their feedback practices, which involved the~integration of a few digital tools, were regular and student-friendly. The study is significant in that it is the~first of its kind. Future researchers can conduct large scale studies to verify if the findings of the~study are true for other university ESL teachers who are teaching online.},
  keywords = {Bangladesh,Case Studies,College Students,Computer Mediated Communication,COVID-19,Cross Cultural Studies,Education,Education & Educational Research,Educational Change,Educational evaluation,Educational Policy and Politics,English (Second Language),English as a second language,Feedback,Feedback (Response),Foreign Countries,Formative Evaluation,India,International and Comparative Education,Language Teachers,Learning and Instruction,Nepal,Online Courses,Onlinefeedback,Onlineformative assessment,Pandemics,Regular,Regular Article,Second Language Instruction,Second Language Learning,Social Sciences,Sociology of Education,Student Evaluation,Teacher Attitudes,Teacher Student Relationship,Teaching,Teaching Methods,University ESL teachers},
  file = {/Users/colin.madland/Zotero/storage/XYLN2XAT/mahapatraOnlineFormativeAssessment2021.pdf}
}

@article{mahmoudiEffectsUsingRubrics2020,
  title = {The {{Effects}} of {{Using Rubrics}} and {{Face}} to {{Face Feedback}} in {{Teaching Writing Skill}} in {{Higher Education}}},
  author = {Mahmoudi, Farzaneh and Bugra, Cemile},
  year = {2020},
  journal = {International Online Journal of Education and Teaching},
  volume = {7},
  number = {1},
  pages = {150--158},
  issn = {EISSN-2148-225X},
  abstract = {The use of rubrics in assessing the writing performance is very popular. In general, educators in universities use rubrics for a more accurate assessment of students writing performance. The first aim of this study is to investigate how using rubrics in teaching writing skills can affect the writing performance of students. The second aim is to investigate how giving of face to face feedback by teachers can have an influence on students writing performance. To this end, ESL Writing Grading Rubric was used in the teaching of writing skill to the preparatory school students (n=36) to help them understand the targets for their learning and the standards of quality for writing skills in order to improve their writing performance. Also, face to face feedback was given to the writing assignments of students to promote the students' awareness about their writing drawbacks. The qualitative analysis of the findings based on the open-ended questionnaire and focused group interview showed that using rubrics in teaching writing skill and also giving face to face feedback improved the students writing performance. Students reported that by gaining awareness about the rubric, they could check their writing work, give feedback to their peers' work, produce high-quality writings, and got better grades.},
  langid = {english},
  keywords = {College Students,English (Second Language),Feedback (Response),Foreign Countries,Grades (Scholastic),Instructional Effectiveness,No DOI found,Scoring Rubrics,Student Attitudes,Synchronous Communication,Writing Instruction,Writing Skills}
}

@article{maierEffectsComputerassistedFormative2016,
  title = {Effects of a Computer-Assisted Formative Assessment Intervention Based on Multiple-Tier Diagnostic Items and Different Feedback Types},
  author = {Maier, U and Wolf, N and Randler, C},
  year = {2016},
  journal = {Computers \& Education},
  volume = {95},
  pages = {85--98},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2015.12.002},
  abstract = {Computer-assisted formative assessments with multiple-tier items are a valid instrument for diagnosing students' conceptual understanding in learning domains with well structured declarative knowledge (e.g. science education). However, it is unknown how feedback on multiple-tier items can improve learning success. Therefore, we assessed (1) predictors of students' perception and use of elaborated feedback, and (2) if feedback content (elaborated, verification, control) matters in explaining students' achievement in post- and retention tests. We developed computer-assisted formative tests for a teaching unit on evolutionary adaptations. Three treatment groups were employed with varying feedback content: Treatment 1 (T1) was an elaborated instruction-based feedback, T2 was a dichotomous verification feedback, and T3 (control) consisted of reading appropriate texts (no formative assessment and no feedback). Afterwards, T1 was separated into one subgroup with pupils who used the feedback thoroughly (T1A) and a subgroup that did not use the feedback (T1B). Ten secondary classrooms were used and 261 pupils participated in this study. Each student in each classroom was randomly assigned to one treatment group. Correlation and univariate regression analysis showed that perception and use of elaborated feedback were related to intrinsic motivation and self-reported grades. Multivariate analysis of covariance was applied to check treatment effects on post-tests and retention tests as dependent variables. Results revealed that verification feedback (T2) and elaborated feedback when students did use it (T1A) was superior to no feedback (T3) and elaborated feedback when students did not use it (T1B). Implications for the design of multiple-tier diagnostic assessments are discussed. (C) 2016 Elsevier Ltd. All rights reserved.},
  langid = {english},
  keywords = {Computer-assisted testing,Feedback,Formative assessment,Science education,Secondary education}
}

@book{majorTeachingOnlineGuide2015,
  ids = {clairehowellmajorTeachingOnlineGuide2015},
  title = {Teaching Online: A Guide to Theory, Research, and Practice},
  author = {Major, Claire Howell},
  year = {2015},
  series = {Tech.Edu: A {{Hopkins}} Series on Education and Technolo},
  publisher = {Johns Hopkins University Press},
  address = {Baltimore, Maryland},
  collaborator = {Project Muse},
  isbn = {978-1-4214-1624-3 1-4214-1624-7},
  lccn = {LB1044.87 .M245 2015},
  keywords = {Methodology,Teaching,Teaching - Methodology,Web-based instruction}
}

@book{makiAssessingLearningBuilding2010,
  title = {Assessing for Learning: Building a Sustainable Commitment across the Institution},
  shorttitle = {Assessing for Learning},
  author = {Maki, Peggy},
  year = {2010},
  publisher = {Stylus Pub.},
  address = {Sterling, Va.},
  isbn = {978-1-57922-440-0 978-1-57922-441-7 978-1-57922-495-0},
  langid = {english},
  annotation = {OCLC: 874197735},
  file = {/Users/colin.madland/Zotero/storage/FPEWQUUP/makiAssessingLearningBuilding2010.pdf}
}

@article{makinaStudentsExperiencesDemotivating2022,
  title = {Students Experiences of Demotivating Online Formative Assessment Strategies at an Open Distance Learning University},
  author = {Makina, Antonia},
  year = {2022},
  journal = {Perspectives in Education},
  volume = {40},
  number = {2},
  issn = {2519593X},
  doi = {10.18820/2519593X/pie.v40.i2.4},
  urldate = {2023-01-15},
  abstract = {There is a growing body of research that suggests that improving~the quality of online formative assessment strategies increases~students' motivation to participate in online assessment.~However, the way in which course leaders at open distance~learning universities communicate the expectations of learning to~students through online formative assessment strategies largely~determines how students approach online formative assessment~tasks. The design of online formative assessment strategies is~an important element that is needed to promote an interactive~level of engagement needed for motivating students learning~online. It is against this background that this paper investigated~the experiences of students with demotivating online formative~assessment strategies at an open distance learning institution. The~study achieved this through phenomenography, a developmental,~qualitative and non-dualistic case study research. Twelve~purposively selected students from a postgraduate course were~interviewed to understand their experiences with demotivating~online formative assessment strategies. Students identified seven~demotivating online formative assessment strategies that provided~insight to course leaders in the production of more motivating~assessment strategies.~The study achieved this through phenomenography, a developmental, qualitative and non-dualistic research approach that used a case study, to interview twelve purposively selected students from a postgraduate course to understand their experiences with demotivating online formative assessment strategies. From the students' own perspective, seven online formative assessment strategies that demotivated them to learn were identified to provide insight to course leaders to produce motivating assessment strategies.},
  file = {/Users/colin.madland/Zotero/storage/NHYSRZG3/makinaStudentsExperiencesDemotivating2022.pdf}
}

@article{makomenawWelcomeNewWorld2012,
  title = {Welcome to a New World: Experiences of {{American Indian}} Tribal College and University Transfer Students at Predominantly White Institutions},
  author = {Makomenaw, Matthew Van Alstine},
  year = {2012},
  month = nov,
  journal = {International Journal of Qualitative Studies in Education},
  volume = {25},
  number = {7},
  pages = {855--866},
  issn = {0951-8398},
  doi = {10.1080/09518398.2012.720732},
  abstract = {This study utilizes an Indigenous methodology and phenomenological methods to better understand the experiences of eight American Indian tribal college and university (TCU) students who transferred to four-year Predominantly White Institutions (PWIs). The participants attended TCUs and PWIs located in the Midwest, a geographic area that is understudied in analyses of American Indian college students, in contrast to the southwest or Great Plains. While many studies focus on the failure of American Indian college students, this study focuses on the attributes of successful American Indian college students. It specifically examines the relationship between the participants? interaction and engagement with their campus and their successful transition to a PWI. Transferring from a predominantly American Indian institution, the participants showed a lack of interest in interacting with non-native faculty, staff, and students and faced ignorance and stereotypes not present at TCUs. This paper has important implications for future research, theory, and practice related to the successful transition of American Indian students from TCUs to PWIs.}
}

@article{Malau-Aduli_2012,
  title = {Peer Review Improves the Quality of Mcq Examinations},
  author = {{Malau-Aduli}, Bunmi S. and Zimitat, Craig},
  year = {2012},
  journal = {Assessment \& Evaluation in Higher Education},
  doi = {10/b52tfz},
  abstract = {The aim of this study was to assess the effect of the introduction of peer review processes on the quality of multiple-choice examinations in the first three years of an Australian medical course. The impact of the peer review process and overall quality assurance (QA) processes were evaluated by comparing the examination data generated in earlier years (2008) with those held under the new QA regime (2009 and 2010) from the same blueprint. Statistical analysis and comparisons of overall examination performance were made by year. Regarding multiple-choice questions (MCQs), item analysis was used to compare the proportion of difficult and discriminating items and functional distractors on summative examinations in 2008 (pre-implementation of peer review) and 2009 and 2010 (post-implementation). The impact of peer review processes resulted in a decrease in the number of items with negative discrimination; increases in reliability, appropriate item difficulty, and numbers of items with significant discriminat...},
  mag_id = {1966704939},
  pmcid = {null},
  pmid = {null}
}

@article{malczykIntroducingSocialWork2019,
  title = {Introducing {{Social Work}} to {{HyFlex Blended Learning}}: {{A Student-centered Approach}}},
  author = {Malczyk, Benjamin R.},
  year = {2019},
  journal = {Journal of Teaching in Social Work},
  volume = {39},
  number = {4-5},
  pages = {414--428},
  publisher = {Routledge},
  issn = {0884-1233},
  doi = {10/gg2n29},
  abstract = {ABSTRACTThe HyFlex blended learning model is a student-driven approach that allows students to determine what blended learning they prefer to meet their unique needs. In a HyFlex course, students are presented with a choice with each class session ? whether to attend face-to-face or participate online. This article introduces social work educators to the HyFlex blended learning model and presents the results from a five-week experiment utilizing the HyFlex blended approach in an undergraduate social welfare policy course. Benefits and challenges of the model are presented and discussed.},
  keywords = {hyflex}
}

@article{malikAssessingReliabilityValidity2019,
  title = {Assessing Reliability and Validity of {{Revised Biggs Two-Factor}} Study Process Questionnaire to Measure Learning Approaches among Undergraduate Medical Students in {{Lahore}}, {{Pakistan}}},
  author = {Malik, Ahmad Azam and Khan, Rehan Ahmed and Malik, Hina Nasreen and Humayun, Ayesha and Butt, Nadeem Shafique and Baig, Mukhtiar},
  year = {2019},
  journal = {JPMA. The Journal of the Pakistan Medical Association},
  volume = {69},
  number = {3},
  pages = {337--342},
  issn = {0030-9982},
  abstract = {OBJECTIVE: To assess reliability and validity of Revised Biggs Two-Factor Study Process Questionnaire to measure Learning approaches among medical students. METHODS: The cross-sectional study was conducted at Shaikh Zayed Medical College, Lahore, Pakistan, from November 15, 2014, to January 15, 2015. The 20-item Revised Biggs Two-Factor Study Process Questionnaire was used to assess medical students enrolled from the first to the final year of their studies. Data was analysed using SPSS 20. The reliability of the questionnaire was assessed by Cronbach's alpha, and confirmatory factor analysis was done to confirm the factor model. RESULTS: Of the 480 students approached, 284(59.2\%) completed the questionnaire. Cronbach's alpha value was found acceptable at 0.79 and 0.72 for the deep approach and surface approach scales respectively. Comparative Fit Index value (0.858) confirmed a good fit for the model. CONCLUSIONS: Revised Biggs Two-Factor Study Process Questionnaire was found to be a reliable and valid instrument to measure learning approaches among medical students.},
  langid = {english},
  pmid = {30890824},
  keywords = {Adolescent,Adult,Cross-Sectional Studies,Factor Analysis Statistical,Humans,Learning,Learning style Biggs study process Medical students Reliability Validity.,Pakistan,Reproducibility of Results,Students Medical,Surveys and Questionnaires,Young Adult},
  file = {/Users/colin.madland/Zotero/storage/TKWBIIRK/malikAssessingReliabilityValidity2019.pdf}
}

@article{malikUseTwitterEducational2019,
  title = {Use of {{Twitter}} across Educational Settings: A Review of the Literature},
  author = {Malik, Aqdas and {Heyman-Schrum}, Cassandra and Johri, Aditya},
  year = {2019},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {16},
  number = {1},
  pages = {1--22},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-019-0166-x},
  abstract = {The use of social media across the educational landscape is on the rise. Subsequently, the body of research on this topic is vibrant and growing. In this article, we present findings from a review of 103 peer-reviewed scientific studies published over the last decade (2007--2017) that address the use of Twitter for educational purposes across formal and informal settings. The majority of the studies reported in the literature are descriptive case studies carried out with students in North American and European higher education settings. Analysis of these studies signals Twitter as a useful tool for communication due to high accessibility, novelty, and real-time format. Students, teachers, and other stakeholders use it as a pedagogical tool to gain information, interact and engage with each other, participate in their respective communities of interests, and share their insights about specific topics. Moreover, Twitter has the potential to enhance students' learning capabilities as well as improve their motivation and engagement due to its unique features and non-traditional teaching approach. Finally, our analysis advocates for carrying out further empirical studies focusing on digital trace data and inference, particularly in the developing countries.},
  keywords = {Community participation,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Developing countries,Digital media,Education,Educational Technology,Empirical analysis,Higher Education,Humanities,Information Systems Applications (incl.Internet),Law,LDCs,Learning,Literature reviews,Review Article,Social media,Social networks,Statistics for Social Sciences,Students,Teaching,Twitter},
  file = {/Users/colin.madland/Zotero/storage/PVKIM4BH/s41239-019-0166-x.pdf}
}

@book{malisiusAcademicRigourVideo2019,
  title = {Academic {{Rigour}} and {{Video Technology}}: {{A Case Study}} on {{Digital Storytelling}} in {{Graduate-level Assignments}}},
  author = {Malisius, E},
  editor = {Altmann, A and Ebersberger, B and Mossenlechner, C and Wieser, D},
  year = {2019},
  series = {{{DISRUPTIVE POWER OF ONLINE EDUCATION}}: {{CHALLENGES}}, {{OPPORTUNITIES}}, {{RESPONSES}}},
  pages = {184},
  abstract = {While some may perceive technology as disruptive in higher education, this chapter makes a case that video technology can be used to increase collaboration and engagement in learning and teaching. It is argued that digital storytelling can be integrated as part of the assessment in graduate-level courses without compromising expectations related to academic rigor. Rather, digital storytelling advances multimedia literacy for the individual and supports the generation of bounded learning communities, specifically in online and blended programmes. Covering social presence, teaching presence and cognitive presence, the chapter draws on two examples of digital storytelling used in the MA in Conflict Analysis and Management and the MA in Global Leadership at Royal Roads University, Canada. Overall, the chapter makes a contribution to the conversation of how assessment formats can be updated to match the shift from traditional, lecture formats and brick-and-mortar institutions to applied, collaborative programmes that are often delivered in blended and online formats. Thus, as the field of higher education continues to evolve and adapt alongside technological innovations, the chapter suggests that digital storytelling can be one way to complement and update assessment formats to match the evolution of the twenty-first century.},
  isbn = {978-1-78754-325-6},
  langid = {english},
  keywords = {academic rigor,assessment,Digital storytelling,online learning,online teaching,video assignments}
}

@article{malouffBiasGradingMetaanalysis2016,
  title = {Bias in Grading: {{A}} Meta-Analysis of Experimental Research Findings},
  shorttitle = {Bias in Grading},
  author = {Malouff, John M and Thorsteinsson, Einar B},
  year = {2016},
  journal = {Australian Journal of Education},
  volume = {60},
  number = {3},
  pages = {245--256},
  issn = {0004-9441, 2050-5884},
  doi = {10.1177/0004944116664618},
  urldate = {2024-09-26},
  abstract = {This article provides a meta-analysis of experimental research findings on the existence of bias in subjective grading of student work such as essay writing. Twenty-three analyses, from 20 studies, with a total of 1935 graders, met the inclusion criteria for the meta-analysis. All studies involved graders being exposed to a specific type of information about a student other than the student's performance on a task. The hypothesized biasing characteristics included different race/ethnic backgrounds, education-related deficiencies, physical unattractiveness and poor quality of prior performance. The statistically significant overall between-groups effect size was g\,=\,0.36. Moderator analyses showed no significant difference in effect size related to whether the work graded was from a primary school student or a university student. No one type of biasing characteristic showed a significantly higher effect size than other types. The results suggest that bias can occur in subjective grading when graders are aware of irrelevant information about the students.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/malouffBiasGradingMetaanalysis2016.pdf}
}

@article{manankil-rankinMovingFieldText2016,
  title = {Moving {{From Field Text}} to {{Research Text}} in {{Narrative Inquiry}}: {{A Study Exemplar}}},
  author = {{Manankil-Rankin}, Louela},
  year = {2016},
  journal = {Canadian Journal of Nursing Research},
  volume = {48},
  number = {3-4},
  pages = {62--69},
  issn = {0844-5621},
  doi = {10.1177/0844562116684728},
  urldate = {2019-02-09},
  abstract = {Narrative Inquiry is a research methodology that enables a researcher to explore experience through a metaphorical analytic three-dimensional space where time, interaction of personal and social conditions, and place make up the dimensions for working with co-participant stories. This inquiry process, analysis, and interpretation involve a series of reflective cognitive movements that make possible the reformulations that take place in the research journey. In this article, I retell the process of my inquiry in moving from field texts (data sources) to research text (interpretation of experience) in Narrative Inquiry. I draw from an inquiry on how nurses experience living their values amidst organizational change to share how I as an inquirer/researcher, moved from field texts to narrative accounts; narrative resonant threads; composite letter as the narrative of experience; personal, practical, and social justifications to construct the research text and represent it another form as a poem. These phases in the inquiry involve considerations in the analytic and interpretive process that are essential in understanding how to conduct Narrative Inquiry. Lastly and unique to my inquiry, I share how a letter can be used as an analytic device in Narrative Inquiry.}
}

@article{manceboWorkHigherEducation2020,
  title = {The {{Work}} in {{Higher Education}}},
  author = {Mancebo, Deise and Santorum, Katia Maria Teixeira and Ribeiro, Carla Vaz dos Santos and L{\'e}da, Denise Bessa},
  year = {2020},
  journal = {Education Policy Analysis Archives},
  volume = {28},
  number = {6},
  issn = {EISSN-1068-2341},
  abstract = {This article presents the dossier, "Work in higher education", composed of 10 articles and discusses the changes that have taken place in the Brazilian labor world since the parliamentary, media and judicial coup that took place in 2016. It considers the hypothesis that one of the central goals of the coup was precisely the attack on work, in distributive sense of income, and also in the organizational sense of social and workers movements. It analyzes the legislation approved in the period -- Law 13.429/2017 and Law 13.467/2017 -- which has led to a sharp setback in the rights enshrined in the 1988 Constitution, and critically lists the main consequences of this legislation for workers such as unemployment, increased turnover, decrease in wages, reduction of recourses to labor justice and, consequently, increased mockery of protective social legislation at work, weakening of trade union organization and greater suffering at work in general. In the end, it develops the impacts of these changes on the work carried out in higher education institutions.},
  langid = {english},
  keywords = {Civil Rights,Colleges,Educational Change,Educational Legislation,Employees,Federal Legislation,Foreign Countries,Higher Education,Justice,Labor Legislation,Labor Turnover,Legal Responsibility,Neoliberalism,No DOI found,Occupational Safety and Health,School Personnel,Social Bias,Taxes,Unemployment,Unions,Wages}
}

@article{mandernachEffectInstructorpersonalizedMultimedia2009,
  title = {Effect of Instructor-Personalized Multimedia in the Online Classroom},
  shorttitle = {Effect of Instructor-Personalized Multimedia in the Online Classroom},
  author = {Mandernach, B. Jean},
  year = {2009},
  month = jun,
  journal = {International Review of Research in Open and Distance Learning},
  volume = {10},
  pages = {1--19},
  issn = {1492-3831},
  abstract = {There is considerable evidence that well-designed multimedia resources can enhance learning outcomes, yet there is little information on the role of multimedia in influencing essential motivational variables, such as student engagement. The current study examines the impact of instructor-personalized multimedia supplements on student engagement in an introductory, college-level online course. A comparison of student engagement between courses that feature increasing numbers of instructor-personalized multimedia components reveals conflicting evidence. While qualitative student feedback indicates enhanced engagement as a function of instructor-generated multimedia supplements, quantitative data reports no significant differences in engagement or learning between the various levels of multimedia inclusion. Findings highlight the complexity surrounding the appropriate use of multimedia within an online course. University policy-makers and instructors are cautioned to examine carefully the cost-benefit ratio of multimedia inclusion for online learning environments.},
  keywords = {LEARNING,Multimedia,Online,Online learning,policy},
  annotation = {3}
}

@article{mandernachRoleInstructorInteractivity2009,
  title = {The {{Role}} of {{Instructor Interactivity}} in {{Promoting Critical Thinking}} in {{Online}} and {{Face-to-Face Classrooms}}},
  shorttitle = {The {{Role}} of {{Instructor Interactivity}} in {{Promoting Critical Thinking}} in {{Online}} and {{Face-to-Face Classrooms}}},
  author = {Mandernach, B. Jean and Forrest, Krista D and Babutzke, Jamie L and Manker, Lanay R},
  year = {2009},
  journal = {MERLOT Journal of Online Learning and Teaching},
  volume = {5},
  pages = {49--62},
  abstract = {The current rise in online learning programs mandates that postsecondary faculty examine means of transferring successful, established critical thinking instructional strategies from the traditional classroom into the online environment. Theoretical arguments support, and even favor, the use of asynchronous learning technologies to promote students' critical thinking skills. The purpose of the current study is to examine students' application of critical thinking strategies when learning in a traditional, face-to-face environment compared to an asynchronous, online classroom. Results indicate that the mode of instructional delivery (face-to-face or online) is not as influential as the instructor's level of interactivity in promoting active engagement with course material. Findings suggest that the asynchronous component of online learning does not inherently prompt students toward enhanced critical thinking, but may serve as a vehicle for online instructors to encourage increased engagement and critical thinking.},
  keywords = {Asynchronous,asynchronous threaded discussions,critical,critical thinking,discussions,instructor,instructor interactivity,interactivity,LEARNING,Online,Online learning,Thinking,threaded},
  annotation = {1}
}

@article{mandouitRevisitingPowerFeedback2023,
  title = {Revisiting ``{{The Power}} of {{Feedback}}'' from the Perspective of the Learner},
  author = {Mandouit, Luke and Hattie, John},
  year = {2023},
  journal = {Learning and Instruction},
  volume = {84},
  pages = {101718},
  issn = {09594752},
  doi = {10.1016/j.learninstruc.2022.101718},
  urldate = {2023-02-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/G8DNNU74/mandouitRevisitingPowerFeedback2023.pdf}
}

@article{mankuteInterraterAgreementStudent2023,
  title = {Interrater Agreement between Student and Teacher Assessments of Endotracheal Intubation Skills in a Self-Directed Simulation Learning Environment},
  author = {Mankute, Aida and Juozapaviciene, Laima and Stucinskas, Justinas and Dambrauskas, Zilvinas and Dobozinskas, Paulius and Sinz, Elizabeth and Rodgers, David L. and Pukenyte, Evelina and Kumpaitiene, Birute and Vaitkaitis, Dinas},
  year = {2023},
  journal = {BMC medical education},
  volume = {23},
  number = {1},
  pages = {256--256},
  publisher = {Springer Nature},
  address = {LONDON},
  issn = {1472-6920},
  doi = {10.1186/s12909-023-04242-z},
  abstract = {BackgroundPractical skill assessment is an important part of the learning process to confirm competencies in acquired medical knowledge.ObjectiveThis study aimed to compare the assessments of endotracheal intubation skills using the HybridLab \& REG; methodology between students and teacher in terms of interobserver reliability.MethodsReliability analysis was performed with observational data (data are reported according to STROBE guidelines). The study was conducted in two countries, the Lithuanian University of Health Science (LUHS) and Pennsylvania State University (PSU) in the US, between 1 January and 30 June 2020. A total of 92 students (60 from LUHS and 32 from PSU) were trained in endotracheal intubation using an algorithm-driven hybrid learning method. At the end of the training session, the participants had to complete the evaluation scenario, which was assessed by one of the students and evaluated remotely by a single teacher. The student assessment of the endotracheal intubation procedure was compared with the teacher's assessment using correlation and estimation of the intraclass correlation coefficient.ResultsOverall, the medians of the student and teacher assessments were both 100\% (0\%). Spearman's correlation coefficient between the student and teacher assessments was 0.879 (p = 0.001). The intraclass correlation coefficient used for interobserver variations between the students and teacher was 0.883 (95\% confidence interval from 0.824 to 0.923).ConclusionsThe algorithm-driven hybrid learning method allows students to reliably assess endotracheal intubation skills to a level comparable with that of the teacher's evaluation. This learning method has the potential to be a cost-effective and efficient way to provide high-quality education while also saving human resources.},
  keywords = {Algorithms,Cohort analysis,Education & Educational Research,Education Scientific Disciplines,Educational Measurement,Empowerment,Feedback,Humans,HybridLab,Intubation,Intubation Intratracheal,Learning,Online instruction,Reproducibility of Results,School environment,Self-directed learning,Simulation,Skill assessment,Skills,Social Sciences,Software,Students,Teacher,Teachers,Teachers Rating of,Teaching methods},
  file = {/Users/colin.madland/Zotero/storage/M4N3S5YS/mankuteInterraterAgreementStudent2023.pdf}
}

@article{manobanProjectBasedLearningEPortfolios2021,
  title = {Project-{{Based Learning}} and {{E-Portfolios}} for {{Preservice Teachers}} in {{Japanese Language Education}}},
  author = {Manoban, Amonrat},
  year = {2021},
  month = jan,
  journal = {Journal of Education and Learning},
  volume = {10},
  number = {4},
  pages = {40--50},
  publisher = {{Journal of Education and Learning}},
  issn = {1927-5250},
  doi = {10.5539/jel.v10n4p40},
  abstract = {This study involved classroom action research that aimed to 1) develop the learning management competency for preservice teachers using the project-based learning approach and e-portfolios and 2) study the reflection of those preservice teachers in terms of learning management using the project-based learning approach and e-portfolios. The target groups for this research comprised 27 fourth-year students of the Teaching Japanese Language Program, Faculty of Education, Khon Kaen University. I divided the research tools into two categories: (a) tools for learning management (four learning management plans and teaching logs) and (b) tools for collecting research data (the portfolio assessment form and e-portfolios). The research results revealed the project-based learning approach and e-portfolios improved the Japanese language and culture learning management competency in each indicator at different levels; in addition, the results reflected the Japanese language and culture learning management focusing on learners and the use of learning materials stimulated learners' interest and systematic working and helped them appreciate the efficiency of work and ability to work with others.},
  keywords = {Active Learning,Cultural Education,Electronic Learning,Foreign Countries,Instructional Effectiveness,Japanese,Knowledge Level,Portfolios (Background Materials),Preservice Teacher Education,Preservice Teachers,Second Language Instruction,Second Language Learning,Student Projects,Teacher Competencies,Thailand,Undergraduate Students},
  file = {/Users/colin.madland/Zotero/storage/HUGF7U9H/manobanProjectBasedLearningEPortfolios2021.pdf}
}

@article{mansourStudentsFacilitatorsExperiences2024,
  title = {Students' and Facilitators' Experiences with Synchronous and Asynchronous Online Dialogic Discussions and e-Facilitation in Understanding the {{Nature}} of {{Science}}},
  author = {Mansour, Nasser},
  year = {2024},
  month = feb,
  journal = {Education and Information Technologies},
  issn = {1360-2357, 1573-7608},
  doi = {10.1007/s10639-024-12473-w},
  urldate = {2024-09-20},
  abstract = {Abstract             The existing literature lacks a precise understanding of how online facilitation and dialogic discussions can positively impact students' comprehension of the Nature of Science (NoS). This study delves into the experiences of students and facilitators engaged in synchronous and asynchronous online dialogic discussions and e-facilitation to enhance our understanding of NoS. An innovative experiment employed a digital dialogue game to engage postgraduate students in a Postgraduate Certificate in Education (PGCE) secondary science course. The participants included sixty-five PGCE science students and three lecturers specializing in different science disciplines (Physics, Chemistry, and Biology). Qualitative data collection methods and analysis, including transcripts of online discussions about NoS topics, were followed by critical event recall interviews to identify specific online dialogue events that significantly contributed to the comprehension of NoS.~The findings contribute significantly to comprehending students' processes in grasping complex and debatable topics such as Nature of Science (NoS) within online dialogic discussions supported by e-facilitation. They emphasize the importance of establishing an open and expansive dialogic space, with a focus on the crucial roles of e-facilitators. The results also highlight a tension between active and passive roles in both synchronous and asynchronous online discussions. Additionally, the study sheds light on the influence of space, time, and texts in understanding NoS through e-facilitated online dialogic discussions. Notably, the research emphasizes the live chat room's significance within Interloc, accentuating its role as a social space fostering a sense of community and a safe environment for inquiry in online dialogue which supported understanding NoS.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/LH942F8J/s10639-024-12473-w.pdf;/Users/colin.madland/Zotero/storage/PE8PXKFH/mansourStudentsFacilitatorsExperiences2024.pdf}
}

@article{maoAssessmentStrategiesSelfRegulated2013,
  title = {Assessment {{Strategies}}, {{Self-Regulated Learning Skills}}, and {{Perceptions}} of {{Assessment}} in {{Online Learning}}},
  author = {Mao, Jin and Peck, Kyle},
  year = {2013},
  journal = {Quarterly Review of Distance Education},
  volume = {14},
  number = {2},
  pages = {75},
  publisher = {IAP - Information Age Publishing, Inc},
  address = {Charlotte},
  issn = {1528-3518},
  abstract = {This study investigated the effects of assessment strategies and self-regulated learning skills on students' learning and perceptions of assessment for learning. The results revealed no statistically significant difference in the immediate skill-based and cognitive learning outcomes, but peer assessment teams scored significantly higher than the other teams in the subsequent collaborative writing process. Significant interaction effects were found in the participants' perceptions of assessment for learning. The findings support the emphasis on assessment processes and long-term learning benefits, and provide further evidence for the benefits of using assessment strategies and the value of learner assessment experience in online environments.;~ This study investigated the effects of assessment strategies and self-regulated learning skills on students' learning and perceptions of assessment for learning. The results revealed no statistically significant difference in the immediate skill-based and cognitive learning outcomes, but peer assessment teams scored significantly higher than the other teams in the subsequent collaborative writing process. Significant interaction effects were found in the participants' perceptions of assessment for learning. The findings support the emphasis on assessment processes and long-term learning benefits, and provide further evidence for the benefits of using assessment strategies and the value of learner assessment experience in online environments. [PUBLICATION ABSTRACT];},
  keywords = {Collaborative Writing,College students,Course Content,Distance learning,Education Courses,Educational Benefits,Essays,Evaluation Criteria,Evaluation Methods,Feedback,Feedback (Response),Higher education,Knowledge Level,Learning Strategies,Likert Scales,Management,Management Systems,Metacognition,No DOI found,Online Courses,Online education,Peer Evaluation,Perceptions,Questionnaires,Scores,Student Attitudes,Student Evaluation,Teaching,Teaching Methods,Undergraduate Students,Writing Evaluation}
}

@misc{Mapping2014,
  title = {V\&{{R}} Mapping},
  year = {2014},
  month = sep,
  journal = {David White},
  urldate = {2021-12-23},
  abstract = {The mapping process is a Visitors and Residents based group activity which is designed to explore individuals engagement with the Web. It's a good starting point for discovering how staff, st{\dots}},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/US4HRRJM/vr-mapping.html}
}

@article{marciniakQualityAssuranceOnline2018,
  title = {Quality {{Assurance}} for {{Online Higher Education Programmes}}: {{Design}} and {{Validation}} of an {{Integrative Assessment Model Applicable}} to {{Spanish Universities}}},
  author = {Marciniak, Renata},
  year = {2018},
  journal = {International Review of Research in Open and Distributed Learning},
  volume = {19},
  number = {2},
  pages = {127--154},
  issn = {EISSN-1492-3831},
  abstract = {The quality assurance of online Higher Education online programmes is one of the great challenges faced by Spanish universities. Regular assessment of these programmes is essential in order to take actions to improve their quality. The said assessment should be complex and include all of the components of the programme, as well as its planning and implementation stages and its effects. The purpose of this paper is to present a model designed to assess the quality of online Higher Education online programmes that includes the assessment of the quality of the programme itself, as well as its continuous assessment. In order to design the model, the author conducted a bibliographical analysis of different standards, models, and guides developed in Spain and other countries to assess online education. The model was validated by 23 international online education experts. The results of the validation were triangulated with specialized literature, thus allowing the author to make decisions regarding whether to change the model by keeping, reformulating, or removing a dimension or indicator. As a result, two variables, fourteen dimensions, and 81 indicators were obtained. In order to verify the utility of the model it was applied in the assessment of four online programmes. The model guides the persons in charge of the implementation of online programmes and allows to conduct a more comprehensive assessment of the programme in order to discover its strengths and weaknesses, and opportunities for its improvement. The model can be also applied by online programme designers as a guideline for creating other, high quality programmes.},
  langid = {english},
  keywords = {College Programs,Educational Quality,Electronic Learning,Foreign Countries,Higher Education,Models,No DOI found,Program Evaluation,Quality Assurance,Validity}
}

@article{marciniakSystemIndicatorsQuality2021,
  title = {A {{System}} of {{Indicators}} for the {{Quality Assessment}} of {{Didactic Materials}} in {{Online Education}}},
  author = {Marciniak, Renata and C{\'a}liz Rivera, Cristina},
  year = {2021},
  journal = {International Review of Research in Open and Distributed Learning},
  volume = {22},
  number = {1},
  pages = {180--198},
  issn = {EISSN-1492-3831},
  doi = {10/gmbvzk},
  abstract = {The quality of didactic materials is a source of concern for teachers, users, and educational institutions that offer online education. There is a lack of indicators to help assess the quality of three key types of didactic materials commonly used in online education: didactic units (i.e., materials that contain program contents), didactic guides (i.e., materials that provide information), and additional didactic materials (materials to deepen knowledge). The objective of this article is to present a system of indicators designed to assess the quality of these types of didactic materials and guide their creation process. The system was developed based on a critical analysis of existing models designed to assess the quality of digital didactic materials. The system was validated by 16 international experts in online education, and a trial application of the system assessed five didactic guides and didactic units used by online universities in three different countries. Results of the validation process were triangulated with relevant literature, allowing the authors to make decisions regarding changes to the system in terms of maintaining, reformulating, or removing indicators. The resulting system comprises 43 assessment indicators and serves as a guide for designers, teachers, and users in the creation and selection of didactic materials for use in online education and in the assessment of their quality.},
  langid = {english},
  keywords = {College Instruction,Educational Quality,Electronic Learning,Evaluation Criteria,Foreign Countries,Instructional Material Evaluation,Instructional Materials,Reliability,Universities,Validity}
}

@article{marcusEvaluatingNursingStudents2021,
  title = {Evaluating {{Nursing Students}}' {{Perceptions}} of {{Using Quick Response Codes}} to {{Enhance Learning During Nursing Health Assessment}}},
  author = {Marcus, J and Adebayo, M and {Cranwell-Bruce}, L and Faulkner, {\relax MS}},
  year = {2021},
  journal = {Nursing Education Perspectives},
  volume = {42},
  number = {6},
  pages = {E133-E134},
  issn = {1536-5026},
  doi = {10.1097/01.NEP.0000000000000652},
  abstract = {Providing engaging activities to supplement classroom learning can be a challenge for today's nurse educator. Quick response (QR) code technology provides hands-on clinical experiences without the use of high-fidelity simulators. The purpose of this article is to evaluate how QR codes during a health assessment simulation activity enhanced learning for first-semester baccalaureate nursing students. The use of QR codes increased student confidence during health assessment with a form of technology they found engaging.},
  langid = {english},
  keywords = {Clinical Education,Health Assessment,QR Codes,Simulation}
}

@article{marinhoDigitalPortfolioAssessment2021,
  ids = {marinhoDigitalPortfolioAssessment2021a},
  title = {The {{Digital Portfolio}} as an {{Assessment Strategy}} for {{Learning}} in {{Higher Education}}},
  author = {Marinho, Paulo and Fernandes, Preciosa and Pimentel, Fernando},
  year = {2021},
  month = jan,
  journal = {Distance Education},
  volume = {42},
  number = {2},
  pages = {253--267},
  publisher = {Distance Education},
  address = {ABINGDON},
  issn = {0158-7919},
  doi = {10.1080/01587919.2021.1911628},
  abstract = {This study was developed in the context of a course in higher education and in a blended learning environment--online, distance, and face-to-face (b-learning). The aim was to identify and characterize the meanings and effects that students and teachers attribute to the use of digital portfolios as an assessment and learning strategy. The experience allowed the portfolio to be recognized as a mediating device in the development of assessment procedures that generate learning--an epicenter of efficient feedback and a means of enhancing the (re)construction of knowledge. The portfolio also helped develop students' reflective capacity on their work and their learning, autonomy, and collaboration action, and improved their learning.},
  keywords = {assessment for learning,Blended Learning,blended learning (b-learning),Brazil,College Students,digital portfolio,Distance learning,Education & Educational Research,Education portfolios,Educational evaluation,Electronic Learning,Feedback (Response),Foreign Countries,Formative Evaluation,Higher education,Learning Strategies,Portfolio Assessment,Portfolios (Background Materials),Reflection,Social Sciences,Student Attitudes,Teacher Attitudes,Young Adults}
}

@article{marionOpportunitiesChallengesSystems2018,
  title = {The {{Opportunities}} and {{Challenges}} of a {{Systems Approach}} to {{Assessment}}},
  author = {Marion, Scott F.},
  year = {2018},
  journal = {Educational Measurement: Issues and Practice},
  volume = {37},
  number = {1},
  pages = {45--48},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {0731-1745},
  doi = {10/gjn22j},
  urldate = {2021-04-08},
  file = {/Users/colin.madland/Zotero/storage/W4KT2DKC/marionOpportunitiesChallengesSystems2018.pdf}
}

@article{markauskaiteRethinkingEntwinementArtificial2022,
  title = {Rethinking the Entwinement between Artificial Intelligence and Human Learning: {{What}} Capabilities Do Learners Need for a World with {{AI}}?},
  author = {Markauskaite, Lina and Marrone, Rebecca and Poquet, Oleksandra and Knight, Simon and {Martinez-Maldonado}, Roberto and Howard, Sarah and Tondeur, Jo and De Laat, Maarten and Buckingham Shum, Simon and Ga{\v s}evi{\'c}, Dragan and Siemens, George},
  year = {2022},
  month = jan,
  journal = {Computers and Education: Artificial Intelligence},
  volume = {3},
  pages = {100056},
  issn = {2666-920X},
  doi = {10.1016/j.caeai.2022.100056},
  abstract = {The proliferation of AI in many aspects of human life---from personal leisure, to collaborative professional work, to global policy decisions---poses a sharp question about how to prepare people for an interconnected, fast-changing world which is increasingly becoming saturated with technological devices and agentic machines. What kinds of capabilities do people need in a world infused with AI? How can we conceptualise these capabilities? How can we help learners develop them? How can we empirically study and assess their development? With this paper, we open the discussion by adopting a dialogical knowledge-making approach. Our team of 11 co-authors participated in an orchestrated written discussion. Engaging in a semi-independent and semi-joint written polylogue, we assembled a pool of ideas of what these capabilities are and how learners could be helped to develop them. Simultaneously, we discussed conceptual and methodological ideas that would enable us to test and refine our hypothetical views. In synthesising these ideas, we propose that there is a need to move beyond AI-centred views of capabilities and consider the ecology of technology, cognition, social interaction, and values.},
  keywords = {AI in education,Capabilities for AI,Ecological approach,Postdigital dialogue},
  file = {/Users/colin.madland/Zotero/storage/9HYQHE4V/markauskaiteRethinkingEntwinementArtificial2022.pdf}
}

@incollection{marksDigitalTransformationHigher2022,
  title = {Digital {{Transformation}} in {{Higher Education}}: {{A Framework}} for {{Maturity Assessment}}},
  shorttitle = {Digital {{Transformation}} in {{Higher Education}}},
  booktitle = {{{COVID-19 Challenges}} to {{University Information Technology Governance}}},
  author = {Marks, Adam and {AL-Ali}, Maytha},
  editor = {Alaali, Mansoor},
  year = {2022},
  pages = {61--81},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-13351-0_3},
  urldate = {2023-03-20},
  isbn = {978-3-031-13350-3 978-3-031-13351-0},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/DU8BC7AE/marksDigitalTransformationHigher2022.pdf}
}

@article{marksonEfficacyOnlineK122018,
  title = {The {{Efficacy}} of {{Online K-12 School Leadership Preparation Programs}}},
  author = {Markson, Craig},
  year = {2018},
  journal = {Journal for Leadership and Instruction},
  volume = {17},
  number = {2},
  pages = {31--39},
  issn = {ISSN-2475-6032},
  abstract = {The purpose of this study was to investigate the efficacy of online K-12 school leadership preparation programs. Sixty-five graduates of a K-12 school leadership preparation program from a large public university in New York State were included in this study. A survey was used to collect school leadership program graduates' scores on the New York State School Building Leader (SBL) and School District Leader (SDL) licensure assessments as well as their perceptions of their coursework and internship training in the Interstate School Leader Licensure Consortium (ISLLC) Standards. The results of this study showed no statistically significant differences on scores for SBL Part I, SBL Part II and the SDL Part I licensure assessments among the face-to-face and online groups. However, there were statistically significant differences for SDL Part II scores. The mean scores showed the online instructional program graduates scoring higher on the dimensions of Leading District Educational Programs and Managing District Resources and Compliance. There were little to no statistically significant differences found on the coursework preparation for the ISLLC Standards among the face-to-face and online program graduates. On internship preparation, there were statistically significant differences on ISLLC Standard Three: management of the organization, operations, and resources for a safe, efficient learning environment. Here, online graduates perceived better preparedness than face-to-face graduates. The implications of this research suggested that online school leadership preparation programs can be as effective as face-to-face programs.},
  langid = {english},
  keywords = {College Graduates,Elementary Secondary Education,Instructional Leadership,Internship Programs,Leadership Training,Licensing Examinations (Professions),No DOI found,Online Courses,Outcomes of Education,Program Effectiveness,Scores}
}

@inproceedings{marshallTwoEyedSeeingElder2017,
  title = {Two-{{Eyed Seeing}} -- {{Elder Albert Marshall}}'s Guiding Principle for Inter-Cultural Collaboration},
  booktitle = {Thinkers {{Lodge}}},
  author = {Marshall, Albert},
  year = {2017},
  address = {Pugwash, NS},
  urldate = {2018-12-02},
  abstract = {Mi'kmaq Elder Albert Marshall (who lives in the community of Eskasoni, Nova Scotia, in the Traditional Territory of Mi'kma'ki) coined the English phrase ``Two-Eyed Seeing'' many years ago for a guiding principle found in Mi'kmaq Knowledge as reflected in the language. Elder Albert is a fluent speaker of Mi'kmaq ... Two- Eyed Seeing in his language is known as Etuaptmumk.}
}

@article{martinDesignMattersDevelopment2021,
  title = {Design {{Matters}}: {{Development}} and {{Validation}} of the {{Online Course Design Elements}} ({{OCDE}}) {{Instrument}}},
  author = {Martin, Florence and Bolliger, Doris U. and Flowers, Claudia},
  year = {2021},
  journal = {International Review of Research in Open and Distributed Learning},
  volume = {22},
  number = {2},
  pages = {46--71},
  issn = {EISSN-1492-3831},
  doi = {10/gmbv2j},
  abstract = {Course design is critical to online student engagement and retention. This study focused on the development and validation of an online course design elements (OCDE) instrument with 38 Likert-type scale items in five subscales: (a) overview, (b) content presentation, (c) interaction and communication, (d) assessment and evaluation, and (e) learner support. The validation process included implementation with 222 online instructors and instructional designers in higher education. Three models were evaluated which included a one-factor model, five-factor model, and higher-order model. The five-factor and higher-order models aligned with the development of the OCDE. The frequency of use of OCDE items was rated above the mean 4.0 except for two items on collaboration and self-assessment. The overall OCDE score was related to self-reported levels of expertise but not with years of experience. The findings have implications for the use of this instrument with online instructors and instructional designers in the design of online courses.},
  langid = {english},
  keywords = {Construct Validity,Factor Analysis,Factor Structure,Goodness of Fit,Higher Education,Instructional Design,Likert Scales,Online Courses,Scores,Test Construction,Test Reliability}
}

@article{martinez-romeraPracticalTrainingSecondary2020a,
  title = {Practical {{Training}} of {{Secondary School Teachers}} in {{Spain}}: {{Tutoring}} and {{Assessment Using ICT}}},
  author = {{Martinez-Romera}, Daniel and {Cebrian-Robles}, Daniel and {Perez-Galan}, Rafael},
  year = {2020},
  month = apr,
  journal = {Turkish Online Journal of Distance Education},
  volume = {21},
  number = {2},
  pages = {153--166},
  publisher = {Turkish Online Journal of Distance Education},
  issn = {1302-6488},
  abstract = {This study is part of a larger R\&D project that analyses the quality of training and the digital skills taught during the preservice training of teachers, as well as during the master's degree dissertation (TFM in Spanish) in the Degree in Education in Spain. The study is descriptive and exploratory in nature. It combines mixed techniques that are used on four sources: (1) External practice guides and dissertations (TFM) from 37 Spanish Faculties of Education; (2) interviews with a sample of 7 Master coordinators; (3) A survey on 94 university tutors from the above-mentioned universities, in charge of trainee teachers' external practice and dissertations (TFM); and (4) Interviews with 46 school tutors from practice schools. Results show the persistence of different situations and a lack of definition in the guidelines as well as in some teachers' perceptions that have more to do with educational models of the past. Among other aspects to improve, this degree shows a marginal use of ICT during Practicum and Dissertation phases, also a lack of assessment criteria in the guides regarding portfolios, theory/practice coordination, tutorship or prevention of plagiarism is observed in most of the studied cases.},
  keywords = {Computer Uses in Education,Faculty Advisers,Foreign Countries,Graduate Students,Masters Programs,Masters Theses,No DOI found,Practicums,Preservice Teacher Education,Preservice Teachers,Secondary Education,Spain,Student Evaluation,Student Teacher Supervisors,Student Teaching,Tutoring,Tutors}
}

@article{martinezDistinguishingServantLeadership2023,
  title = {Distinguishing Servant Leadership from Transactional and Transformational Leadership},
  author = {Martinez, Seth-Aaron and Leija, Nahari},
  year = {2023},
  journal = {Advances in Developing Human Resources},
  volume = {25},
  number = {3},
  pages = {141--188},
  publisher = {Sage Publications},
  issn = {1523-4223},
  doi = {10.1177/15234223231175845},
  abstract = {Problem: The scholarship of leadership abounds with the affordances, limitations, antecedents, and outcomes associated with the different theories in Human Resource Development (HRD) literature. However, a clear delineation between the host of individual leadership theories does not exist. Absent is a nuanced view of the similarities, differences, and any overlap between the various leadership theories. Without a clear understanding of the relationships between leadership theories, knowing when to apply which theories and when becomes difficult. Solution: A systematic review of the literature surrounding servant leadership (SL) through 2022 was conducted to position SL among the more extensively researched transactional and transformational leadership theories. This article outlines the histories of the three theories, focusing on the characteristics, pervasiveness, antecedents, outcomes, and measurement of SL to distinguishing it from transactional and transformational leadership.; Stakeholders: Human resource development, human resource management, and organizational behavior scholars, practitioners, educators, and students. In addition, organizational leaders responsible for setting the organization's vision and practitioners responsible for designing leadership development programs will benefit from this article. (PsycInfo Database Record (c) 2023 APA, all rights reserved)},
  keywords = {Human Resource Management,Leadership,servant leadership,Theories,transactional leadership,Transactional Leadership,transformational leadership,Transformational Leadership}
}

@article{martinhoTeachingSentimentEmergency2021,
  title = {Teaching {{Sentiment}} in {{Emergency Online Learning--A Conceptual Model}}},
  author = {Martinho, Domingos and Sobreiro, Pedro and Vardasca, Ricardo},
  year = {2021},
  journal = {Education Sciences},
  volume = {11},
  issn = {EISSN-2227-7102},
  doi = {10/gmbv2n},
  abstract = {Due to the COVID-19 pandemic, higher education institutions with a face-to-face model have found themselves in the contingency of migrating to online learning. This study explores the perspective of all the lecturers at a Portuguese private higher education institution who were invited to participate, regardless of their research area, in this questionnaire. It aims to propose and test a conceptual model that combines attitudes, preferred activities, and technological experience with the sentiment about the impact of this experience on students' learning process, on their teaching activity, and on the strategy of higher education institutions. An online questionnaire was conducted to 65 lecturers engaging in emergency online lecturing. The obtained results showed that lecturers reveal a positive attitude towards online lecturing, tend to prefer activities in which they feel most comfortable in face-to-face lecturing, and consider having technological experience useful for online activities. Lecturers have a positive sentiment about the impact of online learning on students' learning, their faculty career, and the strategy of higher education institutions. The proposed conceptual model test shows that the model has well-fitting conditions. The results confirm the hypotheses formulated: namely, the predictive effect of attitude, preferred activities, and technological experience on sentiment. Faculty engagement in emergency online lecturing shows that the members are available to participate in the changing process, and the proposed conceptual model can be used to assess this readiness.},
  keywords = {College Faculty,COVID-19,Electronic Learning,Emergency Programs,Foreign Countries,Learning Activities,Pandemics,Positive Attitudes,Preferences,Private Colleges,Teaching Experience,Technological Literacy}
}

@article{martonQualitativeDifferencesLearning1976,
  title = {On Qualitative Differences in Learning - {{I}}: {{Outcome}} and Process},
  shorttitle = {On Qualitative Differences in Learning - {{I}}: {{Outcome}} and Process},
  author = {Marton, F and S{\"a}lj{\"o}, R},
  year = {1976},
  journal = {British Journal of Educational Psychology},
  volume = {46},
  pages = {4--11}
}

@article{martonQUALITATIVEDIFFERENCESLEARNING1976,
  title = {{{ON QUALITATIVE DIFFERENCES IN LEARNING}}: {{I}}---{{OUTCOME AND PROCESS}}*},
  author = {MARTON, F. and S{\"A}LJ{\"O}, R.},
  year = {1976},
  month = feb,
  journal = {British Journal of Educational Psychology},
  volume = {46},
  number = {1},
  pages = {4--11},
  issn = {2044-8279},
  doi = {10.1111/j.2044-8279.1976.tb02980.x}
}

@article{martonQUALITATIVEDIFFERENCESLEARNING1976a,
  title = {{{ON QUALITATIVE DIFFERENCES IN LEARNING}}---{{II OUTCOME AS A FUNCTION OF THE LEARNER}}'{{S CONCEPTION OF THE TASK}}},
  author = {MARTON, F. and S{\"A}ALJ{\"O}, R.},
  year = {1976},
  month = jun,
  journal = {British Journal of Educational Psychology},
  volume = {46},
  number = {2},
  pages = {115--127},
  issn = {2044-8279},
  doi = {10.1111/j.2044-8279.1976.tb02304.x},
  abstract = {Summary.  Two groups of 20 first-year students were asked to read three sections of a textbook. After the first two sections the groups received different types of question. One group received questions which demanded a thorough understanding of the meaning of the passage. The other group was given detailed factual questions. After the final section of reading a common set of questions of both types was asked. Besides providing further evidence of qualitative differences in learning, the experiment showed that students did adapt their way of learning to their conception of what was required of them.}
}

@article{martos-garciaStudentsPerceptionFormative2017,
  title = {Students' {{Perception}} on {{Formative}} and {{Shared Assessment}}: {{Connecting}} Two {{Universities}} through the {{Blogosphere}}},
  author = {{Martos-Garcia}, Daniel and Usabiaga, Oidui and {Valencia-Peris}, Alexandra},
  year = {2017},
  journal = {Journal of New Approaches in Educational Research},
  volume = {6},
  number = {1},
  pages = {64--70},
  publisher = {Univ Alicante, Grupo Investigacion Edutic-Adei},
  address = {ALICANTE},
  issn = {2254-7339},
  doi = {10.7821/naer.2017.1.194},
  abstract = {The aim of this study was to evaluate differences in physical education students' perception on an educational innovation based on formative and peer assessment through the blog-osphere. The sample was made up of 253 students from two Spanish universities. Data was collected using a self-reported questionnaire and t tests were employed in order to find differences among students' groups. Results show significant differences in almost all of the items on which the students were questioned. Basque students were more satisfied with the assessment tool used than the Valencian students. Students found the blog-osphere more active, meaningful, functional and motivating and that it made for collaborative learning in comparison to other traditional evaluation methods. They also showed disapproval related to the demands on attendance, continuity and the greater effort required. For future occasions, negotiation about assessment criteria with the students should be implemented right at the very start of the course.},
  keywords = {Blog,BLOG E-LEARNING,Blogs,Collaboration,Distance learning,Educacion fisica,Education & Educational Research,Educational technology,Evaluacion formativa,Evaluacion por pares,FORMATIVE ASSESSMENT,Higher education,Learning,Online instruction,PEER ASSESSMENT,PHYSICAL EDUCATION,R&D,Research & development,Social Sciences,Students,Teacher education,Teaching},
  file = {/Users/colin.madland/Zotero/storage/BT2JDW8U/martos-garciaStudentsPerceptionFormative2017.pdf}
}

@misc{marxReclaimingSovereigntyDigital2025,
  title = {Reclaiming Sovereignty in the Digital Age},
  author = {Marx, Paris},
  year = {2025},
  month = feb,
  urldate = {2025-04-25},
  abstract = {Cyberlibertarianism must die if there's to be any hope of a better future for the internet},
  howpublished = {https://www.disconnect.blog/p/reclaiming-sovereignty-in-the-digital-age},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/82I4VZX3/reclaiming-sovereignty-in-the-digital-age.html}
}

@article{masonEportfoliosAssessmentTool2004,
  title = {E-Portfolios: An Assessment Tool for Online Courses},
  shorttitle = {E-Portfolios},
  author = {Mason, Robin and Pegler, Chris and Weller, Martin},
  year = {2004},
  month = nov,
  journal = {British Journal of Educational Technology},
  volume = {35},
  number = {6},
  pages = {717--727},
  issn = {0007-1013, 1467-8535},
  doi = {10.1111/j.1467-8535.2004.00429.x},
  urldate = {2022-11-27},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/8MIS4X56/masonEportfoliosAssessmentTool2004.pdf}
}

@article{masromUnderstandingStudentsBehavior2021,
  title = {Understanding Students' Behavior in Online Social Networks: A Systematic Literature Review},
  author = {Masrom, Maslin Binti and Busalim, Abdelsalam H. and Abuhassna, Hassan and Mahmood, Nik Hasnaa Nik},
  year = {2021},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {18},
  number = {1},
  pages = {1--27},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-021-00240-7},
  abstract = {The use of online social networks (OSNs) has increasingly attracted attention from scholars' in different disciplines. Recently, student behaviors in online social networks have been extensively examined. However, limited efforts have been made to evaluate and systematically review the current research status to provide insights into previous study findings. Accordingly, this study conducted a systematic literature review on student behavior and OSNs to explicate to what extent students behave on these platforms. This study reviewed 104 studies to discuss the research focus and examine trends along with the important theories and research methods utilized. Moreover, the Stimulus-Organism-Response (SOR) model was utilized to classify the factors that influence student behavior. This study's results demonstrate that the number of studies that address student behaviors on OSNs have recently increased. Moreover, the identified studies focused on five research streams, including academic purpose, cyber victimization, addiction, personality issues, and knowledge sharing behaviors. Most of these studies focused on the use and effect of OSNs on student academic performance. Most importantly, the proposed study framework provides a theoretical basis for further research in this context.},
  keywords = {Academic Achievement,Addictive Behavior,Computer Appl. in Social and Behavioral Sciences,Computer Mediated Communication,Computer Science,Computers and Education,Educational Technology,Higher Education,Humanities,Information Systems Applications (incl.Internet),Internet,Law,Literature Reviews,Online social networks,Personality Traits,Review Article,Sharing Behavior,Social media,Social Networks,Statistics for Social Sciences,Stimulus-organism-response model,Student Behavior,Students,Students' behavior,Systematic review},
  file = {/Users/colin.madland/Zotero/storage/ZAVJNXM4/masromUnderstandingStudentsBehavior2021.pdf}
}

@article{masseyAssessmentLiteracyCollege2020,
  title = {Assessment {{Literacy}} in {{College Teaching}}: {{Empirical Evidence}} on the {{Role}} and {{Effectiveness}} of a {{Faculty Training Course}}},
  shorttitle = {Assessment {{Literacy}} in {{College Teaching}}},
  author = {Massey, Kyle D. and DeLuca, Christopher and {LaPointe-McEwan}, Danielle},
  year = {2020},
  month = jan,
  journal = {To Improve the Academy},
  volume = {39},
  number = {1},
  issn = {2334-4822},
  doi = {10/gj5ngz},
  urldate = {2021-05-22},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/JZA65XTF/masseyAssessmentLiteracyCollege2020.pdf}
}

@article{Masters_2001,
  title = {Assessment of Multiple Choice Questions in Selected Test Banks Accompanying Text Books Used in Nursing Education},
  author = {Masters, Joan C and Hulsmeyer, Barbara S and Pike, Mary Ellen and Leichty, Kathy and Miller, Margaret T and Verst, Amy L},
  year = {2001},
  journal = {Journal of Nursing Education},
  doi = {10/ghnhs9},
  abstract = {The purpose of this study was to assess multiple-choice questions used in test-banks accompanying selected nursing textbooks. A random sample of 2,913 questions was selected from a convenience sample of 17 test banks. Questions were evaluated on (a) adherence to generally accepted guidelines for writing multiple-choice questions; (b) cognitive level as defined by Bloom's (1961) taxonomy; and (c) distribution of correct answers as A, B, C, or D. The results were 2,233 violations of item-writing guidelines, most of which were minor but some were serious. A large number of questions (47.3\%) were written at the knowledge level and only 6.5\% were written at the analysis level. The correct answers were evenly distributed: c2s ranged from 0.00 to 4.84; chi square value needed to reach .05 probability was 26.30. Faculty are encouraged to evaluate multiple-choice questions from test banks carefully before using them for exams.},
  mag_id = {45479546},
  pmcid = {null},
  pmid = {11198906}
}

@article{masukuAssessmentPedagogyMeasuring2021,
  title = {Assessment as a {{Pedagogy}} and {{Measuring Tool}} in {{Promoting Deep Learning}} in {{Institutions}} of {{Higher Learning}}},
  author = {Masuku, Mfundo Mandla and Jili, Nokukhanya Noqiniselo and Sabela, Primrose Thandekile},
  year = {2021},
  journal = {International Journal of Higher Education},
  volume = {10},
  number = {2},
  pages = {274--283},
  issn = {ISSN-1927-6044},
  doi = {10/gmbv2h},
  abstract = {Traditionally, the key principle of assessment was based on the depth and intensity of the knowledge taught in class. In our modern state, the notion of assessment is more about learning and less about whether it is deep or surface learning. This could be attributed to challenges facing higher education, such as marketisation, massification, access and success. This article aims to demonstrate the significance of assessment as a pedagogical and measuring tool to promote deep learning in institutions of higher learning. It analyses how different types of assessment could contribute to deep learning while enhancing critical thinking and analytical skills. The article adopted the qualitative research approach to appraise critically and examine the literature on assessment in higher education. The sequence in which assessment tasks are presented, the pedagogical approaches adopted and measurement tools used should aim to present general non-threatening questions. The article recognises Bloom's taxonomy as it classifies educational learning objectives in the manner that accommodates deep learning. This article suggests that assessment should be made explicit, aligned with learning outcomes that consider deep learning in terms of acquisition of knowledge, comprehension, application, analysis, synthesis and understanding of basic concepts in what is learnt. It concludes that students need to be engaged in their assessment to enable them to develop skills and dispositions that prepare them for the future as socially responsible citizens. Research needs to be conducted on the higher education challenges that compromise the quality of assessment as this could have negative effects on the development of deep learning.},
  langid = {english},
  keywords = {Alignment (Education),College Instruction,College Students,Educational Assessment,Evaluation Methods,Formative Evaluation,Grading,Higher Education,Measurement Techniques,Student Participation,Teaching Methods,Thinking Skills}
}

@article{mata-domingoDevelopmentCollaborativeInteraction2020,
  title = {Development of a {{Collaborative Interaction Management System}} ({{CIMS}}) for {{Selected Higher Educational Institutions}} in the {{Philippines}}},
  author = {{Mata-Domingo}, Salvacion},
  year = {2020},
  journal = {Online Submission},
  volume = {1},
  number = {1},
  pages = {1--33},
  issn = {ISSN-2719-065X},
  abstract = {This study developed a framework that can be used to build a forum environment, referred to as a Collaborative Interaction Management System (CIMS) that incorporates an automated method of assessing student's individual contributions and group collaborative learning. The framework was fine-tuned by conducting a survey that identified 20 major features that faculty and students from various universities in the National Capital Region of the Philippines mostly prefer to be included in a forum environment. A web-based prototype software was then developed that implements the framework along with the assessment method and the 20 top features. To determine the validity of the main feature of CIMS (i.e., the assessment method), sample forum data consisting of 28 threads with a total of more than 1000 messages spanning various topic domains was collected from the Slashdot forum and the numeric ratings assigned to messages in this data was used to measure accuracy and reliability of the numeric ratings assigned by CIMS by analyzing it using Cohen's Kappa. Based on the results of the survey, the overall means have identified that both faculty and students feel that the prototype software are functional, reliable, and usable enough.},
  langid = {english},
  keywords = {Accuracy,College Faculty,College Students,Computer Mediated Communication,Computer Software,Cooperative Learning,Foreign Countries,Group Discussion,Group Dynamics,Higher Education,Management Systems,No DOI found,Peer Relationship,Reliability,Student Evaluation,Teacher Student Relationship}
}

@article{mateAnalyzingImplementationERP2017,
  title = {Analyzing the {{Implementation}} of an {{ERP System}} by {{Self-Assessment}} in {{Higher Education}}},
  author = {M{\'a}t{\'e}, Domici{\'a}n and B{\'a}cs, Zolt{\'a}n and Tak{\'a}cs, Viktor L{\'a}szl{\'o}},
  year = {2017},
  journal = {Acta Didactica Napocensia},
  volume = {10},
  number = {2},
  pages = {45--56},
  issn = {EISSN-2065-1430},
  doi = {10/gmbv39},
  abstract = {Over the last few decades, not only organizations but also Higher Education Institutions should be more responsive to the demands of the changed global business environment and improve their effectiveness. Our motivation to write this paper is to assess the implementation of an Enterprise Resource Planning (ERP) system in higher education and their associated benefits, with a focus on students' performance when applying an SAP solution. This paper analyses the accuracy of undergraduate students, focusing primarily on the concept of self-assessment as they predict and evaluate their own performance relative to their externally assessed achievement. In the pre- and post-examination predictions the higher achieving students seem to predict and evaluate their examination results more accurately than their lower-achieving fellows. Although a gender gap cannot be found in self-estimation, we found substantial differences by comparing the selected language. Foreign students seem to overestimate their own examination performance to a greater degree than Hungarians do. Consequently, our results might allow decision makers to identify why self-assessment is important when implementing pilot ERP projects. The result of this study also provide evidence for groups of clients and other stakeholders in order to reduce failure in both higher education and business environment.},
  langid = {english},
  keywords = {Accuracy,College Students,Educational Change,Foreign Countries,Gender Differences,Higher Education,Hypothesis Testing,Performance Factors,Predictive Validity,Pretests Posttests,Program Implementation,Regression (Statistics),Self Evaluation (Individuals),Systems Development,Undergraduate Students}
}

@article{mathesMiddleSchoolTeachers2020,
  title = {Middle {{School Teachers}}' {{Perceptions}} of {{Academic}} and {{Behavioral Support Testing Accommodations}}},
  author = {Mathes, Nicole E. and Witmer, Sara E. and Volker, Martin A.},
  year = {2020},
  month = jul,
  journal = {Journal of Applied School Psychology},
  volume = {36},
  number = {3},
  pages = {293--323},
  issn = {1537-7903, 1537-7911},
  doi = {10/gmbwsd},
  urldate = {2021-07-27},
  langid = {english}
}

@phdthesis{mathesonExaminationPersonalFinancial2019,
  title = {An {{Examination}} of {{Personal Financial Literacy Teaching}} and {{Learning}} in {{Ontario High Schools}}},
  author = {Matheson, Murdoch Neil},
  year = {2019},
  journal = {ProQuest Dissertations and Theses},
  address = {Ann Arbor},
  abstract = {The purpose of the study was to examine the experiences of current high school students, teachers, and high school graduates in Ontario regarding their experiences with personal financial curriculum and teaching at the secondary level, and to identify the ways in which this important educational experience may have helped prepare students to become financially literate. I sought to examine how helpful and productive financial literacy teaching and curriculum were at preparing students to confidently address personal financial issues they would inevitably face. I considered this overarching issue using a transdisciplinary lens from the perspective of the three stakeholder groups. Using a case study research design, the first of its kind in Ontario or Canada on this topic, I utilized interviews, artifacts, and surveys to uncover student and teacher experiential data across three high schools and two institutions of higher learning in southeastern Ontario. For the interviews and artifacts, there were 12 students and 12 teachers from three high schools. For the high school graduate surveys, there were 344 participants, drawn from one college and one university. Inductive thematic analysis was used for the interviews and artifacts; descriptive and inferential statistical analyses were used for the surveys, with some significance testing. The major findings were that current students and high school graduates perceived curriculum and teaching experiences as seriously lacking in effectively preparing them to be financially literate, and that a fundamental reorientation around transdisciplinary, student-led learning was key to transforming such learning into a more meaningful and valuable educational experience. The central finding from the teacher perspective was that such instruction should be mandated, properly supported and largely student-led; reaffirming the view that greater student learning, meaning and value were achievable with suitable enactment. Accordingly, the three stakeholder groups shared the view that curriculum and teaching in the area of personal financial literacy was largely absent and/or ineffective at meeting student interests and needs. With mandatory, properly supported, student-oriented (transdisciplinary) instruction, the potential exists for more effective and valuable learning, resulting in better equipped high school students that were properly prepared to successfully navigate financial issues and the path ahead.},
  langid = {english},
  school = {Queen's University (Canada)},
  keywords = {(UMI)AAI13850852,0277:Education finance,0385:Canadian studies,0533:Secondary education,Canada,Canadian studies,Education,Education finance,Financial literacy,High school,Ontario,Secondary education},
  annotation = {13850852},
  file = {/Users/colin.madland/Zotero/storage/BLRQJ89J/mathesonExaminationPersonalFinancial2019.pdf}
}

@book{mauchGuideSuccessfulThesis2003,
  title = {Guide to the Successful Thesis and Dissertation: {{A}} Handbook for Students and Faculty},
  author = {Mauch, James E and Park, Namgi},
  year = {2003},
  series = {Library and {{Information Science}}},
  edition = {5th},
  publisher = {CRC Press},
  address = {New York}
}

@article{mauriUseFeedbackSystems2016,
  title = {The {{Use}} of {{Feedback Systems}} to {{Improve Collaborative Text Writing}}: {{A Proposal}} for the {{Higher Education Context}}},
  author = {Mauri, Teresa and Ginesta, Anna and Rochera, Maria-Jos{\'e}},
  year = {2016},
  month = jan,
  journal = {Innovations in Education and Teaching International},
  volume = {53},
  number = {4},
  pages = {411--423},
  publisher = {{Innovations in Education and Teaching International}},
  issn = {1470-3297},
  doi = {10.1080/14703297.2014.961503},
  abstract = {Collaborative writing is a task commonly used for learning and assessment in higher education. The complexity of this type of task requires special support for learning contents. Feedback can be used as a key element to improve students' learning and engagement. This paper presents and evaluates a teaching innovation that sought to design a model feedback system. In this innovation, 218 students and 4 teachers participated in a course on Educational Psychology in Teacher Training. Questionnaires were used to collect students' perceptions and their satisfaction ratings regarding the quality of feedback received from the teacher. The students' uses of feedback were also taken into account. Additionally, interviews were conducted with instructors. The main results highlight the relevance of integrating the essential characteristics of effective feedback, as well as the use of ICT, for supporting learning in this complex task.},
  keywords = {Collaborative Writing,College Programs,Educational Psychology,Educational Quality,Feedback (Response),Formative Evaluation,Instructional Effectiveness,Interviews,Online Courses,Participant Satisfaction,Questionnaires,Student Attitudes,Teacher Attitudes,Teaching Methods,Technology Uses in Education}
}

@article{maxwellExpandingHistoryRange2016,
  title = {Expanding the {{History}} and {{Range}} of {{Mixed Methods Research}}},
  author = {Maxwell, Joseph A.},
  year = {2016},
  month = jan,
  journal = {Journal of Mixed Methods Research},
  volume = {10},
  number = {1},
  pages = {12--27},
  issn = {1558-6898, 1558-6901},
  doi = {10/gctq87},
  urldate = {2021-07-31},
  abstract = {Presentations of the history and range of mixed methods research presented in textbooks, handbooks, and journal articles have typically ignored a great deal of earlier and contemporary research that integrated qualitative and quantitative approaches, but did not explicitly identify itself as ``mixed methods.'' This article reviews earlier research, in both the natural and social sciences, that clearly integrated qualitative and quantitative approaches and methods, and discusses some contemporary research traditions that use such integration without labeling this ``mixed methods.'' Important implications of these studies and traditions for the conceptualization and conduct of mixed methods research are discussed.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/BQVX4U59/maxwellExpandingHistoryRange2016.pdf}
}

@article{maxwellItemEfficiencyItem2019,
  title = {Item Efficiency: An Item Response Theory Parameter with Applications for Improving the Reliability of Mathematics Assessment},
  shorttitle = {Item Efficiency},
  author = {Maxwell, Mary and Gleason, Jim},
  year = {2019},
  month = feb,
  journal = {International Journal of Mathematical Education in Science and Technology},
  volume = {50},
  number = {2},
  pages = {216--243},
  issn = {0020-739X, 1464-5211},
  doi = {10.1080/0020739X.2018.1492038},
  urldate = {2022-06-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/F6CPIJNJ/maxwellItemEfficiencyItem2019.pdf}
}

@book{maxwellUsingDataImprove2021,
  title = {Using {{Data}} to {{Improve Student Learning Theory}}, {{Research}} and {{Practice}}},
  author = {Maxwell, Graham S},
  year = {2021},
  urldate = {2022-05-07},
  abstract = {This book offers a coherent research-based overview and analysis of theories and practices in using data to improve student learning. It clarifies what 'use of data' means and differentiates the different levels of decision-making in education (relating to the system, district, school, classroom, or individual student). The relationship between data and decision-making is considered and various movements in the use of data to improve student learning are analysed, especially from the perspective of their assumptions and effects. This leads to a focus on effective educational decision-making as a social process requiring collaboration among all relevant participants. It also requires a clear understanding of educational aims, and these are seen to transcend what can be assessed by standardised tests. The consequences of this analysis for decision processes are explored and conclusions are drawn about what principles might best guide educational practice as well as what ambiguities remain. Throughout, the focus is on what existing research says about each of the issues explored. .},
  isbn = {978-3-030-63539-8},
  langid = {english},
  annotation = {OCLC: 1286754358},
  file = {/Users/colin.madland/Zotero/storage/V276P8HV/maxwellUsingDataImprove2021.pdf}
}

@article{mayadasAsynchronousLearningNetworks1997,
  title = {Asynchronous Learning Networks: {{A Sloan Foundation}} Perspective},
  shorttitle = {Asynchronous Learning Networks: {{A Sloan Foundation}} Perspective},
  author = {Mayadas, Frank},
  year = {1997},
  month = mar,
  journal = {Journal of Asynchronous Learning Networks},
  volume = {1},
  pages = {1--16},
  abstract = {Over the years small numbers of motivated individuals have studied by themselves, away from university centers, to acquire knowledge in post-secondary subjects. Correspondence study began over a century ago and since then, other forms of "distance education" have become established. In spite of all this progress, off-campus learners have worked mainly in isolation, with only occasional contact with instructors and peers. Today's low-cost communications and computer technologies, however, enable learning in Asynchronous Learning Networks (ALNs), in the process simultaneously overcoming barriers of isolation, distance and those imposed by rigid time constraints. The paper describes some projects at institutions of higher education funded by the Sloan Foundation, identifies some early results and possible evolution of ALN's to large scale implementations.},
  keywords = {ALN,Asynchronous,Distance,distance education,Education},
  annotation = {1}
}

@article{mayEfficientHelpfulDistracting2018,
  title = {Efficient, Helpful, or Distracting? {{A}} Literature Review of Media Multitasking in Relation to Academic Performance},
  author = {May, Kaitlyn E. and Elder, Anastasia D.},
  year = {2018},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {15},
  number = {1},
  pages = {1--17},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-018-0096-z},
  abstract = {Media multitasking, using two or more medias concurrently, prevails among adolescents and emerging adults. The inherent mental habits of media multitasking---dividing attention, switching attention, and maintaining multiple trains of thought--- have significant implications and consequences for students' academic performance. The goal of this review is to synthesize research on the impacts of media multitasking on academic performance. The research indicates that media multitasking interferes with attention and working memory, negatively affecting GPA, test performance, recall, reading comprehension, note-taking, self-regulation, and efficiency. These effects have been demonstrated during in- class activities (largely lectures) and while students are studying. In addition, students struggle to accurately assess the impact media multitasking will have on their academic performance. Further research should attend to understanding effects of media multitasking in more diverse instructional contexts and for varied academic tasks. Fostering students' self-regulation around media multitasking is a promising area for future efforts towards improving academic performance of college students.},
  keywords = {Academic achievement,Academic performance,Adolescents,Adults,Cognition,Cognition & reasoning,College students,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Digital media,Educational Technology,Higher Education,Humanities,Information Systems Applications (incl.Internet),Law,Literature reviews,Media,Media multitasking,Multitasking,Review Article,Statistics for Social Sciences,Students},
  file = {/Users/colin.madland/Zotero/storage/ATRD3RSF/s41239-018-0096-z.pdf}
}

@book{mayerCambridgeHandbookMultimedia2014,
  title = {The {{Cambridge Handbook}} of {{Multimedia Learning}}},
  editor = {Mayer, Richard E.},
  year = {2014},
  series = {Cambridge {{Handbooks}} in {{Psychology}}},
  edition = {2},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9781139547369},
  abstract = {In recent years, multimedia learning, or learning from words and images, has developed into a coherent discipline with a significant research base. The Cambridge Handbook of Multimedia Learning is unique in offering a comprehensive, up-to-date analysis of research and theory in the field, with a focus on computer-based learning. Since the first edition appeared in 2005, it has shaped the field and become the primary reference work for multimedia learning. Multimedia environments, including online presentations, e-courses, interactive lessons, simulation games, slideshows, and even textbooks, play a crucial role in education. This revised second edition incorporates the latest developments in multimedia learning and contains new chapters on topics such as drawing, video, feedback, working memory, learner control, and intelligent tutoring systems. It examines research-based principles to determine the most effective methods of multimedia instruction and considers research findings in the context of cognitive theory to explain how these methods work.}
}

@book{mayerCambridgeHandbookMultimedia2021,
  title = {The {{Cambridge Handbook}} of {{Multimedia Learning}}},
  editor = {Mayer, Richard E. and Fiorella, Logan},
  year = {2021},
  month = nov,
  edition = {3},
  publisher = {Cambridge University Press},
  doi = {10.1017/9781108894333},
  urldate = {2025-05-14},
  abstract = {Digital and online learning is more prevalent than ever, making multimedia learning a primary objective for many instructors. The Cambridge Handbook of Multimedia Learning examines cutting-edge research to guide creative teaching methods in online classrooms and training. Recognized as the field's major reference work, this research-based handbook helps define and shape this area of study. This third edition provides the latest progress report from the world's leading multimedia researchers, with forty-six chapters on how to help people learn from words and pictures, particularly in computer-based environments. The chapters demonstrate what works best and establishes optimized practices. It systematically examines well-researched principles of effective multimedia instruction and pinpoints exactly why certain practices succeed by isolating the boundary conditions. The volume is founded upon research findings in learning theory, giving it an informed perspective in explaining precisely how effective teaching practices achieve their goals or fail to engage.},
  copyright = {https://www.cambridge.org/core/terms},
  isbn = {978-1-108-89433-3 978-1-108-84158-0 978-1-108-81466-9}
}

@incollection{mayerDesigningInstructionConstructivist1999,
  title = {Designing Instruction for Constructivist Learning},
  booktitle = {Instructional Design Theories and Models: {{A}} New Paradigm of Instructional Theory},
  author = {Mayer, Richard E},
  editor = {Reigeluth, C. M.},
  year = {1999},
  publisher = {Lawrence Erlbaum Associations},
  address = {Mahwah, NJ},
  annotation = {MDDE603 Course Readings}
}

@book{mayerHandbookResearchLearning2011,
  title = {Handbook of Research on Learning and Instruction},
  author = {Mayer, Richard E and Alexander, Patricia A},
  year = {2011},
  series = {Educational {{Psychology Handbook Series}}},
  publisher = {Routledge},
  address = {New York}
}

@article{mayerInstructiveAnimationHelping1992,
  title = {The Instructive Animation: {{Helping}} Students Build Connections between Words and Pictures in Multimedia Learning},
  author = {Mayer, Richard E. and Anderson, Richard B.},
  year = {1992},
  journal = {Journal of Educational Psychology},
  volume = {84},
  number = {4},
  pages = {444--452},
  abstract = {In 2 experiments, Ss studied an animation depicting the operation of a bicycle tire pump or an automobile braking system, along with concurrent oral narration of the steps in the process (concurrent group), successive presentation of animation and narration (by 4 different methods), animation alone, narration alone, or no instruction (control group). On retention tests, the control group performed more poorly than each of the other groups, which did not differ from one another. On problem-solving tests, the concurrent group performed better than each of the other groups, which did not differ from one another. These results are consistent with a dual-coding model in which retention requires the construction of representational connections and problem solving requires the construction of representational and referential connections. An instructional implication is that pictures and words are most effective when they occur contiguously in time or space. (PsycINFO Database Record (c) 2010 APA, all rights reserved)},
  keywords = {college students Oral Communication Pictorial Stimuli Problem Solving Retention Teaching Methods College Students School Learning,instructive animation &/vs concurrent vs successive oral narration,retention of & problem solving in learned task},
  annotation = {Accession Number: edu-84-4-444. First Author \& Affiliation: Mayer, Richard E.; U California, Santa Barbara, US. Other Publishers: Warwick \& York. Release Date: 20060710. Correction Date: 20100816. Publication Type: Journal, Peer Reviewed Journal. Media Covered: Print. Document Type: Journal Article. Language: English. Major Descriptor: Oral Communication; Pictorial Stimuli; Problem Solving; Retention; Teaching Methods. Minor Descriptor: College Students; School Learning. Classification: Curriculum \& Programs \& Teaching Methods (3530); Population: Human (10); . Age Group: Adulthood (18 yrs \& older) (300); . Methodology: Empirical Study. References Available: Y.. Issue Publication Date: Dec, 1992. Publication History: Accepted Date: Apr 6, 1992; Revised Date: Apr 6, 1992; First Submitted Date: Nov 29, 1991. Copyright: American Psychological Association. 1992.;}
}

@article{mayerNineWaysReduce2003,
  title = {Nine {{Ways}} to {{Reduce Cognitive Load}} in {{Multimedia Learning}}},
  author = {Mayer, Richard E. and Moreno, Roxana},
  year = {2003},
  journal = {Educational Psychologist},
  volume = {38},
  number = {1},
  pages = {43--52},
  doi = {10.1207/S15326985EP3801_6},
  abstract = {First, we propose a theory of multimedia learning based on the assumptions that humans possess separate systems for processing pictorial and verbal material (dual-channel assumption), each channel is limited in the amount of material that can be processed at one time (limited-capacity assumption), and meaningful learning involves cognitive processing including building connections between pictorial and verbal representations (active-processing assumption). Second, based on the cognitive theory of multimedia learning, we examine the concept of cognitive overload in which the learner's intended cognitive processing exceeds the learner's available cognitive capacity. Third, we examine five overload scenarios. For each overload scenario, we offer one or two theory-based suggestions for reducing cognitive load, and we summarize our research results aimed at testing the effectiveness of each suggestion. Overall, our analysis shows that cognitive load is a central consideration in the design of multimedia instruction.}
}

@article{mayeshibaEvaluationCriticalThinking2018,
  title = {An {{Evaluation}} of {{Critical Thinking}} in {{Competency-Based}} and {{Traditional Online Learning Environments}}},
  author = {Mayeshiba, Matthew and Jansen, Kay R. and Mihlbauer, Lisa},
  year = {2018},
  journal = {Online Learning},
  volume = {22},
  number = {2},
  pages = {77--89},
  issn = {ISSN-2472-5749},
  abstract = {Nonterm, direct assessment competency-based education (CBE) represents a significant reimagining of the structure of higher education. By regulating students' progress through the program based on their mastery of tightly defined competencies rather than on the time spent learning them, this learning environment affords students far greater flexibility than traditional programs. This focus on defined competencies has led to concerns that students in these types of programs may not demonstrate higher level skills, such as critical thinking, at levels comparable to those enrolled in more traditional programs. This study evaluated 39 students' demonstration of critical thinking in two assessments administered in parallel versions of one course: one offered through the nonterm, direct assessment CBE University of Wisconsin Flexible Option, and the other offered through a traditional online program. For this study, each of the 78 assessments was scored using the critical thinking rubric from the Valid Assessment of Learning in Undergraduate Education (VALUE) project. We found that students from the CBE version of the course received significantly higher (p = 0.0013) overall scores than the students in the traditional online version of the course. While further research is required to refine these methods and ensure the generalizability of these results, they do not support concerns about students' abilities in this learning environment.},
  langid = {english},
  keywords = {Comparative Analysis,Competency Based Education,Conventional Instruction,Correlation,Critical Thinking,Electronic Learning,No DOI found,Online Courses,Outcomes of Education,Regression (Statistics),Scores,Scoring Rubrics,Student Evaluation,Undergraduate Students}
}

@article{mayhewOnlineSubmissionFeedback2022,
  ids = {mayhewOnlineSubmissionFeedback2022a},
  title = {Online Submission, Feedback and Grading of Assessment: What Do Academic Staff Really Think?},
  author = {Mayhew, Emma and Holmes, Vicki and Davies, Madeleine and Dimitriadi, Yota},
  year = {2022},
  journal = {Research in learning technology},
  volume = {30},
  pages = {1--14},
  publisher = {Association for Learning Technology},
  address = {Jarfalla},
  issn = {2156-7077},
  doi = {10.25304/rlt.v30.2458},
  abstract = {The move to institution-wide adoption of online submission, feedback and grading is increasing significantly within the Higher Education sector. This transition is predominantly driven by the need to improve the student assessment experience, but some institutions now also cite the need to improve the staff assessment experience. Existing studies, however, provide seemingly contradictory evidence surrounding this online marking experience. This article adopts a mixed methods approach to explore academic staff preferences of the assessment experience within a UK-based institution following adoption of online submission, feedback and grading during 2017--2018. It finds that although the majority of colleagues prefer to mark and provide feedback online, the process of marking electronically is highly individual. Online marking is not just a single practice but a set of varied, rich approaches, influenced by individual marker perceptions, preferences and previous experiences, and is often highly emotive. Changes to existing marking practices are seen simultaneously as both challenging and liberating by cohorts of markers. Drawing on the results of a detailed staff survey, this article identifies seven themes that are influential to that experience. These findings have significant implications for how institutions manage change to large-scale adoption of online marking.},
  keywords = {assessment and feedback,change management,Distance learning,Educational evaluation,electronic assessment management,Feedback,Higher education,Institutionalization,online assessment,Online instruction,Questionnaires,Schools,Screen time,University students},
  file = {/Users/colin.madland/Zotero/storage/D3JHGXAB/mayhewOnlineSubmissionFeedback2022.pdf}
}

@book{maysGuideMakingOpen2017,
  title = {A Guide to Making Open Textbooks with Students},
  editor = {Mays, Elizabeth},
  year = {2017},
  publisher = {Rebus Community},
  abstract = {"A handbook for faculty interested in practicing open pedagogy by involving students in the making of open textbooks, ancillary materials, or other Open Educational Resources."--Publisher.},
  collaborator = {DeRosa, Robin and Coolidge, Amanda and Andrzejewski, Anna and Ashok, Apurva and Wake Hyde, Zoe and Squires, David and Higginbotham, Gabriel and Barrett, Alice and Ward, Julie and Moore, Matthew and Nicholson, Maxwell and Jhangiani, Rajiv and DeRosa, Robin and Burns, Samara and Wagstaff, Steel and Robbins, Timothy},
  isbn = {978-1-989014-02-8},
  langid = {english},
  annotation = {OCLC: 1042242963}
}

@article{mazzeiProblematicSilenceAction2007,
  title = {Toward a Problematic of Silence in Action Research},
  author = {Mazzei, Lisa A.},
  year = {2007},
  month = dec,
  journal = {Educational Action Research},
  volume = {15},
  number = {4},
  pages = {631--642},
  issn = {0965-0792},
  doi = {10/dfp2zp},
  abstract = {Action researchers often generate large amounts of textual material in the form of notes and transcripts, failing to account for those thoughts that we and our research participants silently voice. As such, action research that attempts to engage practitioners in self reflexivity and textual analysis is a fertile site for a consideration of how silences are used in research settings to communicate meanings previously ignored because they were unspoken. In order to consider these silences as purposeful strategic moves on the part of research participants, I propose a problematic of silence that allows the silences to breathe and speak. This problematic of silence attempts to interrupt fixed notions of what counts as text and speech in our researching of the social and seeks to engage the limits of research in order to allow the spoken silences to be present in the textual records of educational action research.},
  file = {/Users/colin.madland/Zotero/storage/VIHQNDPN/mazzeiProblematicSilenceAction2007.pdf}
}

@article{mcarthurAssessmentSocialJustice2016,
  title = {Assessment for Social Justice: The Role of Assessment in Achieving Social Justice},
  shorttitle = {Assessment for Social Justice},
  author = {McArthur, Jan},
  year = {2016},
  month = oct,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {41},
  number = {7},
  pages = {967--981},
  publisher = {Routledge},
  issn = {0260-2938},
  doi = {10.1080/02602938.2015.1053429},
  urldate = {2024-05-07},
  abstract = {This article provides a rationale for assessment for social justice, through which a greater focus is given to the role of assessment in achieving the social justice aspirations of higher education. It takes inspiration from work on assessment for learning to propose that as assessment is a powerful driver of how and what students learn, we should also consider its potential to drive a commitment for greater social justice within and through higher education. The article provides a critique of procedural notions of social justice, which I argue have implicitly influenced current notions of fairness in assessment. Greater reflection on the possible flaws in such procedural notions is a starting point for rethinking assessment in social justice terms. I then draw on two alternative conceptualisations of social justice -- the capabilities approach and critical theory -- to consider the ways in which key assessment issues would look differently through these alternative lenses. The article does not aim to establish a prescriptive list of practices around the notion of assessment for social justice, but rather upon debate and a greater appreciation of the implications of how we conceptualise justice and the attendant influence on what may be considered appropriate assessment policies and practices.},
  keywords = {assessment,capabilities approach,critical theory,social justice},
  file = {/Users/colin.madland/Zotero/storage/CJUUEJYY/mcarthurAssessmentSocialJustice2016.pdf}
}

@article{mcarthurRethinkingAuthenticAssessment2023,
  ids = {mcarthurRethinkingAuthenticAssessment2023a},
  title = {Rethinking Authentic Assessment: Work, Well-Being, and Society},
  author = {McArthur, Jan},
  year = {2023},
  month = jan,
  journal = {Higher Education},
  volume = {85},
  number = {1},
  pages = {85--101},
  issn = {1573-174X},
  doi = {10.1007/s10734-022-00822-y},
  abstract = {This article seeks a deeper understanding of the concept of authentic assessment which ensures it does not become another educational buzzword, slowly diminishing in real meaning. I consider the origins of the term in the US schooling sector, and how it has developed over time, and in different countries, to today focus in higher education largely on real world tasks. There is, however, I argue, a common conflation of real world with the world of work. Little of this literature actually engages with the rich philosophical debates on authenticity, and in this article, I suggest that this deeper understanding of authenticity can enable us to build on existing work on authentic assessment to develop a more holistic and richer concept that will be more beneficial to individual students and to the larger society of which they are part. I argue that we should move from thinking in terms of either the so-called real world, or the world of work, to focus our justification for authentic assessment on its social value (which encompasses but is not limited to its economic value). To achieve this aim, I suggest we move from simply focusing on the authentic task to considering why that task matters? This then enables a shift from the student in isolation to the student as a member of society. Senses of achievement can become richer, thus enhancing the students' sense of self, self-worth, and well-being.},
  file = {/Users/colin.madland/Zotero/storage/XVQZS2RB/mcarthurRethinkingAuthenticAssessment2023.pdf}
}

@article{mcauleyDecolonizingCyberspaceOnline2011,
  title = {Decolonizing Cyberspace: {{Online}} Support for the {{Nunavut MEd}}},
  author = {McAuley, Alexander and Walton, Fiona},
  year = {2011},
  journal = {The International Review of Research in Open and Distributed Learning},
  volume = {12},
  number = {4},
  pages = {17},
  issn = {1492-3831},
  doi = {10.19173/irrodl.v12i4.848},
  abstract = {Keywords: Inuit; Aboriginal; distance graduate program; decolonization; pedagogy; K-12; school administrator; Indigenous education; Nunavut; decolonizing; educational leadership; distance education; distance learning; blended learning; knowledge building Background: The Nunavut MEd and the Need for Online Support Nunavut, created in 1999, translates to our land in English. [.]compared to non-Inuit educators, Inuit are more likely to find that family and community obligations make it difficult for them to take graduate programs at universities in the south.;Offered between 2006 and 2009 and graduating 21 Inuit candidates, the Nunavut Master of Education program was a collaborative effort made to address the erosion of Inuit leadership in the K-12 school system after the creation of Nunavut, Canada's newest territory, in 1999. Delivered to a large extent in short, intensive, face-to-face courses, the program also made extensive use of online supports. This paper outlines the design challenges -- geographical, technological, pedagogical, and cultural -- that faced the development and delivery of the online portion of the program. It highlights the intersection of the design decisions with the decolonizing principles that framed the program as a whole, the various and varying roles played by the online environment over the course of the program, and the program's contribution to student success.;},
  keywords = {Aboriginal,blended learning,Candidates,decolonization,decolonizing,distance education,distance graduate program,Distance learning,Education,educational leadership,Indigenous education,Inuit,Inuktitut language,K-12,knowledge building,Native peoples,Nunavut,pedagogy,school administrator,School boards,Teachers}
}

@article{mcbainStudentExperienceOral2016,
  title = {Student {{Experience}} of {{Oral Communication Assessment Tasks Online}} from a {{Multi-Disciplinary Trial}}},
  author = {McBain, Bonnie and Drew, Antony and James, Carole and Phelan, Liam and Harris, Keith M and Archer, Jennifer},
  year = {2016},
  month = jan,
  journal = {Education \& Training},
  volume = {58},
  number = {2},
  pages = {134--149},
  publisher = {Education \& Training},
  issn = {0040-0912},
  doi = {10.1108/ET-10-2014-0124},
  abstract = {Purpose: The purpose of this paper is to evaluate the experiences of tertiary students learning oral presentation skills in a range of online and blended learning contexts across diverse disciplines. Design/methodology/approach: The research was designed as a "federation" of trials of diverse online oral communications assessment tasks (OOCATs). Tasks were set in ten courses offered across all five faculties at University of Newcastle, Australia. The authors collected and analysed data about students' experiences of tasks they completed through an anonymous online survey. Findings: Students' engagement with the task was extremely positive but also highly varied. This diversity of student experience can inform teaching, and in doing so, can support student equity. By understanding what students think hinders or facilitates their learning, and which students have these experiences, instructors are able to make adjustments to their teaching which address both real and perceived issues. Student experience in this study highlighted five very clear themes in relation to the student experience of undertaking online oral communications tasks which all benefit from nuanced responses by the instructor: relevance; capacity; technology; time; and support. Practical implications: Using well-designed OOCATs that diverge from more traditional written assessments can help students successfully engage with course content and develop oral communication skills. The student experience can be used to inform teaching by catering for different student learning styles and experience. Student centred approaches such as this allows instructors to reflect upon the assumptions they hold about their students and how they learn. This understanding can help inform adjustments to teaching approaches to support improved student experience of learning oral communications tasks. Originality/value: The importance of learning oral communication skills in tertiary education is widely acknowledged internationally, however, there is limited research on how to teach these skills online in a way that is student centred. This research makes a contribution toward addressing that gap.},
  keywords = {Australia,Blended Learning,College Students,Communication Skills,Computer Software,Electronic Learning,Foreign Countries,Higher Education,Learner Engagement,Likert Scales,Postsecondary Education,Speech Communication,Student Experience,Student Surveys,Technology Integration,Visual Aids},
  file = {/Users/colin.madland/Zotero/storage/CSX3LIRE/mcbainStudentExperienceOral2016.pdf}
}

@article{mccallumEffectivenessFormativeAssessment2021,
  title = {The {{Effectiveness}} of {{Formative Assessment}}: {{Student Views}} and {{Staff Reflections}}},
  author = {McCallum, Suzanne and Milner, Margaret M.},
  year = {2021},
  month = jan,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {46},
  number = {1},
  pages = {1--16},
  publisher = {Assessment \& Evaluation in Higher Education},
  issn = {0260-2938},
  doi = {10.1080/02602938.2020.1754761},
  abstract = {This article reports on the implementation of formative e-assessments in courses taken by first-year students. The central aim is to measure the effectiveness of the formative e-assessments with reference to the student voice and staff reflections. Students engaged with the formative assessments and the evidence gathered via questionnaires show that students perceived that formative e-assessments helped them to monitor their progress; encouraged further study and increased their learning and understanding. The findings also allowed academics to reflect on the benefits of adopting formative e-assessments to foster student engagement and permit early intervention. By focussing on the student view (rather than student performance) the findings add to our understanding of the benefits of integrating regular formative assessment in first-year courses.},
  keywords = {Accounting,Business Administration Education,College Faculty,College Freshmen,Computer Assisted Testing,Feedback (Response),Formative Evaluation,Instructional Effectiveness,Integrated Learning Systems,Progress Monitoring,Self Evaluation (Individuals),Statistics Education,Student Attitudes,Teacher Attitudes},
  file = {/Users/colin.madland/Zotero/storage/T3JI3JP3/mccallumEffectivenessFormativeAssessment2021.pdf}
}

@article{mccarthyEnhancingFeedbackHigher2017,
  ids = {mccarthyEnhancingFeedbackHigher2017a},
  title = {Enhancing Feedback in Higher Education: {{Students}}' Attitudes towards Online and in-Class Formative Assessment Feedback Models},
  author = {McCarthy, Josh},
  year = {2017},
  journal = {Active learning in higher education},
  volume = {18},
  number = {2},
  pages = {127--141},
  publisher = {SAGE Publications},
  address = {London, England},
  issn = {1469-7874},
  doi = {10/f99r6r},
  abstract = {This article explores the efficacy of formative assessment feedback models in higher education. Over 1 year and two courses, three feedback techniques were trialled: staff-to-student feedback in class, peer-to-peer feedback in class and peer-to-peer feedback online, via "the Caf{\'e}," an e-learning application hosted by "Facebook." Every 2 weeks, students were required to bring work-in-progress to tutorial classes and discuss their work with their peers and tutors. In alternating weeks, students posted work-in-progress to a forum in "the Caf{\'e}," and critiqued their peers' submissions. The three feedback measures were evaluated by the participating students at the end of each semester, in the form of an online survey, which provided the opportunity to critically reflect on the experience. The results of the student experience are discussed in light of the growing use of online spaces for collaborative learning and peer feedback.;This article explores the efficacy of formative assessment feedback models in higher education. Over 1year and two courses, three feedback techniques were trialled: staff-to-student feedback in class, peer-to-peer feedback in class and peer-to-peer feedback online, via the Cafe, an e-learning application hosted by Facebook. Every 2weeks, students were required to bring work-in-progress to tutorial classes and discuss their work with their peers and tutors. In alternating weeks, students posted work-in-progress to a forum in the Cafe, and critiqued their peers' submissions. The three feedback measures were evaluated by the participating students at the end of each semester, in the form of an online survey, which provided the opportunity to critically reflect on the experience. The results of the student experience are discussed in light of the growing use of online spaces for collaborative learning and peer feedback.;},
  keywords = {Animation,Blended Learning,College Students,Computer Mediated Communication,Cooperative Learning,Criticism,Design,Education & Educational Research,Electronic Learning,Feedback (Response),Foreign Countries,Formative Evaluation,Higher Education,Introductory Courses,Likert Scales,Online Surveys,Peer Evaluation,Social Media,Social Sciences,Statistical Analysis,Student Attitudes,Student Surveys,Teacher Student Relationship,Tutorial Programs}
}

@article{mcclintockPlaceStudyWorld1971,
  title = {Toward a Place for Study in a World of Instruction},
  author = {McClintock, R.},
  year = {1971},
  journal = {Teachers College Record},
  volume = {73},
  number = {2},
  pages = {161--205},
  issn = {0161-4681},
  keywords = {EDUCATION & EDUCATIONAL RESEARCH}
}

@article{mccorkleTechnologyEnhancedPerformanceBasedFeedback2020,
  title = {Technology-{{Enhanced Performance-Based Feedback}} in {{Teacher Preparation}}},
  author = {McCorkle, Laura S. and Coogle, Christan G.},
  year = {2020},
  month = mar,
  journal = {Teacher Educators' Journal},
  volume = {13},
  pages = {105--123},
  publisher = {Teacher Educators' Journal},
  abstract = {Quality supervision of teacher candidates during field placements can be a challenge for many university supervisors, particularly given time required for travel, locating an appropriate setting, and identifying effective ways to support teacher candidates in their implementation of evidence-based practices. One effective way to support teacher candidates in their use of evidence-based practices is technology-enhanced performance-based feedback. University supervisors have a range of knowledge and experience in implementing performance-based feedback and using technology to deliver feedback. The purpose of this article is to describe how university supervisors can deliver technology-enhanced performance-based feedback to support teacher candidates' use of evidence-based practices within authentic education environments. Specifically, we identify different modes of technology, which university supervisors can use to deliver performance-based feedback (e.g., email, text messaging, bug-in-ear, and video-based feedback). Additionally, we include logistical and practical suggestions for university supervisors to consider when implementing technology-enhanced performance-based feedback to support teacher candidates during field placements.},
  keywords = {Electronic Mail,Feedback (Response),No DOI found,Performance Based Assessment,Preservice Teachers,Student Teacher Supervisors,Student Teaching,Synchronous Communication,Teacher Education,Technology,Telecommunications,Video Technology},
  file = {/Users/colin.madland/Zotero/storage/DBHBVLY6/mccorkleTechnologyEnhancedPerformanceBasedFeedback2020.pdf}
}

@article{mccullochMultipleUsesIThenticate2021,
  title = {The Multiple Uses of {{iThenticate}} in Doctoral Education: {{Policing}} Malpractice or Improving Research Writing?},
  shorttitle = {The Multiple Uses of {{iThenticate}} in Doctoral Education},
  author = {McCulloch, Alistair and Behrend, Monica and Braithwaite, Felicity},
  year = {2021},
  month = sep,
  journal = {Australasian Journal of Educational Technology},
  pages = {20--32},
  issn = {1449-5554, 1449-3098},
  doi = {10.14742/ajet.7100},
  urldate = {2023-01-15},
  abstract = {This article provides a description and analysis of the way in which research degree students and their supervisors at one Australian university (the University of South Australia) use a popular online plagiarism-detection system, iThenticate. The study identifies how these two groups use iThenticate by analysing usage data together with data from an anonymous online survey conducted 12 months after the university took out a pilot subscription to the system. One hundred and nineteen students and 26 supervisors responded to the survey, representing 61\% and 43\% of the active users in each category. The survey found that the two groups of respondents used the system differently but that, while for both groups iThenticate's regulatory function in preventing plagiarism (whether international or accidental) was important, the system's potential educational function in improving research writing capability and publication was equally important. The study highlights the value of regarding the use of anti-plagiarism software so as to encourage a move way from a simple focus on its punitive regulatory dimension and towards its educational possibilities and suggests directions for future research on the relationship between this type of software and the ways scholars work with other people's texts to recreate meanings and develop original contributions.  Implications for practice or policy:    Online plagiarism detection systems (such as iThenticate) can be used either negatively to police doctoral students' practice or positively to improve their research writing practice.  Academic developers should promote a positive approach, aimed at improving research writing practice, as the preferable pedagogy in using online plagiarism-detection systems.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/QWCNEL2E/mccullochMultipleUsesIThenticate2021.pdf}
}

@article{mccuneExperiencedAcademicsPedagogical2018,
  title = {Experienced Academics' Pedagogical Development in Higher Education: Time, Technologies, and Conversations},
  author = {McCune, Velda},
  year = {2018},
  journal = {Oxford review of education},
  volume = {44},
  number = {3},
  pages = {307--321},
  publisher = {Taylor \& Francis},
  address = {ABINGDON},
  issn = {0305-4985},
  doi = {10.1080/03054985.2017.1389712},
  abstract = {This paper focuses on extending our limited understanding of how the teaching and assessment practices of experienced academics develop. The development of academics as teachers is increasingly seen as a key focus but much of the research in this area has focused on formal educational development initiatives. The analysis presented here investigates how experienced academics describe what has shaped their emerging pedagogical practices over time. The emphasis is on participants' informal experiences. Three foci were identified as the most important for these participants' developing practice: the choices participants made about using time in pressured contexts; the interplay between digital technologies and participants' practice; and the conversations which participants had about their teaching and assessment. The implications presented for future research and development work emphasise influencing the institutional policy context and the value of working creatively with the complexities of emerging academic practices.},
  keywords = {Academic staff,College Faculty,Discussion,Education & Educational Research,Educational Technology,Faculty Development,Foreign Countries,Higher Education,Pedagogy,R&D,Research & development,Semi Structured Interviews,Social Sciences,Teacher Competencies,Teacher Role,Teachers,Teaching,Teaching Methods,Teaching Skills,Technology Uses in Education,Time Management},
  file = {/Users/colin.madland/Zotero/storage/R2Q2ZNAD/mccuneExperiencedAcademicsPedagogical2018.pdf}
}

@book{mccutcheonLatentClassAnalysis1987,
  title = {Latent {{Class Analysis}}},
  author = {McCutcheon, Allan},
  year = {1987},
  publisher = {SAGE Publications, Inc.},
  address = {2455 Teller Road,~Thousand Oaks~California~91320~United States of America},
  doi = {10.4135/9781412984713},
  urldate = {2021-06-12},
  isbn = {978-0-8039-2752-0 978-1-4129-8471-3},
  file = {/Users/colin.madland/Zotero/storage/TDB9E5MD/mccutcheonLatentClassAnalysis1987.pdf}
}

@article{mcdowellAsynchronousOnlineAssessment2020,
  title = {Asynchronous {{Online Assessment}} of {{Physical Chemistry Concepts}} in the {{Time}} of {{COVID-19}}},
  author = {McDowell, Sean A. C},
  year = {2020},
  journal = {Journal of chemical education},
  volume = {97},
  number = {9},
  pages = {3256--3259},
  publisher = {{American Chemical Society and Division of Chemical Education, Inc}},
  address = {WASHINGTON},
  issn = {0021-9584},
  doi = {10.1021/acs.jchemed.0c00611},
  abstract = {The COVID-19 pandemic caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has disrupted normal activities all over the world. Education at all levels has been particularly hard hit, and this has resulted in the suspension of face-to-face discourse, instruction, and student assessment worldwide, with the necessity of social distancing preventing the social gatherings common to all learning environments. This has prompted a shift to online modes of teaching and assessment, with varying degrees of success and possibly much discomfort. In this communication, reflections and comments on the results of asynchronous online assessment of physical chemistry courses at the Cave Hill campus of the University of the West Indies are presented. We hope this paper will be useful in delineating some of the challenges faced in the delivery of unsupervised online assessments, especially in situations where limited internet connectivity may disadvantage some students.},
  keywords = {Asynchronous Communication,CAI,Chemistry,Chemistry Multidisciplinary,Colleges & universities,Computer assisted instruction,Computer Assisted Testing,COVID-19,Disease control,Distance Education,Education & Educational Research,Education Scientific Disciplines,Electronic Learning,Foreign Countries,Internet,Learning environment,Pandemics,Physical chemistry,Physical Sciences,Science & Technology,Scientific Concepts,Severe acute respiratory syndrome,Severe acute respiratory syndrome coronavirus 2,Social Sciences,Viral diseases}
}

@article{mcglashanhaleyLGBTQYouthActivism2017,
  title = {{{LGBTQ}} Youth Activism and School: Challenging Sexuality and Gender Norms},
  author = {{McGlashan, Haley} and Fitzpatrick, Katie},
  year = {2017},
  journal = {Health Education},
  volume = {117},
  number = {5},
  pages = {485--497},
  urldate = {2018-09-30},
  abstract = {Purpose -- Previous research examining the experiences of lesbian, gay, bisexual, trans and queer (LGBTQ) youth in schools suggests that schools are not inclusive places for non-heterosexual students. Some scholars, however, suggest that a continued focus on how these young people are marginalised is itself a problem, and that research should also focus on strengths and what is working. The purpose of this paper is to examine the activities of a group of LGBTQ students in one school in Auckland, New Zealand. Design/methodology/approach -- The study employed a critical ethnographic approach in a diverse co-educational, public high school in Auckland, New Zealand. The researcher spent 3-5 days per week at the school throughout three terms (32 weeks) of the 2016 school year and participated, observed and interviewed students and teachers. Post-structural theory was used to analyse the ethnographic materials. Findings -- The study found that LGBTQ students actively challenged the heteronorms of their school. They met regularly to discuss issues, support each other and to plan activist initiatives. These initiatives, in turn, impacted the environment of the school and made LGBTQ students more visible. This visibility, however, also created tensions as students grappled with their identities and the public space of school. Originality/value -- Despite a wealth of research in education on the exclusion of young people at the intersection of gender, sexuality and other identity positions, there is very little research that reports on school-wide health promotion initiatives that both engage young people as leaders and participants in their schools, and work towards creating safe and empowering spaces for LGBTQ youth.},
  langid = {english}
}

@article{mcgranahanWhatEthnographyTeaching2015,
  title = {What Is {{Ethnography}}? {{Teaching}} Ethnographic Sensibilities without Fieldwork},
  author = {McGranahan, Carole},
  year = {2015},
  journal = {Teaching Anthropology; Vol 4 (2014): Learning by example},
  doi = {10.22582/ta.v4i1.421},
  abstract = {How do we teach undergraduate students to think ethnographically, to recognize something as ethnographic and not just as qualitative? Importantly, how do we do so not in the field, where students might learn by doing their own research, but in the static classroom? One approach is to have students cultivate a concept, awareness, and practice of an ethnographic sensibility, that is, of a sense of the ethnographic as the lived expectations, complexities, contradictions, possibilities, and ground of any given cultural group. Such a view opens up an understanding of ethnography and ethnographic research as more than available qualitative methods. Instead, it takes an ethnographic approach to be an epistemological one. Yet, how might we do this? In this article, I discuss my pedagogical strategies for teaching students an ethnographic sensibility without having them conduct fieldwork. I argue that it is both possible and valuable to generate an ethnographic sensibility in the classroom.},
  keywords = {fieldwork ethnography classroom,sensibility}
}

@article{mcgrathPeerAssessmentIrish2020,
  title = {Peer {{Assessment}} in {{Irish Medical Science Education}}: {{Exploring Staff Assessment Literacy}} and {{Assessment Practice}}},
  author = {McGrath, Mary F. and Scott, Lloyd and Logue, Pauline},
  year = {2020},
  journal = {Practitioner Research in Higher Education},
  volume = {13},
  number = {1},
  pages = {37--56},
  issn = {EISSN-1755-1382},
  abstract = {The approach to, and the type of, assessment(s) that a Higher Education (HE) programme employs can be key factors in the effectiveness of assessment as a tool of learning. Peer assessment (PA) has the potential to develop the evaluative competence of students in HE. In the Republic of Ireland (RoI) there are three Institutes that each deliver a professionally validated honours degree programme in Medical/Biomedical Science. The aim of this paper is to report on the experiences and views of the academic staff involved in these three programmes with respect to assessment. Presented here is one aspect of a larger study into assessment practices in the education of Irish Medical Scientists with the overall aim being the development of a framework for the structured inclusion of PA. An insight into the current practices, experiences and views of staff is an essential step in the development of an effective framework. All academic staff (n=80) involved in the three programmes were invited to complete an online anonymous survey. Employing a mixed methods design, the survey incorporated closed questions e.g. subject area, years of experience and formal teaching qualifications, and open questions including staff's understanding of the terminology of assessment, if they use PA, their reasons for choosing PA and any challenges they may have encountered. Thirty-five staff responded to the survey; all three institutes were represented. The thematic analysis of the qualitative data demonstrated that staff generally see assessment as a 'measure' (grade or mark) of understanding and knowledge. The distinction between formative and summative assessment was not clear for all staff; 19/33 staff described summative assessment as an 'end of module' exam and 13/33 staff referred to formative assessment as being 'continuous' or 'ongoing'. There was clear evidence of a lack of use of terms associated with assessment; such as 'assessment as, of and for learning'. Eleven of the respondents use PA in their module(s), they reported the positives and challenges of PA as they experienced e.g. increased student engagement, importance of student preparation. The results of this study confirm the need for, and provides a justification of, building a best practice framework for PA in HE Medical Science education in RoI.},
  langid = {english},
  keywords = {Assessment Literacy,Biomedicine,College Faculty,Definitions,Foreign Countries,Formative Evaluation,Medical Education,No DOI found,Peer Evaluation,Summative Evaluation,Teacher Attitudes,Undergraduate Study,Vocabulary}
}

@article{mcgregorReciprocityIndigenousEducational2018,
  title = {Reciprocity in {{Indigenous Educational Research}}: {{Beyond Compensation}}, {{Towards Decolonizing}}},
  author = {McGregor, Heather E. and Marker, Michael},
  year = {2018},
  journal = {Anthropology \& Education Quarterly},
  volume = {49},
  number = {3},
  pages = {318--328},
  issn = {0161-7761},
  doi = {10.1111/aeq.12249},
  abstract = {With questions about what it means to conduct educational research in Indigenous contexts based on reciprocal relationships, we review key contributions to the literature from Indigenous and qualitative methodologists. We identify four dimensions of reciprocity, extending the notion of reciprocity as transaction or compensation. To design research that fulfills decolonizing commitments, we find resonance with the conceptualization of reciprocity as a ``stance'' (Trainor and Bouchard ), rather than being achieved through any particular method.;With questions about what it means to conduct educational research in Indigenous contexts based on reciprocal relationships, we review key contributions to the literature from Indigenous and qualitative methodologists. We identify four dimensions of reciprocity, extending the notion of reciprocity as transaction or compensation. To design research that fulfills decolonizing commitments, we find resonance with the conceptualization of reciprocity as a "stance" (Trainor and Bouchard [Trainor, Audrey, 2013]), rather than being achieved through any particular method.;},
  keywords = {ANTHROPOLOGY,Compensation,Decolonizing,Education,EDUCATION & EDUCATIONAL RESEARCH,Educational Research,Foreign Policy,Indigenous education,Indigenous Populations,Interpersonal Relationship,Native education,Qualitative Research,reciprocity,Research Design,research methodologies}
}

@article{mcguireAssessmentUsingNew2005,
  title = {Assessment Using New Technology: {{New}} Technology, Learning and Assessment in Higher Education},
  author = {McGuire, Lesley},
  year = {2005},
  journal = {Innovations in education and teaching international},
  volume = {42},
  number = {3},
  pages = {265--276},
  publisher = {Taylor \& Francis},
  address = {London},
  issn = {1470-3297},
  doi = {10.1080/01587910500168025},
  keywords = {Distance teaching,Educational sciences,Teaching aids},
  file = {/Users/colin.madland/Zotero/storage/CNCUAHGA/mcguireAssessmentUsingNew2005.pdf}
}

@incollection{mcinnisAssessmentChangeHigher2006,
  title = {Assessment and Change in Higher Education},
  booktitle = {The {{Realities}} of {{Change}} in {{Higher Education}}: {{Interventions}} to {{Promote Learning}} and {{Teaching}}},
  author = {Mcinnis, Craig},
  editor = {Bromage, Adrian and Hunt, Lynne and Tomkinson, Bland},
  year = {2006},
  publisher = {Taylor \& Francis Group},
  address = {Florence, UNITED STATES},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/7G7W2G4V/mcinnisAssessmentChangeHigher2006.pdf}
}

@article{mckeeProfessionalDevelopmentFaculty2013,
  title = {Professional {{Development}} of the {{Faculty}}: {{Past}} and {{Present}}},
  author = {McKee, C. William and Johnson, Mitzy and Ritchie, William F. and Tew, W. Mark},
  year = {2013},
  journal = {New Directions for Teaching and Learning},
  volume = {2013},
  number = {133},
  pages = {15--20}
}

@article{mckennaNeoliberalismConditioningEffects2022,
  title = {Neoliberalism's Conditioning Effects on the University and the Example of Proctoring during {{COVID-19}} and Since},
  author = {McKenna, Sioux},
  year = {2022},
  month = jul,
  journal = {Journal of Critical Realism},
  pages = {1--14},
  issn = {1476-7430, 1572-5138},
  doi = {10.1080/14767430.2022.2100612},
  urldate = {2022-08-14},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/92U28WKM/mckennaNeoliberalismConditioningEffects2022.pdf}
}

@article{mckenzieUsingPeerWiseDevelop2017,
  ids = {mckenzieUsingPeerWiseDevelop2017a},
  title = {Using {{PeerWise}} to Develop a Contributing Student Pedagogy for Postgraduate Psychology},
  author = {McKenzie, Wendy and Roodenburg, John},
  year = {2017},
  journal = {Australasian Journal Of Educational Technology},
  volume = {33},
  number = {1},
  pages = {32--47},
  publisher = {Australasian Soc Computers Learning Tertiary Education-Ascilite},
  address = {TUGUN},
  issn = {1449-5554},
  doi = {10.14742/ajet.3169},
  abstract = {The importance of the role of peer and self-assessment in developing formative and sustainable assessment practice in higher education is increasingly becoming evident. PeerWise is an online software tool that engages students in contributing to their own and others' learning by authoring, answering and providing feedback on multiple choice questions. Using a mixed methods approach, 20 students responded to discussion questions and an online survey about their perceptions of using PeerWise compared to online quizzes as part of the blended delivery of a postgraduate psychology unit. Students considered both authoring and answering questions in PeerWise to equally benefit their learning. Answering questions in PeerWise was perceived to be more helpful for learning than questions on a Moodle quiz. This advantage was evident across more complex cognitive skills, understanding, applying, evaluating and creating information, although only significant for facilitating understanding. PeerWise and online quizzes were seen to be equally helpful in facilitating recall. Despite the perceived benefits of PeerWise, students preferred quiz questions to be set by an expert if used as recognition of progress. Introducing PeerWise was effective in promoting engagement with peers; however, refinements to the model should focus on increasing student confidence in their own and peers' capabilities. [Author abstract]},
  keywords = {Blended Learning,Comparative Analysis,Computer Assisted Testing,Computer Software,Confidence,Education & Educational Research,Evaluation methods,Feedback,Feedback (Response),Foreign Countries,Formative evaluation,Graduate Students,Graduate study,Higher education,Internet,Likert Scales,Management Systems,Mixed Methods Research,Monash University,Moodle (Learning management system),Multimethod techniques,Multiple Choice Tests,Online education,Online learning,Online Surveys,Online teaching,Peer Evaluation,Peer Relationship,PeerWise (Computer program),Postsecondary education,Psychology,Psychology education,Recall (Psychology),Self Efficacy,Self evaluation (Individuals),Social Sciences,Student assessment,Student Attitudes,Summative Evaluation,Surveys,Teaching Methods,Units of Study,University students},
  file = {/Users/colin.madland/Zotero/storage/RBYQFF42/mckenzieUsingPeerWiseDevelop2017.pdf}
}

@article{mckimValueMixedMethods2017,
  title = {The {{Value}} of {{Mixed Methods Research}}: {{A Mixed Methods Study}}},
  shorttitle = {The {{Value}} of {{Mixed Methods Research}}},
  author = {McKim, Courtney A.},
  year = {2017},
  month = apr,
  journal = {Journal of Mixed Methods Research},
  volume = {11},
  number = {2},
  pages = {202--222},
  issn = {1558-6898, 1558-6901},
  doi = {10/f952f7},
  urldate = {2021-07-26},
  abstract = {The purpose of this explanatory mixed methods study was to examine the perceived value of mixed methods research for graduate students. The quantitative phase was an experiment examining the effect of a passage's methodology on students' perceived value. Results indicated students scored the mixed methods passage as more valuable than those who scored the quantitative or qualitative passage. The qualitative phase involved focus groups to better understand students' perceptions of the perceived value of mixed methods. Findings suggested graduate students view mixed methods passages as having rigorous methods, a newer history, and providing a deeper meaning of the phenomenon. This study adds to the literature base by revealing what value graduate students assign to quantitative, qualitative, and mixed methods research.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/VDURH5FT/mckimValueMixedMethods2017.pdf}
}

@book{mckinleyHandbookIndigenousEducation2019,
  title = {Handbook of {{Indigenous Education}}},
  editor = {McKinley, Elizabeth Ann and Smith, Linda Tuhiwai},
  year = {2019},
  publisher = {Springer Singapore},
  address = {Singapore},
  doi = {10.1007/978-981-10-3899-0},
  urldate = {2024-07-20},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-981-10-3898-3 978-981-10-3899-0},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/T2FW2FYF/mckinleyHandbookIndigenousEducation2019.pdf}
}

@article{mckinneyReassessingIntersectionalityAffirming2018,
  title = {Reassessing {{Intersectionality}}: {{Affirming Difference}} in {{Higher Education}}},
  author = {McKinney, Charlesia},
  year = {2018},
  journal = {Composition Forum},
  volume = {39},
  issn = {ISSN-1522-7502},
  abstract = {This essay offers a review of Jay Dolmage's "Academic Ableism: Disability and Higher Education" and Asao Inoue's "Antiracist Writing Assessment Ecologies: Teaching and Assessing Writing for a Socially Just Future" with the intent of reminding composition instructors of the importance of intersectionality and accessibility. Each text encourages us to challenge traditional perceptions of success and failure thereby also interrogating imbalanced power dynamics between instructors and students particularly in regards to writing assessment and other pedagogical priorities. Finding ways to acknowledge difference, and affirm it, is vital to our collective success especially in the writing classroom.},
  langid = {english},
  keywords = {Access to Education,Attitudes toward Disabilities,Disabilities,Disproportionate Representation,Equal Education,Higher Education,No DOI found,Racial Bias,Social Change,Social Justice,Writing (Composition),Writing Instruction}
}

@article{mclaughlinFacilitatingTeamProjects2016,
  title = {Facilitating {{Team Projects}} in the {{Online Classroom}}: {{Enhancing Student Team Effectiveness}}.},
  author = {McLaughlin, Erin B. and Daspit, Joshua J.},
  year = {2016},
  journal = {Business Education Innovation Journal},
  volume = {8},
  pages = {110--113},
  issn = {19450915},
  doi = {Article},
  abstract = {This paper aims to discuss a best practices exercise for facilitating team projects in the online classroom and enhancing the internal environment of the team-building process. The implications are particularly valuable to enhancing the effectiveness of team-based projects. The paper includes a brief overview of the significance of using team-based projects in the classroom, a description of the exercise, and a discussion of the experiences from professors currently using the activity. [ABSTRACT FROM AUTHOR] Copyright of Business Education Innovation Journal is the property of Elm Street Press and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
  keywords = {Classroom activities,Cohesion,Effective teaching,Group work in education,Internal team environment,Online classroom,Online education,Project method in teaching,Shared leadership,Student projects,Team building process,Team effectiveness,Team projects,Virtual team,Web-based instruction},
  file = {/Users/colin.madland/Zotero/storage/5IBQAXXX/mclaughlinFacilitatingTeamProjects2016.pdf}
}

@phdthesis{mcmahonDigitalSelfdeterminationAboriginal2013,
  type = {Thesis},
  title = {Digital Self-Determination: {{Aboriginal}} Peoples and the Network Society in {{Canada}}},
  shorttitle = {Digital Self-Determination},
  author = {McMahon, Rob},
  year = {2013},
  month = may,
  urldate = {2019-06-13},
  langid = {english},
  school = {Communication, Art \& Technology: School of Communication},
  file = {/Users/colin.madland/Zotero/storage/UFJLLRXT/mcmahonDigitalSelfdeterminationAboriginal2013.pdf;/Users/colin.madland/Zotero/storage/2BDRV7AR/13532.html}
}

@book{mcmillanSAGEHandbookResearch2020,
  title = {{{SAGE Handbook}} of {{Research}} on {{Classroom Assessment}}},
  author = {McMillan, James},
  year = {2020},
  address = {Thousand Oaks, California},
  doi = {10.4135/9781452218649}
}

@article{mcmillanUnderstandingImprovingTeachers2005,
  title = {Understanding and {{Improving Teachers}}' {{Classroom Assessment Decision Making}}: {{Implications}} for {{Theory}} and {{Practice}}},
  shorttitle = {Understanding and {{Improving Teachers}}' {{Classroom Assessment Decision Making}}},
  author = {McMillan, James H.},
  year = {2005},
  month = oct,
  journal = {Educational Measurement: Issues and Practice},
  volume = {22},
  number = {4},
  pages = {34--43},
  issn = {07311745, 17453992},
  doi = {10/d26nxv},
  urldate = {2020-09-30},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/YLUQLUNY/mcmillanUnderstandingImprovingTeachers2005.pdf}
}

@article{mcmorranAssessmentLearningGrades2017,
  title = {Assessment and Learning without Grades? {{Motivations}} and Concerns with Implementing Gradeless Learning in Higher Education},
  shorttitle = {Assessment and Learning without Grades?},
  author = {McMorran, Chris and Ragupathi, Kiruthika and Luo, Simei},
  year = {2017},
  month = apr,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {42},
  number = {3},
  pages = {361--377},
  issn = {0260-2938, 1469-297X},
  doi = {10/gcphr9},
  urldate = {2020-10-30},
  langid = {english}
}

@article{mcnuttTransparencyAuthorsContributions2018,
  title = {Transparency in Authors' Contributions and Responsibilities to Promote Integrity in Scientific Publication},
  author = {McNutt, Marcia K. and Bradford, Monica and Drazen, Jeffrey M. and Hanson, Brooks and Howard, Bob and Jamieson, Kathleen Hall and Kiermer, V{\'e}ronique and Marcus, Emilie and Pope, Barbara Kline and Schekman, Randy and Swaminathan, Sowmya and Stang, Peter J. and Verma, Inder M.},
  year = {2018},
  month = mar,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {115},
  number = {11},
  pages = {2557--2560},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1715374115},
  urldate = {2023-11-10},
  abstract = {In keeping with the growing movement in scientific publishing toward transparency in data and methods, we propose changes to journal authorship policies and procedures to provide insight into which author is responsible for which contributions, better assurance that the list is complete, and clearly articulated standards to justify earning authorship credit. To accomplish these goals, we recommend that journals adopt common and transparent standards for authorship, outline responsibilities for corresponding authors, adopt the Contributor Roles Taxonomy (CRediT) (               docs.casrai.org/CRediT               ) methodology for attributing contributions, include this information in article metadata, and require authors to use the ORCID persistent digital identifier (               https://orcid.org               ). Additionally, we recommend that universities and research institutions articulate expectations about author roles and responsibilities to provide a point of common understanding for discussion of authorship across research teams. Furthermore, we propose that funding agencies adopt the ORCID identifier and accept the CRediT taxonomy. We encourage scientific societies to further authorship transparency by signing on to these recommendations and promoting them through their meetings and publications programs.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/AT99FPQT/mcnuttTransparencyAuthorsContributions2018.pdf}
}

@misc{mcvicarTwitterAlgorithmRevision2020,
  title = {Twitter Algorithm under Revision for Alleged ``Racial Bias''},
  author = {McVicar, Alba},
  year = {2020},
  month = sep,
  journal = {Brig Newspaper},
  urldate = {2020-09-22},
  abstract = {Twitter's image-previewing algorithm under revision for alleged ``racial bias''},
  howpublished = {https://brignews.com/2020/09/22/twitter-algorithm-racial/},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/DJ5VKJSI/twitter-algorithm-racial.html}
}

@article{meccawyAssessmentSurvivalMode2021,
  ids = {meccawyAssessmentSurvivalMode2021a},
  title = {Assessment in `Survival Mode': Student and Faculty Perceptions of Online Assessment Practices in {{HE}} during {{Covid-19}} Pandemic},
  author = {Meccawy, Zilal and Meccawy, Maram and Alsobhi, Aisha},
  year = {2021},
  journal = {International journal for educational integrity},
  volume = {17},
  number = {1},
  pages = {1--24},
  publisher = {Springer Singapore},
  address = {Singapore},
  issn = {1833-2595},
  doi = {10.1007/s40979-021-00083-9},
  abstract = {This paper presents a cross-sectional study that demonstrates how King Abdulaziz University has responded to the lockdown imposed by the Ministry of Education in Saudi Arabia due to the Covid-19 pandemic. The purpose of this study was to examine the perceptions of students and faculty towards assessment that had to take place online due to physical or social distancing rules and lockdowns. A descriptive mixed-method study was conducted with two different self-administered questionnaires that were developed for students and faculty, respectively. A total of 547 responses were received from undergraduate students and 213 from faculty. The main finding suggests the need for a multilevel approach to the problems of cheating and plagiarism, including raising student awareness and ethics, training teachers to detect cheating methods, and institutions activating their code of practice and applying severe sanctions on those who engage in such practices.},
  keywords = {Academic integrity,Blackboard,Cheating,College Students,Computer Assisted Testing,Coronaviruses,COVID-19,Covid-19 pandemic,Distance learning,E-learning,Education,Education & Educational Research,Educational evaluation,Ethics,Foreign Countries,Higher Education,Integrity in an Emergency: Pandemics,International and Comparative Education,Natural Disasters and Other Extreme Conditions,Online assessment,Online instruction,Original,Original Article,Pandemics,Plagiarism,Social Sciences,Student Attitudes,Student Evaluation,Teacher Attitudes},
  file = {/Users/colin.madland/Zotero/storage/KBWFUULG/meccawyAssessmentSurvivalMode2021.pdf}
}

@article{medeirosSystematicLiteratureReview2019,
  title = {A {{Systematic Literature Review}} on {{Teaching}} and {{Learning Introductory Programming}} in {{Higher Education}}},
  author = {Medeiros, Rodrigo Pessoa and Ramalho, Geber Lisboa and Falcao, Taciana Pontual},
  year = {2019},
  journal = {IEEE transactions on education},
  volume = {62},
  number = {2},
  pages = {77--90},
  publisher = {IEEE},
  address = {PISCATAWAY},
  issn = {0018-9359},
  doi = {10.1109/TE.2018.2864133},
  abstract = {Contribution: This paper adds to the results of previous systematic literature reviews by addressing a more contemporary context of introductory programming. It proposes a categorization of introductory programming challenges, and highlights key issues for a research roadmap on introductory programming learning and teaching in higher education. Background: Despite the advances in methods and tools for teaching and learning introductory programming, dropout and failure rates are still high. Published surveys and reviews either cover papers only up to 2007, or focus on methods and tools for teaching introductory programming. Research Questions: 1) What previous skills and background knowledge are key for a novice student to learn programming? 2) What difficulties do novice students encounter in learning how to program? 3) What challenges do teachers encounter in teaching introductory programming? Methodology: Following a formal protocol, automatic and manual searches were performed for work from 2010 to 2016. Of 100 papers selected for data extraction, 89 were retained after quality assessment. Findings: The most frequently cited skills necessary for learning programming were related to problem solving and mathematical ability. Problem solving was also cited as a learning challenge, followed by motivation and engagement, and difficulties in learning the syntax of programming languages. The main teaching challenges concern the lack of appropriate methods and tools, as well as scaling and personalized teaching.},
  keywords = {Achievement,Barriers,Bibliographies,College Faculty,College Instruction,Computer Science Education,Education,Education & Educational Research,Education Scientific Disciplines,Engineering,Engineering Electrical & Electronic,faculty development,Failure rates,Higher Education,Introductory Courses,introductory programming,Learning,Literature reviews,Manuals,Motivation,Prior Learning,Problem solving,Programming,Programming languages,Programming profession,Quality assessment,Science & Technology,Skills,Social Sciences,STEM,student experience,systematic review,Systematics,Teaching,Teaching methods,Technology}
}

@article{medlandAssessmentIlliterateShared2019,
  title = {`{{I}}'m an Assessment Illiterate': Towards a Shared Discourse of Assessment Literacy for External Examiners},
  shorttitle = {`{{I}}'m an Assessment Illiterate'},
  author = {Medland, Emma},
  year = {2019},
  month = may,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {44},
  number = {4},
  pages = {565--580},
  issn = {0260-2938, 1469-297X},
  doi = {10/gj47j3},
  urldate = {2021-07-10},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/B2VJ4G4J/medlandAssessmentIlliterateShared2019.pdf}
}

@article{medlandExaminingAssessmentLiteracy2015,
  title = {Examining the Assessment Literacy of External Examiners},
  author = {Medland, Emma},
  year = {2015},
  month = dec,
  journal = {London Review of Education},
  issn = {1474-8460},
  doi = {10/gk5sph},
  urldate = {2021-07-10},
  abstract = {External scrutiny of higher education courses is evident globally, but the use of an external examiner from another institution for the purposes of quality assurance has been a distinguishing feature of UK higher education since the 1830s. However, the changing higher education context  has led to mounting criticism of the system and the identification of a number of largely unchallenged assumptions underpinning it. One such assumption is that external examiners are assessment literate. This study evaluates levels of assessment literacy demonstrated within the written reports  of external examiners. Findings indicate variable levels of assessment literacy and identify aspects of the concept that require attention. Wider questions concerning the conceptualization and future development of the external examining system are considered.},
  file = {/Users/colin.madland/Zotero/storage/VZTM9HPM/medlandExaminingAssessmentLiteracy2015.pdf}
}

@incollection{mehanSociologicalPerspectiveOpportunity2008,
  title = {A {{Sociological Perspective}} on {{Opportunity}} to {{Learn}} and {{Assessment}}},
  booktitle = {Assessment, {{Equity}}, and {{Opportunity}} to {{Learn}}},
  author = {Mehan, Hugh},
  editor = {Pullin, Diana C. and Haertel, Edward H. and Gee, James Paul and Young, Lauren Jones and Moss, Pamela A.},
  year = {2008},
  series = {Learning in {{Doing}}: {{Social}}, {{Cognitive}} and {{Computational Perspectives}}},
  pages = {42--75},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9780511802157.005},
  abstract = {OVERVIEWThis chapter reviews the major conceptions of opportunities to learn and assessment within the discipline of sociology. The traditional view of schooling as a meritocratic sorting device is contrasted with (1) the view of schooling that asserts schools (either wittingly or unwittingly) serve to reproduce the existing hierarchies of privilege; (2) the point of view that proposes that schools, peers, and families mediate the relations between structural constraints and human action; and (3) a resurgent democratic conception of schooling.In contrast to the meritocratic conception of opportunity to learn (OTL) and assessment that asserts schools provide students with avenues to compete as individuals for valued resources, I present evidence that questions whether students have equal access to valued educational and cultural resources. This leads to defining OTL in terms of establishing the conditions within schools for the open flow of ideas and solving problems that are connected to the ``real world.'' Multiple measures of students' academic performance -- especially those such as portfolios and exhibitions -- that assess learning in authentic contexts (see Gee, this volume, and Mislevy, this volume) are preferred over standardized tests as assessment tools.},
  isbn = {978-0-521-88045-9}
}

@article{mehrabiboshrabadiDesigningCollaborativeProblem2020,
  title = {Designing Collaborative Problem Solving Assessment Tasks in Engineering: An Evaluative Judgement Perspective},
  shorttitle = {Designing Collaborative Problem Solving Assessment Tasks in Engineering},
  author = {Mehrabi Boshrabadi, Abbas and Hosseini, M. Reza},
  year = {2020},
  month = oct,
  journal = {Assessment \& Evaluation in Higher Education},
  pages = {1--15},
  issn = {0260-2938, 1469-297X},
  doi = {10/ghg5m8},
  urldate = {2020-10-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/HEG4URMG/mehrabiboshrabadiDesigningCollaborativeProblem2020.pdf}
}

@misc{mehtaWhyTwitterImage2020,
  title = {Why {{Twitter}}'s Image Cropping Algorithm Appears to Have White Bias},
  author = {Mehta, Ivan},
  year = {2020},
  month = sep,
  journal = {Neural {\textbar} The Next Web},
  urldate = {2020-09-22},
  abstract = {Twitter`s algorithm for automatically cropping images attached to tweets often doesn't focus on the important content in them. A bother, for sure, but it seems like a minor one on the surface. However, over the weekend, researchers found that the cropping algorithm might have a more serious problem: white bias. Several users posted a lot [{\dots}]},
  howpublished = {https://thenextweb.com/neural/2020/09/21/why-twitters-image-cropping-algorithm-appears-to-have-white-bias/},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/PHQNAKCG/why-twitters-image-cropping-algorithm-appears-to-have-white-bias.html}
}

@article{meijerUnfoldingCollaborativeLearning2020,
  ids = {meijerUnfoldingCollaborativeLearning2020a},
  title = {Unfolding Collaborative Learning Assessment Literacy: A Reflection on Current Assessment Methods in Higher Education},
  author = {Meijer, Hajo and Hoekstra, Rink and Brouwer, Jasperina and Strijbos, Jan-Willem},
  year = {2020},
  journal = {Assessment and evaluation in higher education},
  volume = {45},
  number = {8},
  pages = {1222--1240},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0260-2938},
  doi = {10/ghn5nc},
  abstract = {Over the past two decades, curricula in higher education have increasingly incorporated collaborative learning. However, due to (a) large variations in students' domain-specific abilities (e.g. knowledge and/or skills) and the effort they invest into the collaboration and (b) teachers' limited knowledge about how to assess collaborative learning, two main challenges arise. The first challenge concerns ensuring construct validity of the assessment methods, that is, whether an assessment accurately measures students' domain-specific abilities. The second challenge originates from the potential of assessment methods to elicit student behaviour that is misaligned with the objectives of collaborative learning (e.g. free-riding behaviour). This paper aims to enhance teachers', researchers', and students' awareness for and need to develop what we refer to as 'collaborative learning assessment literacy'. In particular, we will discuss the two challenges in relation to three frequently used and discussed methods for assessing collaborative learning - group assessment, individual assessment, and group assessment combined with intra-group peer assessment - with specific attention to the purpose of assessment (i.e. formative and summative). Implications of the two challenges as well as their relation to other core components in the design of any collaborative learning setting (e.g. group constellation) will be discussed.},
  keywords = {assessment literacy,Collaborative learning,Construct Validity,Cooperative Learning,Education & Educational Research,Educational evaluation,Evaluation Methods,Formative Evaluation,Group Behavior,Group Dynamics,group work,higher education,Literacy,Reflection,Social Sciences,Student Evaluation,Student teacher relationship,Summative Evaluation},
  file = {/Users/colin.madland/Zotero/storage/JE3TPVVP/meijerUnfoldingCollaborativeLearning2020.pdf}
}

@misc{meinkeSigningStudentsSurveillance2018,
  title = {Signing {{Students}} up for {{Surveillance}}: {{Textbook Publisher Terms}} of {{Use}} for {{Data}}},
  shorttitle = {Signing {{Students}} up for {{Surveillance}}},
  author = {Meinke, Billy},
  year = {2018},
  month = mar,
  journal = {Medium},
  urldate = {2018-10-08},
  abstract = {This is a second post focusing on surveillance capitalism and how textbook publishers are collecting mass amounts of information about our{\dots}},
  file = {/Users/colin.madland/Zotero/storage/6NRM3KWB/signing-students-up-for-surveillance-textbook-publisher-terms-of-use-for-data-24514fb7dbe4.html}
}

@article{mellarAddressingCheatingEassessment2018,
  ids = {mellarAddressingCheatingEassessment2018a},
  title = {Addressing Cheating in E-Assessment Using Student Authentication and Authorship Checking Systems: Teachers' Perspectives},
  author = {Mellar, Harvey and {Peytcheva-Forsyth}, Roumiana and Kocdar, Serpil and Karadeniz, Abdulkadir and Yovkova, Blagovesna},
  year = {2018},
  journal = {International journal for educational integrity},
  volume = {14},
  number = {1},
  pages = {1--21},
  publisher = {Springer Singapore},
  address = {Singapore},
  issn = {1833-2595},
  doi = {10.1007/s40979-018-0025-x},
  abstract = {Student authentication and authorship checking systems are intended to help teachers address cheating and plagiarism. This study set out to investigate higher education teachers' perceptions of the prevalence and types of cheating in their courses with a focus on the possible changes that might come about as a result of an increased use of e-assessment, ways of addressing cheating, and how the use of student authentication and authorship checking systems might impact on assessment practice. This study was carried out within the context of the project TeSLA (an Adaptive Trust-based e-assessment System for Learning) which is developing a system intended for integration within an institution's Virtual Learning Environment (VLE) offering a variety of instruments to assure student authentication and authorship checking. Data was collected at two universities that were trialling the TeSLA system, one in Turkey, where the main modes of teaching are face-to-face teaching and distance education, and one in Bulgaria, where the main modes of teaching are face-to-face teaching and blended learning. The study used questionnaires and interviews, building on existing TeSLA project evaluation activities and extending these to explore the specific areas we wished to examine in more depth. In three of the four contexts cheating was seen by teachers as a serious and growing problem, the exception was the distance education context where the teachers believed that the existing procedures were effective in controlling cheating. Most teachers in all four contexts expected cheating to become a greater problem with increased use of e-assessment. Student authentication was not seen as a major problem in any of the contexts, as this was felt to be well controlled through face-to-face proctored assessments, though the problem of assuring effective authentication was seen by many teachers as a barrier to increased use of e-assessment. Authorship checking was seen as a major issue in all contexts, as copying and pasting from the web, ghost writing and plagiarism were all reported as widely prevalent, and authorship checking was seen as becoming even more important with increased use of e-assessment. Teachers identified a third category of cheating behaviours, which was the accessing of information from other students, from written materials, and from the internet during assessments. Teachers identified a number of approaches to addressing the problem of cheating: education, technology, assessment design, sanctions, policy, and surveillance. Whilst technology was not seen as the most important approach to prevention, student authentication and authorship checking systems were seen as relevant in terms of reducing reliance on face-to-face proctored examinations, and in improving the quality of assessment through supporting the employment of a wider range of assessment methods. The development of authorship checking based on computational linguistic approaches was an area of particular interest. Student authentication and authorship checking systems were not seen as being able to address the third category of cheating behaviours that the study identified.},
  keywords = {Authors,Authorship,Authorship checking,Barriers,Blended Learning,Cheating,College Faculty,College Students,Computational Linguistics,Computer Simulation,Computer Software,Conventional Instruction,Cross Cultural Studies,Distance Education,Distance learning,E-assessment,Education,Education & Educational Research,Ethics,Foreign Countries,Higher Education,Incidence,Information Sources,Integrity,International and Comparative Education,Learning management systems,Online Systems,Original Article,Plagiarism,Prevention,Project evaluation,Questionnaires,Social Sciences,Student authentication,Student Evaluation,Teacher Attitudes,Teachers' perspectives,Teaching,Teaching Methods,Universities,Writing Assignments,Writing Evaluation},
  file = {/Users/colin.madland/Zotero/storage/LPJUQFA9/mellarAddressingCheatingEassessment2018.pdf}
}

@article{mellarAddressingCheatingEassessment2018a,
  title = {Addressing Cheating in E-Assessment Using Student Authentication and Authorship Checking Systems: Teachers' Perspectives},
  author = {Mellar, Harvey and {Peytcheva-Forsyth}, Roumiana and Kocdar, Serpil and Karadeniz, Abdulkadir and Yovkova, Blagovesna},
  year = {2018},
  journal = {International journal for educational integrity},
  volume = {14},
  number = {1},
  pages = {1--21},
  publisher = {Springer Singapore},
  address = {Singapore},
  issn = {1833-2595},
  doi = {10.1007/s40979-018-0025-x},
  abstract = {Student authentication and authorship checking systems are intended to help teachers address cheating and plagiarism. This study set out to investigate higher education teachers' perceptions of the prevalence and types of cheating in their courses with a focus on the possible changes that might come about as a result of an increased use of e-assessment, ways of addressing cheating, and how the use of student authentication and authorship checking systems might impact on assessment practice. This study was carried out within the context of the project TeSLA (an Adaptive Trust-based e-assessment System for Learning) which is developing a system intended for integration within an institution's Virtual Learning Environment (VLE) offering a variety of instruments to assure student authentication and authorship checking. Data was collected at two universities that were trialling the TeSLA system, one in Turkey, where the main modes of teaching are face-to-face teaching and distance education, and one in Bulgaria, where the main modes of teaching are face-to-face teaching and blended learning. The study used questionnaires and interviews, building on existing TeSLA project evaluation activities and extending these to explore the specific areas we wished to examine in more depth. In three of the four contexts cheating was seen by teachers as a serious and growing problem, the exception was the distance education context where the teachers believed that the existing procedures were effective in controlling cheating. Most teachers in all four contexts expected cheating to become a greater problem with increased use of e-assessment. Student authentication was not seen as a major problem in any of the contexts, as this was felt to be well controlled through face-to-face proctored assessments, though the problem of assuring effective authentication was seen by many teachers as a barrier to increased use of e-assessment. Authorship checking was seen as a major issue in all contexts, as copying and pasting from the web, ghost writing and plagiarism were all reported as widely prevalent, and authorship checking was seen as becoming even more important with increased use of e-assessment. Teachers identified a third category of cheating behaviours, which was the accessing of information from other students, from written materials, and from the internet during assessments. Teachers identified a number of approaches to addressing the problem of cheating: education, technology, assessment design, sanctions, policy, and surveillance. Whilst technology was not seen as the most important approach to prevention, student authentication and authorship checking systems were seen as relevant in terms of reducing reliance on face-to-face proctored examinations, and in improving the quality of assessment through supporting the employment of a wider range of assessment methods. The development of authorship checking based on computational linguistic approaches was an area of particular interest. Student authentication and authorship checking systems were not seen as being able to address the third category of cheating behaviours that the study identified.},
  keywords = {Authors,Authorship,Authorship checking,Barriers,Blended Learning,Cheating,College Faculty,College Students,Computational Linguistics,Computer Simulation,Computer Software,Conventional Instruction,Cross Cultural Studies,Distance Education,Distance learning,E-assessment,Education,Ethics,Foreign Countries,Higher Education,Incidence,Information Sources,Integrity,International and Comparative Education,Learning management systems,Online Systems,Original Article,Plagiarism,Prevention,Project evaluation,Questionnaires,Student authentication,Student Evaluation,Teacher Attitudes,Teachers' perspectives,Teaching,Teaching Methods,Universities,Writing Assignments,Writing Evaluation},
  file = {/Users/colin.madland/Zotero/storage/NPJUSDVR/mellarAddressingCheatingEassessment2018a.pdf}
}

@article{meloHowAssessStudent2022,
  title = {How to Assess? {{Student}} Preferences for Methods to Assess Experiential Learning: {{A}} Best-Worst Scaling Approach},
  author = {Melo, Grace and Monteza, Diego and Colson, Greg and Zhang, Yu Yvette},
  year = {2022},
  journal = {PloS one},
  volume = {17},
  number = {10},
  pages = {e0276745-e0276745},
  publisher = {Public Library Science},
  address = {SAN FRANCISCO},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0276745},
  abstract = {Transitioning from traditional in-person classroom formats to online instructional delivery methods and online student assessments during the COVID-19 pandemic was a significant challenge to effective teaching, learning, and evaluation. Although there is a growing literature assessing the relative efficacy of different online teaching techniques, previous literature has not analyzed, from the student perspective, what methods are preferred for evaluating performance in experiential learning courses. How students perceive assessment methods is critical because it can affect their learning experience and academic achievements. To better understand student preferences for assessment methods, the best-worst scaling approach was used in two online surveys of 218 undergraduate students enrolled in experiential learning-based programs during the COVID-19 pandemic. Analysis of student responses indicates students' highest levels of support for assessments that emphasize the development of critical thinking skills and professional skills, such as case studies. Most students would prefer assessments that are driving (develop different skills such as creative thinking) and realistic (develop skills transferable to the real world), while only a few ({$<$} 1\%) prefer assessments that are fast (involve little time), frequent, safe (has preventive measures to eliminate cheating), or strategic (high probability of getting good grades).},
  keywords = {Academic achievement,Analysis,Assessments,Beliefs opinions and attitudes,Biology and Life Sciences,CAI,Case studies,Classrooms,Collaboration,College students,Computer assisted instruction,COVID-19,Distance learning,Epidemics,Evaluation,Experiential learning,Higher education,Innovations,Learning,Medicine and Health Sciences,Methods,Multidisciplinary Sciences,Online instruction,Pandemics,Pedagogy,People and Places,Performance evaluation,Polls & surveys,Research and Analysis Methods,Science & Technology,Science & Technology - Other Topics,Skills,Social aspects,Social Sciences,Students,Teaching,Undergraduate study,United States},
  file = {/Users/colin.madland/Zotero/storage/7GLMVBH4/meloHowAssessStudent2022.pdf}
}

@article{menyaniOnlineAssessmentDigital2022,
  title = {Online {{Assessment}} in the {{Digital Era}}: {{Moroccan EFL University Students}}' {{Experiences}}, {{Perceptions}} and {{Challenges}}},
  shorttitle = {Online {{Assessment}} in the {{Digital Era}}},
  author = {Menyani, Nourreddine and Boumehdi, Ahlame and El Jaadi, Oumaima},
  year = {2022},
  month = may,
  journal = {IAFOR Journal of Education},
  volume = {10},
  number = {1},
  pages = {193--210},
  issn = {21870594},
  doi = {10.22492/ije.10.1.10},
  urldate = {2023-01-15},
  abstract = {After the scientific consensus on the proliferation of COVID-19, a lethal virus, educational institutions worldwide have swiftly migrated to online learning. This upheaval has propelled online evaluation and assessment to be the norm during this period. The principal objective of the study and research is to explore students' experience with online emergency learning as well as online evaluation. This paper also investigates how Moroccan English as a foreign language (EFL) university learners perceive online assessment in comparison to face-to-face assessment. Data were collected from a sample of 93 Moroccan EFL university students using a self-designed questionnaire. The findings of this research revealed that the students experienced technical issues while submitting their exams. They have also expressed their disappointment with the lack of feedback provided by their professors, not to mention their constant worry about academic honesty. This has led them to lose interest in their studies and possess doubts about reliving this dissatisfactory experience. Therefore, the results implied that participants perceive online assessment as an insignificant factor for performance improvement. This unprecedented experience has had an unadulterated negative impact on students as it has left them both dissatisfied with their experience regarding distance learning and apprehensive about their future educational experiences. It is, then, recommended that the notion of online assessment should be given much attention in higher education in the Moroccan context.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/VAMKFDLI/menyaniOnlineAssessmentDigital2022.pdf}
}

@article{merrillBestPracticesOnline2003,
  title = {Best {{Practices}} for {{Online Facilitation}}},
  shorttitle = {Best {{Practices}} for {{Online Facilitation}}},
  author = {Merrill, Henry S.},
  year = {2003},
  journal = {Adult Learning},
  volume = {14},
  pages = {13--16},
  issn = {10451595},
  abstract = {The article identifies factors that contribute to the efficient facilitation of online learning. In addition to matching the learner abilities and preparation to the content and course level, other factors that contribute to the facilitation of online learning include effective course design, understanding the technologies, developing one's own online style, the multiple roles of the facilitator and effective group interaction. There are many different technologies that contribute to the complexity of distance learning. The designer of an online course should have more ways to deliver information and create interactive communication.},
  keywords = {COMPUTER-assisted,COMPUTER-assisted instruction,Courses,Distance,distance education,Education,EDUCATIONAL,Educational technology,in,instruction,Internet,INTERNET in education,Online,ONLINE courses,technology},
  annotation = {2}
}

@misc{merryAssessmentSallyBrown,
  title = {Assessment with {{Sally Brown}}},
  author = {Merry, Kevin and Brown, Sally},
  number = {14},
  urldate = {2022-09-25},
  abstract = {In this exceptional episode, we discuss all things assessment with the amazing Professor Sally Brown. Sally is an Independent Consultant in Learning, Teaching and Assessment, and Emerita Professor at Leeds Beckett University where she was, until 2010, Pro-Vice-Chancellor. She is a Principal Fellow of the Higher Education Academy, a Staff and Educational Development Association (SEDA) Senior Fellow, and a National Teaching Fellow. Irrespective of the formal accolades she has received, Sally is perhaps one of the most important voices when it comes to issues surrounding assessment in UK higher education today, particularly from an educational development perspective. Sally's work has influenced countless educators at home and abroad, and continues to be a powerful influence on assessment practices in higher education in the post-Covid world. This podcast is essential listening for anyone teaching or supporting student learning in higher education.},
  langid = {english},
  annotation = {2022-07-17},
  file = {/Users/colin.madland/Zotero/storage/6RRU2BMC/Episode-14-Assessment-with-Sally-Brown-e1lb5j6.html}
}

@article{mertalaItImportantThis2021,
  title = {`{{It}} Is Important at This Point to Make Clear That This Study Is Not ``Anti-{{iPad}}''': {{Ed-Tech}} Speak around {{iPads}} in Educational Technology Research},
  shorttitle = {`{{It}} Is Important at This Point to Make Clear That This Study Is Not ``Anti-{{iPad}}'''},
  author = {Mertala, Pekka},
  year = {2021},
  month = apr,
  journal = {Learning, Media and Technology},
  volume = {46},
  number = {2},
  pages = {230--242},
  issn = {1743-9884, 1743-9892},
  doi = {10.1080/17439884.2021.1868501},
  urldate = {2022-12-31},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/VXSQV65K/mertalaItImportantThis2021.pdf}
}

@article{mertensAssumptionsPhilosophicalProgrammatic2016,
  title = {Assumptions at the Philosophical and Programmatic Levels in Evaluation},
  author = {Mertens, Donna M.},
  year = {2016},
  journal = {Evaluation and Program Planning},
  volume = {59},
  pages = {102--108},
  issn = {0149-7189},
  doi = {10.1016/j.evalprogplan.2016.05.010},
  abstract = {Stakeholders and evaluators hold a variety of levels of assumptions at the philosophical, methodological, and programmatic levels. The use of a transformative philosophical framework is presented as a way for evaluators to become more aware of the implications of various assumptions made by themselves and program stakeholders. The argument is examined and demonstrated that evaluators who are aware of the assumptions that underlie their evaluation choices are able to provide useful support for stakeholders in the examination of the assumptions they hold with regard to the nature of the problem being addressed, the program designed to solve the problem, and the approach to evaluation that is appropriate in that context. Such an informed approach has the potential for development of more appropriate and culturally responsive programs being implemented in ways that lead to the desired impacts, as well as to lead to evaluation approaches that support effective solutions to intransigent social problems. These arguments are illustrated through examples of evaluations from multiple sectors; additional challenges are also identified.},
  keywords = {Assumptions,Climate change,Human rights,International development,Sexual violence,Social justice,Transformative}
}

@book{mertensIndigenousPathwaysSocial2013,
  title = {Indigenous Pathways into Social Research: Voices of a New Generation},
  shorttitle = {Indigenous Pathways into Social Research},
  editor = {Mertens, Donna M. and Cram, Fiona and Chilisa, Bagele},
  year = {2013},
  publisher = {Left Coast Press},
  address = {Walnut Creek, Calif},
  isbn = {978-1-59874-695-2 978-1-59874-696-9 978-1-59874-697-6 978-1-61132-684-0},
  lccn = {GN380 .I5289 2013},
  keywords = {Indigenous peoples,Research,Social sciences}
}

@article{mertensMixedMethodsWicked2015,
  title = {Mixed {{Methods}} and {{Wicked Problems}}},
  author = {Mertens, Donna M.},
  year = {2015},
  month = jan,
  journal = {Journal of Mixed Methods Research},
  volume = {9},
  number = {1},
  pages = {3--6},
  issn = {1558-6898, 1558-6901},
  doi = {10/gfgth4},
  urldate = {2021-07-26},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/3ZP5H5SV/mertensMixedMethodsWicked2015.pdf}
}

@article{mertensTransformativeParadigmMixed2007,
  title = {Transformative {{Paradigm}}: {{Mixed Methods}} and {{Social Justice}}},
  author = {Mertens, Donna M.},
  year = {2007},
  month = jul,
  journal = {Journal of Mixed Methods Research},
  volume = {1},
  number = {3},
  pages = {212--225},
  issn = {1558-6898},
  doi = {10.1177/1558689807302811},
  urldate = {2019-03-21},
  abstract = {The intersection of mixed methods and social justice has implications for the role of the researcher and choices of specific paradigmatic perspectives. The transformative paradigm with its associated philosophical assumptions provides a framework for addressing inequality and injustice in society using culturally competent, mixed methods strategies. The recognition that realities are constructed and shaped by social, political, cultural, economic, and racial/ethnic values indicates that power and privilege are important determinants of which reality will be privileged in a research context. Methodological inferences based on the underlying assumptions of the transformative paradigm reveal the potential strength of combining qualitative and quantitative methods. A qualitative dimension is needed to gather community perspectives at each stage of the research process, while a quantitative dimension provides the opportunity to demonstrate outcomes that have credibility for community members and scholars. Transformative mixed methodologies provide a mechanism for addressing the complexities of research in culturally complex settings that can provide a basis for social change.},
  file = {/Users/colin.madland/Zotero/storage/LN3W7C6J/mertensTransformativeParadigmMixed2007.pdf}
}

@inproceedings{mertlerMeasuringTeachersKnowledge2005,
  title = {Measuring {{Teachers}}' {{Knowledge}} \& {{Application}} of {{Classroom Assessment Concepts}}: {{Development}} of the "{{Assessment Literacy Inventory}}"},
  booktitle = {Paper Presented at the Annual Meeting of the {{American Educational Research Association}}},
  author = {Mertler, Craig A and Campbell, Cynthia},
  year = {2005-04-11/2005-04-15},
  address = {Montreal, QC, CA},
  urldate = {2021-03-16},
  abstract = {Assessing student performance is one of the most critical responsibilities of classroom teachers; yet, many teachers do not feel adequately prepared for this task. Teachers often believe that they need remediation or assistance in applying assessment concepts and techniques, as well as making assessment-related decisions. In an effort to measure teachers' "assessment literacy," an instrument, titled the "Assessment Literacy Inventory (ALI)," was developed and its psychometric properties evaluated. The "ALI" was designed to parallel existing "Standards for Teacher Competence in the Educational Assessment of Students." A two-stage pilot test of the instrument was conducted with 152 preservice teachers in Fall 2003 and 249 preservice teachers in the Spring 2004. Item analyses of the second-stage pilot data revealed an overall instrument reliability (KR20) of 0.74. Individual item analyses (i.e., item difficulties and item discriminations), as well as other indices, were examined. Recommendations for future research include content and construct validation of the "ALI" (both of which are currently being examined), as well as an investigation of the appropriateness of the "ALI" as a measure of inservice teacher assessment literacy. Finally, the "Assessment Literacy Inventory" provides a practical mechanism for educators to measure assessment literacy. Considering the current state of high-stakes accountability in education, the "ALI" could provide school districts an effective, as well as efficient way to allocate resources for developing or otherwise selecting teacher professional development opportunities on the topic of classroom assessment. Appended is: Sample Scenario and Selected Items from the "Assessment Literacy Inventory (ALI)." (Contains 2 tables and 2 figures.)},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/IXAE5KKM/mertlerMeasuringTeachersKnowledge2005.pdf}
}

@misc{mertlerPreserviceInserviceTeachers2003,
  title = {Preservice {{Versus Inservice Teachers}}' {{Assessment Literacy}}: {{Does Classroom Experience Make}} a {{Difference}}?},
  author = {Mertler, Craig A},
  year = {2003},
  address = {Columbus, OH},
  urldate = {2021-07-08},
  abstract = {Assessing student performance is one of the most critical aspects of the job of a classroom teacher; however, many teachers do not feel adequately prepared to assess their students' performance. In order to measure and compare preservice and inservice teachers'"assessment literacy," both groups were surveyed using the Classroom Assessment Inventory (CALI), which was designed to parallel the "Standards for Teacher Competence in the Educational Assessment of Students." Inservice teachers performed highest on Standard 3"Administering, Scoring, and Interpreting Results of Assessments"and lowest on Standard 5"Developing Valid Grading Procedures." Respondents were 67 preservice teachers and 197 inservice teachers. Preservice teachers performed highest on Standard 1"Choosing Appropriate Assessment Methods"and lowest on Standard 5"Developing Valid Grading Procedures. Comparisons between the two groups revealed significant differences on five of seven competency areas, as well as on the total scores. In all cases where significant differences were found, the inservice teachers scored higher than their preservice counterparts. (Contains 2 tables and 25 references.) (Author/SLD)},
  file = {/Users/colin.madland/Zotero/storage/J3VVKLVS/mertlerPreserviceInserviceTeachers2003.pdf}
}

@article{mertlerSecondaryTeachersAssessment2005,
  title = {Secondary {{Teachers}}' {{Assessment Literacy}}: {{Does Classroom Experience Make A Difference}}?},
  author = {Mertler, Craig A.},
  year = {2005},
  journal = {American Secondary Education},
  volume = {33},
  number = {2},
  pages = {76--3},
  issn = {00031003},
  urldate = {2023-07-08},
  abstract = {[Assessing student performance is one of the most critical aspects of the job of a classroom teacher, but many teachers do not feel adequately prepared to assess their students' performance. In order to measure and compare secondary preservice and inservice teachers' "assessment literacy", both groups were surveyed using the Classroom Assessment Literacy Inventory (CALI), which was designed to parallel the Standards for Teacher Competence in the Educational Assessment of Students. Inservice teachers performed highest on Administering, Scoring, and Interpreting the Results of Assessments and lowest on Developing Valid Grading Procedures. Preservice teachers performed higher on Choosing Appropriate Assessment Methods and lowest on Developing Valid Grading Procedures. Comparisons between the two groups revealed significant differences on five of the seven competency areas, as well as on the total scores. In all cases where significant differences were found, the secondary inservice teachers scored higher than their preservice counterparts.]},
  keywords = {No DOI found},
  annotation = {Corrected Version},
  file = {/Users/colin.madland/Zotero/storage/GURGN63J/mertlerSecondaryTeachersAssessment2005.pdf}
}

@article{mertlerTeachersAssessmentKnowledge2009,
  title = {Teachers' Assessment Knowledge and Their Perceptions of the Impact of Classroom Assessment Professional Development},
  author = {Mertler, Craig A.},
  year = {2009},
  month = jul,
  journal = {Improving Schools},
  volume = {12},
  number = {2},
  pages = {101--113},
  issn = {1365-4802, 1475-7583},
  doi = {10/c9n35t},
  urldate = {2021-06-23},
  abstract = {Assessing student performance is one of the most critical aspects of the job of a classroom teacher; however, many teachers in the United States do not feel adequately prepared to assess their students' performance. These feelings of inadequacy are exemplified when placed against the context of the No Child Left Behind Act of 2001, especially with its increased focus on accountability and assessment. This study examined the effectiveness of a two-week classroom assessment workshop for inservice teachers. The workshop was based on the Standards for Teacher Competence in the Educational Assessment of Students and focused on discussion, practice, and practical application through performance assessment tasks. The study utilized a parallel mixed-methods design. Teachers were pre-tested and post-tested using the Assessment Literacy Inventory. Additionally, teachers kept daily reflective journals in order to document their experiences. The training was shown to be highly effective for the teachers, as evidenced through the dramatic increase in post-test scores over pre-test scores, and perhaps even more so through critical examination of their reflective journals.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/N8QCH5NU/mertlerTeachersAssessmentKnowledge2009.pdf}
}

@article{meschImpactPositiveInterdependence1988,
  title = {Impact of Positive Interdependence and Academic Group Contingencies on Achievement},
  shorttitle = {Impact of Positive Interdependence and Academic Group Contingencies on Achievement},
  author = {Mesch, Debra and Johnson, David W. and Johnson, Roger},
  year = {1988},
  journal = {Journal of Social Psychology},
  volume = {128},
  pages = {345--352},
  issn = {00224545},
  abstract = {The effects of positive goal interdependence and positive goal and positive reward interdependence on achievement were investigated. The control group (n = 26) consisted of American students in a 10th-grade social studies class, and the experimental group (n = 28) consisted of American students in a 10th-grade social studies class that included four academically disabled and isolated 10th-grade students (3 male and 1 female). The results indicated that cooperation promotes higher achievement than competition does, and that both positive goal and reward interdependence are needed to maximize student achievement. [ABSTRACT FROM AUTHOR] Copyright of Journal of Social Psychology is the property of Taylor \& Francis Ltd and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
  keywords = {Academic,ACADEMIC achievement,ACHIEVEMENT,Behavioral,BEHAVIORAL scientists,CIVILIZATION,Education,sciences,scientists,Social,SOCIAL sciences,STUDENTS},
  annotation = {3}
}

@book{messickAssessmentHigherEducation1999,
  title = {Assessment in Higher Education : Issues of Access, Quality, Student Development, and Public Policy : A Festschrift in Honor of {{Warren W}}. {{Willingham}}},
  author = {Messick, {\relax Samuel}.},
  year = {1999},
  publisher = {L. Erlbaum Associates},
  address = {Mahwah, N.J},
  doi = {10.4324/9781315045009},
  abstract = {Assessment in Higher Education brings together in one place most of the major issues confronting higher education in the 1990s. These include enhancing student access, development, and success in higher education; transforming admissions testing to meet expanding educational needs; resolving the politics of accountability by assessing quality outcomes of higher education; assuring fair assessment responsive to human diversity; and facing the technological future of higher education. An integrative thread that weaves through all of these issues is the concept of equity, especially as it},
  isbn = {1-135-45185-0},
  keywords = {College students -- Rating of -- United States,Electronic books,Universities and colleges -- United States -- Entrance examinations,Universities and colleges -- United States -- Examinations,Willingham Warren W},
  file = {/Users/colin.madland/Zotero/storage/LZETQ76K/messickAssessmentHigherEducation1999.pdf}
}

@article{messickEvidenceEthicsEvaluation1981,
  title = {Evidence and {{Ethics}} in the {{Evaluation}} of {{Tests}}},
  author = {Messick, Samuel},
  year = {1981},
  month = nov,
  journal = {Educational Researcher},
  volume = {10},
  number = {9},
  pages = {9--20},
  issn = {0013-189X, 1935-102X},
  doi = {10/czgbbz},
  urldate = {2020-10-08},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/6AZ3SQ28/messickEvidenceEthicsEvaluation1981.pdf}
}

@article{messickInterplayEvidenceConsequences1994,
  title = {The {{Interplay}} of {{Evidence}} and {{Consequences}} in the {{Validation}} of {{Performance Assessments}}},
  author = {Messick, Samuel},
  year = {1994},
  month = mar,
  journal = {Educational Researcher},
  volume = {23},
  number = {2},
  pages = {13--23},
  publisher = {American Educational Research Association},
  issn = {0013-189X},
  doi = {10.3102/0013189X023002013},
  urldate = {2023-08-08},
  abstract = {Authentic and direct assessments of performances and products are examined in the light of contrasting functions and purposes having implications for validation, especially with respect to the need for specialized validity criteria tailored for performance assessment. These include contrasts between performances and products, between assessment of performance per se and performance assessment of competence or other constructs, between structured and unstructured problems and response modes, and between breadth and depth of domain coverage. These distinctions are elaborated in the context of an overarching contrast between task-driven and construct-driven performance assessment. Rhetoric touting performance assessments because they eschew decomposed skills and decontextualized tasks is viewed as misguided, in that component skills and abstract problems have a legitimate place in pedagogy. Hence, the essence of authentic assessment must be sought elsewhere, that is, in the quest for complete construct representation. With this background, the concepts of ?authenticity? and ?directness? of performance assessment are treated as tantamount to promissory validity claims that they offset, respectively, the two major threats to construct validity, namely, construct underrepresentation and construct-irrelevant variance. With respect to validation, the salient role of both positive and negative consequences is underscored as well as the need, as in all assessment, for evidence of construct validity.},
  file = {/Users/colin.madland/Zotero/storage/FTB2V2ZN/messickInterplayEvidenceConsequences1994.pdf}
}

@article{messickMeaningValuesTest1989,
  title = {Meaning and {{Values}} in {{Test Validation}}: {{The Science}} and {{Ethics}} of {{Assessment}}},
  shorttitle = {Meaning and {{Values}} in {{Test Validation}}},
  author = {Messick, Samuel},
  year = {1989},
  month = mar,
  journal = {Educational Researcher},
  volume = {18},
  number = {2},
  pages = {5--11},
  issn = {0013-189X, 1935-102X},
  doi = {10/d7rxq8},
  urldate = {2020-10-10},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/386FU7H9/messickMeaningValuesTest1989.pdf}
}

@article{messickValidity1987,
  title = {Validity},
  author = {Messick, Samuel},
  year = {1987},
  journal = {ETS Research Report Series},
  volume = {1987},
  number = {2},
  pages = {i-208},
  issn = {23308516},
  doi = {10/gfgqkm},
  urldate = {2021-04-27},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/6U2CJHVX/messickValidity1987.pdf}
}

@article{messickValidityPsychologicalAssessment1995,
  title = {Validity of Psychological Assessment: {{Validation}} of Inferences from Persons' Responses and Performances as Scientific Inquiry into Score Meaning.},
  shorttitle = {Validity of Psychological Assessment},
  author = {Messick, Samuel},
  year = {1995},
  journal = {American Psychologist},
  volume = {50},
  number = {9},
  pages = {741--749},
  issn = {1935-990X, 0003-066X},
  doi = {10.1037/0003-066X.50.9.741},
  urldate = {2024-10-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/messickValidityPsychologicalAssessment1995.pdf}
}

@article{meyerBreakingOutLearning2009,
  title = {Breaking {{Out}}: {{Learning}} Research from 'the Women in Prison Project},
  author = {Meyer, Karen and Fels, Lynn},
  year = {2009},
  journal = {International Review of Qualitative Research},
  volume = {2},
  number = {2},
  pages = {269--290},
  issn = {19408447, 19408455},
  doi = {10.1525/irqr.2009.2.2.269},
  abstract = {[Abstract This article is about context, power located within institutions, and complexities of interpretation tightly twisted in a participatory action research project with women in prison. This narrative speaks to the encounter between us and the women, the unfamiliarity each of us had with the other's language, and the joint challenge to \&\#x2018;decode\&\#x2019; transcripts of incarcerated women's voices. As action researchers we were determined, indeed even smugly pleased, to be undertaking this venture of tutelage, of introducing the women as co-researchers to methods of data analysis. However, we watched a shifting of power (empowerment), as the women became the true researchers through their proximity to and conversations with the transcripts as raw realities, narratives that acknowledged their lives, which we knew only as data. In the end, we came away unsettled, with deeper awareness for the complexity of interpreting \&\#x2018;data,\&\#x2019; which constitutes local knowing, the unsaid, and the unspeakable.]}
}

@article{meyerGradingStudents1908,
  title = {The {{Grading}} of {{Students}}},
  author = {Meyer, Max},
  year = {1908},
  journal = {Science},
  volume = {28},
  number = {712},
  pages = {243--250},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.28.712.243},
  urldate = {2024-03-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/SNBER4KT/Meyer - 1908 - The Grading of Students.pdf}
}

@article{meyerHowOnlineFaculty2011,
  title = {How Online Faculty Improve Student Learning Productivity},
  shorttitle = {How Online Faculty Improve Student Learning Productivity},
  author = {Meyer, Katrina A. and McNeal, Larry},
  year = {2011},
  journal = {Journal of Asynchronous Learning Networks},
  volume = {15},
  pages = {37--53},
  issn = {19395256},
  abstract = {Ten experienced online faculty were interviewed to elicit examples of how they improved student learning productivity in their online courses. The ten faculty represented nine different states, 13 different fields or disciplines, and all were tenured or tenure-track at master's or doctoral level higher education institutions. Based on a thematic analysis of the examples given, improvement in student learning occurred by 1) increasing student access to content, 2) changing the role of faculty (which had two parts: increasing access to and changing faculty roles), 3) increasing interaction with students, 4) emphasizing student effort (including use of experiential learning, group work, learning to learn, and feedback), 5) connecting to the "real world," and 6) focusing on time. These findings suggest that faculty can and do find ways to use different tools in different ways to improve student learning productivity. [ABSTRACT FROM AUTHOR] Copyright of Journal of Asynchronous Learning Networks is the property of Sloan Consortium and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
  keywords = {College,COLLEGE teachers,Distance,distance education,Education,Faculty,Higher,Higher Education,in,Internet,INTERNET in education,LEARNING,Online,Online learning,Productivity,Student,Student Learning Productivity,TEACHERS},
  annotation = {3}
}

@article{meyerInfluenceOnlineTeaching2011,
  title = {The {{Influence}} of {{Online Teaching}} on {{Faculty Productivity}}},
  author = {Meyer, Katrina},
  year = {2011},
  journal = {Innovative Higher Education},
  pages = {1--16},
  abstract = {Ten faculty members with experience teaching online were interviewed about their motivation for teaching online and the effect of teaching online on their teaching and research productivity. They represented nine different states and 13 different fields, and all were tenured or tenure-track at master's or doctoral institutions. All ten mentioned personal motivations for teaching online; eight mentioned professional motivations. Based on analysis of the interviews, several professors felt their teaching productivity had increased as a result of design choices and an increase in workload. Several had freed up time which was spent on service or research although this was modified by the stage of the faculty member's career.},
  keywords = {Humanities,Social Sciences and Law}
}

@article{meyerInvestigationTertiaryAssessment2010,
  title = {An {{Investigation}} of {{Tertiary Assessment Policy}} and {{Practice}}: {{Alignment}} and {{Contradictions}}},
  shorttitle = {An {{Investigation}} of {{Tertiary Assessment Policy}} and {{Practice}}},
  author = {Meyer, Luanna H. and Davidson, Susan and McKenzie, Lynanne and Rees, Malcolm and Anderson, Helen and Fletcher, Richard and Johnston, Patricia M.},
  year = {2010},
  month = jul,
  journal = {Higher Education Quarterly},
  volume = {64},
  number = {3},
  pages = {331--350},
  issn = {09515224, 14682273},
  doi = {10/dvz6kh},
  urldate = {2021-04-25},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/HRW8ND5P/meyerInvestigationTertiaryAssessment2010.pdf}
}

@article{michellPsychometricsPathologicalScience2008,
  title = {Is {{Psychometrics Pathological Science}}?},
  author = {Michell, Joel},
  year = {2008},
  month = may,
  journal = {Measurement: Interdisciplinary Research \& Perspective},
  volume = {6},
  number = {1-2},
  pages = {7--24},
  issn = {1536-6367, 1536-6359},
  doi = {10/bjgwps},
  urldate = {2021-02-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/RNTW6CQV/michellPsychometricsPathologicalScience2008.pdf}
}

@article{middletonConsiderationsFutureOnline2022,
  title = {Considerations for {{Future Online Testing}} and {{Assessment}} in {{Colleges}} and {{Universities}}},
  author = {Middleton, Kyndra V.},
  year = {2022},
  journal = {Educational Measurement: Issues and Practice},
  volume = {41},
  number = {1},
  pages = {51--53},
  issn = {0731-1745, 1745-3992},
  doi = {10.1111/emip.12497},
  urldate = {2023-01-15},
  abstract = {The onset of the coronavirus pandemic forced schools and universities across the nation and world to close and move to distance learning rather immediately. Almost two years later, colleges and universities have reopened, and most students have returned to campuses, but distance learning still occurs at a much higher rate than before the beginning of the pandemic. A few preliminary studies have shown that online assessment results are similar to in-person assessment results. However, as colleges and universities have expanded their online options, new issues have arisen related to best practices, equity, fairness, test security, and test integrity. Paper-and-pencil assessments should not merely be moved to online assessments without careful consideration to how this administration change affects all students. With the switch to more online assessments, educators and researchers should thoroughly evaluate how to provide these assessments in the most secure, fair, and valid manner while also maintaining the test or assessment's integrity and interpretation.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/6DVC9UKI/middletonConsiderationsFutureOnline2022.pdf}
}

@book{milesQualitativeDataAnalysis2014,
  title = {Qualitative Data Analysis: A Methods Sourcebook},
  shorttitle = {Qualitative Data Analysis},
  author = {Miles, Matthew B. and Huberman, A. M. and Salda{\~n}a, Johnny},
  year = {2014},
  edition = {Third edition},
  publisher = {SAGE Publications, Inc},
  address = {Thousand Oaks, Califorinia},
  isbn = {978-1-4522-5787-7},
  lccn = {H62 .M437 2014},
  keywords = {Education,Research,Social sciences}
}

@article{millarRepeatIndividualizedAssessment2021,
  title = {Repeat Individualized Assessment Using Isomorphic Questions: A Novel Approach to Increase Peer Discussion and Learning},
  author = {Millar, Russell and Manoharan, Sathiamoorthy},
  year = {2021},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {18},
  number = {1},
  pages = {1--15},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-021-00257-y},
  abstract = {It is demonstrated that the fully automatic generation of isomorphic questions allows for both repeat assessment, and for this assessment to be individualized. While this does require a substantial up-front effort, once prepared assessments can be reproduced with relative ease and with a near-zero probability of students receiving the same question a second time. We show the effectiveness of this approach using survey and performance data obtained from large year 2 and year 3 computer science classes. A greater than 10-fold increase in online peer discussion was observed, compared to the previous year. Contents analysis of the surveys showed that repeat testing was generally regarded favourably. Quantitative analyses found that prior homework did little to improve initial test performance, but was of vital importance in studying for the follow-up isomorphic test. Moreover, the performance gain on the isomorphic questions was the same for all students regardless of their overall ability, and was retained in the final exam.},
  keywords = {Academic Achievement,Automated assessment,Classroom discussion,Computer Appl. in Social and Behavioral Sciences,Computer Assisted Testing,Computer Science,Computer Science Education,Computers and Education,Cooperative Learning,Discussion (Teaching Technique),Distance learning,Education & Educational Research,Educational evaluation,Educational Technology,Higher Education,Humanities,Information Systems Applications (incl.Internet),Law,Online discussion,Online instruction,Peer learning,Peer Relationship,Peers,Questions,Research Article,Social Sciences,Statistics for Social Sciences,Student assessment,Student Evaluation,Student experience,Students},
  file = {/Users/colin.madland/Zotero/storage/TARYFZRF/millarRepeatIndividualizedAssessment2021.pdf}
}

@misc{millerJodyVanceMedia2021,
  title = {Jody {{Vance}} - {{Media Voices}}},
  author = {{MILLER}},
  year = {2021},
  month = jun,
  urldate = {2021-12-23}
}

@phdthesis{millerLeveragingCSCLTechnology2015,
  title = {Leveraging {{CSCL}} Technology to Support and Research Shared Task Perceptions in Socially Shared Regulation of Learning},
  author = {Miller, Mariel},
  year = {2015},
  address = {Victoria, BC},
  urldate = {2022-01-13},
  abstract = {Collaboration is a vital skill in today's knowledge economy. Regrettably, many learners lack the regulatory skills required for complex collaborative tasks. In particular, groups struggle to construct shared task perceptions of collaborative tasks on which to launch engagement. Thus, the purpose of this dissertation was to examine how computer supported collaborative learning (CSCL) tools can be leveraged to support shared task perceptions for regulating collaboration. Because investigating this process brings forth a wide array of methodological challenges, a second purpose of this dissertation was to explore how CSCL tools can be used as a methodological solution for capturing this process. Towards this end, research unfolded across one conceptual paper and two empirical studies: (a) Miller \& Hadwin (2015a) extended work conceptualizing self-, co-, and shared-regulation in successful collaboration and drew on this theoretical framework to propose ways in which CSCL tools can be designed to support and research regulation of collaboration; (b) Miller, Malmberg, Hadwin, \& J{\"a}rvel{\"a} (2015) investigated the processes that contributed to and constrained groups' construction of shared task perceptions in a CSCL environment in order to inform further refinement of supports; (c) Miller \& Hadwin (2015b) examined the effects of tools providing different levels of individual and group support on construction of shared task perceptions and task performance. Together, findings revealed the potential of blending pedagogical tools to support shared task perceptions with research tools for examining and understanding regulation. In particular, findings evidenced shared task perceptions to be a complex and challenging social phenomenon and shed light on ways in which CSCL tools may prompt and promote this process. In addition, data generated by learners as they interacted with CSCL supports created valuable opportunities to capture shared task perceptions as they unfolded in the context of meaningful collaborative tasks across the individual and group level.},
  school = {University of Victoria},
  file = {/Users/colin.madland/Zotero/storage/KAG5GE6U/millerLeveragingCSCLTechnology2015.pdf}
}

@article{millerScriptingAwarenessTools2015,
  title = {Scripting and Awareness Tools for Regulating Collaborative Learning: {{Changing}} the Landscape of Support in {{CSCL}}},
  shorttitle = {Scripting and Awareness Tools for Regulating Collaborative Learning},
  author = {Miller, Mariel and Hadwin, Allyson},
  year = {2015},
  month = nov,
  journal = {Computers in Human Behavior},
  volume = {52},
  pages = {573--588},
  issn = {07475632},
  doi = {10.1016/j.chb.2015.01.050},
  urldate = {2022-01-13},
  langid = {english}
}

@article{millerTransformingEassessmentAmerican2008,
  title = {Transforming E-Assessment in {{American Sign Language}}: Pedagogical and Technological Enhancements in Online Language Learning and Performance Assessment},
  author = {Miller, Charles and Hooper, Simon and Rose, Susan and {Montalto-Rook}, Michael},
  year = {2008},
  journal = {Learning, Media and Technology: Reframing E-assessment: Adopting New Media and Adapting Old Frameworks},
  volume = {33},
  number = {3},
  pages = {155--168},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {1743-9884;1743-9892;},
  doi = {10/b9rp9b},
  abstract = {The rapid increase in demand for American Sign Language (ASL) instruction between 1998 and 2002 created pervasive challenges in effectively assessing and documenting ASL learner performance. To address these challenges, we designed and developed the "Avenue ASL" e-assessment environment: an integrated, network-based software system to capture, evaluate, and manage ASL learner performances. In this paper, we present a design overview of the "Avenue ASL" system and use a lens of design-based research to examine how the theoretical foundations of the project have been enhanced through an iterative continuation of theory, design, and implementation research. The paper concludes with a discussion of potential further design applications, beyond ASL. (Contains 2 figures and 2 tables.);The rapid increase in demand for American Sign Language (ASL) instruction between 1998 and 2002 created pervasive challenges in effectively assessing and documenting ASL learner performance. To address these challenges, we designed and developed the Avenue ASL e-assessment environment: an integrated, network-based software system to capture, evaluate, and manage ASL learner performances. In this paper, we present a design overview of the Avenue ASL system and use a lens of design-based research to examine how the theoretical foundations of the project have been enhanced through an iterative continuation of theory, design, and implementation research. The paper concludes with a discussion of potential further design applications, beyond ASL.;},
  keywords = {American Sign Language,Computer Mediated Communication,Computer Software,design-based research,EDUCATION & EDUCATIONAL RESEARCH,Hearing Impairments,language performance e-assessment,Performance Based Assessment,Performance Tests,Research Design,Student Attitudes,Technology Uses in Education}
}

@incollection{milliganStandardsDevelopingAssessments2020,
  title = {Standards for {{Developing Assessments}} of {{Learning Using Process Data}}},
  booktitle = {Re-Imagining {{University Assessment}} in a {{Digital World}}},
  author = {Milligan, Sandra},
  editor = {Bearman, Margaret and Dawson, Phillip and Ajjawi, Rola and Tai, Joanna and Boud, David},
  year = {2020},
  volume = {7},
  pages = {179--192},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-41956-1_13},
  urldate = {2022-03-19},
  isbn = {978-3-030-41955-4 978-3-030-41956-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/MZIK64RM/milliganStandardsDevelopingAssessments2020.pdf}
}

@article{milnerHackingSocialInternet2013,
  title = {Hacking the {{Social}}: {{Internet Memes}}, {{Identity Antagonism}}, and the {{Logic}} of {{Lulz}}},
  author = {Milner, Ryan M},
  year = {2013},
  journal = {The Fibreculture Journal},
  number = {22},
  urldate = {2019-01-02},
  abstract = {4chan and reddit are participatory media collectives undergirded by a ``logic of lulz'' that favours distanced irony and critique. It often works at the expense of core identity categories like race and gender. However, the logic need not be entirely counterproductive to public discourse. Provided that diverse identities find voice instead of exclusion, these sites may facilitate vibrant, agonistic discussion instead of disenfranchising antagonism. In order to assess this potential for productive agonism, I undertook a critical discourse analysis of these collectives. Emphasising the image memes they produce, I evaluated discourses on race and gender. Both race and gender representations were dominated by familiar stereotypes and partial representations. However, while dissenting perspectives on race were repressed or excluded, dissenting perspectives on gender were vocalised and contested. The `logic of lulz' facilitated both dominance and counter, each articulated with heavy reliance on irony and critique. This logic ambiguously balanced agonism and antagonism, but contestation provided sharper engagement than repression.},
  file = {/Users/colin.madland/Zotero/storage/GIGJPJUM/fcj-156-hacking-the-social-internet-memes-identity-antagonism-and-the-logic-of-lulz.html}
}

@article{mimirinisQualitativeDifferencesAcademics2019,
  title = {Qualitative Differences in Academics' Conceptions of e-Assessment},
  author = {Mimirinis, M},
  year = {2019},
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {44},
  number = {2},
  pages = {233--248},
  issn = {0260-2938},
  doi = {10.1080/02602938.2018.1493087},
  abstract = {The paper reports the results of a phenomenographic study on academics' conceptions of e-assessment. A cohort of 21 academics from 17 disciplines participated in semi-structured interviews exploring their experiences of using web-based technologies for formative and summative assessment purposes. Through iterative analysis of the interview transcripts, the study identified four qualitatively different ways in which academic teachers understand e-assessment. It was seen as a means of: (a) efficiently managing and streamlining the assessment process; (b) facilitating dialogue and student engagement; (c) enhancing student learning; and (d) developing (digital) identity and the community. Six interrelated dimensions of variation were also established: the benefit of e-assessment, the role of the assessing teacher, the role of the assessed student, the role of the medium, the purpose, quality and level of collaboration, and, finally, the relationship between e-assessment and teaching and learning. The results thematise how university teachers relate to technology-enabled assessment and represent incrementally expanding levels of agency within relatively recent, often hybrid assessment milieus. More importantly, the reported dimensions of variation can be utilised to inform which aspects of e-assessment warrant further attention for the improvement of formative and summative assessment design and practice.},
  langid = {english},
  keywords = {Academic Achievement,Collaboration,College Faculty,Computer Assisted Testing,conceptions,E-assessment,Education & Educational Research,Electronic Learning,Foreign Countries,formative assessment,FORMATIVE ASSESSMENT,Formative Evaluation,Grammatical aspect,Learner Engagement,Learning,ONLINE,Online Courses,phenomenography,Phenomenology,Social Sciences,Student teacher relationship,summative assessment,Summative Evaluation,Technology Uses in Education,Undergraduate Students,United Kingdom (Great Britain),Web Based Instruction},
  file = {/Users/colin.madland/Zotero/storage/6HWWH7DX/mimirinisQualitativeDifferencesAcademics2019.pdf}
}

@inbook{minerMagicalPracticesNacirema2012,
  title = {Magical Practices among the {{Nacirema}}},
  booktitle = {The Anthropology of Education : Classic Readings},
  author = {Miner, Horace},
  year = {2012},
  collaborator = {Hodges, David Julian},
  isbn = {978-1-60927-396-5 1-60927-396-6},
  langid = {english}
}

@misc{ministerofjusticeCanadianHumanRights1985,
  title = {Canadian {{Human Rights Act}}, {{R}}.{{S}}.{{C}}.},
  author = {{Minister of Justice}},
  year = {RSC 1985},
  urldate = {2024-10-08},
  chapter = {3(1)},
  file = {/Users/colin.madland/Zotero/storage/H6.pdf}
}

@article{minnegalievaDeterminingDifficultyLevel2020,
  title = {Determining the {{Difficulty Level}} of {{Tasks}} in {{Online Courses}}},
  author = {Minnegalieva, Chulpan Bakievna and Khabibullin, Timur Vakhtangovich and Giniyatullina, Gulchachak Rishatovna and Giniyatullin, Lenar Ildarovich},
  year = {2020},
  journal = {International Journal of Higher Education},
  volume = {9},
  number = {8},
  pages = {40--45},
  issn = {ISSN-1927-6044},
  doi = {10/gmbv32},
  abstract = {Online courses on different platforms provide thousands of students with the knowledge and skills they need. This paper presents the results of a survey of students, during which they expressed their opinion on the use of electronic resources in teaching. The survey showed that students are more motivated to study when they understand how their knowledge will be used in their professional activities. The survey results also showed that the objectivity of knowledge control is essential. Students are usually familiar with the criteria for assessing the performance of the task. Knowing the criteria for evaluating the task itself, understanding why it is possible to get this particular number of points for completing the task will help students to approach their studies more responsibly. We analyzed the tasks that will be offered to students in the course of learning the MAXScript language. These tasks are assessed according to factors that affect their complexity and the maximum number of points that students can receive for their correct performance. The resulting complexity value can be adjusted after analyzing the scripts written and the trainees' time. This approach to assessing tasks can be applied in the study of information technology and other disciplines.},
  langid = {english},
  keywords = {College Students,Computer Science Education,Difficulty Level,Electronic Learning,Evaluation Criteria,Foreign Countries,Information Technology,Learning Activities,Online Courses,Programming,Programming Languages,Student Attitudes,Task Analysis}
}

@article{mishraSongRemainsSame2009,
  title = {The {{Song Remains}} the {{Same}}: {{Looking Back}} to the {{Future}} of {{Educational Technology}}},
  shorttitle = {The {{Song Remains}} the {{Same}}},
  author = {Mishra, Punya and Koehler, Matthew and Kereluik, Kristen},
  year = {2009},
  month = sep,
  journal = {TechTrends},
  volume = {53},
  number = {5},
  pages = {48--53},
  issn = {8756-3894, 1559-7075},
  doi = {10.1007/s11528-009-0325-3},
  urldate = {2023-08-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/TENQG2SP/SongRemainsSame2009.pdf}
}

@article{mishraTechnologicalPedagogicalContent2006,
  title = {Technological Pedagogical Content Knowledge: {{A}} Framework for Teacher Knowledge},
  author = {Mishra, Punya and Koehler, Matthew J.},
  year = {2006},
  journal = {Teachers College record (1970)},
  volume = {108},
  number = {6},
  pages = {1017--1054},
  publisher = {Sage},
  address = {THOUSAND OAKS},
  issn = {0161-4681},
  doi = {10.1111/j.1467-9620.2006.00684.x},
  abstract = {Research in the area of educational technology has often been critiqued for a lack of theoretical grounding. In this article we propose a conceptual framework for educational technology by building on Shulman's formulation of "pedagogical content knowledge" and extend it to the phenomenon of teachers integrating technology into their pedagogy. This framework is the result of 5 years of work on a program of research focused on teacher professional development and faculty development in higher education. It attempts to capture some of the essential qualities of teacher knowledge required for technology integration in teaching, while addressing the complex, multifaceted, and situated nature of this knowledge. We argue, briefly, that thoughtful pedagogical uses of technology require the development of a complex, situated form of knowledge that we call Technological Pedagogical Content Knowledge (TPCK). In doing so, we posit the complex roles of, and interplay among, three main components of learning environments: content, pedagogy, and technology. We argue that this model has much to offer to discussions of technology integration at multiple levels: theoretical, pedagogical, and methodological. In this article, we describe the theory behind our framework, provide examples of our teaching approach based upon the framework, and illustrate the methodological contributions that have resulted from this work.},
  keywords = {Analysis,Education,Education & Educational Research,Educational Environment,Educational Technology,Educational theory,Faculty Development,High school teachers,High school teaching,Higher Education,Instructional design,Integration,Knowledge Level,Methods,Pedagogical Content Knowledge,Practice,Professional development,Social Sciences,Teacher Characteristics,Technological change,Technology Integration},
  file = {/Users/colin.madland/Zotero/storage/8ICR5HXC/mishraTechnologicalPedagogicalContent2006.pdf}
}

@article{mislevyBriefIntroductionEvidencecentered2003,
  title = {A Brief Introduction to Evidence-Centered Design},
  author = {Mislevy, Robert J. and Almond, Russell G. and Lukas, Janice F.},
  year = {2003},
  month = jun,
  journal = {ETS Research Report Series},
  volume = {2003},
  number = {1},
  pages = {i-29},
  issn = {23308516},
  doi = {10/gf3bp7},
  urldate = {2021-03-10},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/5Y4GCIFU/mislevyBriefIntroductionEvidencecentered2003.pdf}
}

@article{mislevyEvidenceInferenceEducational1994,
  title = {Evidence and Inference in Educational Assessment},
  author = {Mislevy, Robert J.},
  year = {1994},
  month = dec,
  journal = {Psychometrika},
  volume = {59},
  number = {4},
  pages = {439--483},
  issn = {0033-3123, 1860-0980},
  doi = {10/c7xbhx},
  urldate = {2021-04-02},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/MYGAM23S/mislevyEvidenceInferenceEducational1994.pdf}
}

@incollection{mislevyIssuesStructureIssues2008,
  title = {Issues of {{Structure}} and {{Issues}} of {{Scale}} in {{Assessment}} from a {{Situative}}/{{Sociocultural Perspective}}},
  booktitle = {Assessment, {{Equity}}, and {{Opportunity}} to {{Learn}}},
  author = {Mislevy, Robert J.},
  editor = {Pullin, Diana C. and Haertel, Edward H. and Gee, James Paul and Young, Lauren Jones and Moss, Pamela A.},
  year = {2008},
  series = {Learning in {{Doing}}: {{Social}}, {{Cognitive}} and {{Computational Perspectives}}},
  pages = {259--294},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9780511802157.012},
  abstract = {INTRODUCTIONA situative/sociocultural (S/SC) perspective ``views knowledge as distributed among people and their environments, including the objects, artifacts, tools, books, and communities of which they are a part. Analyses of activity in this perspective focus on processes of interaction of individuals with other people and with physical and technological systems'' (Greeno, Collins, and Resnick 1997). Accordingly, ``a situated view of assessment emphasizes questions about the quality of student participation in activities of inquiry and sense making, and considers assessment practices as integral components of the general systems of activity in which they occur'' (p. 37). Research on school learning from the SC perspective ``incorporates explanatory concepts that have proved useful in fields such as ethnography and sociocultural psychology to study collaborative work, {\dots}mutual understanding in conversation, and other characteristics of interaction that are relevant to the functional success of the participants' activities'' (p. 7). In such analyses, attention focuses on patterns of interactions that occur in detailed and particular situations, yields ``thick'' descriptions of the activities, and often produces voluminous data. Studies at this level of detail are essential for understanding the conditions and interactions through which students learn; that is, ``opportunities to learn'' that particular circumstances afford particular students in light of their particular personal and educational histories of experience.Yet no practical assessment at the level of the classroom, let alone a school or a program, can demand scores of hours of video per student, all analyzed by a team of graduate students, each producing a multipage ideographic report.},
  isbn = {978-0-521-88045-9}
}

@techreport{mislevyStructureEducationalAssessments2003,
  type = {Descriptive},
  title = {On the {{Structure}} of {{Educational Assessments}}},
  author = {Mislevy, Robert J and Steinberg, Linda S and Almond, Russell G},
  year = {2003},
  number = {597},
  pages = {73},
  address = {Los Angeles, CA},
  institution = {{Graduate School of Education and Information Studies, University of California}},
  urldate = {2021-03-10},
  abstract = {In educational assessment, we observe what students say, do, or make in a few particular circumstances, and attempt to infer what they know, can do, or have accomplished more generally. A web of inference connects the two. Some connections depend on theories and experience concerning the targeted knowledge in the domain, how it is acquired, and the circumstances under which people bring their knowledge to bear. Other connections may depend on statistical models and probability-based reasoning. Still others concern the elements and processes involved in test construction, administration, scoring, and reporting. This paper describes a framework for assessment that makes explicit the interrelationships among substantive arguments, assessment designs, and operational processes. The work was motivated by the need to develop assessments that incorporate purposes, technologies, and psychological perspectives that are not well served by familiar forms of assessments. However, the framework is equally applicable to analyzing existing assessments or designing new assessments within familiar forms.},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/2GKQBT2A/mislevyStructureEducationalAssessments2003.pdf}
}

@article{mislevyTestTheoryReconceived1994,
  title = {Test Theory Reconceived},
  author = {Mislevy, Robert J.},
  year = {1994},
  month = jun,
  journal = {ETS Research Report Series},
  volume = {1994},
  number = {1},
  issn = {23308516},
  doi = {10/gjm236},
  urldate = {2021-04-02},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/38ZHN9VJ/mislevyTestTheoryReconceived1994.pdf}
}

@article{mitchellEffectSwitchingMandatory2018,
  title = {The Effect of Switching to Mandatory Online Course Assessments on Response Rates and Course Ratings},
  author = {Mitchell, Ojmarrh and Morales, Melissa},
  year = {2018},
  month = jun,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {43},
  number = {4},
  pages = {629--639},
  publisher = {Taylor \& Francis},
  issn = {0260-2938},
  doi = {10.1080/02602938.2017.1390062},
  abstract = {Increasingly, student assessments of courses are being conducted online as opposed to administered in class. A growing body of research compares response rates and course ratings of courses evaluated online versus on paper. The present study extends this research by comparing student course assessments before and after the University of South Florida made online evaluations mandatory for all courses. This change only directly affected courses taught on-campus, as online courses were already being assessed online. However, we examine the effect of this change on courses taught on-campus and online, because we expect this change in policy to have differential effects. We hypothesise that by making online assessments mandatory for all courses, online assessments went from a novel method of evaluation to the norm; and, therefore, increased response rates for online courses, but had the opposite effect for on-campus courses. We find mixed support for our hypothesis. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {course evaluation,Course Evaluation,Distance Education,instructor evaluation,online teaching evaluations,Student evaluation of teaching,Teacher Effectiveness Evaluation,Teaching Methods}
}

@article{mitchellGenderBiasStudent2018,
  title = {Gender {{Bias}} in {{Student Evaluations}}},
  author = {Mitchell, Kristina M. W. and Martin, Jonathan},
  year = {2018},
  journal = {PS: Political Science\& Politics},
  edition = {2018/03/06},
  volume = {51},
  number = {3},
  pages = {648--652},
  publisher = {Cambridge University Press},
  issn = {1049-0965},
  doi = {10.1017/S104909651800001X},
  abstract = {Many universities use student evaluations of teachers (SETs) as part of consideration for tenure, compensation, and other employment decisions. However, in doing so, they may be engaging in discriminatory practices against female academics. This study further explores the relationship between gender and SETs described by MacNell, Driscoll, and Hunt (2015) by using both content analysis in student-evaluation comments and quantitative analysis of students' ordinal scoring of their instructors. The authors show that the language students use in evaluations regarding male professors is significantly different than language used in evaluating female professors. They also show that a male instructor administering an identical online course as a female instructor receives higher ordinal scores in teaching evaluations, even when questions are not instructor-specific. Findings suggest that the relationship between gender and teaching evaluations may indicate that the use of evaluations in employment decisions is discriminatory against women.}
}

@article{mitchellGivingStudentsEDGE2021,
  title = {Giving Students an {{eDGE}}: {{Focusing}} on {{ePortfolios}} for Graduate Employability},
  author = {Mitchell, Lana J and Campbell, Chris and Rigby, Roshan and Williams, Lauren T},
  year = {2021},
  journal = {Journal of Teaching and Learning for Graduate Employability},
  abstract = {Universities are placing increased attention on providing students with ePortfolios and online teaching platforms to enhance learning and employability. This paper reports on a study which aimed to investigate the views of dietetics students on the usefulness of PebblePad as a learning platform and ePortfolio tool for evidencing graduate competency and enhancing employability. This research was conducted within a multi-component design-based research framework. PebblePad was introduced to the Griffith University Bachelor of Nutrition and Dietetics fouryear degree in 2016 as part of the eDGE project (ePortfolios for Dietetics Graduate Employability). Students enrolled in 1st and 3rd year courses utilising PebblePad in 2016 and 2017 were invited to complete an online survey at the conclusion of each course. Surveys were completed by 116 students (2016 n=50; 2017 n=66). Students perceived that PebblePad could impact on their employability through demonstrating their learning as well as assisting their understanding and competency development as a professional. This was more evident in 3rd year students than 1st year. The aspects of PebblePad perceived as most beneficial for employability were the ability to: 1) collate experiences and assessment; 2) evidence dietetics competencies via `tagging'; and 3) facilitate reflection. The least beneficial aspects were: 1) usability and navigation of PebblePad; 2) lack of clarity around using PebblePad to evidence employability; and 3) belief that required reflections were excessive. ePortfolios and learning platforms such as PebblePad are perceived by students to be useful for evidencing employability. Potential improvements in assessment design could further enhance their use.},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/ID9VIIJS/mitchellGivingStudentsEDGE2021.pdf}
}

@article{moccozetVersatileFlexibleEassessment2019,
  title = {A Versatile and Flexible E-Assessment Framework towards More Authentic Summative Examinations in Higher-Education},
  author = {Moccozet, Laurent and Benkacem, Omar and Berisha, Elma and Trindade, Rita Trigo and B{\"u}rgi, Pierre-Yves},
  year = {2019},
  journal = {International Journal of Continuing Engineering Education and Life Long Learning},
  volume = {29},
  number = {3},
  pages = {211--229},
  publisher = {Inderscience Publishers (IEL)},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/2UU97GK7/IJCEELL.2019.html}
}

@inproceedings{moccozetVersatileFlexibleFramework2018,
  title = {A Versatile and Flexible Framework for E-Assessment in {{Higher-Education}}},
  booktitle = {2018 17th {{International Conference}} on {{Information Technology Based Higher Education}} and {{Training}} ({{ITHET}})},
  author = {Moccozet, Laurent and Benkacem, Omar and Tardy, Camille and Berisha, Elma and Trindade, Rita Trigo and B{\"i}rgi, Pierre-Yves},
  year = {2018},
  pages = {1--6},
  publisher = {IEEE},
  doi = {10.1109/ITHET.2018.8424764},
  file = {/Users/colin.madland/Zotero/storage/YDAI8VGW/8424764.html}
}

@misc{Mod01Lec38Introduction,
  title = {Mod-01 {{Lec-38 Introduction}} to {{Structural Equation Modeling}} ({{SEM}})},
  urldate = {2023-09-01},
  abstract = {Applied Multivariate Statistical Modeling  by Dr J Maiti,Department of  Management, IIT Kharagpur.For more details on NPTEL visit http://nptel.ac.in},
  langid = {british},
  file = {/Users/colin.madland/Zotero/storage/74KXYTEF/playlist.html}
}

@article{mohamadiComparativeEffectOnline2018,
  title = {Comparative Effect of Online Summative and Formative Assessment on {{EFL}} Student Writing Ability},
  author = {Mohamadi, Z},
  year = {2018},
  journal = {Studies in Educational Evaluation},
  volume = {59},
  pages = {29--40},
  issn = {0191-491X},
  doi = {10.1016/j.stueduc.2018.02.003},
  abstract = {This study investigated the effect of online summative and formative assessments on 130 Iranian English as foreign language (EFL) junior university students' writing ability. Three assessment interventions in writing performances of participants were investigated in 27 sessions using pretest/posttest time series design. The interventions included online summative assessment and online portfolio writing assessment conducted individually and online collaborative formative assessment. Data were collected from students' individual writing in both online summative and portfolio formative assessments as well as collaborative writing in online collaborative formative assessment in e-writing forum. The writing performances were assessed using International English Language Testing System (IELTS) rating scale. Paired sample t-test and analysis of covariance results indicated improved writing ability in all interventions and highest significant enhanced writing in online collaborative writing assessment intervention. The results imply that using engaging technology and techniques along with appropriate assessment strategies is a powerful way of making learning efficient.},
  langid = {english},
  keywords = {ACHIEVEMENT,Collaborative writing,CORRECTIVE FEEDBACK,ENGAGEMENT,HIGHER-EDUCATION,Online formative assessment,Online summative assessment,PEER ASSESSMENT,PERFORMANCE,PORTFOLIO ASSESSMENT,QUALITY,Student portfolio writing,SYSTEM,TEACHERS}
}

@article{mohamedInitialAnalysisReliability2021,
  title = {An {{Initial Analysis}} of {{Reliability}} and {{Validity}} of a {{Personality Instrument Using}} the {{Rasch Measurement Model}}},
  author = {Mohamed, Noorashikeen and Sulaiman, Wan Shahrazad Wan and {\noopsort{halim}}wati Halim, Fatimah and Masodi, Mohd Saidfudin},
  year = {2021},
  month = sep,
  journal = {International Journal of Academic Research in Business and Social Sciences},
  volume = {11},
  number = {9},
  pages = {Pages 1735-1755},
  issn = {2222-6990},
  doi = {10.6007/IJARBSS/v11-i9/11251},
  urldate = {2021-11-21},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/BMJK838D/mohamedInitialAnalysisReliability2021.pdf}
}

@article{moherPreferredReportingItems2009,
  title = {Preferred {{Reporting Items}} for {{Systematic Reviews}} and {{Meta-Analyses}}: {{The PRISMA Statement}}},
  shorttitle = {Preferred {{Reporting Items}} for {{Systematic Reviews}} and {{Meta-Analyses}}},
  author = {Moher, David and Liberati, Alessandro and Tetzlaff, Jennifer and Altman, Douglas G. and {The PRISMA Group}},
  year = {2009},
  month = jul,
  journal = {PLoS Medicine},
  volume = {6},
  number = {7},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.1000097},
  urldate = {2022-10-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/VTAKR4PN/moherPreferredReportingItems2009.pdf}
}

@article{moiseyCommunityBuildingComputerMediated2008,
  title = {Community {{Building}} and {{Computer-Mediated Conferencing}}},
  author = {Moisey, Susan Darlene and Neu, Candace and {Cleveland-Innes}, Martha},
  year = {2008},
  month = jan,
  journal = {Journal of Distance Education},
  volume = {22},
  number = {2},
  pages = {15--42},
  issn = {0830-0445},
  abstract = {This study examined the relationship between community cohesion and computer-mediated conferencing (CMC), as well as other variables potentially associated with the development of a learning community. Within the context of a graduate-level course in instructional design (a core course in the Masters of Distance Education program at Athabasca University), students participated in asynchronous online discussion groups as an integral part of their course activities. Upon completion of the course, a questionnaire based on Rovai's (2002) Classroom Cohesion Scale (CSS) was administered to examine the relationship between community cohesion and students' perception of their CMC participation as well as other selected variables. The CSS was comprised of two subscales: the Connectedness subscale and the Learning Community subscale. Results revealed a significant positive correlation between community cohesion and passive CMC involvement (i.e., reading postings), but not with more active CMC involvement (e.g., making postings, replying to others' postings). Significant positive correlations were also found between course satisfaction and community cohesion (both the Learning Community and Connectedness subscales) and between program satisfaction and community cohesion (only the Connectedness subscale). (Contains 2 figures and 6 tables.)},
  keywords = {Computer Mediated Communication,Core Curriculum,Correlation,Discussion Groups,distance education,Educational technology,Higher Education,instructional design,Interpersonal Relationship,Learning Experience,ONLINE courses,Questionnaires}
}

@article{mokgwathiDesigningAssessmentTechnical2019,
  title = {Designing {{Assessment}} for {{Technical Writing}} and {{Academic Literacy}}: {{Structuring}} and {{Wording Questions Using Bloom}}'s {{Taxonomy--A Case Study}}},
  author = {Mokgwathi, T. S. and Macha, Annah S. and Morolong, Lebogang},
  year = {2019},
  month = jan,
  journal = {Education Quarterly Reviews},
  volume = {2},
  number = {1},
  pages = {144--154},
  publisher = {Education Quarterly Reviews},
  issn = {2657-215X},
  abstract = {This study investigated how lecturers of Technical Writing and Academic Literacy assessed their students at a science and technology university in Botswana. The data for the study were obtained from the past test, assignment and examination papers administered to year one, year two and year three students enrolled in various programmes under the College of Sciences (including the Department of Information Communication and Technology), and the College of Engineering and Technology at the said university. In addition, a focus group of six teaching staff was interviewed to triangulate the data and to get in-depth information on how they set the assessment pieces. The data obtained from the assessment pieces were analysed qualitatively to determine the nature and the level of questions used. The data from the interview held with the teaching staff were also analysed qualitatively to determine what informed the way they set questions. The results from the study showed that the students were mainly tested for knowledge application; and many of the questions were from the low-level category as per Bloom's Taxonomy (1956) revised for the 21st Century Learners (The University of Utah's Centre for Teaching and Learning Excellence, 2001). The results also showed that lecturers did not take into account the level at which the students were studying. University students should be required to analyse, synthesise and evaluate information before them in order to demonstrate deeper understanding. It is recommended that lecturers should apply Bloom's Taxonomy when setting assessment tasks, taking into consideration the level at which the students were studying. It is hoped that the results from the study will sensitise the teaching staff at this university and other tertiary institutions on the importance of applying Bloom's Taxonomy when assessing their students.},
  keywords = {Academic Language,Assignments,Botswana,Case Studies,College Faculty,Foreign Countries,Information Literacy,Information Science Education,Information Sources,Information Technology,Knowledge Level,Literacy Education,No DOI found,Student Evaluation,Taxonomy,Teacher Attitudes,Technical Writing,Tests,Undergraduate Students}
}

@article{molenaarConceptHybridHumanAI2022,
  title = {The Concept of Hybrid Human-{{AI}} Regulation: {{Exemplifying}} How to Support Young Learners' Self-Regulated Learning},
  author = {Molenaar, Inge},
  year = {2022},
  month = jan,
  journal = {Computers and Education: Artificial Intelligence},
  volume = {3},
  pages = {100070},
  issn = {2666-920X},
  doi = {10.1016/j.caeai.2022.100070},
  abstract = {Hybrid systems combining artificial and human intelligence hold great promise for training human skills. In this paper, I position the concept of Hybrid Human-AI Regulation and illustrate this with an example of a first prototype of a Hybrid Human-AI Regulation (HHAIR) system. HHAIR supports self-regulated learning (SRL) in the context of adaptive learning technologies (ALTs) with the aim to develop learners' self-regulated learning skills. This prototype targets young learners (10--14 years) for whom SRL skills are critical in today's society. Many of these learners use ALTs to learn mathematics and languages every day in school. ALTs optimize learning based on learners' performance data, but even the most sophisticated ALTs fail to support SRL. In fact, most ALTs take over (offload) regulation from learners. In contrast, HHAIR positions hybrid regulation as a collaborative task of the learner and the AI which is gradually transferred from AI-regulation to self-regulation. Learners will increasingly regulate their own learning progressing through different degrees of hybrid regulation. In this way HHAIR supports optimized learning and the transfer and development of SRL skills for lifelong learning (future learning). The HHAIR concept is novel in proposing a hybrid intelligence approach training human SRL skills with AI. This paper outlines theoretical foundations from SRL theory, hybrid intelligence and learning analytics. A first prototype in the context of ALTs for young learners is described as an example of hybrid human-AI regulation and future advancement is discussed. In this way, foundational theoretical, empirical, and design work are combined in articulating the concept of Hybrid Human-AI Regulation which features forward adaptive support for SRL and transfer of control between human and AI over regulation.},
  file = {/Users/colin.madland/Zotero/storage/B95SIFZ6/molenaarConceptHybridHumanAI2022.pdf}
}

@misc{mollickCentaursCyborgsJagged2023,
  title = {Centaurs and {{Cyborgs}} on the {{Jagged Frontier}}},
  author = {Mollick, Ethan},
  year = {2023},
  month = jul,
  urldate = {2023-09-22},
  abstract = {I think we have an answer on whether AIs will reshape work....},
  howpublished = {https://www.oneusefulthing.org/p/centaurs-and-cyborgs-on-the-jagged},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/GS9NPPB8/mollickCentaursCyborgsJagged2023.pdf;/Users/colin.madland/Zotero/storage/QZ2ZEDYW/centaurs-and-cyborgs-on-the-jagged.html}
}

@article{molloyDevelopingLearningcentredFramework2020,
  title = {Developing a Learning-Centred Framework for Feedback Literacy},
  author = {Molloy, Elizabeth and Boud, David and Henderson, Michael},
  year = {2020},
  month = may,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {45},
  number = {4},
  pages = {527--540},
  issn = {0260-2938, 1469-297X},
  doi = {10/gjsfn8},
  urldate = {2021-04-23},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/UT5ES5MF/molloyDevelopingLearningcentredFramework2020.pdf}
}

@article{montenegro-ruedaAssessmentHigherEducation2021,
  title = {Assessment in {{Higher Education}} during the {{COVID-19 Pandemic}}: {{A Systematic Review}}},
  author = {{Montenegro-Rueda}, Marta and {Luque-de la Rosa}, Antonio and {Sarasola Sanchez-Serrano}, Jose Luis and {Fernandez-Cerero}, Jose},
  year = {2021},
  journal = {Sustainability},
  volume = {13},
  number = {19},
  pages = {10509},
  publisher = {Mdpi},
  address = {BASEL},
  issn = {2071-1050},
  doi = {10.3390/su131910509},
  abstract = {In the face of the COVID-19 pandemic, millions of students have been affected by the closure of educational institutions. This has forced a shift from face-to-face to distance education, facing numerous emergency educational measures, such as online assessment. This study aims to present a systematic review of the literature on the impact of assessment in higher education during the pandemic. The study has followed the methodology set out in the PRISMA statement, and includes 13 studies selected from a total of 51. The results indicate that faculty and students have faced numerous challenges in moving to virtual environments; on the faculty side the lack of training in online assessment techniques is the main problem, on the students' side there is dishonesty and misconduct. However, it is concluded that continuous assessment, not focused on exams, but in a more qualitative way is the best way to assess at a distance.},
  keywords = {Colleges & universities,Coronaviruses,COVID-19,Distance learning,Education,Education reform,Educational evaluation,Environmental Sciences,Environmental Sciences & Ecology,Environmental Studies,evaluation,Green & Sustainable Science & Technology,Higher education,Higher education institutions,Life Sciences & Biomedicine,Literature reviews,Online instruction,Pandemics,Pedagogy,review,Science & Technology,Science & Technology - Other Topics,Students,Systematic review,University students,Virtual environments},
  file = {/Users/colin.madland/Zotero/storage/APEEX737/montenegro-ruedaAssessmentHigherEducation2021.pdf}
}

@article{moonen-vanloonAutomaticInterpretationNarrative2022,
  title = {Toward {{Automatic Interpretation}} of {{Narrative Feedback}} in {{Competency-Based Portfolios}}},
  author = {{Moonen-van Loon}, Joyce M. W. and Govaerts, Marjan and Donkers, Jeroen and {\noopsort{rosmalen}}{van Rosmalen}, Peter},
  year = {2022},
  journal = {IEEE transactions on learning technologies},
  volume = {15},
  number = {2},
  pages = {179--189},
  publisher = {IEEE},
  address = {LOS ALAMITOS},
  issn = {1939-1382},
  doi = {10.1109/TLT.2022.3159334},
  abstract = {Self-directed learning is generally considered a key competence in higher education. To enable self-directed learning, assessment practices increasingly embrace assessment for learning rather than the assessment of learning, shifting the focus from grades and scores to provision of rich, narrative, and personalized feedback. Students are expected to collect, interpret, and give meaning to this feedback, in order to self-assess their progress and to formulate new, appropriate learning goals and strategies. However, interpretation of aggregated, longitudinal narrative feedback has been proven to be very challenging, cognitively demanding, and time consuming. In this article, we, therefore, explored the applicability of existing, proven text mining techniques to support feedback interpretation. More specifically, we investigated whether it is possible to automatically generate meaningful information about prevailing topics and the emotional load of feedback provided in medical students' competence-based portfolios (N = 1500), taking into account the competence framework and the students' various performance levels. Our findings indicate that the text-mining techniques topic modeling and sentiment analysis make it feasible to automatically unveil the two principal aspects of narrative feedback, namely the most relevant topics in the feedback and their sentiment. This article, therefore, takes a valuable first step toward the automatic, online support of students, who are tasked with meaningful interpretation of complex narrative data in their portfolio as they develop into self-directed life-long learners.},
  keywords = {Analytical models,Assessment for learning,Competency Based Education,Computer Science,Computer Science Interdisciplinary Applications,Data analysis,Data collection,Data Use,E-portfolio,Education,Education & Educational Research,Evaluation Methods,Feedback (Response),Goal Orientation,Higher Education,Independent Study,Learning Analytics,Longitudinal Studies,Medical Education,Medical Students,narrative feedback,Portfolios,Portfolios (Background Materials),Science & Technology,Sentiment analysis,Social Sciences,Student Evaluation,Technology,Text mining},
  file = {/Users/colin.madland/Zotero/storage/EL7MUHDL/moonen-vanloonAutomaticInterpretationNarrative2022.pdf}
}

@article{mooreDesignModelsWe2021,
  title = {The {{Design Models We Have Are Not}} the {{Design Models We Need}}},
  author = {Moore, Stephanie},
  year = {2021},
  journal = {The Journal of Applied Instructional Design},
  doi = {10.59668/329.5266},
  urldate = {2024-09-22},
  abstract = {Whitbeck (1996) presents a design-anchored approach to ethics that provides a way to think about the intersection of instructional design and social justice. While ethics are typically treated as deciding between what is ``right'' or ``wrong,'' Whitbeck (1996) explains this is a simplistic view, as ethics are about confronting complex moral problems that require designers to devise responses (design). When critiqued through the lens of accessibility and equity and racial and economic inequalities, areas where present design models fall short become apparent. Ethics as design affords a way to see design models anew and reconsider design practices.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/mooreDesignModelsWe2021.pdf}
}

@book{mooreDistanceEducationSystems2005,
  title = {Distance Education: {{A}} Systems View},
  shorttitle = {Distance Education: {{A}} Systems View},
  author = {Moore, Michael and Kearsley, Greg},
  year = {2005},
  edition = {2nd},
  publisher = {Thomson Wadsworth},
  address = {Belmont, CA},
  isbn = {0-534-50688-7}
}

@article{mooreEditorialThreeTypes1989,
  title = {Editorial: {{Three}} Types of Interaction},
  author = {Moore, Michael G.},
  year = {1989},
  month = jan,
  journal = {American Journal of Distance Education},
  volume = {3},
  number = {2},
  pages = {1--7},
  issn = {0892-3647},
  doi = {10.1080/08923648909526659}
}

@article{mooreEmploymentDrivenOnlineStudent2017,
  title = {Employment-{{Driven Online Student Attrition}} and the {{Assessment Policy Divide}}: {{An Australian Open-Access Higher Education Perspective}}},
  author = {Moore, Catherine and Greenland, Steven},
  year = {2017},
  journal = {Journal of Open, Flexible and Distance Learning},
  volume = {21},
  number = {1},
  pages = {52--62},
  issn = {ISSN-1179-7665},
  abstract = {Two hundred and twenty-six qualitative interviews with students studying at Australia's largest online tertiary education organisation, Open Universities Australia (OUA), found that failure to complete assessments due to unexpected and unavoidable employment commitments was the standout reason for dropping out of its open-access courses. The assessment policies of 10 Australian universities that teach the OUA tertiary programmes were then reviewed to evaluate the extent to which employment-related circumstances were considered to be grounds for granting concessions and extensions. Half of these institutions' policies did not mention employment as an extenuating circumstance, others made only passing reference, and one specifically stated that work was not a valid reason for an assignment extension. In this regard, online students may not be receiving the flexible and accessible learning that online education is purported to provide. This situation highlights a broader issue, in that many online educators are using policies and protocols that are designed for traditional on-campus students without adequate adaptation for the online learner. Considerable scope therefore exists for improving online learner satisfaction and retention by more effectively accommodating online student characteristics and needs.},
  langid = {english},
  keywords = {College Students,Dropouts,Employment,Foreign Countries,Interviews,No DOI found,Nontraditional Students,Online Courses,Open Universities,Qualitative Research,School Policy,Student Attitudes,Student Attrition,Withdrawal (Education)}
}

@incollection{mooreEthicsEducationalTechnology2014,
  title = {Ethics of {{Educational Technology}}},
  booktitle = {Handbook of {{Research}} on {{Educational Communications}} and {{Technology}}},
  author = {Moore, Stephanie L. and Ellsworth, James B.},
  editor = {Spector, J. Michael and Merrill, M. David and Elen, Jan and Bishop, M. J.},
  year = {2014},
  pages = {113--127},
  publisher = {Springer New York},
  address = {New York, NY},
  doi = {10.1007/978-1-4614-3185-5_10},
  urldate = {2024-09-22},
  isbn = {978-1-4614-3184-8 978-1-4614-3185-5},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/mooreEthicsEducationalTechnology2014.pdf}
}

@book{mooreEthicsEducationalTechnology2023,
  title = {Ethics and Educational Technology: {{Reflection}}, Interrogation, and Design as a Framework for Practice},
  shorttitle = {Ethics and Educational Technology},
  author = {Moore, Stephanie L. and {Tillberg-Webb}, Heather K.},
  year = {2023},
  month = mar,
  edition = {1},
  publisher = {Routledge},
  address = {New York},
  doi = {10.4324/9780203075241},
  urldate = {2024-07-16},
  isbn = {978-0-203-07524-1},
  langid = {english}
}

@book{mooreOneOtherStories2017,
  title = {One {{Without}} the {{Other}}: {{Stories}} of {{Unity Through Diversity}} and {{Inclusion}}},
  shorttitle = {One {{Without}} the {{Other}}},
  author = {Moore, Shelley and Schnellert, Leyton},
  year = {2017},
  publisher = {Portage \& Main Press},
  address = {Winnipeg},
  urldate = {2021-12-23},
  isbn = {978-1-55379-699-2},
  keywords = {Inclusive education.},
  file = {/Users/colin.madland/Zotero/storage/UYPI9AQX/reader.html}
}

@article{mooreSynthesisResearchMental2022,
  title = {A {{Synthesis}} of {{Research}} on {{Mental Health}} and {{Remote Learning}}: {{How Pandemic Grief Haunts Claims}} of {{Causality}}},
  shorttitle = {A {{Synthesis}} of {{Research}} on {{Mental Health}} and {{Remote Learning}}},
  author = {Moore, Stephanie and Veletsianos, George and Barbour, Michael},
  year = {2022},
  month = sep,
  journal = {The Open/Technology in Education, Society, and Scholarship Association Journal},
  volume = {1},
  number = {1},
  pages = {1--19},
  issn = {2564-4726},
  doi = {10.18357/otessaj.2022.1.1.36},
  urldate = {2022-11-08},
  abstract = {While there has been a lot of debate over the impact of online and remote learning on mental health and well-being, there has been no systematic syntheses or reviews of the research on this particular issue. In this paper, we review the research on the relationship between mental health/well-being and online or remote learning. Our review shows that little scholarship existed prior to 2020 with most studies conducted during the COVID-19 pandemic. We report four findings: (1) pandemic effects are not well-controlled in most studies; (2) studies present a very mixed picture, with variability around how mental health and well-being are measured and how/whether any causal inferences are made in relation to online and remote learning, (3) there are some indications that certain populations of students may struggle more in an online context, and (4) research that does not assume a direct relationship between mental health and online provides the best insight into both confounding factors and possible strategies to address mental health concerns. Our review shows that 75.5\% of published research on this topic either commits the correlation does not equal causation error or asserts a causal relationship even when it fails to establish correlations. Based on this study, we suggest that researchers, policymakers, practitioners, and administrators exercise extreme caution around making generalizable assertions with respect to the impacts of online/remote learning and mental health. We encourage further research to better understand effects on specific learner sub-populations and on course---and institution---level strategies to support mental health.},
  file = {/Users/colin.madland/Zotero/storage/M4UM6V5I/mooreSynthesisResearchMental2022.pdf}
}

@incollection{mooreTheoryTransactionalDistance1993,
  title = {Theory of Transactional Distance},
  shorttitle = {Theory of Transactional Distance},
  booktitle = {Theoretical {{Principles}} of {{Distance Education}}},
  author = {Moore, Michael},
  editor = {Keegan, Desmond},
  year = {1993},
  pages = {22--38},
  publisher = {Taylor \& Francis},
  file = {/Users/colin.madland/Zotero/storage/K7B8N2UM/Theoretical Principles of DE - Keegan.pdf}
}

@article{moorhouseConductingFormativeAssessment2022,
  title = {Conducting Formative Assessment during Synchronous Online Lessons: University Teachers' Challenges and Pedagogical Strategies},
  author = {Moorhouse, {\relax BL} and Kohnke, L},
  year = {2022},
  journal = {Pedagogies: An International Journal},
  volume = {18},
  number = {3},
  issn = {1554-480X},
  doi = {10.1080/1554480X.2022.2065993},
  abstract = {Synchronous online teaching through video-conferencing software (VCS) has become a common mode of instruction during the COVID-19 pandemic. This mode brings unique challenges for teachers that require specific professional digital competences. One such challenge is conducting formative assessment. Through the use of in-depth interviews with nine Hong Kong university teachers who had taught synchronously online for one semester, this exploratory study explored the challenges of conducting formative assessment during synchronous online lessons and the strategies teachers deploy to conduct formative assessment. The findings indicate that the key difficulties include gathering information on students' needs, checking students' understanding, giving individual feedback, and building relationships with students. To address these challenges, the teachers suggested four pedagogical strategies: (1) Combine synchronous with asynchronous approaches; (2) Utilise breakout rooms; (3) Utilise poll functions of the VCS and combine it with other online platforms; and (4) Provide time before or after lessons for informal conversations. The findings suggest that teachers need to develop specific pedagogical strategies to conduct formative assessment. This provides an initial conceptualisation of one important dimension of Professional Digital Competence, teaching using digital technologies, and one aspect of that dimension, how teachers use digital tools and strategies to conduct formative assessment.},
  langid = {english},
  keywords = {COVID-19,Formative assessment,HIGHER-EDUCATION,professional digital competence,PROFESSIONAL DIGITAL COMPETENCE,synchronous online teaching,teachers' assessment practices},
  file = {/Users/colin.madland/Zotero/storage/FUT5RWN5/moorhouseConductingFormativeAssessment2022.pdf}
}

@article{moProjectbasedLearningSystems2017,
  title = {Project-Based Learning of Systems Engineering {{V}} Model with the Support of {{3D}} Printing},
  author = {Mo, John P. T. and Tang, Y. M.},
  year = {2017},
  month = jan,
  journal = {Australasian Journal of Engineering Education},
  volume = {22},
  number = {1},
  pages = {3--13},
  issn = {2205-4952, 1325-4340},
  doi = {10.1080/22054952.2017.1338229},
  urldate = {2022-10-31},
  langid = {english}
}

@incollection{morales-arsenalHowDesignEfficient2022,
  title = {How to {{Design}} an {{Efficient Post-pandemic Online Exam}} in {{Management Science}}: {{A Bayesian Machine Learning Approach}}},
  booktitle = {{{LECT NOTE DATA ENG}}},
  author = {{Morales-Arsenal}, Roberto and {Pinar-P{\'e}rez}, Jes{\'u}s Mar{\'i}a},
  year = {2022},
  series = {Lecture {{Notes}} on {{Data Engineering}} and {{Communications Technologies}}},
  volume = {145},
  pages = {769--783},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-10385-8_55},
  abstract = {The outbreak of the COVID-19 pandemic in 2020 required higher education systems to quickly adapt to a distance learning environment, which was facilitated by the deployment of the hybrid (traditional and innovative) learning model. However, the development of online written exams has been the most difficult challenge due to the commitment to ensure that the quality objectives of student assessment are reliably met. This work analyses the evolution, and the relationship of grades in written exams to determine the characteristics of a suitable and reliable remote exam. The data used were collected from the subject of Decision Methods for management science. Additionally, a global effect of the pandemic on the students performance was analyzed. For this purpose, Bayesian machine learning methods of classification were employed. Empirical results show that a proper design of the online exam should combine the following elements: adjusted time, conceptual questions, total randomization, biometric monitoring systems and additional control elements. The results also indicate that, in general, there has not been a negative global effect on student performance, concluding that the most important variable for determining the final exam grade is the type of question.},
  isbn = {2367-4512},
  keywords = {Distance education,Engineering,Engineering Multidisciplinary,Exam design,Higher education,Operations Research & Management Science,Science & Technology,Technology}
}

@article{moreiraBetweenersSpeakChallenging2013,
  title = {Betweeners {{Speak Up}}: {{Challenging Knowledge Production}} through {{Collaborative Writing}} and {{Visceral Knowledge}} in {{Decolonizing Times}}},
  author = {Moreira, Claudio and Diversi, Marcelo},
  year = {2013},
  journal = {International Review of Qualitative Research},
  volume = {5},
  number = {4},
  pages = {399--406},
  issn = {1940-8447},
  doi = {10.1525/irqr.2012.5.4.399},
  abstract = {While writing together, we have found a dialogical voice that has made our individual work more meaningful, grounded, and fulfilling. Together, we have found a voice that we did not have in our work alone as individuals, a voice that seems, to both of us, more vibrant, truer to our experiences as betweeners and decolonizing scholars. This writing joint-venture exemplifies the very connectedness and co-construction of meaning we advocate in any type of social science preoccupied with empowering praxis. It is also an act of resistance to the academic ranking system and the idea that better work comes from isolated individuals. We have been friends since our late teens, long before each knew what career to pursue, and we have been closely connected from that time. Writing together seems, to us at least, like another important completion of the many intersecting experiences in our lives: friendship, global migration, profession, scholarship, knowledge production, and a keen attraction to a vision of inclusiveness.},
  keywords = {Arts,Behavioral sciences,Colonial literature,Communications,Education,Epistemology,Formal education,Friendship,Information life cycle,Information management,Information production,Information science,Interpersonal relations,Jurisprudence,Justice,Law,Literary history,Literary studies,Literature,Narratives,Pedagogy,Philosophy,Philosophy of law,Postcolonial literature,Psychology,Social justice,Social psychology,Social sciences,Writing,Written communication,Written narratives}
}

@article{moreiraDigitalLearningHigher2017,
  title = {Digital {{Learning}} in {{Higher Education}}: {{A Training Course}} for {{Teaching Online--Universidade Aberta}}, {{Portugal}}},
  author = {Moreira, Jos{\'e} Ant{\'o}nio and Jos{\'e} Ant{\'o}nio, Susana and Goul{\~a}o, Maria de F{\'a}tima and Barros, Daniela},
  year = {2017},
  journal = {Open Praxis},
  volume = {9},
  number = {2},
  pages = {253--263},
  issn = {EISSN-2304-070X},
  doi = {10/gmbv2z},
  abstract = {This paper uses qualitative evidence to describe, explore and discuss the progress of the online teaching training course taught at the Universidade Aberta to Portuguese and foreign professors of higher education institutions. As this is an entirely online course, its pedagogical design results from the combination of the basics of open distance education and network education using the Moodle 2.0 platform and other digital environments. The results point, on one hand, to a dynamic pedagogical design that addresses the need for continuous improvement, and, on the other hand, to the changes in the role of professors in virtual teaching and learning environments, and to the different and specific pedagogical strategies in need of adjustment. They also point to the strong presence of technological and pedagogical elements of innovation.},
  langid = {english},
  keywords = {College Faculty,Communities of Practice,Distance Education,Educational Technology,Electronic Publishing,Foreign Countries,Higher Education,Inservice Teacher Education,Integrated Learning Systems,Online Courses,Portfolios (Background Materials),Teacher Competencies,Teacher Education Programs,Technological Literacy,Technology Uses in Education}
}

@article{morelockUsingNovelResearch2020,
  title = {Using a {{Novel Research Methodology}} to {{Study}} and {{Respond}} to {{Faculty}} and {{Student Experiences}} with {{COVID-19}} in {{Real Time}}},
  author = {Morelock, John R. and Sochacka, Nicola W. and Lewis, Racheida S. and Walther, Joachim and Culloty, Christian M. and Hopkins, Jacob S. and Vedanarayanan, Shweta and Ofunne, Chukwuemeka K.},
  year = {2020},
  month = sep,
  journal = {Advances in Engineering Education},
  volume = {8},
  number = {4},
  publisher = {Advances in Engineering Education},
  issn = {1941-1766},
  abstract = {This paper describes the use of a novel research platform called SenseMaker{\textregistered} to collect and analyze real-time data in the form of participants' qualitative accounts of COVID-19 along with online learning experiences and participants' own quantitative assessments of those experiences. Participants were faculty, students, and staff in the College of Engineering at the University of Georgia during Spring 2020. Results from two waves of data collection informed real-time recommendations to College faculty and administration to address COVID-19-related challenges. Results also facilitated faculty development programming to build instructor communities of learning and support in response to the University's transition to online learning.},
  keywords = {Barriers,College Faculty,Communities of Practice,COVID-19,Data Analysis,Data Collection,Distance Education,Educational Technology,Electronic Learning,Engineering Education,Experience,Faculty Development,Georgia,No DOI found,Online Courses,Pandemics,Undergraduate Students}
}

@article{moreno-ruizCombiningFlippedClassroom2019,
  title = {Combining {{Flipped Classroom}}, {{Project-Based Learning}}, and {{Formative Assessment Strategies}} in {{Engineering Studies}}},
  author = {{Moreno-Ruiz}, L and {Castellanos-Nieves}, D and Braileanu, {\relax BP} and {Gonzalez-Gonzalez}, {\relax EJ} and {Sanchez-De La Rosa}, {\relax JL} and Groenwald, {\relax CLO} and {Gonzalez-Gonzalez}, {\relax CS}},
  year = {2019},
  journal = {International Journal of Engineering Education},
  volume = {35},
  number = {6},
  pages = {1673--1683},
  issn = {0949-149X},
  abstract = {This paper presents a methodology that encourages and fosters proactive student participation in individual and collaborative learning. The methodology combines Flipped Classroom, Formative Assessment and Continuous Assessment, Project-Based Learning, and Problem Solving using Simulators strategies, with an integrated teaching and learning system (ITLS), called SIENA. The tool serves to automate some of the processes inherent in the methodology and serves as a bridge across all of the educational process involved. The methodology has been tested in both undergraduate and postgraduate degrees in Computer Engineering studies, the former in a blended learning subject and the last in an online subject findings to date have proven positive. In addition, we have applied a unified theory of acceptance and use of technology model to ITLS and it has proven to be a useful tool in the learning process.},
  langid = {english},
  keywords = {ACCEPTANCE,active participation,collaborative learning,continuous assessment,DESIGN,flipped classroom,HIGHER-EDUCATION,learning performance,motivation,No DOI found,project-based learning,TECHNOLOGY}
}

@article{morganMovingAssessmentOnline2021,
  ids = {morganMovingAssessmentOnline2021a},
  title = {Moving {{Assessment Online}}: {{Experiences}} within a {{School}} of {{Pharmacy}}},
  author = {Morgan, Kelsey and Adams, Erin and Elsobky, Teresa and Darr, Amber and Brackbill, Marcia},
  year = {2021},
  journal = {Online Learning},
  volume = {25},
  number = {1},
  pages = {245--252},
  publisher = {Online Learning},
  issn = {ISSN-2472-5749},
  abstract = {The COVID-19 pandemic required academic institutions to quickly transition to online learning and make changes to assessment procedures. This study examines how a school of pharmacy creatively approached the challenge of online assessment while maintaining the standards necessary to prepare practice-ready student pharmacists. To conduct traditional exams, instructors deployed two different types of methods using testing software: a video conferencing technology approach which mimicked pre-pandemic, on-campus proctored exams; or open-book, internet access-enabled exams that ensured academic integrity and rigor through various testing strategies. To assess students' clinical skills, faculty used a combination of techniques such as physical examinations, patient interviews, and patient presentations. To understand the student experience with these assessments, students were surveyed using a 12-item questionnaire. Overall, online video proctoring maintained consistency in exam structure and administration, but required extensive instruction for both students and proctors. Students preferred unproctored, open-book, internet access-enabled, standard time exams versus proctored, closed-book, internet-access disabled, extended time exams. Changes to testing procedures, whether with proctored or unproctored methods, appeared to increase student stress.},
  langid = {english},
  keywords = {Cheating,Computer Assisted Testing,COVID-19,Distance Education,Electronic Learning,Evaluation Methods,No DOI found,Pandemics,Pharmaceutical Education,Simulation,Student Evaluation,Student Experience,Videoconferencing}
}

@misc{morganOpenPedagogyVery2016,
  title = {Open Pedagogy and a Very Brief History of the Concept},
  author = {Morgan, Tannis},
  year = {2016},
  month = dec,
  journal = {explorations in the ed tech world},
  urldate = {2018-10-15},
  abstract = {The good folks at \#OER17 have accepted my conference proposal on our University of Guadalajara faculty development program, which I positioned in the proposal as an example of an open pedagogy appr{\dots}},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/YIRME6QM/open-pedagogy-and-a-very-brief-history-of-the-concept.html}
}

@article{morongCulturallyResponsiveOnline2016,
  title = {Culturally Responsive Online Design: Learning at Intercultural Intersections},
  author = {Morong, Gail and DesBiens, Donna},
  year = {2016},
  journal = {Intercultural Education},
  volume = {27},
  number = {5},
  pages = {474--492},
  issn = {1467-5986},
  doi = {10.1080/14675986.2016.1240901},
  abstract = {This article presents evidence-based guidelines to inform culturally responsive online learning design in higher education. Intercultural understanding is now a recognised core learning outcome in a large majority of Canadian public universities; however, supporting design methodology is underdeveloped, especially in online contexts. Our search for valid intercultural learning design criteria began with two questions: What is the research evidence for learning design practices that support intercultural learning? In what ways do current course design rubrics address intercultural learning? For answers, first we explored recent literature reviews, articles, books, professional discourse on cultural aspects of learning, and the related internationalisation and Indigenous literatures on formal learning. Next, we examined three course design rubrics commonly used in Canada to identify practice supports and gaps in relation to the literature. Various research-indicated supports are present in these rubrics; however, major gaps include critical and holistic pedagogies, explicit intercultural learning outcomes, and intentional diversity group work. The proposed guidelines synthesise key research-indicated supports for intercultural learning and show how they can be integrated in core online course design components. The guidelines present a base for online design methodology to support intercultural learning and enable formative evaluation of pedagogy, learning activity and assessment applications.},
  keywords = {Canada,Cooperative Learning,critical discourse,Culturally Relevant Education,Distance Education,engaged pedagogies,Evidence Based Practice,Foreign Countries,Higher Education,Holistic Approach,Indigenisation,Indigenous Populations,Instructional Design,intercultural learning,International Education,internationalisation,Learning Activities,Multicultural Education,Online Courses,Online learning design,Outcomes of Education,Scoring Rubrics,State Universities,Teaching Methods}
}

@article{morrisReviewInformationLiteracy2020,
  title = {A {{Review}} of {{Information Literacy Programmes}} in {{Higher Education}}: {{The Effects}} of {{Face-to-Face}}, {{Online}} and {{Blended Formats}} on {{Student Perception}}},
  author = {Morris, Delyth},
  year = {2020},
  journal = {Journal of Information Literacy},
  volume = {14},
  number = {1},
  pages = {19--40},
  issn = {EISSN-1750-5968},
  doi = {10/gmbv3n},
  abstract = {This review will aim to establish if there is strong evidence to suggest a student preference for delivery format within information literacy teaching. This research supports and builds on research previously undertaken by Cardiff University (Weightman et al., 2017). Weightman et al (2017) addressed the effect of face-to-face or online learning specifically on learning outcomes. This review specifically focuses on the effects of these methods, and blended formats, on student preference. This research informs teaching practice specifically within Cardiff University's library service but also teaching practice generally. A comprehensive systematic literature search was undertaken in four databases: Library, Information Science and Technology Abstracts (LISTA), British Education Index, ERIC and Scopus. Seven new papers were identified to update the previous discussions on student preference of information literacy teaching format (Weightman et al., 2017). Critical appraisal was undertaken of these newly identified papers. Weightman et al.'s (2017) systematic review suggested that there was no student preference in relation to delivery format. Of the seven new papers identified in this review, two (DaCosta, 2007; Gorman \& Staley, 2018) show a slight preference for format; one for online and one for face-to-face although there are limitations to the studies. Of the five remaining studies (Craig \& Friehs, 2013; Kelly, 2017; Lag, 2016; Lapidus et al., 2012; Matlin \& Lantzy, 2017) all showed a comparable experience between formats, although limitations of these studies are also acknowledged. The update search and appraisal of the literature concurs with previous conclusions (Weightman et al., 2017) that experiences are comparable and student preference is generally neutral in relation to delivery format. Student learning outcomes and student preference are comparable regardless of format (Weightman et al., 2017).},
  langid = {english},
  keywords = {Blended Learning,College Students,Delivery Systems,Educational Research,Electronic Learning,Evidence Based Practice,Foreign Countries,Information Literacy,Library Instruction,Library Research,Preferences,Program Effectiveness,Synchronous Communication}
}

@book{morrisUrgencyTeachersWork2018,
  title = {An Urgency of Teachers: The Work of Critical Digital Pedagogy},
  shorttitle = {An Urgency of Teachers},
  author = {Morris, Sean Michael and Stommel, Jesse},
  year = {2018},
  publisher = {Hybrid Pedagogy},
  address = {United States},
  abstract = {This collection of essays explores the authors' work in, inquiry into, and critique of online learning, educational technology, and the trends, techniques, hopes, fears, and possibilities of digital pedagogy."--back cover},
  isbn = {978-0-692-15269-0},
  langid = {english},
  annotation = {OCLC: 1098198170}
}

@book{morrisWorkingTeams2005,
  title = {Working in {{Teams}}},
  author = {Morris, Terry},
  year = {2005},
  volume = {2010}
}

@article{mosalaLeaderIdentityIdentity2024,
  title = {Leader Identity and Identity Work: {{Enhancing}} Coaching of Leaders in Changing Contexts},
  shorttitle = {Leader Identity and Identity Work},
  author = {Mosala, Thabo and Bennett, Kathy},
  year = {2024},
  publisher = {Oxford Brookes University},
  doi = {10.24384/WM88-KE86},
  urldate = {2024-09-27},
  file = {/Users/colin.madland/Zotero/storage/mosalaLeaderIdentityIdentity2024.pdf}
}

@incollection{moscropTechnologyEnhancedAssessmentFeedback2017,
  title = {Technology-{{Enhanced Assessment Feedback}}},
  booktitle = {Scaling up {{Assessment}} for {{Learning}} in {{Higher Education}}},
  author = {Moscrop, Claire and Beaumont, Chris},
  editor = {Carless, David and Bridges, Susan M. and Chan, Cecilia Ka Yuk and Glofcheski, Rick},
  year = {2017},
  volume = {5},
  pages = {193--207},
  publisher = {Springer Singapore},
  address = {Singapore},
  doi = {10.1007/978-981-10-3045-1_13},
  urldate = {2022-05-07},
  isbn = {978-981-10-3043-7 978-981-10-3045-1},
  file = {/Users/colin.madland/Zotero/storage/CY2D2MGR/moscropTechnologyEnhancedAssessmentFeedback2017.pdf}
}

@article{moskalCanYouIncrease2016,
  title = {Can You Increase Teacher Engagement with Evaluation Simply by Improving the Evaluation System?},
  author = {Moskal, Adon C. M. and Stein, Sarah J. and Golding, Clinton},
  year = {2016},
  month = feb,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {41},
  number = {2},
  pages = {286--300},
  publisher = {Taylor \& Francis},
  issn = {0260-2938},
  doi = {10.1080/02602938.2015.1007838},
  abstract = {We know various factors can influence how teaching staff engage with student evaluation, such as institutional policies or staff beliefs. However, little research has investigated the influence of the technical processes of an evaluation system. In this article, we present a case study of the effects of changing the technical system for administering student evaluations at one New Zealand university. We develop a socio-technical model of the institutional evaluation system, and use this model to examine whether introducing an online system for ordering student feedback questionnaires and reducing processing time influenced academic staff engagement with evaluation. Survey responses, interview comments and data about ordering trends suggest the change did increase staff engagement by: (1) improving staff perceptions of evaluation and (2) increasing engaged behaviour, such as voluntarily ordering more evaluations. The outcomes of this study imply that the `practical implementation' of an evaluation system is an important factor in influencing engagement with evaluation. We conclude that we can increase teacher engagement with evaluation simply by improving the `practical implementation' of the evaluation system. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {engagement,Evaluation,socio-technical approach,Student Engagement,student evaluation,Teacher Attitudes,teacher perceptions,Teachers,Teaching,Teaching Methods}
}

@book{mossAssessmentEquityOpportunity2008,
  title = {Assessment, {{Equity}}, and {{Opportunity}} to {{Learn}}},
  editor = {Moss, Pamela A. and Pullin, Diana C. and Gee, James Paul and Haertel, Edward H. and Young, Lauren Jones},
  year = {2008},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9780511802157},
  urldate = {2020-10-09},
  isbn = {978-0-511-80215-7},
  file = {/Users/colin.madland/Zotero/storage/WLQM8BKQ/mossAssessmentEquityOpportunity2008.pdf}
}

@article{mossReconceptualizingValidityClassroom2005,
  title = {Reconceptualizing {{Validity}} for {{Classroom Assessment}}},
  author = {Moss, Pamela A.},
  year = {2005},
  month = oct,
  journal = {Educational Measurement: Issues and Practice},
  volume = {22},
  number = {4},
  pages = {13--25},
  issn = {07311745, 17453992},
  doi = {10/bkxm42},
  urldate = {2020-09-30},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/ZQU2632T/mossReconceptualizingValidityClassroom2005.pdf}
}

@article{mossReconstructingValidity2007,
  title = {Reconstructing {{Validity}}},
  author = {Moss, Pamela A.},
  year = {2007},
  month = nov,
  journal = {Educational Researcher},
  volume = {36},
  number = {8},
  pages = {470--476},
  publisher = {American Educational Research Association},
  issn = {0013-189X},
  doi = {10.3102/0013189X07311608},
  urldate = {2023-07-04},
  abstract = {In response to Lissitz and Samuelsen (2007), the author reconstructs the historical arguments for the more comprehensive unitary concept of validity and the principles of scientific inquiry underlying it. Her response is organized in terms of four questions: (a) How did validity in educational measurement come to be conceptualized as unitary, and why? (b) What is construct validity, and how does it provide the basis for a unitary concept of validity? (c) Why has the focus of validity been on the interpretations and uses of test scores rather than on the test itself? and (d) What sort of guidance for test developers and evaluators has been provided within a unitary concept of validity, and how might it be enhanced? The author highlights the role that cases of programmatic validity research can play in representing validity theory and guiding validity inquiry.},
  file = {/Users/colin.madland/Zotero/storage/E5UJGGFX/mossReconstructingValidity2007.pdf}
}

@article{mossShiftingConceptionsValidity1992,
  title = {Shifting {{Conceptions}} of {{Validity}} in {{Educational Measurement}}: {{Implications}} for {{Performance Assessment}}},
  shorttitle = {Shifting {{Conceptions}} of {{Validity}} in {{Educational Measurement}}},
  author = {Moss, Pamela A.},
  year = {1992},
  month = sep,
  journal = {Review of Educational Research},
  volume = {62},
  number = {3},
  pages = {229--258},
  issn = {0034-6543, 1935-1046},
  doi = {10/cg49kp},
  urldate = {2020-10-08},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/YQ4TPWWL/mossShiftingConceptionsValidity1992.pdf}
}

@incollection{mossSocioculturalImplicationsAssessment2008,
  title = {Sociocultural {{Implications}} for {{Assessment I}}},
  booktitle = {Assessment, {{Equity}}, and {{Opportunity}} to {{Learn}}},
  author = {Moss, Pamela A.},
  editor = {Pullin, Diana C. and Haertel, Edward H. and Gee, James Paul and Young, Lauren Jones and Moss, Pamela A.},
  year = {2008},
  series = {Learning in {{Doing}}: {{Social}}, {{Cognitive}} and {{Computational Perspectives}}},
  pages = {222--258},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9780511802157.011},
  abstract = {In this chapter, I develop the implications of the earlier chapters -- on sociocultural and situative perspectives -- for the practice of classroom assessment. In chapter 11, Moss, Girard, and Greeno further develop the implications of these perspectives for assessment that crosses the boundaries -- from the classroom to the school and from the school to the district, external organization, or beyond -- to serve purposes of professional learning, evaluation, and accountability.Perhaps the central message of the previous chapters on sociocultural and situative (SC/S) perspectives is that if we want to foster learning and opportunity to learn (OTL), we need to understand the dynamic ``relationship between learners and their learning environment'' (Gee, this volume, chapter 4). This includes the relationship between learners and the physical and conceptual tools in their environment; it also includes the relationship between learners and the other people in their environment. In fact, from an SC/S perspective, learning is routinely conceptualized in terms of changes in these relationships. Learners participate more proficiently in the community's activities, disciplinary concepts take on new meanings as they are put to work in solving problems, and so on. Even if one views learning as change in mental representations, the mental representation can only be acquired and demonstrated through interactions between learners and the tools and/or other people in their environment. There is no unmediated access to learning (Gee, this volume, chapter 4).},
  isbn = {978-0-521-88045-9}
}

@incollection{mossSocioculturalImplicationsAssessment2008a,
  title = {Sociocultural {{Implications}} for {{Assessment II}}},
  booktitle = {Assessment, {{Equity}}, and {{Opportunity}} to {{Learn}}},
  author = {Moss, Pamela A. and Girard, Brian J. and Greeno, James G.},
  editor = {Pullin, Diana C. and Haertel, Edward H. and Gee, James Paul and Young, Lauren Jones and Moss, Pamela A.},
  year = {2008},
  series = {Learning in {{Doing}}: {{Social}}, {{Cognitive}} and {{Computational Perspectives}}},
  pages = {295--332},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9780511802157.013},
  abstract = {This chapter takes up issues of opportunity to learn (OTL) and assessment at the level of schools, considered as organizations. An effort directed toward improving OTL for students in a school is an effort to bring about learning by the organization that is that school. The question we address is part of the general question of OTL for an organization: What kinds of resources, programs, and commitments may be needed or helpful in an effort to improve the learning effectiveness of a school? In keeping with the focus of this volume, we concentrate on issues of obtaining and using information to evaluate and support an organization's progress in changing its practices and achieving stronger OTL.In Chapter 9, Moss focuses on the practice of assessment, broadly conceived, within a single (classroom) activity system. Here, we enlarge that focus. Assessments and evaluations used to inform changes in practice across a school are practices that cross the boundaries of activity systems to support professional learning, decision making, and accountability. Here, we consider aspects of such practices, especially ways in which teachers and other participants are positioned in the processes.We begin with the premise that assessment is (or should be) at least, in part, about professionals learning to support students' learning and, in turn, to support one another's learning. Another way of saying this is that it should be about OTL for the professionals in the educational system as well as for students.},
  isbn = {978-0-521-88045-9}
}

@article{mostafaEvaluatingUniversityEassessment2023,
  title = {Evaluating University {{E-assessment}} in {{Egypt}}: {{A}} Teachers' Perspective},
  author = {Mostafa, Lamiaa},
  year = {2023},
  journal = {Journal of education for business},
  volume = {ahead-of-print},
  number = {ahead-of-print},
  pages = {1--9},
  publisher = {Routledge},
  issn = {0883-2323},
  doi = {10.1080/08832323.2023.2208813},
  abstract = {COVID-19 forced educational institutions to work digitally. Universities were not prepared for online assessment during the lockdown. Teachers faced many challenges when assessing students online; they were afraid that they produced inefficient or fake results. This study aims to understand the factors that affect the efficiency of e-assessment from the teachers' perspective. Many factors affect the e-exam efficiency, such as university readiness, educator readiness, plagiarism, cheating, type of assessment, and technical issues. Two hundred sixty-eight teachers were invited to fill in the questionnaire. This study concludes that university readiness, educator readiness, and type of assessment have a positive significant impact on e-exam efficiency, while plagiarism, cheating, and technical issues negatively affect e-exam efficiency Implications for practice are discussed.},
  keywords = {Assessment,E-assessment,Egypt,teacher,university}
}

@article{mottBestPracticesAdult2003,
  title = {Best {{Practices}} in {{Adult}} and {{Continuing Education}}: {{Dialogues}} about {{What Works}}},
  author = {Mott, Vivian W.},
  year = {2003},
  journal = {Adult Learning},
  volume = {14},
  number = {2},
  pages = {4--5},
  abstract = {The article introduces a series of articles that deal with issues related to adult and continuing education.},
  keywords = {ADULT,CONTINUING,Education},
  annotation = {Accession Number: 20961704; Mott, Vivian W. 1; Affiliation: 1: Associate professor and interim chair, Counselor and Adult Education Department, East Carolina University, Greenville, North Carolina; Source Info: Spring2003, Vol. 14 Issue 2, p4; Subject Term: ADULT education; Subject Term: CONTINUING education; NAICS/Industry Codes: 611430 Professional and Management Development Training; Number of Pages: 2p; Document Type: Article}
}

@article{mottOpenLearningCMS2009,
  title = {Open for {{Learning}}: {{The CMS}} and the {{Open Learning Network}}},
  shorttitle = {Open for {{Learning}}},
  author = {Mott, Jon and Wiley, David},
  year = {2009},
  journal = {in education},
  volume = {15},
  number = {2},
  issn = {1927-6117},
  urldate = {2019-08-26},
  abstract = {The course management system (CMS) reinforces the status quo and hinders  substantial teaching and learning innovation in higher education. It  does so by imposing artificial time limits on learner access to course  content and other learners, privileging the role of the instructor at  the expense of the learner, and limiting the power of the network effect  in the learning process. The open learning network (OLN)---a hybrid of  the CMS and the personal learning environment (PLE)---is proposed as an  alternative learning technology environment with the potential to  leverage the affordances of the Web to dramatically improve learning.Keywords: course management system; higher education; open learning network; personal learning environment; technology; internet},
  copyright = {Copyright (c)},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/4ACTN6J4/mottOpenLearningCMS2009.pdf;/Users/colin.madland/Zotero/storage/9UC4TV8V/53.html}
}

@book{mouraHandbookResearchDetermining2021,
  title = {Handbook of {{Research}} on {{Determining}} the {{Reliability}} of {{Online Assessment}} and {{Distance Learning}}:},
  shorttitle = {Handbook of {{Research}} on {{Determining}} the {{Reliability}} of {{Online Assessment}} and {{Distance Learning}}},
  editor = {Moura, Ana S. and Reis, Pedro and Cordeiro, M. Nat{\'a}lia D. S. and {Ord{\'o}{\~n}ez de Pablos}, Patricia},
  year = {2021},
  series = {Advances in {{Mobile}} and {{Distance Learning}}},
  publisher = {IGI Global},
  doi = {10.4018/978-1-7998-4769-4},
  urldate = {2021-07-03},
  isbn = {978-1-7998-4769-4 978-1-7998-4770-0}
}

@article{moyaAcademicIntegrityArtificial2024,
  title = {Academic Integrity and Artificial Intelligence in Higher Education Contexts: {{A}} Rapid Scoping Review},
  author = {Moya, Beatriz Antonieta and Eaton, Sarah Elaine and Pethrick, Helen and Hayden, K Alix and Brennan, Robert and Wiens, Jason and McDermott, Brenda},
  year = {2024},
  journal = {Canadian Perspectives on Academic Integrity},
  volume = {7},
  number = {3},
  pages = {1--19},
  abstract = {Artificial intelligence (AI) developments challenge higher education institutions' teaching, learning, assessment, and research practices. To contribute evidence-based recommendations for upholding academic integrity, we conducted a rapid scoping review focusing on what is known about academic integrity and AI in higher education before the emergence of ChatGPT. We followed the Updated Reviewer Manual for Scoping Reviews from the Joanna Briggs Institute (JBI) and the Preferred Reporting Items for Systematic reviews Meta-Analysis for Scoping Reviews (PRISMA-ScR) reporting standards. Five databases were searched, and the eligibility criteria included higher education stakeholders of any age and gender engaged with AI in the context of academic integrity from 2007 through November 2022 and available in English. The search retrieved 2,223 records, of which 14 publications with mixed methods, qualitative, quantitative, randomized controlled trials, and text and opinion studies met the inclusion criteria. The results showed bounded and unbounded ethical implications of AI. Perspectives included: AI for cheating; AI as legitimate support; an equity, diversity, and inclusion lens into AI; and emerging recommendations to tackle AI implications in higher education. The evidence from the sources provides guidance that can inform educational stakeholders in decision-making processes for AI integration, in the analysis of misconduct cases involving AI, and in the exploration of AI as legitimate assistance. Likewise, this rapid scoping review signals possibilities for future research, which we explore in our discussion.},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/ADATNY3M/moyaAcademicIntegrityArtificial2024.pdf}
}

@article{moyafigueroaExaminingRecommendationsArtificial2023,
  title = {Examining {{Recommendations}} for {{Artificial Intelligence Use}} with {{Integrity}} from a {{Scholarship}} of {{Teaching}} and {{Learning Lens}}},
  author = {Moya Figueroa, Beatriz Antonieta and Eaton, Sarah Elaine},
  year = {2023},
  month = dec,
  journal = {RELIEVE - Revista Electr{\'o}nica de Investigaci{\'o}n y Evaluaci{\'o}n Educativa},
  volume = {29},
  number = {2},
  issn = {1134-4032},
  doi = {10.30827/relieve.v29i2.29295},
  urldate = {2024-01-02},
  abstract = {New developments in the Artificial Intelligence (AI) field allowed the development of Generative Artificial Intelligence (GenAI), capable of creating text resembling what humans can produce. As a result, educators' concerns in the higher education sector quickly emerged. Many organizations and experts have addressed these concerns through recommendations. In this conceptual paper, we draw from the Integrated Model for Academic Integrity through a Scholarship of Teaching and Learning Lens to examine and stimulate discussion from eleven documents that focus on using GenAI with integrity. We identified recommendations suitable for the individual (micro), the departmental/program (meso), the institutional (macro), and the interinstitutional/ national/ international (mega) levels concerning two core elements of the model: ``high-impact professional learning for individuals and groups'' and ``local-level leadership and microcultures.'' Suggestions around the core element ``scholarship, research and inquiry'' were lacking at the micro and meso levels; likewise, recommendations for the core element ``learning spaces, pedagogies, and technologies'' were also absent at the meso, macro, and mega levels. We acknowledge that these recommendations focus on learning, involve various stakeholders, and go beyond student conduct, which aligns with current approaches to academic integrity. However, some gaps need further exploration. We highlight the need to develop more specific and practical guidance and resources for educational stakeholders around GenAI issues related to academic integrity, explore how to better support networks and leaders in higher education in creating the conditions for ethical GenAI use, and emphasizing the need for an Equity, Diversity, and Inclusion lens on GenAI.},
  file = {/Users/colin.madland/Zotero/storage/G38Z4AIX/moyafigueroaExaminingRecommendationsArtificial2023.pdf}
}

@article{mphahleleUseTurnitinHigher2019,
  title = {The {{Use}} of {{Turnitin}} in the {{Higher Education Sector}}: {{Decoding}} the {{Myth}}},
  author = {Mphahlele, Amanda and McKenna, Sioux},
  year = {2019},
  month = jan,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {44},
  number = {7},
  pages = {1079--1089},
  publisher = {Assessment \& Evaluation in Higher Education},
  issn = {0260-2938},
  doi = {10.1080/02602938.2019.1573971},
  abstract = {Plagiarism needs to be addressed to maintain academic standards and to safeguard the integrity of the academic project. With the evolving digital world, conventional methods of addressing plagiarism are gradually being dismissed in favour of new technologies. Unfortunately, there is a general misunderstanding about what such technologies do. This paper was written from a PhD study, and looks at how such misunderstandings emerge across the higher education sector of one country. Institutional policies and other documents related to plagiarism were analysed from public universities across South Africa, and this was then augmented with interviews with members of institutional plagiarism committees. The results of the study revealed that technology is a key facet in these universities' attempts to reduce the incidents of plagiarism, and that Turnitin is the most favored text-matching tool. However, the software is misunderstood to be predominantly a plagiarism detection tool for policing purposes, ignoring its educational potential for student development. The implication is that, if Turnitin is primarily used as a policing tool, students are not only denied access to nuanced pedagogical interventions that might develop their academic writing, but its misuse could also change students' behavior in undesirable ways.},
  keywords = {Computer Software,Computer Uses in Education,Foreign Countries,Higher Education,Misconceptions,Plagiarism,Public Colleges,School Culture,School Policy,South Africa}
}

@incollection{mukerjiConceptualFrameworkEAssessment2013,
  title = {A {{Conceptual Framework}} for {{E-Assessment}} in {{Higher Education}}: {{Authenticity}}, {{Consistency}}, {{Transparency}}, and {{Practicability}}},
  author = {Mukerji, Siran and Tripathi, Purnendu},
  year = {2013},
  pages = {652--673},
  publisher = {IGI Global},
  doi = {10.4018/978-1-4666-4458-8.ch033},
  abstract = {The integration of new technology and global collaboration has undoubtedly transformed learning in higher education from the traditional classroom setting into a domain of support services, academic programs, and educational products which are made available to learners. The Handbook of Research on Transnational Higher Education is a unique compilation of the most recent research done by higher education professionals in the areas of policy, governance, technology, marketing, and leadership development. This publication succeeds in highlighting the most important strategies and policies for professionals, policymakers, administrators, and researchers interested in higher education management. The integration of new technology and global collaboration has undoubtedly transformed learning in higher education from the traditional classroom setting into a domain of support services, academic programs, and educational products which are made available to learners. The Handbook of Research on Transnational Higher Education is a unique compilation of the most recent research done by higher education professionals in the areas of policy, governance, technology, marketing, and leadership development. This publication succeeds in highlighting the most important strategies and policies for professionals, policymakers, administrators, and researchers interested in higher education management.},
  isbn = {1-4666-4458-3},
  keywords = {Educational Science and Technology,Higher Education},
  file = {/Users/colin.madland/Zotero/storage/NUE7U66Y/mukerjiConceptualFrameworkEAssessment2013.pdf}
}

@phdthesis{mullerDesigningEffectiveMultimedia2008,
  title = {Designing Effective Multimedia for Physics Education},
  shorttitle = {Designing Effective Multimedia for Physics Education},
  author = {Muller, Derek},
  year = {2008},
  address = {Sydney},
  abstract = {This thesis summarizes a series of investigations into how multimedia can be designed to promote the learning of physics. The `design experiment' methodology was adopted for the study, incorporating different methods of data collection and iterated cycles of design, evaluation, and redesign. Recently much research has been conducted on learning with multimedia, usually from a cognitive science perspective. Principles of design developed in this way have not often been tested in naturalistic settings, however. Therefore in one preliminary investigation students' perceptions of a popular science video were investigated. Opinions aligned well with most principles though areas for further research were identified. In order to understand the challenges and opportunities presented by physics teaching, a survey of all lecture courses on the topic of quantum mechanics was undertaken. The lectures were a sophisticated form of multimedia, however interactivity in all lectures was low. The learning that results from this teaching was evaluated using a questionnaire on quantum tunneling, a key quantum mechanical phenomenon. The survey revealed that students had many alternative conceptions on the topic and that these could be grouped into a small number of alternative answers. This finding is similar to many of the findings from science education over the past three decades. Using this background, two multimedia treatments were developed to teach the topic of quantum tunneling. One consisted of a lecture-style explanation with only correct information presented. The other took the form of a dialogue between a tutor and student, involving several of the common alternative conceptions. Students who saw the Dialogue performed significantly better on the post-test than those who saw viii the Exposition. In order to generalize the findings, four multimedia treatments on Newton's first and second laws were created and evaluated in a similar way. A refutationary treatment, in which alternative conceptions were stated and refuted by a single speaker, and an Extended Exposition treatment were evaluated in addition to the Dialogue and Exposition. The Dialogue and Refutation outperformed the two expository treatments, confirming the benefits of including alternative conceptions. In a third iteration of the design experiment, four Newtonian mechanics treatments were evaluated with a new cohort of students. The Extended Exposition was replaced by aWorked Examples treatment in which important details were repeated to solve numerical problems. Cognitive load was directly measured in this experiment. Results showed that treatments containing alternative conceptions involved higher cognitive load and resulted in higher post-test scores than the other treatments. ix},
  school = {University of Sydney},
  file = {/Users/colin.madland/Zotero/storage/7H9E8TDA/PhD(Muller).pdf}
}

@article{mullerSayingWrongThing2008,
  title = {Saying the Wrong Thing: {{Improving}} Learning with Multimedia by Including Misconceptions},
  author = {Muller, D. A. and Bewes, J. and Sharma, M. D. and Reimann, P.},
  year = {2008},
  journal = {Journal of Computer Assisted Learning},
  volume = {24},
  number = {2},
  pages = {144--155},
  abstract = {In this study, 364 first-year physics students were randomly assigned to one of four online multimedia treatments on Newton's First and Second Laws of Motion: (1) the {\quotesinglbase}{\"A}{\`o}Exposition{\quotesinglbase}{\"A}{\^o}, a concise lecture-style presentation; (2) the {\quotesinglbase}{\"A}{\`o}Extended Exposition{\quotesinglbase}{\"A}{\^o}, the Exposition with additional interesting information; (3) the {\quotesinglbase}{\"A}{\`o}Refutation{\quotesinglbase}{\"A}{\^o}, the Exposition with common misconceptions explicitly stated and refuted; or (4) the {\quotesinglbase}{\"A}{\`o}Dialogue{\quotesinglbase}{\"A}{\^o}, a student{\quotesinglbase}{\"A}{\`i}tutor discussion of the same material as in the Refutation. Students were tested using questions from mechanics conceptual inventories before and after watching the multimedia treatments. Results show the Refutation and Dialogue produced the greatest learning gains, with effect sizes of 0.79 and 0.83, respectively, compared with the Exposition. Students with low prior knowledge benefited most, however high prior knowledge learners were not disadvantaged by the misconception-based approach. The findings suggest that online multimedia can be greatly improved, promoting conceptual change in students with all levels of experience, by including a discussion of misconceptions. [ABSTRACT FROM AUTHOR] Copyright of Journal of Computer Assisted Learning is the property of Wiley-Blackwell and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
  keywords = {Isaac,Sir},
  annotation = {Accession Number: 31207084; Muller, D.A.; Bewes, J. 1; Sharma, M.D. 1; Reimann, P. 2; Affiliations: 1 : *School of Physics, University of Sydney, New South Wales, Australia; 2 : {\quotesinglbase}{\"A}{\dag}Faculty of Education and Social Work, University of Sydney, New South Wales, Australia; Source Info: Apr2008, Vol. 24 Issue 2, p144; Thesaurus Term: INTERNET in education; Thesaurus Term: COMPUTERS in education; Thesaurus Term: COMPUTER assisted instruction; Thesaurus Term: PHYSICS -- Study \& teaching; Thesaurus Term: RESEARCH; Thesaurus Term: EDUCATION -- Audio-visual aids; Thesaurus Term: INTERNET in higher education; Thesaurus Term: COMMUNICATION \& education; Thesaurus Term: TUTORS \& tutoring; Thesaurus Term: STUDENTS -- Services for; Thesaurus Term: STUDENTS -- Rating of; Thesaurus Term: MOTION -- Study \& teaching; Author-Supplied Keyword: cognitive load theory; Author-Supplied Keyword: conceptual change; Author-Supplied Keyword: misconceptions; Author-Supplied Keyword: multimedia learning; Author-Supplied Keyword: physics education research; Author-Supplied Keyword: vicarious learning; Number of Pages: 12p; Illustrations: 1 Diagram, 3 Charts, 1 Graph; Document Type: Article}
}

@incollection{multonOrdinalScale2010,
  title = {Ordinal {{Scale}}},
  booktitle = {Encyclopedia of {{Research Design}}},
  author = {Multon, Karen D and Coleman, Jill S},
  editor = {Salkind, Neil},
  year = {2010},
  publisher = {SAGE Publications, Inc.},
  address = {2455 Teller Road,~Thousand Oaks~California~91320~United States},
  doi = {10.4135/9781412961288.n294},
  urldate = {2021-08-05},
  isbn = {978-1-4129-6127-1 978-1-4129-6128-8},
  file = {/Users/colin.madland/Zotero/storage/6ZI6WQ27/multonOrdinalScale2010.pdf}
}

@incollection{mumtazParticipatoryActionbasedDesign2015,
  title = {Participatory Action-Based Design Research},
  booktitle = {Creating Together: Participatory, Community-Based, and Collaborative Arts Practices and Scholarship across {{Canada}}},
  author = {Mumtaz, Naureen},
  editor = {Conrad, Diane Helen and Sinner, Anita},
  year = {2015},
  pages = {51--68},
  publisher = {Wilfrid Laurier University Press},
  address = {Waterloo, Ontario},
  isbn = {978-1-77112-023-4},
  lccn = {NX280 .C76 2015},
  keywords = {Arts,Canada,Citizen participation Methodology,Learning and scholarship,Methodology,Research,Research Methodology},
  file = {/Users/colin.madland/Zotero/storage/WKUVDIQ6/mumtazParticipatoryActionbasedDesign2015.pdf}
}

@article{munifPerformanceAssessmentTeachers2019,
  title = {Performance {{Assessment}}: {{Teachers Beliefs}} and {{Practices}} in {{Higher Education}}},
  author = {Munif, Lukluk Argita and Fauziati, Endang and Marmanto, Sri},
  year = {2019},
  journal = {Journal of Education and Learning (EduLearn)},
  volume = {13},
  number = {4},
  pages = {518--526},
  issn = {ISSN-2089-9823},
  doi = {10/gmbvzr},
  abstract = {In educating the students, teachers' beliefs on teaching and learning influenced not only on what to teach and how to do it, but also on how to assess their students. Education has a goal that students can apply the knowledge gained in real world activities. Through assessment process, it helps them to understand their strengths and weaknesses of their abilities development. This research aims to find out teachers' beliefs about performance assessment and how they use it to assess their students in one of public college under The Ministry of Industry in Indonesia. Data findings are obtained by using interviews, observation and document analysis conducted on T1 and T2 as the participants. Researcher used the five elements of performance assessment to make the instruments and analyze the findings. Results indicated that there were differences between what they say and what they do. The differences appeared because of the theories they knew, their own knowledge and experiences they have in teaching.},
  langid = {english},
  keywords = {Beliefs,College Faculty,Foreign Countries,Performance Based Assessment,Scoring,Student Educational Objectives,Student Evaluation,Teacher Attitudes,Test Format}
}

@article{munroeDecolonizingAboriginalEducation2013,
  title = {Decolonizing {{Aboriginal Education}} in the 21st {{Century}}},
  author = {Munroe, Elizabeth Ann and {Lunney-Borden}, Lisa and {Murray-Orr}, Anne and Toney, Denise and Meader, Jane},
  year = {2013},
  journal = {McGill Journal of Education},
  volume = {48},
  number = {2},
  pages = {317},
  issn = {0024-9033},
  abstract = {Concerned by the need to decolonize education for Aboriginal students, the authors explore philosophies of Indigenous ways of knowing and those of the 21st century learning movement. In their efforts to propose a way forward with Aboriginal education, the authors inquire into harmonies between Aboriginal knowledges and tenets of 21st century education. Three stories from the authors' research serve as examples of decolonizing approaches that value the congruence between 21st century education and Indigenous knowledges. These stories highlight the need for two-eyed seeing, co-constructing curriculum for language and culture revitalization, and drawing from community contexts to create curriculum.;~ Concerned by the need to decolonize education for Aboriginal students, the authors explore philosophies of Indigenous ways of knowing and those of the 21st century learning movement. In their efforts to propose a way forward with Aboriginal education, the authors inquire into harmonies between Aboriginal knowledges and tenets of 21st century education. Three stories from the authors' research serve as examples of decolonizing approaches that value the congruence between 21st century education and Indigenous knowledges. These stories highlight the need for two-eyed seeing, co-constructing curriculum for language and culture revitalization, and drawing from community contexts to create curriculum. [PUBLICATION ABSTRACT];},
  keywords = {American Indian Education,Canada,Canada Natives,Curriculum,Education,Educational Assessment,Educational Change,Educational Principles,Elementary School Science,Foreign Countries,Foreign Policy,Gender,Grade 2,Immersion Programs,Indigenous Knowledge,Instruction,Integrated Curriculum,Intergenerational Programs,Junior High Schools,Learning,Mathematics,Native education,Native peoples,Nova Scotia,Parent Attitudes,Secondary School Mathematics,Vignettes}
}

@article{murrayEthicalPrinciplesCollege1996,
  title = {Ethical Principles for College and University Teaching},
  author = {Murray, Harry and Gillese, Eileen and Lennon, Madeline and Mercer, Paul and Robinson, Marilyn},
  year = {1996},
  month = jun,
  journal = {New Directions for Teaching and Learning},
  volume = {1996},
  number = {66},
  pages = {57--63},
  issn = {0271-0633, 1536-0768},
  doi = {10.1002/tl.37219966611},
  urldate = {2024-11-05},
  abstract = {Abstract             Designing, carrying out, and analyzing instruction requires taking into account certain ethical guidelines, ideals, and expectations.},
  copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/murrayEthicalPrinciplesCollege1996.pdf}
}

@misc{MythTechExceptionalism,
  title = {The {{Myth}} of {{Tech Exceptionalism}}},
  journal = {NOEMA},
  urldate = {2022-02-14},
  abstract = {How tech uses the promise of endless innovation to ward off regulating even its present-day harms.},
  howpublished = {https://www.noemamag.com/the-myth-of-tech-exceptionalism},
  langid = {american},
  keywords = {archived},
  annotation = {https://web.archive.org/web/20220210193743/https://www.noemamag.com/the-myth-of-tech-exceptionalism/},
  file = {/Users/colin.madland/Zotero/storage/DI6XG2PI/the-myth-of-tech-exceptionalism.html}
}

@article{nacheva-skopalikIntelligentAdaptableEassessment2016,
  title = {Intelligent Adaptable E-Assessment for Inclusive e-Learning},
  author = {{Nacheva-Skopalik}, Lilyana and Green, Steve},
  year = {2016},
  month = jan,
  journal = {International Journal of Web-Based Learning and Teaching Technologies},
  volume = {11},
  number = {1},
  pages = {21--34},
  publisher = {IGI Global},
  issn = {1548-1093},
  doi = {10.4018/IJWLTT.2016010102},
  abstract = {Access to education is one of the main human rights. Everyone should have access to education and be capable of benefiting from it. However there are a number who are excluded, not because of a lack of ability but simply because they have a disability or specific need which current education systems do not address. A learning system in which content, tools and interfaces can be personalised and adapted to the individual needs and preferences of a variety of learners, including those with disabilities, becomes inclusive. Assessment is an integral part of an e-learning environment and therefore it has to provide not only inclusive e-learning content but also inclusive e-assessment. The proposed research investigates an intelligent adaptable e-learning system for assessing students' level of skill, knowledge and understanding regardless of their disabilities or accessibility needs. It is based on an innovative use of world's first open source adaptable widget design and authoring toolkit (WIDGaT) as the prototyping environment. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {Accessibility,Adaptability,Distance Education,E-assessment,E-learning,Internet,Learning,Learning Environment,Measurement,Personal Learning Environment,Social Inclusion}
}

@article{nadarajahStudentSuicideOnCampus2021,
  title = {Student {{Suicide}} On-{{Campus}}: {{Tort Liability}} of {{Canadian Universities}} and {{Determining}} a {{Duty}} of {{Care}}},
  shorttitle = {Student {{Suicide}} On-{{Campus}}},
  author = {Nadarajah, Shailaja},
  year = {2021},
  journal = {Appeal: Review of Current Law and Law Reform},
  volume = {26},
  pages = {97--120},
  urldate = {2023-09-29},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/6SUK52H4/nadarajahStudentSuicideOnCampus2021.pdf}
}

@article{nadeauEducatingBodiesSelfDetermination2006,
  title = {Educating {{Bodies}} for {{Self-Determination}}: {{A Decolonizing Strategy}}},
  author = {Nadeau, Denise and Young, Alannah},
  year = {2006},
  journal = {Canadian Journal of Native Education},
  volume = {29},
  number = {1},
  pages = {87},
  issn = {0710-1481},
  abstract = {The transformation of the effects of sexual, racial, and colonial violence on Aboriginal people requires unlearning ways of thinking and being. This process involves a reaffirmation of Indigenous Knowledge and pedagogy. This article examines a program developed for urban Aboriginal women in Vancouver that focuses on restoring the felt sense of the sacred interconnections with relations and developing an embodied spiritual pedagogy incorporating traditional teachings. The principles for educating bodies for self determination are remembering, reclamation, and collective witness. These guiding principles provide a framework for a decolonizing strategy in holistic education for Aboriginal peoples. [PUBLICATION ABSTRACT]},
  keywords = {Community,Cultural identity,Cultural values,Education,Learning,Native peoples,Native women,Violence}
}

@article{nagleGapGovernanceAcknowledging2019,
  title = {A {{Gap}} in {{Governance}}: {{Acknowledging}} the {{Challenges}} of {{Organic ePortfolio Implementation}}},
  author = {Nagle, Louise and O' Connell, Michael and Farrelly, Tom},
  year = {2019},
  month = jan,
  journal = {Educational Media International},
  volume = {56},
  number = {4},
  pages = {328--342},
  publisher = {Educational Media International},
  issn = {0952-3987},
  doi = {10.1080/09523987.2019.1682271},
  abstract = {The adoption and integration of ePortfolios into third level teaching and learning provide many benefits as well as challenges. In this article, we capture the perspectives of nine academics from across seven departments within a small Higher Education Institute (HEI) who integrated ePortfolios into their teaching. Through a series of semi-structured interviews, we gained insight into the experiences of academics as they implemented various ePortfolio technologies. What is particularly notable about these participants is that the use of ePortfolios had occurred in an organic manner, often with little or no "official" support. Although, many of these organic initiatives may herald an initial flurry of positive feedback coupled with enthusiasm; the study indicates that without adequate management and support of the planning and implementation of ePortfolios there can be negative outcomes. The major conclusion drawn is that without a comprehensive and appropriate policy framework the implementation of ePortfolios is likely to run into a series of challenges. These are: fear and resistance to ePortfolios; challenges faced by students using ePortfolios; and difficulties with the integration of the technology into teaching \& learning strategies.},
  keywords = {Adoption (Ideas),Barriers,College Faculty,Educational Change,Educational Planning,Electronic Publishing,Governance,Portfolio Assessment,Portfolios (Background Materials),Program Implementation,Resistance to Change,Teacher Attitudes,Technology Integration}
}

@incollection{naickerAutoethnographyHigherEducation2021,
  title = {Autoethnography as/in {{Higher Education}}},
  booktitle = {Handbook of {{Autoethnography}}},
  author = {Naicker, Inbanathan and {Pithouse-Morgan}, Kathleen and Pillay, Daisy},
  editor = {Adams, Tony E. and Jones, Stacy Holman and Ellis, Carolyn},
  year = {2021},
  month = jul,
  edition = {2},
  pages = {215--227},
  publisher = {Routledge},
  address = {New York},
  doi = {10.4324/9780429431760-22},
  urldate = {2023-11-19},
  isbn = {978-0-429-43176-0},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/QSIEPSPP/pithouse-morganAutoethnographyHigherEducation2021.pdf}
}

@article{naikOnlineTeachingLearning2021,
  title = {Online {{Teaching}} and {{Learning}} of {{Higher Education}} in {{India}} during {{COVID-19 Emergency Lockdown}}},
  author = {Naik, Girisha Lakshman and Deshpande, Malteshkumar and Shivananda, D. C. and Ajey, C. P. and Manjunath Patel, G. C.},
  year = {2021},
  journal = {Pedagogical Research},
  volume = {6},
  number = {1},
  issn = {EISSN-2468-4929},
  abstract = {The COVID-19 pandemic has generated a world-wide consciousness that the present way of lifestyle does not work. There are many areas need the revolutionary changes and it has become obvious, one among is educational sector. In India, educational institutes/universities remain closed since the mid of March-2020, because of the fast spread of COVID-19. Emergency lockdown has a preventive measure upended the life of students, parents and teachers. To combat this inevitable crisis educational sectors started conducting the online classes. The sudden changeover in teaching/learning method has raised new challenges and opportunities. In this study, a survey based-investigation has been carried out to analyse the efficacy of online teaching and learning method compared to traditional teaching method. A questionnaire-based survey is prepared to collect the data from different degree students, faculties and parents with general publics. A total of 874 responses gathered from people of different background participated in the survey. The analysis of collected responses confirm that the traditional chalk and talk methodology is often better than online sessions. Results and analysis indicated that lack of facilities, infrastructure, technical tools and the internet access are the major drawback for conducting online sessions. The suggestions and recommendations are provided to improve the current online teaching methods to outreach many students and improve quality teaching/learning experience. The precautions to be taken by the universities to avoid rapid spread of COVID-19 cases are high lightened, if colleges/universities opens before vaccination.},
  langid = {english},
  keywords = {Barriers,College Faculty,College Students,COVID-19,Electronic Learning,Emergency Programs,Foreign Countries,Higher Education,Instructional Effectiveness,Internet,No DOI found,Online Courses,Pandemics,Satisfaction,School Closing,Stakeholders,Teaching Methods}
}

@incollection{nameyDataReductionTechniques2008,
  title = {Data Reduction Techniques for Large Qualitative Data Sets},
  booktitle = {Handbook for {{Team-Based Qualitative Research}}},
  author = {Namey, Emily and Guest, Greg and Thairu, Lucy and Johnson, Laura},
  year = {2008},
  month = jan,
  pages = {137--162},
  abstract = {You have your way. I have my way. As for the right way, the correct way, and the only way, it does not exist. FRIEDRICH NIETZSCHE W ORKING WITH DATA COLLECTED through a team effort or in multiple sites can be both challenging and rewarding. The sheer size and complexity of the data set sometimes makes the analy-sis daunting, cbut a large data set may also yield richer and more useful in-formation. In this chapter, we explore strategies for combining qualitative and quantitative analysis techniques for the analysis of large, qualitative data sets. Large is a relative term, of course, and many of the techniques de-scribed here are applicable to smaller data sets as well. However, the bene-fits of the data reduction techniques we propose increase as the data sets themselves grow in size and complexity. In our selection of techniques, we have taken a broad view of large qualitative data sets, aiming to highlight trends, relationships, or associations for further analysis, without deempha-sizing the importance of the context and richness of the data themselves. This perspective also brings focus to the multiple interpretive lenses that a group of researchers brings to team-based analysis. Throughout the chapter, we use examples from some of our research to illustrate the use of the methods discussed. In doing so, we identify the strengths and weaknesses of each method and suggest ways in which an ap-propriate technique may be chosen for a given research question and its corresponding data set.},
  isbn = {0-7591-0910-9},
  file = {/Users/colin.madland/Zotero/storage/H2IE6XNI/nameyDataReductionTechniques2008.pdf}
}

@article{nasrinnikpeymaFrameworkApproachMethod2014,
  title = {Framework Approach: A Method for Analysis of Qualitative Data},
  author = {{Nasrin Nikpeyma} and {Zhila Abed Saeedi} and {Eznollah Azargashb} and {Hamid Alavi Majd}},
  year = {2014},
  month = feb,
  journal = {payeshj},
  volume = {13},
  number = {1},
  pages = {41--50},
  abstract = {Objective (s): The framework approach was developed in the 1980s as a method to manage and analyze qualitative data in applied policy research. The aim of this article is to introduce the Framework analysis for qualitative data analysis.  Methods: Electronic literature search was performed using PubMed, Science Direct, Ovid, ProQuest, and Google.  Then relevant literature was retrieved and was reviewed.  Results: A number of scientific evidences were identified. In general there were two types of papers: those applied framework analysis in healthcare and social investigations, and those explained about the framework analysis processes. The five steps of framework approach constitute a hierarchical thematic framework that is used to classify and organize data according to key themes, concepts and emergent categories.  Conclusion: The framework approach has become popular, especially among novice healthcare researchers, due to flexibility, easy and clear steps.},
  keywords = {Data analysis,Framework analysis,No DOI found,Qualitative research},
  file = {/Users/colin.madland/Zotero/storage/KJY5FW4I/nasrinnikpeymaFrameworkApproachMethod2014.pdf}
}

@article{nassajiTechnologymediatedFeedbackInstruction2019,
  title = {Technology-Mediated Feedback and Instruction},
  author = {Nassaji, Hossein and Kartchava, Eva},
  year = {2019},
  month = nov,
  journal = {ITL - International Journal of Applied Linguistics},
  volume = {170},
  number = {2},
  pages = {151--153},
  issn = {0019-0829, 1783-1490},
  doi = {10.1075/itl.00018.nas},
  urldate = {2022-08-18},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/LSMELFEA/itl.00018.nas.pdf}
}

@book{nationalacademiesofsciencesDevelopingToolkitFostering2021,
  title = {Developing a {{Toolkit}} for {{Fostering Open Science Practices}}: {{Proceedings}} of a {{Workshop}}},
  author = {{National Academies of Sciences}, {and} Medicine, Engineering},
  editor = {{Thomas Arrison} and {Jennifer Saunders} and {Emi Kameyama}},
  year = {2021},
  publisher = {The National Academies Press},
  address = {Washington, DC},
  doi = {10.17226/26308},
  abstract = {The National Academies Roundtable on Aligning Incentives for Open Science, established in 2019, has taken on an important role in addressing issues with open science. The roundtable convenes critical stakeholders to discuss the effectiveness of current incentives for adopting open science practices, current barriers of all types, and ways to move forward in order to align reward structures and institutional values. The Roundtable convened a virtual public workshop on fostering open science practices on November 5, 2020. The broad goal of the workshop was to identify paths to growing the nascent coalition of stakeholders committed to reenvisioning credit/reward systems (e.g., academic hiring, tenure and promotion, and grants)to fully incentivize open science practices. The workshop explored the information and resource needs of researchers, research institutions, government agencies, philanthropies, professional societies, and other stakeholders interested in further supporting and implementing open science practices.  This publication summarizes the presentations and discussion of the workshop.},
  isbn = {978-0-309-09361-3},
  langid = {english},
  keywords = {Policy for Science and Technology}
}

@book{nationalacademiesofsciencesHowPeopleLearn2018,
  title = {How {{People Learn II}}: {{Learners}}, {{Contexts}}, and {{Cultures}}},
  author = {{National Academies of Sciences}, {and} Medicine, Engineering},
  year = {2018},
  publisher = {The National Academies Press},
  address = {Washington, DC},
  doi = {10.17226/24783},
  abstract = {There are many reasons to be curious about the way people learn, and the past several decades have seen an explosion of research that has important implications for individual learning, schooling, workforce training, and policy. In 2000, How People Learn: Brain, Mind, Experience, and School: Expanded Edition was published and its influence has been wide and deep. The report summarized insights on the nature of learning in school-aged children; described principles for the design of effective learning environments; and provided examples of how that could be implemented in the classroom. Since then, researchers have continued to investigate the nature of learning and have generated new findings related to the neurological processes involved in learning, individual and cultural variability related to learning, and educational technologies. In addition to expanding scientific understanding of the mechanisms of learning and how the brain adapts throughout the lifespan, there have been important discoveries about influences on learning, particularly sociocultural factors and the structure of learning environments. How People Learn II: Learners, Contexts, and Cultures provides a much-needed update incorporating insights gained from this research over the past decade. The book expands on the foundation laid out in the 2000 report and takes an in-depth look at the constellation of influences that affect individual learning. How People Learn II will become an indispensable resource to understand learning throughout the lifespan for educators of students and adults.},
  isbn = {978-0-309-45964-8},
  langid = {english},
  keywords = {Education},
  file = {/Users/colin.madland/Zotero/storage/H55F8INN/nationalacademiesofsciencesHowPeopleLearn2018.pdf}
}

@book{nationalsurveyofstudentengagementFosteringStudentEngagement2011,
  title = {Fostering Student Engagement Campuswide - Annual Results 2011},
  author = {{National Survey of Student Engagement}},
  year = {2011},
  publisher = {Indiana University Center for Postsecondary Research},
  abstract = {The National Survey of Student Engagement (NSSE) documents dimensions of quality in undergraduate education and provides information and assistance to colleges, universities, and other organizations to improve student learning. Its primary activity is annually surveying college students to assess the extent to which they engage in educational practices associated with high levels of learning and development.},
  keywords = {engagement,nsse,Student}
}

@article{natrielloImpactEvaluationProcesses1987,
  title = {The {{Impact}} of {{Evaluation Processes}} on {{Students}}},
  author = {Natriello, Gary},
  year = {1987},
  month = mar,
  journal = {Educational Psychologist},
  volume = {22},
  number = {2},
  pages = {155--175},
  issn = {0046-1520, 1532-6985},
  doi = {10/cgqtqx},
  urldate = {2021-07-05},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/3CDSZCIR/natrielloImpactEvaluationProcesses1987.pdf}
}

@book{naughtonSoftSystemsAnalysis1984,
  title = {Soft Systems Analysis: {{An}} Introductory Guide},
  author = {Naughton, John},
  year = {1984},
  publisher = {The Open University}
}

@book{navarroLearningStatisticsTutorial2018,
  title = {Learning Statistics with {{R}}: {{A}} Tutorial for Psychology Students and Other Beginners. ({{Version}} 0.6.1)},
  shorttitle = {Learning Statistics with {{R}}},
  author = {Navarro, Danielle},
  year = {2018},
  urldate = {2020-01-09},
  abstract = {Learning Statistics with R covers the contents of an introductory statistics class, as typically taught to undergraduate psychology students, focusing on the use of the R statistical software.},
  file = {/Users/colin.madland/Zotero/storage/PLNADWVK/navarroLearningStatisticsTutorial.pdf;/Users/colin.madland/Zotero/storage/GZUVSZUU/book.html}
}

@article{nayaginPreserviceTeachersApproaches2020,
  title = {Pre-Service Teachers' Approaches to Assessment},
  author = {Nayagi N, Kothai and Rajendran, M.},
  year = {2020},
  month = feb,
  journal = {Humanities \& Social Sciences Reviews},
  volume = {8},
  number = {1},
  pages = {666--673},
  issn = {2395-6518},
  doi = {10.18510/hssr.2020.8180},
  urldate = {2021-07-27},
  abstract = {Purpose of the study: The purpose of this study is to investigate the pre-service teachers' understanding of assessment concepts and their approaches to classroom assessment. The relationship between their approaches and confidence in classroom assessment was also established.  Methodology: A survey method was used to study the pre-service teachers' approaches to classroom assessment. One thirty-one second-year pre-service teachers from the University of Delhi, India participated in this study. A modified instrument namely `Approaches to Classroom Assessment Inventory (ACAI)' which consists of two parts was employed Simple t-test, correlation and factor analysis methods were used to analyze the data.  Main Findings: Results showed that the pre-service teachers had a better understanding of three out of five issues which include assessment purpose, measurement theory, and confidence in monitoring the assessment. However, the study found that they have an inadequate understanding of assessment design and assessment practices. Furthermore, the correlation between their approach and their confidence was very low and non-significant. The results are discussed in the context of the assessment curriculum and its transaction at the secondary teacher education program.  Implication /Applications of this study: Understanding of what pre-service teachers think about assessment issues within the current educational context helps in preparing them as better teachers. The study may provide some evidence for policymakers and curriculum framers [developers] that the importance of practical aspects of assessment in the secondary teacher education curriculum.  Novelty/Originality of this study: No study has been done so far on the different aspects of assessment approaches and its issues at pre-service teacher's level in India.},
  file = {/Users/colin.madland/Zotero/storage/HTFV2BFH/nayaginPreserviceTeachersApproaches2020.pdf}
}

@article{ndibalemaOnlineAssessmentEra2021,
  title = {Online {{Assessment}} in the {{Era}} of {{Digital Natives}} in {{Higher Education Institutions}}},
  author = {Ndibalema, Placidius},
  year = {2021},
  month = jan,
  journal = {International Journal of Technology in Education},
  volume = {4},
  number = {3},
  pages = {443--463},
  publisher = {International Journal of Technology in Education},
  issn = {2689-2758},
  abstract = {This study explored students? opinion towards the opportunities and inhibitive factors for online formative assessment. A Google form survey questionnaire was administered to 124 students to generate the information regarding the opportunities of online assessment. Purposive sampling technique was employed on the basis that participants were students registered through Edmodo LMS studying multimedia courses. A system walk-through strategy was used to collect qualitative data from Edmodo platform. A descriptive analysis on the data generated from a survey monkey questionnaire was employed while content analysis was carried out for qualitative data. The findings are presented based on the research questions as follows: First, it was revealed that there were several opportunities from online assessment which included divergent thinking, self-reflection and immediate feedback among students. However, the study revealed several inhibitive factors towards online assessment such as unreliable internet accessibility, lack of technological devices and negative attitudes among students. The study established that in order to have effective online formative assessment, the capacity building to both instructors and students is inevitable. Furthermore, the study calls for the need to harmonize the curriculum by capitalizing on the integration of online formative assessment to support blended learning among digital native students at all levels of education.},
  keywords = {Age Groups,Blended Learning,College Students,Computer Assisted Testing,Foreign Countries,Formative Evaluation,Independent Study,No DOI found,Online Courses,Student Attitudes,Tanzania}
}

@article{ndukweTeachingAnalyticsValue2020,
  title = {Teaching Analytics, Value and Tools for Teacher Data Literacy: A Systematic and Tripartite Approach},
  author = {Ndukwe, Ifeanyi Glory and Daniel, Ben Kei},
  year = {2020},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {17},
  number = {1},
  pages = {1--31},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-020-00201-6},
  abstract = {Teaching Analytics (TA) is a new theoretical approach, which combines teaching expertise, visual analytics and design-based research to support teacher's diagnostic pedagogical ability to use data and evidence to improve the quality of teaching. TA is now gaining prominence because it offers enormous opportunities to the teachers. It also identifies optimal ways in which teaching performance can be enhanced. Further, TA provides a platform for teachers to use data to reflect on teaching outcome. The outcome of TA can be used to engage teachers in a meaningful dialogue to improve the quality of teaching. Arguably, teachers need to develop their teacher data literacy and data inquiry skills to learn about teaching challenges. These skills are dependent on understanding the connection between TA, LA and Learning Design (LD). Additionally, they need to understand how choices in particular pedagogues and the LD can enhance their teaching experience. In other words, teachers need to equip themselves with the knowledge necessary to understand the complexity of teaching and the learning environment. Providing teachers access to analytics associated with their teaching practice and learning outcome can improve the quality of teaching practice. This research aims to explore current TA related discussions in the literature, to provide a generic conception of the meaning and value of TA. The review was intended to inform the establishment of a framework describing the various aspects of TA and to develop a model that can enable us to gain more insights into how TA can help teachers improve teaching practices and learning outcome. The Tripartite model was adopted to carry out a comprehensive, systematic and critical analysis of the literature of TA. To understand the current state-of-the-art relating to TA, and the implications to the future, we reviewed published articles from the year 2012 to 2019. The results of this review have led to the development of a conceptual framework for TA and established the boundaries between TA and LA. From the analysis the literature, we proposed a Teaching Outcome Model (TOM) as a theoretical lens to guide teachers and researchers to engage with data relating to teaching activities, to improve the quality of teaching.},
  keywords = {Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Diagnostic systems,Educational Technology,Higher Education,Humanities,Information Systems Applications (incl.Internet),Law,Learning,Learning analytics,Literacy,Mathematical analysis,Review Article,Skills,Statistics for Social Sciences,Teachers,Teaching,Teaching analytics,Teaching and learning analytics,Teaching outcome model,Tom},
  file = {/Users/colin.madland/Zotero/storage/8XTGARZU/ndukweTeachingAnalyticsValue2020.pdf}
}

@article{nelPreserviceTeachersUse2020,
  title = {Preservice {{Teachers Use}} of {{WhatsApp}} to {{Explain Subject Content}} to {{School Children}} during the {{COVID-19 Pandemic}}},
  author = {Nel, Carisma and Marais, Elma},
  year = {2020},
  month = jan,
  journal = {International Journal of Work-Integrated Learning},
  volume = {21},
  number = {5},
  pages = {629--641},
  publisher = {International Journal of Work-Integrated Learning},
  issn = {2538-1032},
  abstract = {South Africa went into lockdown on 27 March, 2020, as a result of the COVID-19 pandemic. It is unlikely that thousands of preservice teachers will be able to complete their teaching practicum during 2020 at schools. In this action research study, we investigated a two-week teaching practicum experience that was completed via WhatsApp by 12 students. During this time, the student teachers were supervised and monitored by university teaching practicum lecturers and mentored by school mentor teachers via WhatsApp. The results indicated that all participants perceived the teaching practicum experience via WhatsApp to have contributed to the formation of a community of practice that resulted in feedback and assessment being focused on a core teaching practice, namely explaining subject-specific content. Guidelines are provided for universities or teacher training providers who have work-integrated learning components to show how a teaching practicum experience via WhatsApp can be integrated into their training programs.},
  keywords = {Action Research,Communities of Practice,Computer Mediated Communication,COVID-19,Educational Innovation,Electronic Learning,Foreign Countries,No DOI found,Pandemics,Practicums,Social Media,South Africa,Student Teachers,Student Teaching}
}

@article{nerantziFeedbackConversationsBlended2011,
  title = {Feedback Conversations in a Blended Classroom},
  author = {Nerantzi, Chrissi and Currant, N. and Avramenko, Alex and Harvey, V. M.},
  year = {2011},
  journal = {null},
  doi = {null},
  abstract = {Providing and receiving feedback is a hot issue for some time now in Higher Education. Does it have to be this way? Is there anything we can do, and should do, to enhance the feedback experience of our students and make it more meaningful? Where do we start? We work with academics and other professionals who support learning at the university and offer the Postgraduate Certificate in Academic Practice (PGCAP) which enables new academics and other professionals who support learning to develop their teaching skills further, explore innovative teaching methods and approaches but also create the environment in which they can start shaping their teaching philosophy and develop their academic identity. Within the Engaging and Enhancing Student Learning (EESL) module of the PGCAP, we are using electronic portfolios for and of learning and to conduct asynchronous formative feedback conversations on work-in-progress and completed tasks. We encourage a continuous dialogue throughout the EESL to enable deeper and continuous engagement and build-in opportunities for media-rich asynchronous feedback conversations between tutor and participant using digital technologies. It has been noted that these feedback conversations have a positive and powerful effect and impact on engagement and learning. Through feedback conversations sensitive, meaningful and highly personalised feedback and feed forward is provided to our students which they find useful for their learning. This paper consists of a reflective conversation between two academics and two academic developers who discuss the portfolio integrated feedback used during the EESL module, strategies, benefits and impact.},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@article{nerantziFeedbackConversationsBlended2011a,
  title = {Feedback Conversations in a Blended Classroom},
  author = {Nerantzi, Chrissi and Currant, N. and Avramenko, Alex and Harvey, V. M.},
  year = {2011},
  journal = {null},
  doi = {null},
  abstract = {Providing and receiving feedback is a hot issue for some time now in Higher Education. Does it have to be this way? Is there anything we can do, and should do, to enhance the feedback experience of our students and make it more meaningful? Where do we start? We work with academics and other professionals who support learning at the university and offer the Postgraduate Certificate in Academic Practice (PGCAP) which enables new academics and other professionals who support learning to develop their teaching skills further, explore innovative teaching methods and approaches but also create the environment in which they can start shaping their teaching philosophy and develop their academic identity. Within the Engaging and Enhancing Student Learning (EESL) module of the PGCAP, we are using electronic portfolios for and of learning and to conduct asynchronous formative feedback conversations on work-in-progress and completed tasks. We encourage a continuous dialogue throughout the EESL to enable deeper and continuous engagement and build-in opportunities for media-rich asynchronous feedback conversations between tutor and participant using digital technologies. It has been noted that these feedback conversations have a positive and powerful effect and impact on engagement and learning. Through feedback conversations sensitive, meaningful and highly personalised feedback and feed forward is provided to our students which they find useful for their learning. This paper consists of a reflective conversation between two academics and two academic developers who discuss the portfolio integrated feedback used during the EESL module, strategies, benefits and impact.},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@misc{NetworkSovereignty2017,
  title = {Network {{Sovereignty}}},
  year = {2017},
  month = aug,
  journal = {IEEE Technology and Society},
  urldate = {2019-10-08},
  abstract = {Future Out Loud -- July 14, 2017 Marisa Duarta, Andrew Maynard, and Heather Ross},
  howpublished = {https://technologyandsociety.org/network-sovereignty/},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/2KJLV58I/network-sovereignty.html}
}

@book{neumanSocialResearchMethods2006,
  title = {Social Research Methods: {{Qualitative}} and Quantitative Approaches},
  shorttitle = {Social Research Methods: {{Qualitative}} and Quantitative Approaches},
  author = {Neuman, W. Laurence},
  year = {2006},
  edition = {6th},
  publisher = {Allyn \& Bacon},
  address = {Boston},
  isbn = {0-205-45793-2},
  keywords = {qualitative,quantitative,research methods,social reserach}
}

@incollection{newhouseDigitalFormsAssessment2016,
  title = {Digital {{Forms}} of {{Assessment}} in {{Schools}}: {{Supporting}} the {{Processes}} to {{Improve Outcomes}}},
  shorttitle = {Digital {{Forms}} of {{Assessment}} in {{Schools}}},
  booktitle = {Learning, {{Design}}, and {{Technology}}},
  author = {Newhouse, C. Paul},
  editor = {Spector, Michael J and Lockee, Barbara B and Childress, Marcus D.},
  year = {2016},
  pages = {1--29},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-17727-4_41-1},
  urldate = {2021-01-04},
  isbn = {978-3-319-17727-4},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/YF8FZ5ER/newhouseDigitalFormsAssessment2016.pdf}
}

@misc{news*ANALYSISExpertsWarn2023,
  title = {{{ANALYSIS}} {\textbar} {{Some}} Experts Warn Intelligent Machines Will Erase Work. {{Don}}'t Count on It {\textbar} {{CBC News}}},
  author = {News {$\cdot$}, Don Pittis {$\cdot$} CBC},
  year = {2023},
  month = sep,
  journal = {CBC},
  urldate = {2023-09-22},
  abstract = {People keep predicting that each wave of new technology will mean humans can put their feet up. It hasn't happened yet. Some economists and anthropologists who study the subject say even with the arrival of artificial intelligence, humans will remain integral to making the world go round.},
  howpublished = {https://www.cbc.ca/news/business/post-ai-jobs-column-don-pittis-1.6962905},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/9749H9V4/newsANALYSISExpertsWarn2023.pdf;/Users/colin.madland/Zotero/storage/6LIS78EW/post-ai-jobs-column-don-pittis-1.html}
}

@article{newtonClarifyingPurposesEducational2007,
  title = {Clarifying the Purposes of Educational Assessment},
  author = {Newton, Paul E.},
  year = {2007},
  month = jul,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {14},
  number = {2},
  pages = {149--170},
  issn = {0969-594X, 1465-329X},
  doi = {10.1080/09695940701478321},
  urldate = {2022-07-17},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/RSCECKSG/newtonClarifyingPurposesEducational2007.pdf}
}

@article{newtonImplementingNontraditionalAssessment2020,
  title = {Implementing Non-Traditional Assessment Strategies in Teacher Preparation: {{Opportunities}} and Challenges},
  shorttitle = {Implementing Non-Traditional Assessment Strategies in Teacher Preparation},
  author = {Newton, Jennifer R. and Williams, Mira Cole and Feeney, Danielle M},
  year = {2020},
  month = jun,
  journal = {Journal of Culture and Values in Education},
  volume = {3},
  number = {1},
  pages = {39--51},
  issn = {2590-342X},
  doi = {10.46303/jcve.03.01.3},
  urldate = {2020-10-30},
  abstract = {Assessment and grading in higher education have traditionally focused on ``A'' through ``F'', or point-based alpha-numeric letter grades and subjective, independent grading systems. Despite the ubiquity of this system, there are no universal guidelines on how to assess student learning on that scale. What can be problematic about ``the way things have always been'' is that students are frequently de-humanized; higher education faculty often focus on compliance and authoritarian teaching rather than engaging in the learning process alongside the students. In contrast, some faculty members have explored non-traditional assessment practices in their coursework to enhance the learning process and improve individualized student support. This article offers strategies for implementing non-traditional assessments, specifically mediated office hours, mastery learning, and ungrading strategies are addressed.},
  file = {/Users/colin.madland/Zotero/storage/HAAKMBFM/newtonImplementingNontraditionalAssessment2020.pdf}
}

@article{ngendahayoRethinkingRwandanHigher2014,
  title = {Rethinking Rwandan Higher Education Assessment System and Approaches},
  author = {Ngendahayo, Ernest},
  year = {2014},
  journal = {null},
  doi = {null},
  abstract = {In recent years, there have been increasing critiques leveled against Rwandan higher education for the quality of its graduates and various attempts have been made to address the problem. It is argued here that the role played by assessment in Rwandan higher education system has not been given sufficient attention in previous critiques. Research suggests that assessment plays a major role in what and how students learn. Assessments explicitly designed to promote learning lead to complex learning achievements that are widely deemed critical in the 21st century. However, there are indications that Rwandan higher education assessment system has been dominated by summative assessment which does not necessarily promote learning, and is sometimes counterproductive. This paper argues for a more strategic perspective on assessment in a balanced fashion with the main purpose of promoting more complex learning among students. A new assessment paradigm is proposed whereby students should play a central role in ongoing monitoring of their learning. Key words : Assessment purposes, summative assessment, formative assessment, learning complexity, selfregulated learning},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@article{ngendahayoRethinkingRwandanHigher2014a,
  title = {Rethinking Rwandan Higher Education Assessment System and Approaches},
  author = {Ngendahayo, Ernest},
  year = {2014},
  journal = {null},
  doi = {null},
  abstract = {In recent years, there have been increasing critiques leveled against Rwandan higher education for the quality of its graduates and various attempts have been made to address the problem. It is argued here that the role played by assessment in Rwandan higher education system has not been given sufficient attention in previous critiques. Research suggests that assessment plays a major role in what and how students learn. Assessments explicitly designed to promote learning lead to complex learning achievements that are widely deemed critical in the 21st century. However, there are indications that Rwandan higher education assessment system has been dominated by summative assessment which does not necessarily promote learning, and is sometimes counterproductive. This paper argues for a more strategic perspective on assessment in a balanced fashion with the main purpose of promoting more complex learning among students. A new assessment paradigm is proposed whereby students should play a central role in ongoing monitoring of their learning. Key words : Assessment purposes, summative assessment, formative assessment, learning complexity, selfregulated learning},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@article{ngEvaluationAcademicIntegrity2020,
  title = {Evaluation of Academic Integrity of Online Open Book Assessments Implemented in an Undergraduate Medical Radiation Science Course during {{COVID-19}} Pandemic},
  author = {Ng, Curtise Kin Cheung},
  year = {2020},
  month = dec,
  journal = {Journal of Medical Imaging and Radiation Sciences},
  volume = {51},
  number = {4},
  pages = {610--616},
  issn = {19398654},
  doi = {10.1016/j.jmir.2020.09.009},
  urldate = {2022-02-04},
  langid = {english},
  keywords = {archived},
  annotation = {https://web.archive.org/web/20220204162612/https://www.jmirs.org/article/S1939-8654(20)30304-0/fulltext},
  file = {/Users/colin.madland/Zotero/storage/VACA5Z4M/ngEvaluationAcademicIntegrity2020.pdf}
}

@article{nguyenMinimizeOnlineCheating2020,
  ids = {nguyenMinimizeOnlineCheating2020a},
  title = {Minimize {{Online Cheating}} for {{Online Assessments During COVID-19 Pandemic}}},
  author = {Nguyen, Joseph G and Keuseman, Kristopher J and Humston, Jonathan J},
  year = {2020},
  journal = {Journal of chemical education},
  volume = {97},
  number = {9},
  pages = {3429--3435},
  publisher = {{American Chemical Society and Division of Chemical Education, Inc}},
  address = {WASHINGTON},
  issn = {0021-9584},
  doi = {10.1021/acs.jchemed.0c00790},
  abstract = {When campuses across the world needed to transition to the online format due to the COVID-19 pandemic, there were many challenges educators faced, and addressing academic integrity issues were some of the most important. Certain strategies, such as online proctoring or additional software, were not available to most institutions because the expenses and training were too much to overcome. A more pedagogical and cost-effective strategy involved modifying the assessment format in a way that minimized or discouraged cheating. This paper presents strategies that effectively minimize cheating while addressing learning outcomes.},
  keywords = {Cheating,Chemistry,Chemistry Multidisciplinary,College Science,Computer Assisted Testing,COVID-19,Distance Education,Education & Educational Research,Education Scientific Disciplines,Educational Technology,Ethics,Evaluation Methods,Format,Learning outcomes,Online Courses,Online instruction,Pandemics,Physical Sciences,Science & Technology,Science education,Social Sciences,Student Evaluation,Undergraduate Study},
  file = {/Users/colin.madland/Zotero/storage/YIVWC295/nguyenMinimizeOnlineCheating2020.pdf}
}

@article{nguyenMixedMethodStudyHow2020,
  title = {A {{Mixed-Method Study}} of {{How Instructors Design}} for {{Learning}} in {{Online}} and {{Distance Education}}},
  author = {Nguyen, Quan and Rienties, Bart and Whitelock, Denise},
  year = {2020},
  journal = {Journal of Learning Analytics},
  volume = {7},
  number = {3},
  pages = {64--78},
  issn = {EISSN-1929-7750},
  doi = {10/gmbv3v},
  abstract = {The use of analytical methods from learning analytics (LA) research combined with visualizations of learning activities using learning design (LD) tools and frameworks has provided important insight into how instructors design for learning. Nonetheless, there are many subtle nuances in instructors' design decisions that might not easily be captured using LA tools. Therefore, this study sets out to explore how and why instructors design for learning in an online and distance higher education setting by employing a mixed-method approach, which combined semi-structured interviews of 12 instructors with network analyses of their LDs. Our findings uncovered several underlying factors that influenced how instructors designed their modules and highlighted some discrepancies between instructors' pedagogical beliefs and their actual LD as captured by the Open University Learning Design Initiative (OULDI). This study showcases the potential of combining LA with qualitative insights for a better understanding of the complex design process in online distance higher education.},
  langid = {english},
  keywords = {College Faculty,Distance Education,Electronic Learning,Faculty Workload,Foreign Countries,Instructional Design,Learning Analytics,Online Courses,Skill Development,Study Skills,Teacher Attitudes,Virtual Universities}
}

@article{nguyenProjectBasedAssessmentTeaching2021,
  title = {Project-{{Based Assessment}} in {{Teaching Intercultural Communication Competence}} for {{Foreign Language Students}} in {{Higher Education}}: {{A Case Study}}},
  author = {Nguyen, Hong-Thu Thi},
  year = {2021},
  journal = {European Journal of Educational Research},
  volume = {10},
  number = {2},
  pages = {933--944},
  issn = {EISSN-2165-8714},
  doi = {10/gmbvzb},
  abstract = {As a part of learning process, project-based assessment (PBA) is determined to be a potential approach in higher education evaluation that focuses on developing the important objectives related to critical thinking, team working and problems solving skills. The aim of the paper is to find out students' reflection and teachers' beliefs towards using this project-based assessment method in teaching Intercultural Communication Competence (ICC). To collect the data, a project-based assessment design was applied for 124 English major students at B University in the 9 weeks ICC course. This project was implemented from the beginning of the course, and at the end of the course, learners' products were performed with specific activities regarding culture knowledge competition, online cultural community activities, talent performance, situational judgment ability, and eloquence skills. In addition, a set of questionnaires were delivered to the participants, plus the interviews with 36 teachers who have taught culture-related subjects from the universities in Vietnam, Thailand and Malaysia. The findings revealed that although there were certain challenges, using project-based assessment in teaching culture had satisfactory effects on students' intercultural competence, problem- solving skills, critical thinking, and learning motivation.},
  langid = {english},
  keywords = {Active Learning,College Students,Communicative Competence (Languages),Critical Thinking,English (Second Language),Foreign Countries,Intercultural Communication,Problem Solving,Second Language Learning,Student Attitudes,Student Evaluation,Student Motivation,Student Projects}
}

@article{nguyenSustainableAssessmentLifelong2016,
  title = {Sustainable Assessment for Lifelong Learning},
  author = {Nguyen, Tham T.H. and Walker, Melanie},
  year = {2016},
  journal = {Assessment and evaluation in higher education},
  volume = {41},
  number = {1},
  pages = {97--111},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0260-2938},
  doi = {10.1080/02602938.2014.985632},
  abstract = {This paper explores the alignment of assessment practices in universities and lifelong learning as a key process and outcome for expansive student development. It outlines Boud's approach to assessment, operationalises this to analyse practices in two contrasting national contexts: the sociology departments of the Midlands University in the UK and Nam Du University in Vietnam, and reframes this framework as a guide to improving practices and better-supporting lifelong learning. The paper thus contributes to recent debates about sustainable assessment and how to change assessment to better support students for lifelong learning in different countries. The findings suggest that although more elements were found at Midlands University than Nam Du University, assessment in both cases was an imperfect realisation of this framework. Nonetheless, the paper argues that the framework can offer guidance for changes to align assessment practices with lifelong learning, but to do this it should be adapted to the education context and also expanded to include explicit social commitments to others for expansive lifelong learning.},
  keywords = {Administrators,Alignment (Education),Case Studies,College Students,Commitments,Cross Cultural Studies,Cultural Differences,Education & Educational Research,England (Midlands),Evaluation Methods,Focus Groups,Foreign Countries,Higher Education,Lifelong Learning,Reflection,Semi Structured Interviews,social commitments,Social Sciences,Sociology,Students,Sustainability,sustainable assessment,Vietnam},
  file = {/Users/colin.madland/Zotero/storage/32B6T23Q/nguyenSustainableAssessmentLifelong2016.pdf}
}

@article{nicholsExploringTransformativeLearning2020,
  title = {Exploring {{Transformative Learning}} in {{Vocational Online}} and {{Distance Education}}},
  author = {Nichols, Mark and Choudhary, Neeru and Standring, Doug},
  year = {2020},
  journal = {Journal of Open, Flexible and Distance Learning},
  volume = {24},
  number = {2},
  pages = {43--55},
  issn = {ISSN-1179-7665},
  abstract = {Perspective transformation (the enduring development of a person's understanding, the reformulation of their experience, and new ways of acting in the world) is widely understood to be an important outcome of adult education. Various studies performed over the last 30 or so years since Mezirow's theory was first proposed have confirmed its presence and importance in higher education. However, the question remains as to whether transformative learning takes place in vocational distance and online education--particularly if it's not explicitly promoted. This paper investigates the extent of transformative learning taking place in adult learners studying at a distance, online. Drawing on King's Learning Activities Survey (LAS), Open Polytechnic students (n=499) across seven qualifications (six discipline areas) responded to a survey asking about their experience of perspective transformation. The instrument also sought insight as to how vocational providers of vocational online and distance education might promote transformative learning outcomes in learners. Survey results show evidence of perspective transformation in students to varying degrees that are mainly determined by the qualification being studied. The results also reveal which instructional design approaches and teaching activities might contribute to transformation.},
  langid = {english},
  keywords = {Attitude Change,Comparative Analysis,Foreign Countries,Independent Study,Instructional Design,Learning Activities,Majors (Students),No DOI found,Outcomes of Education,Student Attitudes,Student Surveys,Teaching Methods,Transformative Learning,Undergraduate Students}
}

@article{nicholsonEnhancingStudentEngagement2018,
  title = {Enhancing Student Engagement through Online Portfolio Assessment},
  author = {Nicholson, Dawn Theresa},
  year = {2018},
  journal = {Practitioner Research in Higher Education},
  volume = {11},
  number = {1},
  pages = {15--31},
  urldate = {2021-07-27},
  abstract = {This paper reports on an existing undergraduate academic skills module where the assignment, a printed portfolio, has been replaced with an online portfolio. Qualitative feedback reveals that students most valued the provision of rapid and regular feedback on work, and had a raised awareness of employability goals. Tutors most valued the ability to monitor students' progress and provide rapid feedback on work. Some also valued the ease of the marking process and the positive impact on tutorials. However, portfolio organisation adversely impacted on the marking process for some, while others struggled with the effect of the online approach on face-to-face meetings, highlighting the need for further guidance on tutorial management. Quantitative analysis of student grades tentatively indicates higher attainment levels for online portfolios compared with printed equivalents. The findings suggest that online portfolios, combined with progress monitoring, peer learning, feedback practice, and intrinsic motivation, can promote student engagement.},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/CX5W8MR2/nicholsonEnhancingStudentEngagement2018.pdf}
}

@article{nicholsonSciteSmartCitation2021,
  title = {Scite: {{A}} Smart Citation Index That Displays the Context of Citations and Classifies Their Intent Using Deep Learning},
  shorttitle = {Scite},
  author = {Nicholson, Josh M. and Mordaunt, Milo and Lopez, Patrice and Uppala, Ashish and Rosati, Domenic and Rodrigues, Neves P. and Grabitz, Peter and Rife, Sean C.},
  year = {2021},
  month = nov,
  journal = {Quantitative Science Studies},
  volume = {2},
  number = {3},
  pages = {882--898},
  issn = {2641-3337},
  doi = {10.1162/qss_a_00146},
  urldate = {2024-10-16},
  abstract = {Abstract             Citation indices are tools used by the academic community for research and research evaluation that aggregate scientific literature output and measure impact by collating citation counts. Citation indices help measure the interconnections between scientific papers but fall short because they fail to communicate contextual information about a citation. The use of citations in research evaluation without consideration of context can be problematic because a citation that presents contrasting evidence to a paper is treated the same as a citation that presents supporting evidence. To solve this problem, we have used machine learning, traditional document ingestion methods, and a network of researchers to develop a ``smart citation index'' called scite, which categorizes citations based on context. Scite shows how a citation was used by displaying the surrounding textual context from the citing paper and a classification from our deep learning model that indicates whether the statement provides supporting or contrasting evidence for a referenced work, or simply mentions it. Scite has been developed by analyzing over 25 million full-text scientific articles and currently has a database of more than 880 million classified citation statements. Here we describe how scite works and how it can be used to further research and research evaluation.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/nicholsonSciteSmartCitation2021.pdf}
}

@incollection{nicholsRoleTheoriesLearning2016,
  title = {The Role of Theories of Learning and Cognition in Assessment Design and Development},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {Nichols, Paul D. and Kobrin, Jennifer L. and Lai, Emily and Koepfler, James},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch2},
  pages = {13--40},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch2},
  abstract = {Summary In this chapter, we present a framework for evaluating how well theories of learning and cognition inform assessment design and development decisions. We use principled assessment design -- represented in practice by approaches such as evidence-centered design, principled design for efficacy, and assessment engineering -- as a lens through which to evaluate the potential of theories of learning and cognition to inform assessment design and development decisions. Specifically, we discuss two common characteristics of principled assessment design approaches and propose three criteria for evaluating theories of learning and cognition. We then demonstrate the use of these criteria using a learning progression on geometric measurement of area. Finally, we summarize the implications of these decisions for constructing an argument for the validity of assessment results interpretation and use and suggest future directions for principled assessment design.},
  chapter = {2},
  isbn = {978-1-118-95658-8},
  keywords = {assessment design,assessment development,cognition,criteria,learning,learning progression,theories,validity}
}

@article{nicklVideobasedSimulationsTeacher2022,
  title = {Video-Based Simulations in Teacher Education: The Role of Learner Characteristics as Capacities for Positive Learning Experiences and High Performance},
  author = {Nickl, M and Huber, {\relax SA} and Sommerhoff, D and Codreanu, E and Ufer, S and Seidel, T},
  year = {2022},
  month = sep,
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {19},
  number = {1},
  issn = {2365-9440},
  doi = {10.1186/s41239-022-00351-9},
  abstract = {Assessing students on-the-fly is an important but challenging task for teachers. In initial teacher education, a call has been made to better prepare pre-service teachers for this complex task. Advances in technology allow this training to be done through authentic learning environments, such as video-based simulations. To understand the learning process in such simulations, it is necessary to determine how cognitive and motivational learner characteristics influence situative learning experiences, such as the perception of authenticity, cognitive load, and situational motivation, during the simulation and how they affect aspects of performance. In the present study, N = 150 pre-service teachers from German universities voluntarily participated in a validated online video-based simulation targeting on-the-fly student assessments. We identified three profiles of learner characteristics: one with above average knowledge, one with above average motivational-affective traits, and one with below average knowledge and motivational-affective traits. These profiles do not differ in the perception of the authenticity of the simulation. Furthermore, the results indicate that the profiled learners navigate differently through the simulation. The knowledgeable learners tended to outperform learners of the other two profiles by using more learning time for the assessment process, also resulting in higher judgment accuracy. The study highlights how learner characteristics and processes interact, which helps to better understand individual learning processes in simulations. Thus, the findings may be used as a basis for future simulation research with a focus on adaptive and individual support.},
  langid = {english},
  keywords = {ACHIEVEMENT,Assessment process,Assessment skills,Authenticity,DIAGNOSTIC COMPETENCE,EXPECTANCY-VALUE THEORY,Higher education,KNOWLEDGE,Latent profile analysis,Learner characteristics,MOTIVATION,ONE-STEP,Person-centered approaches,PRESERVICE TEACHERS,PROFESSIONAL-DEVELOPMENT,STUDENTS,Teacher education,VARIABLES,Video-based simulation},
  file = {/Users/colin.madland/Zotero/storage/7NIGDIRL/nicklVideobasedSimulationsTeacher2022.pdf}
}

@article{nicola-richmondOnlineProctoredExams2023,
  title = {Online Proctored Exams: Rhetoric vs Reality},
  shorttitle = {Online Proctored Exams},
  author = {{Nicola-Richmond}, Kelli and Dawson, Phillip and Partridge, Helen},
  year = {2023},
  month = jul,
  journal = {Higher Education Research \& Development},
  pages = {1--14},
  issn = {0729-4360, 1469-8366},
  doi = {10.1080/07294360.2023.2234310},
  urldate = {2023-07-25},
  abstract = {Remote proctoring of exams is one of the most divisive issues in higher education. Critiques of remote proctoring abound, and there are a variety of perspectives particularly in relation to the advantages and disadvantages of this type of assessment, and opportunities for cheating. However, these perspectives are largely based on rhetoric with limited empirical data to support or refute the value of remote proctoring. This study used mixedmethods to investigate the experiences, and perceptions of cheating in open-book online proctored exams. An online questionnaire and interviews were conducted with students and academics. Data analysis revealed that the experience of online proctored exams was generally positive although there were mixed preferences for online versus on-campus exams. A variety of advantages and disadvantages of online proctored exams were also identified. Whilst both students and academics reported that they believed students would cheat, actual instances of cheating (as reported by students or academics) were minimal. This may have been because of the use of open-book exams. Based on these findings we comment on the reality versus the rhetoric relating to online proctored exams and suggest a range of ways forward for universities.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/9EAV8FKF/Nicola-Richmond et al. - 2023 - Online proctored exams rhetoric vs reality.pdf}
}

@article{nicolAssessmentLearnerSelfregulation2009,
  title = {Assessment for Learner Self-Regulation: Enhancing Achievement in the First Year Using Learning Technologies},
  author = {Nicol, David},
  year = {2009},
  journal = {Assessment and evaluation in higher education},
  volume = {34},
  number = {3},
  pages = {335--352},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0260-2938},
  doi = {10.1080/02602930802255139},
  abstract = {While there is considerable research on the first-year experience, much less has been written about the impact of assessment and feedback practices on that experience. This paper explores how formative assessment and feedback might be used to enhance the first-year experience and enable students to develop the skills needed for self-regulated learning. It also explores how technology might support formative assessment practices in the current higher education context, where modularisation, larger student numbers and lower staff-student ratios have all reduced opportunities for formative support. A framework is proposed for the design of large-cohort first-year courses based on two recent literature reviews. This provides a lens through which to analyse two first-year courses (Psychology and French) that were redesigned with funding from the Re-engineering Assessment Practices (REAP) project. Evaluations show that both course redesigns resulted in high levels of student satisfaction, in performance improvements in final exams when compared with previous years and in workload efficiency gains brought about by the application of technology. Ways of improving on these designs based on the proposed framework are discussed.},
  keywords = {Case Studies,College Freshmen,Comparative analysis,Curricula,Education & Educational Research,Educational Change,Feedback,Feedback (Response),first-year experience,Foreign Countries,formative assessment,Formative Evaluation,French,French language,Guidelines,Higher education,Introductory Courses,Learning,Metacognition,Neighborhood,Program Descriptions,Psychology,Self evaluation,self-regulation,Skill Development,Social Sciences,Student Attitudes,Student Evaluation,student success,Teaching Methods,technology,United Kingdom},
  file = {/Users/colin.madland/Zotero/storage/9NB4CIE8/nicolAssessmentLearnerSelfregulation2009.pdf}
}

@article{nicolFormativeAssessmentSelf2006,
  title = {Formative Assessment and Self-regulated Learning: A Model and Seven Principles of Good Feedback Practice},
  shorttitle = {Formative Assessment and Self-regulated Learning},
  author = {Nicol, David J. and Macfarlane-Dick, Debra},
  year = {2006},
  month = apr,
  journal = {Studies in Higher Education},
  volume = {31},
  number = {2},
  pages = {199--218},
  issn = {0307-5079, 1470-174X},
  doi = {10/fh4qnb},
  urldate = {2021-03-25},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/6PNHC4TU/nicolFormativeAssessmentSelf2006.pdf}
}

@article{nicolPowerInternalFeedback2021a,
  title = {The Power of Internal Feedback: Exploiting Natural Comparison Processes},
  shorttitle = {The Power of Internal Feedback},
  author = {Nicol, David},
  year = {2021},
  month = jul,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {46},
  number = {5},
  pages = {756--778},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2020.1823314},
  urldate = {2021-12-15},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/4WE582P3/nicolPowerInternalFeedback2021.pdf}
}

@article{nicolReEngineeringAssessmentPractices2009,
  title = {Re-{{Engineering}}  {{Assessment}}  {{Practices}}:  {{A}}  {{Matrix}}  for  {{Curriculum}}  and  {{Institutional}}  {{Change}}},
  author = {Nicol, David and Owen, Catherine},
  year = {2009},
  journal = {Educational  Developments},
  volume = {10},
  number = {2},
  pages = {5--10},
  abstract = {How do you promote and sustain curriculum and institutional change in higher education? For most educational developers this is a long- standing concern. Over the last 20 years, the Centre for Academic Practice and Learning Enhancement (CAPLE) at the University of Strathclyde has been involved in many initiatives to redesign individual courses and to improve the overall undergraduate experience at faculty and institutional level. In this article, we share what we have learned about curriculum and institutional change through our leadership of a large, multi-layered, development project, called REAP (Re-engineering Assessment Practices -- www.reap.ac.uk).},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/R2PWWHTQ/nicolReEngineeringAssessmentPractices2009.pdf}
}

@article{nicolRethinkingFeedbackPractices2014,
  title = {Rethinking Feedback Practices in Higher Education: A Peer Review Perspective},
  shorttitle = {Rethinking Feedback Practices in Higher Education},
  author = {Nicol, David and Thomson, Avril and Breslin, Caroline},
  year = {2014},
  month = jan,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {39},
  number = {1},
  pages = {102--122},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2013.795518},
  urldate = {2023-03-30},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/XGKGKYH5/nicolRethinkingFeedbackPractices2014.pdf}
}

@article{nielsenDigitalExplanationAssessment2020,
  title = {Digital {{Explanation}} as {{Assessment}} in {{University Science}}},
  author = {Nielsen, W and Georgiou, H and Jones, P and Turney, A},
  year = {2020},
  journal = {Research in Science Education},
  volume = {50},
  number = {6},
  pages = {2391--2418},
  issn = {0157-244X},
  doi = {10.1007/s11165-018-9785-9},
  abstract = {Assessments in tertiary science subjects typically assess content knowledge, and there is current need to both develop and assess different forms of knowledge and skills, such as communications and digital literacies. A digital explanation is a multimodal artefact created by students to explain science to a specified audience, which is an alternate form of assessment that has potential to develop and assess these other important forms of knowledge and skills. This research draws from perspectives in multimodality, educational semiotics and science education to gain a better understanding of digital explanation as a form of assessment in university science. Data sources include digital artefacts (n = 42), task descriptions and rubrics and pre-/post-interviews (n = 21) with students who created them as a task in a university science subject. Analysis involved identifying the range of media resources used across the data set, seeking patterns in how multiple resources were used and exploring students' perspectives on the task, including their design decisions. A more detailed look at artefacts from three different science learning contexts illustrates that students base their design decisions on the content knowledge being represented, their technical capabilities to generate them and how to engage the audience. Students enjoy this form of assessment and feel that the tasks allowed them to demonstrate different sorts of capabilities than are normally assessed in their subjects. Recommendations for instructors provide guidance for considering this sort of task in tertiary science contexts.},
  langid = {english},
  keywords = {Assessment,Blended media,Digital explanation,FRAMEWORK,Meaning-making,MULTIPLE,Representations,REPRESENTATIONS,Semiotic resources,SLOWMATION,STUDENTS,Tertiary science,UNDERGRADUATE SCIENCE},
  file = {/Users/colin.madland/Zotero/storage/BSYI5882/nielsenDigitalExplanationAssessment2020.pdf}
}

@article{nielsenMeaningMakingMultiple2022,
  title = {Meaning {{Making}} with {{Multiple Representations}}: A {{Case Study}} of a {{Preservice Teacher Creating}} a {{Digital Explanation}}},
  shorttitle = {Meaning {{Making}} with {{Multiple Representations}}},
  author = {Nielsen, Wendy and Turney, Annette and Georgiou, Helen and Jones, Pauline},
  year = {2022},
  month = jun,
  journal = {Research in Science Education},
  volume = {52},
  number = {3},
  pages = {871--890},
  issn = {0157-244X, 1573-1898},
  doi = {10.1007/s11165-021-10038-2},
  urldate = {2022-10-31},
  abstract = {Abstract                            The construction of dynamic multimedia products requires the selection and integration of a range of semiotic resources. As an assessment task for preservice teachers, this construction process is complex but has significant potential for learning. To investigate how weaving together multiple representations in such tasks enables learners to develop conceptual understanding, the paper presents an indicative case study of a 2nd-year preservice primary (K-6) teacher who created a digital explanation on the topic of `transparency' for stage 3 children (ages 11--12). We focus on data gathered during the 3-h construction process including artefacts such as images, online searches, websites accessed and paper records used for planning; the digital explanation as product; audio and video capture of the construction process and pre- and post-construction interviews. Using multimodal analysis, we examine these data to understand how meanings are negotiated as the maker moves iteratively among multiple representations and through semiotic choices within these representations to explain the science concept. The analyses illustrate the complexity of the construction process while providing insight into the creator's decision-making and to her developing semiotic and conceptual understandings. These findings allow us to build on the concept of cumulative semiotic progression (Hoban \& Nielsen,               Research in Science Education               , 35, 1101-1119, 2013) by explicating the role of iterative reasoning in the production of pedagogic multimedia.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/Z3BHL2D6/nielsenMeaningMakingMultiple2022.pdf}
}

@article{nieminenAssessmentInclusionRethinking2024,
  title = {Assessment for {{Inclusion}}: Rethinking Inclusive Assessment in Higher Education},
  shorttitle = {Assessment for {{Inclusion}}},
  author = {Nieminen, Juuso Henrik},
  year = {2024},
  journal = {Teaching in Higher Education},
  volume = {29},
  number = {4},
  pages = {841--859},
  issn = {1356-2517, 1470-1294},
  doi = {10.1080/13562517.2021.2021395},
  urldate = {2024-04-10},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/9QP27CMJ/nieminenAssessmentInclusionRethinking2024.pdf}
}

@article{nieminenAssessmentMatterBeing2023,
  title = {Assessment as a Matter of Being and Becoming: Theorising Student Formation in Assessment},
  shorttitle = {Assessment as a Matter of Being and Becoming},
  author = {Nieminen, Juuso Henrik and Yang, Lili},
  year = {2023},
  journal = {Studies in Higher Education},
  pages = {1--14},
  issn = {0307-5079, 1470-174X},
  doi = {10.1080/03075079.2023.2257740},
  urldate = {2024-02-08},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/QJJQZUTS/nieminenAssessmentMatterBeing2023.pdf}
}

@article{nieminenDesigningDigitalAuthentic2022,
  title = {Designing the Digital in Authentic Assessment: Is It Fit for Purpose?},
  shorttitle = {Designing the Digital in Authentic Assessment},
  author = {Nieminen, Juuso Henrik and Bearman, Margaret and Ajjawi, Rola},
  year = {2022},
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {48},
  number = {0},
  pages = {1--15},
  issn = {0260-2938},
  doi = {10.1080/02602938.2022.2089627},
  urldate = {2022-06-22},
  abstract = {Authentic assessment aligns higher education with the practices of students' future professions, which are increasingly digitally mediated. However, previous frameworks for authentic assessment appear not to explicitly address how authenticity intersects with a broader digital world. This critical scoping review describes how the digital has been designed into authentic assessment in the higher education literature. Our findings imply that the digital was most often used to enhance assessment design and to develop students' digital skills. Other purposes for designing the digital into assessment were less present. Only eight studies situated the students within the wider context of digital societies, and none of the studies addressed students' critical digital literacies. Thus, while there are pockets of good practice found within the literature, the vast majority of the studies employed the digital as an instrumental tool for garnering efficiencies. We suggest that in order to fit its purpose of preparing students for the digital world, the digital needs to be designed into authentic assessment in meaningful ways.},
  keywords = {assessment design,Authentic assessment,critical review,digital assessment,digital literacies,E-PORTFOLIO,FRAMEWORK,ORAL COMMUNICATION,SCIENCE,TECHNOLOGY},
  file = {/Users/colin.madland/Zotero/storage/BF4IV74Y/nieminenDesigningDigitalAuthentic2022.pdf}
}

@article{nieminenDisruptingPowerRelations2022,
  title = {Disrupting the Power Relations of Grading in Higher Education through Summative Self-Assessment},
  author = {Nieminen, Juuso Henrik},
  year = {2022},
  journal = {Teaching in Higher Education},
  volume = {27},
  number = {7},
  pages = {892--907},
  issn = {1356-2517, 1470-1294},
  doi = {10.1080/13562517.2020.1753687},
  urldate = {2024-09-23},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/nieminenDisruptingPowerRelations2022.pdf}
}

@article{nieminenFeedbackLiteracyCritical2022,
  title = {Feedback Literacy: A Critical Review of an Emerging Concept},
  shorttitle = {Feedback Literacy},
  author = {Nieminen, Juuso Henrik and Carless, David},
  year = {2022},
  journal = {Higher Education},
  volume = {85},
  pages = {1381--1400},
  issn = {0018-1560, 1573-174X},
  doi = {10.1007/s10734-022-00895-9},
  urldate = {2022-07-26},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/4U5WS5L5/nieminenFeedbackLiteracyCritical2022.pdf}
}

@article{nieminenHowTheoryUsed2023,
  title = {How Is Theory Used in Assessment and Feedback Research? {{A}} Critical Review},
  shorttitle = {How Is Theory Used in Assessment and Feedback Research?},
  author = {Nieminen, Juuso Henrik and Bearman, Margaret and Tai, Joanna},
  year = {2023},
  month = jan,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {48},
  number = {1},
  pages = {77--94},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2022.2047154},
  urldate = {2023-02-05},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/39SPFXHJ/nieminenHowTheoryUsed2023.pdf}
}

@article{nieminenTakingUniversalDesign2019,
  title = {Taking {{Universal Design Back}} to {{Its Roots}}: {{Perspectives}} on {{Accessibility}} and {{Identity}} in {{Undergraduate Mathematics}}},
  shorttitle = {Taking {{Universal Design Back}} to {{Its Roots}}},
  author = {Nieminen, Juuso and Pesonen, Henri Valtteri},
  year = {2019},
  month = dec,
  journal = {Education Sciences},
  volume = {10},
  number = {1},
  pages = {12},
  issn = {2227-7102},
  doi = {10.3390/educsci10010012},
  urldate = {2024-05-07},
  abstract = {Universal Design has been promoted to address the diversity of learners in higher education. However, rarely have Universal Design implementations been evaluated by listening to the voices of disabled students. For this study, we investigated the perceptions of three disabled students who took part in an undergraduate mathematics course designed with the principles of Universal Design for Learning and Assessment. The study consists of two parts. First, we observed the experiences students had in relation to the accessibility of the course design. The second part consisted of a further analysis of the students identifying processes to understand how they talked about their learning disabilities during the course. Our results highlight many opportunities and challenges that the course offered to the students, whilst also raising concerns about how the students excluded themselves from their student cohort in their identifying narratives. Based on our results, we argue that Universal Design should be returned to its roots by connecting it with the social model of disability. We call for future research to learn from our mistakes and consider the identifying processes of the students while designing, and hopefully co-designing, inclusive learning environments in mathematics.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/E7Z95SR3/nieminenTakingUniversalDesign2019.pdf}
}

@article{nierenbergInformationLiteracyAbility2023,
  title = {Is Information Literacy Ability, and Metacognition of That Ability, Related to Interest, Gender, or Education Level? {{A}} Cross-Sectional Study of Higher Education Students},
  shorttitle = {Is Information Literacy Ability, and Metacognition of That Ability, Related to Interest, Gender, or Education Level?},
  author = {Nierenberg, Ellen and Dahl, Tove I.},
  year = {2023},
  month = mar,
  journal = {Journal of Librarianship and Information Science},
  volume = {55},
  number = {1},
  pages = {57--69},
  issn = {0961-0006, 1741-6477},
  doi = {10.1177/09610006211058907},
  urldate = {2024-02-09},
  abstract = {How information literate are students in higher education, and how accurate is their metacognition related to that ability? Are students' perceived needs to learn more and their level of interest in becoming information literate related to their pursuit of information literacy (IL) skill development? First-year undergraduates, master's, and PhD students ( N\,=\,760) took an objective IL test and estimated their scores both before and after the test. IL ability, as well as students' estimation of their IL ability, increased with higher education experience and IL test experience, though also varied notably within groups. Low-performers tended to overestimate their abilities, while high-performers tended to underestimate them---both evidence of the Dunning-Kruger effect. Furthermore, gender comparisons revealed that men tended to estimate higher, and more accurate, scores than women. Finally, PhD students reported greater interest in becoming information literate than undergraduates. Although undergraduates felt a greater need to learn more, PhD students were more inclined to pursue IL growth. For both groups, interest in becoming information literate correlated far more with their likelihood to invest effort into developing IL competencies than their perceived need to know more. What implications might these findings have for how we conceptualize the teaching of IL?},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/2SL2NFGH/nierenbergInformationLiteracyAbility2023.pdf}
}

@article{nieRolePodcastingEffective2010,
  title = {The Role of Podcasting in Effective Curriculum Renewal},
  author = {Nie, Ming and Armellini, Alejandro and Harrington, Sue and Barklamb, Kelly and Randall, Ray},
  year = {2010},
  journal = {ALT-J},
  volume = {18},
  number = {2},
  pages = {105--118},
  doi = {10.1080/09687769.2010.492849},
  abstract = {This paper reports on a case study into the contribution of podcasting to the curriculum transformation of two distance?taught master?s programmes. Both programmes attract work?based Occupational Psychology practitioners, most of whom are in full?time employment. Challenges faced by the course team included adding flexibility to the curricula, increasing learner engagement (both with learning materials and feedback) and reducing learner isolation. As part of a coordinated enhancement effort, which included changes to curriculum design and delivery, 59 podcasts were introduced into the curriculum over a 12?month period. Qualitative and quantitative data were gathered from students and staff throughout the study. Action research ensured a regular flow of relevant evidence informing each stage of the renewal process. Evidence suggested that the students? learning experiences improved as a result of four key benefits associated with the integration of podcasting in learning design: personalisation; an additional and different format for providing clear and engaging guidance, support and feedback; increased flexibility and mobility within the curricula; and ?design once, deliver many times? with minimum adaptation.}
}

@incollection{niglasMultidimensionalModelResearch2010,
  title = {The {{Multidimensional Model}} of {{Research Methodology}}: {{An Integrated Set}} of {{Continua}}},
  shorttitle = {The {{Multidimensional Model}} of {{Research Methodology}}},
  booktitle = {{{SAGE Handbook}} of {{Mixed Methods}} in {{Social}} \& {{Behavioral Research}}},
  author = {Niglas, Katrin},
  editor = {Tashakkori, Abbas and Teddlie, Charles},
  year = {2010},
  pages = {215--236},
  publisher = {SAGE Publications, Inc.},
  address = {2455 Teller Road,~Thousand Oaks~California~91320~United States},
  urldate = {2021-07-31},
  isbn = {978-1-4129-7266-6 978-1-5063-3519-3},
  annotation = {10.4135/9781506335193.n9},
  file = {/Users/colin.madland/Zotero/storage/NILBKUXY/niglasMultidimensionalModelResearch2010.pdf}
}

@article{nikolaevaProspectivePhilologistsTranslation2021,
  title = {Prospective {{Philologists}}' {{Translation Assessment Triangulation}}: {{Screen Video Recording}} and {{Think Aloud Protocol Combination}}},
  author = {Nikolaeva, Sofiya and Korol, Tetiana},
  year = {2021},
  month = jan,
  journal = {Advanced Education},
  number = {18},
  pages = {30--41},
  publisher = {Advanced Education},
  issn = {2409-3351},
  doi = {10.20535/2410-8286.228550},
  abstract = {Purpose: The article strives for the enhancement of the efficiency of translation competence assessment in philologists' university training with the help of the triangulation method. It is deemed in the concurrent involvement of different assessment agents (teacher, peer and self) into integrated and collaborative translation performance evaluation from two perspectives, i.e. translation product quality and process workflow, with the use of diversified methods based on different theoretical approaches. This research aims at the study of students' video screen recording contribution combined with think-aloud protocols (TAPs) to increase the assessment objectivity and reliability of the received translation product. Method: A mixed research design was developed and implemented. It involved 40 third-year university students majoring in Philology, who were asked to perform a written translation of the excerpt of English popular science article in Marketing (c. 250 words) into Ukrainian in MS Word using any reference sources at hand, video record the process of their translation and accompany it with their comments. The research was completed with the questionnaire on students' attitude to the screen recording and TAP involvement into translation task performance and assessment. Findings: The findings of this study reported on the positive impact of screen recording on the assessment accuracy, informative value of the collected data and formative effect of triangulated assessment method on students' translation competence acquisition. Implications for research and practice: The received results can serve for the optimisation of the procedures of translation task difficulty measurement and competence assessment in the translation classroom.},
  keywords = {Accuracy,Computational Linguistics,Computer Software,Difficulty Level,English (Second Language),Foreign Countries,Language Processing,Language Usage,Linguistics,Majors (Students),Marketing,Peer Evaluation,Protocol Analysis,Reliability,Second Languages,Self Evaluation (Individuals),Student Evaluation,Translation,Ukraine,Ukrainian,Undergraduate Students,Video Technology},
  file = {/Users/colin.madland/Zotero/storage/T3JUFH8W/nikolaevaProspectivePhilologistsTranslation2021.pdf}
}

@article{nikouAssessmentInterplayLiteracy2021,
  title = {An Assessment of the Interplay between Literacy and Digital {{Technology}} in {{Higher Education}}},
  author = {Nikou, S and Aavakare, M},
  year = {2021},
  journal = {Education and Information Technologies},
  volume = {26},
  number = {4},
  pages = {3893--3915},
  issn = {1360-2357},
  doi = {10.1007/s10639-021-10451-0},
  abstract = {Digital technologies fundamentally transform teaching and learning in higher education environments, with the pace of technological change exacerbating the challenge. Due to the current pandemic situation, higher education environments are all now forced to move away from traditional teaching and learning structures that are simply no longer adaptable to the challenges of rapidly changing educational environments. This research develops a conceptual model and employs Structural Equation Modelling (SEM) using Partial least Squares (PLS) to examine the impact of information and digital literacy on 249 Finnish university staff and students' intention to use digital technologies. The findings show the complex interrelationship between literacy skills and digital technologies among university staff and students. The results illustrate that information literacy has a direct and significant impact on intention to use; while, unlike our expectation, digital literacy does not have a direct impact on the intention to use. However, its effect is mediated through performance expectancy and effort expectancy. The authors suggest that to understand the changes that are taking place in higher education environment, more attention needs to be paid to redefining policies and strategies in order to enhance individuals' willingness to use digital technologies within higher education environments.},
  langid = {english},
  keywords = {Digital literacy,Digital technology,higher education,information literacy,University staff and students,UTAUT},
  file = {/Users/colin.madland/Zotero/storage/YUFPE8SS/nikouAssessmentInterplayLiteracy2021.pdf}
}

@article{nikouMobilebasedAssessmentLiterature2018,
  title = {Mobile-Based Assessment: {{A}} Literature Review of Publications in Major Referred Journals from 2009 to 2018},
  shorttitle = {Mobile-Based Assessment},
  author = {Nikou, Stavros A. and Economides, Anastasios A.},
  year = {2018},
  month = oct,
  journal = {Computers \& Education},
  volume = {125},
  pages = {101--119},
  issn = {03601315},
  doi = {10.1016/j.compedu.2018.06.006},
  urldate = {2022-10-04},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/FC32Y75T/nikouMobilebasedAssessmentLiterature2018.pdf}
}

@article{nkomoSynthesisStudentEngagement2021,
  title = {Synthesis of Student Engagement with Digital Technologies: A Systematic Review of the Literature},
  author = {Nkomo, Larian M. and Daniel, Ben K. and Butson, Russell J.},
  year = {2021},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {18},
  number = {1},
  pages = {34--34},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-021-00270-1},
  abstract = {Restrictions on physical gathering due to COVID-19 has compelled higher education institutions to rapidly embrace digital technologies to support teaching and learning. While logistically, the use of digital technologies offers an obvious solution, attention must be given to these methods' pedagogical appropriateness, mainly how students engage and learn in the spaces supported by these technologies. In this context, we explored the degree to which digital technologies have contributed to teaching and learning practices over the past decade. The study employed a systematic review using a newly developed tripartite model for conducting and presenting literature review reports. The model approaches the literature review process systematically and employs three phases for the critical examination of literature: description, synthesis, and critique. The current review focused on student engagement across technologies that encompass social media, video, and collaborative learning technologies. Relevant articles were obtained from the Scopus and Web of Science databases. Three core themes were identified: there was no shared understanding of what constitutes student engagement with learning technologies, there was a lack of explanation concerning the contextual variation and modalities of student engagement across the digital technologies, and self-reporting was the primary method of measuring student engagement, rendering results as perceptual rather than behavioural. We argue that using multiple datasets and different methodological approaches can provide further insights into student engagement with digital technologies. This approach to measuring engagement can substantiate findings and most likely provide additional insights into students' engagement with digital technologies.},
  keywords = {College Students,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,COVID-19,Digital technologies,Distance learning,Educational Technology,Higher Education,Higher education institutions,Humanities,Information Systems Applications (incl.Internet),Invalid DOI,Law,Learner Engagement,Literature Reviews,Measurement methods,Measurement Techniques,Review,Review Article,Statistics for Social Sciences,Student engagement,Student learning,Student participation,Students,Systematic review,Teaching Methods,Technology Uses in Education}
}

@article{nogueraStudentsInstructorsPerspectives2019,
  title = {Students' and {{Instructors}}' {{Perspectives}} Regarding {{E-Assessment}}: {{A Case Study}} in {{Introductory Digital Systems}}},
  author = {Noguera, I and {Guerrero-Roldan}, {\relax AE} and Rodriguez, {\relax ME} and Baneres, D},
  year = {2019},
  journal = {International Journal of Engineering Education},
  volume = {35},
  number = {2},
  pages = {473--490},
  issn = {0949-149X},
  abstract = {Higher education institutions are increasingly offering opportunities for online learning, yet the issues of identifying students and verifying the authorship of their work limit the adoption of online assessment. Furthermore, little is known about the instructors' and students' background and confidence in e-assessment. This study analyzes students' and instructors' experiences, trust, and expectations regarding the use of an e-authentication system for e-assessment purposes. A total of 154 students and 12 instructors were surveyed, and two group interviews conducted, within the context of a pilot for a European project. The pilot consisted of testing several security mechanisms through diverse e-assessment activities in an online university course in digital systems. The results showed that participants had little experience with courses where all assessments were conducted online. Negative expectations of e-assessment (i.e., workload and time overload) were dispelled while ideas about the expected benefits were realized (i.e., flexibility, mobility and comfort). Attitudes toward e-assessment remained positive despite the technical difficulties that arose during the pilot. The use of security mechanisms was perceived as beneficial and opened up new opportunities for innovative practices in e-assessment but caused some mistrust or sense of invasiveness among participants. This study contributes to advancing the field of technology-enhanced assessment and understanding students' and instructors' perspectives on that matter.},
  langid = {english},
  keywords = {COMPUTER-BASED ASSESSMENT,e-assessment,IMPACT,No DOI found,online education,PERCEPTIONS,PERFORMANCE,security mechanisms,students' and teachers' perceptions}
}

@article{noreenDigitalTechnologiesLearning2020,
  title = {Digital {{Technologies}} for {{Learning}} at {{Allama Iqbal Open University}} ({{AIOU}}): {{Investigating Needs}} and {{Challenges}}},
  author = {Noreen, Sidra and Malik, Muhammad Abid},
  year = {2020},
  month = jan,
  journal = {Open Praxis},
  volume = {12},
  number = {1},
  pages = {39--49},
  publisher = {Open Praxis},
  issn = {2304-070X},
  doi = {10.5944/openpraxis.12.1.1016},
  abstract = {The present study investigated the need of digital technologies for the distance learners of AIOU (Allama Iqbal Open University), and the challenges in its implementation. Within mixed-method approach, an explanatory sequential design was employed to conduct this study. Quantitative data was collected through questionnaires from 963 students to find out the needs for digital technologies. Later 3 administrators and 1 library in-charge were interviewed to find out the challenges in its implementation. Quantitative data was analyzed using descriptive statistics. For qualitative data analysis, inductive analysis was done. Most of the students said that digital technologies were needed for increasing accessibility and flexibility of learning. The challenges for its implementation were in the requirement of diverse online learning resources, access, cost and lack of expertise. The paper recommended that there should be provision of portable devices to students with Wi-Fi, and guidance about its use. Annual need-assessment system was also suggested.},
  keywords = {Access to Education,Barriers,Computer Assisted Testing,Costs,Distance Education,Educational Needs,Electronic Learning,Expertise,Foreign Countries,Graduate Students,Instructional Materials,Internet,Open Universities,Pakistan,Program Implementation,Student Attitudes,Teacher Education,Workshops},
  file = {/Users/colin.madland/Zotero/storage/F6CV9QJ2/noreenDigitalTechnologiesLearning2020.pdf}
}

@book{norlinelainaELearningBusinessPlans2008,
  title = {E-{{Learning}} and {{Business Plans}}: {{National}} and International Case Studies},
  author = {Norlin, Elaina, M and Travis, Tiffini A},
  year = {2008},
  publisher = {The Scarecrow Press},
  address = {Lanham, MD}
}

@article{noronhaTelehealthCompetenciesMedical2022,
  title = {Telehealth {{Competencies}} in {{Medical Education}}: {{New Frontiers}} in {{Faculty Development}} and {{Learner Assessments}}},
  author = {Noronha, Craig and Lo, Margaret C. and Nikiforova, Tanya and Jones, Danielle and Nandiwada, Deepa Rani and Leung, Tiffany I. and Smith, Janeen E. and Lee, Wei Wei},
  year = {2022},
  journal = {Journal of general internal medicine : JGIM},
  volume = {37},
  number = {12},
  pages = {3168--3173},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {0884-8734},
  doi = {10.1007/s11606-022-07564-8},
  abstract = {Telehealth visits have become an integral model of healthcare delivery since the COVID-19 pandemic. This rapid expansion of telehealthcare delivery has forced faculty development and trainee education in telehealth to occur simultaneously. In response, academic medical institutions have quickly implemented clinical training to teach digital health skills to providers across the medical education continuum. Yet, learners of all levels must still receive continual assessment and feedback on their skills to align with the telehealth competencies and milestones set forth by the Association of American Medical Colleges (AAMC) and the Accreditation Council for Graduate Medical Education (ACGME). This paper discusses key educational needs and emerging areas for faculty development in telehealth teaching and assessment of telehealth competencies. It proposes strategies for the successful integration of the AAMC telehealth competencies and ACGME milestones into medical education, including skills in communication, data gathering, and patient safety with appropriate telehealth use. Direct observation tools in the paper offer educators novel instruments to assess telehealth competencies in medical students, residents, and peer faculty. The integration of AAMC and ACGME telehealth competencies and the new assessment tools in this paper provide a unique perspective to advance clinical practice and teaching skills in telehealthcare delivery.},
  keywords = {Analysis,College graduates,Colleges & universities,COVID-19,Education,General & Internal Medicine,Health care,Health care facilities,Health Care Sciences & Services,Integration,Internal Medicine,Life Sciences & Biomedicine,Medical colleges,Medical education,Medical personnel,Medical records,Medical students,Medicine,Medicine & Public Health,Medicine General & Internal,Pandemics,Perspective,Science & Technology,Skills,Teaching,Telemedicine,Training},
  file = {/Users/colin.madland/Zotero/storage/7M84VRZY/noronhaTelehealthCompetenciesMedical2022.pdf}
}

@incollection{nortcliffeEffectiveAssignmentFeedback2010,
  title = {Effective {{Assignment Feedback}} through {{Timely}} and {{Personal Digital Audio Engagement}}},
  booktitle = {Technology-{{Supported Environments}} for {{Personalized Learning}}: {{Methods}} and {{Case Studies}}},
  author = {Nortcliffe, Anne and Middleton, Andrew},
  editor = {O'Donoghue, John},
  year = {2010},
  address = {Univeristy of Central Lancashire},
  abstract = {Audio feedback is a method that can provide rich, personal and detailed feedback that can convey more than the written word. This is particularly achieved through the capturing of the expressive quality of the speaker's voice. Audio feedback has the potential to promote student engagement in the feedback process, as it is not associated with the negative connotations of written feedback. This chapter will draw upon the growing literature base and recent research. It will indicate how different approaches to using audio technology can enhance the learning experience and the feedback process through its personal and timely qualities. The chapter will conclude with guidelines for best practice for implementation of audio feedback.}
}

@article{northHowOnlineLearning2014,
  title = {How Online Learning Can Help Address the Talent and Skills Challenge for the New Economy},
  author = {North, Contact},
  year = {2014},
  month = mar,
  journal = {Contact North},
  urldate = {2014-04-26},
  abstract = {As Premier Kathleen Wynne's call to action and the invitation to the March 18, 2014 Summit on Talent and Skills in the New Economy points out, Ontario, like all other jurisdictions in Canada, faces a major skills challenge now and for the foreseeable future.   A knowledge economy demands more skilled and highly qualified people at a time when many of those seeking work do not have the skills employers are looking for.  We need to a look at innovative approaches to building and sustaining a highly qualified workforce in Ontario.  One of the innovative (and cost-effective) ways to do this is through the systematic use of online learning, an area where Ontario is a recognized leader in Canada.}
}

@article{nortonLecturersViewsAssessment2019,
  title = {Lecturers' Views of Assessment Design, Marking and Feedback in Higher Education: A Case for Professionalisation?},
  author = {Norton, Lin and Floyd, Sarah and Norton, Bill},
  year = {2019},
  journal = {Assessment and evaluation in higher education},
  volume = {44},
  number = {8},
  pages = {1209--1221},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0260-2938},
  doi = {10/gmb8ht},
  abstract = {Research on professional assessment practice in higher education does not always take account of lecturers' perceptions and experiences, or their disciplinary context. This questionnaire study was designed to explore lecturers' views about three inter-related elements of professional assessment practice: assessment design, marking and feedback. It consisted of two questionnaires: the Assessment Design Inventory (ADI), previously published, and the Assessment, Marking and Feedback Inventory (AMFI) which was newly developed for this study. The two main purposes of the research were to: i) establish the validity of these two questionnaires as research tools, ii) explore the existence of professional practice in assessment and analyse any perceived hindrances as well as possible effects of participants' subject discipline. 356 lecturers from two UK universities, with a range of teaching experience and representing soft and hard disciplines, took part. Results indicated that the ADI and the AMFI were robust instruments. Findings showed evidence of assessment professionalism, but also some areas where it was lacking, together with a perceived need for formal training. Participants recognised that there were certain hindrances in putting their pedagogical beliefs into practice. The implications of this study are discussed in terms of advancing the sector's understanding of assessment professionalism.},
  keywords = {Assessment Literacy,assessment practice,assessment professionalism,Assessment questionnaires,Beliefs,College Faculty,Education & Educational Research,Feedback,Feedback (Response),Foreign Countries,Grading,Higher education,Intellectual Disciplines,lecturers' perceptions,Professionalism,Questionnaires,Research tools,Social Sciences,Student Evaluation,Teacher Attitudes,Test Construction,Test Validity}
}

@article{nortonRevitalisingAssessmentDesign2013,
  title = {Revitalising Assessment Design: What Is Holding New Lecturers Back?},
  author = {Norton, Lin and Norton, Bill and Shannon, Lee},
  year = {2013},
  month = aug,
  journal = {Higher Education},
  volume = {66},
  number = {2},
  pages = {233--251},
  issn = {1573-174X},
  doi = {10/gjsn4z},
  abstract = {This paper reports on a survey study exploring new lecturers' views on assessment design (using a questionnaire called the Assessment Design Inventory) with 586 newly qualified or still qualifying lecturers from UK universities. A factor analysis established two factors labelled `desirable practice' and `constraints'. Participants felt that their university teaching programmes had changed their views on assessment design and that assessment practices could be improved. Over 50~\% agreed that there were practical restrictions on assessment design. Findings revealed a perception that there is little incentive to innovate in assessment and that students may not welcome such innovation in any case. Further statistical analysis specified the `external' variables of institution and discipline to be important in shaping desirable practice and perception of constraints. `Individual' variables of gender, length of teaching experience and qualification status showed a statistically significant effect. These analyses demonstrate some key influences on new lecturers' views of assessment design and suggest reasons why they do not always feel able to put what they learn about assessment into practice.},
  file = {/Users/colin.madland/Zotero/storage/GC7CKR4X/nortonRevitalisingAssessmentDesign2013.pdf}
}

@article{nortonRevitalisingAssessmentDesign2013a,
  title = {Revitalising Assessment Design: {{What}} Is Holding New Lecturers Back?},
  author = {Norton, Lin and Norton, Bill and Shannon, Lee},
  year = {2013},
  journal = {Higher education},
  volume = {66},
  number = {2},
  pages = {233--251},
  publisher = {Springer},
  address = {Dordrecht},
  issn = {0018-1560},
  doi = {10/gjsn4z},
  abstract = {This paper reports on a survey study exploring new lecturers' views on assessment design (using a questionnaire called the Assessment Design Inventory) with 586 newly qualified or still qualifying lecturers from UK universities. A factor analysis established two factors labelled 'desirable practice' and 'constraints'. Participants felt that their university teaching programmes had changed their views on assessment design and that assessment practices could be improved. Over 50\_\% agreed that there were practical restrictions on assessment design. Findings revealed a perception that there is little incentive to innovate in assessment and that students may not welcome such innovation in any case. Further statistical analysis specified the 'external' variables of institution and discipline to be important in shaping desirable practice and perception of constraints. 'Individual' variables of gender, length of teaching experience and qualification status showed a statistically significant effect. These analyses demonstrate some key influences on new lecturers' views of assessment design and suggest reasons why they do not always feel able to put what they learn about assessment into practice. Reprinted by permission of Springer;This paper reports on a survey study exploring new lecturers' views on assessment design (using a questionnaire called the Assessment Design Inventory) with 586 newly qualified or still qualifying lecturers from UK universities. A factor analysis established two factors labelled 'desirable practice' and 'constraints'. Participants felt that their university teaching programmes had changed their views on assessment design and that assessment practices could be improved. Over 50 \% agreed that there were practical restrictions on assessment design. Findings revealed a perception that there is little incentive to innovate in assessment and that students may not welcome such innovation in any case. Further statistical analysis specified the 'external' variables of institution and discipline to be important in shaping desirable practice and perception of constraints. 'Individual' variables of gender, length of teaching experience and qualification status showed a statistically significant effect. These analyses demonstrate some key influences on new lecturers' views of assessment design and suggest reasons why they do not always feel able to put what they learn about assessment into practice.[PUBLICATION ABSTRACT];This paper reports on a survey study exploring new lecturers' views on assessment design (using a questionnaire called the Assessment Design Inventory) with 586 newly qualified or still qualifying lecturers from UK universities. A factor analysis established two factors labelled 'desirable practice' and 'constraints'. Participants felt that their university teaching programmes had changed their views on assessment design and that assessment practices could be improved. Over 50 \% agreed that there were practical restrictions on assessment design. Findings revealed a perception that there is little incentive to innovate in assessment and that students may not welcome such innovation in any case. Further statistical analysis specified the 'external' variables of institution and discipline to be important in shaping desirable practice and perception of constraints. 'Individual' variables of gender, length of teaching experience and qualification status showed a statistically significant effect. These analyses demonstrate some key influences on new lecturers' views of assessment design and suggest reasons why they do not always feel able to put what they learn about assessment into practice. (HRK / Abstract {\"u}bernommen).;This paper reports on a survey study exploring new lecturers' views on assessment design (using a questionnaire called the Assessment Design Inventory) with 586 newly qualified or still qualifying lecturers from UK universities. A factor analysis established two factors labelled 'desirable practice' and 'constraints'. Participants felt that their university teaching programmes had changed their views on assessment design and that assessment practices could be improved. Over 50 \% agreed that there were practical restrictions on assessment design. Findings revealed a perception that there is little incentive to innovate in assessment and that students may not welcome such innovation in any case. Further statistical analysis specified the 'external' variables of institution and discipline to be important in shaping desirable practice and perception of constraints. 'Individual' variables of gender, length of teaching experience and qualification status showed a statistically significant effect. These analyses demonstrate some key influences on new lecturers' views of assessment design and suggest reasons why they do not always feel able to put what they learn about assessment into practice. Adapted from the source document.;This paper reports on a survey study exploring new lecturers' views on assessment design (using a questionnaire called the Assessment Design Inventory) with 586 newly qualified or still qualifying lecturers from UK universities. A factor analysis established two factors labelled 'desirable practice' and 'constraints'. Participants felt that their university teaching programmes had changed their views on assessment design and that assessment practices could be improved. Over 50 \% agreed that there were practical restrictions on assessment design. Findings revealed a perception that there is little incentive to innovate in assessment and that students may not welcome such innovation in any case. Further statistical analysis specified the 'external' variables of institution and discipline to be important in shaping desirable practice and perception of constraints. 'Individual' variables of gender, length of teaching experience and qualification status showed a statistically significant effect. These analyses demonstrate some key influences on new lecturers' views of assessment design and suggest reasons why they do not always feel able to put what they learn about assessment into practice.;This paper reports on a survey study exploring new lecturers' views on assessment design (using a questionnaire called the Assessment Design Inventory) with 586 newly qualified or still qualifying lecturers from UK universities. A factor analysis established two factors labelled `desirable practice' and `constraints'. Participants felt that their university teaching programmes had changed their views on assessment design and that assessment practices could be improved. Over 50~\% agreed that there were practical restrictions on assessment design. Findings revealed a perception that there is little incentive to innovate in assessment and that students may not welcome such innovation in any case. Further statistical analysis specified the `external' variables of institution and discipline to be important in shaping desirable practice and perception of constraints. `Individual' variables of gender, length of teaching experience and qualification status showed a statistically significant effect. These analyses demonstrate some key influences on new lecturers' views of assessment design and suggest reasons why they do not always feel able to put what they learn about assessment into practice.;},
  keywords = {Assessment beliefs and practices,Assessment constraints,Assessment design,Assessment design inventory,Ausland,Beginning Teachers,Beliefs opinions and attitudes,Business metrics,College Faculty,College instruction,College teachers,Colleges & universities,Education,Education & Educational Research,Educational evaluation,Educational innovation,Educational research,Evaluation Methods,Factor Analysis,Foreign Countries,Forschung,Grossbritannien,Higher education,Hochschullehrer,Instructional design,Instructional Innovation,Inventory,Learning,Lehre,New lecturers,Public speaking,Quality control,Quantitative analysis,Questionnaires,Research,Research universities,Sex,Social Sciences,Statistical Analysis,Statistical Significance,Student,Student Evaluation,Studium,Surveys,Teacher Attitudes,Teacher Qualifications,Teaching,Teaching experience,Teaching methods,United Kingdom,Universities,Universities and colleges,University teaching programmes},
  file = {/Users/colin.madland/Zotero/storage/JKXW5FHE/Norton2013_Article_RevitalisingAssessmentDesignWh.pdf}
}

@article{nortonTeachersBeliefsIntentions2005,
  title = {Teachers' Beliefs and Intentions Concerning Teaching in Higher Education},
  author = {Norton, Lin and Richardson, T. E. and Hartley, James and Newstead, Stephen and Mayes, Jenny},
  year = {2005},
  month = nov,
  journal = {Higher Education},
  volume = {50},
  number = {4},
  pages = {537--571},
  issn = {0018-1560, 1573-174X},
  doi = {10/fgs287},
  urldate = {2021-04-25},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/VSZS945U/nortonTeachersBeliefsIntentions2005.pdf}
}

@article{Nortvedt_2020,
  title = {Aiding Culturally Responsive Assessment in Schools in a Globalising World},
  author = {Nortvedt, Guri A. and Wiese, Eline F. and Brown, Martin and Burns, Denise and McNamara, Gerry and O'Hara, Joe and Altrichter, Herbert and Fellner, Magdalena and {Herzog-Punzenberger}, Barbara and Nayir, Funda and Taneri, Pervin Oya},
  year = {2020},
  journal = {Educational Assessment, Evaluation and Accountability},
  doi = {10/ghhtsr},
  abstract = {Across the world, teachers' classroom assessment tasks and responsibilities are becoming more diverse due to increased migration. In this review, we address how migrant students are affected by assessment, both summative and formative, at the classroom level, with a focus on culturally responsive assessment (CRA). Previous research has shown that CRA practices mainly occur in student-centred classrooms. Furthermore, both student and teacher beliefs about teaching and learning might negatively affect migrant students' opportunities to engage in assessment situations. Teaching and assessment practices should be negotiated and aligned with and included in classroom norms to be culturally responsive. We propose that what is generally considered a valid and reliable assessment practice might need to be adjusted to account for students' cultural ways of knowing and participating and how this is expressed and communicated within the classroom.},
  mag_id = {3005222113},
  pmcid = {null},
  pmid = {null},
  keywords = {guskey},
  file = {/Users/colin.madland/Zotero/storage/D58K6SE6/Nortvedt_2020.pdf}
}

@article{noteboomStudentUserMapping,
  title = {The Student as User: Mapping Student Experiences of Platformisation in Higher Education},
  shorttitle = {The Student as User},
  author = {Noteboom, Joe},
  journal = {Learning, Media and Technology},
  volume = {0},
  number = {0},
  pages = {1--15},
  issn = {1743-9884},
  doi = {10.1080/17439884.2024.2414055},
  urldate = {2024-11-25},
  abstract = {This article builds on emerging accounts of the `student as user' to explore platformisation in higher education from the perspectives of students. While existing scholarship on platformisation and assetisation has highlighted important concerns about the distribution of power and value in contemporary higher education, much of this literature privileges a top-down focus on the edtech industry or the workings of particular platforms at the expense of lived experience. Departing from this critique, I explore what platformisation looks and feels like in the lives of students by presenting `platform maps' created and narrated by university students in Scotland. The accounts show how student agency is enabled, constrained and shaped by platformisation and how students come to depend on platforms in their everyday lives. In the process, students' lives and higher education more broadly become entangled with dynamics of platformisation in complicated and problematic ways.},
  keywords = {higher education,lived experience,Platformisation,student agency},
  file = {/Users/colin.madland/Zotero/storage/Y6F2WG92/Noteboom - The student as user mapping student experiences of platformisation in higher education.pdf}
}

@article{nsseFosteringStudentEngagement2011a,
  title = {Fostering Student Engagement Campuswide - Annual Results 2011},
  shorttitle = {Fostering Student Engagement Campuswide - Annual Results 2011},
  author = {NSSE},
  year = {2011},
  abstract = {The National Survey of Student Engagement (NSSE) documents dimensions of quality in undergraduate education and provides information and assistance to colleges, universities, and other organizations to improve student learning. Its primary activity is annually surveying college students to assess the extent to which they engage in educational practices associated with high levels of learning and development.},
  keywords = {nsse,student engagement}
}

@article{nurmikko-fullerConstructiveAlignmentAuthentic2020,
  title = {Constructive {{Alignment}} and {{Authentic Assessment}} in a {{Media-Rich Undergraduate Course}}},
  author = {{Nurmikko-Fuller}, Terhi and Hart, Ian E.},
  year = {2020},
  month = jan,
  journal = {Educational Media International},
  volume = {57},
  number = {2},
  pages = {167--182},
  publisher = {Educational Media International},
  issn = {0952-3987},
  doi = {10.1080/09523987.2020.1786775},
  abstract = {This paper describes the process of constructive alignment of the content and assessment of a first year university course on Digital Culture. Previous iterations of the course assessed the students using only written assignments, which proved to be problematic. In 2019 the course team decided to revise the assessment tasks in order to align them more closely with the media that the students were studying. We describe our methodology for constructive alignment that begins with a close examination of the learning outcomes (LOs), considers the authentic activities that support these LOs and develops assessment tasks, which are authentic and valid. We also describe how group projects contributed to the course structure and how peer assessment was designed to provide formative feedback to the students.},
  keywords = {Alignment (Education),College Freshmen,Constructivism (Learning),Feedback (Response),Formative Evaluation,Group Activities,Internet,Multimedia Materials,Peer Evaluation,Performance Based Assessment,Student Educational Objectives,Student Evaluation,Student Projects,Writing Assignments}
}

@article{nutbrownMeasuringImpactHigh2016,
  title = {Measuring the {{Impact}} of {{High Quality Instant Feedback}} on {{Learning}}},
  author = {Nutbrown, Stephen and Higgins, Colin and Beesley, Su},
  year = {2016},
  month = jan,
  journal = {Practitioner Research in Higher Education},
  volume = {10},
  number = {1},
  pages = {130--139},
  publisher = {Practitioner Research in Higher Education},
  issn = {1755-1382},
  abstract = {This paper examines the impact of a novel assessment technique that has been used to improve the feedback given to second year Computer Science students at the University of Nottingham. Criteria for effective, high quality feedback are discussed. An automated marking system (The Marker's Apprentice--TMA) produces instant feedback in synergy with the highlighted best practises. This paper investigates improvements in the work submitted by students after receiving this type of feedback. It draws upon surveys, as well as comparisons to previous cohorts for validating the positive impact of these techniques. It was found that the cohort (141 students) made 35\% fewer common mistakes on a subsequent exercise than the previous cohort. 100\% of students surveyed (35) claimed to have read the feedback, and 91\% agreed it clearly identified areas for improvement. 68\% agreed the feedback is useful for their learning, which is backed up by the improvements seen on the last exercise. Supported by these results, this paper concludes that following feedback best practises can have a substantial impact on learning, and that automated assessment can play a key role in providing this instant, high quality feedback. The results and similar techniques can be applied to other disciplines.},
  keywords = {College Students,Comparative Analysis,Computer Science Education,Feedback (Response),Foreign Countries,Formative Evaluation,Grading,Higher Education,No DOI found,Programming,Student Improvement,Student Surveys,Summative Evaluation,United Kingdom},
  file = {/Users/colin.madland/Zotero/storage/LV9Q4XII/nutbrownMeasuringImpactHigh2016.pdf}
}

@article{nwekeReliabilityAnalysisComplementary2019,
  title = {Reliability {{Analysis}} of {{Complementary Assessment Tools}} for {{Measuring Teacher Candidate Dispositions}}},
  author = {Nweke, Winifred C. and Perkins, Tasha P. and Afolabi, Comfort Y.},
  year = {2019},
  month = sep,
  journal = {Georgia Educational Researcher},
  volume = {16},
  number = {2},
  publisher = {Georgia Educational Researcher},
  issn = {2471-0059},
  doi = {10.20429/ger.2019.160202},
  abstract = {Assessing the dispositions of teacher candidates remains a challenge for many Educator Preparation Providers (EPPs). This article details the process and results of establishing the reliability of two complementary instruments, the "Candidate Beliefs Self-Assessment Survey" (SAS) and the "Candidate Dispositions Performance Assessment Rubric" (CDPA). The instruments are linked through the same dispositional themes that undergird the indicators in the CDPA and belief statements in the SAS. Internal consistency reliability coefficients were determined using Cronbach's alpha for SAS (0.81) and the CDPA (0.96). In addition, inter-rater reliability coefficient of 0.80 was determined for CDPA using Intraclass correlation (ICC) method based on one-way random model and absolute agreement. It is argued that using these instruments in tandem, SAS at program entry and CDPA as well as SAS at program exit, offers a viable solution to assessing and monitoring candidates' development and acquisition of dispositions needed for effective performance in the teaching profession.},
  keywords = {Elementary Secondary Education,Higher Education,Performance Based Assessment,Personality Traits,Preservice Teachers,Scoring Rubrics,Self Evaluation (Individuals),Student Characteristics,Test Reliability},
  file = {/Users/colin.madland/Zotero/storage/Z84V5IYT/nwekeReliabilityAnalysisComplementary2019.pdf}
}

@article{nylandTransactionlevelLearningAnalytics2017,
  ids = {nylandTransactionlevelLearningAnalytics2017a},
  title = {Transaction-Level Learning Analytics in Online Authentic Assessments},
  author = {Nyland, Rob and Davies, Randall S. and Chapman, John and Allen, Gove},
  year = {2017},
  journal = {Journal of computing in higher education},
  volume = {29},
  number = {2},
  pages = {201--217},
  publisher = {Springer US},
  address = {New York},
  issn = {1042-1726},
  doi = {10.1007/s12528-016-9122-0},
  abstract = {This paper presents a case for the use of transaction-level data when analyzing automated online assessment results to identify knowledge gaps and misconceptions for individual students. Transaction-level data, which records all of the steps a student uses to complete an assessment item, are preferred over traditional assessment formats that submit only the final answer, as the system can detect persistent misconceptions. In this study we collected transaction-level data from 996 students enrolled in an online introductory spreadsheet class. Each student's final answer and step-by-step attempts were coded for misconceptions or knowledge gaps regarding the use of absolute references over four assessment occasions. Overall, the level of error revealed was significantly higher in the step-by-step processes compared to the final submitted answers. Further analysis suggests that students most often have misconceptions regarding non-critical errors. Data analysis also suggests that misconceptions identified at the transaction level persist over time.},
  keywords = {Analysis,Data Analysis,Data mining,Distance learning,Education,Education & Educational Research,Educational evaluation,Educational Technology,Error Patterns,Evaluation Methods,Evidence Based Practice,Higher Education,Information management,Introductory Courses,Knowledge Level,Learning and Instruction,Misconceptions,Online Courses,Online instruction,Social Sciences,Spreadsheets,Student Evaluation,Students}
}

@misc{OAVersionWe2022,
  title = {({{OA}} Version) {{We}} Need to Get Online Learning Right before the next Crisis Hits},
  year = {2022},
  month = oct,
  journal = {George Veletsianos, PhD},
  urldate = {2024-06-05},
  abstract = {The Globe and Mail published an op-ed I wrote. As a condition of being featured in the publication, the paper has first publication rights for the first 48 hours. Since it's been more than 48 hours, and for posterity, I'm making a copy available below.},
  chapter = {futures},
  langid = {english}
}

@article{obermeyerDissectingRacialBias2019,
  title = {Dissecting Racial Bias in an Algorithm Used to Manage the Health of Populations},
  author = {Obermeyer, Ziad and Powers, Brian and Vogeli, Christine and Mullainathan, Sendhil},
  year = {2019},
  month = oct,
  journal = {Science},
  volume = {366},
  number = {6464},
  pages = {447--453},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aax2342},
  urldate = {2022-02-16},
  abstract = {Racial bias in health algorithms                            The U.S. health care system uses commercial algorithms to guide health decisions. Obermeyer               et al.               find evidence of racial bias in one widely used algorithm, such that Black patients assigned the same level of risk by the algorithm are sicker than White patients (see the Perspective by Benjamin). The authors estimated that this racial bias reduces the number of Black patients identified for extra care by more than half. Bias occurs because the algorithm uses health costs as a proxy for health needs. Less money is spent on Black patients who have the same level of need, and the algorithm thus falsely concludes that Black patients are healthier than equally sick White patients. Reformulating the algorithm so that it no longer uses costs as a proxy for needs eliminates the racial bias in predicting who needs extra care.                                         Science               , this issue p.               447               ; see also p.               421                        ,              A health algorithm that uses health costs as a proxy for health needs leads to racial bias against Black patients.           ,              Health systems rely on commercial prediction algorithms to identify and help patients with complex health needs. We show that a widely used algorithm, typical of this industry-wide approach and affecting millions of patients, exhibits significant racial bias: At a given risk score, Black patients are considerably sicker than White patients, as evidenced by signs of uncontrolled illnesses. Remedying this disparity would increase the percentage of Black patients receiving additional help from 17.7 to 46.5\%. The bias arises because the algorithm predicts health care costs rather than illness, but unequal access to care means that we spend less money caring for Black patients than for White patients. Thus, despite health care cost appearing to be an effective proxy for health by some measures of predictive accuracy, large racial biases arise. We suggest that the choice of convenient, seemingly effective proxies for ground truth can be an important source of algorithmic bias in many contexts.},
  langid = {english},
  keywords = {archived},
  annotation = {https://web.archive.org/web/20220216063532/https://www.science.org/action/cookieAbsent},
  file = {/Users/colin.madland/Zotero/storage/WIBNGXSM/obermeyerDissectingRacialBias2019.pdf}
}

@article{ockeyExploringPotentialVideoMediated2019,
  title = {Exploring the {{Potential}} of a {{Video-Mediated Interactive Speaking Assessment}}. {{Research Report}}. {{ETS RR-19-05}}},
  author = {Ockey, Gary J. and {Timpe-Laughlin}, Veronika and Davis, Larry and Gu, Lin},
  year = {2019},
  month = dec,
  journal = {ETS Research Report Series},
  publisher = {ETS Research Report Series},
  issn = {2330-8516},
  abstract = {The construct of oral ability is multifaceted, but due to technological and practical constraints, the majority of computer-delivered speaking assessments are designed to measure only certain aspects of this ability. Most notably, interactional competence, which we define as the ability to actively structure dialogic speech in real time, is often not assessed. Innovations in technology, namely, computermediated video, make it possible for test takers in different locations to see and speak with others in real time and may make it achievable for computer-based tests to assess more aspects of oral communication, including interactional competence. This report gives the findings from a study that explored to what extent computer-mediated video, namely, Skype, could function in conjunction with a platform designed to present four innovative speaking tasks that could conceivably assess a broad construct of oral ability. The overarching goals of this project were twofold. First, we aimed to determine (a) the degree to which current computer video-mediated technology can be used effectively to deliver assessments remotely and (b) the extent to which participants felt that four specific tasks could assess speaking ability by means of this technology. The speaking tasks included giving short responses to an interlocutor's questions, summarizing a proposal, defending a position in a group discussion, and giving a prepared presentation and responding to questions from other participants. Two data collections were conducted: one with all 72 participants located in the United States and one with all 74 participants located in China. The findings provide preliminary evidence that the stability of computer video-mediated technology varies considerably, with technical disruptions being relatively few in the U.S. trial but very frequent in the China context. Moreover, the findings suggest that participants viewed the tasks as generally representing interactive speaking activities that they encounter in the oral language use domain, affording them the opportunity to demonstrate their oral abilities, and that these tasks can be effectively completed in a computer video-mediated environment when technology cooperates.},
  keywords = {China (Guangzhou),China (Shanghai),College Students,Computer Assisted Testing,English Language Learners,Foreign Countries,Instructional Effectiveness,Interaction,Interpersonal Competence,No DOI found,Oral Language,Speech Skills,Student Satisfaction,Technology Integration,United States,Usability,Videoconferencing}
}

@incollection{odonnellAssessmentDigitalPractice2020,
  title = {Assessment as and of {{Digital Practice}}: {{Building Productive Digital Literacies}}},
  shorttitle = {Assessment as and of {{Digital Practice}}},
  booktitle = {Re-Imagining {{University Assessment}} in a {{Digital World}}},
  author = {O'Donnell, Marcus},
  editor = {Bearman, Margaret and Dawson, Phillip and Ajjawi, Rola and Tai, Joanna and Boud, David},
  year = {2020},
  volume = {7},
  pages = {111--125},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-41956-1_9},
  urldate = {2022-03-19},
  isbn = {978-3-030-41955-4 978-3-030-41956-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/9FARB56F/odonnellAssessmentDigitalPractice2020.pdf}
}

@misc{OERuOrg,
  title = {{{OERu}}.Org},
  urldate = {2018-11-05},
  howpublished = {https://oeru.org/},
  file = {/Users/colin.madland/Zotero/storage/UZSCMV5A/oeru.org.html}
}

@article{offerdahlChangesInstructorsAssessment2011,
  title = {Changes in Instructors' Assessment Thinking Related to Experimentation with New Strategies},
  author = {Offerdahl, Erika G. and Tomanek, Debra},
  year = {2011},
  journal = {Assessment and evaluation in higher education},
  volume = {36},
  number = {7},
  pages = {781--795},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0260-2938},
  doi = {10/d89z7p},
  abstract = {Formative assessment has been recognised as a critical element in teaching for conceptual development. A case study research design was employed to: (1) characterise the assessment thinking of three science instructors at a research-based university; and (2) examine the complex relationship between instructor thinking and practice by encouraging experimentation with alternative assessment strategies. Interviews, reflective journals, field notes and course documents were the data sources used to create a single case study that documented the development of these university instructors' assessment thinking during their experimentation with formative assessment strategies. Throughout two semesters of experimentation, the instructors' assessment thinking became more sophisticated; they grew to view the purpose of assessment less as a summative activity used for the assignment of marks and more as a tool for diagnosing student learning. However, more sophisticated thinking was not associated with revisions in teaching practice based on formative assessment data. Further investigations are needed to more completely understand the nature of assessment thinking and how assessment thinking influences assessment practices. Implications for professional development of university-level science instructors include personalised experiences through which instructors can become active participants in gathering evidence of student learning that promotes growth in assessment thinking. (Contains 1 note and 1 figure.);Formative assessment has been recognised as a critical element in teaching for conceptual development. A case study research design was employed to: (1) characterise the assessment thinking of three science instructors at a research-based university; and (2) examine the complex relationship between instructor thinking and practice by encouraging experimentation with alternative assessment strategies. Interviews, reflective journals, field notes and course documents were the data sources used to create a single case study that documented the development of these university instructors' assessment thinking during their experimentation with formative assessment strategies. Throughout two semesters of experimentation, the instructors' assessment thinking became more sophisticated; they grew to view the purpose of assessment less as a summative activity used for the assignment of marks and more as a tool for diagnosing student learning. However, more sophisticated thinking was not associated with revisions in teaching practice based on formative assessment data. Further investigations are needed to more completely understand the nature of assessment thinking and how assessment thinking influences assessment practices. Implications for professional development of university-level science instructors include personalised experiences through which instructors can become active participants in gathering evidence of student learning that promotes growth in assessment thinking.;Formative assessment has been recognised as a critical element in teaching for conceptual development. A case study research design was employed to: (1) characterise the assessment thinking of three science instructors at a research-based university; and (2) examine the complex relationship between instructor thinking and practice by encouraging experimentation with alternative assessment strategies. Interviews, reflective journals, field notes and course documents were the data sources used to create a single case study that documented the development of these university instructors' assessment thinking during their experimentation with formative assessment strategies. Throughout two semesters of experimentation, the instructors' assessment thinking became more sophisticated; they grew to view the purpose of assessment less as a summative activity used for the assignment of marks and more as a tool for diagnosing student learning. However, more sophisticated thinking was not associated with revisions in teaching practice based on formative assessment data. Further investigations are needed to more completely understand the nature of assessment thinking and how assessment thinking influences assessment practices. Implications for professional development of university-level science instructors include personalised experiences through which instructors can become active participants in gathering evidence of student learning that promotes growth in assessment thinking. [PUBLICATION ABSTRACT];},
  keywords = {Alternative Assessment,Case Studies,Cognition & reasoning,Cognitive processes,College Faculty,College professors,College students,Education & Educational Research,Educational evaluation,Evaluation Methods,formative assessment,Formative Evaluation,higher education,Learning,Research design,science education,Science Teachers,Social Sciences,Student teacher relationship,Teacher Attitudes,teacher cognition,Teacher education,teacher thinking,Teaching methods,United States (Southwest),university faculty},
  file = {/Users/colin.madland/Zotero/storage/375UY3GK/offerdahlChangesInstructorsAssessment2011.pdf}
}

@misc{officeofindigenousengagementIiTaapohtop,
  title = {Ii' Taa'poh'to'p},
  author = {{Office of Indigenous Engagement}},
  publisher = {University of Calgary},
  file = {/Users/colin.madland/Zotero/storage/IndigenousStrategy_Publication_digital_Sep2019.pdf}
}

@misc{officeofindigenousengagementWalkingParallelPaths,
  title = {Walking Parallel Paths, Together, in a Good Way {\textbar} {{University}} of {{Calgary}}},
  author = {{Office of Indigenous Engagement}},
  urldate = {2024-10-10},
  abstract = {The Office of Indigenous Engagement and ii' taa'poh'to'p guide UCalgary on its path of transformation, and communicate its commitment and responsibility for truth and reconciliation.},
  howpublished = {https://www.ucalgary.ca/indigenous},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/AX8N2TBN/indigenous.html}
}

@article{oflynn-mageeUncoveringNurseEducators2013,
  title = {Uncovering Nurse Educators Beliefs and Values about Grading Academic Papers Guidelines for Best Practices},
  author = {{O'Flynn-Magee}, Kathy and Clauson, Marion},
  year = {2013},
  journal = {Journal of Nursing Education},
  doi = {10/f5hvns},
  abstract = {Fair and consistent assessment, specifically grading, is crucial to teaching and learning scholarship and is a professional responsibility of nurse educators. Yet, many would agree that assessment is one of the most challenging aspects of their role. Despite differing beliefs, values, and meanings attributed to grading and grades, teachers' grading practices should be guided by principles and supported by policies. Inconsistent grading practices among educators, students' unrealistic expectations of grades, and a trend toward grade inflation may be contributing to both educators' and students' concerns. A teaching scholarship project that led to a research study explored nurse educators' beliefs, values, and practices related to the grading of written academic work. The purpose of this article is to share the findings and the resulting grading guidelines that were developed to support nurse educators' endeavors to enact equitable grading practices.},
  pmcid = {null},
  pmid = {23952770}
}

@article{oflynn-mageeUncoveringNurseEducators2013a,
  title = {Uncovering Nurse Educators Beliefs and Values about Grading Academic Papers Guidelines for Best Practices},
  author = {{O'Flynn-Magee}, Kathy and Clauson, Marion},
  year = {2013},
  journal = {Journal of Nursing Education},
  doi = {10/f5hvns},
  abstract = {Fair and consistent assessment, specifically grading, is crucial to teaching and learning scholarship and is a professional responsibility of nurse educators. Yet, many would agree that assessment is one of the most challenging aspects of their role. Despite differing beliefs, values, and meanings attributed to grading and grades, teachers' grading practices should be guided by principles and supported by policies. Inconsistent grading practices among educators, students' unrealistic expectations of grades, and a trend toward grade inflation may be contributing to both educators' and students' concerns. A teaching scholarship project that led to a research study explored nurse educators' beliefs, values, and practices related to the grading of written academic work. The purpose of this article is to share the findings and the resulting grading guidelines that were developed to support nurse educators' endeavors to enact equitable grading practices.},
  pmcid = {null},
  pmid = {23952770}
}

@article{ogan-bekirogluPreServiceTeachers2014,
  title = {Pre-service Teachers' Assessment Literacy and Its Implementation into Practice},
  author = {Ogan-Bekiroglu, Feral and Suzuk, Erol},
  year = {2014},
  month = sep,
  journal = {The Curriculum Journal},
  volume = {25},
  number = {3},
  pages = {344--371},
  issn = {0958-5176, 1469-3704},
  doi = {10/gmdnfr},
  urldate = {2021-08-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/HT8AYKSB/ogan-bekirogluPreServiceTeachers2014.pdf}
}

@article{ogangeStudentPerceptionsEffectiveness2018,
  ids = {ogangeStudentPerceptionsEffectiveness2018a},
  title = {Student {{Perceptions}} of the {{Effectiveness}} of {{Formative Assessment}} in an {{Online Learning Environment}}},
  author = {Ogange, Betty Obura and Agak, John O. and Okelo, Kevin Odhiambo and Kiprotich, Peter},
  year = {2018},
  journal = {Open Praxis},
  volume = {10},
  number = {1},
  pages = {29--39},
  issn = {EISSN-2304-070X},
  doi = {10/gmbv3j},
  abstract = {Assessment is an integral part of the teaching-learning process in both conventional and distance education contexts. Literature suggests that with the increase in the use of Information and Communications Technology in the delivery of learning, a number of institutions are resorting to formative assessment practices that are mediated by technology to not only provide flexible and more efficient means of assessment but also attain improved learning outcomes. This paper investigated student perceptions of the effectiveness of different types of formative assessment used in online learning environments. A 31-item questionnaire was used to gather data on student perceptions. On the level of difficulty, students generally perceived the various types of formative assessment as having no significant differences. Results further indicated that students received more prompt feedback from peer assessment and computer-marked assessment, compared to teacher-marked assessment. The findings of this study will support practitioners in eLearning to use formative assessment and feedback mechanisms more effectively to influence student engagement as well as learning outcomes.},
  langid = {english},
  keywords = {Assignments,Delivery Systems,Difficulty Level,eLearning,Evaluation Methods,Evaluation Research,feedback,Feedback (Response),Foreign Countries,formative assessment,Formative Evaluation,HIGHER-EDUCATION,Likert Scales,Online Courses,online learning,Questionnaires,Statistical Analysis,Student Attitudes,student perceptions,Undergraduate Students},
  file = {/Users/colin.madland/Zotero/storage/5J2VVWRG/ogangeStudentPerceptionsEffectiveness2018.pdf}
}

@article{okadaPedagogicalApproachesEAssessment2019,
  title = {Pedagogical {{Approaches}} for {{E-Assessment}} with {{Authentication}} and {{Authorship Verification}} in {{Higher Education}}},
  author = {Okada, Alexandra and Noguera, Ingrid and Alexieva, Lyubka and Rozeva, Anna and Kocdar, Serpil and Brouns, Francis and Ladonlahti, Tarja and Whitelock, Denise and {Guerrero-Rold{\'a}n}, Ana-Elena},
  year = {2019},
  month = nov,
  journal = {British Journal of Educational Technology},
  volume = {50},
  number = {6},
  pages = {3264--3282},
  publisher = {British Journal of Educational Technology},
  issn = {0007-1013},
  doi = {10.1111/bjet.12733},
  abstract = {Checking the identity of students and authorship of their online submissions is a major concern in Higher Education due to the increasing amount of plagiarism and cheating using the Internet. The literature on the effects of e-authentication systems for teaching staff is very limited because it is a novel procedure for them. A considerable gap is to understand teaching staff' views regarding the use of e-authentication instruments and how they impact trust in e-assessment. This mixed-method study examines the concerns and practices of 108 teaching staff who used the TeSLA--Adaptive Trust-based e-Assessment System in six countries: the UK, Spain, the Netherlands, Bulgaria, Finland and Turkey. The findings revealed some technological, organisational and pedagogical issues related to accessibility, security, privacy and e-assessment design and feedback. Recommendations are to provide a FAQ and an audit report with results, to raise awareness about data security and privacy, to develop policies and guidelines about fraud detection and prevention, e-assessment best practices and course team support.},
  keywords = {Audits (Verification),Bulgaria,Cheating,College Faculty,Computer Assisted Testing,Electronic Learning,Finland,Foreign Countries,Information Security,Internet,Netherlands,Plagiarism,Privacy,Spain,Teacher Attitudes,Trust (Psychology),Turkey,United Kingdom},
  file = {/Users/colin.madland/Zotero/storage/DMXRBK45/okadaPedagogicalApproachesEAssessment2019.pdf}
}

@article{olapiriyakulGuideEstablishingHybrid2006,
  title = {A Guide to Establishing Hybrid Learning Courses: {{Employing}} Information Technology to Create a New Learning Experience, and a Case Study},
  shorttitle = {A Guide to Establishing Hybrid Learning Courses},
  author = {Olapiriyakul, Kamolbhan and Scher, Julian M.},
  year = {2006},
  month = oct,
  journal = {The Internet and Higher Education},
  volume = {9},
  number = {4},
  pages = {287--301},
  issn = {10967516},
  doi = {10/fhrqrg},
  urldate = {2021-01-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/TFMTLNAR/olapiriyakulGuideEstablishingHybrid2006.pdf}
}

@article{olcottGoingOnlineLife2020,
  title = {Going {{Online}}: {{Life}} in the {{Online Fast Lane}} or so the {{Story Goes}}},
  author = {Olcott, Don},
  year = {2020},
  journal = {Asian Journal of Distance Education},
  volume = {15},
  number = {1},
  pages = {180--184},
  issn = {ISSN-1347-9008},
  abstract = {The COVID-19 pandemic has been an unprecedented catalyst for the scaling up from f2f to online teaching and learning. This editorial suggests that the post-pandemic period will be dominated by three primary groups -- The New Kids in Town, The Savvy Shifty Shifters, and the Retrenchment Innovators. Leaders in these groups will need to make major organizational decisions about their future in the online learning market. Leaders will need to lead their organizations through three main phases -- Phase 1 - emergency response; Phase 2 -- decision matrix; and 3) embedding the new organizational culture. Leadership will be crucial to navigating a highly competitive higher education landscape where more providers in online learning will create more options for students to pursue their higher education goals. Competition will be fierce and intense in higher education. Leaders will need to differentiate their organization from competitors and ensure that culture and context are considered in their vision. The game changer in this new normalcy will be visionary and transformational leadership.},
  langid = {english},
  keywords = {COVID-19,Distance Education,Elementary Secondary Education,Higher Education,No DOI found,Pandemics,Profiles,Transformational Leadership,Web Based Instruction}
}

@techreport{oldfieldAssessmentDigitalAge2012,
  title = {Assessment in a {{Digital Age}}: {{A}} Research Review},
  author = {Oldfield, Alison and Broadfoot, Patricia and Sutherland, Rosamund and Timmis, Sue},
  year = {2012},
  institution = {Graduate School of Education, University of Bristol},
  urldate = {2021-01-14},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/62HQFLYU/oldfieldAssessmentDigitalAge2012.pdf}
}

@article{olearyStateoftheartDigitalTechnologybased2018,
  title = {The State-of-the-Art in Digital Technology-Based Assessment},
  author = {O'Leary, Michael and Scully, Darina and Karakolidis, Anastasios and Pitsia, Vasiliki},
  year = {2018},
  journal = {European Journal of Education},
  volume = {53},
  number = {2},
  pages = {160--175},
  issn = {01418211},
  doi = {10.1111/ejed.12271},
  urldate = {2023-07-30},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/ZZMBAE8Y/olearyStateoftheartDigitalTechnologybased2018.pdf}
}

@article{Oliveira_2018,
  title = {Optimized Methodology Using Multi Choice Question Tests on Paper from Question Authoring to Grade Publishing},
  author = {{\noopsort{oliveira}}{de Oliveira}, Filipe Tiago},
  year = {2018},
  journal = {null},
  doi = {10/ghnhtb},
  abstract = {The introduction of the FCT Curricular Profile at Faculdade de Ciencias e Tecnologia, Universidade Nova de Lisboa, a pioneering pedagogical model in Portugal, allowed to accommodate transversal skills, such as research and entrepreneurialism, soft skills and contact with industry in all its BSc, MSc and integrated MSc curricula. Since these skills are increasingly being recognized by employes, the chances for the Faculdade de Ciencias e Tecnologia of Universidade Nova de Lisboa s students to be successful in the job market tend to increase. However, the calendar changes resulting from this pedagogical model imposed serious management problems concerning assessment using on-paper tests, specially to courses with a high number of enrolled students (ranging from 200 to 800).Here we present a methodology that is being used since 2012 that proved to successfully overcome those difficulties. The methodology embraces the whole process of assessment using on-paper tests from its beginning (test authoring) to grades publication. The methodology implementation enabled a significant decrease of faculty s exam/test proctoring time, reduced the grading time for less than an hour, and permitted a much more efficient use of university s rooms dedicated to tests. Moreover, allowed many professors to convey many hours previously spent in related test activities to their research and teaching innovation activities.},
  mag_id = {2907573461},
  pmcid = {null},
  pmid = {null}
}

@article{oliveiraQualityAssessmentOnline2021,
  title = {Quality {{Assessment}} of {{Online Discussion Forums}}: {{Construction}} and {{Validation}} of a {{Scale That Values Student Perception}}},
  author = {{\noopsort{oliveira}}de Oliveira, Alessandro Silva and Silva, Matheus Alberto Rodrigues and {\noopsort{silva}}da Silva, Dirceu and Borges, Richardson Coimbra},
  year = {2021},
  month = oct,
  journal = {Turkish Online Journal of Distance Education},
  volume = {22},
  number = {4},
  pages = {43--57},
  publisher = {Turkish Online Journal of Distance Education},
  issn = {1302-6488},
  abstract = {Online learning is a reality in much of the world. Among the tools available for online learning, there are Online Discussion Forums (ODF), due to their potential to promote collaborative learning. However, there is a lack in the literature about the evaluation of the forums, a gap marked by the absence of quantitative tools that make it possible to evaluate the forums from the student's perspective. In this sense, the objective of this paper was to develop and validate a Quality Perception of Online Discussion Forums (QPODF) scale. To this end, quantitative research was carried out with students of postgraduate courses "lato sensu" the online distance education. Exploratory factor analysis and confirmatory factor analysis was used to validate the QPODF scale. The results demonstrate that the quality of the construct perceived online discussion forums has two dimensions "Forum Structure" and "Forum Mediation." The two identified factors were shown to be consistent and accurate to measure the quality of online forums. Moreover, the theoretical approach used to compose the scale is convergent with the measurement model proposed in the paper.},
  keywords = {Attitude Measures,Brazil,Computer Mediated Communication,Cooperative Learning,Course Evaluation,Discussion Groups,Distance Education,Electronic Learning,Foreign Countries,Graduate Students,Instructional Effectiveness,No DOI found,Student Attitudes,Test Construction,Test Validity}
}

@article{oliverLearningTechnologyTheorising2013,
  title = {Learning Technology: {{Theorising}} the Tools We Study},
  shorttitle = {Learning Technology},
  author = {Oliver, Martin},
  year = {2013},
  month = jan,
  journal = {British Journal of Educational Technology},
  volume = {44},
  number = {1},
  pages = {31--43},
  issn = {00071013},
  doi = {10.1111/j.1467-8535.2011.01283.x},
  urldate = {2022-05-23},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/GXUQWKJ3/oliverLearningTechnologyTheorising2013.pdf}
}

@article{oliverTechnologicalDeterminismEducational2011,
  title = {Technological Determinism in Educational Technology Research: Some Alternative Ways of Thinking about the Relationship between Learning and Technology: {{Educational}} Technology and Determinism},
  shorttitle = {Technological Determinism in Educational Technology Research},
  author = {Oliver, M.},
  year = {2011},
  month = oct,
  journal = {Journal of Computer Assisted Learning},
  volume = {27},
  number = {5},
  pages = {373--384},
  issn = {02664909},
  doi = {10.1111/j.1365-2729.2011.00406.x},
  urldate = {2022-05-24},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/LWFV86ZE/oliverTechnologicalDeterminismEducational2011.pdf}
}

@book{olivierPerspectivesTeacherEducation2022,
  title = {Perspectives on {{Teacher Education}} in the {{Digital Age}}.},
  author = {Olivier, {\relax Jako}. and Oojorah, {\relax Avinash}. and Udhin, {\relax Waaiza}.},
  year = {2022},
  series = {Future {{Education}} and {{Learning Spaces Ser}}.},
  publisher = {Springer},
  address = {Singapore},
  isbn = {978-981-19-4226-6},
  keywords = {Electronic books},
  file = {/Users/colin.madland/Zotero/storage/SKNVCZI6/olivierPerspectivesTeacherEducation2022.pdf}
}

@article{olsenInvestigationTeachersEncouraged2019,
  title = {An {{Investigation}} of {{Teachers Encouraged}} to {{Reform Grading Practices}} in {{Secondary Schools}}},
  author = {Olsen, Brad and Buchanan, Rebecca},
  year = {2019},
  journal = {American Educational Research Journal},
  volume = {56},
  number = {5},
  pages = {2004--2039},
  issn = {0002-8312, 1935-1011},
  doi = {10/dt2k},
  urldate = {2020-10-11},
  abstract = {Despite the ubiquity and complexity of grading, there is limited contemporary research on grading students in schools. There is, however, an outpouring of publications and consultants promoting new approaches. Many eliminate effort and behavior scores, remove the zero, adopt a four-point system, advocate rubrics, or promote their own software packages. To study changes in grading, we collected data in two New York high schools undergoing a year-long professional development program on rethinking grading. We not only used existing literature on grading to frame our study but also relied on institutional theory and teacher identity as frameworks. We found that productive teacher change occurred, but it was partial, tentative, contingent on school-wide support, and not without frustration on the part of teachers.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/JYMYAWH7/olsenInvestigationTeachersEncouraged2019.pdf}
}

@misc{omahonyBiggestWasteAssessment2018,
  type = {Tweet},
  title = {Biggest Waste of Assessment Practices in {{Higher Ed}} Is That Students Work Is Provided to Those That Already Know about the Topic. {{Need}} to Structure Opportunities for Students to Create Work for External Agencies and Civil Society Organisations. @{{DevonDilly}} @{{CARL}}\_{{UCC}}},
  author = {O'Mahony, Dr Catherine},
  year = {2018},
  month = jun,
  journal = {@cath\_omahony},
  urldate = {2018-06-29},
  langid = {english},
  keywords = {plagiarism},
  file = {/Users/colin.madland/Zotero/storage/VD83RLP7/1012643576935780352.html}
}

@article{omarExploringRoleViewing2020,
  title = {Exploring the {{Role}} of {{Viewing Technologies}} in the {{Chemistry Classroom}}},
  author = {Omar, Kassem Ayman and Mozol, Vivian},
  year = {2020},
  month = jan,
  journal = {Papers on Postsecondary Learning and Teaching},
  volume = {4},
  pages = {68--75},
  publisher = {{Papers on Postsecondary Learning and Teaching}},
  issn = {2560-6050},
  abstract = {Spatial ability is an important tool in chemistry and this ability can be improved. Various technologies have been used to improve spatial ability. However, it is not clear if viewing technologies should take the place of the model kit; the traditional method of learning about molecular structures. Our research aims to address this gap. In our study, we aimed to take advantage of student affinity to technology to drive spatial ability improvements (in the context of chemistry) by having students experience molecules in virtual space using modern viewing technologies (WBVE, AR, and VR). Students were first engaged with the technologies then were assessed to see if their ability to solve problems relating to 3D-molecular structure improved. The mean spatial ability of students improved over the course of the semester (permutation test, p {$<$} 0.05) and students using model kits scored higher than those using the technologies (t-test, p {$<$} 0.05). The collection and assessment of anonymous, aggregated, student responses for this study was conducted with the approval of the University of Calgary ethics board (REB13-0724). [Articles in this journal were presented at the University of Calgary Conference on Postsecondary Learning and Teaching.]},
  keywords = {Canada (Calgary),Chemistry,Classroom Environment,Computer Simulation,Cost Effectiveness,Foreign Countries,Handheld Devices,Instructional Effectiveness,Introductory Courses,Manipulative Materials,Models,Molecular Structure,No DOI found,Projection Equipment,Science Instruction,Spatial Ability,Technology Integration,Telecommunications,Undergraduate Students}
}

@article{oneillModelingUndergraduatesSelection2021,
  title = {Modeling Undergraduates' Selection of Course Modality: {{A}} Large Sample, Multi-Discipline Study},
  author = {O'Neill, Kevin and Lopes, Nat{\'a}lia and Nesbit, John and Reinhardt, Suzanne and Jayasundera, Kanthi},
  year = {2021},
  journal = {The Internet and Higher Education},
  volume = {48},
  pages = {100776},
  issn = {1096-7516},
  doi = {10/ghwf67},
  keywords = {Course modality,In-person,Logistic regression,Online,Student choice}
}

@misc{OnlineEtymologyDictionary,
  title = {Online {{Etymology Dictionary}}},
  urldate = {2018-09-23},
  abstract = {The online etymology dictionary is the internet's go-to source for quick and reliable accounts of the origin and history of English words, phrases, and idioms. It is professional enough to satisfy academic standards, but accessible enough to be used by anyone. The site has become a favorite resource of teachers of reading, spelling, and English as a second language., The online etymology dictionary is the internet's go-to source for quick and reliable accounts of the origin and history of English words, phrases, and idioms. It is professional enough to satisfy academic standards, but accessible enough to be used by anyone. The site has become a favorite resource of teachers of reading, spelling, and English as a second language.},
  howpublished = {https://www.etymonline.com/},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/ZZ9KN9FZ/www.etymonline.com.html}
}

@article{onodipeUsingSmartphonesFormative2020,
  title = {Using {{Smartphones}} for {{Formative Assessment}} in the {{Flipped Classroom}}},
  author = {Onodipe, Grace and Ayadi, M. Femi},
  year = {2020},
  month = jan,
  journal = {Journal of Instructional Pedagogies},
  volume = {23},
  publisher = {Journal of Instructional Pedagogies},
  issn = {2327-5324},
  abstract = {Flipped classrooms are by design highly interactive. As a result, formative assessment is a necessary component of the flipped classroom. Professors need to be able to assess students' in the class, use this assessment information to inform classroom activities in real time and personalize learning for their students. One way to integrate formative assessment in the flipped class is with the use of smartphones. This paper describes strategies used to effectively incorporate smartphones into the classroom to enhance teaching and learning. Examples of innovative teaching practices to improve student understanding and performance using a classroom response system app are provided. Ways to capitalize on the benefits and minimize distractions from smartphone use are discussed. Data from exit surveys administered to assess students' perception of mobile technology effectiveness in the classroom are also reported. Results suggest that using this technology enhances student understanding of course concepts. Using the strategies outlined in this paper, professors will gain insight into students' understanding of course materials and these insights could be used to guide current and future lesson plans.},
  keywords = {Audience Response Systems,College Students,Educational Technology,Evaluation Methods,Formative Evaluation,Homework,Learner Engagement,No DOI found,Peer Teaching,Program Effectiveness,Student Attitudes,Student Evaluation,Teaching Methods,Technology Uses in Education,Video Technology},
  file = {/Users/colin.madland/Zotero/storage/FH3T2NQP/onodipeUsingSmartphonesFormative2020.pdf}
}

@misc{open,
  title = {Open},
  author = {Hoad, T. F.},
  year = {2003},
  month = jan,
  isbn = {9780192830982}
}

@misc{OpenAI2023,
  title = {{{OpenAI}}},
  year = {2023},
  urldate = {2023-11-02},
  abstract = {Watch OpenAI DevDay Keynote on Monday, November 6 at 10am},
  howpublished = {https://openai.com/},
  langid = {american}
}

@misc{openaiIntroducingChatGPT2022,
  title = {Introducing {{ChatGPT}}},
  author = {OpenAI},
  year = {2022},
  month = nov,
  journal = {OpenAI},
  urldate = {2023-04-17},
  abstract = {We've trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/HZNR2ZLC/chatgpt.html}
}

@misc{OpenBccampusCa,
  title = {Open.Bccampus.Ca},
  urldate = {2018-06-15},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/3PMFJQ9Y/open-textbook-stats.html}
}

@misc{OpenEducation,
  title = {Open {{Education}}},
  journal = {SPARC},
  urldate = {2018-09-23},
  abstract = {Open Education encompasses resources, tools and practices that can be fully used, shared and adapted in the digital environment. Open Education maximizes the power of the Internet to make education more affordable, accessible and effective.},
  howpublished = {https://sparcopen.org/open-education/},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/SARR4J2T/open-education.html}
}

@misc{OpenEducationalResources2017,
  title = {Open {{Educational Resources}} ({{OER}})},
  year = {2017},
  month = jul,
  journal = {UNESCO},
  urldate = {2018-11-05},
  howpublished = {https://en.unesco.org/themes/building-knowledge-societies/oer},
  langid = {english},
  keywords = {oer},
  file = {/Users/colin.madland/Zotero/storage/HHLQUBAG/oer.html}
}

@misc{OpenEducationConsortium,
  title = {About {{The Open Education Consortium}} {\textbar} {{The Open Education Consortium}}},
  urldate = {2018-11-05},
  howpublished = {https://www.oeconsortium.org/about-oec/},
  keywords = {definition,open education},
  file = {/Users/colin.madland/Zotero/storage/V53DA2IL/about-oec.html}
}

@misc{OpenEducationConsortiuma,
  title = {About {{The Open Education Consortium}} {\textbar} {{The Open Education Consortium}}},
  urldate = {2018-09-23},
  howpublished = {https://www.oeconsortium.org/about-oec/},
  file = {/Users/colin.madland/Zotero/storage/96ZV7V6T/about-oec.html}
}

@misc{OpenEducationSystem,
  title = {Open {{Education System}} {\textbar} {{Anadolu University}}},
  urldate = {2018-10-31},
  howpublished = {https://www.anadolu.edu.tr/en/open-education/openeducationsystem/open-education-system},
  keywords = {open education},
  file = {/Users/colin.madland/Zotero/storage/UXGEY4WV/open-education-system.html}
}

@misc{OpenOriginMeaning,
  title = {Open {\textbar} {{Origin}} and Meaning of Open by {{Online Etymology Dictionary}}},
  urldate = {2018-09-23},
  abstract = {Meaning: "not closed down, raised up" (of gates, eyelids, etc.), also "exposed, evident, well-known, public," often in a bad sense,{\dots} See more definitions.},
  howpublished = {https://www.etymonline.com/word/open},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/J2WUB7ZW/open.html}
}

@misc{OpenPedagogyVery2016,
  title = {Open Pedagogy and a Very Brief History of the Concept},
  year = {2016},
  month = dec,
  journal = {explorations in the ed tech world},
  urldate = {2018-10-20},
  abstract = {The good folks at \#OER17 have accepted my conference proposal on our University of Guadalajara faculty development program, which I positioned in the proposal as an example of an open pedagogy appr{\dots}},
  langid = {english},
  keywords = {history,OEP,open},
  file = {/Users/colin.madland/Zotero/storage/BIR52JIG/open-pedagogy-and-a-very-brief-history-of-the-concept.html}
}

@misc{OpenPeerReview,
  title = {Open {{Peer Review}}},
  journal = {Open Scholar},
  urldate = {2013-11-15},
  howpublished = {http://www.openscholar.org.uk/open-peer-review/}
}

@misc{OpenstaxOrg,
  title = {Openstax.Org},
  urldate = {2018-11-05},
  howpublished = {https://openstax.org/},
  file = {/Users/colin.madland/Zotero/storage/8FN3ITB3/openstax.org.html}
}

@incollection{oranjeEducationalSurveyAssessments2016,
  title = {Educational Survey Assessments},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {Oranje, Andreas and Keehner, Madeleine and Persky, Hilary and {Cayton-Hodges}, Gabrielle and Feng, Gary},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch18},
  pages = {427--445},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch18},
  abstract = {Summary Group-level educational survey assessments have traditionally not been designed for reporting on test taker's specific application of cognition because they are based on broad frameworks from which topics are sampled, rather than built from comprehensive and connected cognitive models and focused on probing aspects of those models. However, more recently assessment goals have been shifting, leading to a different view on what these assessments ought to produce, in part due to the affordances of technology that put expanding measurement and reporting goals within reach. In this chapter we describe how complex interactive tasks produce complex data streams that can be used to create rich narratives about test-takers and reflect a more differentiated understanding of the cognitive, meta-cognitive, and noncognitive factors that affect learning and performance. We argue that expanded large-scale assessment measurement and reporting goals require a significant level of cognitive and learning theory focused on tracking test-taker behaviors of interest and explaining the significance of what is tracked. We show several innovative examples from the NAEP program where important inroads have been made and discuss critical future developments in this line of work.},
  chapter = {18},
  isbn = {978-1-118-95658-8},
  keywords = {cognitive processes,complex assessment tasks,educational survey assessment,group score assessment,NAEP,process data,virtual performance assessments}
}

@article{orderRemixingCreativityLearning2017,
  title = {Remixing {{Creativity}} in {{Learning}} and {{Learning}} of {{Creativity}}: {{A Case Study}} of {{Audio Remix Practice}} with {{Undergraduate Students}}},
  shorttitle = {Remixing {{Creativity}} in {{Learning}} and {{Learning}} of {{Creativity}}},
  author = {Order, Simon and Murray, Leo and Prince, Jon and Hobson, Julia and {\noopsort{freitas}}de Freitas, Sara},
  year = {2017},
  month = dec,
  journal = {Asia Pacific Media Educator},
  volume = {27},
  number = {2},
  pages = {298--310},
  issn = {1326-365X, 2321-5410},
  doi = {10.1177/1326365X17728827},
  urldate = {2022-10-31},
  abstract = {Testing creativity in tertiary learning activities is a young field of research, and current assessment methods are difficult to apply within the diverse context of media production education, where disciplines range from journalism through to video game production. However, the concept of remix is common across this wide range of media, and offers practitioners `endless hybridizations in language, genre, content, technique and the like' (Knobel \& Lankshear, 2008, p. 22). The conceptual commonality of remix indicates that the study conclusions will have useful implications across a range of media production disciplines. This study aims to consider new methods for testing creativity in media production learning activities and to provide better assessments for learning design. This study focused upon a learner cohort of music technology students that were undertaking a work-integrated learning programme with a record label. To make the students more work-ready and inspire greater creativity, they remixed tracks recorded by professional music artists as part of a unit assessment. Subsequent self-report surveys ( N = 29) found that the process of creating a `remix' enhanced their creativity and provided suggested improvements to the design of the learning experience. Importantly, we found no relationship between the survey responses and objective assessments, indicating that the self-reported improvements in creativity were not simply a measure of how well the students performed the formally assessed tasks. Although more research is needed to establish effective measures of creativity, these findings demonstrate that self-report survey tools can be a powerful tool for measuring creativity and supporting improved iterative learning design.},
  langid = {english}
}

@article{orDevelopmentValidationInstrument2022,
  title = {Development and Validation of an Instrument to Measure Online Assessment Acceptance in Higher Education},
  author = {Or, Caleb and Chapman, Elaine},
  year = {2022},
  journal = {British journal of educational technology},
  volume = {53},
  number = {4},
  pages = {977--997},
  publisher = {Wiley},
  address = {HOBOKEN},
  issn = {0007-1013},
  doi = {10.1111/bjet.13180},
  abstract = {Many educational institutions have adopted online assessment in recent years. Previous studies on online assessment have often been tied to studies on learning management systems. As such, questions of online assessment acceptance have typically been overshadowed by a focus on the acceptance of learning management systems in general. The focus of the present research on online assessment is relatively rare. This paper describes the validation of an instrument to measure online assessment adoption by lecturers in higher education.~A total of 213~participants responded to a 20-item online questionnaire. With the data collected and the model fit, the instrument developed was able to meet the expectations to measure online assessment. The preliminary evidence of the validity of the extended Unified Theory of Acceptance and Use of Technology model, based on its reliability found in the current study, supports the use of the instrument as a technology acceptance framework for online assessment systems. Practitioner notes What is already known about this topic Unified Theory of Acceptance and Use of Technology (UTAUT) model has been found to be a reliable and robust model to study and explain technology acceptance and use across various educational contexts. In the UTAUT model, performance expectancy (PE), effort expectancy (EE), social influence (SI) and facilitating conditions are direct determinants of user acceptance and use behaviour. Subsequent validation by Venkatesh et al. (2003) in a longitudinal study found that the UTAUT model was a competent model that explained the relationships between PE, EE, SI and user behavioural intention (BI). What this paper adds An extended UTAUT model has been proposed, with the removal of EE as many UTAUT studies have shown that its influence has not been as consistent as compared to that of the other original constructs. In its place, constructs such as usability and learnability have been added as potential influences on both BI and use behaviour. Attitude as a construct has been added, as this was first included in an earlier Technology Acceptance Model but absent in the original UTAUT model. Development of a validated instrument suitable for assessing educators' acceptance of online assessment based on the extended UTAUT model. Implications for practice and/or policy The instrument proposed in this study can be used as a tool to examine educators' perception on online assessment. The instrument can also be used as a tool to inform educational institutions the factors that influence the successful implementation of online assessment or assessment-related systems. Based on its reliability found in the current study, this study supports the use of the instrument as a technology acceptance framework for online assessment systems.},
  keywords = {Acceptance tests,Analysis,Education & Educational Research,Education Higher,Educational tests & measurements,Higher education,Higher education institutions,Influence,Learning,Learning management systems,Management systems,online assessment,Reliability analysis,Social Sciences,technology acceptance,Technology Acceptance Model,Technology utilization,Unified Theory of Acceptance and Use of Technology},
  file = {/Users/colin.madland/Zotero/storage/HLKENZUK/orDevelopmentValidationInstrument2022.pdf}
}

@techreport{organisationforeconomiccooperationanddevelopmentPISA2021Creative2019,
  title = {{{PISA}} 2021 Creative Thinking Framework ({{Third Draft}})},
  author = {{Organisation for Economic Cooperation {and} Development}},
  year = {2019},
  institution = {{Organisation for Economic Cooperation and Development}},
  urldate = {2021-03-23},
  file = {/Users/colin.madland/Zotero/storage/DED6IDBS/organisationforeconomiccooperationanddevelopmentPISA2021Creative2019.pdf}
}

@article{orrDecolonizingMiKmaw2002,
  title = {Decolonizing {{Mi}}'kmaw Education through Cultural Practical Knowledge},
  author = {Orr, Jeff and Paul, John Jerome and Paul, Sharon},
  year = {2002},
  journal = {McGill Journal of Education},
  volume = {37},
  number = {3},
  pages = {331},
  issn = {0024-9033},
  abstract = {You have to feel the language in your heart: what good is it for me to do something that I don't want to do? When I'm doing attendance, they'll say, 'Here' in Mi'kmaq. At first they had a hard time with it, and then finally, no one laughed and they got it. If they want to leave the room for something, they have to ask in Mi'kmaq. It has to be encouraged in the home. The residential schools beat the Mi'kmaq out of us, and it's about time that someone put it back. Schools should treat their kids right and be a happy place where they want to go. Instead, all they hear is, `Get in line!' and `Sit down!' If you are walking with your kids and they're laughing, someone says, `Oh my gosh, she can't even keep her kids in a straight line.' To me, kids talking and making noise is learning. Sometimes if I want to work individually with one person, I'll pair the other students up and ask them to try and learn together. They're learning how to help each other, and that's the Mi'kmaq way. My class isn't about, 'Sit at your seat and raise your hand if you need to answer or ask a question.' There are days when I will be strict with assignments that need to be done, but there are days when I feel like learning is best when it is informal. If they come up to the front, ask questions, and sit on a desk, it's not necessarily a sign of disrespect. They don't have to sit in a chair to learn. It's a sign of comfort; they want to be close to me. They come to me and they are not afraid to ask any question, whether it be in terms of my life history or sexuality or whatever. They know I'll be honest with them, and I'm not afraid to answer. I'll answer in a professional manner, which makes it less intimidating for them. Most of the students fight to be near the front of the room. If kids are lying on the desks with their calculators, it doesn't bother me because they are learning. If you want to be comfortable, then so be it. We're all in this together, and we're respectful. I love my kids to be learning in that kind of environment, without telling them, 'sit at your seat, raise your hand, open your book and take your hat off.' It's more time-consuming, so I don't dwell on these things. But I won't tolerate swearing. And coming to class without your books is another one I discourage. But other than that, if students want to sit at my desk to listen, then fine, sit at my desk. If you want to type your notes, then sure, you don't have to use a pen. Not too many high school classes are like that. In my class we have a homework derby. Every time they do their homework they get a ballot and it goes in the derby for prizes. We draw every Friday, and they like to win stuff, so they always want homework, and they will finish it. They'll say, `Please, Miss, what's for homework? The bell's gonna ring!' At first I gave them homework that was easy, just to get them started on getting ballots. I fund it myself, but it really helps in terms of getting the students motivated to do their homework. I'm making it fun, and they know the more times they get ballots, the more chances they have to win on Fridays. They can't wait for Fridays; therefore my attendance is not so bad, because if you aren't here then you can't win. The kids do their homework more so than last year or first semester. One student in my class writes slower. I keep a photocopier in my class that helps him. There are days when he can keep up, but it's a struggle for him. Some days he tries so hard, and he just can't, so I tell him just to sit there and pay attention and we'll get the notes photocopied. Now he knows that if he's not able to keep up, he can sit down and relax and ask questions, if need be. I know he's learning, because when I ask a question, he'll answer in Mi'kmaq. So whose language am I going to evaluate him on, the language where he is perfectly correct or the language where he has no understanding of the big terms or words? When he tells me in Mi'kmaq, he knows his stuff, so I don't dwell too much on his expression in English. As long as he can answer in Mi'kmaq, that's all I want. I know he's learning.},
  keywords = {Native culture,Native education,Native North Americans,Native teachers}
}

@article{orsmondTutorsAssessmentPractices2017,
  title = {Tutors Assessment Practices and Students Situated Learning in Higher Education Chalk and Cheese},
  author = {Orsmond, Paul and Merry, Stephen},
  year = {2017},
  journal = {Assessment \& Evaluation in Higher Education},
  doi = {10/gcph6h},
  abstract = {This article uses situated learning theory to consider current tutor assessment and feedback practices in relation to learning practices employed by students outside the overt curriculum. The case is made that an emphasis on constructive alignment and explicitly articulating assessment requirements within curricula may be misplaced. Outside of the overt curriculum students appear to be interdependent learners, participating in communities of practice and learning networks, where sense-making occurs through negotiation and there is identity development. Such negotiation may translate curriculum requirements articulated by tutors into unexpected meanings. Hence, tutors' efforts might be better placed on developing students' ability to self-assess and to effectively evaluate and negotiate information, rather than primarily on their own delivery of the curriculum content and feedback. Tutors cannot be fully effective if they fail to consider students' learning outside the overt curriculum, and ways to facilit...},
  pmcid = {null},
  pmid = {null}
}

@article{orsmondTutorsAssessmentPractices2017a,
  title = {Tutors Assessment Practices and Students Situated Learning in Higher Education Chalk and Cheese},
  author = {Orsmond, Paul and Merry, Stephen},
  year = {2017},
  journal = {Assessment \& Evaluation in Higher Education},
  doi = {10/gcph6h},
  abstract = {This article uses situated learning theory to consider current tutor assessment and feedback practices in relation to learning practices employed by students outside the overt curriculum. The case is made that an emphasis on constructive alignment and explicitly articulating assessment requirements within curricula may be misplaced. Outside of the overt curriculum students appear to be interdependent learners, participating in communities of practice and learning networks, where sense-making occurs through negotiation and there is identity development. Such negotiation may translate curriculum requirements articulated by tutors into unexpected meanings. Hence, tutors' efforts might be better placed on developing students' ability to self-assess and to effectively evaluate and negotiate information, rather than primarily on their own delivery of the curriculum content and feedback. Tutors cannot be fully effective if they fail to consider students' learning outside the overt curriculum, and ways to facilit...},
  pmcid = {null},
  pmid = {null}
}

@article{orusEffectsLearnergeneratedVideos2016,
  title = {The Effects of Learner-Generated Videos for {{YouTube}} on Learning Outcomes and Satisfaction},
  author = {Or{\'u}s, Carlos and Barl{\'e}s, Mar{\'i}a Jos{\'e} and Belanche, Daniel and Casal{\'o}, Luis and Fraj, Elena and Gurrea, Raquel},
  year = {2016},
  month = apr,
  journal = {Computers \& Education},
  volume = {95},
  pages = {254--269},
  publisher = {Elsevier Science},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2016.01.007},
  abstract = {This paper presents the results of an educational innovation project based on learner-generated videos. The videos were created for a YouTube channel specifically developed for a marketing course. Despite the potential of YouTube as a learning tool in education, its use as a learning instrument for learner-generated content is scarce. In this project, students could voluntarily participate in the creation of videos, which were then uploaded to the channel by the professors. At the end of the course, students completed a questionnaire assessing learning outcomes and satisfaction. The findings showed that active participation had a direct influence on the perceived acquisition of cross-curricular competencies and on academic performance. While participation did not directly increase subjective learning or satisfaction with the course, it had an indirect influence through cross-curricular competencies. This research contributes to previous literature by showing how learner-generated content and the use of YouTube as a teaching vehicle has a positive impact on students' learning outcomes and satisfaction. (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
  keywords = {Computer Assisted Instruction,Curriculum,Digital Video,Interactive learning environments,Learning Environment,Marketing,Multimedia systems,Performance,Post-secondary education,Social Networks,Undergraduate Education,Video}
}

@article{osborneIntegratingTechnologiesAuthentic2013,
  title = {Integrating Technologies into "authentic'' Assessment Design: An Affordances Approach},
  author = {Osborne, Richard and Dunne, Elisabeth and Farrand, Paul},
  year = {2013},
  journal = {Research in learning technology},
  volume = {21},
  number = {1},
  pages = {1--18},
  publisher = {Assoc Learning Technology-Alt},
  address = {BICESTER},
  issn = {2156-7069},
  doi = {10.3402/rlt.v21i0.21986},
  abstract = {Current pressures in higher education around student employability are driving new initiatives for change. Assessment is also a topic of debate, as it is a key driver of student behaviour, yet often falls behind other metrics in national surveys. In addition, increasing focus on digital literacies is catalysing new appreciations of what emerging digital culture might mean for both students and staff. These three highly topical challenges were jointly explored by the University of Exeter's Collaborate project, which aimed to create employability-focused assessments enhanced by technology. By combining existing research on assessment with grounded data derived from local stakeholders, the project has developed a model for assessment design which embeds employability directly into the curriculum. Digital technologies have been aligned with this model using a "top trump'' metaphor, where key affordances of technologies are highlighted in the context of the model. This paper explores the design-based research approach taken to develop this model and associated "top trumps'', along with results from the first practical iteration. Results suggest that the model is effective in supporting the design of an "authentic'' assessment and that a targeted affordances approach can support the alignment of specific technologies with a particular pedagogic design.},
  keywords = {affordance,assessment,authentic,Collaboration,College Students,Computer Assisted Testing,Design,Distance learning,Education & Educational Research,Educational technology,employability,Employment Potential,England,evaluation,Flexibility,Foreign Countries,Higher education,Online instruction,Pedagogy,Perceptions,Performance Based Assessment,R&D,Research & development,Research Methodology,Social Sciences,Sociology,Student Evaluation,Students,Teaching,Test Construction},
  file = {/Users/colin.madland/Zotero/storage/AMK64ISD/osborneIntegratingTechnologiesAuthentic2013.pdf}
}

@article{OTESSAJournal,
  title = {{{OTESSA}} Journal},
  issn = {2564-4726}
}

@misc{OurBodiesEncoded2020,
  title = {Our {{Bodies Encoded}}: {{Algorithmic Test Proctoring}} in {{Higher Education}}},
  shorttitle = {Our {{Bodies Encoded}}},
  year = {2020},
  month = apr,
  journal = {Hybrid Pedagogy},
  urldate = {2020-04-11},
  abstract = {Cheating is not a technological problem, but a social and pedagogical problem. Technology is often blamed for creating the conditions in which cheating proliferates and is then offered as the solution to the problem it created; both claims are false.},
  howpublished = {https://hybridpedagogy.org/our-bodies-encoded-algorithmic-test-proctoring-in-higher-education/},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/KJ8E4G89/our-bodies-encoded-algorithmic-test-proctoring-in-higher-education.html}
}

@misc{oxfordenglishdictionaryLiteracy,
  title = {"literacy, n.".},
  author = {{Oxford English Dictionary}},
  howpublished = {https://www.oed.com/view/Entry/109054?redirectedFrom=literacy\&}
}

@article{oxfordInteractionCollaborationCooperation1997,
  title = {Interaction, {{Collaboration}}, and {{Cooperation}}: {{Learning Languages}} and {{Preparing Language Teachers}}: {{Introduction}} to the {{Special Issue}}},
  author = {Oxford, Rebecca L. and Nyikos, Martha},
  year = {1997},
  journal = {The Modern Language Journal},
  volume = {81},
  number = {4},
  pages = {440--442}
}

@article{oyinloyeImpactAssessmentLearning2019,
  title = {The {{Impact}} of {{Assessment}} for {{Learning}} on {{Learner Performance}} in {{Life Science}}},
  author = {Oyinloye, Oluwatoyin Mary and Imenda, Sitwala Namwinji},
  year = {2019},
  month = may,
  journal = {EURASIA Journal of Mathematics, Science and Technology Education},
  volume = {15},
  number = {11},
  issn = {13058223},
  doi = {10/ghbwnt},
  urldate = {2020-09-17},
  file = {/Users/colin.madland/Zotero/storage/IAFIBUUA/oyinloyeImpactAssessmentLearning2019.pdf}
}

@article{ozkaraComparisonCollaborativeIndividual2020,
  title = {Comparison of {{Collaborative}} and {{Individual Learning}} in {{Online Learning}}},
  author = {Ozkara, Betul Ozaydin and Cakir, Hasan},
  year = {2020},
  journal = {Turkish Online Journal of Educational Technology - TOJET},
  volume = {19},
  number = {4},
  pages = {66--74},
  issn = {EISSN-2146-7242},
  abstract = {In the online learning environment, it is seen that problems arise in the absence of interaction. In order to prevent these problems, this study, which was carried out by taking into consideration the principles that are formed using the community of inquiry framework, took place during the 2014-2015 Spring Semester using 30 students from a vocational college located in the Turkish Mediterranean Region who enrolled in the "Graphic Animation" course. The study was used a pretest-posttest control group design. The control group constituted of students working with online problem based individual methods while the experimental group constituted of students working with online problem based collaborative learning methods. The groups were compared in terms of academic success, motivation and satisfaction. It was determined that the motivation was higher in the experimental group, while there was no difference in the achievement and satisfaction in the experimental group and the control group.},
  langid = {english},
  keywords = {Academic Achievement,College Students,Communities of Practice,Computer Mediated Communication,Cooperative Learning,Distance Education,Electronic Learning,Foreign Countries,Independent Study,Inquiry,No DOI found,Problem Based Learning,Public Colleges,Student Motivation,Student Satisfaction,Vocational Education}
}

@article{paakkariHealthEducationTeachers2022,
  title = {Health {{Education Teachers}}' {{Assessment Conceptions}} and {{Practices}}: {{Identifying Assessment Profiles}}},
  shorttitle = {Health {{Education Teachers}}' {{Assessment Conceptions}} and {{Practices}}},
  author = {Paakkari, Olli and Paakkari, Leena and Haapala, Henna and Hirvensalo, Mirja},
  year = {2022},
  month = jul,
  journal = {Educational Assessment},
  volume = {27},
  number = {3},
  pages = {285--299},
  issn = {1062-7197, 1532-6977},
  doi = {10.1080/10627197.2022.2063832},
  urldate = {2022-10-16},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/X84ZE422/paakkariHealthEducationTeachers2022.pdf}
}

@article{pacansky-brockHumanizingOnlineTeaching2020,
  title = {Humanizing {{Online Teaching}} to {{Equitize Higher Education}}},
  author = {{Pacansky-Brock}, Michelle and Smedshammer, Michael and {Vincent-Layton}, Kim},
  year = {2020},
  journal = {Current Issues in Education},
  volume = {21},
  number = {2},
  abstract = {Online courses are increasing access to college for students who have been traditionally left out of higher education. However, minoritized students are less likely to succeed online when compared to their White and Asian peers. As the student population becomes more diverse, colleges and universities have an opportunity to improve this problem by preparing faculty to design and facilitate inclusive online learning experiences that more effectively support the needs of all learners. This paper presents a model for humanized online teaching using a theoretical framework influenced by Culturally Responsive Teaching (CRT), social presence, validation theory, and Universal Design for Learning (UDL). Humanized online teaching ensures the noncognitive components of learning are addressed through instructor-student relationships and community, allowing connection and empathy to drive engagement and rigor. Six humanizing strategies with real teaching examples are discussed, in addition to goals for meaningful professional development to support the adoption of humanized online teaching.},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/ZE8GNLP6/pacansky-brockHumanizingOnlineTeaching2020.pdf}
}

@article{pageComparingTrendsGraduate2018,
  title = {Comparing {{Trends}} in {{Graduate Assessment}}: {{Face}}-to-{{Face}} vs. {{Online Learning}}},
  author = {Page, Lesley and Cherry, Mike},
  year = {2018},
  journal = {Assessment Update},
  volume = {30},
  number = {5},
  pages = {3--15},
  publisher = {Wiley Subscription Services, Inc},
  issn = {1041-6099},
  doi = {10/ggrgxq},
  keywords = {Online education}
}

@article{pagePRISMA2020Statement2021,
  title = {The {{PRISMA}} 2020 Statement: {{An}} Updated Guideline for Reporting Systematic Reviews},
  author = {Page, Matthew J. and McKenzie, Joanne E. and Bossuyt, Patrick M. and Boutron, Isabelle and Hoffmann, Tammy C. and Mulrow, Cynthia D. and Shamseer, Larissa and Tetzlaff, Jennifer M. and Akl, Elie A. and Brennan, Sue E. and Chou, Roger and Glanville, Julie and Grimshaw, Jeremy M. and Hr{\'o}bjartsson, Asbj{\o}rn and Lalu, Manoj M. and Li, Tianjing and Loder, Elizabeth W. and {Mayo-Wilson}, Evan and McDonald, Steve and McGuinness, Luke A. and Stewart, Lesley A. and Thomas, James and Tricco, Andrea C. and Welch, Vivian A. and Whiting, Penny and Moher, David},
  year = {2021},
  month = mar,
  journal = {PLOS Medicine},
  volume = {18},
  number = {3},
  pages = {e1003583},
  publisher = {Public Library of Science},
  doi = {10.1371/journal.pmed.1003583},
  abstract = {Matthew Page and co-authors describe PRISMA 2020, an updated reporting guideline for systematic reviews and meta-analyses.},
  file = {/Users/colin.madland/Zotero/storage/BAXKRZZS/pagePRISMA2020Statement2021.pdf}
}

@article{pagramTalesExamRoom2018,
  ids = {pagramTalesExamRoom2018a},
  title = {Tales from the {{Exam Room}}: {{Trialing}} an {{E-Exam System}} for {{Computer Education}} and {{Design}} and {{Technology Students}}},
  author = {Pagram, Jeremy and Cooper, Martin and Jin, Huifen and Campbell, Alistair},
  year = {2018},
  month = jan,
  journal = {Education Sciences},
  volume = {8},
  publisher = {Education Sciences},
  issn = {2227-7102},
  abstract = {The Centre for Schooling and Learning Technologies (CSaLT) at Edith Cowan University (ECU) was asked in 2016 to be the Western Australian arm of a national e-exam project. This project used a bespoke exam system installed on a USB-drive to deliver what would have been traditional paper-based exams in an enclosed computer-based environment that was isolated from the internet and any resources other than those provided by the lecturer. This paper looks at the two exams chosen by the Western Australian group for the trial; a programming exam for pre-service computing teachers and an occupational health and safety exam for pre-service design and technology teachers. Both groups were drawn from the Graduate Diploma in Education course at ECU. The paper looks at the nature of the exam environment and the procedure for creating e-exams. It also outlines the exam procedures used and examines the feedback provided by both the lecturers and students involved. Conclusions are drawn about the suitability of the e-exam system and improvements are recommended as well as a discussion about e-exams and digital assessment more generally.},
  keywords = {Australia,Computer Assisted Testing,computer education,Computer Science Education,Design,design and technology,digital assessment,E-exam,Evaluation Methods,Foreign Countries,Graduate Students,No DOI found,Occupational Safety and Health,Preservice Teachers,Student Attitudes,Technology Education,Test Construction},
  file = {/Users/colin.madland/Zotero/storage/33FEJEDG/pagramTalesExamRoom2018.pdf}
}

@article{panaderoChangesClassroomAssessment2022,
  title = {Changes in Classroom Assessment Practices during Emergency Remote Teaching Due to {{COVID-19}}},
  author = {Panadero, Ernesto and Fraile, Juan and Pinedo, Leire and {Rodr{\'i}guez-Hern{\'a}ndez}, Carlos and D{\'i}ez, Fernando},
  year = {2022},
  journal = {Assessment in education : principles, policy \& practice},
  volume = {29},
  number = {3},
  pages = {361--382},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0969-594X},
  doi = {10.1080/0969594X.2022.2067123},
  abstract = {This study explores the effects of the shift to emergency remote teaching on assessment practices due to COVID-19 lockdown. A total of 936 Spanish teachers from all educational levels ranging from early childhood to university participated in this nationwide survey. Four aspects were explored: (1) changes in the use of assessment instruments (e.g. exams); (2) changes in assessment criteria, standards and grading; (3) changes in the delivery of feedback and use of rubrics; and (4) changes in students' involvement in assessment (i.e. self- and peer assessment). In general, results are mixed, with some areas undergoing certain changes with the aim of adapting to the new situation (e.g. primary education teachers lowering their grading standards), whereas many other assessment practices have remained similar, especially among higher education teachers. Unfortunately, some of the assessment practices have worsened, such as students' involvement in assessment which has decreased.},
  keywords = {Assessment practices,Childhood,COVID-19,Distance learning,Education & Educational Research,Educational evaluation,Elementary education,emergency remote teaching,feedback,Higher education,Online instruction,online teaching,peer assessment,rubrics,self-assessment,Social Sciences,Students,Teachers,Teaching},
  file = {/Users/colin.madland/Zotero/storage/CL9B2GQ9/panaderoChangesClassroomAssessment2022.pdf}
}

@article{panaderoEffectsRubricsAcademic2023,
  title = {Effects of {{Rubrics}} on {{Academic Performance}}, {{Self-Regulated Learning}}, and Self-{{Efficacy}}: A {{Meta-analytic Review}}},
  author = {Panadero, Ernesto and Jonsson, Anders and Pinedo, Leire and {Fern{\'a}ndez-Castilla}, Bel{\'e}n},
  year = {2023},
  month = dec,
  journal = {Educational Psychology Review},
  volume = {35},
  number = {4},
  pages = {113},
  issn = {1573-336X},
  doi = {10.1007/s10648-023-09823-4},
  abstract = {Rubrics are widely used as instructional and learning instrument. Though they have been claimed to have positive effects on students' learning, these effects have not been meta-analyzed. Our aim was to synthesize the effects of rubrics on academic performance, self-regulated learning, and self-efficacy. The moderator effect of the following variables was also investigated: year of publication, gender, mean age, educational level, type of educational level (compulsory vs. higher education), number of sessions, number of assessment criteria, number of performance levels, use of self and peer assessment, research design, and empirical quality of the study. Standardized mean differences (for the three outcomes) and standardized mean changes (SMC; for academic performance) were calculated from the retrieved studies. After correcting for publication bias, a moderate and positive effect was found in favor of rubrics on academic performance (g\,=\,0.45, k\,=\,21, m\,=\,54, 95\% CI [0.312, 0.831]; SMC\,=\,0.38, 95\% CI [0.02, 0.75], k\,=\,12, m\,=\,30), whereas a small pooled effect was observed for self-regulated learning (g\,=\,0.23, k\,=\,5, m\,=\,17, 95\% CI [-0.15, 0.60]) and for self-efficacy (g\,=\,0.18, k\,=\,3, m\,=\,5, 95\% CI [-0.81, 0.91]). Most of the moderator variables were not significant. Importantly, to improve the quality of future reports on the effects of rubrics, we provide an instrument to be filled out for rubric scholars in forthcoming studies.},
  file = {/Users/colin.madland/Zotero/storage/2BY4Q5W2/panaderoEffectsRubricsAcademic2023.pdf}
}

@book{panitzDefinitionCollaborativeVs1996,
  title = {A Definition of Collaborative vs Cooperative Learning},
  author = {Panitz, Ted},
  year = {1996},
  volume = {2013},
  publisher = {London Metropolitan University}
}

@article{papanthymouAssessmentQualityElectronic2018,
  title = {Assessment of the {{Quality}} of {{Electronic Administrative Services}} in a {{Greek Higher Education Institution}}: ? {{Case Study}}},
  author = {Papanthymou, Anastasia and Darra, Maria},
  year = {2018},
  journal = {International Journal of Higher Education},
  volume = {7},
  number = {2},
  pages = {15--27},
  issn = {ISSN-1927-6044},
  doi = {10/gmbv3p},
  abstract = {The basic aim of this paper is to investigate the perceptions, attitudes and experiences of the students of the Department of Primary Education of University of the Aegean about the quality of the provided services to them by the Secretariat of Administrative Electronic Services. The survey was conducted during the second semester of the academic year 2016-2017 with the use of an anonymous written questionnaire which was answered by 128 undergraduate students of the Department of Primary Education of University of the Aegean. The results of the survey show that students primarily consider as the most important service for them the department's website and the service Studentsweb. The least important service for them is the communication platform uniway for mobiles. Also, the degree of satisfaction with electronic administrative services is related to the criteria: availability, ease of use, good organization, responsiveness of services to the needs and expectations of students, and the degree of information. Moreover, problems such as "Mistakes about courses' grades" and "Unsuccessful academic books' registration" appears to have a negative impact on the degree of satisfaction of students with the corresponding services in which the problems occur. The findings of this research can be useful to the administrative staff and faculty of University of the Aegean as they show the dimensions of electronic administrative services that are important and effective and satisfy or create problems for students.},
  langid = {english},
  keywords = {Access to Information,Case Studies,Educational Administration,Elementary Education,Foreign Countries,Gender Differences,Higher Education,Likert Scales,Questionnaires,Statistical Analysis,Student Attitudes,Student Satisfaction,Student Surveys,Technology Uses in Education,Undergraduate Students,Web Sites}
}

@article{papanthymouStudentSelfAssessmentHigher2018,
  title = {Student {{Self-Assessment}} in {{Higher Education}}: {{The International Experience}} and {{The Greek Example}}},
  author = {Papanthymou, Anastasia and Darra, Maria},
  year = {2018},
  journal = {World Journal of Education},
  volume = {8},
  number = {6},
  pages = {130--146},
  issn = {ISSN-1925-0746},
  doi = {10/gmbv3d},
  abstract = {This study is a review of 34 empirical studies internationally and in Greece from 2008-2018 and aims at investigating: a. the implementation of student self-assessment in Higher education and the outcomes on students, b. the ability of students to self-assess accurately and the factors that affect this ability. According to the main findings, self-assessment is implemented through various ways that include inter alia electronic and non-electronic self-assessment tools. Internationally, most studies have examined and proved the contribution of student self-assessment to improvement of performance and learning. Moreover, self-assessment develops self-regulating learning, increases self-confidence, motivates students to ask guidance from their professors and help from their peers, increases self-efficacy, students' awareness of self-assessment ability and self-control, makes students change attitudes towards course, prepares employability skills of students, reduces anxiety for assessment, increases students' responsibility about their learning, makes them have a critical view on their work and develops critical thinking skills. In Greece, it was found only one study that examined the implementation of student self-assessment in Higher education and its impact on students and findings indicate that self-assessment through a quiz improves performance, self-regulation, motivates students to try more and helps them identify gaps in their learning. Student self-assessment ability and factors that affect this ability have been examined only internationally, so in Greece there is a research gap concerning these parameters. Tertiary students can self-assess accurately and this ability depends on specific factors such as confidence, prior achievement, learning style, scaffolding from professors, training, dialogical interaction and dynamic assessment.},
  langid = {english},
  keywords = {Academic Achievement,College Students,Foreign Countries,Higher Education,Metacognition,Outcomes of Education,Self Esteem,Self Evaluation (Individuals),Student Attitudes,Tests}
}

@article{papapanouMedicalEducationChallenges2022,
  title = {Medical Education Challenges and Innovations during {{COVID-19}} Pandemic},
  author = {Papapanou, Michail and Routsi, Eleni and Tsamakis, Konstantinos and Fotis, Lampros and Marinos, Georgios and Lidoriki, Irene and Karamanou, Marianna and Papaioannou, Theodore G and Tsiptsios, Dimitrios and Smyrnis, Nikolaos and Rizos, Emmanouil and Schizas, Dimitrios},
  year = {2022},
  journal = {Postgraduate medical journal},
  volume = {98},
  number = {1159},
  pages = {321--327},
  publisher = {The Fellowship of Postgraduate Medicine},
  address = {LONDON},
  issn = {0032-5473},
  doi = {10.1136/postgradmedj-2021-140032},
  abstract = {COVID-19 pandemic has undoubtedly disrupted the well-established, traditional structure of medical education. {$T$}he new limitations of physical presence have accelerated the development of an online learning environment, comprising both of asynchronous and synchronous distance education, and the introduction of novel ways of student assessment. At the same time, this prolonged crisis had serious implications on the lives of medical students including their psychological well-being and the impact on their academic trajectories. The new reality has, on many occasions, triggered the `acting up' of medical students as frontline healthcare staff, which has been perceived by many of them as a positive learning and contributing experience, and has led to a variety of responses from the educational institutions. All things considered, the urgency for rapid and novel adaptations to the new circumstances has functioned as a springboard for remarkable innovations in medical education,including the promotion of a more ``evidence-based'' approach.},
  keywords = {Clinical medicine,Coronaviruses,COVID-19,COVID-19 - epidemiology,Disease transmission,Distance learning,Education and learning,Education Distance,Education Medical,Flexibility,General & Internal Medicine,Humans,Life Sciences & Biomedicine,Medical education,medical education & training,Medical schools,Medical students,Medicine General & Internal,Mental health,Online instruction,Pandemics,Patients,SARS-CoV-2,Science & Technology,Severe acute respiratory syndrome coronavirus 2,Students Medical,Teachers},
  file = {/Users/colin.madland/Zotero/storage/KKCGY9FW/papapanouMedicalEducationChallenges2022.pdf}
}

@book{papertMindstormsChildrenComputers1993,
  title = {Mindstorms: Children, Computers, and Powerful Ideas},
  shorttitle = {Mindstorms},
  author = {Papert, Seymour},
  year = {1993},
  edition = {2nd edition},
  publisher = {Basic Books},
  address = {New York, NY},
  isbn = {978-0-465-04629-4 978-0-465-04674-4 978-0-465-04627-0},
  langid = {english}
}

@techreport{papertPaperPresidentCommission1980,
  title = {Paper for the {{President}}'s {{Commission}} for a {{National Agenda}} for the 80s},
  author = {Papert, Seymour},
  year = {1980},
  urldate = {2022-10-01},
  file = {/Users/colin.madland/Zotero/storage/TKWCM5WS/president_paper.html}
}

@inproceedings{papertVisionEducationCapertonPapert1999,
  title = {Vision for {{Education}}: {{The Caperton-Papert Platform}}},
  booktitle = {91st Annual {{National Governors}}' {{Association}}},
  author = {Papert, Seymour and Caperton, Gaston},
  year = {1999},
  month = aug,
  address = {St. Louis, MO},
  urldate = {2022-10-01},
  abstract = {The approach of the 21st century has brought a chorus of pronouncements that "the information society" both requires and makes possible new forms of education. We totally agree with this. But we do not agree that tardiness in translating these declarations into reality can be ascribed, as it often is, to such factors as the lack of money, technology, standards or teacher training. Obviously there is need for improvement in all of those areas. But the primary lack is something very different -- a shortage of bold, coherent, inspiring yet realistic visions of what education could be like 10 and 20 years from now. What we mean by vision is not a blueprint but a compelling view of the "look and feel" of the future -- its needs, its opportunities and how we can prepare ourselves now to act on them. Vision allows us to look beyond the problems that beset us today, giving direction to our passage into the future. Even more important, vision energizes that passage by inspiring and guiding us into action.},
  file = {/Users/colin.madland/Zotero/storage/E9LKIBZP/Vision_for_education.html}
}

@article{paquettePedagogieOuverteInteractive2005,
  title = {{La p{\'e}dagogie ouverte et interactive}},
  author = {Paquette, Claude},
  year = {2005},
  abstract = {L'aventure de la p{\'e}dagogie ouverte et interactive a commenc{\'e} il y a plus de trente-cinq ans, donc, plus ou moins, au tournant de l'ann{\'e}e soixante-dix. Partout en Occident, le socle de la p{\'e}dagogie encyclop{\'e}dique est alors {\'e}branl{\'e} par de nouvelles visions de l'{\'e}ducation et de la p{\'e}dagogie. L'av{\`e}nement de la p{\'e}dagogie ouverte a d{\'e}but{\'e} par une remise en question de la p{\'e}dagogie dominante de l'{\'e}poque (qui, aujourd'hui en 2005, il faut bien l'admettre est toujours dominante).},
  langid = {french}
}

@book{parchomaFinestBlendGraduate2020,
  title = {The Finest Blend: Graduate Education in {{Canada}}},
  shorttitle = {The Finest Blend},
  author = {Parchoma, Gale and Power, Michael and Lock, Jennifer},
  year = {2020},
  abstract = {"As Canadian universities work to increase access to graduate education, many are adopting blended modes of delivery for courses and programs. Within this changing landscape of higher education, The Finest Blend answers the call for rigorous research into these methods to ensure quality learning and teaching experience and presents case studies of French and English universities across Canada that are experimenting with blended learning models in graduate programs. Drawing on various research methods, the contributors to the volume investigate the sustainability of blended learning, shifts in pedagogical practices, and the role of instructional designers. They share key practices for both graduate students and instructors and emphasize the importance of institutional and departmental support for both students and faculty transitioning to blended delivery modes. Touching on theory, design, delivery, facilitation, administration, and evaluation, this book provides a comprehensive overview of current practices and opportunities for blended learning success."--},
  isbn = {978-1-77199-277-0},
  langid = {english},
  annotation = {OCLC: 1130767174}
}

@incollection{pardoBidirectionalEffectData2020,
  title = {The {{Bi-directional Effect Between Data}} and {{Assessments}} in the {{Digital Age}}},
  booktitle = {Re-Imagining {{University Assessment}} in a {{Digital World}}},
  author = {Pardo, Abelardo and Reimann, Peter},
  editor = {Bearman, Margaret and Dawson, Phillip and Ajjawi, Rola and Tai, Joanna and Boud, David},
  year = {2020},
  volume = {7},
  pages = {165--178},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-41956-1_12},
  urldate = {2022-03-19},
  isbn = {978-3-030-41955-4 978-3-030-41956-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/3QHT9MU4/pardoBidirectionalEffectData2020.pdf}
}

@article{pardoUsingLearningAnalytics2019,
  title = {Using Learning Analytics to Scale the Provision of Personalised Feedback},
  author = {Pardo, Abelardo and Jovanovic, Jelena and Dawson, Shane and Ga{\v s}evi{\'c}, Dragan and Mirriahi, Negin},
  year = {2019},
  journal = {British Journal of Educational Technology},
  volume = {50},
  number = {1},
  pages = {128--138},
  publisher = {Wiley},
  address = {HOBOKEN},
  issn = {0007-1013},
  doi = {10.1111/bjet.12592},
  abstract = {There is little debate regarding the importance of student feedback for improving the learning process. However, there remain significant workload barriers for instructors that impede their capacity to provide timely and meaningful feedback. The increasing role technology is playing in the education space may provide novel solutions to this impediment. As students interact with the various learning technologies in their course of study, they create digital traces that can be captured and analysed. These digital traces form the new kind of data that are frequently used in learning analytics to develop actionable recommendations that can support student learning. This paper explores the use of such analytics to address the challenges impeding the capacity of instructors to provide personalised feedback at scale. The case study reported in the paper showed how the approach was associated with a positive impact on student perception of feedback quality and on academic achievement. The study was conducted with first year undergraduate engineering students enrolled in a computer systems course with a blended learning design across three consecutive years (N2013=290, N2014=316 and N2015=415). [Author abstract]},
  keywords = {Academic Achievement,Analytics,Blended Learning,Case studies,College Freshmen,Data Analysis,Education & Educational Research,Educational technology,Engineering Education,Feedback,Feedback (Response),First year students,Higher education,ICT in education,Individualized Instruction,Learning,Learning analytics,Social Sciences,Student Attitudes,Students,Teachers,Technology Uses in Education,Undergraduate Students},
  file = {/Users/colin.madland/Zotero/storage/6VMYHIGI/pardoUsingLearningAnalytics2019.pdf}
}

@misc{ParentsNasalLearners,
  title = {Parents {{Of Nasal Learners Demand Odor-Based Curriculum}}},
  journal = {The Onion},
  urldate = {2022-04-06},
  abstract = {COLUMBUS, OH--Backed by olfactory-education experts, parents of nasal learners are demanding that U.S. public schools provide odor-based curricula for their academically struggling children.},
  howpublished = {https://www.theonion.com/parents-of-nasal-learners-demand-odor-based-curriculum-1819565536},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/3AGIK97P/parents-of-nasal-learners-demand-odor-based-curriculum-1819565536.html}
}

@article{parisInstructorsPerspectivesChallenges2022,
  title = {Instructors' {{Perspectives}} of {{Challenges}} and {{Barriers}} to {{Providing Effective Feedback}}},
  author = {Paris, Brit},
  year = {2022},
  journal = {Teaching and learning inquiry},
  volume = {10},
  pages = {1--13},
  publisher = {{International Society for the Scholarship of Teaching and Learning (ISSOTL)}},
  address = {Calgary},
  issn = {2167-4779},
  doi = {10.20343/teachlearninqu.10.3},
  abstract = {Instructor perspectives regarding the challenges they experience in enacting effective feedback processes have not been the focus in the literature on effective feedback processes. This study investigated the challenges that instructors experienced in providing effective feedback to students between January and April 2020, particularly considering campus closures and the shift to online learning in response to the COVID-19 pandemic. This study consisted of six focus groups held between January and April 2020 with five instructors from different disciplines at the same institution with class sizes ranging from 14 to 82. Through a thematic analysis using a constant comparison method, it was found that the biggest challenges instructors experienced in providing effective feedback was their own workload, the disruption that student inaction on feedback brought to the feedback process, and how the instructors managed their own affective responses and mindsets towards feedback. These findings are discussed within the context of the COVID-19 pandemic and based on these findings, recommendations for instructors include considering their own limitations when designing feedback processes and checking their beliefs about feedback with their students' perspectives on feedback in order to align understanding.},
  keywords = {Class size,classroom assessment,Coronaviruses,COVID-19,Design,Distance learning,Feedback,feedback processes,Focus groups,instructor perspectives,Literacy,Pandemics,Students,written feedback},
  file = {/Users/colin.madland/Zotero/storage/CEPWB483/parisInstructorsPerspectivesChallenges2022.pdf}
}

@book{parkesCollegeClassroomAssessment2017,
  title = {The {{College Classroom Assessment Compendium}}: {{A Practical Guide}} to the {{College Instructor}}'s {{Daily Assessment Life}}},
  shorttitle = {The {{College Classroom Assessment Compendium}}},
  author = {Parkes, Jay and Zimmaro, Dawn},
  year = {2017},
  month = dec,
  edition = {1},
  publisher = {Routledge},
  doi = {10.4324/9781315283852},
  urldate = {2022-06-18},
  isbn = {978-1-315-28385-2},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/LTFX5ZXH/parkesCollegeClassroomAssessment2017.pdf}
}

@article{parkRefiningCompetencyModel2017,
  title = {Refining a {{Competency Model}} for {{Instructional Designers}} in the {{Context}} of {{Online Higher Education}}},
  author = {Park, Jae-Young and Luo, Heng},
  year = {2017},
  journal = {International Education Studies},
  volume = {10},
  number = {9},
  pages = {87--98},
  issn = {ISSN-1913-9020},
  doi = {10/ggmt7v},
  abstract = {This study investigates the instructional designers (IDs) competencies essential for the context of online higher education, and has selected an instruction design unit in a research university as a case of investigation. To identify and compare IDs competencies at organizational and individual levels, this study employed a mixed method to collect and analyze data based on a validated IDs competency model by the International Board of Standards for Training, Performance and Instruction (ibstpi) as a framework. Throughout the study, IDs' expected jobs/tasks and currently performed jobs/tasks were systematically analyzed, and the applicability of the ibstpi model in this specific context of online higher education was verified. Based on the empirical findings, this study proposed a refined competency model to improve IDs performance in human resources development and management practice.},
  langid = {english},
  keywords = {Case Studies,Competency Based Education,Content Analysis,Expertise,Higher Education,Instructional Design,Job Analysis,Likert Scales,Minimum Competency Testing,Mixed Methods Research,Models,Online Courses,Questionnaires,Skill Analysis,Task Analysis}
}

@article{pashlerLearningStylesConcepts2008,
  title = {Learning {{Styles}}: {{Concepts}} and {{Evidence}}},
  author = {Pashler, Harold and McDaniel, Mark and Rohrer, Doug and Bjork, Robert},
  year = {2008},
  month = dec,
  journal = {Psychological Science in the Public Interest},
  volume = {9},
  number = {3},
  pages = {105--119},
  publisher = {SAGE Publications Inc},
  issn = {1529-1006},
  doi = {10/cktcsf},
  urldate = {2020-06-10},
  abstract = {The term ?learning styles? refers to the concept that individuals differ in regard to what mode of instruction or study is most effective for them. Proponents of learning-style assessment contend that optimal instruction requires diagnosing individuals' learning style and tailoring instruction accordingly. Assessments of learning style typically ask people to evaluate what sort of information presentation they prefer (e.g., words versus pictures versus speech) and/or what kind of mental activity they find most engaging or congenial (e.g., analysis versus listening), although assessment instruments are extremely diverse. The most common?but not the only?hypothesis about the instructional relevance of learning styles is the meshing hypothesis, according to which instruction is best provided in a format that matches the preferences of the learner (e.g., for a ?visual learner,? emphasizing visual presentation of information).The learning-styles view has acquired great influence within the education field, and is frequently encountered at levels ranging from kindergarten to graduate school. There is a thriving industry devoted to publishing learning-styles tests and guidebooks for teachers, and many organizations offer professional development workshops for teachers and educators built around the concept of learning styles.The authors of the present review were charged with determining whether these practices are supported by scientific evidence. We concluded that any credible validation of learning-styles-based instruction requires robust documentation of a very particular type of experimental finding with several necessary criteria. First, students must be divided into groups on the basis of their learning styles, and then students from each group must be randomly assigned to receive one of multiple instructional methods. Next, students must then sit for a final test that is the same for all students. Finally, in order to demonstrate that optimal learning requires that students receive instruction tailored to their putative learning style, the experiment must reveal a specific type of interaction between learning style and instructional method: Students with one learning style achieve the best educational outcome when given an instructional method that differs from the instructional method producing the best outcome for students with a different learning style. In other words, the instructional method that proves most effective for students with one learning style is not the most effective method for students with a different learning style.Our review of the literature disclosed ample evidence that children and adults will, if asked, express preferences about how they prefer information to be presented to them. There is also plentiful evidence arguing that people differ in the degree to which they have some fairly specific aptitudes for different kinds of thinking and for processing different types of information. However, we found virtually no evidence for the interaction pattern mentioned above, which was judged to be a precondition for validating the educational applications of learning styles. Although the literature on learning styles is enormous, very few studies have even used an experimental methodology capable of testing the validity of learning styles applied to education. Moreover, of those that did use an appropriate method, several found results that flatly contradict the popular meshing hypothesis.We conclude therefore, that at present, there is no adequate evidence base to justify incorporating learning-styles assessments into general educational practice. Thus, limited education resources would better be devoted to adopting other educational practices that have a strong evidence base, of which there are an increasing number. However, given the lack of methodologically sound studies of learning styles, it would be an error to conclude that all possible versions of learning styles have been tested and found wanting; many have simply not been tested at all. Further research on the use of learning-styles assessment in instruction may in some cases be warranted, but such research needs to be performed appropriately.},
  file = {/Users/colin.madland/Zotero/storage/N5F954M4/pashlerLearningStylesConcepts2008.pdf}
}

@article{paskeviciusConceptualizingOpenEducational2017,
  title = {Conceptualizing {{Open Educational Practices}} through the {{Lens}} of {{Constructive Alignment}}},
  author = {Paskevicius, Michael},
  year = {2017},
  month = jun,
  journal = {Open Praxis},
  volume = {9},
  number = {2},
  pages = {125--140},
  issn = {2304-070X},
  urldate = {2018-10-04},
  copyright = {Copyright (c) 2017 Open Praxis},
  langid = {english},
  keywords = {constructive alignment,Creative Commons,educational development,innovation in teaching and learning,open educational practices (OEP),open educational resources},
  file = {/Users/colin.madland/Zotero/storage/PF7XUAR2/paskeviciusConceptualizingOpenEducational2017.pdf;/Users/colin.madland/Zotero/storage/FHHTPNWV/303.html}
}

@phdthesis{paskeviciusExploringEducatorsExperiences2018,
  title = {Exploring Educators Experiences Implementing Open Educational Practices},
  author = {Paskevicius, Michael},
  year = {2018},
  address = {Victoria, BC},
  urldate = {2021-06-29},
  abstract = {This research focuses on how educators are using openly accessible sources of knowledge and open-source tools in ways that impact their pedagogical designs. Using a phenomenological approach with self-identifying open education practitioners, I explore how open educational practices (OEP) are being actualized in formal higher education and impacting learning design. Specifically, I examine how educators are bringing elements of openness into their everyday teaching and learning practice using educational technologies. I draw upon Giddens (1986) structuration theory, further developed for use in technology adoption research most notably by DeSanctis and Poole (1994) and Orlikowski (2000). This approach positions technologies as being continually socially constructed, interpreted, and put into practice. In an organizational context, the use of technology is intrinsically linked with institutional properties, rules and norms, as well as individual perceptions and knowledge. The findings suggest that OEP represents an emerging form of learning design, which draws from existing models of constructivist and networked pedagogy. Open technologies are being used to support and enable active learning experiences, presenting and sharing learners work in real-time, allowing for formative feedback, peer review, and ultimately, promoting community-engaged coursework. By designing learning in this way, faculty offer learners an opportunity to consider and practice developing themselves as public citizens and develop the knowledge and literacies for working with copyright and controlling access to their online contributions, while presenting options for extending some of those rights to others. Inviting learners to share their work widely, demonstrates to them that their work has inherent value beyond the course and can be an opportunity to engage with their community. Dataset available: https://doi.org/10.5683/SP2/CA77BB},
  school = {University of Victoria},
  file = {/Users/colin.madland/Zotero/storage/5ARSXCYQ/paskeviciusExploringEducatorsExperiences2018.pdf}
}

@misc{paskeviciusOpenDataTranscripts2019,
  title = {Open {{Data Transcripts}} from the {{Study}}: {{Exploring Educators Experiences Implementing Open Educational Practices}}},
  shorttitle = {Open {{Data Transcripts}} from the {{Study}}},
  author = {Paskevicius, Michael},
  year = {2019},
  publisher = {Scholars Portal Dataverse},
  doi = {10.5683/SP2/CA77BB},
  urldate = {2021-06-30},
  abstract = {This dataset contains eight transcripts from interviews conducted with educators as part of a PhD study exploring open educational practices. The research focuses on how educators are using openly accessible sources of knowledge and open-source tools in ways that impact their pedagogical designs. Using a phenomenological approach with self-identifying open education practitioners, I explore how open educational practices are being actualized in formal higher education and impacting learning design. Specifically, I examine how educators are bringing elements of openness into their everyday teaching and learning practice using educational technologies. I draw upon Giddens (1986) structuration theory, further developed for use in technology adoption research most notably by DeSanctis and Poole (1994) and Orlikowski (2000). This approach positions technologies as being continually socially constructed, interpreted, and put into practice. In an organizational context, the use of technology is intrinsically linked with institutional properties, rules and norms, as well as individual perceptions and knowledge. The findings suggest that open educational practices represents an emerging form of learning design, which draws from existing models of constructivist and networked pedagogy. Open technologies are being used to support and enable active learning experiences, presenting and sharing learners work in real-time, allowing for formative feedback, peer review, and ultimately, promoting community-engaged coursework. By designing learning in this way, faculty offer learners an opportunity to consider and practice developing themselves as public citizens and develop the knowledge and literacies for working with copyright and controlling access to their online contributions, while presenting options for extending some of those rights to others. Inviting learners to share their work widely, demonstrates to them that their work has inherent value beyond the course and can be an opportunity to engage with their community.},
  collaborator = {Paskevicius, Michael}
}

@article{paskeviciusTheoreticalMethodologicalApproaches2021,
  title = {Theoretical and {{Methodological Approaches}} for {{Investigating Open Educational Practices}}},
  author = {Paskevicius, Michael and Irvine, Valerie},
  year = {2021},
  month = dec,
  journal = {The Open/Technology in Education, Society, and Scholarship Association Journal},
  volume = {1},
  number = {2},
  pages = {1--19},
  issn = {2564-4726},
  doi = {10.18357/otessaj.2021.1.2.11},
  urldate = {2023-01-28},
  abstract = {To date, the phenomenon associated with open education in relation to teaching and learning practices remains under-theorized in the literature, which represents both a challenge and opportunity for further research (Bulfin et al., 2013; Howard \& Maton, 2011; Knox, 2013; Veletsianos, 2015). There exists an opportunity to develop new theory, as well as to connect the phenomenon to existing theory from education, learning sciences, and pedagogical research. Much of the literature has focused on case studies, strategies for implementation, and broad approaches to institutional change which do not draw upon or develop theory. A significant amount of the empirical work reviewed makes no mention of a theoretical base aside from that of openness as a conceptual framework for considering education. Further, critical studies which examine the pedagogical and educational implications of the use of open educational resources (OER) and engagement in open educational practices (OEP) are even less common (Knox, 2013). In this paper, we share the results of a literature review which investigates both methodological and theoretical approaches used in the available research on open educational practices, with the goal of engaging participants in a critical review of the theoretical and methodological approaches to further advance research in this emerging space.},
  file = {/Users/colin.madland/Zotero/storage/C6A2GJMN/paskeviciusTheoreticalMethodologicalApproaches2021.pdf}
}

@inproceedings{pasquiniGradingDilemmaticSpace2020,
  title = {Grading as a {{Dilemmatic Space}}:  {{A Study}} of {{Teachers Negotiating Classroom Grading Dilemmas}}},
  booktitle = {Canadian {{Society}} for the {{Study}} of {{Education}}, {{Conference}} 2020},
  author = {Pasquini, Rapha{\"e}l and DeLuca, Christopher},
  year = {2020},
  address = {London (CA), Canada},
  urldate = {2021-03-25},
  abstract = {In this paper, we consider grading within a dilemmatic space in which teachers have to negotiate often competing policies, tools, consequences, contextual and social conditions, and assessment theories for decision-making. While previous research into grading has focused primarily on the reliability and composition of teachers' grades as well as the predictive and concurrent validity of grades, our research explores the ways teachers negotiate grades within a dilemmatic space. Specifically, the purpose of this study is to examine teachers' negotiated responses to classroom grading dilemmas. Data were collected from Canadian and Swiss secondary teachers through qualitative methods: interviews, focus groups, and writing reflections. Through inductive thematic analysis, results identified five themes that emerged from the articulation of grading dilemmas which collective characterize the dilemmatic space for teacher grading: (a) fairness, (b) justification of grading decisions and communication, (b) teacher investment, (d) commitments to learning, and (e) validity of grading systems for learning system. Collectively, these results hold implications for teacher assessment education and grading theory, specifically the consideration of grading as a cross-cultural phenomenon and grading as a dilemmatic space.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/XQBZSUV4/pasquiniGradingDilemmaticSpace2020.pdf}
}

@article{passeyTechnologyEnhancedLearning2019,
  title = {Technology-enhanced Learning: {{Rethinking}} the Term, the Concept and Its Theoretical Background},
  author = {Passey, Don},
  year = {2019},
  journal = {British journal of educational technology},
  volume = {50},
  number = {3},
  pages = {972--986},
  publisher = {Wiley},
  address = {HOBOKEN},
  issn = {0007-1013},
  doi = {10.1111/bjet.12783},
  abstract = {This theoretical paper is concerned with problematising the rethinking of theoretical backgrounds associated with one of the commonly used educational technology terms (fields)---technology-enhanced learning---in the wider context of scholarship. Examples will show that the term itself is now used beyond its apparent, stated scope, that it is used in a number of varied ways, and that this is in itself problematic. The ways in which the term is used will be identified, and from these a strategic categorisation to rethink the use of the single term in areas of scholarship (particularly research and teaching) will be proposed, offering terms specifically encompassing the realms in which technologies are being used. From this categorisation, it will be shown that each specific category is based on different conceptions related to or arising from practice. Consequently, ways that theoretical backgrounds should be considered will be explored in each case. While existing theoretical backgrounds enable conceptual underpinnings in some of those cases, in other cases it will be shown that there are currently no fully developed theories or limited theoretical frameworks available. The paper will conclude by identifying key research areas needed if we are to develop and take pertinent aspects of scholarship further forward.},
  keywords = {Classification,Education & Educational Research,Educational Technology,Learning,Scholarship,Social Sciences,Technology Uses in Education,Theories,Vocabulary},
  file = {/Users/colin.madland/Zotero/storage/6QQD67BD/passeyTechnologyEnhancedLearning2019.pdf}
}

@article{pastoreStudentEyesAssessment2020,
  title = {Through Student Eyes: {{Assessment}} Conceptions and Quality Assurance},
  shorttitle = {Through Student Eyes},
  author = {Pastore, Serafina},
  year = {2020},
  month = dec,
  journal = {Journal of Praxis in Higher Education},
  volume = {2},
  number = {2},
  pages = {58--81},
  issn = {2003-3605},
  doi = {10/gmc6b9},
  urldate = {2021-08-01},
  abstract = {Recent reforms of higher education systems in Europe, since the implementation of the Bologna Process, encourage teachers to incorporate a range of assessment practices that should be more responsive to students' learning needs. Over the years, an extensive body of literature has been produced regarding principles and practice guidelines for the assessment of students' learning outcomes. However, what are students' conceptions of assessment? The present article, given the strong drive to understand the role that conceptions have in educational practices, focuses on students' conceptions of assessment within the Italian higher education system. More specifically, this paper reports on a research study realised through the administration of the Students' Conceptions of Assessment Inventory (SCoA). The data were analysed using a Confirmatory Factor Analysis (CFA) design. This study represents a useful step in understanding conceptions that students have of assessment within the framework of quality assurance. Results of the study may set the groundwork for a critical debate on changes and improvements in the higher education field.},
  file = {/Users/colin.madland/Zotero/storage/A7WXA5SX/pastoreStudentEyesAssessment2020.pdf}
}

@article{pastoreTeacherAssessmentLiteracy2019,
  ids = {be4416924b23cc45fbba7460a40eeec59456e155},
  title = {Teacher Assessment Literacy: {{A}} Three-Dimensional Model},
  shorttitle = {Teacher Assessment Literacy},
  author = {Pastore, Serafina and Andrade, Heidi L.},
  year = {2019},
  journal = {Teaching and Teacher Education},
  volume = {84},
  pages = {128--138},
  issn = {0742051X},
  doi = {10/gh5k7b},
  urldate = {2021-07-10},
  abstract = {Assessment literacy has been recognized as important for teachers because it helps them use information about student learning to teach more effectively by responding to students' learning needs. The aim of this paper is to present an updated, expanded model of assessment literacy that represents three key aspects of assessment literacy in context. The paper reports the results of a Delphi inquiry with inter- national experts on educational assessment and teacher education. Conclusions include implications for research on educational assessment and teacher professional development.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/EAHBQYT4/pastoreTeacherAssessmentLiteracy2019.docx;/Users/colin.madland/Zotero/storage/IRCBKU8I/pastoreTeacherAssessmentLiteracy2019.pdf}
}

@article{patallImplicationsOpenScience2021,
  title = {Implications of the Open Science Era for Educational Psychology Research Syntheses},
  author = {Patall, Erika A.},
  year = {2021},
  month = apr,
  journal = {Educational Psychologist},
  volume = {56},
  number = {2},
  pages = {142--160},
  issn = {0046-1520, 1532-6985},
  doi = {10.1080/00461520.2021.1897009},
  urldate = {2022-09-25},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/CD7HSL56/patallImplicationsOpenScience2021.pdf}
}

@article{patersonExploringCollaborationOnline2020,
  title = {Exploring {{Collaboration}} in {{Online Group Based Assessment Contexts}}: {{Undergraduate Business Program}}},
  author = {Paterson, Terrie and Prideaux, Murray},
  year = {2020},
  journal = {Journal of University Teaching and Learning Practice},
  volume = {17},
  number = {3},
  issn = {EISSN-1449-9789},
  abstract = {Focussing on a specific higher education online learning environment (OLE), this study aims to investigate and analyse instructional designs that employ Positive Interdependence, Individual Accountability, Teaching Presence, Authenticity and Group Skills Development as educational strategies to mitigate group work issues and subsequently encourage collaborative group work. Group work is a challenging learning space for both participants and facilitators in the higher education sector. Known issues such as free riding, unfair marking and a lack of existing group work skills in the student cohort, create a catalyst for conflict which can lead to negative perceptions and avoidance of group work. Isolation and the resulting independent learning culture typifying online study contexts further challenge collaborative and active learning pedagogies required in contemporary online adult learning and assessment contexts.},
  langid = {english},
  keywords = {Accountability,Asynchronous Communication,Business Administration Education,Cooperative Education,Experiential Learning,Foreign Countries,Group Dynamics,Instructional Design,Interpersonal Competence,No DOI found,Online Courses,Skill Development,Student Evaluation,Synchronous Communication,Teacher Student Relationship,Teaching Methods,Undergraduate Students}
}

@article{patriciosConsensusStatementConcussion2023,
  title = {Consensus Statement on Concussion in Sport: The 6th {{International Conference}} on {{Concussion}} in {{Sport}}--{{Amsterdam}}, {{October}} 2022},
  author = {Patricios, Jon S and Schneider, Kathryn J and Dvorak, Jiri and Ahmed, Osman Hassan and Blauwet, Cheri and Cantu, Robert C and Davis, Gavin A and Echemendia, Ruben J and Makdissi, Michael and McNamee, Michael and Broglio, Steven and Emery, Carolyn A and {Feddermann-Demont}, Nina and Fuller, Gordon Ward and Giza, Christopher C and Guskiewicz, Kevin M and Hainline, Brian and Iverson, Grant L and Kutcher, Jeffrey S and Leddy, John J and Maddocks, David and Manley, Geoff and McCrea, Michael and Purcell, Laura K and Putukian, Margot and Sato, Haruhiko and Tuominen, Markku P and Turner, Michael and Yeates, Keith Owen and Herring, Stanley A and Meeuwisse, Willem},
  year = {2023},
  month = jun,
  journal = {British Journal of Sports Medicine},
  volume = {57},
  number = {11},
  pages = {695},
  doi = {10.1136/bjsports-2023-106898},
  abstract = {For over two decades, the Concussion in Sport Group has held meetings and developed five international statements on concussion in sport. This 6th statement summarises the processes and outcomes of the 6th International Conference on Concussion in Sport held in Amsterdam on 27--30 October 2022 and should be read in conjunction with the (1) methodology paper that outlines the consensus process in detail and (2) 10 systematic reviews that informed the conference outcomes. Over 3{$\frac{1}{2}$} years, author groups conducted systematic reviews of predetermined priority topics relevant to concussion in sport. The format of the conference, expert panel meetings and workshops to revise or develop new clinical assessment tools, as described in the methodology paper, evolved from previous consensus meetings with several new components. Apart from this consensus statement, the conference process yielded revised tools including the Concussion Recognition Tool-6 (CRT6) and Sport Concussion Assessment Tool-6 (SCAT6, Child SCAT6), as well as a new tool, the Sport Concussion Office Assessment Tool-6 (SCOAT6, Child SCOAT6). This consensus process also integrated new features including a focus on the para athlete, the athlete's perspective, concussion-specific medical ethics and matters related to both athlete retirement and the potential long-term effects of SRC, including neurodegenerative disease. This statement summarises evidence-informed principles of concussion prevention, assessment and management, and emphasises those areas requiring more research.},
  file = {/Users/colin.madland/Zotero/storage/patriciosConsensusStatementConcussion2023.pdf}
}

@book{patsulaApplyingLearningTheories1999,
  title = {Applying {{Learning Theories}} to {{Online Instructional Design}}},
  author = {Patsula, Peter J},
  year = {1999},
  volume = {2010},
  publisher = {Sookmyung Women's University}
}

@article{pattersonGoingDigitalEnhance2020,
  title = {Going Digital to Enhance the Learning of Undergraduate Students},
  author = {Patterson, Nicholas and Schultz, Madeleine and {Wood-Bradley}, Guy and Lanham, Elicia and Adachi, Chie},
  year = {2020},
  month = jul,
  journal = {Journal of University Teaching and Learning Practice},
  volume = {17},
  number = {3},
  pages = {70--85},
  issn = {14499789, 14499789},
  doi = {10.53761/1.17.3.6},
  urldate = {2023-01-15},
  abstract = {The aim of this study was to investigate which of three types of video resources, and which additional resources, were preferred by Information Technology (IT) students for learning and exam preparation. We offered three types of video learning resources to support the delivery of a first year undergraduate IT course. We collated quantitative data on engagement with each video resource through the Learning Management System, drew further insights from an online survey of the students and combined this with data obtained from an institutional student evaluation survey. Whilst there has been much research conducted about the use of video lectures and other online resources, there has been little research conducted specifically with IT students to determine their preferences when selecting learning resources. We report the preferences of IT undergraduate students when provided with a selection of video learning materials, how the resources were used and their perceived learning value. This study not only offers a set of considerations and recommendations for the design of learning materials for IT students, but also for digital learning in higher-education more generally. Short premium videos were watched many more times than full lectures, and 85\% of students agreed that short premium videos were more beneficial and effective than longer, lower quality lecture recordings for their learning. The students' self-assessed video attention span varied greatly, with a mean of 10 minutes. Students perceived that short premium videos helped them to retain knowledge. However, the perceived most useful resource overall was the lecture slides.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/5FBE7WQC/pattersonGoingDigitalEnhance2020.pdf}
}

@article{paunaCalculusCoursesAssessment2017,
  ids = {paunaCalculusCoursesAssessment2017a},
  title = {Calculus {{Courses}}' {{Assessment Data}}},
  author = {Pauna, Matti},
  year = {2017},
  journal = {Journal of Learning Analytics},
  volume = {4},
  number = {2},
  pages = {12--21},
  publisher = {Journal of Learning Analytics},
  issn = {EISSN-1929-7750},
  doi = {10/gmbv2k},
  abstract = {In this paper we describe computer-aided assessment methods used in online Calculus courses and the data they produce. The online learning environment collects a lot of time-stamped data about every action a student makes. Assessment data can be harnessed into use as a feedback, predictor, and recommendation facility for students and instructors. We also describe late professor Mika Sepp{\"a}l{\"a}'s seminal work at the University of Helsinki to develop online materials and tools for learning mathematics since 2001. He also utilized these methods in Calculus teaching at Florida State University. The open online course "Single Variable Calculus" was held in Helsinki in 2004. This intensive work evolved into a complete online English Calculus curriculum starting from the Fall 2013 and soon recognized as an alternative route for taking traditional university Calculus courses in Helsinki. Automatic assessment systems of mathematical competencies, such as STACK and WeBWorK, can take a student's answer as a mathematical object, e.g. a function or an equation, and check whether it satisfies the requirements set for a correct answer as well as give immediate and meaningful feedback. That is a powerful tool especially for formative assessment: log data shows that many students prefer to start with quizzes and when necessary, consult lecturing materials.},
  langid = {english},
  keywords = {Calculus,College Mathematics,Computer Assisted Testing,Educational Technology,Feedback (Response),Finland (Helsinki),Florida,Foreign Countries,Higher Education,Mathematics Instruction,No DOI found,Online Courses,Peer Evaluation,Technology Uses in Education}
}

@article{pavlicNovelCatalogAssessment2022,
  title = {Towards a Novel Catalog of Assessment Patterns for Distant Education in the Information Technology Domain},
  author = {Pavli{\v c}, Luka and Berani{\v c}, Tina and Brezo{\v c}nik, Lucija and Heri{\v c}ko, Marjan},
  year = {2022},
  month = jun,
  journal = {Computers \& Education},
  volume = {182},
  pages = {104470},
  issn = {03601315},
  doi = {10.1016/j.compedu.2022.104470},
  urldate = {2023-01-15},
  langid = {english},
  keywords = {Distance education and online learning,Improving classroom teaching,Pedagogical issues,Post-secondary educations,Teacher professional development}
}

@article{pawsonEvidencebasedPolicySearch2002,
  title = {Evidence-Based Policy: {{In}} Search of a Method},
  author = {Pawson, Ray},
  year = {2002},
  journal = {Evaluation (London, England. 1995)},
  volume = {8},
  number = {2},
  pages = {157--181},
  publisher = {SAGE Publications},
  address = {London, England},
  issn = {1356-3890},
  doi = {10.1177/1358902002008002512},
  abstract = {Evaluation research is tortured by time constraints. The policy cycle revolves quicker than the research cycle, with the result that `real time' evaluations often have little influence on policy making. As a result, the quest for evidence-based policy has turned increasingly to systematic reviews of the results of previous inquiries in the relevant policy domain. However, this shifting of the temporal frame for evaluation is in itself no guarantee of success. Evidence, whether new or old, never speaks for itself. Accordingly, there is debate about the best strategy of marshalling bygone research results into the policy process. This article joins the imbroglio by examining the logic of the two main strategies of systematic review: `meta-analysis' and `narrative review'. Whilst they are often presented as diametrically opposed perspectives, this article argues that they share common limitations in their understanding of how to provide a template for impending policy decisions. This review provides the background for Part II of the article (to be published in the next issue, Evaluation 8[3]), which considers the merits of a new model for evidence-based policy, namely `realist synthesis'.},
  copyright = {Copyright SAGE PUBLICATIONS, INC. Apr 2002},
  langid = {english},
  keywords = {Evaluation,Evaluation research,Evidence based,Evidence based research,Impending,Methodology,Policy cycles,Policy making,Realism,Research methods,Systematic review,Systematic reviews,Time,United Kingdom},
  file = {/Users/colin.madland/Zotero/storage/8LXK68G8/pawsonEvidencebasedPolicySearch2002.pdf}
}

@article{payneHumanisingFeedbackEncounters2022,
  title = {Humanising Feedback Encounters: A Qualitative Study of Relational Literacies for Teachers Engaging in Technology-Enhanced Feedback},
  shorttitle = {Humanising Feedback Encounters},
  author = {Payne, Ameena L. and Ajjawi, Rola and Holloway, Jessica},
  year = {2022},
  month = dec,
  journal = {Assessment \& Evaluation in Higher Education},
  pages = {1--12},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2022.2155610},
  urldate = {2023-02-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/AB87AJUY/Humanising feedback encounters a qualitative study of relational literacies for teachers engaging in technology enhanced feedback.pdf}
}

@incollection{pazurekSocialMediaConnected2021,
  title = {Social {{Media}} for {{Connected Learning}} and {{Engagement}} in {{Online Education}}},
  booktitle = {Learning: {{Design}}, {{Engagement}} and {{Definition}}},
  author = {Pazurek, Angelica},
  editor = {Hokanson, Brad and Exter, Marisa and Grincewicz, Amy and Schmidt, Matthew and Tawfik, Andrew A.},
  year = {2021},
  pages = {137--145},
  publisher = {Springer International Publishing},
  address = {Cham},
  urldate = {2022-01-05},
  isbn = {978-3-030-85077-7 978-3-030-85078-4},
  langid = {english},
  keywords = {archived},
  file = {/Users/colin.madland/Zotero/storage/A5B8CVVT/pazurekSocialMediaConnected2021.pdf}
}

@phdthesis{peacheyStayingCourseLife2007,
  title = {Staying the Course: The Life Stories of Eight Entrepreneurial Women},
  author = {Peachey, Valerie},
  year = {2007},
  abstract = {The impetus for this study was my own curiosity about how seasoned entrepreneurial women were able to stay the course. As someone who has experienced the world of the employee and that of the entrepreneur, my goal was to better understand how, within their varied personal contexts, the lifelong learning experiences of seasoned entrepreneurial women were shaped by socio-cultural influences, significant individuals, gender, and learning challenges. Theories and research on lifelong and biographical learning, entrepreneurial learning, women's learning, and entrepreneurial women's learning helped to frame the study. Semi-structured, in-depth interviews and focus groups with eight women entrepreneurs between the ages of 40 and 60, with 16 to 30 years' experience in running their service-oriented enterprise were conducted. These women's stories illustrate how serendipitous their careers were, that is, they did not begin their working lives thinking they would become entrepreneurs, rather, it became the path that best supported their desires, independence and creativity. They were shaped by and sometimes resisted parents' messages about the role that education, work and marriage with children should play in women's lives. How they faced and learned from adversity and from the support of business mentors and friends were also significant. As they reflected back on their lives, they have a strong sense of mastery. Success for them did not focus on finances, rather, their autonomy, freedom, and control over the direction of their lives and the development of strong caring relationships with others, were key. Their learning was dynamic and experiential, it was both self directed and drew on others' knowledge. Women contemplating an entrepreneurial path may find this study of interest as they can learn how others, particularly family, shape their dreams, how they might meet challenges and learn from adversity, and overall, how central lifelong learning is to the development of their entrepreneurial careers. Educators and policymakers need to appreciate the serendipitous nature of entrepreneurship, how they can create entrepreneurial experiences for students, and expose the learners to not only essential skills required to run a business, but also to the stories regarding the self-development of successful entrepreneurs},
  keywords = {entrepreneur,influences,learning",socio-cultural,women}
}

@article{pedersenUndergraduateStudentResearch2011,
  title = {Do {{Undergraduate Student Research Participants Read Psychological Research Consent Forms}}? {{Examining Memory Effects}}, {{Condition Effects}}, and {{Individual Differences}}},
  author = {Pedersen, Eric R. and Neighbors, Clayton and Tidwell, Judy and Lostutter, Ty W.},
  year = {2011},
  month = jul,
  journal = {Ethics \& Behavior},
  volume = {21},
  number = {4},
  pages = {332--350},
  issn = {1050-8422},
  doi = {10/d5dmpv},
  abstract = {Although research has examined factors influencing understanding of informed consent in biomedical and forensic research, less is known about participants' attention to details in consent documents in psychological survey research. The present study used a randomized experimental design and found the majority of participants were unable to recall information from the consent form in both in-person and online formats. Participants were also relatively poor at recognizing important aspects of the consent form including risks to participants and confidentiality procedures. Memory effects and individual difference characteristics also appeared to influence recall and recognition of consent form information.}
}

@book{pedersenWelcomeGgplot2,
  title = {Welcome {\textbar} Ggplot2},
  author = {Pedersen, Danielle Navarro, {and} Thomas Lin, Hadley Wickham},
  urldate = {2022-11-28},
  abstract = {A book created with bookdown.},
  langid = {english}
}

@article{pedrettiFacilitatingActionResearch1996,
  title = {Facilitating {{Action Research}} in {{Science}}, {{Technology}} and {{Society}} ({{STS}}) {{Education}}: An Experience in Reflective Practice},
  author = {Pedretti, Erminia},
  year = {1996},
  month = jan,
  journal = {Educational Action Research},
  volume = {4},
  number = {3},
  pages = {307--327},
  issn = {0965-0792},
  doi = {10/dzpkqp},
  abstract = {ABSTRACT Action research as a form of professional development encourages teachers to participate in cycles of planning, acting, observing and reflecting, thereby creating possibilities for change and transformation. Equally important are the transformations and professional growth experienced by the facilitator in an action research context. In recent literature, the epistemological and methodological foundations of action research have come under scrutiny. Part of this debate emerges from the experience of those who actually attempt to facilitate action research with groups of teachers. In this paper I critically examine my participation (as a university?based facilitator and researcher) in an action research group in science, technology and society (STS) education to illustrate: (a) how a second?order inquiry enhanced my understanding of the nature of action research, while (b) simultaneously allowing me to explore and develop strategies for facilitating the process.},
  file = {/Users/colin.madland/Zotero/storage/Y75EV3L7/pedrettiFacilitatingActionResearch1996.pdf}
}

@article{pedroCriticalReviewMobile2018,
  title = {A Critical Review of Mobile Learning Integration in Formal Educational Contexts},
  author = {Pedro, Lu{\'i}s Francisco Mendes Gabriel and Barbosa, Cl{\'a}udia Marina M{\'o}nica de Oliveira and Santos, Carlos Manuel das Neves},
  year = {2018},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {15},
  number = {1},
  pages = {1--15},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-018-0091-4},
  abstract = {The use of digital technology in the learning process and teaching practices in formal teaching is highly dependent on the ability of teachers of introducing it without jeopardizing the richness of the classroom environment, namely the attention that students need to follow the flow of argumentation and to guarantee the quality of the inquiring. Although several studies value the importance of technologies in our media-enriched world and the "learn anytime and anywhere" motto associated with mobile learning, we argue that the classroom dynamics are becoming more and more at risk with the addictive dimension brought about by the ubiquitous presence of digital devices and social media in students' lives. In this article, we will make a critical review of the literature related to mobile learning because there is still a need of more extensive research on the interference of technology in the classroom, especially on how multitasking affects the teacher role in-class as a media orchestrator and learning facilitator. Finally, we will discuss the use of technology in the formal classroom environment, mainly to stimulate a much-needed discussion about the bright-not-so-bright impacts of technology in the teaching and learning process.},
  keywords = {Attention,Classroom,Classrooms,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Digital media,Educational Technology,Formal education,Higher Education,Humanities,Information Systems Applications (incl.Internet),Law,Learning,Literature reviews,M-learning,Mobile devices,More than tools? Critical perspectives and alternative visions of technology in higher education,Multitasking,Review Article,Social networks,Statistics for Social Sciences,Students,Teachers,Technology utilization},
  file = {/Users/colin.madland/Zotero/storage/TCSVC34W/pedroCriticalReviewMobile2018.pdf}
}

@article{pedroInstitutionalSupportOnline2020,
  title = {Institutional {{Support}} for {{Online Teaching}} in {{Quality Assurance Frameworks}}},
  author = {Pedro, Neuza Sofia and Kumar, Swapna},
  year = {2020},
  journal = {Online Learning},
  volume = {24},
  number = {3},
  pages = {50--66},
  issn = {ISSN-2472-5749},
  abstract = {The widespread growth of online education at higher education institutions necessitates institutional support for the development, implementation, and sustenance of online education. Faculty who teach online are at the forefront of implementation and play a critical role in online student success. In this scoping review, 13 online education quality frameworks were analyzed for the types of support needed by higher education faculty who teach online. The results are discussed in the context of implications for ensuring quality online education at higher education institutions.},
  langid = {english},
  keywords = {College Faculty,College Instruction,COVID-19,Distance Education,Educational Quality,Electronic Learning,Foreign Countries,Higher Education,No DOI found,Online Courses,Quality Assurance,Web Based Instruction}
}

@article{peimaniOnlineEducationCOVID192021,
  title = {Online {{Education}} and the {{COVID-19 Outbreak}}: {{A Case Study}} of {{Online Teaching}} during {{Lockdown}}},
  author = {Peimani, Nastaran and Kamalipour, Hesam},
  year = {2021},
  journal = {Education Sciences},
  volume = {11},
  issn = {EISSN-2227-7102},
  doi = {10/gmbvx8},
  abstract = {The COVID-19 pandemic has become a critical challenge for the higher education sector. Exploring the capacity of this sector to adapt in the state of uncertainty has become more significant than ever. In this paper, we critically reflect on our experience of teaching urban design research methods online during the early COVID-19 lockdown in the UK. This is an exploratory case study with a qualitative approach with an aim to inform resilient practices of teaching in the face of public health emergencies. Drawing on the experience of teaching the Research Methods and Techniques subject during lockdown, we discuss the rapid transition from face-to-face to online teaching and point to the challenges and opportunities in relation to the learning and teaching activities, assessment and feedback, and digital platforms. This paper concludes by outlining some key considerations to inform the development of more adaptive and resilient approaches to online teaching in the context of unprecedented global health crises such as the COVID-19 pandemic. We argue that it is critical to move beyond fixed pedagogical frameworks to harness the productive capacities of adaptive teaching.},
  keywords = {Adjustment (to Environment),Barriers,Coping,COVID-19,Distance Education,Educational Technology,Electronic Learning,Foreign Countries,Higher Education,Online Courses,Pandemics,Research Methodology,School Closing,Teaching Methods,Urban Schools}
}

@article{pelissierAnthropologyTeachingLearning1991,
  title = {The {{Anthropology}} of {{Teaching}} and {{Learning}}},
  author = {Pelissier, Catherine},
  year = {1991},
  journal = {Annual Review of Anthropology},
  volume = {20},
  eprint = {2155794},
  eprinttype = {jstor},
  pages = {75--95},
  issn = {00846570}
}

@article{pelkolaInvestigatingBloomLearning2018,
  title = {Investigating {{Bloom}}'s {{Learning}} for {{Mastery}} in {{Mathematics}} with {{Online Assessment}}},
  author = {Pelkola, Timo and Rasila, Antti and Sangwin, Christopher},
  year = {2018},
  journal = {Informatics in Education},
  volume = {17},
  number = {2},
  pages = {363--380},
  issn = {ISSN-1648-5831},
  doi = {10/gfj2v7},
  abstract = {In this paper we report a study in which we have developed a teaching cycle based closely on Bloom's Learning for Mastery (LFM). The teaching cycle ameliorates some of the practical problems with LFM by making use of the STACK online assessment system to provide automated assessment and feedback to students. We report a clinical trial of this teaching cycle with groups of university level engineering students. Our results are modest, but positive: performance on the exercises predicted mastery according to the formative tests to a small extent. Students also report being supportive of the use of the new teaching cycle.},
  langid = {english},
  keywords = {Academic Achievement,Calculus,College Mathematics,Computer Assisted Testing,Engineering Education,Foreign Countries,Mastery Learning,Mathematics Instruction,Program Implementation,Undergraduate Students}
}

@article{pellasImmersiveVirtualReality2021,
  title = {Immersive {{Virtual Reality}} in {{K-12}} and {{Higher Education}}: {{A}} Systematic Review of the Last Decade Scientific Literature},
  author = {Pellas, Nikolaos and Mystakidis, Stylianos and Kazanidis, Ioannis},
  year = {2021},
  journal = {Virtual reality : the journal of the Virtual Reality Society},
  volume = {25},
  number = {3},
  pages = {835--861},
  publisher = {Springer London},
  address = {London},
  issn = {1359-4338},
  doi = {10.1007/s10055-020-00489-9},
  abstract = {There has been an increasing interest in applying immersive virtual reality (VR) applications to support various instructional design methods and outcomes not only in K-12 (Primary and Secondary), but also in higher education (HE) settings. However, there is a scarcity of studies to provide the potentials and challenges of VR-supported instructional design strategies and/or techniques that can influence teaching and learning. This systematic review presents a variety of studies that provide qualitative and/or quantitative data to investigate the current practices with VR support focusing on students' outcomes, performance, alongside with the benefits and challenges of this technology concerning the analysis of visual features and design elements with mobile and desktop computing devices in different learning subjects. During the selection and screening process, forty-six ( n =\,46) articles published from the middle of 2009 until the middle of 2020 were finally included for a detailed analysis and synthesis of which twenty-one and twenty-five in K-12 and HE, respectively. The majority of studies were focused on describing and evaluating the appropriateness or the effectiveness of the applied instructional design processes using various VR applications to disseminate their findings on user experience, usability issues, students' outcomes, and/or learning performance. This study contributes by reviewing how instructional design strategies and techniques can potentially benefit students' learning performance using a wide range of VR applications. It also proposes some recommendations to guide and lead effective instructional design settings in several teaching and learning contexts to outline a more accurate and up-to-date picture of the current state of literature.},
  keywords = {Analysis,Artificial Intelligence,Computer Graphics,Computer Science,Computer Science Interdisciplinary Applications,Computer Science Software Engineering,Education,Higher education,Image Processing and Computer Vision,Imaging Science & Photographic Technology,Immersive virtual reality,Instructional design,Learning,Mobile applications,Mobile computing,Original Article,Qualitative analysis,Science & Technology,Students,Systematic review,Teaching methods,Technology,Technology assessment,User experience,User interfaces,User Interfaces and Human Computer Interaction,Virtual reality}
}

@article{pellegrinoFoundationsAssessment2003,
  title = {The {{Foundations}} of {{Assessment}}},
  author = {Pellegrino, James W. and Chudowsky, Naomi},
  year = {2003},
  month = apr,
  journal = {Measurement: Interdisciplinary Research \& Perspective},
  volume = {1},
  number = {2},
  pages = {103--148},
  issn = {1536-6367, 1536-6359},
  doi = {10/b732pk},
  urldate = {2021-03-23},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/6GBN8WUS/pellegrinoFoundationsAssessment2003.pdf}
}

@book{pellegrinoKnowingWhatStudents2001,
  ids = {pellegrinoKnowingWhatStudents2001a},
  title = {Knowing {{What Students Know}}: {{The Science}} and {{Design}} of {{Educational Assessment}}},
  shorttitle = {Knowing {{What Students Know}}},
  author = {Pellegrino, James W. and Chudowsky, Naomi and Glaser, Robert},
  year = {2001},
  month = sep,
  publisher = {National Academies Press},
  address = {Washington, D.C.},
  doi = {10.17226/10019},
  urldate = {2020-09-18},
  isbn = {978-0-309-29322-8},
  langid = {english},
  keywords = {Education},
  file = {/Users/colin.madland/Zotero/storage/DP7LFSAI/pellegrinoKnowingWhatStudents2001.pdf}
}

@article{pellegrinoPerspectivesIntegrationTechnology2010,
  title = {Perspectives on the {{Integration}} of {{Technology}} and {{Assessment}}},
  author = {Pellegrino, James W. and Quellmalz, Edys S.},
  year = {2010},
  month = dec,
  journal = {Journal of Research on Technology in Education},
  volume = {43},
  number = {2},
  pages = {119--134},
  issn = {1539-1523, 1945-0818},
  doi = {10/ggfh8z},
  urldate = {2021-01-14},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/YQS7NBHI/pellegrinoPerspectivesIntegrationTechnology2010.pdf}
}

@incollection{pellegrinoTeachingLearningAssessing2017,
  title = {Teaching, Learning and Assessing 21st Century Skills},
  booktitle = {Pedagogical {{Knowledge}} and the {{Changing Nature}} of the {{Teaching Profession}}},
  author = {Pellegrino, James W.},
  editor = {Guerriero, Sonia},
  year = {2017},
  month = feb,
  pages = {223--251},
  publisher = {OECD},
  doi = {10.1787/9789264270695-12-en},
  urldate = {2021-01-27},
  isbn = {978-92-64-27068-8 978-92-64-27069-5 978-92-64-27072-5 978-92-64-29781-4},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/8P9YR266/pellegrinoTeachingLearningAssessing2017.pdf}
}

@article{pellegrinoTwoDisciplinesProblem2017,
  title = {The Two Disciplines Problem -- `It's like {{D{\'e}j{\`a}}} vu All over Again!'},
  author = {Pellegrino, James W.},
  year = {2017},
  month = jul,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {24},
  number = {3},
  pages = {359--368},
  issn = {0969-594X, 1465-329X},
  doi = {10/gf3bp9},
  urldate = {2021-01-27},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/K6RRCH4I/The two disciplines problem it s like D j vu all over again.pdf}
}

@article{peltierApplicationTwoEyedSeeing2018,
  title = {An {{Application}} of {{Two-Eyed Seeing}}: {{Indigenous Research Methods With Participatory Action Research}}},
  author = {Peltier, Cindy},
  year = {2018},
  journal = {International Journal of Qualitative Methods},
  volume = {17},
  number = {1},
  issn = {1609-4069},
  doi = {10.1177/1609406918812346},
  urldate = {2019-02-24},
  abstract = {In this time of reconciliation, Indigenous researchers-in-relation are sharing research paradigms and approaches that align with Indigenous worldviews. This article shares an interpretation of the Mi?kmaw concept of Two-Eyed Seeing as the synthesis of Indigenous methodology and participatory action research situated within an Indigenous paradigm of relevant, reciprocal, respectful, and responsible research. Two-Eyed Seeing is discussed as a guiding approach for researchers offering Indigenous voices and ways of knowing as a means to shift existing qualitative research paradigms. The author offers practical considerations for conducting research with Indigenous peoples in a ?good and authentic way.? Through the co-creation of knowledge with Indigenous communities, a collective story was produced as a wellness teaching tool to foster the transfer of knowledge in a meaningful way.}
}

@article{pelzerInteractionsMachineTeacher2022,
  title = {Interactions with a Machine Teacher: {{Effects}} of {{Wiley}}'s {{Daila}} on Student Learning Outcomes and Teaching Effectiveness},
  author = {Pelzer, Elena and Turner, Benjamin O.},
  year = {2022},
  journal = {Communication teacher},
  volume = {36},
  number = {4},
  pages = {314--329},
  publisher = {Routledge},
  address = {Annandale},
  issn = {1740-4622},
  doi = {10.1080/17404622.2021.2001551},
  abstract = {With the increase in demand for online learning, machine teachers are becoming an important technology in higher education, since they are expected to improve teaching effectiveness and student learning outcomes. However, machine teachers require an aptitude for technology and are associated with high initial costs. Thus, here, we use a more basal form of a machine teacher that, among other goals, aims to enhance interaction but does not require advanced technological competency on the part of students or instructors to use. In a survey study from two universities in Indonesia, we assess how the machine teacher Wiley Daila affects the teaching and learning environment. The findings indicate that among users of Daila, Daila is perceived as useful and increases perceived teaching effectiveness and student learning outcomes. This study therefore suggests the potential of even basal machine teachers to assist in enhancing student learning.},
  keywords = {Distance learning,Educational objectives,Educational technology,Higher education,Online instruction,Quality of education,Teaching}
}

@article{pelzMyThreePrinciples2010,
  title = {({{My}}) Three Principles of Effective Online Pedagogy},
  shorttitle = {({{My}}) Three Principles of Effective Online Pedagogy},
  author = {Pelz, Bill},
  year = {2010},
  journal = {Journal of Asynchronous Learning Networks},
  volume = {14},
  pages = {127--140},
  issn = {19395256},
  abstract = {The author describes three principles of effective online pedagogy. He notes the importance of letting the students do most of the work. He considers interactivity as the most importance aspect of effective asynchronous learning. He also cites three forms of social presence, namely, affective, interactive and cohesive.},
  keywords = {assisted,Asynchronous,ASYNCHRONOUS learning,Computer,COMPUTER assisted instruction,Courses,Distance,distance education,Education,instruction,LEARNING,Online,ONLINE courses,STUDENTS,WEB-based,WEB-based instruction},
  annotation = {1}
}

@article{penfieldNCMEInstructionalModule2014,
  title = {An {{NCME Instructional Module}} on {{Polytomous Item Response Theory Models}}},
  author = {Penfield, Randall David},
  year = {2014},
  month = mar,
  journal = {Educational Measurement: Issues and Practice},
  volume = {33},
  number = {1},
  pages = {36--48},
  issn = {07311745},
  doi = {10/gcpg4g},
  urldate = {2021-04-17},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/USDV8SF9/penfieldNCMEInstructionalModule2014.pdf}
}

@article{pennAssessingPreServiceTeachers2020,
  title = {Assessing {{Pre-Service Teachers}}' {{Reception}} and {{Attitudes}} towards {{Virtual Laboratory Experiments}} in {{Life Sciences}}},
  author = {Penn, Mafor and Mavuru, Lydia},
  year = {2020},
  month = jan,
  journal = {Journal of Baltic Science Education},
  volume = {19},
  pages = {1092--1105},
  publisher = {Journal of Baltic Science Education},
  issn = {1648-3898},
  doi = {10.33225/jbse/20.19.1092},
  abstract = {This research reports the assessment of pre-service teachers' reception and attitudes towards virtual laboratory experiments in Life Sciences with the aim of advancing adaptability to digital learning. Using sequential mixed-methods in a quasi-experimental design, 68 pre-service teachers in the 3rd year of a Bachelor of Education (B.Ed) program were surveyed before and after virtual learning interventions. This phase was followed by qualitative data gathering using focus group interviews with all participants. Findings from quantitative data analysis revealed a positive significant difference in pre-service teachers' attitudes towards virtual laboratory experiments post learning interventions. From qualitative data pre-service teachers found the progression from using only traditional to including virtual experiments was useful in enhancing their conceptual understandings of Life Sciences concepts, convenience, inquiry-based learning, self-directed and autonomous learning. However, pre-service teachers noted that using virtual laboratories did not significantly develop their science process skills and as a result could not replace the experiences in a traditional biology laboratory. The implications of these findings project virtual laboratories as a supporting tool for experimentation in Life Sciences especially within and post the COVID-19 pandemic where issues of social distancing pose a threat to collaborative and inquiry-based science learning. Recommendations from these findings are discussed herein.},
  keywords = {Biology,Computer Simulation,Educational Technology,Foreign Countries,Hands on Science,Instructional Effectiveness,Laboratory Experiments,Preservice Teachers,Science Experiments,Science Instruction,Science Laboratories,Science Process Skills,South Africa,Student Attitudes,Technology Uses in Education},
  file = {/Users/colin.madland/Zotero/storage/TEE6VWW2/pennAssessingPreServiceTeachers2020.pdf}
}

@article{penningtonAssessmentScienceStory2020,
  title = {Assessment as {{Science}} and {{Story}}: {{A Roadmap}} for {{Christian Higher Education}}},
  author = {Pennington, Rebecca},
  year = {2020},
  journal = {Christian higher education (London, UK)},
  volume = {19},
  number = {5},
  pages = {365--384},
  publisher = {Routledge},
  address = {Philadelphia},
  issn = {1536-3759},
  doi = {10.1080/15363759.2020.1712560},
  abstract = {Institutions of higher education face an increasing demand for evidence that they are providing the high-quality educational experience promised in promotional materials. Accrediting bodies require assessment for accountability to ensure continuous improvement. Faculty at Christian higher education institutions join their secular counterparts in questioning the value of time-consuming assessment activities, disconnected from meaningful teaching designed to fulfill distinctly Christian missions, often understood as ``the integration of faith and learning.'' In 2016, Paul Kaak, faith integration editor of Christian Higher Education, called for ``explorers and cartographers'' to devise more detailed maps of academic faith integration leading to learning in all disciplines that is carried out ``in the light of faith'' (p. 189). This essay answers that call for an integration roadmap as it relates to assessment, planting signposts grounded in Reformed epistemology and framing it as science and story. Three key principles shape the argument: (a) educational assessment constitutes a God-designed natural act of human knowing and valuing, though finite and distorted by sin; (b) human fallibility necessitates assessment processes that are characterized by transparency, enabling learners to use their gifts for God's glory; and (c) assessment is most effective when enacted in a loving community of learners who recognize that performance does not determine worth in God's eyes. Finally, the article concludes with practical guidelines to implement a Christian vision of assessment.},
  langid = {english},
  keywords = {Accountability,Christianity,Church Related Colleges,Educational Assessment,Educational evaluation,Educational Quality,Epistemology,Evaluation Criteria,Evaluation Methods,Evidence,Guidelines,Higher education,Institutional Mission,Intellectual Disciplines,Outcomes of Education,Psychometrics,Religious Education,Religious Factors,Scientific Research,Teaching Methods}
}

@incollection{penuelSocialModelsLearning2016,
  title = {Social Models of Learning and Assessment},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {Penuel, William R. and Shepard, Lorrie A.},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch7},
  pages = {146--173},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch7},
  abstract = {Summary In this chapter, we describe social models of learning that guide contemporary assessment design, interpretation, and use for informing teaching. Drawing specifically on examples of curricular activity systems that highlight social dimensions of learning, we analyze variations in ways research teams articulate the three vertices of the ``assessment triangle.'' We introduce two additional important dimensions that emphasize the social dimensions of learning: (1) how each model justifies the importance of particular goals for learning and (2) how each conceptualizes the relationship between becoming proficient in a domain and appropriating disciplinary dispositions, tools, and practices. We present brief analyses of three different multi-year assessment projects to illustrate our framework followed by a comparative synthesis. In the concluding part of the chapter, we argue for the need for assessment developers to consider further some aspects of sociocultural perspectives on learning not yet reflected fully in contemporary assessments for learning.},
  chapter = {7},
  isbn = {978-1-118-95658-8},
  keywords = {classroom assessment,curricular activity system,knowledge-in-pieces,learning progressions,social models of cognition,sociocultural theory}
}

@misc{PeopleArePointing2020,
  title = {People {{Are Pointing Out That Twitter}}'s {{Photo Preview Tool Seems To Be Oddly Racist}}},
  year = {2020},
  month = sep,
  journal = {Junkee},
  urldate = {2020-09-22},
  abstract = {People have discovered that Twitter's auto-crop tool continuously cuts out Black faces to focus on white ones.},
  chapter = {Culture},
  howpublished = {https://junkee.com/twitter-photo-crop-preview-racist/271652},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/YVNX2AUL/271652.html}
}

@article{pereiraAssessmentRevisitedReview2016,
  title = {Assessment Revisited: A Review of Research in {{{\emph{Assessment}}}}{\emph{ and }}{{{\emph{Evaluation}}}}{\emph{ in }}{{{\emph{Higher Education}}}}},
  shorttitle = {Assessment Revisited},
  author = {Pereira, Diana and Flores, Maria Assun{\c c}{\~a}o and Niklasson, Laila},
  year = {2016},
  month = oct,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {41},
  number = {7},
  pages = {1008--1032},
  issn = {0260-2938, 1469-297X},
  doi = {10/f3mwxr},
  urldate = {2021-07-04},
  abstract = {A review of articles published in Assessment and Evaluation in Higher Education, over the last eight years (2006--2013) on assessment in higher education, since the introduction of the Bologna process, is the subject of the paper. The first part discusses the key issue of assessment in higher education and the method used for selecting articles. The second part presents results according to the main emerging themes arising from data analysis: assessment methods, modes of assessment and assessment related to a given teaching and learning method. The paper concludes that the foci of the studies are aligned with assessment practices other than the written test, in accordance with a learner-oriented perspective. Although the implementation of the Bologna process has had different kinds of impact in different European countries, the review shows that the use and effects of a diversity of assessment methods in higher education have been investigated, particularly those pointing to the so-called alternative methods. Implications of the findings are discussed.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/9CGE98ZU/pereiraAssessmentRevisitedReview2016.pdf}
}

@article{pereiraHowUndergraduatesPerceive2021,
  title = {How Do Undergraduates Perceive the Use of Assessment? {{A}} Study in Higher Education},
  shorttitle = {How Do Undergraduates Perceive the Use of Assessment?},
  author = {Pereira, Diana and Cadime, Irene and Brown, Gavin and Flores, Maria Assun{\c c}{\~a}o},
  year = {2021},
  month = jan,
  journal = {European Journal of Higher Education},
  pages = {1--17},
  issn = {2156-8235, 2156-8243},
  doi = {10/gk36vq},
  urldate = {2021-07-05},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/5AYVHPX7/pereiraHowUndergraduatesPerceive2021.pdf}
}

@article{pereiraPerceptionsPortugueseUndergraduate2017,
  title = {Perceptions of {{Portuguese}} Undergraduate Students about Assessment: A Study in Five Public Universities},
  shorttitle = {Perceptions of {{Portuguese}} Undergraduate Students about Assessment},
  author = {Pereira, Diana and Assun{\c c}{\~a}o Flores, Maria and Barros, Alexandra},
  year = {2017},
  month = aug,
  journal = {Educational Studies},
  volume = {43},
  number = {4},
  pages = {442--463},
  issn = {0305-5698, 1465-3400},
  doi = {10/gmb98n},
  urldate = {2021-07-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/PIGBQBPH/pereiraPerceptionsPortugueseUndergraduate2017.pdf}
}

@article{perera-diltzFormativeSummativeAssessment2014,
  title = {Formative and {{Summative Assessment}} in {{Online Education}}},
  author = {{Perera-Diltz}, Dilani M and Moe, Jeffry L},
  year = {2014},
  journal = {Journal of Research in Innovative Teaching},
  volume = {7},
  number = {1},
  pages = {130--142},
  abstract = {Assessment is an integral part of both traditional and online education, especially when determining student learning outcomes. In the online learning environment, both formative and summative assessment practices require an understanding of the features and tools inherent to the electronic medium. Creating assessments for online education, either formative or summative, also requires application of constructivist learning principles to our collective understanding of the educational process and related goals. In this paper, we offer an overview of formative and summative assessment approaches suited to the online education environment.},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/DWI3G6NJ/perera-diltzFormativeSummativeAssessment2014.pdf}
}

@article{perez-torregrosaDigitalRubricbasedAssessment2022,
  title = {Digital Rubric-Based Assessment of Oral Presentation Competence with Technological Resources for Preservice Teachers},
  author = {{Perez-Torregrosa}, {\relax AB} and {Gallego-Arrufat}, {\relax MJ} and {Cebrian-de-la-Serna}, M},
  year = {2022},
  journal = {Estudios Sobre Educacion},
  number = {43},
  pages = {177--198},
  issn = {1578-7001},
  doi = {10.15581/004.43.009},
  abstract = {This study focuses on e-assessment of oral presentation competence using technology resources in a model that combines project-based learning and flipped learning. This study uses a digital rubric to assess oral presentation competence in different situations of progressive assessment for 99 preservice teachers, situations in which participation was either optional or compulsory. Findings show that the digital rubric used at various times is a methodology and a technology that facilitates the feedback process and dialogue between teachers and students about the assessment criteria. The results support future decisions for methodological design of formative assessment appropriate to online learning environments.},
  langid = {english},
  keywords = {Assessment,DESIGN,HIGHER-EDUCATION,IMPACT,METAANALYSIS COMPARING PEER,Oral presentation competence,PRESENTATION SKILLS,Preservice teachers,REFLECTION,Rubric,VALIDITY},
  file = {/Users/colin.madland/Zotero/storage/6MMYTLRE/perez-torregrosaDigitalRubricbasedAssessment2022.pdf}
}

@article{perkinsAssessmentEvaluationOnline2019,
  title = {Assessment and {{Evaluation}} in {{Online Learning}}},
  author = {Perkins, Ross A.},
  year = {2019},
  journal = {Library Technology Reports},
  volume = {55},
  number = {4},
  pages = {31},
  publisher = {American Library Association},
  issn = {0024-2586},
  keywords = {Evaluation,Methods,No DOI found,Online education,Rating of,Students}
}

@article{perrigoHourWorkersWho2023,
  title = {The \$2 {{Per Hour Workers Who Made ChatGPT Safer}}},
  author = {Perrigo, Billy},
  year = {2023},
  journal = {Time},
  urldate = {2023-02-02},
  abstract = {A TIME investigation reveals the difficult conditions faced by the workers who made ChatGPT possible},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/R45AXJVX/openai-chatgpt-kenya-workers.html}
}

@article{perrottaReflectiveStudyOnline2020,
  title = {A {{Reflective Study}} of {{Online Faculty Teaching Experiences}} in {{Higher Education}}},
  author = {Perrotta, Katherine and Bohan, Chara Haeussler},
  year = {2020},
  journal = {Journal of Effective Teaching in Higher Education},
  volume = {3},
  number = {1},
  pages = {50--66},
  issn = {EISSN-2578-7608},
  doi = {10/gmbvzw},
  abstract = {Despite the popularity of online course and degree offerings in higher education, a lack of data persists on the unique challenges and opportunities online faculty face. Gaining insights about these experiences is important to ensure the quality of online teaching as colleges and universities continue expanding e-learning programs. Therefore, the purpose of this study is to examine the online teaching experiences of two faculty members through the implementation of reflective study methods. Major findings show that faculty access to professional development and mentoring, isolation and connectedness to the campus community, and academic freedom and curriculum control have significant implications for online teaching and student learning. In the wake of COVID-19 as colleges across the nation suddenly are faced with moving to exclusively online learning, this study is needed more than ever.},
  langid = {english},
  keywords = {Academic Freedom,Asynchronous Communication,College Environment,College Faculty,Educational Technology,Electronic Learning,Faculty Development,Integrated Learning Systems,Mentors,Online Courses,Professional Autonomy,Teacher Attitudes,Teacher Effectiveness,Teaching Experience}
}

@article{perveenUseWordClouds2021,
  title = {Use of {{Word Clouds}} for {{Task Based Assessment}} in {{Asynchronous E-Language Learning}}},
  author = {Perveen, Ayesha},
  year = {2021},
  month = jan,
  journal = {MEXTESOL Journal},
  volume = {45},
  number = {2},
  publisher = {MEXTESOL Journal},
  issn = {2395-9908},
  abstract = {Word clouds can be used as an effective tool for the teaching and learning processes in language learning, as the visual input during schemata activation, and other parts of the lesson, serve as manageable and meaningful target language input. There are emerging studies that explore their effectiveness, but less so with respect to their use in the online second language classroom. This study explores the effectiveness of word clouds for teaching English as a Foreign Language (EFL) in an asynchronous mode. The study used a mixed methods design and triangulation was used for data collection. The participant group, as bachelor's degree students at the Virtual University of Pakistan (VUP), were given word clouds based assessment activities in two communication skills courses: Eng 001 (305 students participated) and Eng 101 (1714 and 1516 students participated in two activities respectively). The scores of the students were analyzed to gauge the suitability of task-based assessment in an asynchronous mode. Furthermore, an online survey questionnaire was administered to seek their input on the assessment activities. A total of 272 (N= 272) students responded to the survey questionnaire. The results reflected that the students responded positively overall regarding the use of word clouds for reading comprehension and essay writing tasks but had mixed opinions about reading and writing skill improvement tasks. The study concludes that the use of word clouds for pre-reading and pre-writing activities for task-based EFL teaching in asynchronous learning environments can be effective with the constraints that are described.},
  keywords = {Asynchronous Communication,Computer Simulation,Electronic Learning,English (Second Language),Essays,Foreign Countries,Instructional Effectiveness,Learning Processes,Linguistic Input,No DOI found,Online Courses,Pakistan,Reading Comprehension,Schemata (Cognition),Scores,Second Language Instruction,Second Language Learning,Student Attitudes,Student Evaluation,Task Analysis,Teaching Methods,Undergraduate Students,Universities,Visual Aids,Writing (Composition)}
}

@article{peslakSentimentLinguisticAnalysis2019,
  title = {A {{Sentiment}} and {{Linguistic Analysis}} of {{Online Reviews}} of {{Online Universities}}},
  author = {Peslak, Alan},
  year = {2019},
  journal = {Information Systems Education Journal},
  volume = {17},
  number = {4},
  pages = {16--23},
  issn = {EISSN-1545-679X},
  abstract = {The growth and proliferation of online higher education have been staggering. This comes despite an overall decline in university enrollments. But the quality of online courses has been questioned by many researchers, suggesting it may be less than a traditional face to face experience. Many researchers have explored this area but our research study reviews online universities from an impartial non-profit organization and analyzes both the content and the sentiment in these reviews. This analysis provides a unique perspective on how online universities and their programs are viewed by their students. Implications of this analysis are examined.},
  langid = {english},
  keywords = {College Students,Distance Education,Educational Quality,Educational Technology,Higher Education,No DOI found,Online Courses,Program Effectiveness,Student Attitudes,Technology Uses in Education,Virtual Universities}
}

@incollection{petersScopingReviews2020,
  title = {Scoping {{Reviews}}},
  shorttitle = {Chapter 11},
  booktitle = {{{JBI Manual}} for {{Evidence Synthesis}}},
  author = {Peters, Micah and Godfrey, Christina and McInerney, Patricia and Munn, Zachary and Trico, Andrea and Khalil, Hanan},
  editor = {Aromataris, Edoardo and Munn, Zachary},
  year = {2020},
  publisher = {JBI},
  doi = {10.46658/JBIMES-20-12},
  urldate = {2022-10-22},
  isbn = {978-0-6488488-0-6},
  file = {/Users/colin.madland/Zotero/storage/JRP25BNG/petersScopingReviews2020.pdf}
}

@article{petronziOnlineCampusOaC2020,
  title = {The {{Online}} and {{Campus}} ({{OaC}}) {{Model}} as a {{Sustainable Blended Approach}} to {{Teaching}} and {{Learning}} in {{Higher Education}}: {{A Response}} to {{COVID-19}}},
  author = {Petronzi, Rebecca and Petronzi, Dominic},
  year = {2020},
  journal = {Journal of Pedagogical Research},
  volume = {4},
  number = {4},
  pages = {498--507},
  issn = {EISSN-2602-3717},
  doi = {10/gkr9wc},
  abstract = {The COVID-19 pandemic represents an unprecedented challenge for wider society and has impacted all facets of life, including Higher Education Institution (HEIs) provision for teaching and learning -- demanding an immediate digital response. The core challenge lies with the inherent choice made by students upon embarking on an undergraduate degree; that face-to-face learning was their preference. Now, HEIs must address this by utilising a range of digital solutions -- that crucially, must also be embraced by those that no longer have the luxury to be risk averse or believe that digital solutions align with their existing pedagogical approaches. Higher Education Institutions should be -- to an extent -- well placed to deliver online provision. This paper aims to explore pertinent literature surrounding blended approaches with regards to key pedagogical and learning theories, with an overall aim of suggesting the Online and Campus (OaC) model as a potential 'blueprint' that incorporates campus, synchronous and asynchronous learning experiences. We refer to asynchronous as flexible, self-paced learning, and synchronous as an environment in which learners are in the same place at a given time (either online or campus) and accessing the same materials. For the purposes of this paper -- and the OaC model -- both asynchronous and synchronous learning refers to online provision, and we make the distinction between face-to-face teaching by reference to 'Campus'.},
  langid = {english},
  keywords = {Active Learning,Asynchronous Communication,Blended Learning,COVID-19,Educational Technology,Electronic Learning,Higher Education,Online Courses,Pandemics,School Closing,Social Development,Student Role,Synchronous Communication,Teacher Role}
}

@article{petrovicOnlineFormativeAssessments2017,
  title = {Online Formative Assessments in a Digital Signal Processing Course: {{Effects}} of Feedback Type and Content Difficulty on Students Learning Achievements},
  author = {Petrovic, J and Pale, P and Jeren, B},
  year = {2017},
  month = nov,
  journal = {Education and Information Technologies},
  volume = {22},
  number = {6},
  pages = {3047--3061},
  issn = {1360-2357},
  doi = {10.1007/s10639-016-9571-0},
  abstract = {This study aimed to investigate the effects of using online formative assessments on students' learning achievements. Using a quasi-experimental study design with one control group (no formative assessments available), and two experimental groups receiving feedback in available online formative assessments (knowledge of the correct response - KCR, or elaborated feedback - EF), it was investigated how feedback type in combination with learning content complexity will affect students' learning achievements when used in-vivo, in a digital signal processing university course. Data generated by the two experimental groups was additionally used to investigate differences in using online formative assessments based on the feedback type. Study findings suggest online formative assessments are a very efficient educational intervention for this domain. The acquired data suggests that students quickly recognized the value of the formative assessments and that more than 90\% of students have used them extensively. Statistically significant improvements in learning achievements were observed in the KCR group compared to the control group (p {$<$} 0.01, Cohen's d between 0.691 and 1.080, depending on the learning content complexity), and KCR group compared to the EF group (p {$<$} 0.01, Cohen's d = 0.877, in the case of most complex of the three learning contents used). No statistically significant differences were found in formative assessment usage between the two experimental groups, aside from the difference in the time between consecutive formative assessment attempts, indicating students did make use of the available feedback. Reported results are significant for demonstrating the potential of online formative assessments in achieving the desired learning outcomes in higher education, as well as for gaining insights into students' habits of using them.},
  langid = {english},
  keywords = {E-assessments,Engineering education,EXAM PERFORMANCE,Formative feedback,Online formative assessments,OUTCOMES,PARTICIPATION,QUIZZES,SCIENCES,SCORES}
}

@article{pettitOnlineTeachingModule2018,
  title = {Online {{Teaching Module}}: {{Council}} for the {{Accreditation}} of {{Educator Preparation}} ({{CAEP}}) {{Key Assessment Example}}},
  author = {Pettit, Stacie K. and Edwards, Susan},
  year = {2018},
  journal = {Becoming: Journal of the Georgia Association for Middle Level Education},
  volume = {29},
  number = {1},
  pages = {11--19},
  issn = {EISSN-2641-7715},
  doi = {10/gmbv3w},
  abstract = {The Augusta University Online Teaching Module is a key assessment administered once during one specified course in each educator preparation program. Augusta University teacher candidates are required to show proficiency in ISTE standards and CAEP [Council for the Accreditation of Educator Preparation] standard 1.5. The online teaching model measures candidates' ability to apply technology standards in order to design, implement, and assess learning experiences to engage students and improve learning. In order to pass the Online Teaching Module, candidates must score 3 out of 4 possible points on at least five of the six indicators. If a candidate does not pass this assessment, goals will be created along with strategies to require the candidate to improve on area(s) of weakness in technology use. After the strategies have been implemented, the candidate will be able to redo this key assessment. Candidates will not be able to progress to student teaching without passing this assessment. This paper outlines this key assessment's administration, purpose, instructions, and rubric. We hope it will be useful to others as they prepare for CAEP visits.},
  langid = {english},
  keywords = {Accreditation (Institutions),Electronic Learning,Preservice Teachers,Standards,Student Evaluation,Technology Uses in Education}
}

@article{phamImpactSelfAssessmentProcess2020,
  title = {Impact of the {{Self-Assessment Process}} on {{Quality Enhancement}} of {{Higher Education Institutions}}: {{A Case Study}} of {{Vietnam}}},
  author = {Pham, Phuong-Tam and Duong, Tran-Binh and Phan, Thi-Thuy-Trang and Nguyen, Thai-Huu and Nguyen, Minh-Thanh and Nguyen, Manh-Tuan and Hoang, Ngoc-Anh and Nguyen, Van-Thai-Binh and Nguyen, Tien-Trung},
  year = {2020},
  journal = {International Journal of Education and Practice},
  volume = {8},
  number = {3},
  pages = {536--546},
  issn = {ISSN-2311-6897},
  doi = {10/gmbv3r},
  abstract = {Quality assurance and accreditation has been implemented in Vietnam for nearly twenty years. It is mandatory for all Vietnamese higher education institutions to undertake accreditation including self-assessment. This study aims to investigate the impact of the self-assessment processes on quality enhancement of universities in Vietnam. Semi-structured interviews were conducted with 33 participants from three Vietnamese universities located in three major regions: the North, the Central and the South. The interviewees were those who directly involved in the self-assessment processes including institutional leaders, department heads, faculty deans, internal quality assurance staff and lecturers. Thematic analysis identified that there was a number of notable impacts resulting from the implementation of self-assessment on higher education quality. Key impacts were reported in relation to: leadership and management, teaching staff, students and student support, and training programs. The study concludes that self-assessment processes had a positive impact on improving the quality of teaching, learning, program management and student support in Vietnamese universities sampled for the current study.},
  langid = {english},
  keywords = {Academic Support Services,Accreditation (Institutions),Administrator Attitudes,College Administration,College Faculty,College Students,Educational Quality,Foreign Countries,Higher Education,Leadership Effectiveness,Quality Assurance,Self Evaluation (Groups),Training}
}

@article{phillipsLOLingTragedyFacebook2011,
  title = {{{LOLing}} at Tragedy: {{Facebook}} Trolls, Memorial Pages and Resistance to Grief Online},
  shorttitle = {{{LOLing}} at Tragedy},
  author = {Phillips, Whitney},
  year = {2011},
  month = nov,
  journal = {First Monday},
  volume = {16},
  number = {12},
  issn = {13960466},
  doi = {10.5210/fm.v16i12.3168},
  urldate = {2019-02-16},
  abstract = {This paper examines the emergence of organized trolling behaviors on Facebook, specifically in relation to memorial groups and fan pages. In addition to mapping the development of RIP trolling --- in which online instigators post abusive comments and images onto pages created for and dedicated to the deceased --- the paper also examines the highly contentious and ultimately parasitic relationship(s) between memorial trolls, Facebook's social networking platform and mainstream media outlets. Recalling Oring's account of disaster humor, the paper goes on to suggest that, inadvertently or not, Facebook memorial page trolling presents a pointed critique of a tragedy--obsessed global media.},
  copyright = {Copyright (c)},
  langid = {english},
  keywords = {cyberbullying,disaster humor,Facebook,Online grief,Trolling},
  file = {/Users/colin.madland/Zotero/storage/XH5WXWKX/3168.html}
}

@book{phillipsThisWhyWe2015,
  title = {This Is Why We Can't Have Nice Things: Mapping the Relationship between Online Trolling and Mainstream Culture},
  author = {Phillips, Whitney},
  year = {2015},
  number = {Book, Whole},
  publisher = {The MIT Press},
  address = {Cambridge, Massachusetts},
  abstract = {Internet trolls live to upset as many people as possible, using all the technical and psychological tools at their disposal. They gleefully whip the media into a frenzy over a fake teen drug crisis; they post offensive messages on Facebook memorial pages, traumatizing grief-stricken friends and family; they use unabashedly racist language and images. They take pleasure in ruining a complete stranger's day and find amusement in their victim's anguish. In short, trolling is the obstacle to a kinder, gentler Internet. To quote a famous Internet meme, trolling is why we can't have nice things online. Or at least that's what we have been led to believe. In this provocative book, Whitney Phillips argues that trolling, widely condemned as obscene and deviant, actually fits comfortably within the contemporary media landscape. Trolling may be obscene, but, Phillips argues, it isn't all that deviant. Trolls' actions are born of and fueled by culturally sanctioned impulses -- which are just as damaging as the trolls' most disruptive behaviors. Phillips describes, for example, the relationship between trolling and sensationalist corporate media -- pointing out that for trolls, exploitation is a leisure activity; for media, it's a business strategy. She shows how trolls, "the grimacing poster children for a socially networked world," align with social media. And she documents how trolls, in addition to parroting media tropes, also offer a grotesque pantomime of dominant cultural tropes, including gendered notions of dominance and success and an ideology of entitlement. We don't just have a trolling problem, Phillips argues; we have a culture problem. This Is Why We Can't Have Nice Things isn't only about trolls; it's about a culture in which trolls thrive.;Why the troll problem is actually a culture problem: how online trolling fits comfortably within today's media landscape.;Internet trolls live to upset as many people as possible, using all the technical and psychological tools at their disposal. They gleefully whip the media into a frenzy over a fake teen drug crisis; they post offensive messages on Facebook memorial pages, traumatizing grief-stricken friends and family; they use unabashedly racist language and images. They take pleasure in ruining a complete stranger's day and find amusement in their victim's anguish. In short, trolling is the obstacle to a kinder, gentler Internet. To quote a famous Internet meme, trolling is why we can't have nice things online. Or at least that's what we have been led to believe. In this provocative book, Whitney Phillips argues that trolling, widely condemned as obscene and deviant, actually fits comfortably within the contemporary media landscape. Trolling may be obscene, but, Phillips argues, it isn't all that deviant. Trolls' actions are born of and fueled by culturally sanctioned impulses -- which are just as damaging as the trolls' most disruptive behaviors. Phillips describes, for example, the relationship between trolling and sensationalist corporate media -- pointing out that for trolls, exploitation is a leisure activity; for media, it's a business strategy. She shows how trolls, "the grimacing poster children for a socially networked world," align with social media. And she documents how trolls, in addition to parroting media tropes, also offer a grotesque pantomime of dominant cultural tropes, including gendered notions of dominance and success and an ideology of entitlement. We don't just have a trolling problem, Phillips argues; we have a culture problem.This Is Why We Can't Have Nice Thingsisn't only about trolls; it's about a culture in which trolls thrive.;},
  isbn = {0262028948;9780262028943;},
  keywords = {Communication Networking and Broadcast Technologies,Computing and Processing,General Topics for Engineers,Internet,Internet users,Moral and ethical aspects,Online chat groups,Online etiquette,Online etiquette - Social aspects,Online identities,Social aspects,Technology}
}

@article{phongsirikulTraditionalAlternativeAssessments2018,
  title = {Traditional and {{Alternative Assessments}} in {{ELT}}: {{Students}}' and {{Teachers}}' {{Perceptions}}},
  author = {Phongsirikul, Marissa},
  year = {2018},
  month = jan,
  journal = {rEFLections},
  volume = {25},
  number = {1},
  pages = {61--84},
  publisher = {rEFLections},
  abstract = {The study aimed to investigate teachers' and students' perceptions towards traditional and alternative types of assessment within a classroom context of an English course provided for English-majoring students at tertiary level. A combination of traditional and alternative assessment tools was implemented in the study. The researcher developed iPortfolio, WeCreate Activity, and iLearn \& Teach Project as alternative assessment tools, while paper-and-pencil quizzes and exams were used as traditional assessment tools. The questionnaires were used to gather the information concerning students' and teachers' perceptions towards the overall features of the assessment tools and their effectiveness. The participants consisted of 103 students and 5 teachers. The findings showed that both teachers and students generally place a higher value on traditional assessment tools especially in terms of their validity and reliability. However, they expressed ideas indicating the possibility of using alternative assessment tools as assessment tools and catalysts for learning motivation in other English skill courses.},
  keywords = {Alternative Assessment,College Students,Comparative Analysis,Foreign Countries,Grammar,Language Tests,Learning Motivation,Majors (Students),No DOI found,Portfolio Assessment,Reliability,Second Language Instruction,Second Language Learning,Student Attitudes,Teacher Attitudes,Testing Problems,Thailand (Bangkok),Validity}
}

@article{PhysRevSTPER.10.020105,
  title = {Assessing the Quality of a Student-Generated Question Repository},
  author = {Bates, Simon P. and Galloway, Ross K. and Riise, Jonathan and Homer, Danny},
  year = {2014},
  month = jul,
  journal = {Phys. Rev. ST Phys. Educ. Res.},
  volume = {10},
  number = {2},
  pages = {11},
  publisher = {American Physical Society},
  doi = {10/gfz4h9}
}

@article{pidgeonMoreChecklistMeaningful2016,
  title = {More {{Than}} a {{Checklist}}: {{Meaningful Indigenous Inclusion}} in {{Higher Education}}},
  author = {Pidgeon, M.},
  year = {2016},
  journal = {Social Inclusion},
  volume = {4},
  number = {1},
  pages = {77--91},
  issn = {2183-2803},
  doi = {10.17645/si.v4i1.436},
  abstract = {Since the 1970s there has been increased focus by institutions, government, and Indigenous nations on improving Aboriginal peoples participation and success in Canadian higher education; however disparity continues to be evident in national statistics of educational attainment, social determinants of health, and socio-economic status of Aboriginal compared to non-Aboriginal Canadians. For instance, post-secondary attainment for Aboriginal peoples is still only 8\% compared to 20\% of the rest of Canada (Statistics Canada, 2008, 2013). A challenge within higher education has been creating the space within predominately Euro-Western defined and ascribed structures, academic disciplines, policies, and practices to create meaningful spaces for Indigenous peoples. Indigenization is a movement centering Indigenous knowledges and ways of being within the academy, in essence transforming institutional initiatives, such as policy, curricular and co-curricular programs, and practices to support Indigenous success and empowerment. Drawing on research projects that span the last 10 years, this article celebrates the pockets of success within institutions and identifies areas of challenge to Indigenization that moves away from the tokenized checklist response, that merely tolerates Indigenous knowledge(s), to one where Indigenous knowledge(s) are embraced as part of the institutional fabric.},
  keywords = {Aboriginal peoples,Aboriginal peoples Canada,Academic disciplines,American Indians,Canada,Economic policy,Education policy,Educational attainment,Empowerment,Fraser Simon,Health,Health problems,Higher education,indigenization,indigenous higher education,Indigenous populations,Knowledge,Native North Americans,Participation,post-secondary education,recruitment,retention,Social integration,SOCIAL SCIENCES INTERDISCIPLINARY,Socioeconomic status}
}

@article{pidgeonPushingMarginsIndigenous2008,
  title = {Pushing against the {{Margins}}: {{Indigenous Theorizing}} of ``{{Success}}'' and {{Retention}} in {{Higher Education}}},
  author = {Pidgeon, Michelle},
  year = {2008},
  month = nov,
  journal = {Journal of College Student Retention: Research, Theory \& Practice},
  volume = {10},
  number = {3},
  pages = {339--360},
  issn = {1521-0251},
  doi = {10.2190/CS.10.3.e},
  urldate = {2019-02-15},
  abstract = {What does it mean to be ?successful? in higher education? For some in mainstream society, the value is placed on the financial status gained from a university education. Governments and university administration measure success through graduation rates. While the economic and social benefits of a university education are also important to Aboriginal people, successful negotiation of mainstream higher education also entails maintaining their cultural integrity (Tierney \& Jun, 2001). Broadening notions of success and corresponding retention theories is important to move forward the agenda of Aboriginal higher education. The purpose of this article is to further the theoretical and practical discussions of educational success of Aboriginal students. Using social reproduction theory and a post-colonial framework, this article presents an argument that shows how/why conventional discourses on retention and student success often exclude Indigenous understandings and worldviews. To this end, it provides a counter-hegemonic on current discourses relating to retention and Aboriginal persistence in mainstream institutions. The article concludes with some thoughts on how to enrich the educational experiences of Aboriginal students from an Indigenous understanding of success and retention.}
}

@article{pil-heewooAnalysisStandardsInstruments2021,
  title = {Analysis of {{Standards}} and {{Instruments}} of {{Teacher Assessment Literacy}} in {{Korea}}},
  author = {{Pil-hee Woo} and {Myung-seub Song} and {Ju-beom Song}},
  year = {2021},
  journal = {Journal for Curriculum and Evaluation},
  volume = {24},
  number = {1},
  doi = {10/gmgbpx},
  abstract = {Recently, interests to teachers' assessment literacy, which influence to quality of the assessment, have been increased as assessment has been emphasized as the bridge between teaching and learning. 24 standards and instruments of teacher assessment literacy in Korea were analyzed by a framework of four identified classifications: purpose of assessment; contexts of assessment; aspect of assessment; scale of assessment literacy instruments. Most of the standards and instruments were not specified by purpose and contexts. Knowledge and skills related to assessment processes were revealed the most. However, proportion of item related to formative assessment, classroom culture, and collaboration in instruments of assessment literacy were somewhat increased under the influence of curriculum revision. Development of assessment literacy was analyzed by scale of assessment literacy instruments. As result of that, most of the instruments could measure the level of literacy and development quantitatively through average of Likert-type scale. However, the result had limit to suggest direction to teachers to develop assessment literacy. The result of study would suggest implication in terms of aspect and development of assessment literacy for teachers who implement assessment.}
}

@article{pillaiEnduserSatisfactionTechnologyenabled2021,
  title = {End-User Satisfaction of Technology-Enabled Assessment in Higher Education: {{A}} Coping Theory Perspective},
  author = {Pillai, K. R. and Upadhyaya, Pallavi and Prakash, Ashish Viswanath and Ramaprasad, Badrinarayan Srirangam and Mukesh, H. V. and Pai, Yogesh},
  year = {2021},
  journal = {Education and information technologies},
  volume = {26},
  number = {4},
  pages = {3677--3698},
  publisher = {Springer US},
  address = {New York},
  issn = {1360-2357},
  doi = {10.1007/s10639-020-10401-2},
  abstract = {The current study examines students' coping process of a forced technological intervention in academic outcome assessment in a higher education setting. A mixed-method approach was used to study 246 post-graduate students' post-usage behaviour of electronic tablet-PC exams and examined their end-user satisfaction. This is an empirical study grounded in the Coping Model of User Adaptation (CMUA). Respondents of the study comprise of post-graduate students, who were exposed to an innovative digital device for writing descriptive exams as a substitute to the conventional paper-mode exam. Data were analyzed using SPSS and Nvivo. Findings indicate that problem-focused coping has a significant influence on end-user satisfaction, and on the contrary emotion-focused coping is insignificant among the students. The study offers insights into those institutions, which are aspiring to advance with similar interventions in academic outcome assessment. The study contributes to the literature on technostress, coping strategy, and end-user satisfaction of ICT.},
  keywords = {Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Education,Education & Educational Research,Education Higher,Educational Technology,Graduate students,Higher education,Information Systems Applications (incl.Internet),Social Sciences,User Interfaces and Human Computer Interaction,User satisfaction},
  file = {/Users/colin.madland/Zotero/storage/XELGJ3WR/pillaiEnduserSatisfactionTechnologyenabled2021.pdf}
}

@article{pinaRegularSubstantiveInteraction2023,
  title = {Regular and {{Substantive Interaction}} in {{Online Courses}}: {{Why}} It {{Matters}} for {{Administrators}}},
  author = {Pi{\~n}a, Anthony A and Martindale, Trey},
  year = {2023},
  journal = {Online Journal of Distance Learning Administration},
  volume = {26},
  number = {2},
  abstract = {Regular and substantive interaction differentiates distance education from correspondence education and can have serious economic ramifications for institutions that fail to include it in their online courses. While ambiguities in its definition and a federal health emergency provided temporary flexibilities and exemptions from regulations, the end of the pandemic, along with revised definitions and regulations for distance education, makes regular and substantive interaction in online courses critical to both faculty and administrators.},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/8BEJD7GE/Pia - Regular and Substantive Interaction in Online Cour.pdf}
}

@article{pinargote-ortegaPeerAssessmentUsing2021,
  title = {Peer Assessment Using Soft Computing Techniques},
  author = {{Pinargote-Ortega}, Maricela and {Bowen-Mendoza}, Lorena and Meza, Jaime and Ventura, Sebasti{\'a}n},
  year = {2021},
  journal = {Journal of computing in higher education},
  volume = {33},
  number = {3},
  pages = {684--726},
  publisher = {Springer US},
  address = {New York},
  issn = {1042-1726},
  doi = {10.1007/s12528-021-09296-w},
  abstract = {In this paper, we applied a peer assessment scenario at the Technical University of Manab{\'i} (Ecuador). Students and professors evaluated some works through rubrics, assigned a numerical score, and provided textual feedback grounding why such a numerical score was determined, to detect inaccuracy between both assessments. The proposed model uses soft computing techniques to reduce the professor's workload in the correction process. Experiments were carried out with a data set in the Spanish language. We applied a supervised machine learning approach to obtain a sentiment score corresponding to specific textual feedback, and the fuzzy logic approach to detect inaccuracy between numerical and sentiment scores and obtain the assessment score. The results showed that the support vector machine model had a better performance with low computational costs when the feedback was represented as a 1-g and 2-g vector, whose relevance was weighted with term frequency-inverse document frequency; moreover, the grader's critical judgment validity was inferred from the similarities between numerical and sentiment scores. At the end, the outcomes assert the model is reliable and guarantees a fair peer assessment procedure.},
  keywords = {Accuracy,Analysis,College Faculty,College Students,Colleges & universities,Computation,Computational linguistics,Computer Uses in Education,Computing costs,Costs,Education,Education & Educational Research,Educational evaluation,Educational Technology,Evaluative Thinking,Evaluators,Faculty Workload,Feedback,Foreign Countries,Fuzzy logic,Higher Education,Language processing,Learning and Instruction,Machine learning,Mathematical models,Methods,Natural language interfaces,Natural language processing,Peer Evaluation,Peers,Reliability,Scoring Rubrics,Social Sciences,Soft computing,Spanish language,Support vector machines,Validity}
}

@incollection{pinheiroDigitalTransformationsNordic2023,
  title = {Digital {{Transformations}} in {{Nordic Higher Education}}: {{A Step Towards Unpacking}} a {{Multifaceted}} and {{Emergent Phenomenon}}},
  shorttitle = {Digital {{Transformations}} in {{Nordic Higher Education}}},
  booktitle = {Digital {{Transformations}} in {{Nordic Higher Education}}},
  author = {Pinheiro, R{\'o}mulo and T{\o}mte, Cathrine Edelhard and Barman, Linda and Degn, Lise and Geschwind, Lars},
  editor = {Pinheiro, R{\'o}mulo and Edelhard T{\o}mte, Cathrine and Barman, Linda and Degn, Lise and Geschwind, Lars},
  year = {2023},
  pages = {3--26},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-27758-0_1},
  urldate = {2025-03-22},
  abstract = {Digitalisation-related challenges and opportunities in higher education are not new, but awareness of their transformative potential has increased, with global trends including massive open online courses (MOOCs) and other forms of technology-enhanced open education. The COVID-19 pandemic has emphasised the importance of flexible forms of teaching and learning, and, as a result, has intensified the adoption of technological platforms and solutions across the board. In this introductory chapter to the volume, the editors provide a state of the art on the topic of digital transformations, including clarifications on concepts and definitions, alongside the articulation of a systemic framework that considers the complexity, dynamic, and multifaceted nature of the phenomenon under investigation.},
  isbn = {978-3-031-27758-0},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/3AT2G2IC/Pinheiro et al. - 2023 - Digital Transformations in Nordic Higher Education A Step Towards Unpacking a Multifaceted and Emergent Phenomenon.pdf}
}

@misc{pinkstoneTwitterInvestigatesIts2020,
  title = {Twitter Investigates Its 'racist' Photo Preview Algorithm},
  author = {Pinkstone, Joe},
  year = {2020},
  month = sep,
  journal = {Mail Online},
  urldate = {2020-09-22},
  abstract = {Tests of the algorithm on the social media site over the weekend led to several examples of a preference for white faces from the automated system.},
  chapter = {Science},
  howpublished = {https://www.dailymail.co.uk/sciencetech/article-8754885/Twitter-investigates-racist-photo-preview-algorithm.html},
  file = {/Users/colin.madland/Zotero/storage/L8N4E8CJ/Twitter-investigates-racist-photo-preview-algorithm.html}
}

@article{pirbhai-illichDecolonizingTeacherEducation2016,
  title = {Towards {{Decolonizing Teacher Education}}: {{Criticality}}, {{Relationality}} and {{Intercultural Understanding}}},
  author = {{Pirbhai-Illich}, Fatima and Martin, Fran},
  year = {2016},
  journal = {Journal of Intercultural Studies},
  volume = {37},
  number = {4},
  pages = {355--372},
  issn = {0725-6868},
  abstract = {This paper critically examines two studies that investigated pre-service teacher learning in contrasting contexts: an international study visit and a local service-learning experience. The article describes the Global Partnerships as Sites for Mutual Learning project, conducted by four researchers in three nations: India, Gambia and the UK. It is argued that it is useful to conceive of these experiences as intercultural. It is further maintained that how "intercultural" is theorized in the weatern academy is object-based, with roots in colonialism.}
}

@article{pirespereiraTeacherEducationCOVID192021,
  ids = {pirespereiraTeacherEducationCOVID192021a},
  title = {Teacher {{Education}} during the {{COVID-19 Lockdown}}: {{Insights}} from a {{Formative Intervention Approach Involving Online Feedback}}},
  author = {Pires Pereira, Iris Susana and Fernandes, Eva Lopes and Flores, Maria Assuncao},
  year = {2021},
  journal = {Education sciences},
  volume = {11},
  number = {8},
  pages = {400},
  publisher = {Mdpi},
  address = {BASEL},
  issn = {2227-7102},
  doi = {10.3390/educsci11080400},
  abstract = {This paper examines preservice teachers' perspectives on assessment feedback developed in a teacher education course during the first lockdown due to the COVID-19 pandemic. As initially negotiated with students, feedback was learner-centred and involved a formative intervention approach applied iteratively by the teacher educator over the course of one semester. Although such feedback was initially face-to-face, it had to be given exclusively online following the unexpected closure of the university. Analysis of student teachers' perspectives, which were collected through an online questionnaire completed after their final assessment, reveals both positive and critical aspects regarding the feedback provided by the teacher educator. While reaffirming the significance of feedback as a crucial element for learning in online teacher education contexts, the findings also show that the clarity, affective bonding and multimodal meaning-making involved in face-to-face interaction are particularly challenging when the communication of feedback is digitally mediated. The implications and limitations of such findings are discussed.},
  keywords = {COVID-19,Distance learning,Education & Educational Research,face-to-face and online feedback,feedback,Online instruction,preservice teacher education,Social Sciences,Teaching},
  file = {/Users/colin.madland/Zotero/storage/YY89ZDCP/pirespereiraTeacherEducationCOVID192021.pdf}
}

@article{pithersCriticalThinkingEducation2000,
  title = {Critical Thinking in Education: A Review},
  shorttitle = {Critical Thinking in Education: A Review},
  author = {Pithers, R. T. and Soden, Rebecca},
  year = {2000},
  journal = {Educational Research},
  volume = {42},
  pages = {237--249},
  issn = {00131881},
  doi = {10.1080/001318800440579},
  abstract = {National governments and employers have argued that it is important for all sectors of education to prepare individuals who are able to think well and for themselves. 'Good thinking' and 'thinking well' are commonly used terms bound up with what is called 'critical thinking' in the research literature. Evidence is presented in this paper, however, which suggests that not all students may be good at critical thinking; nor do some teachers appear to teach students 'good thinking' skills. A review of the research literature in this area was undertaken and the methods and conceptions of teaching likely to inhibit and enhance critical thinking are outlined, as well as what is required to improve students' thinking skills. Ways forward in teaching critical thinking, and in helping students to learn to think well and for themselves, are described and discussed. [ABSTRACT FROM AUTHOR] Copyright of Educational Research is the property of Routledge and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
  keywords = {and,critical,CRITICAL REASONING,critical thinking,Education,LEARNING,Reasoning,Teaching,TEACHING AND LEARNING,Thinking},
  annotation = {3}
}

@misc{pittImpactsHigherEducation2022,
  title = {Impacts of Higher Education Assessment and Feedback Policy and Practice on Students: {{A}} Review of the Literature 2016-2021},
  author = {Pitt, Edd and Quinlan, Kathleen M.},
  year = {2022},
  month = may,
  publisher = {Advance HE},
  abstract = {Research Report for Advance HE following a Systematic literature review of assessment and feedback policy and practice on students},
  file = {/Users/colin.madland/Zotero/storage/ZLU3TE78/pittImpactsHigherEducation2022.pdf}
}

@article{pittsEngagingFrameworkInformation2019,
  ids = {pittsEngagingFrameworkInformation2019a},
  title = {Engaging the {{Framework}} for {{Information Literacy}} for {{Higher Education}} as a {{Lens}} for {{Assessment}} in an {{ePortfolio Social Pedagogy Ecosystem}} for {{Science Teacher Education}}},
  author = {Pitts, Wesley and {Lehner-Quam}, Alison},
  year = {2019},
  journal = {International Journal of ePortfolio},
  volume = {9},
  number = {1},
  pages = {29--44},
  publisher = {International Journal of ePortfolio},
  issn = {ISSN-2157-622X},
  abstract = {This article highlights a case study that assesses how graduate-level, in-service science teachers engage in an ePortfolio social pedagogy ecosystem to document their growth in knowledge practices and dispositions in information literacy. The ePortfolio social pedagogy ecosystem and this study are situated within the context of the Catalyst Framework. The three modes of interrelated social learning activities include: (1) authoring the written ePortfolio in an online ePortfolio digital media platform, (2) presenting the ePortfolio in the webinar platform, and (3) presenting the ePortfolio in-person in a physical setting. We used case study methodology to systematically investigate how each participant used their ePortfolio capstone exit project to engage the Association of College and Research Libraries' (2015) Framework for Information Literacy for Higher Education (ACRL Framework) as a conceptual lens to document their competencies (as part of reflective practice) in information literacy. The unit of analysis we used was the ePortfolio entry focused on using information literacy to understand science education theory and practice. Findings show that the participants emphasized content in different but connected communication modes across the ePortfolio social pedagogy ecosystem. Findings also show that ePortfolio is an effective tool for self-assessment and reflection on one's information literacy competencies. Implications for outcomes assessment are also discussed.},
  langid = {english},
  keywords = {Capstone Experiences,Competence,Electronic Publishing,Graduate Students,Higher Education,Information Literacy,Inservice Teacher Education,No DOI found,Portfolio Assessment,Science Education,Science Teachers,Secondary School Science,Teacher Competencies}
}

@incollection{pittTechnologyEnhancedDialogic2020,
  title = {Towards {{Technology Enhanced Dialogic Feedback}}},
  booktitle = {Re-Imagining {{University Assessment}} in a {{Digital World}}},
  author = {Pitt, Edd and Winstone, Naomi},
  editor = {Bearman, Margaret and Dawson, Phillip and Ajjawi, Rola and Tai, Joanna and Boud, David},
  year = {2020},
  volume = {7},
  pages = {79--94},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-41956-1_7},
  urldate = {2022-03-19},
  isbn = {978-3-030-41955-4 978-3-030-41956-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/BPDDUSRY/pittTechnologyEnhancedDialogic2020.pdf}
}

@article{plackmargaretMethodAssessingReflective2005,
  title = {A {{Method}} for {{Assessing Reflective Journal Writing}}},
  author = {Plack, Margaret, M. and Driscoll, Maryanne and Blissett, Sylvene and McKenna, Raymond and Plack, Thomas, P.},
  year = {2005},
  journal = {Journal of Allied Health},
  volume = {34},
  number = {4},
  pages = {199},
  abstract = {Reflection is widely accepted as a learning tool and is considered integral to professional practice. Journal writing is advocated in facilitating reflection, yet little is written about how to assess reflection in journals. The purpose of this study was to develop and test a method of assessing the elements of reflection in journals and to determine whether, and to what level, reflection occurs in journals. Twenty-seven physical therapy students maintained written reflective journals throughout three of their four eight-week clinical affiliations. The students were introduced to concepts of reflective practice with definitions of terms and reflective questions before their second affiliation. A coding schema was developed to assess the journals. Three raters assessed forty-three journals. The text of each journal was analyzed for evidence of nine elements of reflection, and each journal was categorized as showing no evidence of reflection, evidence of reflection, or evidence of critical reflection. Descriptive statistics were used to demonstrate evidence of reflection. Reliability between each pair of raters was assessed using percent agreement, phi coefficients, and gamma statistics. Interrater reliability of all raters was assessed using intraclass correlation coefficients (ICC[2,1]). Results showed that the raters assessed 95.3\%-100\% of the journals as showing at least one element of reflection. The percent agreement between rater pairs for the nine elements of reflection ranged from 65.1\% to 93.0\%, the phi coefficient ranged from 0.08 to 0.81, and the ICC(2,1) values used to assess reliability among the three raters on each element ranged from 0.03 to 0.72. Averaging the assessment of the three raters for the overall journal, 14.7\% of the journals were assessed as showing no evidence of reflection, 43.4\% as showing evidence of reflection, and 41.9\% as showing evidence of critical reflection. The percent agreement between rater pairs for the overall assessment of the journals ranged from 67.4\% to 85.7\%, the gamma statistic ranged from 0.88 to 0.98, and the ICC(2,1) among all raters was 0.74 (95\% confidence interval, 0.61-0.84). These results represent an acceptable level of agreement for use of this method of assessment for educational purposes. The coding schema developed provides a mechanism to assess evidence of reflection in written journals, which will enable instructors to evaluate student competency, obtain a baseline for facilitating reflective practice, and assess their own efficacy in facilitating reflection among students.}
}

@article{plakeAssessmentCompetenciesTeachers2005,
  title = {Assessment {{Competencies}} of {{Teachers}}: {{A National Survey}}},
  shorttitle = {Assessment {{Competencies}} of {{Teachers}}},
  author = {Plake, Barbara S. and Impara, James C. and Fager, Jennifer J.},
  year = {2005},
  month = oct,
  journal = {Educational Measurement: Issues and Practice},
  volume = {12},
  number = {4},
  pages = {10--12},
  issn = {07311745, 17453992},
  doi = {10/fw7g9p},
  urldate = {2021-07-29},
  langid = {english}
}

@article{plakeTeacherAssessmentLiteracy1993,
  title = {Teacher Assessment Literacy: {{Teachers}}' Competencies in the Educational Assessment of Students},
  author = {Plake, Barbara S},
  year = {1993},
  journal = {Mid-Western Educational Researcher},
  volume = {6},
  number = {1},
  pages = {21--27},
  urldate = {2021-07-09},
  abstract = {It has been estimated that teachers are involved in assessment-related activities up to 50 percent of the time. However, teacher training programs frequently do not contain specific training in educational assessment or testing. In order to identify assessment com- petencies for development of training materials in educational assessment for inservice teachers, a national survey was undertaken to measure teacher knowledge in assessment and testing. The instrument was designed to assess the competencies identified in 1990 by a joint committee of the National Educational Association, the American Federation of Teachers, and the National Council on Measure- ment in Education, StandardsforTeacherCompetenceintheEducationalAssessmentofStudents.Of the seven competency areas articulated in these Standards,teachers showed their best performance in the area of"administering, scoring and interpreting test results" and poorest performance in "communicating test results:' Based on the survey results, a joint committee of NEA, AFT, and NCME is planning the development of a training prototype for delivering inservice programs to increase teacher competency in educational assessment.},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/DBYMWGIX/plakeTeacherAssessmentLiteracy1993.pdf}
}

@article{planarEffectivenessInstructorPersonalized2016,
  title = {The {{Effectiveness}} of {{Instructor Personalized}} and {{Formative Feedback Provided}} by {{Instructor}} in an {{Online Setting}}: {{Some Unresolved Issues}}},
  author = {Planar, Dolors and Moya, Soledad},
  year = {2016},
  month = jan,
  journal = {Electronic Journal of e-Learning},
  volume = {14},
  number = {3},
  pages = {196--203},
  publisher = {Electronic Journal of e-Learning},
  issn = {1479-4403},
  abstract = {Formative feedback has great potential for teaching and learning in online undergraduate programmes. There is a large number of courses where the main source of feedback is provided by the instructor. This is particularly seen in subjects where assessments are designed based on specific activities which are the same for all students, and where the assessment is performed by the instructor, not by a peer. Additionally, in introductory or basically procedural courses, there is often a need for instructor feedback, as opposed to peer-feedback, as it demands high quality feedback both in the content and in the process in order not to mislead students. Therefore personalized feedback provided by instructor is an academic demand in the current educational models that have positioned the student at the center of the learning process. However in the present context of high student-staff ratio, it is not easy to extend the use of individual comments delivered by instructors among the academic community. This article focuses on the virtual higher education environment given its present and future potential as well as the amount of queries currently surrounding it. Literature on formative feedback in higher education has been reviewed for the period 2000 to 2014, in order to find answers as to which aspects are relevant to efficiently implement personalized feedback prepared by the teacher. Findings show that effective personalized feedback in an virtual environment requires a three-dimensional analysis: from the student perspective, from the instructor one and from the media perspective (written text, video recording or audio recording) , in order to find shared aspects that contribute to the enhancement in the use of personalized feedback performed by faculty.},
  keywords = {Computer Mediated Communication,Feedback (Response),Formative Evaluation,Instructional Effectiveness,Literature Reviews,No DOI found,Online Courses,Student Evaluation,Teacher Student Ratio,Undergraduate Students}
}

@techreport{plowdenChildrenTheirPrimary1967,
  title = {Children and Their {{Primary Schools}}},
  author = {Plowden, Bridget},
  year = {1967},
  address = {London},
  institution = {Central Advisory Council for Education (England)}
}

@inproceedings{pmlr-v81-buolamwini18a,
  title = {Gender Shades: {{Intersectional}} Accuracy Disparities in Commercial Gender Classification},
  author = {Buolamwini, Joy and Gebru, Timnit},
  editor = {Friedler, Sorelle A. and Wilson, Christo},
  year = {2018},
  series = {Proceedings of Machine Learning Research},
  volume = {81},
  pages = {77--91},
  publisher = {PMLR},
  address = {New York, NY, USA},
  abstract = {Recent studies demonstrate that machine learning algorithms can discriminate based on classes like race and gender. In this work, we present an approach to evaluate bias present in automated facial analysis algorithms and datasets with respect to phenotypic subgroups. Using the dermatologist approved Fitzpatrick Skin Type classification system, we characterize the gender and skin type distribution of two facial analysis benchmarks, IJB-A and Adience. We find that these datasets are overwhelmingly composed of lighter-skinned subjects (79.6\% for IJB-A and 86.2\% for Adience) and introduce a new facial analysis dataset which is balanced by gender and skin type. We evaluate 3 commercial gender classification systems using our dataset and show that darker-skinned females are the most misclassified group (with error rates of up to 34.7\%). The maximum error rate for lighter-skinned males is 0.8\%. The substantial disparities in the accuracy of classifying darker females, lighter females, darker males, and lighter males in gender classification systems require urgent attention if commercial companies are to build genuinely fair, transparent and accountable facial analysis algorithms.},
  pdf = {http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf},
  file = {/Users/colin.madland/Zotero/storage/3IEVSBRM/pmlr-v81-buolamwini18a.pdf;/Users/colin.madland/Zotero/storage/PLQJ7JL7/pmlr-v81-buolamwini18a.pdf}
}

@article{podsiadFacultyAcceptancePeer2020,
  title = {Faculty {{Acceptance}} of the {{Peer Assessment Collaboration Evaluation Tool}}: {{A Quantitative Study}}},
  author = {Podsiad, Megan and Havard, Byron},
  year = {2020},
  month = jun,
  journal = {Educational Technology Research and Development},
  volume = {68},
  number = {3},
  pages = {1381--1407},
  publisher = {{Educational Technology Research and Development}},
  issn = {1042-1629},
  doi = {10.1007/s11423-020-09742-z},
  abstract = {The problem this study sought to address was faculty reluctance to use new online peer-assessment tools. The purpose of this study was to examine the motivational factors that influence the acceptance of the Peer Assessment Collaboration Evaluation (PACE) Tool among faculty employed at a mid-sized university in the Southeastern United States. This study used Davis's (1986) technology acceptance model (TAM) and motivational constructs "attitude toward using, perceived usefulness and perceived ease of use" (p. 44). The researcher used simple linear regression and standard multiple regression to determine if there was a significant relationship, if any, between the motivational constructs. The results of the linear regressions denoted positive, significant relationships between perceived ease of use of the PACE Tool and attitude toward using the PACE Tool, perceived usefulness of the PACE Tool and attitude toward using the PACE Tool; and perceived ease of use of the PACE Tool and perceived usefulness of the PACE Tool. The results of the multiple regression indicated that both perceived ease of use and perceived usefulness of the PACE Tool were positively, significantly related to attitude toward using the PACE Tool. Through faculty members' speculations, the researcher was able to measure their motivation to use the PACE Tool. The results of this study demonstrated faculty members are motivated to use the PACE Tool, which indicates high acceptability and potential usage in the future. By understanding how faculty members perceive the PACE Tool, designers may be able to develop online peer-assessment tools that are more acceptable.},
  keywords = {College Faculty,Correlation,Educational Technology,Evaluation Methods,Peer Evaluation,Teacher Attitudes,Teacher Motivation,Usability}
}

@article{polakTabletAssistedObjective2022,
  title = {Tablet-assisted Objective Structured Spotter Practical Examination ({{TOSSPE}}): {{Advantages}} of an Innovative Anatomy Spotter Examination Method for Medical Student Assessment},
  author = {Polak, Katarzyna and Gielecki, Jerzy Stanis{\l}aw and {\.Z}urada, Anna},
  year = {2022},
  journal = {Anatomical sciences education},
  volume = {15},
  number = {6},
  pages = {1060--1073},
  publisher = {Wiley},
  address = {HOBOKEN},
  issn = {1935-9772},
  doi = {10.1002/ase.2131},
  abstract = {The affordances of technology-based assessments, like the objectively structured practical examination, have become an integral part of gross anatomy courses. The Department of Anatomy Faculty of Medicine at the University of Warmia and Mazury developed and introduced an application for tablet devices which has been implemented in student examinations and assessments, called the tablet-assisted objective structured spotter practical examination. It was created to simplify the educational process and to build a rich learning environment, facilitating deep learning for students through examination and feedback data. The method consists of cadaver stations with traditional corresponding pin spotters in an expanded tablet application. It not only provides instant feedback on various observations of teaching--learning skills but has also positively affected the entire process of education. The method provides an unbiased evaluation of knowledge and understanding of the anatomy course, ensuring objectivity and standardization. The current study was performed on a total of 608 first-year medical students in Polish and English divisions and focused on the observed advantages since the new method was introduced. Outcomes indicate that after the implementation of the method for both the Polish and English divisions' first-year medical students, the mean score of examinations significantly increased compared to other teaching--learning methods. The study highlights that students were excited about the implementation of the new method and identified its many benefits. It is recognized that technological development and the digital environment offer a range of opportunities and added value versus traditional assessment activities, methods, and processes.},
  keywords = {Analysis,Anatomy,Anatomy & physiology,assessment,College students,Computer Assisted Testing,Education & Educational Research,Education Scientific Disciplines,Educational Technology,Evaluation Methods,Feedback (Response),Foreign Countries,gross anatomy education,Handheld Devices,Laboratory Procedures,Learning,Medical education,medical student perceptions,Medical Students,Methods,objective structured practical examination,OSPE,practical examination,Program Effectiveness,Social Sciences,Student Attitudes,Student Evaluation,Telecommunications,undergraduate education}
}

@article{pollardMentoringGraduateStudents2021,
  title = {Mentoring {{Graduate Students Online}}: {{Strategies}} and {{Challenges}}},
  author = {Pollard, Rhiannon and Kumar, Swapna},
  year = {2021},
  journal = {International Review of Research in Open and Distributed Learning},
  volume = {22},
  number = {2},
  pages = {267--284},
  issn = {EISSN-1492-3831},
  doi = {10/gmbv2p},
  abstract = {The proliferation of online graduate programs, and more recently, higher education institutions' moves to online interactions due to the COVID-19 crisis, have led to graduate student mentoring increasingly occurring online. Challenges, strategies, and outcomes associated with online mentoring of graduate students are of primary importance for the individuals within a mentoring dyad and for universities offering online or blended graduate education. The nature of mentoring interactions within an online format presents unique challenges and thus requires strategies specifically adapted to such interactions. There is a need to examine how mentoring relationships have been, and can best be, conducted when little to no face-to-face interaction occurs. This paper undertook a literature review of empirical studies from the last two decades on online master's and doctoral student mentoring. The main themes were challenges, strategies and best practices, and factors that influence the online mentoring relationship. The findings emphasized the importance of fostering interpersonal aspects of the mentoring relationship, ensuring clarity of expectations and communications as well as competence with technologies, providing access to peer mentor groups or cohorts, and institutional support for online faculty mentors. Within these online mentoring relationships, the faculty member becomes the link to an otherwise absent yet critical experience of academia for the online student, making it imperative to create and foster an effective relationship based on identified strategies and best practices for online mentoring.},
  langid = {english},
  keywords = {Best Practices,Computer Mediated Communication,Electronic Learning,Faculty Advisers,Graduate Students,Interpersonal Relationship,Literature Reviews,Mentors}
}

@article{pollioWhenTailWags2000,
  title = {When the {{Tail Wags}} the {{Dog}}: {{Perceptions}} of {{Learning}} and {{Grade Orientation}} in, and by, {{Contemporary College Students}} and {{Faculty}}},
  shorttitle = {When the {{Tail Wags}} the {{Dog}}},
  author = {Pollio, Howard R. and Beck, Hall P.},
  year = {2000},
  month = jan,
  journal = {The Journal of Higher Education},
  volume = {71},
  number = {1},
  eprint = {2649283},
  eprinttype = {jstor},
  pages = {84},
  issn = {00221546},
  doi = {10.2307/2649283},
  urldate = {2022-04-23},
  file = {/Users/colin.madland/Zotero/storage/LKJY4VTA/pollioWhenTailWags2000.pdf}
}

@article{pophamAssessmentLiteracyOverlooked2011,
  title = {Assessment {{Literacy Overlooked}}: {{A Teacher Educator}}'s {{Confession}}},
  author = {Popham, W. James},
  year = {2011},
  month = sep,
  journal = {The Teacher Educator},
  volume = {46},
  number = {4},
  pages = {265--273},
  publisher = {Routledge},
  issn = {0887-8730},
  doi = {10/dctz5h},
  abstract = {This article presents reflections and guidance concerning assessment literacy in teacher education. Previous inadequacies in teacher training in educational assessment highlight the need for teachers to be assessment literate. Assessment literacy consists of an individual's understanding of the fundamental assessment concepts and procedures deemed likely to influence educational decisions. Due to the current focus on accountability assessments, it is in teachers' best interest, and also the students', that teachers develop a level of understanding in assessment. Assessment, when used appropriately, is also a powerful tool for learning. What is needed to facilitate assessment literacy in teacher education is more than a brief mention of assessment in a course. A course in assessment with an appropriate text is necessary to bring a more complete understanding of assessment to beginning teachers.},
  file = {/Users/colin.madland/Zotero/storage/7R2WKNYM/pophamAssessmentLiteracyOverlooked2011.pdf}
}

@article{pophamAssessmentLiteracyTeachers2009,
  title = {Assessment {{Literacy}} for {{Teachers}}: {{Faddish}} or {{Fundamental}}?},
  shorttitle = {Assessment {{Literacy}} for {{Teachers}}},
  author = {Popham, W. James},
  year = {2009},
  month = jan,
  journal = {Theory Into Practice},
  volume = {48},
  number = {1},
  pages = {4--11},
  issn = {0040-5841, 1543-0421},
  doi = {10/djcn3z},
  urldate = {2021-07-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/ZDTTTMCM/pophamAssessmentLiteracyTeachers2009.pdf}
}

@article{pophamCanClassroomAssessments2013,
  title = {Can {{Classroom Assessments}} of {{Student Growth Be Credibly Used}} to {{Evaluate Teachers}}?},
  author = {Popham, W. James},
  year = {2013},
  journal = {The English Journal},
  volume = {103},
  number = {1},
  pages = {34--39},
  publisher = {National Council of Teachers of English},
  issn = {00138274},
  urldate = {2022-06-02},
  abstract = {[Should teacher-supplied evidence of student growth---evidence garnered by using classroom assessments---be used to evaluate a teacher?]},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/QIW65R7K/pophamCanClassroomAssessments2013.pdf}
}

@article{pophamFormativeAssessmentProcess2011,
  title = {Formative {{Assessment}}\----{{A Process}}, {{Not}} a {{Test}} - {{Education Week}}},
  author = {Popham, W. James},
  year = {2011},
  month = feb,
  journal = {Education Week},
  urldate = {2020-06-16},
  abstract = {Formative assessment can work wonders when teachers realize it's a process of using assessment results to adjust how they work with their students, W. James Popham writes.}
}

@article{poquetTransitionsLifelongLearning2021,
  title = {Transitions through Lifelong Learning: {{Implications}} for Learning Analytics},
  author = {Poquet, Oleksandra and Kitto, Kirsty and Jovanovic, Jelena and Dawson, Shane and Siemens, George and Markauskaite, Lina},
  year = {2021},
  month = jan,
  journal = {Computers and Education: Artificial Intelligence},
  volume = {2},
  pages = {100039},
  issn = {2666-920X},
  doi = {10.1016/j.caeai.2021.100039},
  abstract = {The ability to develop new skills and competencies is a central concept of lifelong learning. Research to date has largely focused on the processes and support individuals require to engage in upskilling, re-learning or training. However, there has been limited attention examining the types of support that are necessary to assist a learner's transition from ``old'' workplace contexts to ``new''. Professionals often undergo significant restructuring of their knowledge, skills, and identities as they transition between career roles, industries, and sectors. Domains such as learning analytics (LA) have the potential to support learners as they use the analysis of fine-grained data collected from education technologies. However, we argue that to support transitions throughout lifelong learning, LA needs fundamentally new analytical and methodological approaches. To enable insights, research needs to capture and explain variability, dynamics, and causal interactions between different levels of individual development, at varying time scales. Scholarly conceptions of the context in which transitions occur are also required. Our interdisciplinary argument builds on the synthesis of literature about transitions in the range of disciplinary and thematic domains such as conceptual change, shifts between educational systems, and changing roles during life course. We highlight specific areas in research designs and current analytical methods that hinder insight into transformational changes during transitions. The paper concludes with starting points and frameworks that can advance research in this area.},
  keywords = {Causality,Complex dynamic systems,Human development,Learning analytics,Lifelong learning,Transitions},
  file = {/Users/colin.madland/Zotero/storage/LBXGL883/poquetTransitionsLifelongLearning2021.pdf}
}

@book{portelliKeyQuestionsEducators2005,
  title = {Key Questions for Educators},
  author = {Portelli, John P. and Hare, William},
  year = {2005},
  publisher = {Edphil Books},
  address = {Halifax},
  isbn = {0-9697253-3-7 978-0-9697253-3-6},
  langid = {english}
}

@article{porterCollaborativeOnlineAnnotation2022,
  title = {Collaborative {{Online Annotation}}: {{Pedagogy}}, {{Assessment}} and {{Platform Comparisons}}},
  shorttitle = {Collaborative {{Online Annotation}}},
  author = {Porter, Gavin W.},
  year = {2022},
  month = may,
  journal = {Frontiers in Education},
  volume = {7},
  issn = {2504-284X},
  doi = {10.3389/feduc.2022.852849},
  urldate = {2022-11-05},
  abstract = {Annotating a text while reading is commonplace and essentially as old as printed text itself. Collaborative online annotation platforms are enabling this process in new ways, turning reading from a solitary into a collective activity. The platforms provide a critical discussion forum for students and instructors that is directly content-linked, and can increase uptake of assigned reading. However, the student viewpoint regarding collaborative online annotation platforms remains largely unexplored, as do comparisons between annotation and traditional reading assessment methods, and comparisons between the two leading platforms (Hypothes.is vs. Perusall) for annotation by the same student population. The results in this study indicate that collaborative online annotation is largely preferred by students over a traditional reading assessment approach, that students regularly exceed annotation requirements indicated by an instructor, and that overall annotation quality increased as the students gained experience with the platforms. The data analysis in this study can serve as a practical exemplar for measurement of student annotation output, where baselines have yet to be established. These findings link the established research areas of peer learning, formative assessment, and asynchronous learning, with an emerging educational technology.},
  file = {/Users/colin.madland/Zotero/storage/IHTYLG84/porterCollaborativeOnlineAnnotation2022.pdf}
}

@techreport{porterWhatChallengesCommunity2019,
  title = {What Challenges Do Community College Students Face?},
  author = {Porter, Stephen R and Umbach, Paul D},
  year = {2019},
  pages = {1--17},
  address = {Raleigh, NC},
  institution = {Percontor, LLC},
  urldate = {2019-02-17}
}

@article{postareffAcademicsConceptionsAssessment2012,
  title = {Academics' Conceptions of Assessment and Their Assessment Practices},
  author = {Postareff, Liisa and Virtanen, Viivi and Katajavuori, Nina and {Lindblom-Yl{\"a}nne}, Sari},
  year = {2012},
  month = sep,
  journal = {Studies in Educational Evaluation},
  volume = {38},
  number = {3-4},
  pages = {84--92},
  issn = {0191491X},
  doi = {10/gh73g7},
  urldate = {2021-04-25},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/VFZXYDJQ/postareffAcademicsConceptionsAssessment2012.pdf}
}

@article{pothContributionsMixedInsights2018,
  title = {The Contributions of Mixed Insights to Advancing Technology-Enhanced Formative Assessments within Higher Education Learning Environments: An Illustrative Example},
  author = {Poth, Cheryl},
  year = {2018},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {15},
  number = {1},
  pages = {1--19},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10/gmb9k5},
  abstract = {Technology-enhanced formative assessment (TEFA) represents strategies for improving student learning and motivation, yet researchers point to methodological issues underpinning claims of effectiveness. This mixed methods paper, using an empirical example, illustrates the novel contributions of mixed insights in informing the implementation of two TEFA classroom strategies. An embedded mixed methods case study design bounded by an 8-week undergraduate course across three terms was used to answer the following research question: How can a mixed methods approach examining the influences to and effects of involvement in TEFA offset the weaknesses inherent to either qualitative or quantitative data and guide collection, analysis, and integration? A qualitative dominant crossover mixed analysis strategy generated four novel mixed insights from the integration of 175 classroom-based observations, 26 instructional team meeting summaries, and 274 end-of-course student questionnaires. These are represented in a case summary and joint displays: influences on involvement, effects on learning, accessibility of feedback, and impacts on instruction. The mixed insights have important implications for theory, research, and practice related to TEFA strategies and highlight the contribution that mixed methods approaches can have in advancing educational technology in higher education.;Abstract Technology-enhanced formative assessment (TEFA) represents strategies for improving student learning and motivation, yet researchers point to methodological issues underpinning claims of effectiveness. This mixed methods paper, using an empirical example, illustrates the novel contributions of mixed insights in informing the implementation of two TEFA classroom strategies. An embedded mixed methods case study design bounded by an 8-week undergraduate course across three terms was used to answer the following research question: How can a mixed methods approach examining the influences to and effects of involvement in TEFA offset the weaknesses inherent to either qualitative or quantitative data and guide collection, analysis, and integration? A qualitative dominant crossover mixed analysis strategy generated four novel mixed insights from the integration of 175 classroom-based observations, 26 instructional team meeting summaries, and 274 end-of-course student questionnaires. These are represented in a case summary and joint displays: influences on involvement, effects on learning, accessibility of feedback, and impacts on instruction. The mixed insights have important implications for theory, research, and practice related to TEFA strategies and highlight the contribution that mixed methods approaches can have in advancing educational technology in higher education.;},
  keywords = {Case studies,case study,Classrooms,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Education,Education & Educational Research,Educational Technology,Empirical analysis,formative assessment,Higher Education,higher education learning environment,Information Systems Applications (incl.Internet),joint display,Learning,Martinez Ruiz Jose (Azorin) (1873-1967),mixed methods research,Qualitative analysis,School environment,Social Sciences,Statistics for Social Science Behavorial Science Education Public Policy and Law,Teaching methods,Technology assessment}
}

@article{pothContributionsMixedInsights2018a,
  title = {The Contributions of Mixed Insights to Advancing Technology-Enhanced Formative Assessments within Higher Education Learning Environments: An Illustrative Example},
  author = {Poth, C},
  year = {2018},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {15},
  issn = {2365-9440},
  doi = {10.1186/s41239-018-0090-5},
  abstract = {Technology-enhanced formative assessment (TEFA) represents strategies for improving student learning and motivation, yet researchers point to methodological issues underpinning claims of effectiveness. This mixed methods paper, using an empirical example, illustrates the novel contributions of mixed insights in informing the implementation of two TEFA classroom strategies. An embedded mixed methods case study design bounded by an 8-week undergraduate course across three terms was used to answer the following research question: How can a mixed methods approach examining the influences to and effects of involvement in TEFA offset the weaknesses inherent to either qualitative or quantitative data and guide collection, analysis, and integration? A qualitative dominant crossover mixed analysis strategy generated four novel mixed insights from the integration of 175 classroom-based observations, 26 instructional team meeting summaries, and 274 end-of-course student questionnaires. These are represented in a case summary and joint displays: influences on involvement, effects on learning, accessibility of feedback, and impacts on instruction. The mixed insights have important implications for theory, research, and practice related to TEFA strategies and highlight the contribution that mixed methods approaches can have in advancing educational technology in higher education.},
  langid = {english},
  keywords = {case study,educational technology,formative assessment,higher education learning environment,joint display,mixed methods research,THINKING},
  file = {/Users/colin.madland/Zotero/storage/CV96L9PK/pothContributionsMixedInsights2018b.pdf}
}

@book{pothInnovationMixedMethods2018,
  title = {Innovation in Mixed Methods Research: A Practical Guide to Integrative Thinking with Complexity},
  shorttitle = {Innovation in Mixed Methods Research},
  author = {Poth, Cheryl N.},
  year = {2018},
  publisher = {SAGE},
  address = {Los Angeles},
  isbn = {978-1-4739-0668-6 978-1-4739-0669-3},
  lccn = {H62 .P6455 2018},
  keywords = {Methodology,Mixed methods research,Research},
  annotation = {OCLC: on1064922180}
}

@book{powellOpennessDropoutStudy2009,
  title = {Openness and Dropout: {{A}} Study of Four Open Distance Education Universities},
  author = {Powell, Rick},
  year = {2009-06-07/2009-06-10}
}

@article{preacherChoosingOptimalNumber2013,
  title = {Choosing the {{Optimal Number}} of {{Factors}} in {{Exploratory Factor Analysis}}: {{A Model Selection Perspective}}},
  author = {Preacher, Kristopher J. and Zhang, Guangjian and Kim, Cheongtag and Mels, Gerhard},
  year = {2013},
  journal = {Multivariate Behavioral Research},
  volume = {48},
  number = {1},
  pages = {28--56},
  publisher = {Routledge},
  issn = {0027-3171},
  doi = {10.1080/00273171.2012.710386},
  abstract = {A central problem in the application of exploratory factor analysis is deciding how many factors to retain (m). Although this is inherently a model selection problem, a model selection perspective is rarely adopted for this task. We suggest that Cudeck and Henly's (1991) framework can be applied to guide the selection process. Researchers must first identify the analytic goal: identifying the (approximately) correct m or identifying the most replicable m. Second, researchers must choose fit indices that are most congruent with their goal. Consistent with theory, a simulation study showed that different fit indices are best suited to different goals. Moreover, model selection with one goal in mind (e.g., identifying the approximately correct m) will not necessarily lead to the same number of factors as model selection with the other goal in mind (e.g., identifying the most replicable m). We recommend that researchers more thoroughly consider what they mean by ?the right number of factors? before they choose fit indices.},
  file = {/Users/colin.madland/Zotero/storage/5J3YHUQ4/preacherChoosingOptimalNumber2013.pdf}
}

@article{prenskyDigitalNativesDigital2001,
  title = {Digital {{Natives}}, {{Digital Immigrants Part}} 1},
  author = {Prensky, Marc},
  year = {2001},
  month = sep,
  journal = {On the Horizon},
  volume = {9},
  number = {5},
  pages = {1--6},
  issn = {1074-8121},
  doi = {10/cxwdzq},
  urldate = {2020-04-20},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/KM37NHUC/prenskyDigitalNativesDigital2001.pdf}
}

@article{presseyMachineAutomaticTeaching1927,
  title = {A Machine for Automatic Teaching of Drill Material.},
  author = {Pressey, S. L.},
  year = {1927},
  journal = {School \& Society},
  volume = {25},
  pages = {549--552},
  publisher = {Society for the Advancement of Education},
  address = {US},
  issn = {0036-6455(Print)},
  abstract = {A description is given of a drill apparatus which will omit a question from further presentation as soon as the learner has obtained the correct answer twice in succession. The apparatus is alleged to be meritorious in that it keeps the question to be mastered before the learner until he finds the correct answer, it informs him at once of the corrections of his response, and it prevents the overlearning of some parts of the lesson as well as the underlearning of others. Labor-saving devices in education are encouraged. (PsycINFO Database Record (c) 2018 APA, all rights reserved)},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/MAKQJPNN/presseyMachineAutomaticTeaching1927.pdf}
}

@patent{presseyMachineIntelligenceTests1930,
  title = {Machine for {{Intelligence Tests}}},
  author = {Pressey, Sidney L},
  year = {1930},
  month = mar,
  number = {1749226},
  nationality = {US}
}

@misc{pressLyingComputerGeneratedTexts,
  title = {``{{Lying}}'' in {{Computer-Generated Texts}}: {{Hallucinations}} and {{Omissions}}},
  shorttitle = {``{{Lying}}'' in {{Computer-Generated Texts}}},
  author = {Press, Oxford University},
  journal = {Library Journal},
  urldate = {2023-09-22},
  abstract = {There is huge excitement about ChatGPT and other large generative language models that produce fluent and human-like texts in English and other human languages. But these models have one big drawback, which is that their texts can be factually incorrect (hallucination) and also leave out key information (omission).},
  howpublished = {https://www.libraryjournal.com/story/lying-in-computer-generated-texts-hallucinations-and-omissions-lj230901},
  file = {/Users/colin.madland/Zotero/storage/UIHCI2FH/pressLyingComputerGeneratedTexts.pdf;/Users/colin.madland/Zotero/storage/V8HRRMW2/lying-in-computer-generated-texts-hallucinations-and-omissions-lj230901.html}
}

@inproceedings{presteraFacilitatingAsynchronousDistance,
  title = {Facilitating Asynchronous Distance Learning: {{Exploiting Opportunities}} for Knowledge Building in Asynchronous Distance Learning Environments},
  booktitle = {Mid-{{South Instructional Technology Conference}}},
  author = {Prestera, Gustavo E and Moller, Leslie A}
}

@article{priceIfWasGoing2011,
  title = {If {{I}} Was Going There {{I}} Wouldn't Start from Here: A Critical Commentary on Current Assessment Practice},
  shorttitle = {If {{I}} Was Going There {{I}} Wouldn't Start from Here},
  author = {Price, Margaret and Carroll, Jude and O'Donovan, Berry and Rust, Chris},
  year = {2011},
  month = jul,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {36},
  number = {4},
  pages = {479--492},
  issn = {0260-2938, 1469-297X},
  doi = {10/d4sz5m},
  urldate = {2021-04-25},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/NKI3WPP3/priceIfWasGoing2011.pdf}
}

@article{pricePuttingSocialConstructivist2007,
  title = {Putting a Social Constructivist Assessment Process Model into Practice Building the Feedback Loop into the Assessment Process through Peer Review},
  author = {Price, Margaret and O'Donovan, Berry and Rust, Chris},
  year = {2007},
  journal = {Innovations in Education and Teaching International},
  doi = {10/d6qmr7},
  abstract = {This paper reports the latest stage of a research project focused on developing students' understanding of assessment criteria, the assessment process and assessment standards. It explains the theory of a social-constructivist assessment process model and details one particular module where the authors have tried to put it into practice. In particular, it focuses on attempts to actively engage the students with feedback on their work, and the feedback process, and considers the evidence of whether it has been effective.},
  pmcid = {null},
  pmid = {null}
}

@article{pricePuttingSocialConstructivist2007a,
  title = {Putting a Social Constructivist Assessment Process Model into Practice Building the Feedback Loop into the Assessment Process through Peer Review},
  author = {Price, Margaret and O'Donovan, Berry and Rust, Chris},
  year = {2007},
  journal = {Innovations in Education and Teaching International},
  doi = {10/d6qmr7},
  abstract = {This paper reports the latest stage of a research project focused on developing students' understanding of assessment criteria, the assessment process and assessment standards. It explains the theory of a social-constructivist assessment process model and details one particular module where the authors have tried to put it into practice. In particular, it focuses on attempts to actively engage the students with feedback on their work, and the feedback process, and considers the evidence of whether it has been effective.},
  pmcid = {null},
  pmid = {null}
}

@misc{PrivacySurveillanceQuiz,
  title = {Privacy and {{Surveillance Quiz}}},
  journal = {Digital Tattoo},
  urldate = {2021-12-23},
  howpublished = {https://digitaltattoo.ubc.ca/quizzes/privacy-and-surveillance/},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/WUWKEQPA/privacy-and-surveillance.html}
}

@misc{ProjectBasedLearning,
  title = {Project {{Based Learning}} in a {{Virtual World}}.Pdf},
  journal = {Google Docs},
  urldate = {2020-05-22},
  howpublished = {https://drive.google.com/file/d/132GqM9VzpEpd1kGPkJQlPFf2Efq-Kp7G/view?usp=embed\_facebook},
  file = {/Users/colin.madland/Zotero/storage/HEVAHSJ8/view.html}
}

@misc{ProjectManagementInstructional,
  title = {Project {{Management}} for {{Instructional Designers}}},
  journal = {Open Textbook Library},
  urldate = {2020-04-29},
  abstract = {Project Management for Instructional Designers (PM4ID) is -- as the name suggests -- a book about project management tailored specifically for instructional designers. This book is a revise / remix of a pre-existing, openly licensed project management textbook which was donated to the commons by a benefactor that desires to be attributed as Anonymous.},
  howpublished = {https://open.umn.edu/opentextbooks/textbooks/project-management-for-instructional-designers},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/NLV3MA9R/project-management-for-instructional-designers.html}
}

@article{prokhorovImplementationDigitalTechnology2022,
  title = {Implementation of Digital Technology for Student Involvement Based on a {{3D}} Quest Game for Career Guidance and Assessing Students' Digital Competences},
  author = {Prokhorov, Oleksandr V. and Lisovichenko, Vladyslav O. and Mazorchuk, Mariia S. and Kuzminska, Olena H.},
  year = {2022},
  journal = {Educational technology quarterly},
  volume = {2022},
  number = {4},
  pages = {366--387},
  publisher = {{Academy of Cognitive and Natural Sciences}},
  issn = {2831-5332},
  doi = {10.55056/etq.430},
  abstract = {This article describes the process of developing a career advice 3D adventure game for applicants interested in working in IT departments. The game is based on a 3D representation of the computer science and information technologies department at the Kharkiv Aviation Institute. The quest challenges are designed to measure applicants' and first-year students' digital competency. The theoretical foundation, software tools, development stages, implementation obstacles, and gaming application scenario were all used in the article. The game scenario includes a virtual tour of a 3D university department. In terms of how closely the game resembles real-life stuff, applicants can examine the department's equipment and classrooms. The team used C\# and C++, Unity 3D, and Source Engine to create the game application. We used Hammer Editor, Agisoft PhotoScan Pro, and photogrammetry technology to model objects for realistic gaming. Based on the Digital Competence Framework for Citizens (DigComp 2.2), players can assess their digital competences in a variety of ways, including a test activity, a puzzle, assembling a computer, and putting up an IT-specialist firm. The experiment conducted at the online open house day 2020 demonstrated the efficiency of the 3D quest game. A 3D quest was rated as a more modern and appealing kind of involvement by the candidates. According to the 3D quest findings, applicants displayed an average degree of digital competence, with certain specific item challenges graded at 0.5. Several psychometric item parameters were thoroughly examined in order to increase the item's quality.},
  keywords = {3D model,career guidance,computer science,higher education,quest game,virtual reality},
  file = {/Users/colin.madland/Zotero/storage/3KW7URX3/prokhorovImplementationDigitalTechnology2022.pdf}
}

@article{pryorChallengingFormativeAssessment2010,
  title = {Challenging Formative Assessment: Disciplinary Spaces and Identities},
  shorttitle = {Challenging Formative Assessment},
  author = {Pryor, John and Crossouard, Barbara},
  year = {2010},
  month = may,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {35},
  number = {3},
  pages = {265--276},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602930903512891},
  urldate = {2022-06-23},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/27AG5NS8/pryorChallengingFormativeAssessment2010.pdf}
}

@article{pryorSocioCulturalTheorisation2008,
  title = {A Socio-cultural Theorisation of Formative Assessment},
  author = {Pryor, John and Crossouard, Barbara},
  year = {2008},
  month = feb,
  journal = {Oxford Review of Education},
  volume = {34},
  number = {1},
  pages = {1--20},
  issn = {0305-4985, 1465-3915},
  doi = {10.1080/03054980701476386},
  urldate = {2022-06-23},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/GEZIW8II/pryorSocioCulturalTheorisation2008.pdf}
}

@article{puchumniUsingInformationRetrieval2019,
  title = {Using {{Information Retrieval Activities}} to {{Foster Analytical Thinking Skills}} in {{Higher Education}} in {{Thailand}}: {{A Case Study}} of {{Local Wisdom Education}}},
  author = {Puchumni, Puchit and Tungpradabkul, Sumalee and Magee, Ratana},
  year = {2019},
  journal = {Asian Journal of Education and Training},
  volume = {5},
  number = {1},
  pages = {80--85},
  issn = {EISSN-2519-5387},
  doi = {10/gmbv35},
  abstract = {Three information retrieving lessons were designed to foster analytical thinking in freshmen with minimal prior active learning experience. Thailand Local Wisdom contents were used as an online information platform due to the scarcity in well-established credible information sources. The lessons were collaborative learning both within own group and between groups. The information retrieving, credibility sorting, classroom sharing, analytical thinking assessments, and self-evaluating activities were conducted in sequential steps and repeated in three trials. A reflective pause was introduced between trials. The self-evaluating pause procedure using teacher's feedback was possibly a major reason for gains, from 65.0\% to 82.5\% and to 92.5\%, in the number of students exhibiting analytical thinking evidence. A free-response survey after the learning experience showed that the students express high appreciation for the active learning activities as fun and analytical-thinking-promoting learning experiences.},
  langid = {english},
  keywords = {Active Learning,College Freshmen,Foreign Countries,Higher Education,Indigenous Knowledge,Information Retrieval,Learning Experience,Thinking Skills}
}

@misc{puenteduraBuildingTransformationIntroduction2009,
  title = {Building {{Transformation}}: {{An Introduction}} to the {{SAMR Model}}},
  author = {Puentedura, Ruben R},
  year = {2009},
  journal = {http://hippasus.com},
  urldate = {2023-01-19},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/WNPH4VP5/puenteduraBuildingTransformationIntroduction2009.pdf}
}

@misc{pufekAIObservatory2023,
  title = {{{AI Observatory}}},
  author = {Pufek, Samantha},
  year = {2023},
  journal = {HESA},
  urldate = {2023-09-22},
  abstract = {Roundtable Meetings Policies \& Guidelines News \& Research Submission Form HESA PRESENTS Observatory on AI Policies in Canadian Post-Secondary Education {\dots} Continued},
  howpublished = {https://higheredstrategy.com/ai-observatory-home/},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/U3JAQTKL/ai-observatory-home.html}
}

@article{pughCanAutomatedItem2020,
  title = {Can Automated Item Generation Be Used to Develop High Quality {{MCQs}} That Assess Application of Knowledge?},
  author = {Pugh, Debra and De Champlain, Andr{\'e} and Gierl, Mark and Lai, Hollis and Touchie, Claire},
  year = {2020},
  month = dec,
  journal = {Research and Practice in Technology Enhanced Learning},
  volume = {15},
  number = {1},
  pages = {12},
  issn = {1793-7078},
  doi = {10.1186/s41039-020-00134-8},
  urldate = {2022-03-12},
  abstract = {Abstract             The purpose of this study was to compare the quality of multiple choice questions (MCQs) developed using automated item generation (AIG) versus traditional methods, as judged by a panel of experts. The quality of MCQs developed using two methods (i.e., AIG or traditional) was evaluated by a panel of content experts in a blinded study. Participants rated a total of 102 MCQs using six quality metrics and made a judgment regarding whether or not each item tested recall or application of knowledge. A Wilcoxon two-sample test evaluated differences in each of the six quality metrics rating scales as well as an overall cognitive domain judgment. No significant differences were found in terms of item quality or cognitive domain assessed when comparing the two item development methods. The vast majority of items ({$>$} 90\%) developed using both methods were deemed to be assessing higher-order skills. When compared to traditionally developed items, MCQs developed using AIG demonstrated comparable quality. Both modalities can produce items that assess higher-order cognitive skills.},
  langid = {english},
  keywords = {archived},
  annotation = {https://web.archive.org/web/20220312235433/https://telrp.springeropen.com/articles/10.1186/s41039-020-00134-8},
  file = {/Users/colin.madland/Zotero/storage/8V2SURNC/pughCanAutomatedItem2020.pdf}
}

@incollection{pullinAssessmentEquityOpportunity2008,
  title = {Assessment, {{Equity}}, and {{Opportunity}} to {{Learn}}},
  booktitle = {Assessment, {{Equity}}, and {{Opportunity}} to {{Learn}}},
  author = {Pullin, Diana C.},
  editor = {Pullin, Diana C. and Haertel, Edward H. and Gee, James Paul and Young, Lauren Jones and Moss, Pamela A.},
  year = {2008},
  series = {Learning in {{Doing}}: {{Social}}, {{Cognitive}} and {{Computational Perspectives}}},
  pages = {333--352},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9780511802157.014},
  abstract = {Although assessment has a long history in American education, at no time in the nation's history has it been so prominent and pervasive as it is today. Due to state initiatives and the No Child Left Behind Act of 2001 (NCLB) (P.L.107--110, 2002), externally mandated testing is currently seen as the primary means of driving education reform, a means through which evidence-based decisions can be made to achieve accountability, allocate resources, inform parents and taxpayers, and credential educators. This is in addition to the longstanding and widespread use of tests to determine placement of individuals in special education or gifted programs, grade-to-grade promotion, certification for graduation, allocation of scholarships and vouchers, special intervention in instructional programs, accreditation of schools, and higher education admissions. Testing, however, is only one type of educational assessment, and in the nation's schools there are a wide range of assessment practices used by teachers and other educators, the primary users of assessment information and the primary providers of learning opportunities to students. The work represented in this volume is intended to challenge our understandings of the roles of assessment in schools and to reform our perspectives on the relationships between assessment, learning, and the provision of meaningful learning opportunities.},
  isbn = {978-0-521-88045-9}
}

@incollection{pullinAssessmentLensOpportunity2008,
  title = {Assessment {{Through}} the {{Lens}} of ``{{Opportunity}} to {{Learn}}''},
  booktitle = {Assessment, {{Equity}}, and {{Opportunity}} to {{Learn}}},
  author = {Pullin, Diana C. and Haertel, Edward H.},
  editor = {Pullin, Diana C. and Haertel, Edward H. and Gee, James Paul and Young, Lauren Jones and Moss, Pamela A.},
  year = {2008},
  series = {Learning in {{Doing}}: {{Social}}, {{Cognitive}} and {{Computational Perspectives}}},
  pages = {17--41},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9780511802157.004},
  abstract = {Educational tests are sometimes viewed as no more than measuring instruments, neutral indicators of learning outcomes. For more than a century, though, tests and assessments have been used in the United States to influence curriculum, allocate educational resources and opportunities, and influence classroom instructional practices (Haertel and Herman 2005). It is argued in this chapter that the idea of opportunity to learn (OTL) offers a useful lens through which to understand these many consequences of testing policies and practices, both positive and negative. Whenever assessment affects instructional content, resources, or processes, whether by design or otherwise, it is affecting OTL.After framing the interplay of assessment with conceptions of OTL in terms of (1) content taught; (2) adequacy and allocation of educational resources; and (3) teaching practices, the chapter turns to five cases that illustrate some of these intersections. First considered is the intelligence-testing movement of the early twentieth century. This was a well-intentioned but unfortunate attempt to use testing to guide more efficient resource allocation. Second is Tyler's Eight-Year Study in the 1930s. This study reflected the designers' deep understanding that neither curriculum content nor instructional practices could be changed fundamentally unless consequential examinations were changed at the same time. The third case considered is the minimum competency testing (MCT) movement of the 1970s and 1980s, which prompted litigation leading to the legal requirement that students have a fair opportunity to learn what is covered on a high school graduation test.},
  isbn = {978-0-521-88045-9}
}

@incollection{pullinIndividualizingAssessmentOpportunity2008,
  title = {Individualizing {{Assessment}} and {{Opportunity}} to {{Learn}}},
  booktitle = {Assessment, {{Equity}}, and {{Opportunity}} to {{Learn}}},
  author = {Pullin, Diana C.},
  editor = {Pullin, Diana C. and Haertel, Edward H. and Gee, James Paul and Young, Lauren Jones and Moss, Pamela A.},
  year = {2008},
  series = {Learning in {{Doing}}: {{Social}}, {{Cognitive}} and {{Computational Perspectives}}},
  pages = {109--135},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9780511802157.007},
  abstract = {Students with disabilities are a group for whom opportunity to learn (OTL) and educational assessment present special issues of public policy and challenges for educational research and practice. These challenges highlight both the powerful prospects for improving schools and the significant limitations inherent in current practice. One commentator has suggested that ``when read critically, special education provides the structural and cultural insights that are necessary to begin reconstructing public education for the historical conditions of the twenty-first century and, ultimately, for reconciling it with its democratic ideals'' (Skrtic 1991, 206).Children with disabilities were a group long excluded from our nation's schools. In 1974, Congress estimated that more than a million children with disabilities were not in school (Hehir and Gamm 1999; Pullin 1999). When a commitment was made to educate this population, it was embedded in a series of state and federal legal protections that define access to educational opportunity in a manner quite different from the opportunities afforded to students without disabilities. Although our system of educating students with disabilities is far from perfect in either design or implementation, examination of the treatment of students with disabilities affords a different lens for viewing the challenges associated with providing every child with a full and fair opportunity to learn utilizing appropriate and meaningful testing and assessment.Almost nine percent of the students in the country, more than six million children and youth, received special education services in 2002 under the federal Individuals with Disabilities Education Act (IDEA); almost half of these students were those placed in the category of individuals with specific learning disabilities (U.S. Department of Education 2004).},
  isbn = {978-0-521-88045-9}
}

@article{puntiRethinkingRaceEthnicity2021,
  title = {Rethinking {{Race}}, {{Ethnicity}}, and the {{Assessment}} of {{Intercultural Competence}} in {{Higher Education}}},
  author = {Punti, Gemma and Dingel, Molly},
  year = {2021},
  journal = {Education Sciences},
  volume = {11},
  issn = {EISSN-2227-7102},
  abstract = {This qualitative study aims to explore the limitations of using a cultural assessment tool in higher education with the goal of preparing students to thrive in a highly demanding, diverse, and global community. Colleges and universities are potentially important sites of cross-cultural and cross-racial engagement and socialization, and cultural competence is arguably one of the critical skills that many higher education institutions are embracing to prepare students for our diverse, but increasingly polarized, global society. In particular, this study discusses the use of the intercultural development inventory (IDI), a cultural assessment tool that has not been validated in the U.S. for racial, ethnic, or social class differences, and which leaves out the role of structural inequalities in intercultural relationships. Findings reveal that interview data from black, indigenous, and people of color (BIPOC) did not align with their IDI results and that the tool dismisses the complex experiences of BIPOC students. These findings jeopardize the tool's purpose and validity. Finally, this study reveals the importance of educating students about structural competence to improve empathy and understanding of a diverse student body.},
  keywords = {African American Students,American Indian Students,Cultural Awareness,Empathy,Ethnicity,Health Sciences,Institutional Characteristics,Intercultural Communication,Living Learning Centers,Majors (Students),Measures (Individuals),Minority Group Students,No DOI found,Race,Racial Differences,Social Class,Social Differences,Socialization,Student Attitudes,Student Diversity,Undergraduate Students,Validity}
}

@article{purkayasthaCriticalComponentsFormative2019,
  ids = {purkayasthaCriticalComponentsFormative2019a},
  title = {Critical {{Components}} of {{Formative Assessment}} in {{Process-Oriented Guided Inquiry Learning}} for {{Online Labs}}},
  author = {Purkayastha, Saptarshi and Surapaneni, Asha K. and Maity, Pallavi and Rajapuri, Anushri S. and Gichoya, Judy W.},
  year = {2019},
  journal = {Electronic Journal of e-Learning},
  volume = {17},
  number = {2},
  pages = {79--92},
  publisher = {Acad Conferences \& Publ Int Ltd},
  address = {NR READING},
  issn = {EISSN-1479-4403},
  doi = {10/gmbv2x},
  abstract = {In the traditional lab setting, it is reasonably straightforward to monitor student learning and provide ongoing feedback. Such formative assessments can help students identify their strengths and weaknesses, and assist faculty to recognize where students are struggling and address problems immediately. But in an online virtual lab setting, formative assessment has challenges that go beyond space-time synchrony of online classroom. As we see increased enrollment in online courses, learning science needs to address the problem of formative assessment in online laboratory sessions. We developed a student team learning monitor (STLM module) in an electronic health record system to measure student engagement and actualize the social constructivist approach of Process Oriented Guided Inquiry Learning (POGIL). Using iterative Plan-Do-Study-Act cycles in two undergraduate courses over a period of two years, we identified critical components that are required for online implementation of POGIL. We reviewed published research on POGIL classroom implementations for the last ten years and identified some common elements that affect learning gains. We present the critical components that are necessary for implementing POGIL in online lab settings, and refer to this as Cyber POGIL. Incorporating these critical components are required to determine when, how and the circumstances under which Cyber POGIL may be successfully implemented. We recommend that more online tools be developed for POGIL classrooms, which evolve from just providing synchronous communication to improved task monitoring and assistive feedback.},
  langid = {english},
  keywords = {Active learning,Active Learning,CAI,Computer assisted instruction,Cooperative Learning,Critical components,Design,Distance learning,Education,Education & Educational Research,Educational technology,Electronic health records,Formative Evaluation,Health informatics,Information management,Information Management,Inquiry,Inquiry method,Laboratories,Learner Engagement,Online Courses,Online instruction,Organic chemistry,Pedagogy,Pharmacology,Physical sciences,Process Education,Science,Skills,Social Sciences,Student Evaluation,Student participation,Students,Undergraduate Students,Virtual Classrooms},
  file = {/Users/colin.madland/Zotero/storage/G3FTCVRF/purkayasthaCriticalComponentsFormative2019.pdf}
}

@book{puzziferroSupportingOnlineFaculty2010,
  title = {Supporting Online Faculty - Revisiting the Seven Principles},
  author = {Puzziferro, Maria and Shelton, Kaye},
  year = {July 15, 2010 2009},
  volume = {12},
  abstract = {Since 2005, the landscape of online teaching and learning has changed as well as the landscape of the academy, and continues to transform before our eyes. These changes are not only a product of technological innovation, but also a result of new and reconceptualized values of higher education, and so we must reexamine what changes to faculty role, position and perspectives best support these new values. Drawing on the Seven Principles of Good Practice, this article visits the need for effective faculty support and development in online education. Online education has forever transformed higher education, and we are learning that quality requires flexibility and the ability to adapt to the changing demands of learners, the new promises of technology, and the new competitive landscape of higher education. If higher education is to remain competitive, we must refocus and redesign our paradigms, as well as design business processes that integrate with quality assurance models.}
}

@article{qiaoExplanatoryCognitiveDiagnostic2021,
  title = {Explanatory Cognitive Diagnostic Modeling Incorporating Response Times},
  author = {Qiao, Xin and Jiao, Hong},
  year = {2021},
  journal = {Journal of Educational Measurement},
  volume = {58},
  number = {4},
  pages = {564--585},
  publisher = {Wiley-Blackwell Publishing Ltd.},
  issn = {0022-0655},
  doi = {10.1111/jedm.12306},
  abstract = {This study proposes explanatory cognitive diagnostic model (CDM) jointly incorporating responses and response times (RTs) with the inclusion of item covariates related to both item responses and RTs. The joint modeling of item responses and RTs intends to provide more information for cognitive diagnosis while item covariates can be used to predict item parameters when item calibration is not feasible in diagnostic assessments or item parameter estimation errors could be too large due to small sample sizes for calibration. In addition, the inclusion of the item covariates allows the evaluation of cognitive theories underlying the test design in item development. Model parameter estimation is explored using the Bayesian Markov chain Monte Carlo (MCMC) method. A Monte Carlo simulation study is conducted to examine the parameter recovery of the proposed model under different simulated conditions in comparison to alternative competing models. Further, the application of the proposed model is illustrated using the Programme for International Student Assessment (PISA) 2012 problem-solving items modeling both item response and RT data. The study results indicate that model parameters can be well recovered using the MCMC algorithm and the explanatory CDM jointly incorporating item responses and RTs with item covariates holds promising applications in digital-based diagnostic assessments. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {cognitive diagnostic modeling,Cognitive Psychology,Diagnostic Criteria,Inclusion,International Students,item covariates,Markov Chains,Problem Solving,Reaction Time,response times,Responses,Simulation,Statistical Estimation}
}

@article{qinHowServantLeadership2021,
  title = {How {{Servant Leadership Sparks Feedback-Seeking Behavior}}: {{A Moderated Mediation Model}}},
  author = {Qin, D. and Xu, Yan and Li, Chaoping and Meng, Xue},
  year = {2021},
  month = nov,
  journal = {Frontiers in Psychology},
  doi = {10.3389/FPSYG.2021.748751},
  abstract = {Drawing upon social information processing theory, we propose that moqi with supervisors mediates the relationship between servant leadership and follower feedback-seeking behavior. Subordinates' traditionality plays a moderating role in this process. A total of 440 Chinese working adults responded to the two-wave questionnaire survey in paper and pencil forms. Correlation analyses, mediation analysis, and moderated mediation analysis was performed through R and SPSS PROCESS Macro. The results revealed that servant leadership positively correlates with followers' feedback-seeking behavior via moqi with supervisors. Moreover, these indirect effects of servant leadership were moderated by traditionality, such that servant leadership had weaker relations with feedback-seeking behavior when traditionality was higher (vs. lower). Theoretical contributions and practical implications, limitations and suggestions for further study were discussed.}
}

@incollection{qualmanChapterSixteenEmpower2012,
  title = {Chapter {{Sixteen}} - {{Empower Others}}},
  booktitle = {Digital Leader: 5 Simple Keys to Success and Influence},
  author = {Qualman, Erik},
  year = {2012},
  publisher = {McGraw-Hill},
  address = {New York},
  isbn = {978-0-07-179244-8},
  lccn = {HD57.7},
  keywords = {Influence (Psychology),Internet,Leadership,Reputation,Social aspects}
}

@article{quArtificialIntelligenceLeads2022,
  title = {Artificial Intelligence Leads the Reform of Education Models},
  author = {Qu, Jianjing and Zhao, Yanan and Xie, Yongping},
  year = {2022},
  journal = {Systems Research and Behavioral Science},
  volume = {39},
  number = {3},
  pages = {581--588},
  issn = {1092-7026, 1099-1743},
  doi = {10.1002/sres.2864},
  urldate = {2023-09-23},
  abstract = {Abstract             Artificial intelligence has become a new engine to achieve innovation-driven development. Integrating artificial intelligence and education will lead to a new education development model and promote better education. Analysing the development trends in artificial intelligence education in various countries shows the demands for training and platform construction of artificial intelligence education. Artificial intelligence education presents the characteristics of diversified technology, personalized instruction, and intelligent student assessment.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/K448KY5C/quArtificialIntelligenceLeads2022.pdf}
}

@article{quesada-serraWhatAreWe2016,
  title = {What Are We Missing? {{Spanish}} Lecturers' Perceptions of Their Assessment Practices},
  author = {{Quesada-Serra}, V. and {Rodr{\'i}guez-G{\'o}mez}, G. and {Ibarra-S{\'a}iz}, M.S.},
  year = {2016},
  journal = {Innovations in Education and Teaching International},
  volume = {53},
  number = {1},
  pages = {48--59},
  publisher = {Routledge},
  issn = {1470-3297},
  doi = {10/gjphqx},
  abstract = {Many studies have explored alternative assessment practices that focus on students and their learning. In this paper, we present a survey study that analyses lecturers? perceptions of their assessment practices. Special attention is paid to assessment tasks developed to monitor student learning and those designed to promote active student participation in the assessment process. Lecturers? perceptions of the importance, perceived competence and implementation of such assessment tasks are considered throughout the paper. Responses showed that lecturers assigned importance to the monitoring of student learning and felt reasonably capable of implementing assessment tasks for that purpose. Much less importance was placed on student participation in such assessments; lecturers perceived their abilities to implement assessment tasks to promote student participation to be poor and they rarely used such tasks.},
  file = {/Users/colin.madland/Zotero/storage/R9C4LLHC/quesada-serraWhatAreWe2016.pdf}
}

@article{quesadaShouldUseCoassessment2019,
  title = {Should {{I}} Use Co-Assessment in Higher Education? {{Pros}} and Cons from Teachers and Students' Perspectives},
  shorttitle = {Should {{I}} Use Co-Assessment in Higher Education?},
  author = {Quesada, Victoria and G{\'o}mez Ruiz, Miguel {\'A}ngel and Gallego Noche, Maria Beatriz and {Cubero-Ib{\'a}{\~n}ez}, Jaione},
  year = {2019},
  month = oct,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {44},
  number = {7},
  pages = {987--1002},
  issn = {0260-2938, 1469-297X},
  doi = {10/gjphqv},
  urldate = {2021-04-10},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/7RHEEJ8L/quesadaShouldUseCoassessment2019.pdf}
}

@misc{QuestionsSwirlPossible,
  title = {Questions Swirl about Possible Racial Bias in {{Twitter}} Image Function {\textbar} {{The Star}}},
  urldate = {2020-09-22},
  howpublished = {https://www.thestar.com.my/tech/tech-news/2020/09/22/questions-swirl-about-possible-racial-bias-in-twitter-image-function},
  file = {/Users/colin.madland/Zotero/storage/RTF4WBYE/questions-swirl-about-possible-racial-bias-in-twitter-image-function.html}
}

@article{qureshiAdvancementMassiveOpen2019,
  title = {Advancement in {{Massive Open Online Courses}} ({{MOOCs}}) to {{Revolutionize Disruptive Technology}} in {{Education}}: {{A Case}} of {{Pakistan}}},
  author = {Qureshi, Jawaid Ahmed},
  year = {2019},
  journal = {Journal of Education and Educational Development},
  volume = {6},
  number = {2},
  pages = {219--234},
  issn = {ISSN-2310-0869},
  doi = {10/gmbv3f},
  abstract = {Massive Open Online Courses (MOOCs) is a relatively recent advancement in the distance learning and online education. With the strategic collaboration of the founders of MOOC (MIT and Harvard University), many universities and institutions across the world offer a variety of courses in numerous domains. MOOCs have disrupted the global education sector by providing free to subsidized inclusive education. These include state-of-the-art pedagogies, assessment tools and interactive cum engaging learning sessions. This article aims to discover the opportunities and inclinations of adult students in Pakistan toward MOOC, especially their awareness, perceptions, peer and mentor advice and self-motivation and commitment to do such courses. The study deployed in-depth interviews under phenomenology approach using Delphi method for this study. Twenty-four students from management sciences department of a leading university in Karachi were selected: 12 who had done courses through MOOC and 12 who had never done any course on MOOC. Ten experts on distance education and online education were selected through snowball sampling method for the study. The findings uncovered that the inclination of the students towards MOOC is at its inception stage.},
  langid = {english},
  keywords = {Access to Education,Adult Students,Distance Education,Educational Technology,Foreign Countries,Higher Education,Large Group Instruction,Mentors,Online Courses,Peer Influence,Student Attitudes,Student Motivation,Technology Uses in Education}
}

@article{raaheimDigitalAssessmentHow2019,
  ids = {raaheimDigitalAssessmentHow2019a,raaheimDigitalAssessmentHow2019b},
  title = {Digital Assessment - How Does It Challenge Local Practices and National Law? {{A Norwegian}} Case Study},
  author = {Raaheim, Arild and Mathiassen, Ketil and Moen, Vegard and Lona, Irene and Gynnild, Vidar and Bun{\ae}s, Bente Ringlund and Hasle, Emil Trygve},
  year = {2019},
  journal = {European journal of higher education},
  volume = {9},
  number = {2},
  pages = {219--231},
  publisher = {Routledge},
  issn = {2156-8235},
  doi = {10.1080/21568235.2018.1541420},
  abstract = {The traditional exam has a strong holding within Norwegian higher education and is very often the preferred way of assessing students. Digital technology opens up for alternatives to the traditional exam, but so far focus has predominantly been on exchanging pen and paper with personal computers within the traditional framework. Digital alternatives may come in conflict with existing law governing teaching and assessment at university, as the law was written at a time when digital technology did not exist. We present data from a workshop in which 48 individuals from 11 institutions, academics as well as administration, were asked to identify and discuss challenges related to the introduction of digital alternatives. A case study strategy was considered appropriate as this gave us the opportunity to collect information from representatives from many universities and university colleges across Norway. Lack of knowledge about alternatives to the traditional exam, and lack of knowledge as to how digital technology may be used in assessing students were the kind of challenges most often mentioned. Assessment practices may be rooted in an assessment policy, but data from a survey (29\% response rate) indicate that there is little awareness concerning this issue within Norwegian higher education institutions.},
  keywords = {Achievement Tests,Active Learning,Administrator Attitudes,assessment,assessment policy,Case Studies,College Faculty,College Students,Computer Assisted Testing,digital technology,Educational Change,Evaluation Methods,Foreign Countries,Higher Education,Information Technology,Knowledge Level,Laws,Student Evaluation,Teacher Attitudes,Teaching Methods,Workshops},
  file = {/Users/colin.madland/Zotero/storage/QFQYY4RI/raaheimDigitalAssessmentHow2019.pdf}
}

@misc{RacistTwitterAlgorithm2020,
  title = {'{{Racist}}' {{Twitter}} Algorithm Erases Black Faces from Preview Pictures},
  year = {2020},
  month = sep,
  journal = {Metro},
  urldate = {2020-09-22},
  abstract = {Tests suggest the platform may treat white faces as the focal point more frequently.},
  chapter = {News},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/54TZ323U/racist-twitter-algorithm-erases-black-faces-from-preview-pictures-13305262.html}
}

@article{radnorProblemsFacilitatingQualitative1994,
  title = {The Problems of Facilitating Qualitative Formative Assessment in Pupils},
  author = {Radnor, Hilary A.},
  year = {1994},
  month = feb,
  journal = {British Journal of Educational Psychology},
  volume = {64},
  number = {1},
  pages = {145--160},
  issn = {00070998},
  doi = {10/fr2r66},
  urldate = {2020-11-01},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/49B9WSMW/radnorProblemsFacilitatingQualitative1994.pdf}
}

@article{raffaghelliCenteringComplexityEducators2020,
  title = {Centering Complexity in 'educators' Data Literacy' to Support Future Practices in Faculty Development: A Systematic Review of the Literature},
  author = {Raffaghelli, Juliana E. and Stewart, Bonnie},
  year = {2020},
  journal = {Teaching in Higher Education},
  volume = {25},
  number = {4},
  pages = {435--455},
  publisher = {Routledge},
  address = {Abingdon},
  issn = {1356-2517},
  doi = {10.1080/13562517.2019.1696301},
  abstract = {As algorithmic decision-making and data collection become pervasive in higher education, how can educators make sense of the systems that shape life and learning in the twenty-first century? This paper outlines a systematic literature review that investigated gaps in the current framing of data and faculty development, and explores how these gaps prevent the formulation of potential pathways and principles for fostering educators' data literacy. The analysis of 137 papers through classification by relevant categories and key word mapping shows that there is little attention on higher education teachers. It also makes clear that most approaches to educators' data literacy address management and technical abilities, with less emphasis on critical, ethical and personal approaches to datafication in education. The authors conceptualize this situation as a 'complicated' approach to data literacy in the academic profession, as opposed to a complex vision which would bundle management and technical skills together with a critical, systemic approach to professional learning and data.},
  keywords = {Classification,College Faculty,complexity,Data Analysis,Data literacy,Decision Making,educators,Epistemology,Ethics,Faculty Development,Higher Education,Literacy,Research Reports,Systematic review,Systems Approach,Teachers,Technological Literacy},
  file = {/Users/colin.madland/Zotero/storage/DGIWE4S8/raffaghelliCenteringComplexityEducators2020.pdf}
}

@article{raffaghelliCenteringComplexityEducators2020a,
  title = {Centering Complexity in `Educators' Data Literacy' to Support Future Practices in Faculty Development: A Systematic Review of the Literature},
  shorttitle = {Centering Complexity in `Educators' Data Literacy' to Support Future Practices in Faculty Development},
  author = {Raffaghelli, Juliana E. and Stewart, Bonnie},
  year = {2020},
  month = may,
  journal = {Teaching in Higher Education},
  volume = {25},
  number = {4},
  pages = {435--455},
  issn = {1356-2517, 1470-1294},
  doi = {10.1080/13562517.2019.1696301},
  urldate = {2024-02-09},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/3BELU6VQ/raffaghelliCenteringComplexityEducators2020a.pdf}
}

@article{rahayuOpenEducationalResources2018,
  title = {Open {{Educational Resources Based Online Tutorial Model}} for {{Developing Critical Thinking}} of {{Higher Distance Education Students}}},
  author = {Rahayu, Ucu and Sapriati, Amalia},
  year = {2018},
  journal = {Turkish Online Journal of Distance Education},
  volume = {19},
  number = {4},
  pages = {163--175},
  issn = {EISSN-1302-6488},
  abstract = {This paper aims to develop a prototype of learning for the achievement of critical thinking skills of Higher Distance Education students through the utilization of open educational resources (OER). It is based on a research and development project conducted from September 2013 until April 2014 at Universitas Terbuka (UT), the Indonesia Open University. The research consisted of three stages. The first stage developed the Tutorial Activity Plan (TAP) and the Tutorial Activity Unit (TAU). The second stage developed a prototype online tutorial model along with the initiation materials and tasks. The third stage was a trial implementation of online tutorials using OER. The Online tutorials were a course called Natural Resource Conservation and Environment (NRCE). Data on student learning outcomes on the completion of tasks and discussion activities were collected. Student learning outcomes were based on indicators of Enis's critical thinking skills. Student perceptions toward online tutorial activities were based on the students' assessment of the online tutorial implementation. Data were collected using a questionnaire, tests, document analysis forms, and interviews. The results indicated that critical thinking can be develop through the utilization online tutorial activities. The students utilized OER as reference source when they were engaging in online tutorial tasks and online discussions. Critical thinking skills of the students could be evaluated based on student learning outcomes, e.g. student discussions and answering questions while undertaking online tutorial tasks.},
  langid = {english},
  keywords = {College Students,Computer Mediated Communication,Critical Thinking,Discussion,Distance Education,Educational Resources,Foreign Countries,Natural Resources,No DOI found,Online Courses,Open Universities,Outcomes of Education,Student Attitudes,Task Analysis,Thinking Skills}
}

@article{rajagopalUnderstandingPersonalLearning2012a,
  title = {Understanding Personal Learning Networks: {{Their}} Structure, Content and the Networking Skills Needed to Optimally Use Them},
  shorttitle = {Understanding Personal Learning Networks},
  author = {Rajagopal, Kamakshi and {Joosten-ten Brinke}, Desir{\'e}e and Van Bruggen, Jan and Sloep, Peter B},
  year = {2012},
  month = jan,
  journal = {First Monday},
  volume = {17},
  number = {1},
  issn = {13960466},
  doi = {201202071132},
  urldate = {2022-02-28},
  keywords = {archived,attitude,Invalid DOI},
  annotation = {https://web.archive.org/web/20220120213350/https://journals.uic.edu/ojs/index.php/fm/article/view/3559},
  file = {/Users/colin.madland/Zotero/storage/98JMEPYY/rajagopalUnderstandingPersonalLearning2012.pdf}
}

@article{ramaprasadDefinitionFeedback1983,
  title = {On the Definition of Feedback},
  author = {Ramaprasad, Arkalgud},
  year = {1983},
  month = jan,
  journal = {Behavioral Science},
  volume = {28},
  number = {1},
  pages = {4--13},
  issn = {00057940, 10991743},
  doi = {10.1002/bs.3830280103},
  urldate = {2024-04-25},
  copyright = {http://doi.wiley.com/10.1002/tdm\_license\_1.1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/J5PYERHQ/ramaprasadDefinitionFeedback1983.pdf}
}

@article{ramdaniConstructionAcademicIntegrity2018,
  title = {Construction of Academic Integrity Scale},
  author = {Ramdani, Zulmi},
  year = {2018},
  month = mar,
  journal = {International Journal of Research Studies in Psychology},
  volume = {7},
  number = {1},
  issn = {2243-769X, 2243-7681},
  doi = {10.5861/ijrsp.2018.3003},
  urldate = {2024-11-05},
  file = {/Users/colin.madland/Zotero/storage/ramdaniConstructionAcademicIntegrity2018.pdf}
}

@phdthesis{ramrakhianiExploratoryFactorAnalysis2017,
  title = {An {{Exploratory Factor Analysis Examining Experiences}} and {{Perceptions}} of {{Campus Safety}} for {{International Students}}},
  author = {Ramrakhiani, Sonia H.},
  year = {2017},
  doi = {10.25777/3EXK-6V23},
  urldate = {2024-02-21},
  abstract = {Although international students make up a significant percentage of the college population and contribute to higher education institutions in multiple ways, a lack of attention is paid to their safety needs. This dissertation examined the experiences and perceptions of campus safety among international college/university students in the United States. The researcher sampled participants from different institutions around the country, who self-identified as international students. A researcher-developed 53-item Likert scale questionnaire, International Students' Safety Questionnaire (ISSQ), was administered to the sample. Findings from the exploratory factor analysis (EFA) provided evidence for the four-factor solution for the 26-item ISSQ accounting for 48.65\% of the shared variance. Additionally, the ISSQ was found to have adequate internal consistency, a Cronbach alpha of .85 for the overall instrument and subscale alphas ranging from .72 to .81. Salient demographic variables, such as nationality, faith belief, college status and perceived proficiency in English, were found to be significantly linked to derived factor scores. Further, significant positive correlations were found between personality variables, such as extraversion, openness, and neuroticism, and the derived factor scores. Implications for counseling, counselor education, and higher education institutions, along with limitations and directions for future research are included.},
  school = {Old Dominion University Libraries},
  file = {/Users/colin.madland/Zotero/storage/AYJ8FQHB/ramrakhianiExploratoryFactorAnalysis2017.pdf}
}

@book{ramsdenLearningTeachHigher1992,
  title = {Learning to Teach in Higher Education},
  author = {Ramsden, Paul},
  year = {1992},
  publisher = {Routledge},
  address = {London}
}

@book{ramsdenLearningTeachHigher2003,
  title = {Learning to {{Teach}} in {{Higher Education}}},
  author = {Ramsden, Paul},
  year = {2003},
  month = sep,
  publisher = {Routledge},
  doi = {10.4324/9780203507711},
  urldate = {2022-11-29},
  isbn = {978-1-134-41206-8},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/I4C2MNVC/ramsdenLearningTeachHigher2003.pdf}
}

@article{rangelExaminationPoetryPeople2016,
  title = {An {{Examination}} of {{Poetry}} for the {{People}}: {{A Decolonizing Holistic Approach}} to {{Arts Education}}},
  author = {Rangel, Nicole},
  year = {2016},
  journal = {Educational Studies},
  volume = {52},
  number = {6},
  pages = {536--551},
  issn = {0013-1946;0305-5698;},
  doi = {10.1080/00131946.2016.1231680},
  abstract = {This article is concerned with the epidemic of alienation created by colonization and the ideologies that maintain systems of domination. More specifically, it argues that a decolonizing holistic pedagogy can help address the root of our individual and collective alienation to facilitate healing. This position is supported by the findings of an ethnographic study, conducted in 2013-2014, highlighting Poetry for the People (P4P), an arts/activism course started by poet-activist-professor, June Jordan, at UC Berkeley. The article opens with a theoretical framework that centers healing and love as decolonial priorities and pedagogical imperatives, and speaks to the mindbodyspirit labor, restoration, and creativity involved in decolonizing education. Emphasizing the need for decolonizing epistemologies to inform classroom dialogue, this article points to the power inherent in those dialogues for creating connections that mend alienation and for generating apertures for personal and social transformation. However, it is the voices of the P4P participants interviewed that give testimony to the effectiveness of a decolonizing holistic pedagogy to foster rigorous investigation of self and society, authentic community-building across difference, as well as the healing power of writing, sharing, and witnessing others share personal/political poetry.},
  keywords = {Activism,Alienation,Art,Classroom Communication,College Faculty,Course Descriptions,Creativity,Dialogs (Language),EDUCATION & EDUCATIONAL RESEARCH,Educational Change,Epistemology,Foreign Policy,Higher Education,Holistic Approach,Instructional Effectiveness,Interviews,PEDAGOGY,Poetry,Poets,Political Attitudes,Self Concept,Social Change,Teacher Attitudes,Teaching Methods,Transformative Learning,Trauma,Young Adults}
}

@article{rapantaUseArgumentMaps2016,
  title = {The {{Use}} of {{Argument Maps}} as an {{Assessment Tool}} in {{Higher Education}}},
  author = {Rapanta, C and Walton, D},
  year = {2016},
  journal = {International Journal Of Educational Research},
  volume = {79},
  pages = {211--221},
  issn = {0883-0355},
  doi = {10.1016/j.ijer.2016.03.002},
  abstract = {The use of argument diagrams to foster argumentation has been an object of research in education, as a way to support students' argumentative interaction and, potentially, learning. In this paper it is shown how argument analysis and evaluation assisted by means of argument diagramming tools, further developed in artificial intelligence (AI), can also support the assessment of argumentation skills in the classroom. A case study is presented to show how informal logic contributions on fallacies, in particular, can be combined with the data of an argument-diagramming task, to form a method of assessing students' weaknesses in reasoning about everyday issues using argument maps. Our contribution is mainly methodological, as we suggest an application of AI and argumentation theories in education. (C) 2016 Elsevier Ltd. All rights reserved.},
  langid = {english},
  keywords = {ABILITY,Argument maps,Argumentation theory,Artificial intelligence,Assessment,COMPUTER,Diagramming tools,DIAGRAMS,DISCUSSIONS,Education,EXPLANATION,Fallacies,FALLACIES,REPRESENTATIONAL TOOLS,SCHOOL,SKILLS},
  file = {/Users/colin.madland/Zotero/storage/KD7JZ9K2/rapantaUseArgumentMaps2016.pdf}
}

@article{raposo-rivasUniversityStudentsPerceptions2016,
  title = {University {{Students}}' {{Perceptions}} of {{Electronic Rubric-Based Assessment}}},
  author = {{Raposo-Rivas}, Manuela and {Gallego-Arrufat}, Mar{\'i}a-Jes{\'u}s},
  year = {2016},
  month = dec,
  journal = {Digital Education Review},
  number = {30},
  pages = {220--233},
  publisher = {Digital Education Review},
  issn = {2013-9144},
  abstract = {Integrating technology into assessment processes in university contexts can change educational practices, in some cases by fostering self-regulated learning and in others by enabling more interactivity and participation among users. In this paper, we examine the opportunity to use electronic rubrics (erubrics) to assess learning. We report a student perception analysis on the process of assessment with electronic rubric at the university level. In this study, erubrics are applied in a Preschool (3-6 year-olds) and Primary Education (6-12 year-olds) pre-service teacher context. 87 students from two Spanish universities enrolled in a quarterly course of Education Technologies in the Faculty of Education used erubrics ({\copyright}Gtea) for self- and peer assessment. Through a satisfaction survey, the study concluded that electronic rubric is an assessment facilitating resource for students as participants in the assessment process. Students tend to be satisfied with their use in both self- and peer assessment and acknowledge certain advantages regarding rubric features, implementation process and impact on learning process.},
  keywords = {College Students,Educational Technology,Elementary Education,Foreign Countries,Formative Evaluation,Higher Education,Learning Processes,No DOI found,Peer Evaluation,Preschool Education,Preservice Teachers,Scoring Rubrics,Self Evaluation (Individuals),Spain,Student Attitudes,Student Surveys,Technology Integration}
}

@article{rasooliCriticalReviewFairness2024,
  title = {A {{Critical Review}} of {{Fairness}} from {{Multiple Perspectives}}: {{Implications}} for {{Classroom Assessment Theory}}},
  shorttitle = {A {{Critical Review}} of {{Fairness}} from {{Multiple Perspectives}}},
  author = {Rasooli, Amirhossein and DeLuca, Christopher},
  year = {2024},
  month = apr,
  journal = {Applied Measurement in Education},
  pages = {1--17},
  issn = {0895-7347, 1532-4818},
  doi = {10.1080/08957347.2024.2345594},
  urldate = {2024-04-25},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/EG33T9IL/rasooliCriticalReviewFairness2024.pdf}
}

@article{rasooliStudentsCriticalIncidents2019,
  title = {Students' Critical Incidents of Fairness in Classroom Assessment: An Empirical Study},
  author = {Rasooli, Amirhossein and DeLuca, Christopher and Rasegh, Abdollah and Fathi, Sajad},
  year = {2019},
  journal = {Social psychology of education},
  volume = {22},
  number = {3},
  pages = {701--722},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  issn = {1381-2890},
  doi = {10.1007/s11218-019-09491-9},
  abstract = {Conceptualizing fairness through social psychology theory has recently been called for in classroom assessment (CA) literature. This study used two open-ended questionnaires to explore university students' critical incidents of fairness and unfairness and their affective and behavioral reactions to experiences of un/fairness. The findings showed that students' perceptions of CA fairness were comprised of distributive, procedural, and interactional justice principles. Collectively, students considered the distribution of outcomes, the procedures for outcome distributions, the interpersonal relationships, and the communication procedures in conceptualizing fairness. Students also reported positive feelings such as happiness, satisfaction, feeling valued, and hopefulness when describing fair incidents, while they tended to report negative feelings such as anger, upset, disappointment, and embarrassment as responses to unfair incidents. Students also reported increased classroom engagement and greater adaptation in responses to fairness incidents, while they reported class disengagement, inaction, and dissent as responses to unfair incidents. Building on these empirical findings, a more comprehensive conceptualization of fairness in CA contexts is proposed.},
  keywords = {Analysis,Behavioral psychology,Classrooms,College Students,Critical Incidents Method,Education,Educational psychology,Interpersonal Communication,Interpersonal relations,Interpersonal Relationship,Justice,Learner Engagement,Personality and Social Psychology,Psychological Patterns,Psychology,Psychology Educational,Social psychology,Social Sciences,Sociology of Education,Student Attitudes,Student Behavior,Surveys,University students},
  file = {/Users/colin.madland/Zotero/storage/MAH42C6E/rasooliStudentsCriticalIncidents2019.pdf}
}

@book{rasTechnologyEnhancedAssessment2018,
  title = {Technology {{Enhanced Assessment}} 20th {{International Conference}}, {{TEA}} 2017, {{Barcelona}}, {{Spain}}, {{October}} 5--6, 2017, {{Revised Selected Papers}}},
  author = {Ras, {\relax Eric}. and Guerrero Rold{\'a}n, Ana Elena.},
  year = {2018},
  series = {Communications in {{Computer}} and {{Information Science}}, 829},
  edition = {1st ed. 2018.},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-97807-9},
  abstract = {Chapter "Student perception of scalable peer-feedback design in Massive Open Online Courses" is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/). For further details see license information in the chapter.},
  isbn = {3-319-97807-1},
  keywords = {Application software,Computer Appl. in Social and Behavioral Sciences,Computers and Education,Education-Data processing,Educational technology,Educational Technology,Information Systems Applications (incl. Internet),User interfaces (Computer systems),User Interfaces and Human Computer Interaction},
  file = {/Users/colin.madland/Zotero/storage/K8AUPXSL/rasTechnologyEnhancedAssessment2018.pdf}
}

@article{rawlusykAssessmentHigherEducation2018,
  title = {Assessment in {{Higher Education}} and {{Student Learning}}},
  author = {Rawlusyk, P. E.},
  year = {2018},
  journal = {Journal of Instructional Pedagogies},
  volume = {21},
  issn = {ISSN-2327-5324},
  abstract = {This research addressed ongoing academic concerns about whether assessment practices in higher education support student learning. Authors state that examinations have become the focus of assessment, which adversely affect learning. Effective assessment for learning promotes the active engagement of students. A web-based survey gathered information from a sample of postsecondary educators in Alberta. The questionnaire used the three criteria of learning-oriented assessment, tasks as learning tasks (authentic), self- and peer assessment, and feedback to determine learning potential. Findings illustrated that the implementation of only three of 15 authentic tasks occurred by over 30\% of educators. Results also found that teachers have conflicting views relative to student use of feedback and the use of dialogue. These outcomes show that there is limited involvement of learners in assessment strategies, which can impact learning. It is recommended that teachers utilize professional development to understand how to optimize the active participation of students in various authentic assessment methods and feedback. Future research using a qualitative design should be conducted to obtain reasons why assessment problems exist.},
  langid = {english},
  keywords = {Academic Achievement,College Faculty,Feedback (Response),Foreign Countries,Formative Evaluation,Higher Education,Learner Engagement,No DOI found,Peer Evaluation,Performance Based Assessment,Self Evaluation (Individuals),Summative Evaluation}
}

@article{rawlusykAssessmentHigherEducation2018a,
  title = {Assessment in {{Higher Education}} and {{Student Learning}}},
  author = {Rawlusyk, P. E.},
  year = {2018},
  journal = {Journal of Instructional Pedagogies},
  volume = {21},
  urldate = {2023-12-12},
  abstract = {This research addressed ongoing academic concerns about whether assessment practices in higher education support student learning. Authors state that examinations have become the focus of assessment, which adversely affect learning. Effective assessment for learning promotes the active engagement of students. A web-based survey gathered information from a sample of postsecondary educators in Alberta. The questionnaire used the three criteria of learning-oriented assessment, tasks as learning tasks (authentic), self- and peer assessment, and feedback to determine learning potential. Findings illustrated that the implementation of only three of 15 authentic tasks occurred by over 30\% of educators. Results also found that teachers have conflicting views relative to student use of feedback and the use of dialogue. These outcomes show that there is limited involvement of learners in assessment strategies, which can impact learning. It is recommended that teachers utilize professional development to understand how to optimize the active participation of students in various authentic assessment methods and feedback. Future research using a qualitative design should be conducted to obtain reasons why assessment problems exist.},
  file = {/Users/colin.madland/Zotero/storage/T69WE8VQ/EJ1194243.pdf}
}

@article{rayChatGPTComprehensiveReview2023,
  title = {{{ChatGPT}}: {{A}} Comprehensive Review on Background, Applications, Key Challenges, Bias, Ethics, Limitations and Future Scope},
  author = {Ray, Partha Pratim},
  year = {2023},
  month = jan,
  journal = {Internet of Things and Cyber-Physical Systems},
  volume = {3},
  pages = {121--154},
  issn = {2667-3452},
  doi = {10.1016/j.iotcps.2023.04.003},
  abstract = {In recent years, artificial intelligence (AI) and machine learning have been transforming the landscape of scientific research. Out of which, the chatbot technology has experienced tremendous advancements in recent years, especially with ChatGPT emerging as a notable AI language model. This comprehensive review delves into the background, applications, key challenges, and future directions of ChatGPT. We begin by exploring its origins, development, and underlying technology, before examining its wide-ranging applications across industries such as customer service, healthcare, and education. We also highlight the critical challenges that ChatGPT faces, including ethical concerns, data biases, and safety issues, while discussing potential mitigation strategies. Finally, we envision the future of ChatGPT by exploring areas of further research and development, focusing on its integration with other technologies, improved human-AI interaction, and addressing the digital divide. This review offers valuable insights for researchers, developers, and stakeholders interested in the ever-evolving landscape of AI-driven conversational agents. This study explores the various ways ChatGPT has been revolutionizing scientific research, spanning from data processing and hypothesis generation to collaboration and public outreach. Furthermore, the paper examines the potential challenges and ethical concerns surrounding the use of ChatGPT in research, while highlighting the importance of striking a balance between AI-assisted innovation and human expertise. The paper presents several ethical issues in existing computing domain and how ChatGPT can invoke challenges to such notion. This work also includes some biases and limitations of ChatGPT. It is worth to note that despite of several controversies and ethical concerns, ChatGPT has attracted remarkable attentions from academia, research, and industries in a very short span of time.},
  keywords = {ChatGPT,Context understanding,Conversational AI,Generative AI,GPT-3.5,Language model,Natural language processing},
  file = {/Users/colin.madland/Zotero/storage/UHX7L2NL/rayChatGPTComprehensiveReview2023.pdf}
}

@article{raymondCathedralBazaar1999,
  title = {The Cathedral and the Bazaar},
  author = {Raymond, Eric},
  year = {1999},
  month = sep,
  journal = {Knowledge, Technology \& Policy},
  volume = {12},
  number = {3},
  pages = {23--49},
  issn = {1874-6314},
  doi = {10.1007/s12130-999-1026-0},
  abstract = {I anatomize a successful open-source project, fetchmail, that was run as a deliberate test of some theories about software engineering suggested by the history of Linux. I discuss these theories in terms of two fundamentally different development styles, the "cathedral" model, representing most of the commercial world, versus the "bazaar" model of the Linux world. I show that these models derive from opposing assumptions about the nature of the software-debugging task. I then make a sustained argument from the Linux experience for the proposition that "Given enough eyeballs, all bugs are shallow," suggest productive analogies with other self-correcting systems of selfish agents, and conclude with some exploration of the implications of this insight for the future of software.},
  file = {/Users/colin.madland/Zotero/storage/JU3XEPZR/raymondCathedralBazaar1999.pdf}
}

@article{raynaultTeachingExperiencesEAuthentic2022,
  title = {Teaching {{Experiences}} of {{E-Authentic Assessment}}: {{Lessons Learned}} in {{Higher Education}}},
  shorttitle = {Teaching {{Experiences}} of {{E-Authentic Assessment}}},
  author = {Raynault, Audrey and Heilporn, G{\'e}raldine and Mascarenhas, Alice and Denis, Constance},
  year = {2022},
  month = dec,
  journal = {Journal of Teaching and Learning with Technology},
  volume = {11},
  number = {1},
  issn = {2165-2554},
  doi = {10.14434/jotlt.v11i1.34594},
  urldate = {2023-06-20},
  abstract = {The realities of the 21st century have led professors and lecturers to renew their learning assessment practices so that they are more adapted to and contextualized in the current professional world. Despite advances in teaching and learning, assessment methods may still deviate from practice in authentic contexts. Although some instructors are already familiar with more authentic assessments, most are accustomed to using exams as standard practices to test students' achievement of course objectives and essays to prepare students for research or written argumentation. Despite their benefits, such typical assessments often lack authenticity and do not develop the full potential of students' 21st-century learning or literacy skills such as communication, creativity, or working with technologies. Over the past decade, we have been witnessing the beginnings of a broader reflection on teaching, learning, and evaluating with technologies, including more authentic assessments. This reflective essay will present how technologies make it possible to diversify assessment methods, resulting in enhanced authenticity and development of 21st-century learning and literacy skills. Authentic assessment methods with technologies will be illustrated, e.g., recorded video presentations, explanatory interviews with descriptive assessment grids, PechaKucha presentations, blog posts, and social media and e-portfolios, with examples from several disciplines. Authors will also explain how proposing a number of methods to students for the same assessment may help answer their various needs and preferences without increasing instructors' grading load. Furthermore, authors will discuss how diversifying assessment methods with technologies often results in a transformation of assessment modalities. Beyond assessments as an evaluation of knowledge and/or skills at a fixed schedule, authentic assessments with technologies may become continuous or iterative processes with multiple feedbacks from instructors, thereby combining synchronous interactions and/or discussions with asynchronous reflections to improve students' involvement and active learning.},
  file = {/Users/colin.madland/Zotero/storage/SBTXSZ2S/raynaultTeachingExperiencesEAuthentic2022.pdf}
}

@incollection{raziOpenAnonymousPeer2016,
  title = {Open and Anonymous Peer Review in a Digital Online Environment Compared in Academic Writing Context},
  booktitle = {Innovative Language Teaching and Learning at University: Enhancing Participation and Collaboration},
  author = {Raz{\i}, Salim},
  editor = {Goria, Cecilia and Speicher, Oranna and Stollhans, Sascha},
  year = {2016},
  month = jan,
  pages = {49--56},
  publisher = {Research-publishing.net},
  doi = {10.14705/rpnet.2016.000404},
  urldate = {2023-06-20},
  abstract = {This study compares the impact of `open' and `anonymous' peer feedback as an adjunct to teacher-mediated feedback in a digital online environment utilising data gathered on an academic writing course at a Turkish university. Students were divided into two groups with similar writing proficiencies. Students peer reviewed papers either anonymously or openly, then resubmitted them. The lecturer provided feedback and students again resubmitted their assignments. Finally, students submitted a reflection paper on how or whether they benefited from both peer and teacher-mediated feedback. Findings provide evidence for the positive contribution of multiple anonymous peer feedback in a digital online environment towards improved academic writing skills.},
  isbn = {978-1-908416-32-2},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/WPB3DUIW/Raz - 2016 - Open and anonymous peer review in a digital online.pdf}
}

@manual{rcoreteamLanguageEnvironmentStatistical2020,
  type = {Manual},
  title = {R: {{A}} Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  year = {2020},
  address = {Vienna, Austria},
  organization = {R Foundation for Statistical Computing}
}

@manual{rcoreteamLanguageEnvironmentStatistical2023,
  type = {Manual},
  title = {R: {{A}} Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  year = {2023},
  address = {Vienna, Austria},
  institution = {R Foundation for Statistical Computing}
}

@incollection{reasonIntroductionInquiryParticipation2001,
  title = {Introduction: {{Inquiry}} and {{Participation}} in {{Search}} of a {{World Worthy}} of {{Human Aspiration}}},
  booktitle = {Handbook of Action Research: Participative Inquiry and Practice},
  author = {Reason, Peter and Bradbury, Hilary},
  year = {2001},
  publisher = {SAGE},
  address = {London ; Thousand Oaks, Calif},
  isbn = {978-0-7619-6645-6},
  lccn = {HM571 .H36 2001},
  keywords = {Action research,Handbooks manuals etc,Participant observation},
  annotation = {OCLC: ocm44015575},
  file = {/Users/colin.madland/Zotero/storage/KEEBI2TW/reasonIntroductionInquiryParticipation2001.pdf}
}

@misc{ReconciliationIndigenousEducation2018,
  title = {Reconciliation {{Through Indigenous Education}}},
  year = {2018},
  month = jul,
  journal = {edX},
  urldate = {2018-11-30},
  abstract = {Advancing reconciliation in classrooms, organizations, and communities through the teaching and learning of Indigenous ways of knowing.},
  howpublished = {https://www.edx.org/course/reconciliation-through-indigenous-education-0},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/NBGST3LD/reconciliation-through-indigenous-education-0.html}
}

@article{reddyReviewRubricUse2010,
  title = {A Review of Rubric Use in Higher Education},
  author = {Reddy, Y. Malini and Andrade, Heidi},
  year = {2010},
  month = jul,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {35},
  number = {4},
  pages = {435--448},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602930902862859},
  urldate = {2024-04-19},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/AXMF8P8R/reddyReviewRubricUse2010.pdf}
}

@article{redmondOnlineEngagementFramework2018,
  title = {An {{Online Engagement Framework}} for {{Higher Education}}},
  author = {Redmond, Petrea and Abawi, Lindy-Anne and Brown, Alice and Henderson, Robyn and Heffernan, Amanda},
  year = {2018},
  journal = {Online Learning},
  volume = {22},
  number = {1},
  pages = {183--204},
  issn = {ISSN-2472-5749},
  abstract = {Student engagement is understood to be an important benchmark and indicator of the quality of the student experience for higher education; yet the term "engagement" continues to be elusive to define and it is interpreted in different ways in the literature. This paper firstly presents a short review of the literature regarding online engagement in the higher education environment, moving beyond discipline-specific engagement. It then presents a conceptual framework which builds upon recurring themes within the literature, including students' beliefs, attitudes, and behaviors. The framework was developed by adopting a constant comparison method to analyse the literature, and to search for and identify current and emerging themes. The framework identifies indicators for five key elements of online engagement, and the authors propose that the framework provides a guide for researchers and academics when exploring online engagement from a conceptual, practical and research basis. Finally, the paper provides recommendations for practice, outlining how the framework might be used to reflect critically upon the effectiveness of online courses and their ability to engage students.},
  langid = {english},
  keywords = {Beliefs,Comparative Analysis,Cooperation,Distance Education,Educational Technology,Guides,Higher Education,Learner Engagement,Literature Reviews,No DOI found,Online Courses,Student Attitudes,Student Behavior,Student Participation,Technology Uses in Education}
}

@article{reedyRespondingCOVID19Emergency2021,
  title = {Responding to the {{COVID-19 Emergency}}: {{Student}} and {{Academic Staff Perceptions}} of {{Academic Integrity}} in the {{Transition}} to {{Online Exams}} at {{Three Australian Universities}}},
  author = {Reedy, Alison and Pfitzner, Darius and Rook, Laura and Ellis, Leonie},
  year = {2021},
  month = jan,
  journal = {International Journal for Educational Integrity},
  volume = {17},
  publisher = {International Journal for Educational Integrity},
  issn = {1833-2595},
  abstract = {This paper explores the perceptions of academic staff and students to student cheating behaviours in online exams and other online assessment formats. The research took place at three Australian universities in July and August 2020 during the emergency transition to online learning and assessment in response to the COVID-19 pandemic. The study sought to inform decision making about the future of online exams at the participating universities. Quantitative and qualitative data were collected using online surveys. The findings of the study led to seven key observations, most notably the need to redefine the characteristics of academic misconduct to account for changes wrought to examinations in a digital world. The study concludes with lessons learned in relation to enhancing academic integrity in digital examinations and assessments.},
  keywords = {Australia,Cheating,College Faculty,College Students,Computer Assisted Testing,COVID-19,Distance Education,Emergency Programs,Foreign Countries,No DOI found,Pandemics,Student Attitudes,Teacher Attitudes}
}

@article{reevesAlternativeAssessmentApproaches2000,
  title = {Alternative {{Assessment Approaches}} for {{Online Learning Environments}} in {{Higher Education}}},
  author = {Reeves, Thomas C.},
  year = {2000},
  month = jul,
  journal = {Journal of Educational Computing Research},
  volume = {23},
  number = {1},
  pages = {101--111},
  publisher = {SAGE Publications Inc},
  issn = {0735-6331},
  doi = {10/fn39q4},
  urldate = {2021-07-05},
  abstract = {This article describes the need and prospects for alternative assessment approaches in online learning environments within the context of higher education. Assessment in higher education has traditionally focused on retention of knowledge and its application in limited contexts as measured by paper and pencil tests and academic assignments such as writing term papers. Increased interest among academics in what has been labeled ?alternative assessment? reflects both dissatisfaction with national approaches to assessment and the desire to assess the attainment of higher order educational goals that involve deep understanding and active use of knowledge in complex, realistic contexts. Concerns about current assessment approaches are increasing as online learning environments become more prevalent in higher education. The article prescribes three different approaches to integrating alternative assessment approaches into online learning environments: 1) cognitive assessment, 2) performance assessment, and 3) portfolio assessment.},
  file = {/Users/colin.madland/Zotero/storage/LKB87JER/reevesAlternativeAssessmentApproaches2000.pdf}
}

@article{reganEthicalChallengesEdtech2019,
  title = {Ethical Challenges of Edtech, Big Data and Personalized Learning: Twenty-First Century Student Sorting and Tracking},
  shorttitle = {Ethical Challenges of Edtech, Big Data and Personalized Learning},
  author = {Regan, Priscilla M. and Jesse, Jolene},
  year = {2019},
  journal = {Ethics and Information Technology},
  volume = {21},
  number = {3},
  pages = {167--179},
  issn = {1388-1957, 1572-8439},
  doi = {10/gg3d2t},
  urldate = {2020-06-27},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/JCZCFNU8/reganEthicalChallengesEdtech2019.pdf}
}

@article{rehanahmedkhanShortCommunicationTechnology2020,
  title = {Short {{Communication}} - {{Technology Enhanced Assessment}} ({{TEA}}) in {{COVID}} 19 {{Pandemic}}},
  author = {{Rehan Ahmed Khan} and {Masood Jawaid}},
  year = {2020},
  journal = {Pakistan journal of medical sciences},
  volume = {36},
  number = {S4},
  pages = {S108},
  publisher = {Knowledge Bylanes},
  address = {Karachi},
  issn = {1682-024X},
  abstract = {ABSTRACT Online teaching and learning is not a new phenomenon. For the last many years, it has been mainly used as a part of face to face teaching. Assessment is an essential part of teaching and learning, as it establishes the achievement of course learning outcomes by the students. Computer-based assessment is in place for a long time now, however, online assessments have been less practiced. This is because of the issues of validity, reliability and dishonesty. During the COVID 19 pandemic, the educational environment has taken a paradigm shift in many medical schools, both nationally and internationally. This situation demands a method of assessment that is safe, valid, reliable, acceptable, feasible and fair. This paper describes the different formats of online assessment and their application in formative and summative assessments during and after the COVID 19 pandemic.},
  keywords = {Cheating,Critical thinking,Epidemics,Feedback,Internet,Learning management systems,Medical colleges,Medical education,Methods,Online instruction,Pandemics,Skills,Students,Teaching},
  file = {/Users/colin.madland/Zotero/storage/298GYCYP/Short_Communication_Technology__Pakistan_Journal_of_Medical_Sciences_Karachi_Pakistan___May_31_2020.pdf}
}

@book{reigeluthInstructionalDesignTheoriesModels1999,
  title = {Instructional-{{Design Theories}} and {{Models}}},
  author = {Reigeluth, Charles M},
  year = {1999},
  volume = {2},
  publisher = {Lawrence Erlbaum Associates},
  address = {Mahwah, NJ}
}

@article{reiseItemResponseTheory2005,
  title = {Item {{Response Theory}}: {{Fundamentals}}, {{Applications}}, and {{Promise}} in {{Psychological Research}}},
  shorttitle = {Item {{Response Theory}}},
  author = {Reise, Steven P. and Ainsworth, Andrew T. and Haviland, Mark G.},
  year = {2005},
  month = apr,
  journal = {Current Directions in Psychological Science},
  volume = {14},
  number = {2},
  pages = {95--101},
  issn = {0963-7214, 1467-8721},
  doi = {10/cph54h},
  urldate = {2020-10-22},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/QBVAKKWV/reiseItemResponseTheory2005.pdf}
}

@article{rejuComparativeInvestigationAssessment2020,
  title = {A {{Comparative Investigation}} of {{Assessment Practices}} in {{Distance}} and {{Online Learning Undergraduate Mathematics}} in {{Nigeria}}},
  author = {Reju, Comfort O. and Jita, Loyiso C.},
  year = {2020},
  journal = {Journal of Educational Research and Practice},
  volume = {10},
  number = {1},
  pages = {90--103},
  issn = {EISSN-2167-8693},
  doi = {10/gmbv2b},
  abstract = {We investigate and compare assessment practices in two (dual- and single-mode) institutions in Nigeria. A mixed-methods approach was employed. Descriptive statistics and narration were carried out for the purpose of determining what the assessment practices were and how they may be related to the students learning of undergraduate mathematics in distance and online education. Results show that there are similarities and variations in assessment practices that shaped open and distance learning practices in these universities. This suggests a need for careful review of assessment practices aimed at improving students' engagement and learning for outstanding undergraduate mathematics learning experiences.},
  langid = {english},
  keywords = {Barriers,College Mathematics,Computer Assisted Testing,Distance Education,Educational Technology,Evaluation Methods,Foreign Countries,Mathematics Instruction,Online Courses,Preferences,Student Attitudes,Student Evaluation,Technology Uses in Education,Undergraduate Students}
}

@book{rencklyAirUniversitySampling2002,
  title = {Air {{University Sampling}} and {{Surveying Handbook}}},
  author = {Renckly, Thomas R},
  year = {2002},
  publisher = {United States of America Department of Defense},
  langid = {english},
  keywords = {No DOI found,survey design},
  annotation = {ZSCC: 0000008},
  file = {/Users/colin.madland/Zotero/storage/PCV5QKRU/rencklyAirUniversitySampling2002.pdf}
}

@article{rensaaAssessmentConsiderationsLockdown2023,
  title = {Assessment Considerations during Lockdown in {{Norway}}: {{An}} Exploratory Case Study with Focus on Misconducts in University Mathematics},
  author = {Rensaa, Ragnhild Johanne},
  year = {2023},
  journal = {Cogent education},
  volume = {10},
  number = {1},
  publisher = {Cogent},
  address = {Abingdon},
  issn = {2331-186X},
  doi = {10.1080/2331186X.2023.2210456},
  abstract = {The present paper raises a discussion about assessment formats in mathematics courses at Norwegian universities during the Covid lockdown. This proved to be challenging since the European GDPR regulations are strictly interpreted in Norway, making proctoring at home difficult. Based on analyses of nine university teachers' feedback on how exams were carried out at their university during lockdown, a discussion is raised about assessment modes and misconducts. The result shows how a framework from another research field can be adjusted to analyze data about the assessment situations. Next, by utilizing the different components (themes) of the adjusted framework, we shed light on perspectives on misconducts in un-proctored home exams. In doing so, the paper informs the discussion on challenges related to assessing students in mathematics at home. Results are relevant for future educational settings since change in the demographic profile of students increase topicality of online assessment.},
  keywords = {Academic misconduct,assessment,COVID-19,Distance learning,Educational evaluation,Higher education,mathematics,Mathematics education,misconducts,Online instruction,perspectives,Un-proctored exams},
  file = {/Users/colin.madland/Zotero/storage/97GJJSWQ/rensaaAssessmentConsiderationsLockdown2023.pdf}
}

@incollection{renStealthAssessmentEmbedded2019,
  title = {Stealth {{Assessment Embedded}} in {{Game-Based Learning}} to {{Measure Soft Skills}}: {{A Critical Review}}},
  booktitle = {Game-{{Based Assessment Revisited}}},
  author = {Ren, Xinyue},
  editor = {Ifenthaler, Dirk and Kim, Yoon Jeon},
  year = {2019},
  pages = {67--83},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-15569-8_4},
  abstract = {The chapter aims to discuss how to embed stealth assessment in game-based learning (GBL) to empower learners from theoretical and practical perspectives. Numerous studies indicate that well-designed digital games integrated in learning settings can perform both entertainment and educational purposes. Many educators have adopted digital games for building active and engaging learning environments to enhance students' learning outcomes. However, game-based assessment (GBA) is underdeveloped in the field of knowledge assessment. Among different types of game-based assessments, stealth assessment can be effectively used to reduce students' test anxiety and to overcome the limitations of traditional standardized and high-stake tests. However, limited research has focused on how to effectively design and implement stealth assessment to evaluate the soft skills which are valued in the twenty-first century, such as problem-solving, creativity, and teamwork. Through investigating previous studies, the chapter will examine the theoretical and pragmatic bases of stealth assessment design and the effective practices of stealth assessment implementation and interpretation. The critical analysis addressed in the chapter will contribute to the knowledge in the field of stealth assessment on soft skills measurement. Finally, recommendations and implications will be discussed to improve the development of GBA.},
  isbn = {978-3-030-15569-8},
  file = {/Users/colin.madland/Zotero/storage/3LIXT6BC/renStealthAssessmentEmbedded2019.pdf}
}

@misc{ReportPresident2000,
  title = {Report of the {{President}} 2000--01},
  urldate = {2019-07-10},
  howpublished = {https://web.mit.edu/president/communications/rpt00-01.html}
}

@misc{ResearchPropoalSample,
  title = {Research Propoal Sample Methods},
  author = {, Roger},
  urldate = {2023-03-11},
  file = {/Users/colin.madland/Zotero/storage/32TI492N/quantproposal.pdf}
}

@misc{ResourcesNCME,
  title = {Resources - {{NCME}}},
  urldate = {2021-04-28},
  howpublished = {https://www.ncme.org/resources/database},
  langid = {english},
  keywords = {software},
  file = {/Users/colin.madland/Zotero/storage/EUC9QJCV/database.html}
}

@article{restouleAboriginalIdentityNeed2000,
  title = {Aboriginal Identity: {{The}} Need for Historical and Contextual Perspectives},
  author = {Restoule, Jean-Paul},
  year = {2000},
  journal = {Canadian Journal of Native Education},
  volume = {24},
  number = {2},
  pages = {102--112}
}

@misc{restouleFiveIndigenousResearch2008,
  title = {The Five {{R}}'s of {{Indigenous}} Research: {{Relationship}}, Respect, Relevance, Responsibility, and Reciprocity},
  author = {Restoule, Jean-Paul},
  year = {2008},
  month = nov,
  address = {Toronto, ON, Canada}
}

@book{restouleIndigenousResearchTheories2018,
  title = {Indigenous Research: Theories, Practices, and Relationships},
  editor = {Restoule, Jean-Paul and McGregor, Deborah and Johnston, Rochelle},
  year = {2018},
  publisher = {Canadian Scholars},
  address = {Toronto ; Vancouver},
  abstract = {"Scholars understand what Indigenous research is, but how we practice Indigenous research ethically and respectfully in Canada is under exploration. This ground-breaking edited collection provides readers with concrete and in-depth examples of how to overcome the challenges of Indigenous research with respect to Indigenous worldviews, epistemologies, and ontology. In collaboration with their communities, and with guidance from Elders and other traditional knowledge keepers, each contributor links their personal narrative of Indigenous research to current discussions and debates. Accessible in nature, this interdisciplinary research tool is an essential read for all students and scholars in Indigenous Studies, as well as in the education, anthropology, sociology, and history research methodology classroom."--},
  isbn = {978-1-77338-085-8 1-77338-085-0},
  lccn = {E76.7 .I53 2018},
  keywords = {Canada,Indigenous peoples,Methodology,Research,Research Methodology},
  annotation = {OCLC: 1050770238}
}

@incollection{restouleWhereIndigenousKnowledge2017,
  title = {Where {{Indigenous Knowledge Lives}}: {{Bringing Indigenous Perspectives}} to {{Online Learning Environments}}},
  booktitle = {Handbook of {{Indigenous Education}}},
  author = {Restoule, Jean-Paul},
  editor = {McKinley, Elizabeth Ann and Smith, Linda Tuhiwai},
  year = {2017},
  pages = {1--23},
  publisher = {Springer Singapore},
  address = {Singapore},
  doi = {10.1007/978-981-10-1839-8_62-1},
  abstract = {This chapter will highlight some of the challenges and opportunities specific to bringing Indigenous knowledge and perspectives to online learning environments. Drawing on two recent Indigenous education case studies -- the author's experience developing a massive open online course (MOOC) on Indigenous worldviews and codesigning an online course for principals working in First Nations schools across Canada -- this chapter will discuss the opportunities and challenges of designing online learning experiences that invite all learners to engage with Indigenous knowledges, worldviews, and pedagogies in culturally appropriate, respectful, and meaningful ways. This research is based on a decolonizing theoretical framework using a critical pedagogical and relational approach to processes of knowledge production, informed by Indigenous research methodologies and epistemological frameworks. Applying an Indigenous ethics derived from Indigenous knowledge protocols in both the course design and the subsequent analysis of data drawn from evaluations of the course, the chapter argues that indigenizing online learning spaces is possible but also fraught with the same challenges of any learning space not of our own making.},
  isbn = {978-981-10-1839-8},
  file = {/Users/colin.madland/Zotero/storage/LGFJ8QSY/restouleWhereIndigenousKnowledge2017.pdf}
}

@article{retnawatiSystematicReviewUse2024,
  title = {A {{Systematic Review}} of the {{Use}} of {{Technology}} in {{Educational Assessment Practices}}: {{Lesson Learned}} and {{Direction}} for {{Future Studies}}},
  shorttitle = {A {{Systematic Review}} of the {{Use}} of {{Technology}} in {{Educational Assessment Practices}}},
  author = {Retnawati, Heri and Kardanova, Elena and Sumaryanto, Sumaryanto and Prasojo, Lantip Diat and Jailani, Jailani and Arliani, Elly and Hidayati, Kana and Susanti, Mathilda and Lestari, Himmawati Puji and Apino, Ezi and Rafi, Ibnu and Rosyada, Munaya Nikma and Tuanaya, Rugaya and Dewanti, Septinda Rima and Sotlikova, Rimajon and Kassymova, Gulzhaina Kuralbayevna},
  year = {2024},
  month = oct,
  journal = {International Journal of Robotics and Control Systems},
  volume = {4},
  number = {4},
  pages = {1656--1693},
  issn = {2775-2658},
  doi = {10.31763/ijrcs.v4i4.1572},
  urldate = {2025-02-11},
  abstract = {Previous studies have demonstrated that technology helps achieve learning outcomes. However, many studies focus on just one aspect of technology's role in educational assessment practices, leaving a gap in studies that examine how various aspects affect the use of technology in assessments. Hence, through a systematic work, we analyzed the extent and manner in which technology is integrated into educational assessments and how education level, domain of learning, and region may affect the use of technology. We reviewed empirical studies from two major databases (i.e., Scopus and ERIC) and a national journal whose focus and scope are on educational measurement and assessment, following PRISMA guidelines for systematic reviews. The findings of the present study are directed towards emphasizing the roles of technology in educational assessment practices and how these roles are adapted to varying educational contexts such as the level of education, the three domains of learning (i.e., cognitive, psychomotor, and affective), and the setting in which the assessment was conducted. These findings not only highlight the current roles of technology in educational assessment but also provide a roadmap for future research aimed at optimizing the integration of technology across diverse educational contexts.},
  copyright = {https://creativecommons.org/licenses/by-sa/4.0},
  file = {/Users/colin.madland/Zotero/storage/retnawatiSystematicReviewUse2024_1.pdf}
}

@article{reyeslopezAnalyzingGitHubCollaborative2017,
  title = {Analyzing {{GitHub}} as a {{Collaborative Software Development Platform}}: {{A Systematic Review}}},
  shorttitle = {Analyzing {{GitHub}} as a {{Collaborative Software Development Platform}}},
  author = {Reyes L{\'o}pez, Arturo},
  year = {2017},
  urldate = {2022-10-02},
  abstract = {GitHub is a popular social coding site where developers not only host their code  and use git functions, but also use social features to communicate, collaborate, and  be aware of changes and others' activities. This new paradigm to code together, and  the availability of data have given rise to much research studying collaboration from  different angles. However, the vast accumulated knowledge about GitHub tends to  be scattered and fragmented.  The goal of this study is to collect the available research on GitHub that is focused  on identifying the impact of GitHub in software development. The design of the  study includes two sections. First, a systematic search in 7 electronic digital libraries  was conducted using a de fined search protocol, which included a keyword string and  exclusion/inclusion criteria. Second, the extraction of data from each publication and  manual coding was conducted to defi ne categories of knowledge based on research  questions and fi ndings.  The study results show a growing trend in research with an increase in mixed  methodology. The preferred data sources for empirical studies about GitHub are the  GitHub API and GHTorrent in 72.57\% of publications. The study reveals that a group  made of 30 researchers publish 45.86\% of total research. The research in NorthAmerica  represents 26\% of publications. The research on GitHub is focused on the evaluation  of pull requests and use of issues(30.77\%), popular projects characteristics  (20.88\%), collaboration and transparency (15.38\%), developers' roles (9.89\%), influence  of popular developers (8.79\%), quick-start package with guidelines and datasets  (8.79\%), tools to improve contributions and collaboration (4.40\%) and other (1.1\%).},
  copyright = {Available to the World Wide Web},
  langid = {english},
  keywords = {No DOI found},
  annotation = {Accepted: 2017-04-24T19:17:26Z},
  file = {/Users/colin.madland/Zotero/storage/YR8VQ3TQ/reyeslopezAnalyzingGitHubCollaborative2017.pdf;/Users/colin.madland/Zotero/storage/SL3A5BF4/7953.html}
}

@article{reynaCoCreationKnowledgeUsing2020,
  title = {Co-{{Creation}} of {{Knowledge Using Mobile Technologies}} and {{Digital Media}} as {{Pedagogical Devices}} in {{Undergraduate STEM Education}}},
  author = {Reyna, Jorge and Meier, Peter},
  year = {2020},
  month = jan,
  journal = {Research in Learning Technology},
  volume = {28},
  publisher = {Research in Learning Technology},
  issn = {2156-7069},
  abstract = {Digital media assignments are a widely used method of assessing student learning in higher education. Despite their common use, the literature on digital media assignments has many gaps regarding theoretical frameworks to guide their design, implementation and evaluation. This research paper focuses on student attitudes towards the use of mobile technology and digital media assignments in undergraduate STEM education. The study used a set of novel theoretical frameworks to identify training needs in digital media production, development of assessment weightings, marking rubrics and student training and resources. Longitudinal data were captured over a period of 4 years (n = 1724) using a mixed-methods approach. Validated questionnaires measured student attitudes to digital media support and attitudes to technology, understanding of the assignment, knowledge construction and digital media for learning and career development. Open-ended questions helped gather suggestions from students for improving the assessment task. Questionnaire data were analysed by using descriptive statistics and qualitative data with thematic analysis. The results suggested that students enjoyed group work, found learning with digital media to be engaging and developed critical thinking and digital media skills. In conclusion, STEM students had a positive learning experience repurposing mobile technology as pedagogical devices that present knowledge by using a multi-modal approach mediated by digital media.},
  keywords = {Assignments,Australia,Career Development,Critical Thinking,Educational Technology,Foreign Countries,Group Activities,Handheld Devices,Job Skills,Knowledge Level,Multimedia Materials,No DOI found,STEM Education,Student Attitudes,Teaching Methods,Technological Literacy,Technology Uses in Education,Telecommunications,Undergraduate Students}
}

@article{reynaDigitalMediaAssignments2021,
  title = {Digital {{Media Assignments}} in {{Undergraduate Science Education}}: {{An Evidence-Based Approach}}},
  author = {Reyna, Jorge},
  year = {2021},
  month = jan,
  journal = {Research in Learning Technology},
  volume = {29},
  publisher = {Research in Learning Technology},
  issn = {2156-7069},
  abstract = {Digital media assignments empower students to become co-creators of knowledge rather than passive consumers of content. The Internet explosion and the affordability of digital technologies and devices such as smartphones, tablets and action cameras have created opportunities to use digital media in the classroom. This article aims to present an evidence-based approach to help educators to design, implement and evaluate digital media assignments in the classroom. For this purpose, four theoretical models were tested to inform the design of digital media assignments in undergraduate science education. These models helped to identify the student training in digital media needed, develop effective marking rubrics, and inform the design, implementation and evaluation of digital media assessment tasks. Trials were conducted in Spring 2016 (n = 458) and Autumn 2017 (n = 1329), respectively. Data collection used a mixed-methods approach, including a qualitative survey, open-ended questions, group contribution data and marks attained. Data analysis showed positive outcomes of the systematic implementation of digital media assignments. In conclusion, students enjoyed the support they received, being creative, working in groups and learning with digital media. To date, this intervention is one of the most comprehensive and practical approaches to digital media assignments in the classroom, which has been undertaken.},
  keywords = {Assignments,Australia,College Science,Educational Technology,Foreign Countries,Group Activities,Intervention,No DOI found,Program Development,Program Effectiveness,Science Education,Student Attitudes,Technological Literacy,Technology Integration,Technology Uses in Education,Undergraduate Students}
}

@article{reynaLearnerGeneratedDigitalMedia2018,
  title = {Learner-{{Generated Digital Media}} ({{LGDM}}) as an {{Assessment Tool}} in {{Tertiary Science Education}}: {{A Review}} of {{Literature}}},
  author = {Reyna, Jorge and Meier, Peter},
  year = {2018},
  month = dec,
  journal = {IAFOR Journal of Education},
  volume = {6},
  number = {3},
  pages = {93--109},
  publisher = {IAFOR Journal of Education},
  issn = {2187-0594},
  doi = {10.22492/ije.6.3.06},
  abstract = {Learner-Generated Digital Media (LGDM) in tertiary science education focuses on research skills, inquiry, active learning, teamwork, and collaboration. LGDM across disciplines is under-theorised, under-researched, and only in its early development. This paper evaluates the research in the field of LGDM in tertiary science education. The literature review had four stages -- identification, screening, filtering, and selection of relevant scholarly research. Results showed that research in the field of LGDM assignments had been done without a systematic approach to designing, implementing, and evaluating the assessment task. Most studies neglected student digital media training and are characterised by a lack of compelling marking rubrics or strategies to ensure efficient groupwork. Studies also lack rigorous methodologies for data capture to evaluate the intervention and they use small sample size cohorts and different digital media types that require different sets of production skills. With the empirical data available, validation of the benefits of LGDM assignments in science education is not possible, and studies have limited scalability. These gaps in the literature create a need to develop theoretical models for the design, implementation, and evaluation of LGDM in the classroom. This paper discusses future research needs in this field and the implications for assessment design.},
  keywords = {Animation,Assignments,Audio Equipment,College Science,College Students,Computer Software,Educational Technology,Handheld Devices,Information Dissemination,Program Effectiveness,Science Instruction,Story Telling,Technology Uses in Education,Video Technology},
  file = {/Users/colin.madland/Zotero/storage/RLKYM3CZ/reynaLearnerGeneratedDigitalMedia2018.pdf}
}

@article{reynaSystematicApproachDesigning2021,
  title = {A {{Systematic Approach}} to {{Designing}}, {{Implementing}}, and {{Evaluating Learner-Generated Digital Media}} ({{LGDM}}) {{Assignments}} and {{Its Effect}} on {{Self-regulation}} in {{Tertiary Science Education}}},
  author = {Reyna, Jorge and Hanham, Jose and Vlachopoulos, Panos and Meier, Peter},
  year = {2021},
  journal = {Research in Science Education},
  volume = {51},
  number = {6},
  pages = {1501--1527},
  issn = {0157-244X, 1573-1898},
  doi = {10.1007/s11165-019-09885-x},
  urldate = {2022-10-31},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/4CWDCBL4/reynaSystematicApproachDesigning2021.pdf}
}

@article{reynaUsingLearnerGeneratedDigital2018,
  title = {Using the {{Learner-Generated Digital Media}} ({{LGDM}}) {{Framework}} in {{Tertiary Science Education}}: {{A Pilot Study}}},
  author = {Reyna, J and Meier, P},
  year = {2018},
  journal = {Education Sciences},
  volume = {8},
  number = {3},
  issn = {2227-7102},
  doi = {10.3390/educsci8030106},
  abstract = {Learner-Generated Digital Media (LGDM) has become prevalent in higher education. Frameworks have been developed for video-making in the classroom that consider technical requirements, pedagogies, and the combination of both. However, missing is a practical model to guide academics and students on the implementation of LGDM assignments. This research aims to test a model to design, implement, and evaluate LGDM as an assessment tool. The model was built based on research gaps and it considers the following elements: (1) pedagogy, (2) student training, (3) hosting of videos, (4) marking schemes, (5) group contribution, (6) feedback, (7) reflection, and (8) evaluation. For this purpose, five science subjects (N = 270) were used to test the model as a guide to implementing LGDM assignments. Data was gathered using a validated 33-step questionnaire instrument. Additionally, group contributions were received using the SPARKPlus peer review application, and marks attained were gathered. Methodological triangulation of the datasets suggested that students have a positive attitude toward LGDM for science learning. Students enjoyed the group work and creativity, and they identified digital media support as a critical component of their learning experience. Preliminary data support using the LGDM framework to design digital media assignments for science education.},
  langid = {english},
  keywords = {blended media,COMPUTER,digital media,digital media as an assessment tool,digital media literacies,KNOWLEDGE,Learner-generated digital media,MULTIMEDIA,PEER ASSESSMENT,SELF-EFFICACY,SLOWMATION,STUDENTS,TOOL,VIDEO,video as an assessment tool},
  file = {/Users/colin.madland/Zotero/storage/BXLL32AV/reynaUsingLearnerGeneratedDigital2018.pdf}
}

@article{rhemtullaWorseMeasurementError2020,
  title = {Worse than Measurement Error: {{Consequences}} of Inappropriate Latent Variable Measurement Models.},
  shorttitle = {Worse than Measurement Error},
  author = {Rhemtulla, Mijke and Van Bork, Riet and Borsboom, Denny},
  year = {2020},
  month = feb,
  journal = {Psychological Methods},
  volume = {25},
  number = {1},
  pages = {30--45},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000220},
  urldate = {2024-07-25},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/3FC2ZLEC/rhemtullaWorseMeasurementError2020.pdf}
}

@article{riantoBlendedLearningApplication2020,
  title = {Blended {{Learning Application}} in {{Higher Education}}: {{EFL Learners}}' {{Perceptions}}, {{Problems}}, and {{Suggestions}}},
  author = {Rianto, Agus},
  year = {2020},
  journal = {Indonesian Journal of English Language Teaching and Applied Linguistics},
  volume = {5},
  number = {1},
  pages = {55--68},
  issn = {ISSN-2527-6492},
  abstract = {This study sought to explore Indonesian university students' perceptions, problems, and suggestions of the application of blended learning in their EFL [English as a Foreign Language] courses. A questionnaire consisting of 6 categories (benefits of online learning, benefits of face-to-face learning, learning assessment, problems in blended learning, suggestions for quality improvement of blended learning, and open-ended questions) was used as the research instrument. The collected data were analyzed descriptively and qualitatively. The results showed that most of the students perceived positively both the online and face-to-face modes used in their blended EFL courses, although they tended to have negative views on certain online technical aspects. Internet connectivity was the main problem and the solution of all technical problems was the main suggestion reported by the students. As this research was conducted only with students from one study program, the results should not be generalized and future research is suggested to be more focused on the comparison of students' preferences for other blended course formats and relate them to students' EFL achievement.},
  langid = {english},
  keywords = {Academic Achievement,Barriers,Blended Learning,College Students,Comparative Analysis,Conventional Instruction,Educational Benefits,English (Second Language),Foreign Countries,Internet,No DOI found,Online Courses,Preferences,Second Language Instruction,Second Language Learning,Student Attitudes,Teaching Methods}
}

@article{ribeiropereiraConceptionsPracticesAssessment2016,
  title = {Conceptions and {{Practices}} of {{Assessment}} in {{Higher Education}}: {{A Study}} of {{Portuguese University Teachers}}},
  shorttitle = {Conceptions and {{Practices}} of {{Assessment}} in {{Higher Education}}},
  author = {Ribeiro Pereira, Diana and Flores, Maria Assun{\c c}{\~a}o},
  year = {2016},
  journal = {Revista Iberoamericana de Evaluaci{\'o}n Educativa},
  volume = {9.1},
  number = {2016},
  issn = {19890397},
  doi = {10.15366/riee2016.9.1.001},
  urldate = {2022-05-09},
  file = {/Users/colin.madland/Zotero/storage/WF988RV5/ribeiropereiraConceptionsPracticesAssessment2016.pdf}
}

@article{richardsonPsychologicalCorrelatesUniversity2012,
  title = {Psychological {{Correlates}} of {{University Students}}' {{Academic Performance}}: {{A Systematic Review}} and {{Meta-Analysis}}},
  author = {Richardson, Michelle and Abraham, Charles and Bond, Rod},
  year = {2012},
  journal = {Psychological Bulletin},
  volume = {138},
  pages = {353--387},
  issn = {0033-2909},
  abstract = {A review of 13 years of research into antecedents of university students' grade point average (GPA) scores generated the following: a comprehensive, conceptual map of known correlates of tertiary GPA; assessment of the magnitude of average, weighted correlations with GPA; and tests of multivariate models of GPA correlates within and across research domains. A systematic search of PsycINFO and Web of Knowledge databases between 1997 and 2010 identified 7,167 English-language articles yielding 241 data sets, which reported on 50 conceptually distinct correlates of GPA, including 3 demographic factors and 5 traditional measures of cognitive capacity or prior academic performance. In addition, 42 non-intellective constructs were identified from 5 conceptually overlapping but distinct research domains: (a) personality traits, (b) motivational factors, (c) self-regulatory learning strategies, (d) students' approaches to learning, and (e) psychosocial contextual influences. We retrieved 1,105 independent correlations and analyzed data using hypothesis-driven, random-effects meta-analyses. Significant average, weighted correlations were found for 41 of 50 measures. Univariate analyses revealed that demographic and psychosocial contextual factors generated, at best, small correlations with GPA. Medium-sized correlations were observed for high school GPA, SAT, ACT, and A level scores. Three non-intellective constructs also showed medium-sized correlations with GPA: academic self-efficacy, grade goal, and effort regulation. A large correlation was observed for performance self-efficacy, which was the strongest correlate (of 50 measures) followed by high school GPA, ACT, and grade goal. Implications for future research, student assessment, and intervention design are discussed. (Contains 11 tables and 1 figure.)},
  keywords = {Academic Achievement,ACT Assessment; SAT (College Admission Test),Concept Mapping,Correlation,Data Analysis,Databases,Doctoral Programs,Evaluation Methods,Grade Point Average,Graduate Students,Identification,Learning Strategies,Meta Analysis,Models,Personality Traits,Psychology,Self Efficacy,Tests,Universities}
}

@article{richtikPolicyFrameworkSettling1975,
  title = {The {{Policy Framework}} for {{Settling}} the {{Canadian West}} 1870-1880},
  author = {Richtik, James M.},
  year = {1975},
  journal = {Agricultural History},
  volume = {49},
  number = {4},
  pages = {613--628},
  publisher = {Agricultural History Society},
  issn = {00021482, 15338290},
  urldate = {2024-05-13},
  keywords = {No DOI found}
}

@book{rieberCollectedWorksVygotsky1987,
  title = {The Collected Works of {{L}}. {{S}}. {{Vygotsky}}},
  shorttitle = {The Collected Works of {{L}}. {{S}}. {{Vygotsky}}},
  author = {Rieber, Robert W and Carton, Aaron S},
  editor = {Rieber, Robert W},
  year = {1987},
  series = {Cognition and {{Language}}},
  volume = {1},
  publisher = {Plenum Press},
  address = {New York, NY}
}

@misc{rieckenIndigenousResurgenceGaps2018,
  title = {Indigenous Resurgence Gaps with {{Shauneen Pete}}},
  author = {Riecken, Ted and Baldwin, Courtney},
  year = {2018},
  month = dec,
  urldate = {2018-12-18},
  abstract = {Dr. Shauneen Pete is the Indigenous Resurgence Coordinator at the University of Victoria's Department of Indigenous Education in the Faculty of Education.   As a long-time educator, Pete heard from te},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/UDMRYTI6/shauneen-pete.html}
}

@incollection{rigneyDefiningCulturallyResponsive2017,
  title = {Defining {{Culturally Responsive Digital Education}} for {{Classrooms}}: {{Writing}} from {{Oceania}} to {{Build Indigenous Pacific Futures}}},
  booktitle = {Handbook of {{Indigenous Education}}},
  author = {Rigney, Lester-Irabinna},
  editor = {McKinley, Elizabeth Ann and Smith, Linda Tuhiwai},
  year = {2017},
  pages = {1--17},
  publisher = {Springer Singapore},
  address = {Singapore},
  doi = {10.1007/978-981-10-1839-8_44-1},
  abstract = {Digital education, technology-rich schools, and smart classrooms particularly configured by cloud-computing and blended-learning programs are growing. Participation in education is a key factor affecting the life chances for Indigenous children of the Pacific, yet they have lower rates of participation than non-Indigenous people. Pacific twenty-first-century learning requires new culturally inclusive spaces that do not override Indigenous cultures but draw upon them as a learning foundation on which to build new digital learning. Research on technology and equity as a means of raising school achievement are becoming more attractive in education systems seeking to improve school processes and outcomes. Although international research in this area is extensive, covering about two decades, there are still gaps in its research base specifically on the concept of Culturally Responsive Digital Education for Indigenous peoples. While literature on culturally responsive schooling (CRS) for academic improvement of American Indian and Alaska Natives peoples has emerged, this literature is yet to theorize Indigenous online education and complimentary teacher pedagogy, especially in the Pacific. This chapter will define culturally responsive digital schooling (CRDS) for Indigenous peoples of the Pacific drawing from robust information communication technology (ICT) research, critical and CRS studies. This chapter first argues the need for CRDS that comprises of three interdependent dimensions of ``benefits,'' ``decolonization,'' and ``cultural responsiveness.'' Understanding these dimensions are necessary before purpose, effects, or impact of CRDS can be understood. Finally, the chapter defines CRDS and proposes a ten-point model as a cultural standard to support CRDS Indigenous schooling in the Pacific.},
  isbn = {978-981-10-1839-8}
}

@incollection{ripleyTechnologyServiceTwentyfirst2008,
  title = {Technology in the Service of Twenty-First Century Learning and Assessment},
  booktitle = {Unlocking Assessment: Understanding for Reflection and Application},
  author = {Ripley, Martin},
  editor = {Swaffield, Sue},
  year = {2008},
  publisher = {Routledge},
  address = {Abingdon, Oxon ; New York, NY},
  isbn = {978-0-415-45313-4 978-0-203-93093-9},
  lccn = {LB3051 .U58 2008},
  keywords = {Educational tests and measurements},
  file = {/Users/colin.madland/Zotero/storage/MQH7Y5T2/ripleyTechnologyServiceTwentyfirst2008.pdf}
}

@article{riskoCognitiveOffloading2016,
  title = {Cognitive {{Offloading}}},
  author = {Risko, Evan F. and Gilbert, Sam J.},
  year = {2016},
  month = sep,
  journal = {Trends in Cognitive Sciences},
  volume = {20},
  number = {9},
  pages = {676--688},
  issn = {13646613},
  doi = {10.1016/j.tics.2016.07.002},
  urldate = {2022-06-12},
  langid = {english}
}

@article{rittelDilemmasGeneralTheory1973,
  title = {Dilemmas in a {{General Theory}} of {{Planning}}},
  author = {Rittel, Horst W J and Webber, Melvin M},
  year = {1973},
  month = jun,
  journal = {Policy Sciences},
  volume = {4},
  number = {2},
  pages = {155},
  publisher = {Elsevier Scientific Publishing},
  address = {Amsterdam},
  issn = {0032-2687},
  doi = {10/c8mscz},
  abstract = {Social problems are insoluble; they can only be discussed within their own terms},
  keywords = {Social Affairs},
  file = {/Users/colin.madland/Zotero/storage/ASJPKZZ2/rittelDilemmasGeneralTheory1973.pdf}
}

@book{ritzhauptCasesEducationalTechnology2013,
  title = {Cases on Educational Technology Implementation for Facilitating Learning [Electronic Resource] / {{Albert D}}. {{Ritzhaupt}} and {{Swapna Kumar}}, Editors.},
  author = {Ritzhaupt, Albert D. and Kumar, Swapna},
  year = {2013},
  publisher = {Hershey, Pa. : IGI Global (701 E. Chocolate Avenue, Hershey, Pennsylvania, 17033, USA), c2013.},
  abstract = {Abstract: "This book blends together vital research and advancements on educational technologies into one comprehensive collection; while structuring the information to make it accessible for implementation into the classroom"--Provided by publisher.},
  isbn = {978-1-4666-3677-4},
  keywords = {Education -- Effect of technological innovations on -- Case studies,Educational technology -- Case studies}
}

@article{ritzhauptDevelopmentValidationEducational2014,
  title = {Development and Validation of the Educational Technologist Multimedia Competency Survey},
  author = {Ritzhaupt, Albert D. and Martin, Florence},
  year = {2014},
  month = feb,
  journal = {Educational Technology Research and Development},
  volume = {62},
  number = {1},
  pages = {13--33},
  issn = {1042-1629, 1556-6501},
  doi = {10/f5tdtp},
  urldate = {2021-10-27},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/PMEIK9SB/ritzhauptDevelopmentValidationEducational2014.pdf}
}

@article{ritzhauptDevelopmentValidationEducational2018,
  title = {Development and Validation of the Educational Technologist Competencies Survey ({{ETCS}}): Knowledge, Skills, and Abilities},
  shorttitle = {Development and Validation of the Educational Technologist Competencies Survey ({{ETCS}})},
  author = {Ritzhaupt, Albert D. and Martin, Florence and Pastore, Raymond and Kang, Youngju},
  year = {2018},
  month = apr,
  journal = {Journal of Computing in Higher Education},
  volume = {30},
  number = {1},
  pages = {3--33},
  issn = {1042-1726, 1867-1233},
  doi = {10.1007/s12528-017-9163-z},
  urldate = {2023-04-15},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/QLABTZYP/ritzhauptDevelopmentValidationEducational2018.pdf}
}

@article{robertsonUsingTechnologyTools2019,
  title = {Using {{Technology Tools}} for {{Formative Assessments}}},
  author = {Robertson, Sarah N. and Humphrey, Samia M. and Steele, John P.},
  year = {2019},
  month = jul,
  journal = {Journal of Educators Online},
  volume = {16},
  number = {2},
  issn = {1547-500X},
  abstract = {Assessment is and has been a deliberate and essential piece of education. However, with the recent emergence and popularity of online education, faculty members have to find new ways to engage online learners with formative assessments. While much of the online learning environment can be self-guided, faculty interventions can make the content more engaging for the learner. Biggs and Tang (2011) note the term "backwash" which refers to the direct effect assessments have on a student's learning. Baleni (2015) further expounded on this point by stating that the assessments, not the curriculum, can define how and what a student learns. Using technology to create engaging formative assessment is one way that faculty members can enhance student learning while helping learners prepare for a summative assessment. However, one of the important findings of this study is the time and effort saved by online faculty members using this type of technology for formative assessment. Using an independent samples t-test, this study found a nonsignificant difference in quiz scores between the two formats (paper or Socrative) for formative assessment. The results suggest that Web 2.0 tools can be just beneficial in helping students prepare for a summative assessment. In addition, when chosen wisely, these tools can also influence participation, student wait time for feedback, and teacher grading time.},
  keywords = {Computer Assisted Testing,Efficiency,Feedback (Response),Formative Evaluation,Grading,No DOI found,Scores,Student Evaluation,Summative Evaluation,Test Format,Test Preparation,Undergraduate Students,Web 2.0 Technologies},
  file = {/Users/colin.madland/Zotero/storage/42PPKZ7W/robertsonUsingTechnologyTools2019.pdf}
}

@incollection{robertsOpenEducationalPractices2018,
  title = {Open {{Educational Practices}} in {{K-12 Online}} and {{Blended Learning Environments}}},
  booktitle = {Handbook of Research on {{K-12}} Online and Blending Learning},
  author = {Roberts, Verena and Blomgren, Constance and Ishmael, Kristina and Graham, Lee},
  editor = {Kennedy, Kathryn and Ferdig, Richard E},
  year = {2018},
  edition = {2},
  pages = {527--544},
  publisher = {Carnegie Mellon University: ETC Press},
  address = {Pittsburgh, PA},
  urldate = {2020-07-10},
  abstract = {"The Handbook of Research on K-12 Online and Blended Learning is an edited collection of chapters that sets out to present the current state of research in K-12 online and blended learning. The chapters describe where we have been, what we currently know, and where we hope to go with research in multiple areas."--Book home page.},
  isbn = {978-1-387-73335-4},
  langid = {english},
  annotation = {OCLC: 1031715034}
}

@article{robinsonCompleteSMOCkeryDaily2021,
  ids = {robinsonCompleteSMOCkeryDaily2021a},
  title = {A {{Complete SMOCkery}}: {{Daily Online Testing Did Not Boost College Performance}}},
  author = {Robinson, Daniel H.},
  year = {2021},
  journal = {Educational psychology review},
  volume = {33},
  number = {3},
  pages = {1213--1220},
  publisher = {Springer US},
  address = {New York},
  issn = {1040-726X},
  doi = {10.1007/s10648-020-09588-0},
  abstract = {In an article published in an open-access journal, (Pennebaker et al. PLoS One, 8 (11), e79774, 2013 ) reported that an innovative computer-based system that included daily online testing resulted in better student performance in other concurrent courses and a reduction in achievement gaps between lower and upper middle-class students. This article has had high impact, not only in terms of citations, but it also launched a multimillion-dollar university project and numerous synchronous massive online courses (SMOCs). In this study, I present a closer look at the data used in the Pennebaker et al. study. As in many cases of false claims, threats to internal validity were not adequately addressed. Student performance increases in other courses can be explained entirely by selection bias, whereas achievement gap reductions may be explained by differential attrition. It is hoped that the findings reported in this paper will inform future decisions regarding SMOC courses. More importantly, our field needs watchdogs who expose such unsupported extravagant claims---especially those appearing in pay-to-publish journals.},
  keywords = {Academic Achievement,Bias,Child and School Psychology,College Students,Computer Assisted Testing,differential attrition,Distance learning,Education,Educational Psychology,internal validity,Junior high school students,Learning and Instruction,Online Courses,Online education,Pennebaker James W,Psychology,Psychology Educational,quackery,Replication,selection bias,SMOC,Social Sciences,Student Evaluation,Validity},
  file = {/Users/colin.madland/Zotero/storage/A9A8S6XQ/robinsonCompleteSMOCkeryDaily2021.pdf}
}

@article{robinsonHelpingInstructorsIdentify2021,
  title = {Helping {{Instructors Identify Course Design Flaws}}},
  author = {Robinson, Sarah E. and Noyd, Robert K. and Jones, Steven K.},
  year = {2021},
  month = apr,
  journal = {College Teaching},
  volume = {69},
  number = {2},
  pages = {100--106},
  issn = {8756-7555, 1930-8299},
  doi = {10/gjhqhs},
  urldate = {2021-03-21},
  langid = {english}
}

@article{robinsonImpactOpenTextbooks2014,
  title = {The {{Impact}} of {{Open Textbooks}} on {{Secondary Science Learning Outcomes}}},
  author = {Robinson, T. Jared and Fischer, Lane and Wiley, David and Hilton, John},
  year = {2014},
  journal = {Educational Researcher},
  doi = {10.3102/0013189X14550275},
  abstract = {Given the increasing costs associated with commercial textbooks and decreasing financial support of public schools, it is important to better understand the impacts of open educational resources on student outcomes. The purpose of this quantitative study is to analyze whether the adoption of open science textbooks significantly affects science learning outcomes for secondary students in earth systems, chemistry, and physics.This study uses a quantitative quasi-experimental design with propensity score matched groups and multiple regression to examine whether student learning was influenced by the adoption of open textbooks instead of traditional publisher-produced textbooks. Students who used open textbooks scored .65 points higher on end-of-year state standardized science tests than students using traditional textbooks when controlling for the effects of 10 student and teacher covariates. Further analysis revealed statistically significant positive gains for students using the open chemistry textbooks, with no significant difference in student scores for earth systems of physics courses. Although the effect size of the gains were relatively small, and not consistent across all textbooks, the finding that open textbooks can be as effective or even slightly more effective than their traditional counterparts has important considerations in terms of school district policy in a climate of finite educational funding.}
}

@misc{rodrigoTwitterInvestigatingAutomated2020,
  type = {Text},
  title = {Twitter Investigating Automated Image Previews over Apparent Algorithmic Bias},
  author = {Rodrigo, Chris Mills},
  year = {2020},
  month = sep,
  journal = {TheHill},
  urldate = {2020-09-22},
  abstract = {Twitter is investigating~the algorithm it uses to crop pictures for its mobile platform after several users pointed out a tendency to zero in on white faces.},
  howpublished = {https://thehill.com/policy/technology/517437-twitter-investigating-automated-image-previews-over-apparent-algorithmic},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/IPCQIDDN/517437-twitter-investigating-automated-image-previews-over-apparent-algorithmic.html}
}

@article{rodriguesAssessmentPatternsPortuguese2022,
  title = {Assessment {{Patterns}} during {{Portuguese Emergency Remote Teaching}}},
  author = {Rodrigues, Carlota and Costa, Joana Martinho and Moro, Sergio},
  year = {2022},
  journal = {Sustainability (Basel, Switzerland)},
  volume = {14},
  number = {5},
  pages = {3131},
  publisher = {Mdpi},
  address = {BASEL},
  issn = {2071-1050},
  doi = {10.3390/su14053131},
  abstract = {COVID-19 certainly brought more negative aspects than positive ones to education. On the one hand, new gaps and challenges emerged from the lockdowns worldwide. On the other hand, we have been witnessing the increased relationship between technology and education, which created an opportunity for education to evolve and enhance the use of digital tools in classes. During several lockdowns worldwide, due to the pandemic crisis, millions of students and teachers were forced to continue the process of teaching and learning at home and experienced Emergency Remote Teaching (ERT), which led to new challenges on the process of students' assessment. To understand what assessment challenges teachers face during the ERT and their patterns for evaluation, we performed a survey in Portugal where the ERT lasted several months in the last two years. The survey was validated and conducted in the first semester of 2021. We found two main patterns: (i) the group of teachers that prefer oral discussion and dialogue simulation and display disbelief towards traditional tests and educational games; and (ii) the group of teachers that tend to prefer oral simulation and display greater disbelief about educational games, dialogue simulation and peer work and review. From the survey analysis, we also found that teachers considered their students to be more distracted and less engaged in online classes. They were negatively affected both in their learning and evaluation process. Using digital tools to collect and validate data and creating patterns between collected data is essential to understand what to expect in future crises. The presented analysis should be correlated with other studies to extract patterns of knowledge from data and to be able to obtain conclusions about how to move education forward.},
  keywords = {assessment patterns,COVID-19,Data collection,Distance education,Education,emergency remote teaching (ERT),Environmental Sciences,Environmental Sciences & Ecology,Environmental Studies,Epidemics,Evaluation,Games,Green & Sustainable Science & Technology,Learning,Life Sciences & Biomedicine,Methods,online assessment,Pandemics,Polls & surveys,Portugal,Science & Technology,Science & Technology - Other Topics,Simulation,Social aspects,Students,Teachers,Teaching},
  file = {/Users/colin.madland/Zotero/storage/NJBK9RFD/rodriguesAssessmentPatternsPortuguese2022.pdf}
}

@article{rodriguez-gomezLearningorientedEassessmentEffects2016,
  title = {Learning-Oriented e-Assessment: The Effects of a Training and Guidance Programme on Lecturers' Perceptions},
  author = {{Rodr{\'i}guez-G{\'o}mez}, Gregorio and {Quesada-Serra}, Victoria and {Ibarra-S{\'a}iz}, Mar{\'i}a Soledad},
  year = {2016},
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {41},
  number = {1},
  pages = {35--52},
  publisher = {Routledge},
  issn = {0260-2938},
  doi = {10/gcphwr},
  abstract = {Various frameworks that acknowledge the importance of assessment as a core aspect of the learning process have been proposed to enhance life-long learning and promote participative strategies. In this context, learning-oriented e-assessment was developed to enhance learning through assessment in a technology-mediated context. Using a quantitative?qualitative mixed research method, the current study aimed to analyse the effects of a learning-oriented e-assessment training and guidance programme on university lecturers? perceptions of the importance of assessment, their competence in assessment and their actual use of assessment, and to consider lecturers? experience and perception when implementing learning-oriented e-assessment in one of their courses. The results of the quantitative research showed a significant difference between the pre-test and post-test measures in the competence and use criteria for the following four categories: ?assessment planning and design?, ?monitoring of student learning?, ?participation of students in the assessment process? and ?improvement and changes to the assessment process?. The qualitative results support the quantitative outcomes, providing some insight into lecturers? perception of the experience.},
  file = {/Users/colin.madland/Zotero/storage/M7VA9UQQ/rodriguez-gomezLearningorientedEassessmentEffects2016.pdf}
}

@article{rodriguez-gomezLearningorientedEassessmentEffects2016a,
  title = {Learning-Oriented e-Assessment: The Effects of a Training and Guidance Programme on Lecturers' Perceptions},
  author = {{Rodriguez-Gomez}, G and {Quesada-Serra}, V and {Ibarra-Saiz}, {\relax MS}},
  year = {2016},
  journal = {ASSESSMENT \& EVALUATION IN HIGHER EDUCATION},
  volume = {41},
  number = {1},
  pages = {35--52},
  issn = {0260-2938},
  doi = {10.1080/02602938.2014.979132},
  abstract = {Various frameworks that acknowledge the importance of assessment as a core aspect of the learning process have been proposed to enhance life-long learning and promote participative strategies. In this context, learning-oriented e-assessment was developed to enhance learning through assessment in a technology-mediated context. Using a quantitative-qualitative mixed research method, the current study aimed to analyse the effects of a learning-oriented e-assessment training and guidance programme on university lecturers' perceptions of the importance of assessment, their competence in assessment and their actual use of assessment, and to consider lecturers' experience and perception when implementing learning-oriented e-assessment in one of their courses. The results of the quantitative research showed a significant difference between the pre-test and post-test measures in the competence and use criteria for the following four categories: assessment planning and design', monitoring of student learning', participation of students in the assessment process' and improvement and changes to the assessment process'. The qualitative results support the quantitative outcomes, providing some insight into lecturers' perception of the experience.},
  langid = {english},
  keywords = {assessment design,assessment literacy,e-assessment,FEEDBACK,HIGHER-EDUCATION,learning-oriented e-assessment,PEER,peer assessment,STUDENTS}
}

@article{rodriguez-gomezVozEstudianteEvaluacion2012,
  title = {La Voz Del Estudiante En La Evaluaci{\'o}n Del Aprendizaje: Un Camino Por Recorrer En La Universidad},
  shorttitle = {La Voz Del Estudiante En La Evaluaci{\'o}n Del Aprendizaje},
  author = {{Rodr{\'i}guez-G{\'o}mez}, Gregorio and {Ibarra-S{\'a}iz}, M Soledad and Gallego Noche, Beatriz and {G{\'o}mez-Ruiz}, Miguel-{\'A}ngel and Quesada Serra, Victoria},
  year = {2012},
  month = dec,
  journal = {RELIEVE - Revista Electr{\'o}nica de Investigaci{\'o}n y Evaluaci{\'o}n Educativa},
  volume = {18},
  number = {2},
  issn = {1134-4032},
  doi = {10/c897},
  urldate = {2021-04-10},
  annotation = {Student voice in learning assessment: a pathway not yet developed at university},
  file = {/Users/colin.madland/Zotero/storage/5G2F772Z/rodriguez-gomezVozEstudianteEvaluacion2012.pdf;/Users/colin.madland/Zotero/storage/HRB43ZTN/rodriguez-gomezVozEstudianteEvaluacion2012.pdf}
}

@article{rodriguez-trianaInstructionStudentEngagement2020,
  title = {Instruction, {{Student Engagement}}, and {{Learning Outcomes}}: {{A Case Study Using Anonymous Social Media}} in a {{Face-to-Face Classroom}}},
  author = {{Rodriguez-Triana}, Maria Jesus and Prieto, Luis P. and Holzer, Adrian and Gillet, Denis},
  year = {2020},
  month = oct,
  journal = {IEEE Transactions on Learning Technologies},
  volume = {13},
  number = {4},
  pages = {718--733},
  publisher = {IEEE Transactions on Learning Technologies},
  issn = {1939-1382},
  doi = {10.1109/TLT.2020.2995557},
  abstract = {With the wide availability of mobile devices and the growing interest in social media, numerous applications have emerged to support student engagement in the classroom. There is conflicting evidence, however, on whether the engagement benefits of such applications outweigh their potential cost as a source of disaffection. To investigate these issues, this article presents a case study on the usage of a social media app (SpeakUp) during a semester-long face-to-face university course, and its relations with the context and the learning outcomes. In this mixed-methods study, we gathered data from multiple sources (video recordings of the lessons, SpeakUp logs and messages, student questionnaires, and course assessments) in order to extract self-reported and observable behavioral and emotional indicators. Our findings reveal that simple measures of behavioral engagement were insufficient to predict academic performance. Nevertheless, our models significantly improved using relatively simple and unobtrusive indicators of both behavioral and emotional engagement and disaffection. This article also indicates that the mere introduction of social media in educational settings does not guarantee a positive impact on learning. To promote an effective use of social media in the classroom (raising engagement while avoiding disaffection), teachers need to design the learning activities aligning the use of social media with the learning goals.},
  keywords = {Alignment (Education),College Students,Computer Oriented Programs,Handheld Devices,Instructional Design,Learner Engagement,Outcomes of Education,Psychological Patterns,Social Media},
  file = {/Users/colin.madland/Zotero/storage/JWSHWJ3D/rodriguez-trianaInstructionStudentEngagement2020.pdf}
}

@incollection{rogatenAreAssessmentPractices2020,
  title = {Are {{Assessment Practices Well Aligned Over Time}}? {{A Big Data Exploration}}},
  shorttitle = {Are {{Assessment Practices Well Aligned Over Time}}?},
  booktitle = {Re-Imagining {{University Assessment}} in a {{Digital World}}},
  author = {Rogaten, Jekaterina and Clow, Doug and Edwards, Chris and Gaved, Mark and Rienties, Bart},
  editor = {Bearman, Margaret and Dawson, Phillip and Ajjawi, Rola and Tai, Joanna and Boud, David},
  year = {2020},
  volume = {7},
  pages = {147--164},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-41956-1_11},
  urldate = {2022-03-19},
  isbn = {978-3-030-41955-4 978-3-030-41956-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/6UYNQ5BT/rogatenAreAssessmentPractices2020.pdf}
}

@article{rogerson-revellConstructivelyAligningTechnologies2015,
  title = {Constructively Aligning Technologies with Learning and Assessment in a Distance Education Master's Programme},
  author = {{Rogerson-Revell}, Pamela},
  year = {2015},
  journal = {Distance education},
  volume = {36},
  number = {1},
  pages = {129--147},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0158-7919},
  doi = {10.1080/01587919.2015.1019972},
  abstract = {This paper reports on an action research study investigating the use of online learning activities or "e-tivities" to enhance the learning and assessment experience of students on a distance master's programme. The study suggests that to be successfully integrated in a programme, such activities need to be carefully aligned with learning outcomes and assessment practices, and their value needs to be clear both to students and staff. The paper describes how e-tivities were designed, adopting a constructive alignment approach, to introduce more flexible and innovative approaches to learning and assessment. The e-tivities used a range of technologies (e.g., voice-based discussion boards, podcasts, wikis and blogs) to carry out group-based reflective activities. The study provides some evidence that such e-tivities, particularly voice-based activities, can help provide earlier, more detailed formative assessment, stimulate a more collaborative approach to learning and motivate students to engage more broadly with course content.},
  keywords = {Action Research,Alignment (Education),Applied Linguistics,assessment,Constructive alignment,Content Analysis,Cooperative Learning,Curriculum Implementation,Distance Education,Distance learning,e-tivities,Education & Educational Research,Educational Practices,Educational Strategies,Electronic Learning,Feedback (Response),Foreign Countries,Formative Evaluation,Graduate studies,Higher education,Integrated Activities,Interaction,Interviews,Learning Activities,Learning Experience,Masters Programs,Motivation Techniques,Online education,Online learning,Pilot Projects,Reflection,Social Sciences,Student assessment,Student Evaluation,Student Surveys,Technology Integration,Technology Uses in Education,United Kingdom,Web based courses},
  file = {/Users/colin.madland/Zotero/storage/MB9QTZV2/rogerson-revellConstructivelyAligningTechnologies2015.pdf}
}

@article{rohsMOOCsClaimEducation2015,
  title = {{{MOOCs}} and the Claim of Education for All: {{A}} Disillusion by Empirical Data},
  shorttitle = {{{MOOCs}} and the Claim of Education for All},
  author = {Rohs, Matthias and Ganz, Mario},
  year = {2015},
  month = dec,
  journal = {The International Review of Research in Open and Distributed Learning},
  volume = {16},
  number = {6},
  issn = {1492-3831},
  doi = {10.19173/irrodl.v16i6.2033},
  urldate = {2018-12-02},
  abstract = {MOOCs have shaped the discussion on learning with digital media for the last few years. One claim of MOOCs in the tradition of Open Educational Resources is to expand access to education, mainly in the field of higher education. But do MOOCs meet this claim? The empirical data in this article confirm the suspicion that, despite all the heterogeneity of the participants, MOOCs are mostly used by people with a higher level of education. Data of participants from two MOOCs from Germany, as well as, empirical data from large providers and universities are used. But due to the different forms of MOOCs there is no comprehensive proof possible. With respect to the Knowledge Gap Theory and the Digital Divide, a theoretical framework is provided to explain possible causes of a different usage. The aim of the article is to point out the risks of an increase of inequalities as a consequence of hyping MOOCs and to stimulate a discussion about possible answers to make MOOCs an instrument of education for all.},
  copyright = {Copyright (c) 2015 Matthias Rohs, Mario Ganz},
  langid = {english},
  keywords = {Digital Divide,Exclusion,MOOC},
  file = {/Users/colin.madland/Zotero/storage/6NVIJR5Q/rohsMOOCsClaimEducation2015.pdf;/Users/colin.madland/Zotero/storage/9J74V3AA/2033.html}
}

@article{rolimExaminingUseAssessment2019,
  ids = {catarinarolimExaminingUseEassessment2019,rolimExaminingUseEAssessment2019},
  title = {Examining the Use of E-assessment in Higher Education: Teachers and Students' Viewpoints},
  author = {Rolim, Catarina and Isaias, Pedro},
  year = {2019},
  journal = {British Journal of Educational Technology},
  volume = {50},
  number = {4},
  pages = {1785--1800},
  publisher = {Wiley},
  address = {HOBOKEN},
  issn = {0007-1013},
  doi = {10.1111/bjet.12669},
  abstract = {The combination of teaching and information technologies is at the origin of a more embracing, flexible and accessible approach to learning. Assessment is considered an integral part of the learning process, but it has always been considered challenging for teachers. Through the adoption of information technologies, it is possible to create new opportunities to improve assessment. Despite its numerous advantages, e-assessment remains a topic of much discussion for many, due to doubts that arise about its efficiency and effectiveness. In order to understand this issue, this study aims to explore e-assessment in higher education, from the viewpoint of teachers and students. Four online surveys were distributed among teachers and students in Portugal and other countries. While the results show that Portugal is slightly behind in terms of adoption, there is a strong awareness of the importance of e-assessment. Internationally, e-assessment has higher adoption rates, and both teachers and students believe that this method of assessment is advantageous.},
  keywords = {College teachers,Computer Assisted Testing,Education,Education & Educational Research,Evaluation methods,Foreign Countries,Higher education,Higher Education,ICT in education,Information Technology,Learning,Online assessment,Online learning,Online Surveys,Portugal,Quantitative research,Social Sciences,Student assessment,Student Attitudes,Students,Teacher attitudes,Teacher Attitudes,Teachers,University teaching},
  file = {/Users/colin.madland/Zotero/storage/GT4N6SVU/rolimExaminingUseAssessment2019.pdf}
}

@book{romero-hallResearchMethodsLearning2020,
  title = {Research {{Methods}} in {{Learning Design}} and {{Technology}}},
  author = {{Romero-Hall}, Enilda},
  editor = {{Romero-Hall}, Enilda},
  year = {2020},
  month = sep,
  edition = {1},
  publisher = {Routledge},
  doi = {10.4324/9780429260919},
  urldate = {2021-03-25},
  isbn = {978-0-429-26091-9},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/8QJP27VB/romero-hallResearchMethodsLearning2020.pdf}
}

@article{romero-ivanovaDigitalStoriesMaterial2021,
  title = {Digital {{Stories}}, {{Material Transformations}}: {{Reflections}} of {{Education Students}} in a {{Pre-Teacher Program}}},
  author = {{Romero-Ivanova}, Christina Louise and Cook, Paul and Faurote, Greta},
  year = {2021},
  month = jan,
  journal = {English Teaching: Practice and Critique},
  volume = {20},
  number = {2},
  pages = {245--260},
  publisher = {{English Teaching: Practice and Critique}},
  issn = {1175-8708},
  doi = {10.1108/ETPC-07-2020-0066},
  abstract = {Purpose: This study centers on high school pre-teacher education students' reviews of their peers' digital stories. The purpose of this study is twofold: to bring digital storytelling to the forefront as a literacy practice within classrooms that seeks to privilege students' voices and experiences and also to encapsulate the authors' different experiences and perspectives as teachers. The authors sought to understand how pre-teacher education candidates analyzed, understood and made meaning from their classmates' digital stories using the seven elements of digital storytelling (Dreon "et al.," 2011). Design/methodology/approach: Using grounded theory (Charmaz, 2008) as a framework, the question of how do high school pre-teacher education program candidates reflectively peer review their classmates' digital stories is addressed and discussed through university and high school instructors' narrative reflections. Through peer reviews of their fellow classmates' digital stories, students were able to use the digital storytelling guide that included the seven elements of digital storytelling planning to critique and offer suggestions. The authors used the 2018-2019 and 2019-2020 cohorts' digital stories, digital storytelling guides and peer reviews to discover emerging categories and themes and then made sense of these through narrative analysis. This study looks at students' narratives through the contexts of peer reviews. Findings: The seven elements of digital storytelling, as noted by Dreon "et al." (2011, p. 5), which are point of view, dramatic question, emotional content, the gift of your voice, the power of the soundtrack, economy and pacing, were used as starting points for coding students' responses in their evaluations of their peers' digital stories. Situated on the premise of 21st century technologies as important promoters of differentiated ways of teaching and learning that are highly interactive (Greenhow "et al.," 2009), digital stories and students' reflective practices of peer reviewing were the foundational aspects of this paper. Research limitations/implications: The research the authors have done has been in regards to reviewing and analyzing students' peer reviews of their classmates' digital stories, so the authors did not conduct a research study empirical in nature. What the authors have done is to use students' artifacts (digital story, digital storytelling guides and reflections/peer reviews) to allow students' authentic voices and perspectives to emerge without their own perspectives marring these. The authors, as teachers, are simply the tools of analysis. Practical implications: In reading this paper, teachers of different grade levels will be able to obtain ideas on using digital storytelling in their classrooms first. Second, teachers will be able to obtain hands-on tools for implementing digital storytelling. For example, the digital storytelling guide to which the authors refer (Figure 1) can be used in different subject areas to help students plan their stories. Teachers will also be able to glean knowledge on using students' peer reviews as a kind of authentic assessment. Social implications: The authors hope in writing and presenting this paper is that teachers and instructors at different levels, K-12 through higher education, will consider digital storytelling as a pedagogical and learning practice to spark deeper conversations within the classroom that flow beyond margins and borders of instructional settings out into the community and beyond. The authors hope that others will use opportunities for storytelling, digital, verbal, traditional writing and other ways to spark conversations and privilege students' voices and lives. Originality/value: As the authors speak of the original notion of using students' crucial events as story starters, this is different than prior research for digital storytelling that has focused on lesson units or subject area content. Also, because the authors have used crucial events, this is an entry point to students' lives and the creation of rapport within the classroom.},
  keywords = {Active Learning,College Faculty,Criticism,Grounded Theory,High School Teachers,Information Technology,Literacy,Multiple Literacies,Peer Evaluation,Personal Narratives,Preservice Teacher Education,Preservice Teachers,Story Telling,Student Attitudes,Teacher Attitudes},
  file = {/Users/colin.madland/Zotero/storage/R3BXHKPR/romero-ivanovaDigitalStoriesMaterial2021.pdf}
}

@article{romero-martinFormativeAssessmentCommunication2017,
  ids = {romero-martinFormativeAssessmentCommunication2017a},
  title = {Formative {{Assessment}}, {{Communication Skills}} and {{ICT}} in {{Initial Teacher Training}}},
  author = {{Romero-Martin}, M. Rosario and {Castejon-Oliva}, Francisco-Javier and {Lopez-Pastor}, Victor-Manuel and {Fraile-Aranda}, Antonio},
  year = {2017},
  journal = {Comunicar (Huelva, Spain)},
  volume = {25},
  number = {52},
  pages = {73--82},
  publisher = {Grupo Comunicar},
  address = {HUELVA},
  issn = {1134-3478},
  doi = {10.3916/C52-2017-07},
  abstract = {The purpose of this study is to analyze the perception of students, graduates, and lecturers in relation to systems of formative and shared assessment and to the acquisition of teaching competences regarding communication and the use of Information and Communications Technology (ICT) in initial teacher education (ITE) on degrees in Primary Teaching Physical Education (PTPE) and Physical Education and Sports Science (PESS). An ad hoc questionnaire was applied to a total sample of 1,243 students, 487 graduates and 345 lecturers from 24 Spanish universities that cover most of Spain's Regional Autonomous Communities. The results from the questionnaires indicate that for all three groups the most relevant element in the assessment process is the teacher-student interaction, and the second most relevant are the competences in interpersonal relationships. Significant differences are also found in practically all the items in the questionnaire between the responses of lecturers and students and between those of students and graduates. In our detailed study of the perceptions of students regarding their competence in ICT, those taking the degree in PTPE perceive a greater use of ICT than those taking the degree in PESS. The same difference was found with students under 22 years of age in relation to the older students. No gender differences were found.},
  keywords = {ATTITUDES,Communication,Education & Educational Research,FEEDBACK,Formative assessment,graduate,higher education,HIGHER-EDUCATION,INFORMATION,skills communicative,Social Sciences,teacher training,TECHNOLOGIES,UNIVERSITY,university students,university teacher},
  file = {/Users/colin.madland/Zotero/storage/C6FCDYMS/romero-martinFormativeAssessmentCommunication2017.pdf}
}

@article{romeroalonsoBarriersTeacherPerception2019,
  ids = {romeroalonsoBarriersTeacherPerception2019a},
  title = {Barriers in {{Teacher Perception}} about the {{Use}} of {{Technology}} for {{Evaluation}} in {{Higher Education}}},
  author = {Romero Alonso, Rosita and Riquelme Plaza, Irma and Halal Orfali, Carol},
  year = {2019},
  journal = {Digital Education Review},
  publisher = {Digital Education Review},
  issn = {EISSN-2013-9144},
  abstract = {This article describes barriers in higher education teachers' perceptions facing changes when innovating in their evaluation practices by integrating information and communication technologies (ICT) in a Chilean university. Forming and evaluating in a competency-based approach involves challenges for the teaching staff and changes in their role that are accepted or resisted. The same happens in the face of innovation processes with information and communication technologies (ICT) integration in teaching practices. The primary results show a relationship between pedagogical beliefs and evaluation which is consistent with adoption and assessment of the digital tool used. In addition, it reveals the role of beliefs as secondary barriers to change in the face of teaching practices with the use of technology (Ertmer, Ottenbreit-Leftwich, Sadik, Sendurur, \& Sendurur, 2012). This study identifies the value of autonomy in student work and feedback as key beliefs in technology adoption.},
  langid = {english},
  keywords = {Barriers,Chile,College Faculty,Competency Based Education,Evaluation Methods,Foreign Countries,Graduate Students,Information Technology,No DOI found,Online Courses,Student Evaluation,Teacher Attitudes,Technology Uses in Education}
}

@book{rosdailSloopersTheirAncestry1961,
  title = {The {{Sloopers}}: {{Their}} Ancestry and Posterity},
  author = {Rosdail, J. Hart},
  year = {1961},
  publisher = {Norwegian Slooper Society of America},
  address = {Illinois}
}

@article{rosenAssessingStudentsHuman2017,
  title = {Assessing Students in Human-to-agent Settings to Inform Collaborative Problem-solving Learning},
  author = {Rosen, Yigal},
  year = {2017},
  journal = {Journal of Educational Measurement},
  volume = {54},
  number = {1},
  pages = {36--53},
  publisher = {Wiley-Blackwell Publishing Ltd.},
  issn = {0022-0655},
  doi = {10.1111/jedm.12131},
  abstract = {In order to understand potential applications of collaborative problem-solving (CPS) assessment tasks, it is necessary to examine empirically the multifaceted student performance that may be distributed across collaboration methods and purposes of the assessment. Ideally, each student should be matched with various types of group members and must apply the skills in varied contexts and tasks. One solution to these assessment demands is to use computer-based (virtual) agents to serve as the collaborators in the interactions with students. This article proposes a human-to-agent (H-A) approach for formative CPS assessment and describes an international pilot study aimed to provide preliminary empirical findings on the use of H-A CPS assessment to inform collaborative learning. Overall, the findings showed promise in terms of using a H-A CPS assessment task as a formative tool for structuring effective groups in the context of CPS online learning. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {collaboration,Collaboration,Problem Solving,problem-solving learning,students,Students}
}

@article{rossAdaptingClassroomSimulation2021,
  title = {Adapting a {{Classroom Simulation Experience}} to an {{Online Escape Room}} in {{Nutrition Education}}},
  author = {Ross, Jenifer M. and Wright, Lauri and Arikawa, Andrea Y.},
  year = {2021},
  journal = {Online Learning},
  volume = {25},
  number = {1},
  pages = {238--244},
  issn = {ISSN-2472-5749},
  abstract = {Due to the COVID-19 emergency transition to remote learning, an undergraduate class in nutrition and dietetics modified a face-to-face experiential "escape room" assignment into a comparable online experience. The online assignment was structured so that students had to use knowledge and clues to move through each step of the Nutrition Care Process; students proceeded through the escape room individually until each successfully "escaped." An important component of this assignment was the postactivity debriefing process, which took place via video conferencing in small groups. Students indicated that they were pleasantly surprised at the effectiveness of the online assignment. However, analytics showed that students progressed through most of the steps fairly quickly; thus, instructors plan to improve future deployments by using a variety of interactive assessments and adding more layered criteria and clues within each of the escape room steps.},
  langid = {english},
  keywords = {COVID-19,Distance Education,Electronic Learning,Instructional Effectiveness,No DOI found,Nutrition Instruction,Pandemics,Problem Solving,Simulation,Student Experience,Undergraduate Students,Videoconferencing}
}

@article{rosseelLavaanPackageStructural2012,
  title = {Lavaan: {{An R Package}} for {{Structural Equation Modeling}}},
  author = {Rosseel, Yves},
  year = {2012},
  month = may,
  journal = {Journal of Statistical Software},
  volume = {48},
  number = {2},
  pages = {1--36},
  doi = {10.18637/jss.v048.i02},
  urldate = {2023-06-27},
  abstract = {Structural equation modeling (SEM) is a vast field and widely used by many applied researchers in the social and behavioral sciences. Over the years, many software packages for structural equation modeling have been developed, both free and commercial. However, perhaps the best state-of-the-art software packages in this field are still closed-source and/or commercial. The R package lavaan has been developed to provide applied researchers, teachers, and statisticians, a free, fully open-source, but commercial-quality package for latent variable modeling. This paper explains the aims behind the development of the package, gives an overview of its most important features, and provides some examples to illustrate how lavaan works in practice.},
  chapter = {Articles},
  file = {/Users/colin.madland/Zotero/storage/FVUVAMZ6/rosseelLavaanPackageStructural2012.pdf}
}

@article{rossMultimodalAssessmentFramework2020,
  ids = {rossMultimodalAssessmentFramework2020a},
  title = {A Multimodal Assessment Framework for Higher Education},
  author = {Ross, Jen and Curwood, Jen Scott and Bell, Amani},
  year = {2020},
  month = jul,
  journal = {E-Learning and Digital Media},
  volume = {17},
  number = {4},
  pages = {290--306},
  publisher = {SAGE Publications},
  address = {London, England},
  issn = {2042-7530, 2042-7530},
  doi = {10.1177/2042753020927201},
  urldate = {2022-05-29},
  abstract = {Higher education institutions increasingly expect students to work effectively and critically with multiple modes, semiotic resources and digital tools. However, assessment practices are often insufficient to capture how multimodal artefacts represent disciplinary knowledge in complex ways. This study explores and theorises the design and assessment of students' digitally mediated multimodal work, and it offers insight into how to effectively communicate expectations and evaluate student learning in a digital age. We propose a framework for multimodal assessment that takes account of criticality, creativity, the holistic nature of these assignments and the importance of valuing multimodality.},
  langid = {english},
  keywords = {Alternative Assessment,College Faculty,College Students,Creativity,Education & Educational Research,Educational Technology,Evaluation Methods,Foreign Countries,Holistic Approach,Learning Modalities,Scoring Rubrics,Social Sciences,Student Evaluation,Technology Uses in Education},
  file = {/Users/colin.madland/Zotero/storage/5RY3QLN5/rossMultimodalAssessmentFramework2020.pdf}
}

@incollection{roulstonAnalysingInterviews2021,
  title = {Analysing {{Interviews}}},
  booktitle = {The {{SAGE Handbook}} of {{Qualitative Data Analysis}}},
  author = {Roulston, Kathryn},
  editor = {Flick, Uwe},
  year = {2021},
  month = aug,
  publisher = {SAGE Publications Ltd},
  address = {London},
  doi = {10.4135/9781446282243}
}

@article{rourkeAssessingSocialPresence2001,
  title = {Assessing Social Presence in Asynchronous Text-Based Computer Conferencing},
  author = {Rourke, Liam and Anderson, Terry and Garrison, D. R. and Archer, Walter},
  year = {2001},
  journal = {Journal of Distance Education/Revue de l'enseignement {\`a} distance},
  volume = {14},
  number = {2},
  abstract = {Instructional media such as computer conferencing engender high levels of student-student and student-teacher interaction; therefore, they can support models of teaching and learning that are highly interactive and consonant with the communicative ideals of university education. This potential and the ubiquity of computer conferencing in higher education prompted three of the authors of the this article to develop a community of inquiry model that synthesizes pedagogical principles with the inherent instructional and access benefits of computer conferencing (Garrison, Anderson, \& Archer, 2000). This article explicates one element of the model, social presence. Social presence is defined as the ability of learners to project themselves socially and affectively into a community of inquiry. A template for assessing social presence in computer conferencing is presented through content analysis of conferencing transcripts. To facilitate explication of the scheme and subsequent replication of this study, selections of coded transcripts are included, along with interrater reliability figures. The article concludes with a discussion of the implications and benefits of assessing social presence for instructors, conference moderators, and researchers.}
}

@article{rourkeLearningCommunitiesInquiry2009,
  title = {Learning in Communities of Inquiry: {{A}} Review of the Literature},
  shorttitle = {Learning in Communities of Inquiry: {{A}} Review of the Literature},
  author = {Rourke, Liam and Kanuka, Heather},
  year = {2009},
  journal = {Journal of Distance Education},
  volume = {23},
  pages = {19--48},
  abstract = {The purpose of this study was to investigate learning in communities of inquiry (CoI) as the terms are defined in Garrison, Anderson, and Archer's (2000) framework. We identified 252 reports from 2000-2008 that referenced the framework, and we reviewed them using Ogawan and Malen's (1991) strategy for synthesizing multi-vocal bodies of literature. Of the 252 reports, 48 collected and analyzed data on one or more aspects of the CoI framework; only five included a measure of student learning. Predominantly, learning was defined as perceived learning and assessed with a single item on a closed-form survey. Concerns about the soundness of such measures pervade the educational measurement community; in addition, we question the validity of the particular items employed in the CoI literature. Bracketing these concerns, the review indicates that it is unlikely that deep and meaningful learning arises in CoI. Students associate the surface learning that does occur with independent activities or didactic instruction; not sustained communication in critical CoI. We encourage researchers to conduct more, substantial investigations into the central construct of the popular framework for e-learning and theorists to respond to the mounting body of disconfirming evidence.},
  annotation = {1}
}

@article{rovaiOnlineTraditionalAssessments2000,
  title = {Online and Traditional Assessments: What Is the Difference?},
  shorttitle = {Online and Traditional Assessments},
  author = {Rovai, Alfred P.},
  year = {2000},
  month = jul,
  journal = {The Internet and Higher Education},
  volume = {3},
  number = {3},
  pages = {141--151},
  issn = {10967516},
  doi = {10.1016/s1096-7516(01)00028-8},
  urldate = {2022-02-04},
  langid = {english},
  keywords = {archived},
  annotation = {https://web.archive.org/web/20220204163405/https://www.sciencedirect.com/science/article/abs/pii/S1096751601000288?via\%3Dihub},
  file = {/Users/colin.madland/Zotero/storage/9H4546LW/rovaiOnlineTraditionalAssessments2000.pdf}
}

@article{rowlettPartiallyautomatedIndividualizedAssessment2022,
  title = {Partially-Automated Individualized Assessment of Higher Education Mathematics},
  author = {Rowlett, P},
  year = {2022},
  month = may,
  journal = {International Journal of Mathematical Education in Science and Technology},
  volume = {53},
  number = {6},
  pages = {1413--1434},
  issn = {0020-739X},
  doi = {10.1080/0020739X.2020.1822554},
  abstract = {A partially-automated method of assessment is proposed, in which automated question setting is used to generate individualized versions of a coursework assignment, which is completed by students and marked by hand. This is designed to be (a) comparable to a traditional written coursework assignment in validity, in that complex and open-ended tasks can be set with diverse submission formats that would not be suitable for written examination or automated marking; and, (b) comparable to e-assessment in terms of reduction of academic misconduct, with individualization acting as a barrier to copying and collusion. This method of assessment is implemented in practice. Evaluation focuses on expert second-marking, student feedback and analysis of marks, and aims to establish that the partially-automated method can be useful in practice. The partially-automated method proposed appears to be capable of adapting a coursework assignment to make it less sensitive to copying and collusion (and therefore more reliable) while maintaining its validity, though leading to reduced efficiency for the marker. This paper therefore contributes the introduction of a novel approach to assessment which offers a way to bring automated individualization to the assessment of higher order skills in higher education mathematics.},
  langid = {english},
  keywords = {assessment,computer-aided assessment,COMPUTER-AIDED ASSESSMENT,e-assessment,MARKING,Partially-automated assessment,skills,STUDENT},
  file = {/Users/colin.madland/Zotero/storage/V5KIKBKD/rowlettPartiallyautomatedIndividualizedAssessment2022.pdf}
}

@article{rowleyEvolvedLandscapeEPortfolios2018,
  title = {The Evolved Landscape of {{ePortfolios}}: {{Current}} Values and Purposes of Academic Teachers and Curriculum Designers},
  shorttitle = {The Evolved Landscape of {{ePortfolios}}},
  author = {Rowley, Jennifer and Munday, Jennifer},
  year = {2018},
  month = feb,
  journal = {Journal of Teaching and Learning for Graduate Employability},
  volume = {9},
  number = {1},
  pages = {2},
  issn = {1838-3815},
  doi = {10.21153/jtlge2018vol9no1art669},
  urldate = {2022-10-31},
  abstract = {As ePortfolios are increasingly being used in universities to help develop self-reflective practitioners, academic teachers and students need to develop the skills and processes required to implement them. During 2015, a series of webinars was presented by a cross-university team to provide professional development for academic teachers, curriculum designers and other staff interested in initiating or extending ePortfolio learning in their institutions. A survey was conducted with participants to gauge the depth of understanding and use of ePortfolios in degree programs. The survey aimed to clarify participants' perception of the value of ePortfolio tools in Australian universities, and to identify future directions for developing knowledge and learning related to ePortfolios. Through the survey questions participants were able to provide information anonymously about their knowledge and use of ePortfolios. Respondents were also invited to be interviewed. Nine interviews, conducted in 2016, explored ePortfolio-users' opinions of the learning tool. The results indicate that teachers' use of the ePortfolio as a learning tool has evolved beyond that reported in the current literature. Furthermore, when used for reflection, assessment and documenting professional standards, the ePortfolio tool contributes to the students' development of skills required to transition to future careers.},
  file = {/Users/colin.madland/Zotero/storage/LGLL5C4R/rowleyEvolvedLandscapeEPortfolios2018.pdf}
}

@article{royAboriginalWorldviewsEpidemiological2014,
  title = {Aboriginal Worldviews and Epidemiological Survey Methodology: {{Overcoming}} Incongruence},
  shorttitle = {Aboriginal Worldviews and Epidemiological Survey Methodology},
  author = {Roy, Amrita},
  year = {2014},
  month = apr,
  journal = {International Journal of Multiple Research Approaches},
  volume = {8},
  number = {1},
  pages = {117--128},
  issn = {1834-0806, 1834-0814},
  doi = {10.5172/mra.2014.8.1.117},
  urldate = {2019-03-30},
  langid = {english}
}

@misc{RRU,
  title = {{{RRU}}}
}

@article{rudolphChatGPTBullshitSpewer2023,
  title = {{{ChatGPT}}: {{Bullshit}} Spewer or the End of Traditional Assessments in Higher Education?},
  shorttitle = {{{ChatGPT}}},
  author = {Rudolph, J{\"u}rgen and Tan, Samson and Tan, Shannon},
  year = {2023},
  month = jan,
  journal = {Journal of Applied Learning \& Teaching},
  volume = {6},
  number = {1},
  issn = {2591-801X, 2591-801X},
  doi = {10.37074/jalt.2023.6.1.9},
  urldate = {2023-02-02},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/2DXSGXP9/rudolphChatGPTBullshitSpewer2023.pdf}
}

@article{ruitenbergThatJustYour2007,
  title = {``{{That}}'s {{Just Your Opinion}}!'' - ``{{American Idol}}'' and the {{Confusion Between Pluralism}} and {{Relativism}}},
  author = {Ruitenberg, Claudia},
  year = {2007},
  journal = {Philosophical Inquiry in Education},
  volume = {16},
  number = {1},
  pages = {55--59},
  abstract = {Many student-teachers (and the students they teach) fail to understand the difference between opinions in the sense of preferences, and opinions in the sense of judgments. The phrase ``That's just your opinion!'' (as wielded by contestants on the television series ``American Idol'') is used to shield not only preferences but also judgments from public scrutiny. This misunderstanding springs from confusion between pluralism and relativism. Students' fear of moral absolutism leads them to espouse relativism when they should be promoting pluralism. Within a conception of education as a social practice that mediates between the private and the public, students must learn both to justify their own judgments and to examine the judgments and justifications that others provide. This requires that students learn to distinguish ``just my opinion'' and ``just your opinion'' from morally significant judgments.}
}

@article{rumbleReinventingDistanceEducation2001,
  title = {Re-Inventing Distance Education, 1971-2001},
  shorttitle = {Re-Inventing Distance Education, 1971-2001},
  author = {Rumble, Greville},
  year = {2001},
  month = jan,
  journal = {International Journal of Lifelong Education},
  volume = {20},
  pages = {31--43},
  issn = {0260-1370},
  doi = {10.1080/02601370010008246},
  urldate = {2012-02-05},
  abstract = {Over the period 1971?2001, distance education has changed enormously. This article identifies five key changes. Firstly, and technologically, the period opened with the establishment of one of the most successful of the multi-media based distance education systems, the UK Open University, but ends with the rush towards online education. This technological change underpins a second change, a pedagogical shift within distance education from a transmission model of education towards a constructivist model exploiting computer-mediated communication. Paradoxically this has occurred just when some commentators have seen the dehumanization of the traditional education. The third change has been the growing acceptance of distance education, and with this, its expansion. Linked to this is the fourth change ? the change in the way distance education is perceived. It has moved from low status to acceptance, with increased confidence as its methods are adopted across education as a whole. Finally, distance education can be seen to be evolving from an essentially modernist (bureaucratic or Fordist) form of education into a post-modernist phenomenon with a focus on the student as consumer, on flexibility and global reach.},
  annotation = {1-2}
}

@article{rupnowPerturbedSystemHow2020,
  title = {A {{Perturbed System}}: {{How Tenured Faculty Responded}} to the {{COVID-19 Shift}} to {{Remote Instruction}}},
  author = {Rupnow, Rachel L and LaDue, Nicole D and James, Nicole M and {Bergan-Roller}, Heather E},
  year = {2020},
  journal = {Journal of chemical education},
  volume = {97},
  number = {9},
  pages = {2397--2407},
  publisher = {{American Chemical Society and Division of Chemical Education, Inc}},
  address = {WASHINGTON},
  issn = {0021-9584},
  doi = {10.1021/acs.jchemed.0c00802},
  abstract = {This study investigates six university professors' reflections on the shift to remote instruction during the Spring 2020 semester in response to the COVID-19 global pandemic. The rapid shift in instructional platform presents an opportunity to learn from unresolved challenges that persisted through the semester. Here we present a qualitative study of how experienced (i.e., associate or full) chemistry professors report their teaching practices in light of the COVID-19 disruptions. We observed four major themes: personal factors, contextual factors of the structure and culture, teacher thinking, and teachers' practice. These themes revealed that the professors in this study adapted quickly using institutionally offered platforms, modified their courses as minimally as possible, struggled with assessment, and held diverging beliefs about teaching and students. The outcomes of this study have implications for ongoing efforts to reform instructional practices at the institutional and departmental level. Specifically, we recommend similar studies to ascertain current faculty beliefs and instructional practices in other departments in order to identify shared visions for change and effective supports for enacting that change.},
  keywords = {Adjustment (to Environment),Chemical Education Research,Chemistry,Chemistry Multidisciplinary,College Faculty,College Science,College students,Colleges & universities,Context Effect,COVID-19,Cultural factors,Distance Education,Education & Educational Research,Education Scientific Disciplines,Educational Technology,Electronic Learning,Higher education,Individual Characteristics,Online Courses,Online instruction,Pandemics,Physical Sciences,Qualitative research,Remote computing,School Closing,Science & Technology,Science Instruction,Social Sciences,Student Evaluation,Teacher Attitudes,Teachers,Teaching,Teaching Methods,Tenure,Undergraduate Study}
}

@book{ruppHandbookCognitionAssessment2016,
  title = {The {{Handbook}} of {{Cognition}} and {{Assessment}}: {{Frameworks}}, {{Methodologies}}, and {{Applications}}},
  shorttitle = {The {{Handbook}} of {{Cognition}} and {{Assessment}}},
  editor = {Rupp, Andr{\'e} A. and Leighton, Jacqueline P.},
  year = {2016},
  month = nov,
  publisher = {John Wiley \& Sons, Inc.},
  address = {Hoboken, NJ, USA},
  doi = {10.1002/9781118956588},
  urldate = {2020-10-14},
  isbn = {978-1-118-95658-8 978-1-118-95657-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/FFXD8U6K/ruppHandbookCognitionAssessment2016.pdf}
}

@incollection{ruppIntroductionHandbook2016,
  title = {Introduction to {{Handbook}}},
  booktitle = {The {{Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {Rupp, Andr{\'e} A. and Leighton, Jacqueline P.},
  editor = {Rupp, Andr{\'e} A. and Leighton, Jacqueline P.},
  year = {2016},
  month = nov,
  pages = {1--11},
  publisher = {John Wiley \& Sons, Inc.},
  address = {Hoboken, NJ, USA},
  doi = {10.1002/9781118956588.ch1},
  urldate = {2020-10-14},
  isbn = {978-1-118-95658-8 978-1-118-95657-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/N58L6J94/ruppIntroductionHandbook2016.pdf}
}

@article{russellNoSignificantDifferenceND,
  title = {No {{Significant Difference}}},
  author = {Russell, Thomas},
  year = {ND}
}

@book{russellProjectManagementTrainers2000,
  title = {Project {{Management}} for {{Trainers}}},
  author = {Russell, Lou},
  year = {2000},
  publisher = {ASTD Press},
  address = {Alexandria, VA}
}

@article{russellUsingOnlineEnvironment2006,
  title = {Using the Online Environment in Assessment for Learning: A Case-study of a Web-based Course in Primary Care},
  shorttitle = {Using the Online Environment in Assessment for Learning},
  author = {Russell, Jill and Elton, Lewis and Swinglehurst, Deborah and Greenhalgh, Trisha},
  year = {2006},
  month = aug,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {31},
  number = {4},
  pages = {465--478},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602930600679209},
  urldate = {2022-05-04},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/3B7DDMBX/russellUsingOnlineEnvironment2006.pdf}
}

@article{Rust_2002,
  title = {The Impact of Assessment on Student Learning How Can the Research Literature Practically Help to Inform the Development of Departmental Assessment Strategies and Learner Centred Assessment Practices},
  author = {Rust, Chris},
  year = {2002},
  journal = {Active Learning in Higher Education},
  doi = {10/ds53hn},
  abstract = {In the context of a worldwide paradigm shift towards student-centred outcomes-based approaches, and at a time when many UK departments are developing learning, teaching and assessment strategies, this article reviews what the research literature says about the impact of assessment on students' learning. It then proceeds to translate that into practical suggestions for practice with the specific intention that this should help to inform departments in the development of appropriate assessment strategies and learner-centred assessment practices which meet the Quality Assurance Agency (QAA) general principles on assessment.},
  mag_id = {2165281830},
  pmcid = {null},
  pmid = {null},
  keywords = {guskey}
}

@article{rustSocialConstructivistAssessment2005,
  title = {A Social Constructivist Assessment Process Model: How the Research Literature Shows Us This Could Be Best Practice},
  author = {Rust, Chris and O'Donovan, Berry and Price, Margaret},
  year = {2005},
  journal = {Assessment and evaluation in higher education},
  volume = {30},
  number = {3},
  pages = {231--240},
  publisher = {{Taylor and Francis Ltd}},
  address = {Abingdon},
  issn = {0260-2938},
  doi = {10.1080/02602930500063819},
  abstract = {Although assessment is acknowledged as vitally important in its effect on students' approaches to learning, there is much criticism of assessment practice. This paper argues that if a social constructivist approach is applied to the assessment process many of the problems could be overcome. It describes what a social constructivist approach to assessment would look like and gives practical examples, from the research literature, of ways it could be implemented.},
  keywords = {Achievement tests,Best practice,Constructivism (Learning),Educational evaluation,Evaluation Methods,Feedback,Higher Education,Learning,Literary criticism,Research methodology,Student Evaluation,Student Participation},
  file = {/Users/colin.madland/Zotero/storage/KVZNX7UP/rustSocialConstructivistAssessment2005.pdf}
}

@article{ryanDigitalStorytellingStudent2021,
  ids = {ryanDigitalStorytellingStudent2021a},
  title = {Digital Storytelling, Student Engagement and Deep Learning in {{Geography}}},
  author = {Ryan, Anne Wally and Aasetre, J{\o}rund},
  year = {2021},
  journal = {Journal of geography in higher education},
  volume = {45},
  number = {3},
  pages = {380--396},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0309-8265},
  doi = {10.1080/03098265.2020.1833319},
  abstract = {This study aims to provide insight into the usefulness of integrating digital stories in teaching and learning activities in Geography in higher education. More specifically, to identify how digital stories can enhance deep learning in Geography. Deep learning indicates understanding and creative use of knowledge in new settings, i.e. the highest levels in the revised version of Bloom's taxonomy, a knowledge dimension from factual knowledge to meta-knowledge. Data are based on two evaluation processes: a university student who conducted a process of making digital stories in a class of upper secondary school students, and secondly, by 41 university students who did a two-step evaluation process of these stories. Despite the Norwegian learning context, from which data are obtained, the approaches will largely be recognizable in other countries because of the general learning principles and framework for teaching geographical topics. The study shows that digital storytelling has the potential to improve interactive learning outcome that can enhance ethical and deep learning of geography, including "the affective domain" of how geography is felt and valued. The awareness of integration of technology into the learning process is underlined.},
  keywords = {Affective Behavior,Case Studies,College Students,Colleges & universities,Deep learning,digital storytelling,Education & Educational Research,Educational Principles,Ethics,Evaluation Methods,Foreign Countries,Geography,Geography Instruction,Information Technology,Interactive learning,Learning Activities,Learning Processes,Narration,Outcomes of Education,Secondary School Students,Social Sciences,Story Telling,storytelling,Student Attitudes,Student Evaluation,Students,Taxonomy,Teaching Methods,Technology Integration}
}

@incollection{rybakovaHumanizingOnlineAssessment2020,
  title = {Humanizing {{Online Assessment}}: {{Screencasting}} as a {{Multimedia Feedback Tool}} for {{First Generation College Students}}},
  shorttitle = {Humanizing {{Online Assessment}}},
  booktitle = {Advances in {{Educational Technologies}} and {{Instructional Design}}},
  author = {Rybakova, Katie},
  editor = {Sullivan, Pamela M. and Lantz, Jessica L. and Sullivan, Brian A.},
  year = {2020},
  pages = {500--518},
  publisher = {IGI Global},
  doi = {10.4018/978-1-7998-0246-4.ch022},
  urldate = {2021-12-28},
  abstract = {In this chapter, the author will investigate the use of screencasting as a multimedia feedback tool in two classes--- a college level introduction to literature class, and a computers across the curriculum class geared towards K-12 preservice teachers. After situating the concepts of modeling and feedback strategies within seminal and contemporary scholarships, the author will provide a practical and anecdotal narrative of the uses of screencasting as an assessment tool within the frame of literacy pedagogies. In identifying the ways in which screencasting (video feedback) can be leveraged to enhance personalized instruction, the author will examine: 1) how technology can be used as a literacy practice; and 2) how a teacher preparation professor can model the practice of technology as a literacy for assessment purposes.},
  isbn = {978-1-7998-0246-4 978-1-7998-0247-1},
  file = {/Users/colin.madland/Zotero/storage/ZX78WVVS/rybakovaHumanizingOnlineAssessment2020.pdf}
}

@incollection{rybasHumanizingAssessmentCall2021,
  title = {Toward {{Humanizing Assessment}}: {{A Call}} to {{Find Justice}} to {{Students}}, to {{Faculty}}, and to {{Data}}},
  shorttitle = {Toward {{Humanizing Assessment}}},
  booktitle = {Innovations in {{Higher Education Teaching}} and {{Learning}}},
  author = {Rybas, Natalia and Quenette, Andrea},
  editor = {Sengupta, Enakshi and Blessinger, Patrick and Makhanya, Mandla},
  year = {2021},
  month = jan,
  pages = {105--116},
  publisher = {Emerald Publishing Limited},
  doi = {10.1108/S2055-364120200000035011; https://web.archive.org/web/20211228204132/https://www.emerald.com/insight/content/doi/10.1108/S2055-364120200000035011/full/html},
  urldate = {2021-12-28},
  isbn = {978-1-83909-861-1 978-1-83909-860-4},
  keywords = {archived}
}

@article{sabbaghanMultimodalEffectsVoiceBased2019,
  title = {The {{Multimodal Effects}} of {{Voice-Based Asynchronous Technology-Mediated Communication}} on {{EAP Speaking Performance}}},
  author = {Sabbaghan, Soroush and Peglar, Murray and Tweedie, M. Gregory},
  year = {2019},
  month = jan,
  journal = {TESL Canada Journal},
  volume = {36},
  number = {3},
  pages = {82--109},
  publisher = {TESL Canada Journal},
  issn = {0826-435X},
  doi = {10.18806/tesl.v36i3.1322},
  abstract = {This study investigates how using a voice-based Asynchronous Technology-Mediated Communication framework (ATMC) can affect English for Academic Purposes (EAP) students' fluency, accuracy, and intelligibility. Research has highlighted the benefits of ATMC in improving various elements of spoken communication, but to date, its application to EAP contexts has been little studied. In EAP speaking/listening courses at a large Canadian university, a team of instructor-researchers developed a system to provide learners more speaking and listening practice opportunities and to give individualized video feedback (veedback) on speaking performance. The instructor-researchers used a practitioner enquiry research methodology to investigate the effectiveness of the voice-based ATMC for 14 participants, drawing upon qualitative data from student interviews and the instructor's qualitative and quantitative assessment of the students' responses to tasks. Findings indicate that the system resulted in overall gains in fluency, accuracy, and intelligibility due to a combination of the voice-based ATMC design, repetition and practice, and the veedback. Qualitative comments from participants indicate personalized feedback led to increased motivation. The framework described in this article, therefore, represents several important benefits for the application of voice-based ATMCs in EAP classrooms.},
  keywords = {Accuracy,Asynchronous Communication,Canada,College Students,Communication Skills,Comprehension,English (Second Language),English for Academic Purposes,Feedback (Response),Foreign Countries,Language Fluency,Listening Skills,Program Effectiveness,Second Language Instruction,Speech Skills,Video Technology},
  file = {/Users/colin.madland/Zotero/storage/6EVZHV7C/sabbaghanMultimodalEffectsVoiceBased2019.pdf}
}

@article{sadiEAssessmentJordanUniversities2021,
  title = {E-{{Assessment}} at {{Jordan}}'s {{Universities}} in the {{Time}} of the {{COVID-19 Lockdown}}: {{Challenges}} and {{Solutions}}},
  author = {Sa'di, Rami A. and Abdelraziq, Ahmad and Sharadgah, Talha A.},
  year = {2021},
  month = apr,
  journal = {Arab World English Journal},
  pages = {37--54},
  publisher = {Arab World English Journal},
  issn = {2229-9327},
  abstract = {This study aims to delineate the observations of instructors at Princess Sumaya University for Technology (PSUT) in Jordan with regards to online assessment of their students in the time of the Coronavirus lockdown. Specifically, the study attempts to find out whether universities are prepared for online assessment during the lockdown and to probe feasible solutions to the challenges that hinder proper assessment in a virtual learning environment (VLE). As the challenges are determined, the study suggests a number of practical solutions. Data on faculty's observations were obtained by means of an online survey. Eighty-three faculty members participated in this study. The findings showed that universities swiftly shifted to e-classes during the lockdown but that they were not adequately primed for an appropriate assessment in an online environment. The findings further showed that instructors were skeptical about the efficiency of remote assessment of their students. In addition, faculty members believed there was still a long way to go with regards to (1) the unavailability of reliable software to preclude academic dishonesty; (2) some faculty being unable to assess their students in VLE as it was their first experience; and (3) formative assessment not having been given enough attention. It is concluded that universities should have an exigency strategy for any sudden future lockdowns. This strategy includes, among other things, intensive e-teaching and e-testing training for faculty, high-tech invigilation and plagiarism software, reliable e-learning platforms with sufficient Internet bandwidth, setting up an e-assessment council at the university level.},
  keywords = {Barriers,College Faculty,Computer Assisted Testing,COVID-19,Educational Needs,Educational Technology,Foreign Countries,Formative Evaluation,Jordan,No DOI found,Online Courses,Pandemics,Program Effectiveness,School Closing,Student Evaluation,Summative Evaluation,Teacher Attitudes,Teacher Competencies,Technology Uses in Education}
}

@article{sadlerFeedforwardPracticesSystematic2022,
  title = {Feedforward Practices: A Systematic Review of the Literature},
  author = {Sadler, Ian and Reimann, Nicola and Sambell, Kay},
  year = {2022},
  month = may,
  journal = {Assessment \& Evaluation in Higher Education},
  pages = {1--16},
  publisher = {Routledge},
  issn = {0260-2938},
  doi = {10.1080/02602938.2022.2073434},
  abstract = {AbstractThe notion of ?feedforward? has emerged as popular with practitioners, and there has been an upsurge in publications which include this term. This interpretivist and conceptual systematic review sought to consider the different forms of educational practices that are framed in relation to feedforward. The initial search of four electronic databases found 1076 articles published between 2007 and 2019, which were reduced to 68 once duplicates had been removed and exclusion/inclusion criteria applied during screening and eligibility procedures. An iterative meta-ethnographic approach to analysis resulted in the identification of five main practices, framed as feedforward. These were: alignment and timing (41\%); use (25\%); comments (18\%); self-review (9\%); and teaching (7\%). The vast majority involved a process where student improvement was a key goal, but the design of this process differed between practices. A large proportion supported improvement from one task to the next, almost exclusively within the ?future horizon? of the module/study unit, while only a small proportion of articles focuses on improving the amount, nature or quality of the information delivered to learners. Evidence of student sense-making and uptake was rarely sought, and few practices offered genuine opportunities for student agency, self-regulation and the development of evaluative judgment.}
}

@article{sadlerFormativeAssessmentDesign1989,
  title = {Formative Assessment and the Design of Instructional Systems},
  author = {Sadler, D. Royce},
  year = {1989},
  month = jun,
  journal = {Instructional Science},
  volume = {18},
  number = {2},
  pages = {119--144},
  issn = {0020-4277, 1573-1952},
  doi = {10.1007/BF00117714},
  urldate = {2022-11-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/XI56HURU/sadlerFormativeAssessmentDesign1989.pdf}
}

@article{sadlerVariationDevelopmentTeachers2018,
  title = {Variation in the Development of Teachers' Understandings of Assessment and Their Assessment Practices in Higher Education},
  author = {Sadler, Ian and Reimann, Nicola},
  year = {2018},
  journal = {Higher education research and development},
  volume = {37},
  number = {1},
  pages = {131--144},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0729-4360},
  doi = {10.1080/07294360.2017.1344199},
  abstract = {This paper reports a study into the development of staff understanding of assessment and assessment practice. Eight teachers from two universities constructed an initial concept map about assessment that was discussed in a one-to-one semi-structured interview. A year later, a new map was created and the interview focused on change in thinking and practice. Multiple models of assessment were evident in the participants' understandings at the same time and change was characterised by subtle evolution in thinking. Development in practice was more significant and often associated with the foregrounding of assessment for learning. Vignettes are used to illustrate the variation in nature and scale of development. Interplay between this development of practice and understanding was multidirectional and external context played an important role. The approach offers detailed insight into the relationship between assessment thinking and practice and demonstrates that both research and academic development need to go beyond conventional approaches to conceptualising the development of academics and take account of the finer grained complexities of assessment thinking and practices.},
  keywords = {academic development,assessment for learning,College Faculty,Concept Mapping,Conceptions,Education & Educational Research,Evaluation,Evaluation Criteria,Familiarity,Foreign Countries,Formative Evaluation,Higher Education,Interpersonal Communication,Knowledge Base for Teaching,Knowledge Level,Program Implementation,Social Sciences,Teacher Attitudes,Teacher Collaboration,Technology Uses in Education,Vignettes},
  file = {/Users/colin.madland/Zotero/storage/Q8HWSSDT/sadlerVariationDevelopmentTeachers2018.pdf}
}

@article{sadlerVariationDevelopmentTeachers2018a,
  title = {Variation in the Development of Teachers' Understandings of Assessment and Their Assessment Practices in Higher Education},
  author = {Sadler, Ian and Reimann, Nicola},
  year = {2018},
  month = jan,
  journal = {Higher Education Research \& Development},
  volume = {37},
  number = {1},
  pages = {131--144},
  issn = {0729-4360, 1469-8366},
  doi = {10.1080/07294360.2017.1344199},
  urldate = {2023-08-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/IDU3IYQD/sadlerVariationDevelopmentTeachers2018a.pdf}
}

@article{safarBYODHigherEducation2018,
  title = {{{BYOD}} in {{Higher Education}}: {{A Case Study}} of {{Kuwait University}}},
  author = {Safar, Ammar H.},
  year = {2018},
  journal = {Journal of Educators Online},
  volume = {15},
  number = {2},
  issn = {EISSN-1547-500X},
  doi = {10/gmbv2f},
  abstract = {One key trend in the educational application of new technologies involves the integration of the "bring your own device" (BYOD) initiative. This study's objective was to determine the impact and usefulness of a BYOD program for students' learning and academic excellence at Kuwait University (KU). A quasiexperimental design was employed that compared classroom assessment scores and final grades for control (i.e., non-BYOD) and experimental (BYOD) student groups. The results showed that BYOD intervention had a statistically significant positive effect on students' learning and achievement, as measured by improvement in test scores, quality of work on projects, and final grades, along with heightening students' motivation, attitudes, and involvement in the course.},
  langid = {english},
  keywords = {College Students,Educational Technology,Females,Foreign Countries,Grades (Scholastic),Handheld Devices,Laptop Computers,Ownership,Program Effectiveness,Scores,Student Attitudes,Student Motivation,Student Participation,Technology Uses in Education,Telecommunications,Tests}
}

@book{safarywa-mbalekaSageHandbookOnline2023,
  title = {{The Sage Handbook of Online Higher Education}},
  author = {{Safary Wa-Mbaleka} and {Kelvin Thompson} and {Leni Casimiro}},
  year = {2023},
  publisher = {SAGE Publications Ltd},
  address = {[S.l.]},
  abstract = {The SAGE Handbook of Online Higher Education~presents a cutting-edge collection of 50 essays that explores the rapidly evolving landscape of online teaching and learning in higher education. Assembled and contributed by a team of leading experts, the Handbook adopts a uniquely holistic approach to examining the needs of online education. Chapters bring together voices from diverse and international backgrounds to provide insights applicable to a broad range of contexts, and present practical strategies for planning, delivering quality online higher education. The handbook covers a wide range of topics, including online pedagogy, instructional design, student engagement, technological innovation, assessment, leadership, and the developing role of online education in the context of broader societal and cultural shifts. The SAGE Handbook of Online Higher Education~is an essential resource for educators, researchers, policymakers, and practitioners who seek to understand and shape the future of higher education in the digital age. Section 1: Fundamentals of Online Education Section 2: Online Education Around the World Section 3: Online Instructional Design Section 4: Online Instructional Delivery Section 5: Instructional Technology for Online Education Section 6: Online Education Administration and Management Section 7: Student Support Services},
  isbn = {978-1-5296-0436-8},
  langid = {Undetermined},
  keywords = {EDUCATION / Distance Open & Online Education,EDUCATION / Schools / Levels / Higher,Educational technology,Internet in higher education,Web-based instruction}
}

@article{safonovPostDigitalWorldPandemic2020,
  title = {Post-{{Digital World}}, {{Pandemic}} and {{Higher Education}}},
  author = {Safonov, Alexander Sergeevich and Mayakovskaya, Anastasia Vladimirovna},
  year = {2020},
  journal = {International Journal of Higher Education},
  volume = {9},
  number = {8},
  pages = {90--94},
  issn = {ISSN-1927-6044},
  doi = {10/gmbv34},
  abstract = {The article examines the prospects that open up for the implementation of the educational process in higher educational institutions, as well as the problems faced by the modern higher education system in the context of the transition to distance learning caused by the current epidemiological situation in the post-digital world. On the basis of the data from a student survey made during the COVID-19 pandemic, who studied using distance digital technologies, we have analyzed the current state of higher education. Consequently, the authors have concluded that the universities, implementing programs for the digitalization of the educational process and the creation of massive online courses, are actually away from the real social circles of the post-digital society. Given the results, the authors argue that digitalization is not a way to resolve the internal contradictions of higher education. Moreover, digitalization as a goal of higher education somewhat hides the real contradictions of the learning process.},
  langid = {english},
  keywords = {College Students,COVID-19,Disease Control,Distance Education,Educational Change,Educational Objectives,Epidemiology,Foreign Countries,Higher Education,Learning Processes,Online Courses,Pandemics,Program Implementation,Student Attitudes,Student Surveys,Teaching Methods,Universities}
}

@article{sagriDigitalStorytellingComics2018,
  title = {Digital {{Storytelling}}, {{Comics}} and {{New Technologies}} in {{Education}}: {{Review}}, {{Research}} and {{Perspectives}}},
  author = {Sagri, Maria and Sofos, Filippos and Mouzaki, Despoina},
  year = {2018},
  month = jan,
  journal = {International Education Journal: Comparative Perspectives},
  volume = {17},
  number = {4},
  pages = {97--112},
  publisher = {International Education Journal: Comparative Perspectives},
  issn = {2202-493X},
  abstract = {This work reviews the current application of one of the most widely used techniques in education around the world: Digital Storytelling (DS), along with comic and animation tools, and presents a study about the Greek educational system as well as posing questions concerning the form of a new study, design, implementation and assessment of educational project across all educational levels. Nowadays, people and students at all educational levels in the developed world are surrounded by multiple electronic media and are familiar with a variety of pictures, video and information from early childhood. The educational process, as it proceeds in parallel with fast technological and societal evolution, tries to smoothly adjust new educational methods without abandoning traditional teaching and moving away from its main aim: the establishment of knowledge.},
  keywords = {Animation,Cartoons,College Faculty,Computer Uses in Education,Elementary School Students,Elementary School Teachers,Foreign Countries,Greece,High School Students,No DOI found,Secondary School Teachers,Story Telling,Student Needs,Technological Advancement}
}

@article{sahinClassroomResponseSystems2019,
  ids = {sahinClassroomResponseSystems2019a},
  title = {Classroom {{Response Systems}} as a {{Formative Assessment Tool}}: {{Investigation}} into {{Students}}' {{Perceived Usefulness}} and {{Behavioural Intention}}},
  author = {Sahin, Muhittin},
  year = {2019},
  month = jan,
  journal = {International Journal of Assessment Tools in Education},
  volume = {6},
  number = {4},
  pages = {693--705},
  publisher = {International Journal of Assessment Tools in Education},
  issn = {2148-7456},
  abstract = {Assessments are conducted to determine the effectiveness of learning. One type of these assessments are formative assessment, which aims to fill the gap between the learner's present situation and the desired situation by giving feedback to learners. For this purpose, Classroom Response Systems can be used in large groups. Paper-based tests, Kahoot, Quizizz, and, Plickers were used for formative assessment. Multiple-choice tests can be created for students with these applications. Students can connect to Kahoot and Quizizz applications via any computer, tablet or mobile phones with an internet connection and answer the questions in the test. For the Plickers application, the questions are displayed by the instructor in an area that all students can see. Students indicate their responses by lifting their paper which has QR code. The instructor scans these QR codes with the help of a mobile device and the students' answers are seen directly. In this context, the perceived usefulness and behavioral intention of the students to use different classroom response systems were investigated. The research was conducted with freshman students at a state university and continued for four weeks. Different applications were presented to the students as like that a paper-based test, Kahoot, Quizizz, and Plickers. When the findings were examined, it was found that students noted Kahoot, Quizizz, and Plickers applications were statistically more useful than the paper-based test. Based on these results, it can be said that students prefer to use technology-supported classroom response systems instead of the paper-based test.},
  keywords = {Audience Response Systems,Behavioral intention,Classroom response systems,College Freshmen,Computer Oriented Programs,Computer Uses in Education,Formative assessment,Formative Evaluation,Intention,No DOI found,Perceived usefulness,Student Attitudes,Student Behavior},
  file = {/Users/colin.madland/Zotero/storage/KPGRJBZ4/sahinClassroomResponseSystems2019.pdf}
}

@article{sahniLearningAnalyticsFuture2023,
  title = {Is {{Learning Analytics}} the {{Future}} of {{Online Education}}? : {{Assessing Student Engagement}} and {{Academic Performance}} in the {{Online Learning Environment}}},
  author = {Sahni, Jolly},
  year = {2023},
  journal = {International journal of emerging technologies in learning},
  volume = {18},
  number = {2},
  pages = {33},
  publisher = {International Association of Online Engineering (IAOE)},
  address = {Vienna},
  issn = {1863-0383},
  doi = {10.3991/ijet.v18i02.32167},
  abstract = {Educational structures have been evolving, that even so rapidly with the revolution of information technology and internet. Recent pandemic and its after effects are still looming over the globe, posing as challenge and an opportunity for educators. Online education was one such innovation, which has changed the dynamics of education around the world. The purpose of the paper is three-fold, first, to assess the levels of student engagement in the online learning environment, second, to examine how student engagement is related to their academic performance using learning analytic tools and third, to propose an integrated learning analytics framework. The study used, an exploratory research method and the data was collected from multiple sources; LMS Logs, self-administered questionnaires from students, and interviews with the instructor. The study was conducted at a course level in a private university. The finding suggests a positive relationship between student engagement and their academic performance and advocate the application of an analytics plug-in on LMS which supported instructors in identifying students at risk and providing them with real-time feedback aiming to improve their performance. The study provides insights into the field of online learning and offers evidence-based recommendations to educators. The utilization of Learning Analytics to examine student engagement and understanding of how students learn would contribute to the development of learning theories and in designing an appropriate digital learning environment that supports and improves their learning.},
  keywords = {Academic achievement,Distance learning,Education,Learning analytics,School environment,Student participation},
  file = {/Users/colin.madland/Zotero/storage/YPKVCUYG/sahniLearningAnalyticsFuture2023.pdf}
}

@article{salas-pilcoArtificialIntelligenceApplications2022,
  title = {Artificial Intelligence Applications in {{Latin American}} Higher Education: A Systematic Review},
  author = {{Salas-Pilco}, Sdenka Zobeida and Yang, Yuqin},
  year = {2022},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {19},
  number = {1},
  pages = {1--20},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-022-00326-w},
  abstract = {Over the last decade, there has been great research interest in the application of artificial intelligence (AI) in various fields, such as medicine, finance, and law. Recently, there has been a research focus on the application of AI in education, where it has great potential. Therefore, a systematic review of the literature on AI in education is therefore necessary. This article considers its usage and applications in Latin American higher education institutions. After identifying the studies dedicated to educational innovations brought about by the application of AI techniques, this review examines AI applications in three educational processes: learning, teaching, and administration. Each study is analyzed for the AI techniques used, such as machine learning, deep learning, and natural language processing, the AI tools and algorithms that are applied, and the main education topic. The results reveal that the main AI applications in education are: predictive modelling, intelligent analytics, assistive technology, automatic content analysis, and image analytics. It is further demonstrated that AI applications help to address important education issues (e.g., detecting students at risk of dropping out) and thereby contribute to ensuring quality education. Finally, the article presents the lessons learned from the review concerning the application of AI technologies in higher education in the Latin American context.},
  keywords = {Algorithms,Artificial intelligence,Artificial intelligence (AI),Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Content analysis,Deep learning,Educational Technology,Higher Education,Higher education institutions,Humanities,Information Systems Applications (incl.Internet),Latin America,Law,Literature reviews,Machine learning,Natural language processing,Prediction models,Review Article,Statistics for Social Sciences,Systematic review,Technology-mediated educational innovations in Latin American higher education institutions},
  file = {/Users/colin.madland/Zotero/storage/IEW592Z5/salas-pilcoArtificialIntelligenceApplications2022.pdf}
}

@article{salesAssessmentPracticesHigher2013,
  title = {Assessment Practices in Higher Education the Experiences of Newly Appointed Academics in Professional Fields from a Phenomenological Perspective},
  author = {Sales, Rachel Mary},
  year = {2013},
  journal = {null},
  doi = {null},
  abstract = {For a novice academic, the first experience of marking can be as memorable as preparing for and giving their first teaching session. Yet, while academic reflections and narratives abound for the latter, there is a paucity of literature regarding the former. This study begins to address this lack of literature through an exploration of the experiences of six newly appointed academics as they begin to mark students' coursework. In choosing interpretive phenomenology as the methodological and philosophical influences for this study, I committed to an approach which required a search for an ontological understanding of being involved in marking as a new academic, rather than an understanding of what is known about marking. Each participant's experience is illustrated through extracts from interviews that reflect rich descriptions of actions, behaviours and intentions, with the objective of evoking a `phenomenological nod' that might resonate with others. Towards the end of the first year each participant reflected on the challenges in relation to their experience of unanticipated emotional effects and ethical considerations. Confidence, processes, accountability and responsibility and judgements emerged from the data as common themes. The concept of being-in-the-world-of-marking demonstrates conceptually the experiences of the newly appointed academics as they began to come to know themselves as markers and academics; not through the learning of facts about marking, but through their understanding and self-interpretation of their own and others' marking practices. The experiences shared throughout the thesis support and further develop previous research findings, highlighting the need for additional training and guidance in relation to assessment and feedback within higher education, and reinforcing the necessity for newly appointed academics to be offered formal and informal mentorship and guidance in the theory and practice of assessment.},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@article{salesAssessmentPracticesHigher2013a,
  title = {Assessment Practices in Higher Education the Experiences of Newly Appointed Academics in Professional Fields from a Phenomenological Perspective},
  author = {Sales, Rachel Mary},
  year = {2013},
  journal = {null},
  doi = {null},
  abstract = {For a novice academic, the first experience of marking can be as memorable as preparing for and giving their first teaching session. Yet, while academic reflections and narratives abound for the latter, there is a paucity of literature regarding the former. This study begins to address this lack of literature through an exploration of the experiences of six newly appointed academics as they begin to mark students' coursework. In choosing interpretive phenomenology as the methodological and philosophical influences for this study, I committed to an approach which required a search for an ontological understanding of being involved in marking as a new academic, rather than an understanding of what is known about marking. Each participant's experience is illustrated through extracts from interviews that reflect rich descriptions of actions, behaviours and intentions, with the objective of evoking a `phenomenological nod' that might resonate with others. Towards the end of the first year each participant reflected on the challenges in relation to their experience of unanticipated emotional effects and ethical considerations. Confidence, processes, accountability and responsibility and judgements emerged from the data as common themes. The concept of being-in-the-world-of-marking demonstrates conceptually the experiences of the newly appointed academics as they began to come to know themselves as markers and academics; not through the learning of facts about marking, but through their understanding and self-interpretation of their own and others' marking practices. The experiences shared throughout the thesis support and further develop previous research findings, highlighting the need for additional training and guidance in relation to assessment and feedback within higher education, and reinforcing the necessity for newly appointed academics to be offered formal and informal mentorship and guidance in the theory and practice of assessment.},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@book{salmonEmoderatingStageModel2004,
  title = {E-Moderating: {{The}} 5 Stage Model},
  author = {Salmon, Gilly},
  year = {2004},
  volume = {2012}
}

@article{salvoAfricanAmericanMales2019,
  title = {African {{American Males Learning Online}}: {{Promoting Academic Achievement}} in {{Higher Education}}},
  author = {Salvo, Susan G. and Shelton, Kaye and Welch, Brett},
  year = {2019},
  journal = {Online Learning},
  volume = {23},
  number = {1},
  pages = {22--36},
  issn = {ISSN-2472-5749},
  abstract = {Online education is expanding within higher education. However, attrition rates for African American males enrolled in higher education in general, and in online courses specifically, is on the rise. Because the future of our nation depends on how well our educational institutions develop, nurture, and deploy talent, this study identified factors that promoted online course completion among African American male undergraduate students. The researchers interviewed 10 males who successfully completed online courses and identified significant themes. Factors that contributed to online course completion were financial assistance, prior academic achievement, previous information technology (IT) training, continuous academic enrollment, student selection of topics perceived as uncomplicated and less demanding or familiar due to sufficient prior knowledge, use of handheld digital devices, and a non-prejudicial learning environment. This study also revealed challenges and obstacles encountered by participants. Based on these findings, the researchers made recommendations that include strategies policymakers and educationalists can implement to promote academic achievement and degree attainment among African American males in higher education.},
  langid = {english},
  keywords = {Academic Achievement,Academic Persistence,African American Students,Best Practices,Course Selection (Students),Distance Education,Educational Environment,Electronic Learning,Enrollment,Financial Support,Handheld Devices,Inclusion,Information Technology,Males,No DOI found,Online Courses,Prior Learning,Technological Literacy,Undergraduate Students}
}

@book{sambellAssessmentLearningHigher2013,
  ids = {sambellAssessmentLearningHigher2013a},
  title = {Assessment for Learning in Higher Education},
  author = {Sambell, Kay and McDowell, Liz and Montgomery, Catherine},
  year = {2013},
  number = {Book, Whole},
  publisher = {Routledge},
  address = {Milton Park, Abingdon, Oxon [England];New York, N.Y;},
  doi = {10.4324/9780203818268},
  abstract = {"an invaluable guide for practitioners, quality assurors, university managers and students themselves who wish to better understand the importance of assessment for learning, and it will further scholarship in the field significantly." -Professor Sally Brown ~Assessment for Learning in Higher Education is a practical guide to Assessment for Learning (AfL); a term that has become internationally accepted in Higher Education and features in the learning and teaching strategies of many universities. It is also mandated by official bodies such as QAA in the UK. Many staff in Higher Education are uncertain about how to implement AfL, especially in times of increasingly constrained resources and this vital new guide provides solutions that make best use of assessment as a tool for learning. This book provides an important and accessible blend of practical examples of AfL in a variety of subject areas. The authors present practical, often small-scale and eminently 'do-able' ideas that will make its introduction achievable. It provides practical case examples both for new lecturers and more experienced staff who may be interested in embedding AfL principles and practice into their university teaching. AfL approaches go beyond minor adaptations to teaching practice, and signify a shift in the foundations of thinking about assessment. With this in mind there is guidance on the development of effective learning environments and communities through the use of: collaboration and dialogue authentic assessment formative assessment peer and self assessment student development for the long term innovative approaches to effective feedback . It provides helpful, realistic guidance backed up by relevant theory and is written in an accessible, jargon-free style, grounded in practical experience and brought to life via a wide range of illustrative examples and case studies. Assessment for Learning in Higher Education fills a vital gap in assessment literature and as AfL is increasingly on the Higher Education agenda, with the promotion of assessment as a tool for learning, this book will become an essential handbook to guide all academic practitioners.;"an invaluable guide for practitioners, quality assurors, university managers and students themselves who wish to better understand the importance of assessment for learning, and it will further scholarship in the field significantly." -Professor Sally Brown Assessment for Learning in Higher Education is a practical guide to Assessment for Learning (AfL); a term that has become internationally accepted in Higher Education and features in the learning and teaching strategies of many universities. It is also mandated by official bodies such as QAA in the UK. Many staff in Higher Education are uncertain about how to implement AfL, especially in times of increasingly constrained resources and this vital new guide provides solutions that make best use of assessment as a tool for learning. This book provides an important and accessible blend of practical examples of AfL in a variety of subject areas. The authors present practical, often small-scale and eminently `do-able' ideas that will make its introduction achievable. It provides practical case examples both for new lecturers and more experienced staff who may be interested in embedding AfL principles and practice into their university teaching. AfL approaches go beyond minor adaptations to teaching practice, and signify a shift in the foundations of thinking about assessment. With this in mind there is guidance on the development of effective learning environments and communities through the use of: collaboration and dialogue authentic assessment formative assessment peer and self assessment student development for the long term innovative approaches to effective feedback . It provides helpful, realistic guidance backed up by relevant theory and is written in an accessible, jargon-free style, grounded in practical experience and brought to life via a wide range of illustrative examples and case studies. Assessment for Learning in Higher Education fills a vital gap in assessment literature and as AfL is increasingly on the Higher Education agenda, with the promotion of assessment as a tool for learning, this book will become an essential handbook to guide all academic practitioners.;"an invaluable guide for practitioners, quality assurors, university managers and students themselves who wish to better understand the importance of assessment for learning, and it will further scholarship in the field significantly." -Professor Sally Brown~Assessment for Learning in Higher Education is a practical guide to Assessment for Learning (AfL); a term that has become internationally accepted in Higher Education and features in the learning and teaching strategies of many universities. It is also mandated by official bodies such as QAA in the UK. Many staff in Higher Education are uncertain about how to implement AfL, especially in times of increasingly constrained resources and this vital new guide provides solutions that make best use of assessment as a tool for learning.This book provides an important and accessible blend of practical examples of AfL in a variety of subject areas. The authors present practical, often small-scale and eminently 'do-able' ideas that will make its introduction achievable. It provides practical case examples both for new lecturers and more experienced staff who may be interested in embedding AfL principles and practice into their university teaching. AfL approaches go beyond minor adaptations to teaching practice, and signify a shift in the foundations of thinking about assessment. With this in mind there is guidance on the development of effective learning environments and communities through the use of:collaboration and dialogueauthentic assessment formative assessment peer and self assessment student development for the long term innovative approaches to effective feedback . It provides helpful, realistic guidance backed up by relevant theory and is written in an accessible, jargon-free style, grounded in practical experience and brought to life via a wide range of illustrative examples and case studies.Assessment for Learning in Higher Education fills a vital gap in assessment literature and as AfL is increasingly on the Higher Education agenda, with the promotion of assessment as a tool for learning, this book will become an essential handbook to guide all academic practitioners.;"an invaluable guide for practitioners, quality assurors, university managers and students themselves who wish to better understand the importance of assessment for learning, and it will further scholarship in the field significantly." -Professor Sally Brown Assessment for Learning in Higher Education is a practical guide to Assessment for Learning (AfL); a term that has become internationally accepted in Higher Education and features in the learning and teaching strategies of many universities. It is also mandated by official bodies such as QAA in the UK. Many staff in Higher Education are uncertain about how to implement AfL, especially in times of increasingly constrained resources and this vital new guide provides solutions that make best use of assessment as a tool for learning. This book provides an important and accessible blend of practical examples of AfL in a variety of subject areas. The authors present practical, often small-scale and eminently 'do-able' ideas that will make its introduction achievable. It provides practical case examples both for new lecturers and more experienced staff who may be interested in embedding AfL principles and practice into their university teaching. AfL approaches go beyond minor adaptations to teaching practice, and signify a shift in the foundations of thinking about assessment. With this in mind there is guidance on the development of effective learning environments and communities through the use of: collaboration and dialogue authentic assessment formative assessment peer and self assessment student development for the long term innovative approaches to effective feedback . It provides helpful, realistic guidance backed up by relevant theory and is written in an accessible, jargon-free style, grounded in practical experience and brought to life via a wide range of illustrative examples and case studies. Assessment for Learning in Higher Education fills a vital gap in assessment literature and as AfL is increasingly on the Higher Education agenda, with the promotion of assessment as a tool for learning, this book will become an essential handbook to guide all academic practitioners.;"an invaluable guide for practitioners, quality assurors, university managers and students themselves who wish to better understand the importance of assessment for learning, and it will further scholarship in the field significantly." -Professor Sally Brown Assessment for Learning in Higher Education is a practical guide to Assessment for Learning (AFL); a term that has become internationally accepted in Higher Education and features in the learning and teaching strategies of many universities. It is also mandated by official bodies such as QAA in the UK. Many staff in Higher Education are uncertain about how to implement AfL, especially in times of increasingly constrained resources and this vital new guide provides solutions that make best use of assessment as a tool for learning.This book provides an important and accessible blend of practical examples of AFL in a variety of subject areas. The authors present practical, often small-scale and eminently "do-able" ideas that will make its introduction achievable. It provides practical case examples both for new lecturers and more experienced staff who may be interested in embedding AfL principles and practice into their university teaching. AFL approaches go beyond minor adaptations to teaching practice, and signify a shift in the foundations of thinking about assessment. With this in mind there is guidance on the development of effective learning environments and communities through the use of: collaboration and dialogue authentic assessment formative assessment peer and self assessment student development for the long term innovative approaches to effective feedback . It provides helpful, realistic guidance backed up by relevant theory and is written in an accessible, jargon-free style, grounded in practical experience and brought to life via a wide range of illustrative examples and case studies.Assessment for Learning in Higher Education fills a vital gap in assessment literature and as AFL is increasingly on the Higher Education agenda, with the promotion of assessment as a tool for learning, this book will become an essential handbook to guide all academic practitioners"-- "Assessment for Learning in Higher Education is a practical guide to Assessment for Learning (AFL); a term that has become internationally accepted in Higher Education (HE) and features in the learning and teaching strategies of many universities, and is mandated by official bodies such as QAA in the UK. Many staff in HE are uncertain about how to implement AFL, especially in times of increasingly constrained resources, and this vital new guide provides low cost solutions that make best use of the essential new assessment tool. This book provides an important and accessible blend of practical examples of AFL in a variety of subject areas. AFL approaches require more than minor adaptations to teaching practice, but the authors present practical, often small-scale and eminently 'do-able' ideas that will make its introduction achievable. It provides practical case examples both for new lecturers and more experienced staff who may be interested in embedding AFL principles and practice into their university teaching"--;},
  isbn = {9780415586580;0415586585;0415586577;9780415586573;0203818261;9780203818268;},
  langid = {english},
  keywords = {Assessment,College students,EDUCATION / General,EDUCATION / Higher,EDUCATION / Testing & Measurement,Education Higher,Educational tests and measurements,Evaluation,Evaluation Methodology,Examinations,Higher Education,Methodology,Teaching & Learning,Universities and colleges},
  file = {/Users/colin.madland/Zotero/storage/ZLI9EHFU/sambellAssessmentLearningHigher2013.pdf}
}

@incollection{sammonsContributionMixedMethods2010,
  title = {The {{Contribution}} of {{Mixed Methods}} to {{Recent Research}} on {{Educational Effectiveness}}},
  booktitle = {{{SAGE Handbook}} of {{Mixed Methods}} in {{Social}} \& {{Behavioral Research}}},
  author = {Sammons, Pamela},
  editor = {Tashakkori, Abbas and Teddlie, Charles},
  year = {2010},
  edition = {2},
  publisher = {SAGE Publications, Inc.},
  address = {Thousand Oaks, California},
  doi = {10.4135/9781506335193},
  file = {/Users/colin.madland/Zotero/storage/HZIGTUDJ/sammonsContributionMixedMethods2010.pdf}
}

@article{sancho-gilMovingPredictableFailure2020,
  title = {Moving beyond the Predictable Failure of {{Ed-Tech}} Initiatives},
  author = {{Sancho-Gil}, Juana M. and {Rivera-Vargas}, Pablo and {Mi{\~n}o-Puigcerc{\'o}s}, Raquel},
  year = {2020},
  journal = {Learning, Media and Technology},
  volume = {45},
  number = {1},
  pages = {61--75},
  publisher = {Routledge},
  issn = {1743-9884},
  doi = {10/ggcdkp}
}

@article{sanCooperativeCollaborativeLearning,
  title = {Cooperative and {{Collaborative Learning}} - {{Theoretical Perspectives}} on {{Collaboration}}, {{Collaborative Learning}} in {{Dyads}} and {{Groups}}, {{Group}} and {{Individual Performance}}},
  author = {San, Eval)kyaw},
  urldate = {2014-09-06}
}

@article{sandvollWhenIntentionsMeet2014,
  title = {When Intentions Meet Reality: {{Consonance}} and Dissonance in Teacher Approaches to Peer Assessment},
  author = {Sandvoll, Ragnhild},
  year = {2014},
  journal = {Canadian journal of higher education (1975)},
  volume = {44},
  number = {2},
  pages = {118},
  publisher = {Canadian Society for the Study of Higher Education},
  address = {Toronto},
  issn = {0316-1218},
  doi = {10.47678/cjhe.v44i2.183858},
  abstract = {This article focuses on teachers' experiences in implementing peer assessment with first semester students. It explores the relationship between teachers' conceptions of teaching and their approach to peer assessment, where both conceptions and approaches are described as being either learning focused or content focused. Drawing upon analysis of interviews with eight teachers, the study found that one had a consonant view of the interrelationship between conceptions of teaching and approaches to peer assessment, while the remaining seven described their conceptions of teaching and their approaches to peer assessment with a combination of learning-focused and contentfocused statements. These statements are labelled as dissonant. Discussion focuses on implications of consonant and dissonant relationships between conceptions of teaching and approaches to peer assessment for implementation of peer assessment; it also addresses academic development issues. The study reveals that when implementing new methods (here, peer assessment), underlying assumptions will impact on the nature of teacher engagement. Cet article porte sur les exp{\'e}riences d'enseignants qui mettent en oeuvre l'{\'e}valuation par les pairs avec des {\'e}tudiants du premier semestre. On y explore la relation entre les conceptions des enseignants sur l'enseignement et leur approche envers l'{\'e}valuation par les pairs, ces deux conception et approche {\'e}tant ax{\'e}es soit sur l'apprentissage, soit sur le contenu. En s'appuyant sur l'analyse d'entretiens avec huit enseignants, l'{\'e}tude a r{\'e}v{\'e}l{\'e} que seul un d'entre eux {\'e}tait favorable {\`a} la relation entre les conceptions de l'enseignement et les m{\'e}thodes d'{\'e}valuation par les pairs, tandis que les sept autres ont d{\'e}crit leurs conceptions de l'enseignement et leurs m{\'e}thodes d'{\'e}valuation par les pairs avec des d{\'e}clarations ax{\'e}es sur l'apprentissage et le contenu. Ces d{\'e}clarations sont {\'e}tiquet{\'e}es comme discordantes. La discussion porte sur les implications des relations concordantes et discordantes entre les conceptions de l'enseignement et les m{\'e}thodes d'{\'e}valuation par les pairs, pour la mise en oeuvre de l'{\'e}valuation par ceux-ci; elle aborde {\'e}galement les questions de perfectionnement scolaire. D'apr{\`e}s l'{\'e}tude, lorsqu'on applique de nouvelles m{\'e}thodes, les hypoth{\`e}ses sous-jacentes ont des r{\'e}percussions sur la qualit{\'e} de l'engagement des enseignants. Peer assessment may involve increased time and workload for both students and teachers, and assessors may lack familiarity with necessary procedures and skill (Vu \& Dall'Alba, 2007). Sluijsmans and Prins (2006) stress that peer assessment skills are not easily and automatically acquired. They are complex skills and hence, adequate time is needed to prepare, train, and monitor assessors in order to foster adequate mastery (Sadler, 1998; Sluijsmans, Brand-Gruwel, van [Van Merri]{\"e}nboer, \& Martens, 2004). Vu and Dall'Alba (2007) have argued that preparation should include providing both a rationale and skills training. Rationale should stress the values and benefits of peer assessment and underscore its potential outcomes on the learning process, while training should prepare peer assessors to use criteria and to develop their skills in judging standards and in giving and receiving feedback ([Sambell] et al., 2013; Sluijsmans et al., 2004; Sluijsmans \& Prins, 2006). Students, when they take on the assessment role, need to be familiarized with assessment criteria, either through training or through involvement in developing and negotiating these criteria (Sluijsmans et al., 2004), and they will need practice in and feedback on how to use the standards and criteria. The referred peer assessment literature seems mainly to focus on training students as part of implementing peer assessment. However, it is reasonable to assume that teachers also need preparation before implementing peer assessment, preparation focusing on the rationale behind both the activity and the skills related to peer assessment orchestration.;This article focuses on teachers' experiences in implementing peer assessment with first semester students. It explores the relationship between teachers' conceptions of teaching and their approach to peer assessment, where both conceptions and approaches are described as being either learning focused or content focused. Drawing upon analysis of interviews with eight teachers, the study found that one had a consonant view of the interrelationship between conceptions of teaching and approaches to peer assessment, while the remaining seven described their conceptions of teaching and their approaches to peer assessment with a combination of learning-focused and contentfocused statements. These statements are labelled as dissonant. Discussion focuses on implications of consonant and dissonant relationships between conceptions of teaching and approaches to peer assessment for implementation of peer assessment; it also addresses academic development issues. The study reveals that when implementing new methods (here, peer assessment), underlying assumptions will impact on the nature of teacher engagement.;},
  langid = {english},
  keywords = {Educational evaluation,Higher education,Learning,Pedagogiske fag: 280,Samfunnsvitenskap: 200,Students,Studies,Teaching,VDP}
}

@article{sangraLearningEcologiesLens2019,
  title = {Learning Ecologies through a Lens: {{Ontological}}, Methodological and Applicative Issues. {{A}} Systematic Review of the Literature},
  shorttitle = {Learning Ecologies through a Lens},
  author = {Sangr{\'a}, Albert and Raffaghelli, Juliana Elisa and Guitert-Catas{\'u}s, Montse},
  year = {2019},
  month = jul,
  journal = {British Journal of Educational Technology},
  volume = {50},
  number = {4},
  pages = {1619--1638},
  issn = {0007-1013, 1467-8535},
  doi = {10.1111/bjet.12795},
  urldate = {2023-02-12},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/S7QATBNS/sangraLearningEcologiesLens2019.pdf}
}

@article{santosCOVID19LockdownEffects2022,
  title = {{{COVID-19 Lockdown Effects}} on {{Student Grades}} of a {{University Engineering Course}}: {{A Psychometric Study}}},
  author = {Santos, Hernan},
  year = {2022},
  journal = {IEEE transactions on education},
  volume = {65},
  number = {4},
  pages = {1--9},
  publisher = {IEEE},
  address = {PISCATAWAY},
  issn = {0018-9359},
  doi = {10.1109/TE.2021.3131745},
  abstract = {Contribution: This article is centered on effects that the COVID-19 lockdown has produced on the student performance in specific engineering course. The study treats to evaluate if the changes in the teaching and student assessment have been suited. Background: Most of higher education courses have had to adapt to this situation and made quick changes in its teaching and evaluation. The course applied computing was not the exception and has to split into two blocks. Teaching and evaluation of the first block was given totally in-person with traditional methodology. On the other hand, the second block that was affected by the lockdown, was fully taught with online flipped classroom (FC) teaching and remote assessment. Research Questions: This has given the opportunity to analyze how these changes have affected the student performance and what benefits of incorporated online FC teaching have been produced in this course. Methodology: The reliability of tests and item analysis techniques have been employed to measure the consistency and the item difficulty of the performed tests, respectively. From this psychometric study, the quality of the methodology of student assessment can be established. The study is also applied to the previous year where the in-person traditional methodology was employed. Moreover, the effectiveness of the teaching methodology is analyzed with student surveys. Findings: The reliability of online student assessment for FC teaching is high, yet when compared with traditional assessment for this specific course in both analyzed years. The different level of item difficulty is constant in the first block, being a possible cause for the low reliability of the test. Moreover, student surveys and student performance suggest that the online FC teaching method can be suitable for this specific course, and can be applied in the future.},
  keywords = {Academic Achievement,Correlation,COVID-19,Cronbach's alpha,Difficulty Level,Distance Education,Education,Education & Educational Research,Education Scientific Disciplines,Educational Change,Engineering,Engineering Education,Engineering Electrical & Electronic,Flipped Classroom,flipped classroom (FC),Higher Education,Indexes,Outcomes of Education,Pandemics,psychometric analysis,Psychometrics,Reliability,Science & Technology,Social Sciences,Software,Student Evaluation,Technology,Test Items,Test Reliability}
}

@article{sapiaUsingOnlineInstructor2020,
  title = {Using an {{Online Instructor Survey}} as {{Part}} of a {{Comprehensive Assessment}}: {{An Example}} in {{Oral Communication}}},
  author = {Sapia, Molly and Heller, Gina and Dawson, Dana and Carmack, Nicholas},
  year = {2020},
  journal = {Research \& Practice in Assessment},
  volume = {15},
  number = {1},
  issn = {EISSN-2161-4210},
  abstract = {Oral communication is an important learning outcome in higher education that can be difficult to assess. This article presents how one institution paired an online survey of instructors with a more traditional direct assessment to conduct a comprehensive assessment of oral communication in a General Education program, illuminating both how students are performing and how instructors are teaching oral communication. Detailed methodology and a full survey instrument are provided so that readers can translate this model to assessing oral communication or other major competency areas at their own institutions. Highlights of the survey results are also presented. The authors ultimately explain how the survey has led to faculty development around oral communication and to new oral communication resources that are aligned with the specific obstacles identified by survey respondents. They also describe how survey results helped to further explain the findings of the direct assessment.},
  langid = {english},
  keywords = {College Faculty,College Instruction,College Students,Communication Skills,General Education,No DOI found,Online Surveys,Performance Based Assessment,Speech Communication,Teacher Surveys}
}

@book{saqrLearningAnalyticsMethods2024,
  title = {Learning {{Analytics Methods}} and {{Tutorials}}: {{A Practical Guide Using R}}},
  shorttitle = {Learning {{Analytics Methods}} and {{Tutorials}}},
  editor = {Saqr, Mohammed and {L{\'o}pez-Pernas}, Sonsoles},
  year = {2024},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-54464-4},
  urldate = {2025-03-05},
  copyright = {https://creativecommons.org/licenses/by/4.0},
  isbn = {978-3-031-54463-7 978-3-031-54464-4},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/saqrLearningAnalyticsMethods2024.pdf}
}

@article{sarcedagorgosoPerceptionTechnologyAssessment2019,
  ids = {guevaraPerceptionTechnologyAssessment2019a,sarceda-gorgosoPerceptionTechnologyAssessment2019},
  title = {Perception of Technology as an Assessment Tool. {{A}} Comparative Analysis from the Learner's Perspective},
  author = {Sarceda Gorgoso, Mar{\'i}a del Carmen and Caldeiro Pedreira, Mari Carmen and Guevara, Sandra},
  year = {2019},
  journal = {Digital education review},
  number = {35},
  pages = {216--228},
  publisher = {Univ Barcelona, Res Group Educ \& Virtual Learning, Digital Educ Observatory},
  address = {BARCELONA},
  issn = {2013-9144},
  doi = {10.1344/der.2019.35.216-228},
  abstract = {The current state of technology is unquestionably changing our lives and consequently, causing some effects in the educational field; specifically on higher education. Therefore, the objective of this work is to know the perception of higher education Ibero-American students with regard to technology as a learning assessment tool. The sample group is made up by 122 people studying at the Education School in Tecnica del Norte University (Ecuador) and at the Teacher Training School in the University of Santiago de Compostela (Spain) who, throughout their educational trajectory, have been assessed at some point through technology. It is a quantitative study that applies the questionnaire as an instrument for data collection. Data analysis shows different perceptions, both in terms of contexts and experience itself, which allows us to identify those elements and factors influencing on the added value to technology as a resource for evaluation.},
  keywords = {assessment,Collaboration,College Students,Comparative analysis,Computer Assisted Testing,Ecuador,Education,Education & Educational Research,Educational objectives,Educational Technology,Evaluation Methods,Foreign Countries,Higher education,ICT,Internet access,Learning,No DOI found,Perceptions,Preservice Teachers,Social Sciences,Society,Spain,Student Attitudes,Student Evaluation,Students,Teaching,Technology Uses in Education,User perceptions},
  file = {/Users/colin.madland/Zotero/storage/T4PSNU2C/sarcedagorgosoPerceptionTechnologyAssessment2019.pdf}
}

@article{sargentNoneMyOther2021,
  title = {'{{None}} of My Other Teachers Know My Face/Emotions/Thoughts': Digital Technology and Democratic Assessment Practices in Higher Education Physical Education},
  author = {Sargent, Julia and Lynch, Shrehan},
  year = {2021},
  journal = {Technology, pedagogy and education},
  volume = {30},
  number = {5},
  pages = {693--705},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {1475-939X},
  doi = {10.1080/1475939X.2021.1942972},
  abstract = {Digital technology and its use within democratic pedagogy has been an under-researched area in physical education (PE) and higher education (HE). Furthermore, we know little about how democratic assessment methods are experienced by students in HE. As such, this article explores student perceptions and experiences of democratic assessment practices through video narratives in HE PE and how these video narratives allowed students to demonstrate their learning. Using student responses from an e-questionnaire, the findings discuss how the video narratives elevate students' self-awareness, generate emotive and affective responses, elicit performative acts and provide an authentic assessment experience. In particular, the consideration of a student's environment is presented as a novel finding in comparison to previous literature. The authors discuss these findings in relation to teachers' democratic practices and video narratives as a vehicle for supporting authentic assessment experiences.},
  keywords = {Assessment,Digital technology,Education & Educational Research,Higher education,Pedagogy,Physical education,Social Sciences,student,video narratives},
  file = {/Users/colin.madland/Zotero/storage/D5U22AU7/sargentNoneMyOther2021.pdf}
}

@article{sarmientoAssessmentPracticesPhilippine2020,
  title = {Assessment {{Practices}} in {{Philippine Higher STEAM Education}}},
  author = {Sarmiento, Celina P. and Morales, Marie Paz E. and Elipane, Levi E. and Palomar, Brando C.},
  year = {2020},
  journal = {Journal of University Teaching and Learning Practice},
  volume = {17},
  number = {5},
  issn = {EISSN-1449-9789},
  abstract = {The study explored practices of the sampled higher education Philippine STEAM educators in assessing learners. Data sourced from the database of a state-funded research on Philippine STEAM education using a Classroom Observation Protocol, included 106 STEAM teachers from purposely selected institutions drawn from 14 regions. Systematic data analysis (through data condensation, data display, and drawing and verifying conclusions) revealed that STEAM teachers used both appropriate traditional and authentic assessment tools and strategies with inclusive integration of technology. Furthermore, results showed that STEAM teachers' best assessment practices may be categorised as: 1) assessment for career or industry readiness, 2) mounting assessment system to support instruction, and 3) collective and reflective assessment process. COVID-19 pandemic implications and policy recommendations are also offered, which may enhance assessment practices and suggest a perspective in crafting and recommending national and international standards and guidelines on assessment literacy among higher STEAM educators.},
  langid = {english},
  keywords = {Art Education,Career Readiness,College Faculty,Cooperation,COVID-19,Evaluation Methods,Foreign Countries,No DOI found,Pandemics,Performance Based Assessment,Reflection,School Business Relationship,Skill Development,STEM Education,Student Evaluation,Technology Integration}
}

@article{sarmientoAssessmentPracticesPhilippine2020a,
  title = {Assessment Practices in {{Philippine}} Higher {{STEAM}} Education},
  author = {Sarmiento, {\relax CP} and Morales, {\relax MPE} and Elipane, {\relax LE} and Palomar, {\relax BC}},
  year = {2020},
  journal = {JOURNAL OF UNIVERSITY TEACHING AND LEARNING PRACTICE},
  volume = {17},
  number = {5},
  issn = {1449-9789},
  doi = {10.53761/1.17.5.18},
  abstract = {The study explored practices of the sampled higher education Philippine STEAM educators in assessing learners. Data sourced from the database of a state-funded research on Philippine STEAM education using a Classroom Observation Protocol, included 106 STEAM teachers from purposely selected institutions drawn from 14 regions. Systematic data analysis (through data condensation, data display, and drawing and verifying conclusions) revealed that STEAM teachers used both appropriate traditional and authentic assessment tools and strategies with inclusive integration of technology. Furthermore, results showed that STEAM teachers' best assessment practices may be categorised as: 1) assessment for career or industry readiness, 2) mounting assessment system to support instruction, and 3) collective and reflective assessment process. COVID-19 pandemic implications and policy recommendations are also offered, which may enhance assessment practices and suggest a perspective in crafting and recommending national and international standards and guidelines on assessment literacy among higher STEAM educators.},
  langid = {english},
  keywords = {assessment,STEAM higher education,TECHNOLOGY},
  file = {/Users/colin.madland/Zotero/storage/5U2E7P7J/sarmientoAssessmentPracticesPhilippine2020b.pdf}
}

@article{sarmientoAssessmentPracticesPhilippine2020b,
  title = {Assessment {{Practices}} in {{Philippine Higher STEAM Education}}},
  author = {Sarmiento, Celina P. and Morales, Marie Paz E. and Elipane, Levi E. and Palomar, Brando C.},
  year = {2020},
  month = jan,
  journal = {Journal of University Teaching and Learning Practice},
  volume = {17},
  number = {5},
  publisher = {{Journal of University Teaching and Learning Practice}},
  issn = {1449-9789},
  doi = {10.53761/1.17.5.18},
  abstract = {The study explored practices of the sampled higher education Philippine STEAM educators in assessing learners. Data sourced from the database of a state-funded research on Philippine STEAM education using a Classroom Observation Protocol, included 106 STEAM teachers from purposely selected institutions drawn from 14 regions. Systematic data analysis (through data condensation, data display, and drawing and verifying conclusions) revealed that STEAM teachers used both appropriate traditional and authentic assessment tools and strategies with inclusive integration of technology. Furthermore, results showed that STEAM teachers' best assessment practices may be categorised as: 1) assessment for career or industry readiness, 2) mounting assessment system to support instruction, and 3) collective and reflective assessment process. COVID-19 pandemic implications and policy recommendations are also offered, which may enhance assessment practices and suggest a perspective in crafting and recommending national and international standards and guidelines on assessment literacy among higher STEAM educators.},
  keywords = {Art Education,Career Readiness,College Faculty,Cooperation,COVID-19,Evaluation Methods,Foreign Countries,Pandemics,Performance Based Assessment,Philippines,Reflection,School Business Relationship,Skill Development,STEM Education,Student Evaluation,Technology Integration},
  file = {/Users/colin.madland/Zotero/storage/USV4YKF2/sarmientoAssessmentPracticesPhilippine2020a.pdf}
}

@article{sarstedtPLSSEMIndeedSilver2023,
  title = {"{{PLS-SEM}}: Indeed a Silver Bullet" - Retrospective Observations and Recent Advances},
  author = {Sarstedt, Marko and Hair, Joseph F. and Ringle, Christian M.},
  year = {2023},
  journal = {Journal of marketing theory and practice},
  volume = {31},
  number = {3},
  pages = {261--275},
  publisher = {Routledge},
  issn = {1069-6679},
  doi = {10.1080/10696679.2022.2056488},
  abstract = {In 2011, the Journal of Marketing Theory \& Practice published "PLS-SEM: Indeed a silver bullet," which became a cornerstone contribution in marketing. Critical reflection of research work is a fundamental building block of science, including one's own writing. In this spirit, we offer a review of our own 2011 paper, assuming we were reviewers with today's background knowledge of the method. Taking a reviewer's perspective in our comments, we clarify several ambiguities in our initial overview presentation and offer updates of - from today's perspective- outdated descriptions that led to some criticisms in recent years which have since been overcome.},
  file = {/Users/colin.madland/Zotero/storage/FNGUHRLK/sarstedtPLSSEMIndeedSilver2023.pdf}
}

@article{saScholarOnlineOrganizational2020,
  title = {Scholar's {{Online Organizational Engagement}} and {{Its Consequences}} for {{Higher Education Sustainability}}},
  author = {S{\'a}, Maria Jose and Ferreira, Carlos Miguel and Serpa, Sandro},
  year = {2020},
  journal = {Journal of Education and e-Learning Research},
  volume = {7},
  number = {2},
  pages = {153--158},
  issn = {ISSN-2518-0169},
  doi = {10/gmbvz3},
  abstract = {Currently, there is an increase in online organizational engagement in the academic profession. This paper fits in this context and aims to analyze the scholar's online organizational engagement in higher education sustainability. For that purpose, the authors carried out a collection and documentary analysis of publications on this topic. The results of this conceptual analysis allow concluding that some academics may perceive the requirements for online engagement as excessive. These academics question the confidence they have in their institution and, consequently, the psychological contract itself and the distinction between professional life and personal and family life, which they may perceive as a new form of control and monitoring. However, it is worth highlighting the difference in expectations between academics themselves, caused, among other factors, by the type of contractual experience and by their digital literacy, as well as by their ideological representations about the academic profession and, consequently, in the relative importance of their professional autonomy. In this scenario, the pre- and initial organizational socialization processes are critical in the (re)definition of the psychological contract of scholar's online organizational engagement in the context of higher education sustainability.},
  langid = {english},
  keywords = {College Faculty,Faculty College Relationship,Foreign Countries,Higher Education,Internet,Organizational Climate,Organizational Objectives,Psychological Patterns,Teacher Attitudes}
}

@article{sasereGlobalPerceptionsFaculties2020,
  title = {Global {{Perceptions}} of {{Faculties}} on {{Virtual Programme Delivery}} and {{Assessment}} in {{Higher Education Institutions}} during the 2020 {{COVID-19 Pandemic}}},
  author = {Sasere, Oluwasola Babatunde and Makhasane, Sekitla Daniel},
  year = {2020},
  journal = {International Journal of Higher Education},
  volume = {9},
  number = {5},
  pages = {181--192},
  issn = {ISSN-1927-6044},
  doi = {10/gmbvzf},
  abstract = {Amidst the outbreak of COVID-19 worldwide, virtually all national governments declared a "lockdown" of all institutions in a bid to curtail its spread. This posed serious challenges to programme delivery and assessment in Higher Education Institutions (HEIs), with foreseeable long and short-term consequences. This study investigated the effectiveness of virtual programme delivery and assessment in Higher Education Institutions (HEIs) during the COVID-19 (Corona Virus) pandemic, from a global perspective. The study assesses the success rate of virtual teaching and learning via various online platforms that were set up to make up for time lost due to the unanticipated global HEIs closure. Organisational Change Theory was used to inform the study, within the confines of simple qualitative research approach. Data were collected using interview while participants were selected through convenience sampling technique via online platforms such as the reputable online academic community, email, WhatsApp, and the UNESCO website. Data were analysed using thematic analysis. The findings revealed disparities in responses to virtual learning across HEIs and national contexts. Training and re-training of lecturers and students, and the provision of virtual learning enabling infrastructure, were recommended to mitigate similar situation in future.},
  langid = {english},
  keywords = {Access to Computers,College Faculty,Comparative Education,Computer Mediated Communication,COVID-19,Developing Nations,Electronic Learning,Instructional Effectiveness,Internet,Pandemics,School Closing,Teacher Attitudes,Technological Literacy}
}

@article{sasereGlobalPerceptionsFaculties2020a,
  title = {Global {{Perceptions}} of {{Faculties}} on {{Virtual Programme Delivery}} and {{Assessment}} in {{Higher Education Institutions}} during the 2020 {{COVID-19 Pandemic}}},
  author = {Sasere, Oluwasola Babatunde and Makhasane, Sekitla Daniel},
  year = {2020},
  month = jan,
  journal = {International Journal of Higher Education},
  volume = {9},
  number = {5},
  pages = {181--192},
  publisher = {International Journal of Higher Education},
  issn = {1927-6044},
  doi = {10.5430/ijhe.v9n5p181},
  abstract = {Amidst the outbreak of COVID-19 worldwide, virtually all national governments declared a "lockdown" of all institutions in a bid to curtail its spread. This posed serious challenges to programme delivery and assessment in Higher Education Institutions (HEIs), with foreseeable long and short-term consequences. This study investigated the effectiveness of virtual programme delivery and assessment in Higher Education Institutions (HEIs) during the COVID-19 (Corona Virus) pandemic, from a global perspective. The study assesses the success rate of virtual teaching and learning via various online platforms that were set up to make up for time lost due to the unanticipated global HEIs closure. Organisational Change Theory was used to inform the study, within the confines of simple qualitative research approach. Data were collected using interview while participants were selected through convenience sampling technique via online platforms such as the reputable online academic community, email, WhatsApp, and the UNESCO website. Data were analysed using thematic analysis. The findings revealed disparities in responses to virtual learning across HEIs and national contexts. Training and re-training of lecturers and students, and the provision of virtual learning enabling infrastructure, were recommended to mitigate similar situation in future.},
  keywords = {Access to Computers,College Faculty,Comparative Education,Computer Mediated Communication,COVID-19,Developing Nations,Electronic Learning,Instructional Effectiveness,Internet,Pandemics,School Closing,Teacher Attitudes,Technological Literacy},
  file = {/Users/colin.madland/Zotero/storage/QZF44VIR/sasereGlobalPerceptionsFaculties2020a.pdf}
}

@article{saveryBEVOCALCharacteristics2010,
  title = {{{BE VOCAL}}: {{Characteristics}} of {{Successful Online Instructors}}},
  author = {Savery, John R.},
  year = {2010},
  journal = {Journal of Interactive Online Learning},
  volume = {9},
  number = {3},
  pages = {141--152},
  abstract = {While classroom teaching and management strategies are well documented, the online learning environment presents different challenges and benefits. Teaching in an online environment requires a special set of teaching skills since many of the strategies and tactics associated with best teaching practices are somewhat constrained by the primarily text-based environment. The VOCAL approach summarizes the key characteristics that a master instructor utilizes to be effective in an online environment. VOCAL is an acronym for Visible, Organized, Compassionate, Analytical and Leader-by-example. The ability of the teacher to effectively infuse these characteristics into their instructional practice--to BE VOCAL--will promote a supportive, challenging, constructive, rigorous and effective instructional environment. Instructors who practice a VOCAL approach will have more productive learning environments, fewer management problems and more positive learning experiences with their students.},
  keywords = {Adjustment,Courses,EDUCATIONAL,Effectiveness,Electronic,environment,Environment),Expectation,Expectations,Instructional,LEARNING,Methods,of,Online,Relationship,SCHOOL,Skills,Student,STUDENTS,Teacher,Teaching,to},
  annotation = {University of Alabama. 152 Rose Administration, P.O. Box 870104, Tuscaloosa, AL 35487. Web site: http://www.ncolr.org/jiol Accession Number: EJ938844; Acquisition Information: University of Alabama. 152 Rose Administration, P.O. Box 870104, Tuscaloosa, AL 35487. Web site: http://www.ncolr.org/jiol; Language: English; Education Level: Higher Education; Reference Count: 33; Journal Code: OCT2011; Level of Availability: Not available from ERIC; Publication Type: Journal Articles; Publication Type: Reports - Descriptive; Entry Date: 2011}
}

@misc{SaylorOrg,
  title = {Saylor.Org},
  journal = {Saylor Academy {\textbar} Free and open online courses for people everywhere},
  urldate = {2018-11-05},
  abstract = {Saylor Academy provides free online courses and affordable college credit opportunities to learners everywhere. Start your course today!},
  howpublished = {https://www.saylor.org/},
  langid = {american},
  keywords = {saylor},
  file = {/Users/colin.madland/Zotero/storage/AYULRZ3H/www.saylor.org.html}
}

@article{sazIntroducingPersonalLearning2016,
  title = {Introducing a {{Personal Learning Environment}} in {{Higher Education}}. {{An Analysis}} of {{Connectivity}}},
  author = {Saz, Alexandra and Engel, Anna and Coll, C{\'e}sar},
  year = {2016},
  month = jun,
  journal = {Digital Education Review},
  number = {29},
  pages = {1--14},
  publisher = {Digital Education Review},
  issn = {2013-9144},
  abstract = {Universities have a key role to play in the progress and development of the Knowledge Society. They should lead the way in the design of teaching strategies that promote knowledge building. Personal learning environments (PLE) represent a groundbreaking new development in educational practices through the incorporation of Information and Communications Technology (ICT), and an opportunity to promote the creation of universities without walls able to meet the demands of the knowledge society. This study focuses on the relationships established by the participants (students and teachers) in two higher education instructional sequences using institutionally-powered PLE (iPLE). One of the sequences was carried out at the University of Barcelona and the other at the University of Andorra. Both used the same technological support, the "Elgg" platform, which allows users to build their own personal work and learning environment. The main hypothesis of the study is that the relationships formed depend on the techno-pedagogical design of the teaching and learning process. The results show that in both cases the relationships that the participants establish with their peers and teachers are indeed related to the characteristics and requirements of the particular techno-pedagogical designs. Although the technological environment allowed all the participants to establish relationships with others, the main interactions were found in small working groups created to carry out learning and assessment activities. In conclusion, we stress the importance of planning teaching and learning activities and assessment processes that are able to exploit the full potential of PLE.},
  keywords = {Aptitude Treatment Interaction,Case Studies,College Faculty,College Students,Educational Environment,Foreign Countries,Higher Education,Instructional Design,Instructional Development,Learning Processes,Mixed Methods Research,Network Analysis,No DOI found,Spain,Teacher Student Relationship,Teaching Models,Technology Uses in Education}
}

@article{sbaffiEvaluatingPedagogicalApproach2022,
  title = {Evaluating a Pedagogical Approach to Promoting Academic Integrity in Higher Education: {{An}} Online Induction Program},
  author = {Sbaffi, Laura and Zhao, Xin},
  year = {2022},
  journal = {Frontiers in psychology},
  volume = {13},
  pages = {1009305--1009305},
  publisher = {Frontiers Media Sa},
  address = {LAUSANNE},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2022.1009305},
  abstract = {Academic integrity is at the heart of excellent education. However, resources explaining the concept tend to be definition-driven, while using complex language and sometimes even an austere tone designed to discourage students from breaches. This study aims to design and evaluate an online module at a UK University across 2 years, designed to improve students' understanding of concepts of academic integrity and practice. The module includes a range of interactive resources (e.g., gamified quizzes and e-booklets) and was made available to a large cohort of postgraduate students (448). The study adopts a mixed-methods approach composed of three sequential phases involving first collecting students' views on existing academic integrity resources (7 students participating in a focus group and 39 competing a questionnaire), then developing a range of new ones based on students' feedback to form the content of the module, and finally gathering students' evaluation on the newly created resources (sample size: 361 students). Results illustrate a clear improvement in relation to the accessibility, usefulness and understandability of new resources. Results also highlight a remarkable increase in student confidence levels regarding academic integrity. Students also considered the new module as more appealing and informative. This manuscript offers a good example of a pedagogical approach aimed at promoting academic integrity in an innovative and engaging fashion.},
  keywords = {academic integrity,educational games,online module,online pedagogy,policy and practice,Psychology,Psychology Multidisciplinary,Social Sciences},
  file = {/Users/colin.madland/Zotero/storage/766NS87B/sbaffiEvaluatingPedagogicalApproach2022.pdf}
}

@article{scagnoliStudentOrientationsOnline2001,
  title = {Student Orientations for Online Programs},
  author = {Scagnoli, Norma I},
  year = {2001},
  journal = {Journal of Research on Technology in Education},
  volume = {34},
  number = {1},
  pages = {19},
  abstract = {Considering the flow of virtual students, universities offering distance learning programs have to design orientation programs suited for the students that will take distance courses. Scagnoli introduces the issues to be considered in designing an orientation for students in online programs and presents the strategies being used currently in some Internet-based courses.},
  keywords = {Colleges,Education,instruction,Online,Orientations,technology,universities}
}

@article{scanlonDesigningEducationalTechnology2015,
  title = {{\textbf{Designing for }}{{{\textbf{Educational Technology}}}}{\textbf{ to }}{{{\textbf{Enhance}}}}{\textbf{ the }}{{{\textbf{Experience}}}}{\textbf{ of }}{{{\textbf{Learners}}}}{\textbf{ in }}{{{\textbf{Distance Education}}}}{\textbf{: }}{{{\textbf{How Open Educational Resources}}}}{\textbf{, }}{{{\textbf{Learning Design}}}}{\textbf{ and }}{{{\textbf{Moocs Are Influencing Learning}}}}{\textbf{ }}},
  author = {Scanlon, Eileen and McAndrew, Patrick and O'Shea, Tim},
  year = {2015},
  journal = {Journal of Interactive Media in Education},
  volume = {2015},
  doi = {10.5334/jime.al},
  abstract = {\textbf{ }The area of learning has a justifiable claim to be a special case in how it can be enhanced or supported by~technology. In areas such as commerce and web design the aim is usually to ensure efficiency and support~specific actions such as purchasing or accessing information as quickly and easily as possible. Working~with technology for the purpose of learning, the user is expected to spend time facing challenges,~struggling through them and in almost every case the interaction with the technology is only one of~many influences in achieving success. This does not mean that computing and the Internet has not had a~major impact on how we learn and the choices available to learners. On the contrary, the area of formal~learning is undergoing a period of rapid change, and the barriers between formal and informal learning~are showing signs of falling away, in part due to the changes in the access to information or alternative~modes of delivery.The influence of technology on pedagogy (the manner or structure of teaching) is complex. There is~relatively little direct research on the ways that technological possibilities and the pedagogical response~to these operate to benefit the lifelong learner. In this article we are bringing together the evidence from~strands of research based on work in online and distance learning in formal settings, and also on open~and free online education, which is often less formal. This research sheds light on several factors relevant~to the outcomes of instruction: the often unpredictable motivations of learners, the trajectories they~take through courses, and the indicators for success in formal and informal learning, in terms of both~pedagogy and technology. We present the outcomes of practical endeavours to widen access to education~using technology which indicate that open education is offering alternative ways of supporting learners.~These suggest a focus on design decisions that can help integrate the process of learning more closely~with ways in which online systems currently support learning and the data that can be used to interpret~how well those designs are working.}
}

@incollection{scardamaliaNewAssessmentsEnvironments2012,
  title = {New {{Assessments}} and {{Environments}} for {{Knowledge Building}}},
  booktitle = {Assessment and {{Teaching}} of 21st {{Century Skills}}},
  author = {Scardamalia, Marlene and Bransford, John and Kozma, Bob and Quellmalz, Edys},
  editor = {Griffin, Patrick and McGaw, Barry and Care, Esther},
  year = {2012},
  pages = {231--300},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-94-007-2324-5_5},
  abstract = {This chapter proposes a framework for integrating two different approaches to twenty-first century skills: ``working backward from goals'' and ``emergence of new competencies.'' Working backward from goals has been the mainstay of educational assessment and objectives-based instruction. The other approach is based on the premise that breakthroughs in education to address twenty-first century needs require not only targeting recognized objectives but also enabling the discovery of new objectives---particularly capabilities and challenges that emerge from efforts to engage students in authentic knowledge creation. Accordingly, the focus of this chapter is on what are called ``knowledge building environments.'' These are environments in which the core work is the production of new knowledge, artifacts, and ideas of value to the community---the same as in mature knowledge-creating organizations. They bring out things students are able to do that are obscured by current learning environments and assessments. At the heart of this chapter is a set of developmental sequences leading from entry-level capabilities to the abilities that characterize members of high-performing knowledge-creating teams. These are based on findings from organization science and the learning sciences, including competencies that have already been demonstrated by students in knowledge-building environments. The same sources have been mined for principles of learning and development relevant to these progressions.},
  isbn = {978-94-007-2324-5},
  file = {/Users/colin.madland/Zotero/storage/B4EB2DWQ/scardamaliaNewAssessmentsEnvironments2012.pdf}
}

@misc{ScenesHowTwitter,
  title = {Behind the Scenes: {{How Twitter}} Decided to Open up Its Image-Cropping Algorithm to the Public}
}

@article{schaferMeasurementTrainingSchool1987,
  title = {Measurement {{Training}} for {{School Personnel Recommendations}} and {{Reality}}},
  author = {Schafer, William D. and Lissitz, Robert W.},
  year = {1987},
  month = may,
  journal = {Journal of Teacher Education},
  volume = {38},
  number = {3},
  pages = {57--63},
  issn = {0022-4871, 1552-7816},
  doi = {10/d97wmb},
  urldate = {2021-07-09},
  abstract = {Using evidence from a national survey and earlier literature, Schafer and Lissitz note that the time spent by teachers in assessment activities is not reflected in their evaluation skills nor in their prep aration programs. Prospective teachers receive limited preparation in assess ment procedures despite the existence of well-developed recommendations from professional groups vis-a-vis as sessment objectives for preprofessional training. The authors suggest that cur ricular change be evidenced in teacher preparation programs to ensure that teachers have adequate assessment skills.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/5NX43T4D/schaferMeasurementTrainingSchool1987.pdf}
}

@article{schalkExploringConceptDigital2022,
  title = {Exploring the Concept of the Digital Educator during {{COVID-19}}},
  author = {Schalk, {\relax AE} and McAvinia, C and Rooney, P},
  year = {2022},
  journal = {Australasian Journal of Educational Technology},
  volume = {38},
  number = {2},
  pages = {129--141},
  issn = {1449-3098},
  doi = {10.14742/ajet.7316},
  abstract = {In this paper, we explore academic identity, specifically the identity of the educator in higher education and academics' conceptualisations of the digital educator. We suggest that the concept of a digital educator is not only about technology, tools and uses. The context for this exploration is academics' participation in an online professional development module, Digital Education, and the "pivot online" (Weller, 2020a) during campus closures caused by the COVID-19 pandemic in 2020. Through qualitative research, we explored participants' sense of teaching identity, whether they had or have a concept of being a digital educator and the extent to which these identities might have shifted while the campus closure continued. We present analysis of their accounts and reflect on the implications of this analysis, particularly in relation to organisational digital capacity defined as "the skills, competencies, attitudes, infrastructure, and resources that enable people to work, live and learn in a world that is increasingly digital world" (National Fonun, 2018, p. iv). We consider how higher education institutions will cope with the complex challenges facing us and suggest ways in which the implications of this research could better enable institutions to navigate change and build organisational digital capacity. Implications for practice or policy: The pivot to online teaching and assessment during the COVID-19 pandemic has had complex effects on professional identities which need to be researched and understood. Programme teams in campus based institutions have experienced erosion of professional nonns and relationships. They need support and leadership during the gradual return to campus. Faculty integrated technologies rapidly but unevenly into practice; therefore, the ongoing building of digital capacity and the shift towards post-digital pedagogies needs dedicated support and leadership.},
  langid = {english},
  keywords = {digital capacity,digital educator,IDENTITY,leadership,post-digital pedagogies,professional identity,qualitative research},
  file = {/Users/colin.madland/Zotero/storage/53KIDC9S/schalkExploringConceptDigital2022.pdf}
}

@book{scheinOrganizationalCultureLeadership2016,
  title = {Organizational {{Culture}} and {{Leadership}}},
  author = {Schein, Peter A. and Schein, Edgar H.},
  year = {2016},
  publisher = {John Wiley \& Sons, Incorporated},
  address = {New York},
  isbn = {978-1-119-21213-3},
  keywords = {Corporate culture.,Culture.,Leadership.},
  file = {/Users/colin.madland/Zotero/storage/9UXDQQU9/scheinOrganizationalCultureLeadership2016.pdf}
}

@article{scheiterTechnologyenhancedLearningTeaching2021,
  title = {Technology-Enhanced Learning and Teaching: An Overview},
  author = {Scheiter, Katharina},
  year = {2021},
  journal = {Zeitschrift f{\"u}r Erziehungswissenschaft},
  volume = {24},
  number = {5},
  pages = {1039--1060},
  publisher = {Springer Nature},
  address = {WIESBADEN},
  issn = {1434-663X},
  doi = {10.1007/s11618-021-01047-y},
  abstract = {This article describes the current state of research on the use of digital media in educational contexts against the background of two research perspectives. The first research perspective, which has been established for some time, deals with technology-enhanced learning. It primarily examines learning processes and outcomes as a function of media characteristics and individual learner characteristics. This research tradition has produced numerous findings. However, the question of how to integrate digital media into the classroom in a way that is effective for learning is not considered here. This is where the second, more recent research perspective on technology-enhanced teaching comes in, which addresses teaching with digital media and the professional competencies of teachers required for this. Finally, the paper argues for combining both research perspectives, especially since they have relevant commonalities in their basic assumptions. Thus, in both research perspectives, digital media are analyzed less on the basis of surface features, but rather in terms of their functions for the promotion of learning and teaching processes.},
  keywords = {Education & Educational Research,Social Sciences},
  file = {/Users/colin.madland/Zotero/storage/WRPRJAQY/scheiterTechnologyenhancedLearningTeaching2021.pdf}
}

@article{schellekensScopingReviewNotions2021,
  title = {A Scoping Review on the Notions of {{Assessment}} as {{Learning}} ({{AaL}}), {{Assessment}} for {{Learning}} ({{AfL}}), and {{Assessment}} of {{Learning}} ({{AoL}})},
  author = {Schellekens, Lonneke H. and Bok, Harold G.J. and De Jong, Lubberta H. and Van Der Schaaf, Marieke F. and Kremer, Wim D.J. and Van Der Vleuten, Cees P.M.},
  year = {2021},
  month = dec,
  journal = {Studies in Educational Evaluation},
  volume = {71},
  pages = {101094},
  issn = {0191491X},
  doi = {10.1016/j.stueduc.2021.101094},
  urldate = {2024-04-25},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/UCR2IVLN/schellekensScopingReviewNotions2021.pdf}
}

@article{schilderMeasuringMediaLiteracy2019,
  title = {Measuring {{Media Literacy Inquiry}} in {{Higher Education}}: {{Innovation}} in {{Assessment}}},
  author = {Schilder, Evelien and Redmond, Theresa},
  year = {2019},
  journal = {Journal of Media Literacy Education},
  volume = {11},
  number = {2},
  pages = {95--121},
  issn = {EISSN-2167-8715},
  doi = {10/gmbvzn},
  abstract = {The ability to critically access, analyze, evaluate, and create media messages is crucial in the process of becoming an informed and engaged citizen throughout life. Asking critical questions is not only a valuable dimension of media literacy, but also an indispensable aspect of participating in a democracy. Yet, measuring the effectiveness of media literacy is still a major challenge for the field. It is unclear to what extent people of all ages may engage in critical questioning habits with regards to media. To address this gap, we studied the changes in critical questioning habits for college-aged students enrolled in media literacy courses. To measure students' media literacy inquiry, we evaluated the questions they posed in response to viewing an advertisement. We analyzed questions by media literacy concept and by level of complexity before and after their participation in the media literacy courses. Findings revealed that after the media literacy courses, students' inquiries were more complex and involved more attention to key concepts related to production techniques and representations. Our study is significant as it reflects an innovative approach to media literacy assessment and a fresh perspective for examining the impact of media literacy on cultivating complex, critical thinking skills that could be applied with learners of all ages.},
  langid = {english},
  keywords = {Critical Thinking,Difficulty Level,Fundamental Concepts,Inquiry,Media Literacy,Questioning Techniques,Undergraduate Students}
}

@article{schindlerComputerbasedTechnologyStudent2017,
  title = {Computer-Based Technology and Student Engagement: A Critical Review of the Literature},
  author = {Schindler, Laura A. and Burkholder, Gary J. and Morad, Osama A. and Marsh, Craig},
  year = {2017},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {14},
  number = {1},
  pages = {1--28},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-017-0063-0},
  abstract = {Computer-based technology has infiltrated many aspects of life and industry, yet there is little understanding of how it can be used to promote student engagement, a concept receiving strong attention in higher education due to its association with a number of positive academic outcomes. The purpose of this article is to present a critical review of the literature from the past 5 years related to how web-conferencing software, blogs, wikis, social networking sites ( Facebook and Twitter ), and digital games influence student engagement. We prefaced the findings with a substantive overview of student engagement definitions and indicators, which revealed three types of engagement (behavioral, emotional, and cognitive) that informed how we classified articles. Our findings suggest that digital games provide the most far-reaching influence across different types of student engagement, followed by web-conferencing and Facebook . Findings regarding wikis, blogs, and Twitter are less conclusive and significantly limited in number of studies conducted within the past 5 years. Overall, the findings provide preliminary support that computer-based technology influences student engagement, however, additional research is needed to confirm and build on these findings. We conclude the article by providing a list of recommendations for practice, with the intent of increasing understanding of how computer-based technology may be purposefully implemented to achieve the greatest gains in student engagement.},
  keywords = {Blogs,Computer & video games,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Educational Technology,Facebook,Higher Education,Humanities,Information management,Information resources,Information Systems Applications (incl.Internet),Law,Literature reviews,Review Article,Social networking,Social networks,Statistics for Social Sciences,Student engagement,Technology education,Teleconferencing,Web-conferencing,Wikis},
  file = {/Users/colin.madland/Zotero/storage/48G5MU4C/schindlerComputerbasedTechnologyStudent2017.pdf}
}

@article{schinskeTeachingMoreGrading2014,
  title = {Teaching {{More}} by {{Grading Less}} (or {{Differently}})},
  author = {Schinske, Jeffrey and Tanner, Kimberly},
  year = {2014},
  journal = {CBE Life Sciences Education},
  volume = {13},
  number = {2},
  pages = {159--166},
  issn = {1931-7913},
  doi = {10.1187/cbe.CBE-14-03-0054},
  urldate = {2024-03-19},
  abstract = {The authors explore a history of grading and review the literature regarding the purposes and impacts of grading. They then suggest strategies for making grading more supportive of learning, including balancing accuracy-based and effort-based grading, using self/peer evaluation, curtailing curved grading, and exercising skepticism about the meaning of grades.},
  pmcid = {PMC4041495},
  pmid = {26086649},
  file = {/Users/colin.madland/Zotero/storage/JTFFHFYT/Schinske and Tanner - 2014 - Teaching More by Grading Less (or Differently).pdf}
}

@article{schlagweinOpennessInformationTechnology2017,
  title = {``{{Openness}}'' with and without {{Information Technology}}: A Framework and a Brief History},
  author = {Schlagwein, Daniel and Conboy, Kieran and Feller, Joseph and Leimeister, Jan Marco and Morgan, Lorraine},
  year = {2017},
  journal = {Journal of Information Technology},
  volume = {32},
  number = {4},
  pages = {297--305},
  issn = {1466-4437},
  doi = {10.1057/s41265-017-0049-3},
  abstract = {Over the past two decades, openness (e.g. `open' innovation, `open' education and `open' strategy) has been of increasing interest for researchers and of increasing relevance to practitioners. Openness is often deeply embedded in information technology (IT) and can be both a driver for and a result of innovative IT. To clarify the concept of ``openness'', we provide an overview of the scope of cross-disciplinary research on openness. Based on this overview, we develop a framework of openness, which proposes a higher-order concept of ``openness'' characterised by transparency, access, participation and democracy. The framework further distinguishes open resources, open processes and the effects of opening on particular domains. To provide the historical context and to appreciate the role of IT in openness, we discuss two historical examples of openness: the introduction of an open science model in academia (openness without IT) and the emergence of open source software development (openness with IT). We conclude by highlighting some concerns with and limitations of ``openness''.}
}

@article{schmitzQualityQuantityCompletion2019,
  title = {Quality or {{Quantity}}: {{Completion Rewards}} and {{Formative Assessments}} in {{Flipped Instruction Classes}}},
  author = {Schmitz, Kurt},
  year = {2019},
  month = jan,
  journal = {International Journal for the Scholarship of Teaching and Learning},
  volume = {13},
  number = {3},
  publisher = {{International Journal for the Scholarship of Teaching and Learning}},
  issn = {1931-4744},
  doi = {10.20429/ijsotl.2019.130304},
  abstract = {Flipped instruction shifts the burden for engaging course content to the students. Moving these activities outside the classroom creates motivational challenges. This study investigates the role of formative assessments and completion rewards. Definitions are provided for flipped instruction and formative assessments. A classification of reward scores is offered to guide data collection in two field experiments. The study seeks to provide an empirical basis to guide use of completion rewards for flipped instruction classes. This study finds that completion rewards can increase quantity of formative assessment engagement. However, this change in quantity does not improve exam scores. The data suggests completion rewards may undermine the quality of engagement.},
  keywords = {College Students,Educational Technology,Formative Evaluation,Homework,Learner Engagement,Program Effectiveness,Rewards,Scores,Student Motivation,Student Participation,Teaching Methods,Technology Uses in Education,Tests,Video Technology},
  file = {/Users/colin.madland/Zotero/storage/VP5JXVPX/schmitzQualityQuantityCompletion2019.pdf}
}

@article{schneiderLinkingPersonalityTeachers2020,
  title = {Linking Personality to Teachers' Literacy in Classroom Assessment: A Cross-Cultural Study},
  shorttitle = {Linking Personality to Teachers' Literacy in Classroom Assessment},
  author = {Schneider, Christoph and DeLuca, Christopher and Pozas, Marcela and Coombs, Andrew},
  year = {2020},
  month = feb,
  journal = {Educational Research and Evaluation},
  volume = {26},
  number = {1-2},
  pages = {53--74},
  issn = {1380-3611, 1744-4187},
  doi = {10/gk5r6r},
  urldate = {2021-07-10},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/SW4NLFF6/schneiderLinkingPersonalityTeachers2020.pdf}
}

@article{schneiderMakingGradeHistory2014,
  title = {Making the Grade: A History of the {{A}}--{{F}} Marking Scheme},
  shorttitle = {Making the Grade},
  author = {Schneider, Jack and Hutt, Ethan},
  year = {2014},
  journal = {Journal of Curriculum Studies},
  volume = {46},
  number = {2},
  pages = {201--224},
  issn = {0022-0272, 1366-5839},
  doi = {10.1080/00220272.2013.790480},
  urldate = {2025-03-20},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/schneiderMakingGradeHistory2014.pdf}
}

@article{schneiderVariablesAssociatedAchievement2017,
  title = {Variables {{Associated With Achievement}} in {{Higher Education}}: {{A Systematic Review}} of {{Meta-Analyses}}},
  author = {Schneider, Michael and Preckel, Franzis},
  editor = {Albarrac{\'i}n, Dolores},
  year = {2017},
  journal = {Psychological bulletin},
  volume = {143},
  number = {6},
  pages = {565--600},
  publisher = {American Psychological Association},
  address = {WASHINGTON},
  issn = {0033-2909;1939-1455;},
  doi = {10/f97vgb},
  abstract = {The last 2 decades witnessed a surge in empirical studies on the variables associated with achievement in higher education. A number of meta-analyses synthesized these findings. In our systematic literature review, we included 38 meta-analyses investigating 105 correlates of achievement, based on 3,330 effect sizes from almost 2 million students. We provide a list of the 105 variables, ordered by the effect size, and summary statistics for central research topics. The results highlight the close relation between social interaction in courses and achievement. Achievement is also strongly associated with the stimulation of meaningful learning by presenting information in a clear way, relating it to the students, and using conceptually demanding learning tasks. Instruction and communication technology has comparably weak effect sizes, which did not increase over time. Strong moderator effects are found for almost all instructional methods, indicating that how a method is implemented in detail strongly affects achievement. Teachers with high-achieving students invest time and effort in designing the microstructure of their courses, establish clear learning goals, and employ feedback practices. This emphasizes the importance of teacher training in higher education. Students with high achievement are characterized by high self-efficacy, high prior achievement and intelligence, conscientiousness, and the goal-directed use of learning strategies. Barring the paucity of controlled experiments and the lack of meta-analyses on recent educational innovations, the variables associated with achievement in higher education are generally well investigated and well understood. By using these findings, teachers, university administrators, and policymakers can increase the effectivity of higher education. (PsycINFO Database Record;The last 2 decades witnessed a surge in empirical studies on the variables associated with achievement in higher education. A number of meta-analyses synthesized these findings. In our systematic literature review, we included 38 meta-analyses investigating 105 correlates of achievement, based on 3,330 effect sizes from almost 2 million students. We provide a list of the 105 variables, ordered by the effect size, and summary statistics for central research topics. The results highlight the close relation between social interaction in courses and achievement. Achievement is also strongly associated with the stimulation of meaningful learning by presenting information in a clear way, relating it to the students, and using conceptually demanding learning tasks. Instruction and communication technology has comparably weak effect sizes, which did not increase over time. Strong moderator effects are found for almost all instructional methods, indicating that how a method is implemented in detail strongly affects achievement. Teachers with high-achieving students invest time and effort in designing the microstructure of their courses, establish clear learning goals, and employ feedback practices. This emphasizes the importance of teacher training in higher education. Students with high achievement are characterized by high self-efficacy, high prior achievement and intelligence, conscientiousness, and the goal-directed use of learning strategies. Barring the paucity of controlled experiments and the lack of meta-analyses on recent educational innovations, the variables associated with achievement in higher education are generally well investigated and well understood. By using these findings, teachers, university administrators, and policymakers can increase the effectivity of higher education. [web URL: http://psycnet.apa.org/record/2017-12895-001];The last 2 decades witnessed a surge in empirical studies on the variables associated with achievement in higher education. A number of meta-analyses synthesized these findings. In our systematic literature review, we included 38 meta-analyses investigating 105 correlates of achievement, based on 3,330 effect sizes from almost 2 million students. We provide a list of the 105 variables, ordered by the effect size, and summary statistics for central research topics. The results highlight the close relation between social interaction in courses and achievement. Achievement is also strongly associated with the stimulation of meaningful learning by presenting information in a clear way, relating it to the students, and using conceptually demanding learning tasks. Instruction and communication technology has comparably weak effect sizes, which did not increase over time. Strong moderator effects are found for almost all instructional methods, indicating that how a method is implemented in detail strongly affects achievement. Teachers with high-achieving students invest time and effort in designing the microstructure of their courses, establish clear learning goals, and employ feedback practices. This emphasizes the importance of teacher training in higher education. Students with high achievement are characterized by high self-efficacy, high prior achievement and intelligence, conscientiousness, and the goal-directed use of learning strategies. Barring the paucity of controlled experiments and the lack of meta-analyses on recent educational innovations, the variables associated with achievement in higher education are generally well investigated and well understood. By using these findings, teachers, university administrators, and policymakers can increase the effectivity of higher education.;Gut qualifizierte Lehrende sind ein wichtiger Faktor f{\"u}r den akademischen Erfolg von Studierenden. Das zeigt der {\"U}bersichtsartikel der Trierer Psychologen. Die Forscher fassten alle bisher in der Fachliteratur publizierten Metaanalysen zu verschiedenen Faktoren akademischen Erfolgs Studierender zusammen. In die Auswertung gingen die relevantesten 38 Metaanalysen ein, mit Daten von insgesamt 3330 Einzelstudien und fast zwei Millionen Studierenden. (HoF/Text {\"u}bernommen). The last 2 decades witnessed a surge in empirical studies on the variables associated with achievement in higher education. A number of meta-analyses synthesized these findings. In our systematic literature review, we included 38 meta-analyses investigating 105 correlates of achievement, based on 3,330 effect sizes from almost 2 million students. We provide a list of the 105 variables, ordered by the effect size, and summary statistics for central research topics. The results highlight the close relation between social interaction in courses and achievement. Achievement is also strongly associated with the stimulation of meaningful learning by presenting information in a clear way, relating it to the students, and using conceptually demanding learning tasks. Instruction and communication technology has comparably weak effect sizes, which did not increase over time. Strong moderator effects are found for almost all instructional methods, indicating that how a method is implemented in detail strongly affects achievement. Teachers with high-achieving students invest time and effort in designing the microstructure of their courses, establish clear learning goals, and employ feedback practices. This emphasizes the importance of teacher training in higher education. Students with high achievement are characterized by high self-efficacy, high prior achievement and intelligence, conscientiousness, and the goal-directed use of learning strategies. Barring the paucity of controlled experiments and the lack of meta-analyses on recent educational innovations, the variables associated with achievement in higher education are generally well investigated and well understood. By using these findings, teachers, university administrators, and policymakers can increase the effectivity of higher education. (HoF/text adopted).;The last 2 decades witnessed a surge in empirical studies on the variables associated with achievement in higher education. A number of meta-analyses synthesized these findings. In our systematic literature review, we included 38 meta-analyses investigating 105 correlates of achievement, based on 3,330 effect sizes from almost 2 million students. We provide a list of the 105 variables, ordered by the effect size, and summary statistics for central research topics. The results highlight the close relation between social interaction in courses and achievement. Achievement is also strongly associated with the stimulation of meaningful learning by presenting information in a clear way, relating it to the students, and using conceptually demanding learning tasks. Instruction and communication technology has comparably weak effect sizes, which did not increase over time. Strong moderator effects are found for almost all instructional methods, indicating that how a method is implemented in detail strongly affects achievement. Teachers with high-achieving students invest time and effort in designing the microstructure of their courses, establish clear learning goals, and employ feedback practices. This emphasizes the importance of teacher training in higher education. Students with high achievement are characterized by high self-efficacy, high prior achievement and intelligence, conscientiousness, and the goal-directed use of learning strategies. Barring the paucity of controlled experiments and the lack of meta-analyses on recent educational innovations, the variables associated with achievement in higher education are generally well investigated and well understood. By using these findings, teachers, university administrators, and policymakers can increase the effectivity of higher education. (PsycINFO Database Record (c) 2017 APA, all rights reserved) (Source: journal abstract);},
  keywords = {Academic achievement,Academic Success,Achievement,Adult,Analysis,College students,Communication technology,Conscientiousness,Education - legislation & jurisprudence,Education Higher,Feedback,Female,Higher education,Humans,Individueller Unterschied,Innovations,Intelligence,Interpersonal Relations,Learning,Learning strategies,Literature reviews,Male,Meta-analysis,Metaanalyse,Policy making,Psychological aspects,Psychology,Psychology Multidisciplinary,Self-efficacy,Self-efficacy (Psychology),Social interaction,Social Sciences,Stimulation,Students - psychology,Systematic review,Teachers,Tertiare Bildung,Unterrichtsprozess,Variables}
}

@techreport{schornReplicatedTextDetection2015,
  title = {Replicated {{Text Detection}}: {{Test}} of {{TurnItIn}}},
  author = {Schorn, Susan},
  year = {2015},
  file = {/Users/colin.madland/Zotero/storage/5KF8WYLX/schornReplicatedTextDetection2015.pdf}
}

@article{schreiberIssuesRecommendationsExploratory2021,
  title = {Issues and Recommendations for Exploratory Factor Analysis and Principal Component Analysis},
  author = {Schreiber, James B.},
  year = {2021},
  journal = {Research in Social and Administrative Pharmacy},
  volume = {17},
  number = {5},
  pages = {1004--1011},
  issn = {15517411},
  doi = {10.1016/j.sapharm.2020.07.027},
  urldate = {2024-06-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/SGRM3YTU/schreiberIssuesRecommendationsExploratory2021.pdf}
}

@book{schreinerHandbookResearchAssessment2009,
  title = {Handbook of {{Research}} on {{Assessment Technologies}}, {{Methods}}, and {{Applications}} in {{Higher Education}}},
  author = {Schreiner, Christopher},
  year = {2009},
  publisher = {IGI Global},
  address = {Hershey},
  abstract = {This research publication accommodates in-depth studies that elucidate both the prospects and problems of learning assessment in higher education--Provided by publisher.},
  isbn = {978-1-60566-667-9},
  keywords = {College students,Data processing,Educational tests and measurements,Handbooks manuals etc,Rating of,United States},
  file = {/Users/colin.madland/Zotero/storage/IMETIXUV/schreinerHandbookResearchAssessment2009.pdf}
}

@misc{schroederPreparingStudentsAIEnhanced,
  title = {Preparing {{Students}} for the {{AI-Enhanced Workforce}}},
  author = {Schroeder, Ray},
  journal = {Inside Higher Ed},
  urldate = {2023-09-22},
  abstract = {Our graduating and certificate-completing students need documented generative AI skills, and they need them now. The common adage repeated again and again is that AI will not take your job; a person with AI skills will replace you. The learners we are teaching this fall who will be entering, re-entering or seeking advancement in the workforce at the end of the year or in the spring must become demonstrably skilled in using generative AI. The vast majority of white-collar jobs will demand the efficiencies and flexibilities defined by generative AI now and in the future. As higher education institutions, we will be called upon to document and validate generative AI skills.},
  howpublished = {https://www.insidehighered.com/opinion/blogs/online-trending-now/2023/09/15/preparing-students-ai-enhanced-workforce},
  langid = {english},
  keywords = {premium},
  file = {/Users/colin.madland/Zotero/storage/QEVJEPZX/schroederPreparingStudentsAIEnhanced.pdf;/Users/colin.madland/Zotero/storage/SV7GZLC7/preparing-students-ai-enhanced-workforce.html}
}

@article{schrumAuthenticLearningDisciplines2021,
  ids = {schrumAuthenticLearningDisciplines2021a},
  title = {Authentic {{Learning Across Disciplines}} and {{Borders}} with {{Scholarly Digital Storytelling}}},
  author = {Schrum, Kelly and Majury, Niall and Simonelli, Anne Laure},
  year = {2021},
  journal = {Teaching and learning inquiry},
  volume = {9},
  number = {2},
  pages = {1--16},
  publisher = {Univ Calgary Press},
  address = {CALGARY},
  issn = {2167-4779},
  doi = {10.20343/teachlearninqu.9.2.8},
  abstract = {Scholarly digital storytelling combines academic research and digital skills to communicate scholarly work within and beyond the classroom. This article presents three case studies that demonstrate efforts to integrate scholarly digital storytelling, a technology-enhanced assessment, across disciplines, geographic locations, and teaching contexts. The case studies originate in the United States, Northern Ireland [UK], and Norway, and represent learning across multiple disciplines, including history, higher education, geography, and biology. This article explores the potential for scholarly digital storytelling, when carefully planned, scaffolded, and implemented, to engage students in authentic learning, teaching students to think deeply and creatively about disciplinary content while creating sharable digital products.},
  keywords = {authentic learning,Case studies,Classrooms,College students,digital skills,Education,Education & Educational Research,Educational technology,Focus groups,Geography,Graduate students,Higher education,Humanities,Humanities and Social Sciences,Learning,Pedagogy,PEDAGOGY,Qualitative research,Scholarly communication,scholarly digital storytelling,Science,Social Sciences,Storytelling,Teaching,technology-enhanced assessment},
  file = {/Users/colin.madland/Zotero/storage/IBRN94AC/schrumAuthenticLearningDisciplines2021.pdf}
}

@article{schrumCultivatingResearchSkills2021,
  title = {Cultivating Research Skills through Scholarly Digital Storytelling},
  author = {Schrum, K and Bogdewiecz, S},
  year = {2021},
  journal = {Higher Education Research \& Development},
  issn = {0729-4360},
  doi = {10.1080/07294360.2021.2010667},
  abstract = {A fundamental responsibility of higher education institutions, across disciplines, is to develop student research skills. The exponential growth of digital scholarship, however, challenges traditional definitions of research. There is a need for deeper understanding of the ways in which students can develop and implement academic research skills and digital research skills simultaneously. This qualitative study explored graduate student engagement in scholarly digital storytelling, a technology-enhanced assessment, across multiple disciplines at a research university in the United States. Findings suggest that students developed the essential research skills of autonomy and flexible thinking along with multimodal research skills throughout the semester-long process of creating scholarly digital stories. Implications for utilizing technology-enhanced assessments, such as scholarly digital storytelling, in higher education are discussed.},
  langid = {english},
  keywords = {digital skills,EDUCATION,graduate education,inquiry-based learning,research skills,Technology-enhanced assessment}
}

@article{schrumDevelopingStudentCapacity2022,
  title = {Developing Student Capacity to Produce Digital Scholarship in the Humanities},
  author = {Schrum, K},
  year = {2022},
  journal = {Arts and Humanities in Higher Education},
  volume = {21},
  number = {2},
  pages = {158--175},
  issn = {1474-0222},
  doi = {10.1177/14740222211045246},
  abstract = {Despite the increased use of technology in higher education classrooms, we need a better understanding of pedagogical strategies that improve student ability to produce quality scholarly digital content in the humanities. This research was designed to examine student learning through scholarly digital storytelling, a technology-enhanced assessment The researcher collected data during and after an interdisciplinary, graduate scholarly digital storytelling course, including student work, student reflections, and individual interviews, to examine experiences at key points throughout the learning process. The results indicate that this pedagogical approach, when carefully scaffolded alongside formative feedback and ongoing student support, can increase student capacity-including digital agency, problem-solving skills, and digital knowledge production skills-to produce scholarly digital work in the humanities. Students can also learn to understand the interplay between disciplinary learning and digital skills and the ways in which both are essential for scholarly communication within and beyond the classroom.},
  langid = {english},
  keywords = {AGENCY,digital agency,digital knowledge production,graduate education,INQUIRY,PEDAGOGY,problem-solving,scholarly digital storytelling,Technology-enhanced assessment},
  file = {/Users/colin.madland/Zotero/storage/7X8H3N2M/schrumDevelopingStudentCapacity2022.pdf}
}

@book{schuelkaSageHandbookInclusion2019,
  title = {The {{Sage Handbook}} of {{Inclusion}} and {{Diversity}} in {{Education}}},
  author = {Schuelka, Matthew and Johnstone, Christopher and Thomas, Gary and Artiles, Alfredo},
  year = {2019},
  publisher = {SAGE Publications Ltd},
  address = {1 Oliver's Yard,~55 City Road~London~EC1Y 1SP},
  doi = {10.4135/9781526470430},
  urldate = {2021-07-04},
  isbn = {978-1-5264-3555-2 978-1-5264-7043-0}
}

@article{schultzDefiningMeasuringAuthentic2022,
  title = {Defining and Measuring Authentic Assessment: A Case Study in the Context of Tertiary Science},
  author = {Schultz, Madeleine and Young, Karen and K. Gunning, Tiffany and Harvey, Michelle L.},
  year = {2022},
  journal = {Assessment and evaluation in higher education},
  volume = {47},
  number = {1},
  pages = {77--94},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0260-2938},
  doi = {10.1080/02602938.2021.1887811},
  abstract = {This study explored perceptions and practices around authentic assessment within a diverse, science-based school at an Australian University. We were motivated to inquire into authentic assessment through a work-readiness lens, with the goal of embedding the assessment of skills that are transferable across a range of STEM roles and graduate roles requiring STEM skills. The findings from the project included overlapping perceptions of what is considered 'authentic' for staff and students. Four shared themes were: assessments that 1) demonstrated skills that will be used in future workplaces, 2) tested scientific concepts (not memorisation), 3) involved using critical thinking or problem-solving skills, and 4) included student choice or input into the assessment. We consolidated shared facets of these themes with the literature to define authentic assessment in our context. Based on the resulting operational definition, we built an online tool to allow academic staff to self-assess the inclusions and levels of authenticity in their assessment tasks. We further investigated some obstacles related to assessment design and delivery for science academic staff. This study sheds new light on the lived experiences of practicing academic staff in applying their visions of authentic assessment to improve outcomes for science graduates.},
  keywords = {Authentic assessment,Career preparation,Career Readiness,College Faculty,College Science,Context,Education & Educational Research,Educational evaluation,employability,Foreign Countries,graduate learning outcomes,Higher education,industry engagement,Performance Based Assessment,Problem solving,Self evaluation,Self Evaluation (Individuals),Social Sciences,STEM education,Student Attitudes,Student Evaluation,Students,Teacher Attitudes,Undergraduate Students,University graduates}
}

@incollection{schumacherLinkingAssessmentLearning2020,
  title = {Linking {{Assessment}} and {{Learning Analytics}} to {{Support Learning Processes}} in {{Higher Education}}},
  booktitle = {Learning, {{Design}}, and {{Technology}}},
  author = {Schumacher, Clara},
  editor = {Spector, Michael J and Lockee, Barbara B and Childress, Marcus D.},
  year = {2020},
  pages = {1--40},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-17727-4_166-1},
  urldate = {2021-01-04},
  isbn = {978-3-319-17727-4},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/UZN4TLTK/schumacherLinkingAssessmentLearning2020.pdf}
}

@article{schumannCocreatingValueTeaching2013,
  title = {Cocreating {{Value}} in {{Teaching}} and {{Learning Centers}}},
  author = {Schumann, David W. and Peters, John and Olsen, Taimi},
  year = {2013},
  journal = {New Directions for Teaching and Learning},
  volume = {2013},
  number = {133},
  pages = {21--32}
}

@article{Schtze_2018,
  title = {Stichwort Formatives Assessment},
  author = {Sch{\"u}tze, Birgit and Souvignier, Elmar and Hasselhorn, Marcus},
  year = {2018},
  journal = {Zeitschrift Fur Erziehungswissenschaft},
  doi = {10/ghhtsn},
  abstract = {Formatives Assessment gilt als eines der wirksamsten Rahmenkonzepte zur Forderung schulischen Lernens. Es bezeichnet die lernbegleitende Beurteilung von Schulerleistung mit dem Ziel, diagnostische Informationen zu nutzen, um Unterricht und Lernen zu verbessern. Grundlegende Merkmale von formativem Assessment sind die Klarung von Lernzielen, die Diagnose der individuellen Leistung sowie eine darauf basierende Ruckmeldung und Forderung. Die Gestaltung von formativem Assessment reicht von spontanem on-the-fly-Assessment bis hin zu im Voraus geplantem, formalisiertem und curricular eingebettetem Assessment. Studien untermauern die lernforderliche Wirkung von formativem Assessment, wobei diese von der konkreten Gestaltung abhangt. Obwohl politische, wissenschaftliche und schulische Entwicklungen zur Implementation von formativem Assessment beitragen, ist die Umsetzung nach wie vor herausfordernd. Im vorliegenden Beitrag wird der aktuelle Forschungsstand dargelegt, indem eine begriffliche Bestimmung und Charakterisierung des Konstrukts vorgenommen wird, empirische Befunde zur Wirksamkeit prasentiert sowie implementationsrelevante Entwicklungen und Herausforderungen beschrieben werden.},
  mag_id = {2810899917},
  pmcid = {null},
  pmid = {null},
  keywords = {guskey}
}

@book{schutzHandbookEducationalPsychology2024,
  title = {Handbook of Educational Psychology},
  editor = {Schutz, Paul A. and Muis, Krista R.},
  year = {2024},
  edition = {Fourth edition},
  publisher = {Routledge},
  address = {New York London},
  doi = {10.4324/9780429433726},
  abstract = {"The fourth edition of the Handbook of Educational Psychology, sponsored by Division 15 of the American Psychological Association, addresses new developments in educational psychology theory and research methods while honoring the legacy of the field's past. Comprised of thirty-one chapters written by a diverse group of recognized Educational Psychologist and/or Learning and Motivational Scientist (EDP/LMS) scholars, this volume provides integrative reviews and critical syntheses of inquiry across a variety of foundational and new areas. Key constructs like motivation, development, beliefs, literacy, and emotions are given substantive updates, while entire new chapters in touch on trends that have materialized since the publication of the third edition, such as inquiry world views, Critical Race Theory, cognitive neuroscience, and emerging technologies in education. Throughout this new edition, chapter authors coalesce on issues of social justice, situated approaches to inquiry, and progressive inquiry methods. The Handbook of Educational Psychology, Fourth Edition, will be an important reference volume for current and future EDP/LMS scholars, broadly conceived, as well as for teacher educators, practicing teachers, policy makers and the academic libraries serving these audiences. It is also appropriate for graduate-level courses in educational psychology, learning and motivational sciences, and research methods in education and psychology"--},
  isbn = {978-0-429-43372-6},
  langid = {english}
}

@book{schwartzAssessmentCaseStudies2002,
  title = {Assessment : Case Studies, Experience, and Practice from Higher Education},
  author = {Schwartz, Peter L. and Webb, Graham},
  year = {2002},
  series = {Case Studies of Teaching in Higher Education},
  publisher = {Routledge},
  address = {London},
  doi = {10.4324/9781315042589},
  abstract = {The fourth volume in this series deals with one of the ubiquitous higher and further education subjects. With a practice-based approach, the text avoids being overly academic and instead uses a case study format to detail a wide range of approaches to assessment.},
  isbn = {1-135-38409-6},
  keywords = {College teaching,Education Higher,Educational tests and measurements,Electronic books},
  file = {/Users/colin.madland/Zotero/storage/SIAUJ99H/schwartzAssessmentCaseStudies2002.pdf}
}

@article{scottFormativeAssessmentPractices2011,
  title = {Formative Assessment Practices in Built Environment Higher Education Programmes and the Enhancement of the Student Learning Experience},
  author = {Scott, Lloyd and Fortune, Chrisopher},
  year = {2011},
  journal = {null},
  doi = {null},
  abstract = {It is widely accepted across Higher Education (HE) that assessment has a strong link with learning and a key factor in this link is formative assessment. Formative assessment is generally defined as an activity taking place during a programme or unit of learning with the express purpose of improving and enhancing student learning. However, there is still considerable disagreement over the roles of lecturers and students in this process. It is therefore very important to understand how lecturers in built environment (BE) undergraduate education perceive their own roles and the role of their students in using assessment strategy to deliver deep learning. An investigation into lecturers' perceptions of their roles and their conceptions related to the assessment process of students in BE programmes is reported. An on-line survey was conducted with over 130 Irish BE academics involved with the delivery of undergraduate programmes in the areas of Architecture, Architectural Technology, Quantity Surveying and Construction Management. Additional data were also obtained and analysed from their associated programme documentation. Discussion is focused on a critical evaluation of the findings of the study with the current literature on the roles of BE academics in the formative assessment process. As a result recommendations are made on how lecturers may better formulate appropriate assessments for their students that will encourage deep learning and thus create enhanced HE learning experiences.},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@article{scottFormativeAssessmentPractices2011a,
  title = {Formative Assessment Practices in Built Environment Higher Education Programmes and the Enhancement of the Student Learning Experience},
  author = {Scott, Lloyd and Fortune, Chrisopher},
  year = {2011},
  journal = {null},
  doi = {null},
  abstract = {It is widely accepted across Higher Education (HE) that assessment has a strong link with learning and a key factor in this link is formative assessment. Formative assessment is generally defined as an activity taking place during a programme or unit of learning with the express purpose of improving and enhancing student learning. However, there is still considerable disagreement over the roles of lecturers and students in this process. It is therefore very important to understand how lecturers in built environment (BE) undergraduate education perceive their own roles and the role of their students in using assessment strategy to deliver deep learning. An investigation into lecturers' perceptions of their roles and their conceptions related to the assessment process of students in BE programmes is reported. An on-line survey was conducted with over 130 Irish BE academics involved with the delivery of undergraduate programmes in the areas of Architecture, Architectural Technology, Quantity Surveying and Construction Management. Additional data were also obtained and analysed from their associated programme documentation. Discussion is focused on a critical evaluation of the findings of the study with the current literature on the roles of BE academics in the formative assessment process. As a result recommendations are made on how lecturers may better formulate appropriate assessments for their students that will encourage deep learning and thus create enhanced HE learning experiences.},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@article{scottMatchingFinalAssessment2018,
  title = {Matching Final Assessment to Employability: Developing a Digital Viva as an End of Programme Assessment},
  author = {Scott, Margaret and Unsworth, John},
  year = {2018},
  journal = {Higher education pedagogies},
  volume = {3},
  number = {1},
  pages = {373--384},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {2375-2696},
  doi = {10.1080/23752696.2018.1510294},
  abstract = {While traditionally the viva voce examination had a central role in student assessment it fell out of favour as higher education expanded. This paper describes the development of a digital video viva examination to promote a more authentic and lower stakes method of assessment for students in their final under-graduate module. The paper presents a case study using a module from pre-registration nursing but the approach could be useful for other practice based and vocational disciplines in the health sciences, social work and business management and law. The paper describes the challenges of developing a truly authentic assessment when faced with academic requirements of the programme.~ The problems of video assessment include broadband speeds and file sharing are discussed.~ The authors were able to develop a lower stakes assessment with students on average recording and re-recording their viva submission 3.41 times and rehearsing it 3.67 times.},
  keywords = {authentic assessment,Case Studies,Computer Mediated Communication,Education & Educational Research,employability,Evaluation Criteria,Evaluation Methods,Foreign Countries,Higher Education,Information Technology,National Surveys,Nursing Education,Outcomes of Education,Performance Based Assessment,Social Media,Social Sciences,Student Attitudes,Student Evaluation,Testing Problems,Undergraduate Students,Video Technology,Viva examination},
  file = {/Users/colin.madland/Zotero/storage/H8B7KGCR/scottMatchingFinalAssessment2018.pdf}
}

@incollection{scrivenMethodologyEvaluation1967,
  title = {The Methodology of Evaluation},
  booktitle = {Perspectives of Curriculum Evaluation},
  author = {Scriven, Michael},
  editor = {Smith, B. Othanel},
  year = {1967},
  series = {Rand {{McNally Education Series}}},
  publisher = {Rand McNally},
  abstract = {Current conceptions of the evaluation of educational instruments (e.g. new curricula, programmed texts, inductive methods, in\- dividual teachers) are still inadequate both philosophically and practically. This paper attempts to exhibit and reduce some of the deficiencies. Intellectual progress is possible only because new\- comers can stand on the shoulders of giants. This feat is often con\- fused with treading on their toes, particularly but not only by the newcomer. I confess a special obligation to Professor Cronbach's (1963) work,2 and to valuable discussions with the personnel of CIRCE at the University of Illinois, as well as thoughtful cor\- respondence from several others, especially James Shaver.},
  mag_id = {1538058441},
  pmcid = {null},
  pmid = {null},
  keywords = {guskey,Invalid DOI},
  file = {/Users/colin.madland/Zotero/storage/47QXH4XQ/scrivenMethodologyEvaluation1967.pdf}
}

@incollection{seeberFailedPedagogyPunishment2016,
  ids = {seeberFailedPedagogyPunishment2016a},
  title = {The {{Failed Pedagogy}} of {{Punishment}}: {{Moving Discussions}} of {{Plagiarism}} beyond {{Detection}} and {{Discipline}}},
  shorttitle = {The {{Failed Pedagogy}} of {{Punishment}}},
  author = {Seeber, Kevin P},
  year = {2016},
  series = {Critical {{Library Pedagogy Handbook}}},
  publisher = {ACRL Press},
  doi = {10.25261/IR00000048},
  urldate = {2020-04-11},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/QT4REDF3/seeberFailedPedagogyPunishment2016.pdf;/Users/colin.madland/Zotero/storage/BMGTHFGT/00001.html}
}

@book{seifertEducationalPsychology2009,
  title = {Educational {{Psychology}}},
  author = {Seifert, Kelvin and Sutton, Rosemary},
  year = {2009},
  publisher = {Independent},
  urldate = {2020-04-29},
  abstract = {Chapters in the text can be assigned either from beginning to end, as with a conventional printed book, or they can be selected in some other sequence to meet the needs of particular students or classes. In general the first half of the book focuses on broader questions and principles taken from psychology per se, and the second half focuses on somewhat more practical issues of teaching. But the division between ``theory'' and ``practice'' is only approximate; all parts of the book draw on research, theory, and practical wisdom wherever appropriate. Chapter 2 is about learning theory, and Chapter 3 is about development; but as we point out, these topics overlap with each other as well as with the concerns of daily teaching. Chapter 4 is about several forms of student diversity (what might be called individual differences in another context), and Chapter 5 is about one form of diversity that has become prominent in schools recently---students with disabilities. Chapter 6 is about motivation, a topic that is heavily studied by psychological researchers, but that also poses perennial challenges to classroom teachers.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/ZEGA9HS3/seifertEducationalPsychology2009.pdf;/Users/colin.madland/Zotero/storage/HTK2MPZX/153.html}
}

@article{seifertOnlineSelfassessmentPeerassessment2019,
  title = {Online Self-Assessment and Peer-Assessment as a Tool to Enhance Student-Teachers' Assessment Skills},
  author = {Seifert, Tami and Feliks, Orna},
  year = {2019},
  journal = {Assessment and evaluation in higher education},
  volume = {44},
  number = {2},
  pages = {169--185},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0260-2938},
  doi = {10/gmbgtb},
  abstract = {Self-assessment and peer-assessment are strategies employed to encourage students to take more responsibility for the learning process. Although the advantages are not obvious, the process has the potential to empower learning and to assist the development of assessment skills, which are so important for future teachers. The research aimed to identify student-teachers' attitudes concerning the contribution of self-assessment and anonymous peer-assessment to the quality of their assignments and improvement of their assessment skills, using both qualitative and quantitative methodologies. The sample included 300 students studying for bachelor's or master's degrees. Texts that were analysed included: responses to a questionnaire, self and peer-assessments, word comments on the assignments and written blog content relating to students' activities and their performance of peer evaluations. The students noted that they significantly benefitted from the process, learned various methods of assignment and assessment performance and it positioned them in relation to others, noticing how others evaluated them. Anonymous evaluation allowed students to overcome inhibitions in evaluating peers' works and improved their assessment skills.},
  keywords = {anonymous assessment,Assignments,Blogs,Computer Uses in Education,Education & Educational Research,Graduate Students,Learning,online assessment,Peer Evaluation,Peer-assessment,Peers,Preservice Teacher Education,Preservice Teachers,Questionnaires,rubric,Self evaluation,Self Evaluation (Individuals),self-assessment,Skills,Social Sciences,Student Attitudes,Student teacher relationship,Students,Teacher attitudes,Undergraduate Students}
}

@article{sekendizUtilisationFormativePeerassessment2018,
  title = {Utilisation of Formative Peer-Assessment in Distance Online Education: A Case Study of a Multi-Model Sport Management Unit},
  author = {Sekendiz, B},
  year = {2018},
  journal = {Interactive Learning Environments},
  volume = {26},
  number = {5},
  pages = {682--694},
  issn = {1049-4820},
  doi = {10.1080/10494820.2017.1396229},
  abstract = {Higher education system has been globally evolving over time with the development of courses that offer distance online models of delivery to meet the changing needs of students in an era of technology-driven transformation. However, one of the biggest challenges of distance online education has been higher attrition rates mostly due to difficulties in engaging the students in the learning process adequately. In this regard, peer-assessment has been recommended in the literature as an interactive method to optimise student engagement and learning in collaborative environments. This study demonstrates how formative peer-assessment was utilised in an online multi-model sport management unit to enhance engaged learning outcomes.},
  langid = {english},
  keywords = {Distance education,FEEDBACK,formative peer-assessment,learner engagement,online education,peer-feedback,sport management}
}

@book{selwynDigitalTechnologyContemporary2014,
  title = {Digital {{Technology}} and the {{Contemporary University}}: {{Degrees}} of Digitization},
  shorttitle = {Digital {{Technology}} and the {{Contemporary University}}},
  author = {Selwyn, Neil},
  year = {2014},
  month = may,
  edition = {1},
  publisher = {Routledge},
  urldate = {2022-02-04},
  isbn = {978-1-315-76865-6},
  langid = {english},
  keywords = {archived},
  file = {/Users/colin.madland/Zotero/storage/9MHIERM5/selwynDigitalTechnologyContemporary2014.pdf}
}

@article{selwynEditorialPraisePessimism2011,
  title = {Editorial: {{In}} Praise of Pessimism---the Need for Negativity in Educational Technology},
  shorttitle = {Editorial: {{In}} Praise of Pessimism---the Need for Negativity in Educational Technology},
  author = {Selwyn, Neil},
  year = {2011},
  journal = {British Journal of Educational Technology},
  volume = {42},
  pages = {713--718},
  issn = {1467-8535},
  doi = {10.1111/j.1467-8535.2011.01215.x},
  annotation = {5}
}

@book{selwynEducationTechnologyKey2022,
  title = {Education and Technology: Key Issues and Debates},
  shorttitle = {Education and Technology},
  author = {Selwyn, Neil},
  year = {2022},
  edition = {Third edition},
  publisher = {Bloomsbury Academic},
  address = {London ; New York},
  abstract = {"What does the future hold for digital technology and education? What can be learnt from the history of technology use in education? Does digital technology make education more individualized? Will it eventually replace the school, university and teacher? In a thoroughly revised edition of this successful book, Neil Selwyn takes a critical look at some of the major current debates and controversies concerning digital technologies and education. Focusing on the social as well as the technical aspects of these issues, Selwyn addresses fundamental but often unvoiced questions about education and technology. Over the course of eight chapters, the book gives careful thought to the people, practices, processes and structures behind the rapidly increasing use of technologies in education, with an emphasis on the implications of digital technologies for individuals and institutions. Brand new chapters on trends in AI and 'big data' driven automation of education, and the future(s) of education and technology are included. This edition also features new sections exploring 'post-digital' perspectives, personalized learning, digital labour, and the impending need for sustainable forms of digital education. The book focuses attention on the connections between recent technology developments and broader changes in education practice, education policy and education theory over the past few decades. It also challenges us to reflect on future directions and controversies for education in the (post)digital age. Expanded study questions, annotated further reading and a new glossary of key terms are included to support readers. An updated companion website links to bonus chapters and audio recordings for further discussion"--},
  isbn = {978-1-350-14553-5 978-1-350-14556-6},
  lccn = {LB1028.3},
  keywords = {Computer-assisted instruction,Curricula,Educational technology,Internet in education,Study and teaching,United States},
  file = {/Users/colin.madland/Zotero/storage/DQCLUDQI/selwynEducationTechnologyKey2022.pdf}
}

@article{selwynITNotJust1996,
  title = {{{IT}}'s {{Not Just}} a {{Kids}}' {{Revolution}}: An Empirical Study of Adult Computer Learners},
  shorttitle = {{{IT}}'s {{Not Just}} a {{Kids}}' {{Revolution}}},
  author = {Selwyn, Neil and Moss, Dennis},
  year = {1996},
  month = jan,
  journal = {Research in Post-Compulsory Education},
  volume = {1},
  number = {3},
  pages = {275--290},
  issn = {1359-6748, 1747-5112},
  doi = {10.1080/1359674960010301},
  urldate = {2022-11-27},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/J3NTSSTI/selwynITNotJust1996.pdf}
}

@article{selwynLookingLearningNotes2010,
  title = {Looking beyond Learning: Notes towards the Critical Study of Educational Technology: {{Looking}} beyond Learning},
  shorttitle = {Looking beyond Learning},
  author = {Selwyn, N.},
  year = {2010},
  month = jan,
  journal = {Journal of Computer Assisted Learning},
  volume = {26},
  number = {1},
  pages = {65--73},
  issn = {02664909, 13652729},
  doi = {10.1111/j.1365-2729.2009.00338.x},
  urldate = {2023-01-09},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/FUXWT727/selwynLookingLearningNotes2010.pdf}
}

@article{selwynMakingSenseYoung2012,
  title = {Making Sense of Young People, Education and Digital Technology: The Role of Sociological Theory},
  author = {Selwyn, Neil},
  year = {2012},
  month = feb,
  journal = {Oxford Review of Education},
  volume = {38},
  number = {1},
  pages = {81--96},
  publisher = {Routledge},
  issn = {0305-4985},
  doi = {10/bhcv58},
  file = {/Users/colin.madland/Zotero/storage/IHZGN7GU/selwynMakingSenseYoung2012.pdf}
}

@article{selwynMindingOurLanguage2016,
  title = {Minding Our Language: Why Education and Technology Is Full of Bullshit\,{\dots}\,and What Might Be Done about It},
  author = {Selwyn, Neil},
  year = {2016},
  journal = {Learning, Media and Technology},
  volume = {41},
  number = {3},
  pages = {437--443},
  issn = {1743-9884},
  doi = {10.1080/17439884.2015.1012523},
  file = {/Users/colin.madland/Zotero/storage/5QYGINIL/selwynMindingOurLanguage2016.pdf}
}

@article{selwynNecessaryEvilRise2021,
  title = {A Necessary Evil? {{The}} Rise of Online Exam Proctoring in {{Australian}} Universities},
  shorttitle = {A Necessary Evil?},
  author = {Selwyn, Neil and O'Neill, Chris and Smith, Gavin and Andrejevic, Mark and Gu, Xin},
  year = {2021},
  month = apr,
  journal = {Media International Australia},
  pages = {1329878X2110058},
  issn = {1329-878X, 2200-467X},
  doi = {10/gj6tzt},
  urldate = {2021-05-25},
  abstract = {The COVID-19 pandemic has seen the rapid but sometimes controversial take-up of `online examination proctoring' systems by universities keen to maintain their assessment schedules during times of campus closure. Following the theoretical tradition of media `domestication', this article examines the mainstream adoption of different online proctoring systems in Australian higher education during the first year of the pandemic. Through analysis of interviews, documents, news, social media and marketing materials, the article examines the `appropriation', `objectification', incorporation' and `conversion' of proctoring technology from the perspective of commercial providers, university authorities, university staff and student groups. This raises a number of critical issues underpinning the adoption of this exam surveillance technology -- not least the surrender of control to commercial providers, the hidden labour required to sustain `automated' systems and the increased vulnerabilities of `remote' studying.},
  langid = {english}
}

@book{selwynTechnologyGoodEducation2016,
  title = {Is Technology Good for Education?},
  author = {Selwyn, Neil},
  year = {2016},
  publisher = {Malden, MA},
  address = {Cambridge, UK},
  isbn = {978-0-7456-9646-1},
  keywords = {Computer-assisted instruction -- Evaluation,Education -- Aims and objectives,Education -- Effect of technological innovations on,Educational technology -- Evaluation}
}

@article{selwynUseComputerTechnology2007,
  title = {The Use of Computer Technology in University Teaching and Learning: A Critical Perspective: {{A}} Critical Look at Computer Use in Higher Education},
  shorttitle = {The Use of Computer Technology in University Teaching and Learning},
  author = {Selwyn, N.},
  year = {2007},
  month = jan,
  journal = {Journal of Computer Assisted Learning},
  volume = {23},
  number = {2},
  pages = {83--94},
  issn = {02664909, 13652729},
  doi = {10.1111/j.1365-2729.2006.00204.x},
  urldate = {2022-05-22},
  abstract = {Despite huge efforts to position information and communication technology (ICT) as a central tenet of university teaching and learning, the fact remains that many university students and faculty make only limited formal academic use of computer technology. Whilst this is usually attributed to a variety of operational deficits on the part of students, faculty, and universities, this paper considers the wider social relations underpinning the relatively modest use of technology in higher education. The paper explores how university use of computer technology is shaped into marginalized and curtailed positions by a variety of actors. From the `writing' of ICT at a national policy level through to the marginalization of ICT within the lived `student experience', a consistent theme emerges where computer technology use is constructed in limited, linear, and rigid terms far removed from the creative, productive, and empowering uses which are often celebrated by educational technologists. In the light of such constraints, the paper considers how these dominant constructions of a peripheral and limited use of ICT may be challenged by the higher education community. In particular, it concludes by reflecting on current critical thinking about how educational technologists can foster a more expansive and empowered use of computer technology within university settings.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/M2VWN48N/selwynUseComputerTechnology2007.pdf}
}

@article{selwynWhatMightSchool2020,
  title = {What Might the School of 2030 Be like? {{An}} Exercise in Social Science Fiction},
  author = {Selwyn, Neil and Pangrazio, Luci and Nemorin, Selena and Perrotta, Carlo},
  year = {2020},
  journal = {Learning, Media and Technology},
  volume = {45},
  number = {1},
  pages = {90--106},
  publisher = {Routledge},
  issn = {1743-9884},
  doi = {10/ggfbkn}
}

@article{selwynWhatNextEdTech2020,
  title = {What's next for {{Ed-Tech}}? {{Critical}} Hopes and Concerns for the 2020s},
  shorttitle = {What's next for {{Ed-Tech}}?},
  author = {Selwyn, Neil and Hillman, Thomas and Eynon, Rebecca and Ferreira, Giselle and Knox, Jeremy and Macgilchrist, Felicitas and {Sancho-Gil}, Juana M.},
  year = {2020},
  month = jan,
  journal = {Learning, Media and Technology},
  volume = {45},
  number = {1},
  pages = {1--6},
  issn = {1743-9884, 1743-9892},
  doi = {10.1080/17439884.2020.1694945},
  urldate = {2021-01-14},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/KB3WM6LP/selwynWhatNextEdTech2020.pdf}
}

@article{senelRemoteAssessmentHigher2021,
  title = {Remote {{Assessment}} in {{Higher Education}} during {{COVID-19 Pandemic}}},
  author = {Senel, Selma and Senel, Huseyin Can},
  year = {2021},
  month = jan,
  journal = {International Journal of Assessment Tools in Education},
  volume = {8},
  number = {2},
  pages = {181--199},
  publisher = {International Journal of Assessment Tools in Education},
  issn = {2148-7456},
  abstract = {Universities have made a compulsory shift to distance education due to the Covid-19 pandemic. All of the higher education institutions in Turkey have completed 2019-2020 Spring semester using online tools. However, most of these institutions were not fully-prepared to have all of their courses online. Technical inadequacies, lack of qualified online tools, inexperience of instructors and students in distance education have emerged as major issues that institutions have to face. In addition to all, a new question arised; which approaches will be used for assessment. This study aimed to seek the common assessment approaches used through pandemic, how students perceived the quality of the assessment and the pros and cons of using these practices. Additionally, we examined whether participants' perceptions about quality of the assessment differ according to interaction with faculty members and use of online tests. Researchers employed survey design to reply four research questions and used a three-part instrument to collect qualitative and quantitative data. 486 students from 61 universities voluntarily participated in the study. Results indicated assignments are the mostly used tools and students are generally satisfied about the quality of the assessment practices. Another result is that students who interact with faculty members are more satisfied with the quality of the assessment practices. This emphasizes the importance of formative assessment and feedback in remote assessment. Further, students who took online tests are more satisfied with the quality of assessment. Suggestions were made for future research.},
  keywords = {Computer Assisted Testing,COVID-19,Distance Education,Feedback (Response),Foreign Countries,Formative Evaluation,Higher Education,Interaction,No DOI found,Pandemics,Student Evaluation,Student Satisfaction,Teacher Student Relationship,Turkey,Undergraduate Students}
}

@article{senelUseTakeHomeExam2021,
  title = {Use of {{Take-Home Exam}} for {{Remote Assessment}}: {{A Case Study}} from {{Turkey}}},
  author = {Senel, Selma and Senel, H{\"u}seyin Can},
  year = {2021},
  month = jan,
  journal = {Journal of Educational Technology and Online Learning},
  volume = {4},
  number = {2},
  pages = {236--255},
  publisher = {{Journal of Educational Technology and Online Learning}},
  issn = {2618-6586},
  abstract = {COVID-19 has changed the way we teach. Today, we have become far more experienced in the delivery of distance education and use of online tools. However, the quality of distance education and learning outcomes have become a matter of ongoing debate. Just as higher education aims to develop high-level skills in its students, researchers are seeking ways to perform valid and reliable assessment in distance education. Institutions and educators are also in search of assessment tools that can help prevent instances of cheating and plagiarism. However, performance-based assessment tools may also offer options to measure both high-level skills and in limiting cheating behaviors. In this study, we used the take-home exam as a formative remote assessment tool as a local case in Turkey. We surveyed the views of 43 undergraduate students about the quality of take-home exams as a remote assessment tool. The results showed that participants had a high quality perception about the use of take-home exam, especially with regards to being kept informed about evaluation and scoring, rapid assessment, the provision of feedback, and consistency of scope between assessment and course content. Whereas students highly perceived the use of take-home exams, they reported more moderate views regarding take-home exams increasing the level of interaction with their peers. The results of this study suggest that the use of take-home exams is significantly preferred by higher education students, that it is a reliable and distinctive way to measure students' academic performance, and may increase student-teacher interaction through its formative use.},
  keywords = {Affordances,Computer Assisted Testing,COVID-19,Distance Education,Foreign Countries,Formative Evaluation,Late Adolescents,No DOI found,Pandemics,Performance Based Assessment,Preferences,Public Colleges,Statistics Education,Test Format,Test Reliability,Turkey,Undergraduate Students}
}

@article{seppShiftingOnline122022,
  title = {Shifting Online: 12 Tips for Online Teaching Derived from Contemporary Educational Psychology Research},
  author = {Sepp, Stoo and Wong, Mona and Hoogerheide, Vincent and {Castro-Alonso}, Juan Cristobal},
  year = {2022},
  month = jul,
  journal = {Journal of Computer Assisted Learning},
  volume = {38},
  number = {5},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {0266-4909},
  doi = {10.1111/jcal.12715},
  urldate = {2022-07-10},
  abstract = {Abstract Background As a result of the COVID-19 pandemic, many teachers found themselves making a rapid and often challenging shift from in-person classroom teaching to teaching in an online environment. As teachers continue to learn about working in this new environment, research in cognitive and learning sciences, specifically findings from cognitive load theory and related areas, can provide meaningful strategies for teaching in this ?new normal?. Objectives This paper describes 12 tips derived from contemporary research in educational psychology, focusing particularly on empirically supported strategies that teachers may apply in their online classroom to ensure that learning is optimized. Implications for Practice These strategies are generalizable across age groups and learning areas, and are categorized into one of two themes: approaches to optimize the design of online learning materials, and instructional strategies to support student learning. A discussion follows, outlining how teachers may apply these strategies in different contexts, with a brief overview of emerging efforts that aim to bridge cognitive load theory and self-regulated learning research.},
  keywords = {cognitive load theory,cognitive theory of multimedia learning,generative and self-regulated learning,online teaching and learning},
  file = {/Users/colin.madland/Zotero/storage/REWIK5JJ/seppShiftingOnline122022.pdf}
}

@article{serenkoStudentSatisfactionCanadian2011,
  title = {Student Satisfaction with {{Canadian}} Music Programmes: The Application of the {{American Customer Satisfaction Model}} in Higher Education},
  shorttitle = {Student Satisfaction with {{Canadian}} Music Programmes},
  author = {Serenko, Alexander},
  year = {2011},
  month = may,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {36},
  number = {3},
  pages = {281--299},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602930903337612},
  urldate = {2023-09-19},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/6SACREPI/serenkoStudentSatisfactionCanadian2011.pdf}
}

@article{serranoCriticalPedagogyAssessment2018,
  title = {Critical {{Pedagogy}} and Assessment in Higher Education: {{The}} Ideal of `Authenticity' in Learning},
  author = {Serrano, Maria Martinez and O'Brien, Mark and Roberts, Krystal and Whyte, David},
  year = {2018},
  journal = {Active learning in higher education},
  volume = {19},
  number = {1},
  pages = {9--21},
  publisher = {SAGE Publications},
  address = {London, England},
  issn = {1469-7874},
  doi = {10/gc3z8g},
  abstract = {Current forms of marketisation in university systems create pressures towards purely ends-focused expectations among students and have implications for learning and assessment processes. The potential harm that these trends have on `learning' should be resisted by educators and students alike. Critical Pedagogy approaches offer one way of conceptualising and implementing such resistance in the interests of `authenticity' in learning. However, the issue becomes sharpest at the point of assessment. Here, the ideals of Critical Pedagogy can collide with student expectations of final degree success. By addressing the question of `authenticity' for assessment in relation to Critical Pedagogy, this article explores the challenges posed by this conundrum and draws upon interviews conducted with module leaders who apply recognisably (although not explicitly) Critical Pedagogy principles in their teaching and in the types of assessment they use. The themes that emerged present a picture of the kinds of potential that Critical Pedagogy influenced forms of assessment have for supporting authenticity in learning, as well as the difficulties involved in its application. It also helps to trace out the possible boundaries for further inquiry.},
  keywords = {Active Learning,Barriers,Critical Theory,Education & Educational Research,Familiarity,Foreign Countries,Higher Education,Humanities,Independent Study,Institutional Characteristics,Interviews,Learning Modules,Learning Processes,Resistance (Psychology),Social Sciences,Student Educational Objectives,Student Evaluation,Student Motivation,Teacher Attitudes,Teacher Surveys}
}

@phdthesis{seseTeacherPerceptionsAlternative2020,
  title = {Teacher {{Perceptions}} of {{Alternative Grading}} to {{Support Authentic Learning}}},
  author = {Sese, Gina},
  year = {2020},
  journal = {ProQuest Dissertations and Theses},
  address = {Ann Arbor},
  abstract = {Alternative grading practices are often used in authentic learning environments where the focus is on connecting instruction to real-world issues, problems, and applications. Scholarly literature lacks research studies related to teacher perceptions of alternative grading to support authentic learning. The purpose of this basic qualitative study was to explore the perceptions of high school science teachers regarding their use of alternative grading to support authentic learning, student self-reflection, and student articulation of their learning. The conceptual framework for this study was based on Herrington and Oliver's instructional design framework for authentic learning environments. The focus of the research questions was on how high school science teachers perceive their implementation of alternative grading as a support for authentic learning, student reflection, and student articulation of their learning. Data were collected from 11 high school science teachers using qualitative interviews. Participants were selected through the purposeful sampling method. The data collected were then coded by hand and using qualitative data analysis software to discover emergent themes. Findings indicated that educators perceived their use of alternative grading, student self-reflection, and articulation opportunities to be essential for supporting student learning in an authentic learning environment. This study may contribute to best practices in education by providing school district administrators with information they can use to develop professional development for new teachers that is focused on alternative assessment strategies. With this knowledge, educators may be more empowered to provide education that prepares students for real-world challenges.},
  isbn = {9798662460584},
  langid = {english},
  school = {Walden University},
  keywords = {0456:Pedagogy,0458:Education Policy,0714:Science education,Alternative assessment,Alternative grading,Articulation,Education policy,Employability agenda,Pedagogy,Science education,Self reflection,Workforce skills},
  annotation = {28025617},
  file = {/Users/colin.madland/Zotero/storage/R8VPZKDK/seseTeacherPerceptionsAlternative2020.pdf}
}

@article{sesserExploringRoleFeedback2019,
  title = {Exploring the {{Role}} of {{Feedback}} and Its {{Impact}} within a {{Digital Badge System}} from {{Student Perspectives}}},
  author = {Sesser, {\relax ED} and Newby, {\relax TJ}},
  year = {2019},
  journal = {TechTrends},
  volume = {63},
  number = {4},
  pages = {485--495},
  issn = {8756-3894},
  doi = {10.1007/s11528-019-00386-2},
  abstract = {In academic settings where digital badges are taking over conventional task formats, educators are faced with the challenge of how to deliver and assess content and skills within badges. Imposing a mastery learning approach, where feedback is key, to a digital badge system may be a potential solution to using digital badges within higher education. As a way to support student learning, Guskey, Journal of Advanced Academics, 19(1), 8-31 (2007) emphasizes the importance of not only frequent feedback but specific feedback. In order to examine how students are using feedback to inform their coursework within a digital badge context, an online survey was designed consisting of open-ended questions about the nature and value of instructional feedback within a digital badge system. Results from the questionnaire indicated three major thematic groups illustrating feedback from the students' perspective: Importance and Nature of Feedback, Authority over Knowledge and Learning, and Learning for Mastery.},
  langid = {english},
  keywords = {7 PRINCIPLES,Digital badges,EDUCATION,Feedback,Mastery learning,METAANALYSIS,PEER-ASSESSMENT,Qualitative research}
}

@misc{sesyncannapolisFoundationsDebatesAnthropology,
  title = {Foundations and Debates in Anthropology},
  author = {{sesync annapolis}},
  urldate = {2018-09-14},
  collaborator = {West, Paige},
  keywords = {Paige West}
}

@article{shachakTAMUTAUTFuture2019,
  title = {Beyond {{TAM}} and {{UTAUT}}: {{Future}} Directions for {{HIT}} Implementation Research},
  shorttitle = {Beyond {{TAM}} and {{UTAUT}}},
  author = {Shachak, Aviv and Kuziemsky, Craig and Petersen, Carolyn},
  year = {2019},
  month = dec,
  journal = {Journal of Biomedical Informatics},
  volume = {100},
  pages = {103315},
  issn = {1532-0464},
  doi = {10.1016/j.jbi.2019.103315},
  urldate = {2023-10-17},
  abstract = {The Technology Acceptance Model (TAM) and Unified Theory of Acceptance and Use of Technology (UTAUT) have been used widely in studies of health information technology (HIT) implementation. However, TAM and UTAUT have also been criticized for being overly simplistic (TAM) and for taking a narrow perspective, which focuses only on individual adopters' beliefs, perceptions and usage intention. Furthermore, with thousands of studies using these theories, their contribution to knowledge has reached a plateau. In this commentary, we discuss some of the criticism of TAM and UTAUT, and argue that biomedical informatics research would benefit from shifting attention from these theories to multi-dimensional approaches that can better capture the complexity of issues surrounding implementation and use of HIT. We propose a number of future undertakings which, in our opinion, are more likely to move the field forward.},
  keywords = {Complexity science,Health information technology implementation,Technology acceptance model,Technology use,Unified theory of acceptance and use of technology},
  file = {/Users/colin.madland/Zotero/storage/E6FTQQ24/shachakTAMUTAUTFuture2019.pdf}
}

@article{shachmutBuildingFluentAssistive2019,
  title = {Building a {{Fluent Assistive Technology Testing Pool}} to {{Improve Campus Digital Accessibility}} ({{Practice Brief}})},
  author = {Shachmut, Kyle and Deschenes, Amy},
  year = {2019},
  month = dec,
  journal = {Journal of Postsecondary Education and Disability},
  volume = {32},
  number = {4},
  pages = {445--452},
  publisher = {{Journal of Postsecondary Education and Disability}},
  issn = {2379-7762},
  abstract = {Usability testing that includes people who are fluent in assistive technology is an important way to ensure that digital products meet the needs of all users. In settings such as universities, with highly distributed content creator networks and vast differences in project sizes and scopes, it can be challenging for non-experts to find and use the best methods to assess accessibility. This article describes creation of a pilot pool of fluent assistive technology users from the surrounding geographic area made widely available internally to university content creators. The availability of the pool (n = 40) provided increased capacity to test internally developed products and vended solutions, increasing overall accessibility assessments at the university. Authors review the benefits and challenges in creating the participant pool, along with implementation details. Further discussion includes efficiencies for the university, learning by content creators, and potential directions for future research.},
  keywords = {Academic Libraries,Accessibility (for Disabled),Assistive Technology,College Faculty,Courseware,No DOI found,Staff Role,Students with Disabilities,Testing,Universities,Usability,Video Technology,Web Sites}
}

@article{shahjahanMappingFieldAntiColonial2005,
  title = {Mapping the {{Field}} of {{Anti-Colonial Discourse}} to {{Understand Issues}} of {{Indigenous Knowledges}}: {{Decolonizing Praxis}}},
  author = {Shahjahan, Riyad Ahmed},
  year = {2005},
  journal = {McGill Journal of Education},
  volume = {40},
  number = {2},
  pages = {213--40},
  issn = {0024-9033},
  abstract = {In this paper, I examine some of the past and current issues in anti-colonial discourse by briefly reviewing the ideas of thirteen anti-colonial scholars from different regions of the world. I relate these ideas to the discussion of knowledge production and indigenous knowledges. I also examine some critical areas that require more attention from future decolonizing scholarship and practice. With respect to scholarship, these critical areas include: the question of agency; the ambivalence towards Euro-American thought; recognizing the dynamism among knowledge systems; language accessibility; integrating indigenous ways of knowing, and dismantling the academic regime. In addition, I suggest that the questions of decolonizing one's spirit and recognizing the importance of spirituality, often ignored, are very important to integrate in decolonizing practice. This paper concludes by challenging anti-colonial scholars to open possibilities for ourselves and others by "walking the talk" in our scholarly endeavours and every day lives. (Contains 5 notes.);~ In this paper, I examine some of the past and current issues in anti-colonial discourse by briefly reviewing the ideas of thirteen anti-colonial scholars from different regions of the world. I relate these ideas to the discussion of knowledge production and indigenous knowledges. I also examine some critical areas that require more attention from future decolonizing scholarship and practice. With respect to scholarship, these critical areas include: the question of agency; the ambivalence towards Euro-American thought; recognizing the dynamism among knowledge systems; language accessibility; integrating indigenous ways of knowing, and dismantling the academic regime. In addition, I suggest that the questions of decolonizing one's spirit and recognizing the importance of spirituality, often ignored, are very important to integrate in decolonizing practice. This paper concludes by challenging anti-colonial scholars to open possibilities for ourselves and others by "walking the talk" in our scholarly endeavours and every day lives. [PUBLICATION ABSTRACT];},
  keywords = {Colonialism,Culture,Discourse Analysis,Education,Foreign Countries,Foreign Policy,Indigenous Knowledge,Knowledge,literary theory and criticism,postcolonial literary theory and criticism,Religious Factors,Scholarship,Spirituality}
}

@article{shahjahanRekindlingSacredDecolonizing2009,
  title = {Rekindling the {{Sacred}}: {{Toward}} a {{Decolonizing Pedagogy}} in {{Higher Education}}},
  author = {Shahjahan, Riyad Ahmed and Wagner, Anne and Wane, Njoki Nathani},
  year = {2009},
  journal = {Journal of Thought},
  volume = {44},
  number = {1-2},
  pages = {59--75},
  issn = {0022-5231},
  doi = {10.2307/jthought.44.1-2.59},
  abstract = {[.] we conclude by discussing the implications of a decolonizing pedagogy that centers spirituality in the context of a transformative teaching project in higher education. A decolonizing pedagogy provides us with the following tools for transformative education: * To emphasize in our teaching the importance of self, subjectivity and interdependence with others who form our community. * To create a learning environment that begins by nurturing the inner self, the inner connections and allows space for personal development. * To understand the challenges of bringing spirituality into the academy. * To acknowledge and accept that there are multiple ways of knowing and theorizing equity issues, and to use these methods to make an inclusive curriculum and pedagogy. * To allow for alternative epistemological viewpoints to be expressed and legitimized within the classroom. * To promote a sense of compassion, respect, and understanding among all participants. * To acknowledge humility in teaching and learning and accept the uncertainty and discomfort that arises within the classroom. * To promote a language and embodiment of healing among students in anti-oppressive pedagogy. * To recover a sense of sacredness in knowing, teaching, and learning.},
  keywords = {Behavioral sciences,Classroom activities,Cognitive processes,Cognitive psychology,Communications,Cultural identity,Education,Educational activities,Environmental education,Environmental studies,Epistemology,Formal education,Higher education,Information life cycle,Information management,Information production,Information science,Learning,Multiculturalism,Narratives,Pedagogy,Personal development,Philosophy,Political communication,Political discourse,Political science,Political sociology,Psychology,Religion,Social sciences,Spiritual belief systems,Spirituality,Teachers,Teaching}
}

@article{shaikInteractiveDesignTool2023,
  title = {An {{Interactive Design Tool}} for {{Assessing Student}} Understanding in {{Digital Environments}}},
  author = {Shaik, Asif Hussain and Prabhu, Madhava and Hussain, Shaik Mazhar and Poloju, Kiran Kumar},
  year = {2023},
  journal = {SHS Web of Conferences},
  volume = {156},
  pages = {9004},
  publisher = {EDP Sciences},
  address = {Les Ulis},
  issn = {2261-2424},
  doi = {10.1051/shsconf/202315609004},
  abstract = {Various e-tools and interactive media have improved and enhanced the teaching and learning in higher education. For example, flipped teaching pedagogy encourages the students to engage in the various in-class activities rather than just to be a passive learner by listening to the lectures. On the other hand, newly joined students have trouble understanding the key modules since they don't know the fundamental concepts related to the modules. This paper illustrates how online quiz creators and education tools might improve the student performance in academic setup. The online quiz creator has numerous styles, including photo quizzes, team quizzes, one-page quizzes, image quizzes, memory games, and match games for dynamic, energetic, and passionate student engagement. Students may self-assess their progress using ICT-based online quizzes. This platform assists with student engagement and learning to make them active learner. Students are greatly motivated by various learning styles and technology that suits them. This also has helped the students to avoid a random online tool and join a safe environment to enhance their learning. Supporting multiple learning styles is one of the techniques that should be implemented in every module delivery. The effectiveness of using these practices in teaching is measured through student feedback. Based on their responses, it is concluded that many benefits are found by adapting these practices, such as students' increased interest in their modules, improved understanding skills, and relational abilities.},
  keywords = {assessment,Cognitive style,foss,Learning,online,quiz,Student participation,technology},
  file = {/Users/colin.madland/Zotero/storage/ASZ3NP77/shaikInteractiveDesignTool2023.pdf}
}

@inproceedings{shalatskaImplementationEassessmentHigher2020,
  title = {Implementation of {{E-assessment}} in {{Higher Education}}},
  author = {Shalatska, Hanna and {Zotova-Sadylo}, Olena and Makarenko, Olexandr and Dzevytska, Larysa},
  year = {2020},
  publisher = {CEUR Workshop Proceedings},
  doi = {10.31812/123456789/4466},
  file = {/Users/colin.madland/Zotero/storage/R2GS84SF/shalatskaImplementationEassessmentHigher2020.pdf;/Users/colin.madland/Zotero/storage/3RUFR85P/3598.html}
}

@article{shanahanShiftingRolesApproaches2007,
  title = {Shifting Roles and Approaches: Government Coordination of Post-secondary Education in {{Canada}}, 1995--2006},
  shorttitle = {Shifting Roles and Approaches},
  author = {Shanahan, Theresa and Jones, Glen A.},
  year = {2007},
  month = mar,
  journal = {Higher Education Research \& Development},
  volume = {26},
  number = {1},
  pages = {31--43},
  issn = {0729-4360, 1469-8366},
  doi = {10/cd9vzx},
  urldate = {2021-07-06},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/DECGUC7V/shanahanShiftingRolesApproaches2007.pdf}
}

@article{shankImprovingResultsReducingn.d.,
  title = {Improving Results and Reducing Frustrations from Team Activities},
  author = {Shank, Patti},
  year = {n.d.}
}

@article{sharadgahPreparednessInstitutionsHigher2020,
  title = {Preparedness of {{Institutions}} of {{Higher Education}} for {{Assessment}} in {{Virtual Learning Environments}} during the {{COVID-19 Lockdown}}: {{Evidence}} of {{Bona Fide Challenges}} and {{Pragmatic Solutions}}},
  author = {Sharadgah, Talha Abdullah and Sa'di, Rami Abdulatif},
  year = {2020},
  journal = {Journal of information technology education},
  volume = {19},
  number = {Journal Article},
  pages = {755},
  publisher = {Informing Science Institute},
  address = {Santa Rosa},
  issn = {1547-9714},
  doi = {10.28945/4615},
  abstract = {Aim/Purpose This study investigates the perceptions of faculty members at Prince Sattam bin Abdulaziz University, Saudi Arabia, towards preparedness of institutions of higher education (IHE) for assessment in virtual learning environments (VLEs) during the COVID-19 lockdown. In addition, the study explores evidence of bona fide challenges that impede the implementation of assessment in VLE for both formative and summative purposes, and it attempts to propose some pragmatic solutions.;Aim/Purpose: This study investigates the perceptions of faculty members at Prince Sattam bin Abdulaziz University, Saudi Arabia, towards preparedness of institutions of higher education (IHE) for assessment in virtual learning environments (VLEs) during the COVID-19 lockdown. In addition, the study explores evidence of bona fide challenges that impede the implementation of assessment in VLE for both formative and summative purposes, and it attempts to propose some pragmatic solutions. Background: Assessment of student performance is an essential aspect of teaching and learning. However, substantial challenges exist in assessing student learning in VLEs. Methodology: Data on faculty's perceptions were collected using an e-survey. Ninety-six faculty members took part in this study. Contribution: This paper contributes to COVID-19 research by investigating preparedness of IHE for assessment in VLEs from faculty members' perceptions. This practical research explores deleterious challenges that impede the implementation of assessment in VLE for both formative and summative purposes, and it proposes effective solutions to prevent future challenges. These solutions can be used by IHE to improve the quality of assessment in VLEs. Findings: The findings revealed that IHE were not fully prepared to provide a proper assessment in a VLE during the lockdown, nor did they have clear mechanisms for online assessment. The findings also showed that faculty members were not convinced that e-assessment could adequately assess all intended learning outcomes. They were convinced that most students cheated in a way or another. Additionally, faculty had other concerns about (1) the absence of advanced systems to prevent academic dishonesty; (2) insufficient qualifications of some faculty in e-assessment because most of them have never done it before, and e-assessment has never been mandated by the university before the pandemic; and (3) insufficient attention paid to formative assessment. Recommendations for Practitioners: It is recommended that decision makers help faculty members improve by continuous training on developing e-assessment tests for both formative and summative assessments. Decision makers should also ensure the inclusion of technology-based invigilation software to preclude cheating, make pedagogical and technical expertise available, and reconsider e-assessment mechanisms. Faculty members are recommended to attend training sessions if they do not master the basic skills of e-assessment and should devise a variety of innovative e-assessments for formative and summative purposes. Recommendations for Researchers: More similar work is needed to provide more solutions to the challenges identified in this paper regarding the e-assessment in response to the COVID-19 pandemic. Impact on Society: The study suggests introducing technology-based solutions to ensure e-assessment security, or holding tests in locations where they can be invigilated whilst rules of social distancing can still be applied. Future Research: Future research could suggest processes and mechanisms to help faculty develop assessment in VLEs more effectively.;},
  langid = {english},
  keywords = {Cheating,College Faculty,Computer Assisted Testing,Coronaviruses,COVID-19,Distance Education,Educational Technology,Faculty Development,Foreign Countries,Formative Evaluation,Higher education,Learning management systems,Online Courses,Pandemics,Readiness,School Closing,Student Evaluation,Summative Evaluation,Teacher Attitudes,Teacher Qualifications}
}

@book{sharpeHandbookDigitalHigher2022,
  title = {Handbook of {{Digital Higher Education}}.},
  author = {Sharpe, {\relax Rhona}. and Bennett, {\relax Sue}. and {Varga-Atkins}, {\relax T{\"u}nde}.},
  year = {2022},
  series = {Elgar {{Handbooks}} in {{Education Ser}}.},
  publisher = {Edward Elgar Publishing Limited},
  address = {Cheltenham},
  isbn = {978-1-80088-849-4},
  keywords = {Electronic books}
}

@article{shawEfficacyOnlineCognitive2019,
  ids = {shawEfficacyOnlineCognitive2019a,shawEfficacyOnlineCognitive2019b},
  title = {The {{Efficacy}} of an {{Online Cognitive Assessment Tool}} for {{Enhancing}} and {{Improving Student Academic Outcomes}}},
  author = {Shaw, Lindsay and MacIsaac, Janet and {Singleton-Jackson}, Jill},
  year = {2019},
  journal = {Online Learning},
  volume = {23},
  number = {2},
  pages = {124--144},
  publisher = {Online Learning},
  issn = {ISSN-2472-5749},
  abstract = {With technology at the fingertips of most undergraduate students, it has been difficult for instructors to fully engage students in the classroom, which has resulted in the creation of several innovative online cognitive assessment tools. These tools often integrate several cognitive learning strategies within an assessment, with the goal of actually enhancing learning, as opposed to just measuring it. In the current study, students' level of engagement and test performance using a recently developed online application were compared to their final multiple-choice paper-and-pencil exam mark to determine the efficacy of the new online application in achieving improved learning outcomes. Results indicated that students had high test scores using the online tool despite their limited engagement in the cognitive learning features, calling into question the online cognitive assessment tool's facilitation of long-term learning. Implications and recommendations for future online cognitive assessment application implementation in educational environments are discussed.},
  langid = {english},
  keywords = {Academic Achievement,Canada,Cognitive Measurement,Electronic Learning,Feedback (Response),Foreign Countries,FORMATIVE ASSESSMENT,GRADE-ORIENTATIONS,HIGHER-EDUCATION,Learner Engagement,Learning Strategies,No DOI found,online assessment,online learning,Outcomes of Education,PERSONALITY,PRESSURE,Psychology,RETRIEVAL,Self Efficacy,STRATEGIES,student engagement with online tools,TEST ANXIETY,TEST-PERFORMANCE,Undergraduate Students,UNIVERSITY},
  file = {/Users/colin.madland/Zotero/storage/KV3J7234/shawEfficacyOnlineCognitive2019.pdf}
}

@article{sheaCognitivePresenceOnline2009,
  title = {Cognitive Presence and Online Learner Engagement: A Cluster Analysis of the Community of Inquiry Framework},
  author = {Shea, Peter and Bidjerano, Temi},
  year = {2009},
  month = dec,
  journal = {Journal of Computing in Higher Education},
  volume = {21},
  number = {3},
  pages = {199--217},
  issn = {1042-1726},
  doi = {10.1007/s12528-009-9024-5},
  langid = {english},
  keywords = {community of inquiry,Online learning,study}
}

@misc{sheadTwitterInvestigatingRacial2020,
  title = {Twitter Investigating Racial Bias after Users Noticed the Platform Sometimes Prefers {{White}} Faces},
  author = {Shead, Sam},
  year = {2020},
  month = sep,
  journal = {CNBC},
  urldate = {2020-09-22},
  abstract = {Twitter says it's investigating why its picture-cropping algorithm sometimes prefers White faces to Black ones after users alerted the company to the issue.},
  chapter = {Finding Solutions},
  howpublished = {https://www.cnbc.com/2020/09/21/twitter-investigating-after-users-spot-mobile-app-prefers-white-faces.html},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/RN3V5P3Z/twitter-investigating-after-users-spot-mobile-app-prefers-white-faces.html}
}

@incollection{shedletskyDoesOnlineDiscussion2010,
  title = {Does {{Online Discussion Produce Increased Interaction}} and {{Critical Thinking}}?},
  booktitle = {Cases on {{Online Discussion}} and {{Interaction}}: {{Experiences}} and {{Outcomes}}},
  author = {Shedletsky, Leonard},
  year = {2010},
  pages = {1--38},
  publisher = {IGI Global},
  abstract = {This chapter explores the question: Does online discussion increase critical thinking and interaction? It presents a selective review of the literature concerned with critical thinking and/or interaction during online discussion. It reports a program of 5 studies of the effects of instructional media and instructional methods on critical thinking and interaction. Study 1 tests the influence on critical thinking of online vs. face-to-face discussion, individual vs. group consensus in summarizing discussion, and discussion of examples of concepts vs. discussion of more abstract analysis. Study 2 examines the relationship between the level of critical thinking in discussion and the quality of papers later written by discussants. Study 3 explores the question: Can a teaching assistant (TA) help to facilitate student-to-student interaction and critical thinking? Study 4 asks: Does personal relevance of discussion topic influence student participation and level of critical thinking in discussion online? Study 5 asks: Does the use of rubrics influence the level of student interaction and/or the level of critical thinking in online discussion? The evidence suggests that it is easier to influence students to interact than to think critically. The chapter offers some suggestions on how to increase student-to-student interaction and critical thinking.}
}

@article{sheedyHegemonyAssessmentStudent2018,
  title = {Hegemony and {{Assessment}}: {{The Student Experience}} of {{Being}} in a {{Male Homogenous Higher Education Computing Course}}},
  author = {Sheedy, Caroline},
  year = {2018},
  journal = {Practitioner Research in Higher Education},
  volume = {11},
  number = {1},
  pages = {59--69},
  issn = {EISSN-1755-1382},
  abstract = {This work emanates from a previous study examining the experiences of male final year students in computing degree programmes that focused on their perceptions as students where they had few, if any, female classmates. This empirical work consisted of focus groups, with the findings outlined here drawn from two groups that were homogeneous with respect to gender. It identified that the masculinisation of computing and the resulting hegemonic masculinity has far-reaching impact. An unanticipated theme was how this homogeneity impacted their course assessments. Students participating in this research identified discomfort with their experience of the institutional hegemonic masculinity. Further work to understand how this hegemonic masculinity impacts teachers is also proposed.},
  langid = {english},
  keywords = {Beliefs,Competence,Computer Science Education,Course Evaluation,Focus Groups,Gender Differences,Higher Education,Homogeneous Grouping,Institutional Characteristics,Interviews,Males,Masculinity,No DOI found,Student Experience,Student Satisfaction}
}

@article{shenEverydayAlgorithmAuditing2021,
  title = {Everyday {{Algorithm Auditing}}: {{Understanding}} the {{Power}} of {{Everyday Users}} in {{Surfacing Harmful Algorithmic Behaviors}}},
  shorttitle = {Everyday {{Algorithm Auditing}}},
  author = {Shen, Hong and DeVos, Alicia and Eslami, Motahhare and Holstein, Kenneth},
  year = {2021},
  month = oct,
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {5},
  number = {CSCW2},
  pages = {1--29},
  issn = {2573-0142},
  doi = {10.1145/3479577},
  urldate = {2022-02-16},
  langid = {english},
  keywords = {archived},
  annotation = {https://web.archive.org/web/20220216030733/https://dl.acm.org/doi/10.1145/3479577},
  file = {/Users/colin.madland/Zotero/storage/XSHBIFRD/shenEverydayAlgorithmAuditing2021.pdf}
}

@article{shepardClassroomAssessmentPrinciples2018,
  title = {Classroom {{Assessment Principles}} to {{Support Learning}} and {{Avoid}} the {{Harms}} of {{Testing}}},
  author = {Shepard, L. A. and Penuel, W. R. and Pellegrino, J. W.},
  year = {2018},
  journal = {Educational Measurement: Issues and Practice},
  volume = {37},
  number = {1},
  pages = {52--57},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {0731-1745},
  doi = {10/ghrpzh},
  urldate = {2021-04-08},
  file = {/Users/colin.madland/Zotero/storage/GZHBWIIX/shepardClassroomAssessmentPrinciples2018.pdf}
}

@incollection{shepardFormativeAssessmentCaveat2017,
  title = {Formative Assessment: {{Caveat}} Emptor},
  booktitle = {The Future of Assessment: Shaping Teaching and Learning},
  author = {Shepard, Lorrie},
  editor = {Dwyer, Carol Anne},
  year = {2017},
  isbn = {978-1-351-54441-2 978-1-351-54442-9 978-1-351-54440-5 978-1-315-08654-5},
  langid = {english},
  annotation = {OCLC: 1005608225},
  file = {/Users/colin.madland/Zotero/storage/D92F8VLL/shepardFormativeAssessmentCaveat2017.pdf}
}

@article{shepardPsychometriciansBeliefsLearning1991,
  title = {Psychometricians' {{Beliefs About Learning}}},
  author = {Shepard, Lorrie A.},
  year = {1991},
  month = oct,
  journal = {Educational Researcher},
  volume = {20},
  number = {7},
  pages = {2--16},
  issn = {0013-189X, 1935-102X},
  doi = {10/cc96nv},
  urldate = {2021-07-13},
  abstract = {The author contends that disputes within the measurement community about what constitutes legitimate test preparation and whether ``teaching to the test'' is good or bad for student learning can be explained by differences in measurement specialists beliefs about learning. Qualitative analysis of interview data from a nationally representative sample of 50 district testing directors revealed that approximately half of the measurement specialists operate from implicit learning theories that advocate, first, close alignment of tests with curriculum and, second, judicious teaching of tested content. Historical quotations are used to show that these beliefs, associated with criterion-referenced testing, derive from behaviorist learning theory, which requires sequential mastery of constituent skills and explicit testing of each learning step. The sequential, facts-before-thinking model of learning is contradicted, however, by a substantial body of evidence from cognitive psychology. Implicit beliefs should be made explicit because an understanding of learning theory assumptions is fundamental to evaluating evidence of testing effects and therfore to framing validity investigations.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/VWAE5Y62/shepardPsychometriciansBeliefsLearning1991.pdf}
}

@article{shepardRoleAssessmentLearning2000,
  title = {The {{Role}} of {{Assessment}} in a {{Learning Culture}}},
  author = {Shepard, Lorrie A.},
  year = {2000},
  month = oct,
  journal = {Educational Researcher},
  volume = {29},
  number = {7},
  pages = {4--14},
  issn = {0013-189X, 1935-102X},
  doi = {10/cw9jwc},
  urldate = {2021-07-06},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/2UJS8IB7/shepardRoleAssessmentLearning2000.pdf}
}

@inbook{shepardShouldMeasurementHave2019,
  title = {Should ``{{Measurement}}'' {{Have}} a {{Role}} in {{Teacher Learning}} about {{Classroom Assessment}}?},
  booktitle = {Classroom {{Assessment}} and {{Educational Measurement}}},
  author = {Shepard, Lorrie A.},
  year = {2019},
  month = jul,
  edition = {1},
  pages = {192--206},
  publisher = {Routledge},
  address = {New York},
  urldate = {2023-12-21},
  collaborator = {Brookhart, Susan M. and McMillan, James H.},
  isbn = {978-0-429-50753-3},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/E2YA4LL4/shepardShouldMeasurementHave2019.pdf}
}

@article{shepardUsingLearningMotivation2018,
  title = {Using {{Learning}} and {{Motivation Theories}} to {{Coherently Link Formative Assessment}}, {{Grading Practices}}, and {{Large-Scale Assessment}}},
  author = {Shepard, L. A. and Penuel, W. R. and Pellegrino, J. W.},
  year = {2018},
  month = mar,
  journal = {Educational Measurement: Issues and Practice},
  volume = {37},
  number = {1},
  pages = {21--34},
  issn = {07311745},
  doi = {10/gfjzj7},
  urldate = {2021-04-08},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/G5L3RW59/shepardUsingLearningMotivation2018.pdf}
}

@article{shererOnlineCommunitiesPractice2003,
  title = {Online {{Communities}} of {{Practice}}: {{A Catalyst}} for {{Faculty Development}}},
  author = {Sherer, Pamela and Shea, Timothy and Kristensen, Eric},
  year = {2003},
  journal = {Innovative Higher Education},
  volume = {27},
  number = {3},
  pages = {183--194},
  abstract = {This article addresses the concept of communities of practice and how it has come of age for the professional development of professors as teachers. Thanks to current technological options, faculty developers can enhance the opportunity for the entire faculty to learn through the use of online communities. Designing a faculty development portal using community of practice concepts can be an effective means to jump-start, facilitate, develop, and sustain faculty involvement in academic communities.},
  keywords = {Humanities,Social Sciences and Law}
}

@article{sheridanAchievingWILPlacement2019,
  title = {Achieving {{WIL Placement}} and {{Theoretical Learning Concurrently}}: {{An Online Strategy}} for {{Higher Education Institutions}}},
  author = {Sheridan, Lynnaire and Gibbons, Belinda and Price, Oriana},
  year = {2019},
  journal = {Journal of University Teaching and Learning Practice},
  volume = {16},
  number = {3},
  issn = {EISSN-1449-9789},
  abstract = {The Australian Government requires Higher Education Institutions to demonstrate the work-readiness of graduates. Consequently, Work Integrated Learning (WIL) has been adopted to enhance the workplace skills and professional networks of students to improve graduate employability. While WIL can take many forms, experiences located in workplaces (placements, internships) have been popular. The introduction of the Australian Government's Fair Work Act 2009 required that placements be tightly embedded within curriculum thereby presenting the challenge of how to enable WIL via placements and theoretical learning in already compact study programs. As a response, we present the pragmatic use of online theoretical instruction and online WIL assessment within an undergraduate core Capstone business subject, as an enabler of the WIL placement. We examine learner perspectives on, and grade outcomes from, undertaking online theoretical instruction concurrent with WIL placements to discuss the key WIL and online learning design implications for this cohort of learners. Our findings are increasingly pertinent given the 2017 Australian Government Higher Education Reform package incentivising the expansion of WIL into all degrees.},
  langid = {english},
  keywords = {Business Administration Education,Capstone Experiences,Computer Assisted Testing,Electronic Learning,Foreign Countries,Grades (Scholastic),Instructional Effectiveness,Integrated Learning Systems,No DOI found,Student Attitudes,Undergraduate Students,Work Experience Programs}
}

@article{sherPrimingEnablingAssessment2019,
  title = {Priming, Enabling and Assessment of Curiosity},
  author = {Sher, Keren Ben-Tov and {Levi-Keren}, Michal and Gordon, Goren},
  year = {2019},
  journal = {Educational technology research and development},
  volume = {67},
  number = {4},
  pages = {931--952},
  publisher = {Springer US},
  address = {New York},
  issn = {1042-1629},
  doi = {10.1007/s11423-019-09665-4},
  abstract = {In the information age, where all answers are just a click away, curiosity, the intrinsic drive to learn, becomes of paramount importance. How easy is it to prime for curiosity and what are its effects? What simple interventions can be used to enable curiosity-driven behaviors? We have conducted a large-scale study to address these questions, using a novel curiosity-based application (app) on university applicants. Using the same app, we addressed the issue of curiosity assessment, which in recent years has mainly been performed via self-reporting questionnaires. The curiosity assessment tool was developed in order to assess curiosity via an objective, quantitative and digital way. The tool measured several behavioral aspects during a free and task-less interaction with the tablet app. From the recorded activity logs we calculated quantitative behavioral measures related to their exploration patterns. We show that a single word can prime the participants and induce better learning of their self-explored knowledge. We also show that by simply enabling more time to explore, without the ability to stop at will, induces more exploration and more learning. Finally, we show that our behavioral measures, obtained with the digital quantitative assessment tool, are significant predictors of the participants' self-reported curiosity and Psychometric Entrance Test scores. These results suggest that simple priming for curiosity and enabling enough time to explore improve self-paced learning, and that a relatively simple and short interaction with a digital app can greatly improve state-of-the-art curiosity assessment.},
  keywords = {Analysis,Behavior,College applications,College Students,Computer Oriented Programs,Development Article,Discovery Learning,Education,Education & Educational Research,Educational Technology,Handheld Devices,Higher education,Learning and Instruction,Pacing,Personality Measures,Personality Traits,Priming,Psychometrics,Social Sciences}
}

@misc{sherrycukuNarrativeResearch,
  title = {Narrative {{Research}}},
  author = {{Sherry Cuku}},
  urldate = {2019-02-09}
}

@article{shiCollegeStudentsCognitive2020,
  title = {College {{Students}}' {{Cognitive Learning Outcomes}} in {{Technology-Enabled Active Learning Environments}}: {{A Meta-Analysis}} of the {{Empirical Literature}}},
  author = {Shi, Yinghui and Yang, Huiyun and MacLeod, Jason and Zhang, Jingman and Yang, Harrison Hao},
  year = {2020},
  journal = {Journal of educational computing research},
  volume = {58},
  number = {4},
  pages = {791--817},
  publisher = {SAGE Publications},
  address = {Los Angeles, CA},
  issn = {0735-6331},
  doi = {10.1177/0735633119881477},
  abstract = {Technology-enabled active learning environments (TE-ALEs) have attracted considerable research interest, particularly in higher education. However, research shows inconsistent results describing the influence of TE-ALEs toward students' cognitive learning outcomes. This study was designed to identify high-quality empirical research examining college students' cognitive learning outcomes and to utilize meta-analysis to determine the overall effectiveness of TE-ALEs. A systematic literature search identified 31 high-quality peer-reviewed journal articles that met the inclusion criteria. Meta-analysis showed that the calculated effect size of TE-ALEs more positively influenced students' cognitive learning than traditional lecture-based environments. Moderator variable analysis suggested that social context, study design, and sample size were significant factors that influence the effectiveness of TE-ALE. TE-ALEs were found more effective when instructors employed individualized learning contexts as well as when bias was reduced in randomized controlled trials. TE-ALEs were also found to be more effective in small courses rather than in large courses.},
  keywords = {Active Learning,Cognitive Development,College Students,Educational Environment,Educational Objectives,Instructional Effectiveness,Meta Analysis,Technology Uses in Education},
  file = {/Users/colin.madland/Zotero/storage/RAN7Z6NL/shiCollegeStudentsCognitive2020.pdf}
}

@misc{ShiftMeasurementMindset,
  title = {A {{Shift}} in {{Measurement Mindset}}},
  journal = {Mindful Measurement},
  urldate = {2020-10-13},
  abstract = {When I think about mindful measurement, as the structure of the word `mindful' suggests, I think of what fills the mind with respect to an assessment. What fills students' minds when they take an assessment? When they see their scores? What fills teachers' minds when they administer an assessment? W},
  howpublished = {https://www.mindfulmeasurement.com/blog/a-shift-in-measurement-mindset},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/78RFTS5M/a-shift-in-measurement-mindset.html}
}

@article{shimImpactFacultyTeaching2012,
  title = {The Impact of Faculty Teaching Practices on the Development of Students' Critical Thinking Skills},
  shorttitle = {The Impact of Faculty Teaching Practices on the Development of Students' Critical Thinking Skills},
  author = {Shim, Woo-jeong and Walczak, Kelley},
  year = {2012},
  journal = {International Journal of Teaching and Learning in Higher Education},
  volume = {24},
  pages = {16--30},
  issn = {1812-9129},
  abstract = {Colleges and universities recognize that one of the primary goals of higher education is to promote students' ability to think critically. Using data from the Wabash National Study of Liberal Arts Education (WNS), this study examined the relationship between faculty teaching practices and the development of students' critical thinking skills, specifically the differences between students' self report and the direct assessment (i.e., CAAP) of critical thinking. The results from multinomial logistic regression and OLS regression analyses showed that asking challenging questions increased both students' self-reported and the directly measured critical thinking abilities. Interpreting abstract concepts as well as giving well-organized presentation increased students' self-reported gains in critical thinking; however, these same practices did not significantly impact their CAAP scores. Inconsistent with previous literature, class presentations as well as group discussions decreased either students' self-reported or directly assessed critical thinking abilities. These findings can guide faculty teaching practices to foster critical thinking for first-year college students.},
  annotation = {1}
}

@article{shinMultipleChoiceItemDistractor2019,
  title = {Multiple-{{Choice Item Distractor Development Using Topic Modeling Approaches}}},
  author = {Shin, Jinnie and Guo, Qi and Gierl, Mark J.},
  year = {2019},
  month = apr,
  journal = {Frontiers in Psychology},
  volume = {10},
  pages = {825},
  issn = {1664-1078},
  doi = {10/gg29tj},
  urldate = {2020-06-26},
  file = {/Users/colin.madland/Zotero/storage/VZ2KP4YJ/shinMultipleChoiceItemDistractor2019.pdf}
}

@article{shinMultipleChoiceItemDistractor2019a,
  title = {Multiple-{{Choice Item Distractor Development Using Topic Modeling Approaches}}},
  author = {Shin, Jinnie and Guo, Qi and Gierl, Mark J.},
  year = {2019},
  month = apr,
  journal = {Frontiers in Psychology},
  volume = {10},
  pages = {825},
  issn = {1664-1078},
  doi = {10/gg29tj},
  urldate = {2021-07-17},
  file = {/Users/colin.madland/Zotero/storage/5EVBZD8R/shinMultipleChoiceItemDistractor2019a.pdf}
}

@article{shraimOnlineExaminationPractices2019,
  ids = {shraimOnlineExaminationPractices2019a,shraimOnlineExaminationPractices2019c},
  title = {Online {{Examination Practices}} in {{Higher Education Institutions}}: {{Learners}}' {{Perspectives}}},
  shorttitle = {Online {{Examination Practices}} in {{Higher Education Institutions}}},
  author = {Shraim, Khitam},
  year = {2019},
  month = oct,
  journal = {Turkish Online Journal of Distance Education},
  pages = {185--196},
  publisher = {Turkish Online Journal of Distance Education},
  issn = {1302-6488},
  doi = {10/gmbvpb},
  urldate = {2021-07-27},
  keywords = {Computer Assisted Testing,Educational Benefits,Foreign Countries,Formative Evaluation,Higher Education,No DOI found,Palestine,Student Attitudes,Student Evaluation,Test Construction,Test Reliability,Test Validity,Testing Problems,Undergraduate Students},
  file = {/Users/colin.madland/Zotero/storage/CYEFJUAS/shraimOnlineExaminationPractices2019.pdf}
}

@article{shuellCognitiveConceptionsLearning1986,
  title = {Cognitive {{Conceptions}} of {{Learning}}},
  author = {Shuell, Thomas J.},
  year = {1986},
  journal = {Review of Educational Research},
  volume = {56},
  number = {4},
  pages = {411--436},
  publisher = {[Sage Publications, Inc., American Educational Research Association]},
  issn = {00346543, 19351046},
  doi = {10.2307/1170340},
  urldate = {2022-08-09},
  abstract = {[Although cognitive psychology currently represents the mainstream of psychological and educational thinking, it is only recently that much concern has been shown for learning as such -- that is, concern for the factors and/or variables that influence "changes" in human performance, knowledge structures, and/or conceptions. This article examines current thinking about learning within the framework of cognitive psychology and how a new, cognitive conception of learning can guide future research on both learning and instruction. Similarities and differences between behavioral and cognitive conceptions of learning are discussed, along with issues such as the active (rather than passive) nature of learning, the concern for understanding (i.e., comprehension), the role of prior knowledge, the cumulative nature of most forms of human learning, and the role played by cognitive analyses of performance. Several cognitive theories of learning are presented as examples of how cognitive psychology has influenced research on learning.]},
  file = {/Users/colin.madland/Zotero/storage/GPZRT3PJ/shuellCognitiveConceptionsLearning1986.pdf}
}

@article{shute21stCenturyAssessment2010,
  title = {21st Century Assessment to Promote 21st Century Learning: {{The}} Benefits of Blinking},
  author = {Shute, Valerie J. and Dennen, Vanessa P. and Kim, Yoon-jeon and Donmez, Oktay and Wang, Chen-yen},
  year = {2010},
  abstract = {What competencies do kids need to succeed in the 21stcentury, and how do these skills differ from those  reflected  in  current  state  standards?  What  is  the  best  way  to  assess  and  support  new competencies?   This   paper   extends   current   thinking   about   educationally   valuable   skills   and instructional system design by identifying and modeling 21stcentury skills.The first stage (described in  this  paper)  of  our  multi-stage  research  involves:  (a)  conducting  an  extensive  literature  review  to identify a set of viable and valuable 21stcentury skills,and (b) modeling each in terms of constituent sub-skills,  at  a  sufficiently  refined  grain  size  so  that  we  can  measure  and  diagnose  competency levels. The competencies showcased in this paper include: systems thinking, creativity, collaborative learning, and  managing social  identities. Subsequent stages of this research will  include developing appropriate and engaging assessmentsto extract data on our relevant 21stcentury skills from students--individually  and  in  groups--during  interaction  with  immersive learning environments. Findings from  the second  stage  will then inform  the  third  stage  which  will  involve  adapting  existing (or developing  new)  learning environments  that  incorporate problems, assessments,  and instructional support in relation to our set ofimportant 21stcentury skills.},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/JVDYAZNQ/shute21stCenturyAssessment2010.pdf}
}

@article{shuteAdvancesScienceAssessment2016,
  title = {Advances in the {{Science}} of {{Assessment}}},
  author = {Shute, Valerie J. and Leighton, Jacqueline P. and Jang, Eunice E. and Chu, Man-Wai},
  year = {2016},
  month = jan,
  journal = {Educational Assessment},
  volume = {21},
  number = {1},
  pages = {34--59},
  issn = {1062-7197, 1532-6977},
  doi = {10/gfgtrs},
  urldate = {2021-01-17},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/7874YTUG/shuteAdvancesScienceAssessment2016.pdf}
}

@incollection{shuteAssessingSupportingHardtomeasure2016,
  title = {Assessing and Supporting Hard-to-Measure Constructs in Video Games},
  booktitle = {The {{Wiley Handbook}} of {{Cognition}} and {{Assessment}}},
  author = {Shute, Valerie and Wang, Lubin},
  year = {2016},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118956588.ch22},
  pages = {535--562},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781118956588.ch22},
  abstract = {Summary In this chapter we discuss challenges with traditional assessment when researchers deal with hard-to-measure constructs such as systems-thinking, creativity, or persistence. We then describe how the frameworks of evidence-centered design and stealth assessment may be used to develop assessments that can be embedded in video games to make valid inferences about learners' competencies. We illustrate the process step-by-step with two projects in which we assess (a) problem solving skills with Plants vs. Zombies 2 and (b) creativity with Physics Playground. We discuss the methodological importance of and associated caveats for the use of external measures to validate in-game measurement. We conclude the chapter with a brief discussion of key future directions of stealth assessment in video games, which include valid actionable diagnoses of performance problems and provision of real-time feedback.},
  chapter = {22},
  isbn = {978-1-118-95658-8},
  keywords = {Bayesian networks,creativity,evidence-centered design,game-based assessment,game-based learning,problem solving,stealth assessment}
}

@article{shuteFocusFormativeFeedback2008,
  ids = {Shute_2008},
  title = {Focus on {{Formative Feedback}}},
  author = {Shute, Valerie J.},
  year = {2008},
  month = mar,
  journal = {Review of Educational Research},
  volume = {78},
  number = {1},
  pages = {153--189},
  issn = {0034-6543, 1935-1046},
  doi = {10/bd5cgq},
  urldate = {2021-02-01},
  langid = {english},
  mag_id = {2135995390},
  pmcid = {null},
  pmid = {null},
  keywords = {guskey},
  file = {/Users/colin.madland/Zotero/storage/MZS2IHR6/shuteFocusFormativeFeedback2008.pdf}
}

@article{shuteStealthAssessmentCreativity2021,
  title = {Stealth Assessment of Creativity in a Physics Video Game},
  author = {Shute, Valerie J. and Rahimi, Seyedahmad},
  year = {2021},
  journal = {Computers in Human Behavior},
  volume = {116},
  pages = {106647},
  issn = {07475632},
  doi = {10.1016/j.chb.2020.106647},
  urldate = {2022-03-23},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/WBWP6WNZ/shuteStealthAssessmentCreativity2021.pdf}
}

@article{shyrDesigningTechnologyEnhanced2018,
  title = {Designing a Technology-enhanced Flipped Learning System to Facilitate Students' Self-regulation and Performance},
  author = {Shyr, Wen-Jye and Chen, Ching-Huei},
  year = {2018},
  journal = {Journal of computer assisted learning},
  volume = {34},
  number = {1},
  pages = {53--62},
  publisher = {Wiley},
  address = {HOBOKEN},
  issn = {0266-4909},
  doi = {10.1111/jcal.12213},
  abstract = {In recent years, the flipped classroom has become prevalent in many educational settings. Flipped classroom adopts a pedagogical model in which short video lectures are viewed by students at home before class so that the teacher can lead students to participate in activities, problem-solving, and discussions. Yet the design or use of technology that employs planned instructional strategies with sustainable support of self-regulation is scant. We propose a technology-enhanced flipped language learning system (Flip2Learn) that provides facilitation and guidance for learning performance and self-regulation. A quasi-experimental study was carried out to examine whether Flip2Learn could enhance college students' self-regulatory skills and later contribute to the learning performance in the flipped classrooms. The results showed that Flip2Learn not only better prepared students for flipped classrooms but also better promoted learning performance compared to the conventional flipped classrooms. The results of this research advanced our understanding of the dynamics of flipped classrooms and represented a revolutionary new approach to the technology-enhanced learning for flipped classrooms. Lay Description What is currently known about the subject matter: Flipped classroom has been implemented in various disciplines and across different educational levels. Flipped classroom gives students more opportunities to participate in more interactive and higher-order activities. To fully participate in the flipped classroom, watching or listening to online materials is an essential part of flipped learning. What this paper adds to this: This study designed and implemented a technology-enhanced flipped language learning system (Flip2Learn) with self-regulated scaffolds to better acquaint students with flipped classrooms and to maximize the benefits of the flipped classroom. Students exposed to Flip2Learn not only showed better self-regulation skills, but also better readiness for subsequent flipped learning. Results from this study demonstrated the feasibility of implementing the Flip2Learn approach to facilitate low prior knowledge students' learning performance. The implications of study findings for practitioners: Results from this study implied that learning mechanism incorporating hard and soft scaffolds provide students with instant help and guidance helps students avoid feelings of isolation or a lack of motivation to learn. A focus on self-regulated learning can advance and deepen the learning in flipped classrooms.},
  keywords = {Blended Learning,Classrooms,College Students,Comparative Analysis,Discussion (Teaching Technique),Education,Education & Educational Research,Educational technology,Feasibility studies,Flipped classroom,Instructional Design,Instructional Effectiveness,language learning,Laws regulations and rules,Learning,Lecture Method,Management Systems,Metacognition,Problem Solving,Quasiexperimental Design,Scaffolds,Second Language Instruction,Second Language Learning,Self Management,self-regulated learning,Skills,Social Sciences,Students,Teaching Methods,technology-enhanced learning system,Video Technology},
  file = {/Users/colin.madland/Zotero/storage/YI6X32S5/shyrDesigningTechnologyEnhanced2018.pdf}
}

@article{sickelGreatMediaDebate2019,
  title = {The {{Great Media Debate}} and {{TPACK}}: {{A Multidisciplinary Examination}} of the {{Role}} of {{Technology}} in {{Teaching}} and {{Learning}}},
  shorttitle = {The {{Great Media Debate}} and {{TPACK}}},
  author = {Sickel, Jamie L.},
  year = {2019},
  month = apr,
  journal = {Journal of Research on Technology in Education},
  volume = {51},
  number = {2},
  pages = {152--165},
  issn = {1539-1523, 1945-0818},
  doi = {10.1080/15391523.2018.1564895},
  urldate = {2023-08-07},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/3FL8LV3L/sickelGreatMediaDebate2019.pdf}
}

@article{siemensConnectivismLearningTheory2005,
  title = {Connectivism: {{A Learning Theory}} for the {{Digital Age}}},
  author = {Siemens, George},
  year = {2005},
  journal = {International Journal of Instructional Technology and Distance Learning},
  volume = {2},
  number = {1},
  issn = {1550-6908},
  urldate = {2022-01-25},
  keywords = {archived,No DOI found},
  file = {/Users/colin.madland/Zotero/storage/5X9WUF5K/article01.html}
}

@article{siemensHumanArtificialCognition2022,
  title = {Human and Artificial Cognition},
  author = {Siemens, George and {Marmolejo-Ramos}, Fernando and Gabriel, Florence and Medeiros, Kelsey and Marrone, Rebecca and Joksimovic, Srecko and {\noopsort{laat}}{de Laat}, Maarten},
  year = {2022},
  month = jan,
  journal = {Computers and Education: Artificial Intelligence},
  volume = {3},
  pages = {100107},
  issn = {2666-920X},
  doi = {10.1016/j.caeai.2022.100107},
  abstract = {Predictions of the timelines for when machines will be able to perform general cognitive activities that rival humans, or even the arrival of ``super intelligence'', range from years to decades to never. For researchers in the education sector, the potential future state of AI, while provocative, is secondary to important shorter-term questions that influence how AI is integrated into learning and knowledge practices such as sensemaking and decision making. AI is not a future technology. It is already present in our daily lives, often shaping, behind the scenes, the types of information we encounter. It is, therefore, important to consider immediate questions surrounding the dynamics of human-machine interactions. In this paper, we focus on the relationship between human and artificial cognition and treat these as separate systems, each with distinct strengths and capabilities. We adopt a functional view (i.e., discrete tasks) of the activities that artificial cognition completes and those that are best handled by humans. This creates a foundation to then evaluate models for how these two cognitive systems interact and the mechanisms for coordination that are required. In doing so, we create a basis for future researchers to develop testable hypotheses regarding the impact of artificial cognition on knowledge processes such as learning, sensemaking, and decision making. Our evaluation provides insight for researchers regarding the optimal relationship between which cognitive activities should be handed off to the machine, which should remain the domain of human performance, and how these two should then be integrated when outputs are passed from one cognitive system (human or artificial) to the other.},
  keywords = {Artificial intelligence,Cognition,Human-machine collaboration,Knowledge processing},
  file = {/Users/colin.madland/Zotero/storage/YFX9CWEC/siemensHumanArtificialCognition2022.pdf}
}

@article{silvermanWhatHappensWhen2021,
  title = {What {{Happens When You Close}} the {{Door}} on {{Remote Proctoring}}? {{Moving Toward Authentic Assessments}} with a {{People-Centered Approach}}},
  shorttitle = {What {{Happens When You Close}} the {{Door}} on {{Remote Proctoring}}?},
  author = {Silverman, Sarah and Caines, Autumm and Casey, Christopher and {Garcia de Hurtado}, Belen and Riviere, Jessica and Sintjago, Alfonso and Vecchiola, Carla},
  year = {2021},
  month = mar,
  journal = {To Improve the Academy},
  volume = {39},
  number = {3},
  issn = {2334-4822},
  doi = {10.3998/tia.17063888.0039.308},
  urldate = {2021-11-02},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/6YQQXQ3K/silvermanWhatHappensWhen2021.pdf}
}

@article{simonPostsecondaryDistanceEducation2014,
  title = {Post-Secondary Distance Education in a Contemporary Colonial Context: {{Experiences}} of Students in a Rural {{First Nation}} in {{Canada}}},
  shorttitle = {Post-Secondary Distance Education in a Contemporary Colonial Context},
  author = {Simon, Jesse and Burton, Kevin and Lockhart, Emily and O'Donnell, Susan},
  year = {2014},
  month = jan,
  journal = {The International Review of Research in Open and Distributed Learning},
  volume = {15},
  number = {1},
  issn = {1492-3831},
  doi = {10.19173/irrodl.v15i1.1357},
  urldate = {2019-02-17},
  langid = {english},
  keywords = {distance education,higher education,online learning},
  file = {/Users/colin.madland/Zotero/storage/93IRM3RW/simonPostsecondaryDistanceEducation2014.pdf;/Users/colin.madland/Zotero/storage/7UWUJK2X/1357.html}
}

@article{simonsonDistanceEducationResearch2011,
  title = {Distance Education Research: A Review of the Literature},
  author = {Simonson, Michael and Schlosser, Charles and Orellana, Anymir},
  year = {2011},
  journal = {Journal of Computing in Higher Education},
  volume = {23},
  number = {2},
  pages = {124--142},
  abstract = {Distance education is defined, the various approaches for effective research are summarized, and the results of major research reviews of the field are explained in this article. Additionally, two major areas of research are included---research on barriers to the adoption of distance education and research summaries that explain and support best practices in the field. This paper concludes with the summary statement that it is not different education, it is distance education ; what is known about effectiveness in education is most often also applicable to distance education.},
  keywords = {Humanities,Social Sciences and Law}
}

@article{simperAssessmentThresholdsAcademic2020,
  ids = {simperAssessmentThresholdsAcademic2020a},
  title = {Assessment Thresholds for Academic Staff: Constructive Alignment and Differentiation of Standards},
  shorttitle = {Assessment Thresholds for Academic Staff},
  author = {Simper, Natalie},
  year = {2020},
  month = oct,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {45},
  number = {7},
  pages = {1016--1030},
  publisher = {Assessment \& Evaluation in Higher Education},
  issn = {0260-2938, 1469-297X},
  doi = {10/gkq35c},
  urldate = {2021-06-18},
  abstract = {This qualitative study utilized episodic narrative interviews to investigate assessment thresholds involved in the development of assessment literacy. The goal of the study was to inform efforts toward quality improvements in higher education. Thirty-five academic staff from universities in Australia, Canada and Sweden shared stories of significant changes they made to their assessment practice. Thematic analysis found troublesome aspects to include instructor expectations, lack of consistency, differentiation of performance, student expectations, time constraints/workload, logistical/technological constraints and assessment policy. A belief in meaningful learning, embracing constraints and the desire to meet the needs of students, added to other enablers for assessment change, such as resources, support and strategic use of technology. Findings suggested assessment thresholds of constructive alignment and differentiation of standards. Reflection, collaboration and professional development were found to support the integration of assessment knowledge and build conceptual understanding of assessment thresholds. Authors recommend that higher education institutions provide academic staff with a foundation of conceptual understanding of these key areas to promote moves toward quality assessment practices.},
  langid = {english},
  keywords = {Alignment (Education),Assessment Literacy,Australia,Canada,Change,College Faculty,Evaluation Problems,Foreign Countries,Fundamental Concepts,Language Usage,Multiple DOI,Standards,Student Evaluation,Sweden},
  file = {/Users/colin.madland/Zotero/storage/ZALPKISM/simperAssessmentThresholdsAcademic2020.pdf}
}

@article{sinclairIntroductionRefinementAssessment2016,
  title = {The Introduction and Refinement of the Assessment of Digitally Recorded Audio Presentations},
  author = {Sinclair, Stefanie},
  year = {2016},
  journal = {Open learning},
  volume = {31},
  number = {2},
  pages = {163--175},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0268-0513},
  doi = {10.1080/02680513.2016.1190640},
  abstract = {This case study critically evaluates benefits and challenges of a form of assessment included in a final year undergraduate Religious Studies Open University module, which combines a written essay task with a digital audio recording of a short oral presentation. Based on the analysis of student and tutor feedback and sample assignments, this study critically examines how teaching and learning practices linked to this novel form of assessment have been iteratively developed in light of the project findings over a period of two years. It concludes that while this form of assessment poses a number of challenges, it can create valuable opportunities for the development of transferable twenty-first-century graduate employability skills as well as deep, effective learning experiences, particularly - though not exclusively - in distance learning settings.},
  keywords = {assessment,Audio Equipment,Case Studies,digital technology,Distance Education,Distance learning,Education & Educational Research,Educational evaluation,Educational Technology,employability,Essays,Evaluation Methods,Foreign Countries,Online Surveys,Open Universities,Oral presentations,podcasts,Public Speaking,Questionnaires,Religious Education,Social Sciences,Student Attitudes,Student Evaluation,Teacher Attitudes,Teaching Methods,Technology Uses in Education,Undergraduate Study,United Kingdom},
  file = {/Users/colin.madland/Zotero/storage/K8JUIZI5/sinclairIntroductionRefinementAssessment2016.pdf}
}

@article{singer-freemanGrandChallengesAssessment2020a,
  title = {Grand {{Challenges}} for {{Assessment}} in {{Higher Education}}},
  author = {{Singer-Freeman}, Karen E and Robinson, Christine},
  year = {2020},
  journal = {Research \& Practice in Assessment},
  volume = {15},
  number = {2},
  pages = {20},
  abstract = {A grand challenge is a problem that requires broad cooperation for successful resolution from a community of scholars. Several national and international organizations have generated lists of grand challenges to unify the efforts of scholars and practitioners in a field. However, the field of assessment has yet to identify its own set of grand challenges that could serve to organize and motivate progress toward meaningful goals. This article describes the process by which potential grand challenges were identified and subsequently evaluated by professionals in the field through a national survey. Results of the survey demonstrate broad support for the importance of four challenges: 1) Use assessment findings to increase equity; 2) Use assessment findings to direct immediate pedagogical improvements; 3) Produce visible and actionable assessment findings that drive innovation; and 4) Examine changes in institutional effectiveness (including student learning) over time. The article concludes with a discussion of the grand challenges that emerged from this work and a description of an ongoing national effort to address these challenges through strategic planning.},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/MHCR7XF6/singer-freemanGrandChallengesAssessment2020.pdf}
}

@article{singhPedagogisingKnowledgeBernstein2002,
  title = {Pedagogising {{Knowledge}}: {{Bernstein}}'s Theory of the Pedagogic Device},
  shorttitle = {Pedagogising {{Knowledge}}},
  author = {Singh, Parlo},
  year = {2002},
  month = dec,
  journal = {British Journal of Sociology of Education},
  volume = {23},
  number = {4},
  pages = {571--582},
  issn = {0142-5692, 1465-3346},
  doi = {10.1080/0142569022000038422},
  urldate = {2022-06-18},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/X2VJ9LK4/singhPedagogisingKnowledgeBernstein2002.pdf}
}

@article{singhSmartEducationalTechnology2021,
  title = {``{{Smart}}'' {{Educational Technology}}: {{A Conversation}} between Sava Saheli Singh, {{Jade E}}. {{Davis}}, and {{Chris Gilliard}}},
  shorttitle = {``{{Smart}}'' {{Educational Technology}}},
  author = {{\noopsort{singh}}saheli {singh}, sava and Davis, Jade E. and Gilliard, Chris},
  year = {2021},
  month = jun,
  journal = {Surveillance \& Society},
  volume = {19},
  number = {2},
  pages = {262--271},
  issn = {1477-7487},
  doi = {10.24908/ss.v19i2.14812},
  urldate = {2023-02-10},
  abstract = {A conversation about smart technology use in educational settings.},
  file = {/Users/colin.madland/Zotero/storage/H88HJE8N/singhSmartEducationalTechnology2021.pdf}
}

@misc{SixMisconceptionsThreePaper2017,
  title = {Six {{Misconceptions}} about the {{Three-Paper Route}}},
  year = {2017},
  month = apr,
  journal = {PhDLife Blog},
  urldate = {2022-01-20},
  abstract = {Monograph dissertations are still the norm for many PhD students, but some disciplines allow a collection of papers to be submitted instead. We talked to a PhD student taking this route to learn mo{\dots}},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/TJRTWXMM/2017 - Six Misconceptions about the Three-Paper Route.html}
}

@article{skeneHigherEducationSurveillance2020,
  title = {Higher {{Education}} under {{Surveillance}}},
  author = {Skene, Allyson and Raffoul, Jessica and Chittle, Laura},
  year = {2020},
  journal = {Collected Essays on Learning and Teaching},
  volume = {13},
  pages = {160--165},
  issn = {ISSN-2368-4526},
  doi = {10/gmbv3x},
  abstract = {Certain government agencies are requiring more and more evidence from colleges and universities that they are efficient, effective, and relevant by calling for numbers, key performance indicators, benchmarks, and quality assurance protocols--that is, evidence based on productivity, 'economic efficiency', and 'value for money' (Power, 1994; Shore, 2008; Shore \& Wright, 2004, 2015). In this context, quality is determined by what is most visible to external scrutiny, and accountability has become conflated with accountancy, giving rise to what researchers have called "audit culture" (Power, 1994; Shore \& Wright, 2004). This article explores how audit culture has emerged in higher education by critiquing the many ways in which it directs energy towards processes of compliance and by discussing how accountability might be reported without sacrificing quality. In the end, the authors propose strategies for navigating audit and accountability culture while meeting external requirements and maintaining the values and principles of higher education.},
  langid = {english},
  keywords = {Accountability,Audits (Verification),Compliance (Legal),Educational Quality,Higher Education,Quality Assurance}
}

@article{skidmorePersoncentredApproachUnderstanding2018,
  title = {A Person-Centred Approach to Understanding Cultures of Assessment},
  author = {Skidmore, Susan T. and Hsu, Hsien-Yuan and Fuller, Matthew},
  year = {2018},
  journal = {Assessment and evaluation in higher education},
  volume = {43},
  number = {8},
  pages = {1241--1257},
  publisher = {Routledge},
  address = {Abingdon},
  issn = {0260-2938},
  doi = {10.1080/02602938.2018.1447082},
  abstract = {The purpose of the present study was to investigate how faculty members coalesce into distinguishable groups in terms of their perceived cultures of assessment at their respective institutions. To date, although researchers have posited the existence of various cultures of assessment, no study to our knowledge has empirically demonstrated the presence of these unobserved (latent) cultures analytically. Accordingly, a latent profile analysis was conducted using Mplus to identify these unobserved groups based on faculty (n~=~1148) members' responses to 12 items (6-point Likert scale) selected from the 2014 Faculty Survey of Assessment Culture. The resulting 4-class solution, including a previously unidentified group, was confirmed by the Lo-Mendell-Rubin Adjusted Likelihood Ratio Test: Culture of Student Learning (n~=~502); Evolving Student Learning Culture (n~=~398); Culture of Compliance (n~=~168); and Culture of Fear (n~=~80). Characteristics of each class are described and the prevalence of each class by type of degree granting institution and primary discipline is provided.},
  keywords = {Academic Achievement,Administrator Attitudes,Assessment,College Faculty,Cultural change,Cultural groups,culture of assessment,Educational evaluation,faculty perceptions,Higher Education,Instructional Leadership,latent profile analysis,Learning,Organizational Culture,Outcomes of Education,Statistical Analysis,Teacher Administrator Relationship,Teacher Attitudes},
  file = {/Users/colin.madland/Zotero/storage/P3IYU7UN/skidmorePersoncentredApproachUnderstanding2018.pdf}
}

@book{skinnerBehaviourOrganisms1938,
  title = {The Behaviour of Organisms},
  author = {Skinner, {\relax BF}},
  year = {1938},
  publisher = {Appleton-Century-Crofts},
  address = {New York}
}

@article{skinnerTeachingMachinesExperimental1958,
  title = {Teaching {{Machines}}: {{From}} the Experimental Study of Learning Come Devices Which Arrange Optimal Conditions for Self-Instruction.},
  shorttitle = {Teaching {{Machines}}},
  author = {Skinner, B. F.},
  year = {1958},
  month = oct,
  journal = {Science},
  volume = {128},
  number = {3330},
  pages = {969--977},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.128.3330.969},
  urldate = {2022-10-01},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/VGNJWB99/skinnerTeachingMachinesExperimental1958.pdf}
}

@article{slabbert-redpathCriticalReflectionCurriculum2014,
  title = {A Critical Reflection on the Curriculum Praxis of Classroom Assessment within a Higher Education Context},
  author = {{Slabbert-Redpath}, Jacqueline},
  year = {2014},
  journal = {null},
  doi = {null},
  abstract = {N/A: no abstract available},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@article{slabbert-redpathCriticalReflectionCurriculum2014a,
  title = {A Critical Reflection on the Curriculum Praxis of Classroom Assessment within a Higher Education Context},
  author = {{Slabbert-Redpath}, Jacqueline},
  year = {2014},
  journal = {null},
  doi = {null},
  abstract = {N/A: no abstract available},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@article{sladeInsightsHowAcademics2022,
  title = {Insights into How Academics Reframed Their Assessment during a Pandemic: Disciplinary Variation and Assessment as Afterthought},
  shorttitle = {Insights into How Academics Reframed Their Assessment during a Pandemic},
  author = {Slade, Christine and Lawrie, Gwendolyn and Taptamat, Nantana and Browne, Eleanor and Sheppard, Karen and Matthews, Kelly E.},
  year = {2022},
  month = may,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {47},
  number = {4},
  pages = {588--605},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2021.1933379},
  urldate = {2022-12-24},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/HHJI72MK/sladeInsightsHowAcademics2022.pdf}
}

@article{sladeLearningAnalyticsEthical2013,
  title = {Learning {{Analytics}}: {{Ethical Issues}} and {{Dilemmas}}},
  shorttitle = {Learning {{Analytics}}},
  author = {Slade, Sharon and Prinsloo, Paul},
  year = {2013},
  journal = {American Behavioral Scientist},
  volume = {57},
  number = {10},
  pages = {1510--1529},
  issn = {0002-7642, 1552-3381},
  doi = {10.1177/0002764213479366},
  urldate = {2024-09-25},
  abstract = {The field of learning analytics has the potential to enable higher education institutions to increase their understanding of their students' learning needs and to use that understanding to positively influence student learning and progression. Analysis of data relating to students and their engagement with their learning is the foundation of this process. There is an inherent assumption linked to learning analytics that knowledge of a learner's behavior is advantageous for the individual, instructor, and educational provider. It seems intuitively obvious that a greater understanding of a student cohort and the learning designs and interventions they best respond to would benefit students and, in turn, the institution's retention and success rate. Yet collection of data and their use face a number of ethical challenges, including location and interpretation of data; informed consent, privacy, and deidentification of data; and classification and management of data. Approaches taken to understand the opportunities and ethical challenges of learning analytics necessarily depend on many ideological assumptions and epistemologies. This article proposes a sociocritical perspective on the use of learning analytics. Such an approach highlights the role of power, the impact of surveillance, the need for transparency, and an acknowledgment that student identity is a transient, temporal, and context-bound construct. Each of these affects the scope and definition of learning analytics' ethical use. We propose six principles as a framework for considerations to guide higher education institutions to address ethical issues in learning analytics and challenges in context-dependent and appropriate ways.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/sladeLearningAnalyticsEthical2013.pdf}
}

@article{slavinCooperativeLearning1980,
  title = {Cooperative Learning},
  author = {Slavin, Robert E.},
  year = {1980},
  journal = {Review of Educational Research},
  volume = {50},
  number = {2},
  pages = {315--342},
  abstract = {Research on classroom cooperative learning techniques, in which students work in small groups and receive rewards or recognition based on their group performance, has been increasing in the past few years. This review summarizes the results of 28 primary field projects lasting at least 2 weeks, in which cooperative learning methods were used in elementary or secondary classrooms. The pattern of research findings supports the utility of cooperative learning methods in general for increasing student achievement, positive race relations in desegregated schools, mutual concern among students, student self-esteem, and other positive outcomes. The various cooperative learning methods are contrasted in terms of characteristics and outcomes, and the next steps for research in this area are outlined.},
  file = {/Users/colin.madland/Zotero/storage/43RV4JKG/slavinCooperativeLearning1980.pdf}
}

@book{slavinCooperativeLearningTheory1995,
  title = {Cooperative Learning: {{Theory}}, Research and Practice},
  shorttitle = {Cooperative Learning: {{Theory}}, Research and Practice},
  author = {Slavin, Robert E.},
  year = {1995},
  edition = {2nd},
  publisher = {{Allyn and Bacon}},
  address = {Boston}
}

@incollection{slavinInstructionBasedCooperative2011,
  title = {Instruction Based on Cooperative Learning},
  booktitle = {Handbook of Research on Learning and Instruction},
  author = {Slavin, Robert E.},
  editor = {Mayer, Richard E and Alexander, Patricia A},
  year = {2011},
  series = {Educational {{Psychology Handbook Series}}},
  pages = {344--360},
  publisher = {Routledge},
  address = {New York}
}

@article{slaydonQuantifyingPersonalFactor2020,
  title = {Quantifying the {{Personal Factor}} of {{FTF}} in an {{Online World}}},
  author = {Slaydon, James and Rose, David and Allen, Larry},
  year = {2020},
  journal = {Journal of Instructional Pedagogies},
  volume = {23},
  issn = {ISSN-2327-5324},
  abstract = {Online Students miss out on experiences that face-to-face classes offer which allows the connection between them with faculty and other students. Regardless, online education appears to be the darling of higher education leadership likely because it represented nearly three quarters of all enrollment increases last year. However, there is a gap in research regarding the human factor probably due to lack of measurability of the subject. The primary objective of this paper is to measure how the separation of teacher and student in online courses influences the student's perception of the quality of instruction. To measure students' perception, a survey based upon six statements was given to both face-to-face (FTF) and online as well as undergraduate and graduate. In every case, there was a significant difference in the means between online students and FTF students (both FTF and online undergraduate students plus FTF and online graduate students). This difference plainly favored FTF instruction for both undergraduate and graduate students. Additionally, of the six statements, the data demonstrated that instructor availability is the primary missing factor in online courses.},
  langid = {english},
  keywords = {Conventional Instruction,Educational Quality,Educational Technology,Graduate Students,Interaction,No DOI found,Online Courses,Student Attitudes,Teacher Effectiveness,Teacher Student Relationship,Teaching Methods,Technology Uses in Education,Undergraduate Students}
}

@article{sleeterCriticalFamilyHistory2016,
  title = {Critical {{Family History}}: {{Situating Family}} within {{Contexts}} of {{Power Relationships}}.},
  author = {Sleeter, Christine E.},
  year = {2016},
  journal = {Journal of Multidisciplinary Research (1947-2900)},
  volume = {8},
  number = {1},
  pages = {11--24},
  issn = {19472900},
  abstract = {Family history research has become increasingly popular as online genealogical research tools have become widely available. However, family historians, particularly those from dominant social groups, usually end up interpreting their family story within dominant national narratives. As a form of "memory work" (Kuhn, 1995), family history has the potential to unearth hidden or "forgotten" memories about the past and its implication for the present. Drawing on theoretical tools of the critical theoretical traditions, critical family history interrogates the interaction between family and context, with a particular focus on power relationships among sociocultural groups. In this article, I use my own family history to illustrate the recovery of a silenced or suppressed national narrative. Specifically, through an examination of property records and wills, I show how social relationships that colonization forged, rather than being a relic of the past, live on in the present, and how family history can challenge a national mythology that minimizes the importance and ongoing impact of colonization. [ABSTRACT FROM AUTHOR]},
  keywords = {colonization,COLONIZATION,critical race theory,family wealth,GENEALOGY,historical memory,HISTORIOGRAPHY,INTERPERSONAL relations,national mythology,No DOI found,SOCIAL groups},
  file = {/Users/colin.madland/Zotero/storage/9MDF6HMA/sleeterCriticalFamilyHistory2016.pdf}
}

@misc{smithAboriginalEducationMatters2012,
  title = {Aboriginal {{Education Matters}}: {{The Status}} of {{Aboriginal People}} and {{Scholarship}} in the {{Academy}} {\textbar} {{Federation}} for the {{Humanities}} and {{Social Sciences}}},
  author = {Smith, Malinda S},
  year = {2012},
  month = mar,
  journal = {Federation for the Humanities and Social Sciences},
  urldate = {2019-02-15},
  howpublished = {http://www.ideas-idees.ca/blog/aboriginal-education-matters-status-aboriginal-people-and-scholarship-academy},
  file = {/Users/colin.madland/Zotero/storage/SXSQZMD4/aboriginal-education-matters-status-aboriginal-people-and-scholarship-academy.html}
}

@article{smithAssessmentLiteracyStudent2013,
  title = {Assessment Literacy and Student Learning: The Case for Explicitly Developing Students `Assessment Literacy'},
  shorttitle = {Assessment Literacy and Student Learning},
  author = {Smith, Calvin Douglas and Worsfold, Kate and Davies, Lynda and Fisher, Ron and McPhail, Ruth},
  year = {2013},
  month = feb,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {38},
  number = {1},
  pages = {44--60},
  issn = {0260-2938, 1469-297X},
  doi = {10/fw72hb},
  urldate = {2021-07-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/J9LK2MPM/smithAssessmentLiteracyStudent2013.pdf}
}

@incollection{smithDesigningDeliveryStrategies2005,
  title = {Designing {{Delivery Strategies}}},
  booktitle = {Instructional {{Design}}},
  author = {Smith, {\relax PL} and Ragan, {\relax TJ}},
  year = {2005},
  edition = {3rd},
  publisher = {Wiley Jossey-Bass Education},
  address = {Hoboken, NJ}
}

@article{smithglasgowStandardizedTestingNursing2019,
  title = {Standardized Testing in Nursing Education: {{Preparing}} Students for {{NCLEX-RN}}{\textregistered} and Practice},
  shorttitle = {Standardized Testing in Nursing Education},
  author = {Smith Glasgow, Mary Ellen and Dreher, H. Michael and Schreiber, James},
  year = {2019},
  journal = {Journal of Professional Nursing},
  volume = {35},
  number = {6},
  pages = {440--446},
  issn = {87557223},
  doi = {10/ggqh9p},
  urldate = {2021-07-13},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/TBSD6UWV/smithglasgowStandardizedTestingNursing2019.pdf}
}

@article{smithImpactFramingEffect2009,
  title = {The Impact of Framing Effect on Student Preferences for University Grading Systems},
  author = {Smith, Jeffrey K. and Smith, Lisa F.},
  year = {2009},
  month = dec,
  journal = {Studies in Educational Evaluation},
  volume = {35},
  number = {4},
  pages = {160--167},
  issn = {0191491X},
  doi = {10/bs7388},
  urldate = {2021-01-02},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/Z7NXUT52/smithImpactFramingEffect2009.pdf}
}

@book{smithInstructionalDesign2005,
  ids = {smithp.l.raganInstructionalDesign2005},
  title = {Instructional {{Design}}},
  author = {Smith, {\relax PL} and Ragan, {\relax TJ}},
  year = {2005},
  edition = {3rd},
  publisher = {Wiley Jossey-Bass Education},
  address = {Hoboken, NJ}
}

@incollection{smithKaupapaMaoriResearch2000,
  title = {Kaupapa {{M{\=a}ori}} Research},
  booktitle = {Reclaiming Indigenous Voice and Vision},
  author = {Smith, Linda Tuhiwai},
  editor = {Battiste, Marie Ann},
  year = {2000},
  publisher = {UBC Press},
  address = {Vancouver},
  abstract = {"The essays in Reclaiming Indigenous Voice and Vision spring from an International Summer Institute on the cultural restoration of oppressed Indigenous peoples. The contributors, primarily Indigenous, unravel the processes of colonization that enfolded modern society and resulted in the oppression of Indigenous peoples." "In moving and inspiring ways, Reclaiming Indigenous Voice and Vision elaborates a new inclusive vision of a global and national order and articulates new approaches for protecting, healing, and restoring long-oppressed peoples, and for respecting their cultures and la},
  isbn = {0-7748-0745-8 978-0-7748-0745-6 0-7748-0746-6 978-0-7748-0746-3},
  lccn = {GN380 .R43 2000},
  keywords = {Decolonization,Indigenous peoples},
  annotation = {OCLC: 43282269}
}

@misc{smithLiteratureReviewsOverview,
  title = {Literature {{Reviews}}: {{An Overview}} for {{Graduate Students}}},
  shorttitle = {Literature {{Reviews}}},
  urldate = {2022-09-03},
  abstract = {NC State University Libraries},
  collaborator = {Smith, Eleanor and Duckett, Kim and Bankston, Sarah and Classen, John and Orphanides, Andreas and Baker, Susan},
  howpublished = {https://www.lib.ncsu.edu//videos/literature-reviews-overview-graduate-students},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/Z4CE782P/literature-reviews-overview-graduate-students.html}
}

@incollection{smithPreparingTeachersUse2014,
  title = {Preparing {{Teachers}} to {{Use}} the {{Enabling Power}} of {{Assessment}}},
  booktitle = {Designing {{Assessment}} for {{Quality Learning}}},
  author = {Smith, Lisa F. and Hill, Mary F. and Cowie, Bronwen and Gilmore, Alison},
  editor = {{Wyatt-Smith}, Claire and Klenowski, Valentina and Colbert, Peta},
  year = {2014},
  volume = {1},
  pages = {303--323},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-94-007-5902-2_19},
  urldate = {2021-08-04},
  isbn = {978-94-007-5901-5 978-94-007-5902-2},
  file = {/Users/colin.madland/Zotero/storage/2BW3UGK4/smithPreparingTeachersUse2014.pdf}
}

@incollection{smithProtectingRespectingIndigenous2000,
  title = {Protecting and {{Respecting Indigenous Knowledge}}},
  booktitle = {Reclaiming Indigenous Voice and Vision},
  author = {Smith, Graham Hingangaroa},
  editor = {Battiste, Marie Ann},
  year = {2000},
  publisher = {UBC Press},
  address = {Vancouver},
  abstract = {"The essays in Reclaiming Indigenous Voice and Vision spring from an International Summer Institute on the cultural restoration of oppressed Indigenous peoples. The contributors, primarily Indigenous, unravel the processes of colonization that enfolded modern society and resulted in the oppression of Indigenous peoples." "In moving and inspiring ways, Reclaiming Indigenous Voice and Vision elaborates a new inclusive vision of a global and national order and articulates new approaches for protecting, healing, and restoring long-oppressed peoples, and for respecting their cultures and la},
  isbn = {0-7748-0745-8 978-0-7748-0745-6 0-7748-0746-6 978-0-7748-0746-3},
  lccn = {GN380 .R43 2000},
  keywords = {Decolonization,Indigenous peoples},
  annotation = {OCLC: 43282269}
}

@article{smithReconsideringReliabilityClassroom2003,
  title = {Reconsidering {{Reliability}} in {{Classroom Assessment}} and {{Grading}}},
  author = {Smith, Jeffrey K.},
  year = {2003},
  month = dec,
  journal = {Educational Measurement: Issues and Practice},
  volume = {22},
  number = {4},
  pages = {26--33},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {0731-1745},
  doi = {10/dtnvgw},
  urldate = {2020-09-30},
  abstract = {It is argued that classroom assessment evolves from a different set of issues and demands from more traditional measurement concerns and that approaches to reliability developed from traditional concerns are not appropriate for most classroom settings. The assessment and grading issues for high school instruction are examined from the perspective of reliability. An alternative conceptualization of reliability, sufficiency of information, is proposed and explored. This conceptualization is based on the argument that at a rudimentary level, reliability theory is based on the notion of having enough information to make decisions or draw inferences.},
  keywords = {classroom assessment,measurement theory,reliability},
  file = {/Users/colin.madland/Zotero/storage/ZW54WVD3/smithReconsideringReliabilityClassroom2003.pdf}
}

@inproceedings{smithResearchIssuesRelated1992,
  title = {Research Issues Related to Maori Education},
  booktitle = {The {{Issue}} of {{Research}} and {{M{\=a}ori}}},
  author = {Smith, Graham Hingangaroa},
  year = {1992},
  publisher = {Research Unit for M{\=a}ori Education},
  address = {Aukland, NZ}
}

@article{snekalathaMedicalStudentsPerception2021,
  title = {Medical Students' Perception of the Reliability, Usefulness and Feasibility of Unproctored Online Formative Assessment Tests},
  author = {Snekalatha, S. and Marzuk, S. Mohamed and Meshram, Swapnatai A. and Maheswari, K. Uma and Sugapriya, G. and Sivasharan, K.},
  year = {2021},
  journal = {Advances in physiology education},
  volume = {45},
  number = {1},
  pages = {84--88},
  publisher = {Amer Physiological Soc},
  address = {BETHESDA},
  issn = {1043-4046},
  doi = {10.1152/advan.00178.2020},
  abstract = {Medical education has gone online because of the COVID-19 pandemic. Formative assessment is essential to facilitate the learning process in medical education. However, various challenges arise during online assessment, which include reliability, when done without monitoring and practical concerns like Internet connectivity issues. This study was done to assess the medical students' perceptions of the reliability, usefulness, and practical challenges of online tests. One hundred first-year undergraduate medical students taking up online classes and tests in the subject of physiology were enrolled in this study. A questionnaire with items regarding practical challenges, reliability, and usefulness of the online tests, in general, and about different types of online assessment methods, in particular, were sent to the students online. Each item was rated on a five-point Likert scale, and the responses were analyzed anonymously. A large percentage of students used mobile phones (81.4\%) to undertake online tests. Although most students (73.2\%; P {$<$} 0.001) felt that online tests helped them substantially in learning the subject, network connectivity issues were considered to be a matter of serious concern (85.5\%, P {$<$} 0.001). Among the assessment methods used, viva voce by video conferencing was thought to be most reliable (83\%, P {$<$} 0.001). Multiple-choice question-based assessment when done online was felt to be more practically feasible with faster feedback than classroom assessment. The results of the study suggest that medical students find online formative assessments helpful for their learning, despite their concerns about reliability and practical challenges.},
  keywords = {Cellular telephones,College students,Computer Assisted Testing,COVID-19,Education & Educational Research,Education Distance - methods,Education Distance - standards,Education Medical - methods,Education Medical - standards,Education Scientific Disciplines,Educational Measurement - methods,Educational Measurement - standards,Evaluation Methods,Feasibility Studies,Female,Foreign Countries,Formative Evaluation,Handheld Devices,Humans,Internet,Learning,Life Sciences & Biomedicine,Male,Medical education,Medical Students,Online instruction,Pandemics,Physiology,Reproducibility of Results,Science & Technology,Social Sciences,Student Attitudes,Students Medical - psychology,Supervision,Surveys and Questionnaires,Test Reliability,Test Validity,Undergraduate Students},
  file = {/Users/colin.madland/Zotero/storage/46GLH684/snekalathaMedicalStudentsPerception2021.pdf}
}

@article{snowGuidingPrinciplesIndigenous2015,
  title = {Guiding Principles for Indigenous Research Practices},
  author = {Snow, Kevin C and Hays, Danica G and Caliwagan, Guia and Ford, David J and Mariotti, Davide and Mwendwa, Joy Maweu and Scott, Wendy E},
  year = {2015},
  journal = {Action Research},
  volume = {14},
  number = {4},
  pages = {357--375},
  issn = {1476-7503},
  doi = {10.1177/1476750315622542},
  urldate = {2019-02-15},
  abstract = {Based upon expansions of indigenous research methodologies in the literature, researchers are encouraged to understand indigenous research conceptualization and implementation within various communities. The purpose of this review is to outline six tenets or principles that are intended to engage researchers in practices that privilege the voices and goals of indigenous populations: indigenous identity development; indigenous paradigmatic lens; reflexivity and power sharing; critical immersion; participation and accountability; and methodological flexibility. Future research directions for expanding and operationalizing principles of indigenous research practices are also provided.}
}

@article{snowWhatDoesBeing2018,
  title = {What {{Does Being}} a {{Settler Ally}} in {{Research Mean}}? {{A Graduate Students Experience Learning From}} and {{Working Within Indigenous Research Paradigms}}},
  author = {Snow, Kathy},
  year = {2018},
  journal = {International Journal of Qualitative Methods},
  volume = {17},
  number = {1},
  pages = {1609406918770485},
  issn = {1609-4069},
  doi = {10.1177/1609406918770485},
  urldate = {2019-02-15},
  abstract = {Research with Indigenous peoples is fraught with complexity and misunderstandings. The complexity of negotiating historical and current issues as well as the misunderstandings about what the issues really mean for individuals and communities can cause non-Indigenous researchers to shy away from working with Indigenous groups. In conducting research for my doctoral dissertation, I was a novice researcher faced with negotiating two very different sets of social contracts: the Western Canadian university?s and my Indigenous participants?. Through narrative inquiry of my experience, this article explores issues of ethics, institutional expectations, and community relationships. Guided by Kirkness and Barnhardt?s ?Four R?s? framework of respect, relevance, reciprocity, and responsibility, I aimed to meet the needs of both the groups, but it was not without challenges. What do you do when needs collide? This article shares my process of negotiating the research, the decisions made, and how I came to understand my role in the process as a Settler Ally. It closes with some implications for other researchers who are considering their own roles as Settler Allies.}
}

@article{sockalingamStudentTutorPerceptions,
  title = {Student and Tutor Perceptions on Attributes of Effective Problems in Problem-Based Learning},
  author = {Sockalingam, Nachamma and Rotgans, Jerome and Schmidt, Henk},
  journal = {Higher Education},
  abstract = {Abstract\&nbsp;\&nbsp;This study aimed to identify the attributes that students and tutors associated with effective PBL problems, and assess the extent to which these attributes related to the actual effectiveness of problems. To this end, students and tutors in focus groups were asked to discuss about possible attributes of effective problems. The same participants were then asked to individually and independently judge eight sample problems they had worked with. Text analysis of the focus group discussion transcripts identified eleven problem attributes. Participants' judgments of the sample problems were then frequency-scored on the eleven problem attributes. Relating the participants' judgments with the entire student cohort's grades yielded high and significant correlations, suggesting that the eleven problem attributes reflect aspects of problem effectiveness.}
}

@misc{SoftwarePlagiatsPortal,
  title = {Software << {{Plagiats Portal}}},
  urldate = {2019-04-24},
  howpublished = {http://plagiat.htw-berlin.de/software-en/},
  file = {/Users/colin.madland/Zotero/storage/J9T9P7NV/software-en.html}
}

@article{solano-alpizarDecolonizingEducationAccepting2015,
  title = {Decolonizing {{Education}} or {{Accepting}} the {{Challenge}} of {{Taking}} a {{Different Path}}},
  author = {{Solano-Alp{\'i}zar}, Jos{\'e}},
  year = {2015},
  journal = {Revista Electronic@ Educare},
  volume = {19},
  number = {1},
  pages = {117--129},
  doi = {10.15359/ree.19-1.7},
  abstract = {This paper discusses the importance of decolonizing education as one of the strategies to help create a new, more human, more caring and more critical vision of the world.~ It directs the reader's attention to a territory of which much has been written --education-- but still has many pending discussions regarding the possibility of thinking about another type of education: a type of education that allows us to see ourselves as historical subjects that give meaning to our existence by breaking the ideological attachment to the epistemic, cultural, axiological and ontological frameworks that were used and are still being used to base the current matrix of neocolonial domination.},
  keywords = {Descolonizacion educativa,descolonizacion epistemologica,educacion liberadora,emancipacion sociocultural,sumak kawsay o buen vivir}
}

@article{solomonidouStudentsConceptionsAssessment2017,
  title = {Students' Conceptions of Assessment Purposes in a Low Stakes Secondary-School Context: {{A}} Mixed Methodology Approach},
  shorttitle = {Students' Conceptions of Assessment Purposes in a Low Stakes Secondary-School Context},
  author = {Solomonidou, Georgia and Michaelides, Michalis},
  year = {2017},
  month = mar,
  journal = {Studies in Educational Evaluation},
  volume = {52},
  pages = {35--41},
  issn = {0191491X},
  doi = {10/f9w8gd},
  urldate = {2021-08-03},
  abstract = {Though assessment in its early history was conceived as a measurement device, alternative approaches to assessment of student achievement have appeared the past few decades. In this context, studies have been conducted to investigate students' conceptions of assessment approaches and purposes, as there is evidence that these will affect their learning and ultimately their achievement. This study uses a sequential mixed methods design to investigate students' conceptions about the purposes of assessment and their definitions of assessment. A questionnaire was administered to 599 lower secondary school students in Cyprus, followed by group interviews with 15 students to explain and build upon initial quantitative findings. Results show that students' perceptions are in alignment with the current shift in assessment to be used primarily for enhancing teaching and learning. Students seem to agree with the legitimate purposes of assessment and realize that it is an ongoing procedure linked with teaching and learning.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/7WDMRK8J/solomonidouStudentsConceptionsAssessment2017.pdf}
}

@article{somersApplyingNaturalLanguage2021,
  title = {Applying Natural Language Processing to Automatically Assess Student Conceptual Understanding from Textual Responses},
  author = {Somers, Rick and {Cunningham-Nelson}, Samuel and Boles, Wageeh},
  year = {2021},
  month = dec,
  journal = {Australasian Journal of Educational Technology},
  volume = {37},
  number = {5},
  pages = {98--115},
  issn = {1449-5554, 1449-3098},
  doi = {10.14742/ajet.7121},
  urldate = {2023-01-15},
  abstract = {In this study, we applied natural language processing (NLP) techniques, within an educational environment, to evaluate their usefulness for automated assessment of students' conceptual understanding from their short answer responses. Assessing understanding provides insight into and feedback on students' conceptual understanding, which is often overlooked in automated grading. Students and educators benefit from automated formative assessment, especially in online education and large cohorts, by providing insights into conceptual understanding as and when required. We selected the ELECTRA-small, RoBERTa-base, XLNet-base and ALBERT-base-v2 NLP machine learning models to determine the free-text validity of students' justification and the level of confidence in their responses. These two pieces of information provide key insights into students' conceptual understanding and the nature of their understanding. We developed a free-text validity ensemble using high performance NLP models to assess the validity of students' justification with accuracies ranging from 91.46\% to 98.66\%. In addition, we proposed a general, non-question-specific confidence-in-response model that can categorise a response as high or low confidence with accuracies ranging from 93.07\% to 99.46\%. With the strong performance of these models being applicable to small data sets, there is a great opportunity for educators to implement these techniques within their own classes. Implications for practice or policy: Students' conceptual understanding can be accurately and automatically extracted from their short answer responses using NLP to assess the level and nature of their understanding. Educators and students can receive feedback on conceptual understanding as and when required through the automated assessment of conceptual understanding, without the overhead of traditional formative assessment. Educators can implement accurate automated assessment of conceptual understanding models with fewer than 100 student responses for their short response questions.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/8WD8BPVQ/somersApplyingNaturalLanguage2021.pdf}
}

@article{songInsightsThreeOnline2021,
  ids = {songInsightsThreeOnline2021a},
  title = {Insights {{From Three Online Art Educators}}: {{Strategies}} for {{Instruction}}, {{Interaction}}, and {{Assessment}}},
  author = {Song, Borim and Lim, Kyungeun and Kwon, Hyunji},
  year = {2021},
  journal = {Art Education},
  volume = {74},
  number = {4},
  pages = {16--21},
  publisher = {Routledge},
  issn = {0004-3125},
  doi = {10.1080/00043125.2021.1905399},
  abstract = {Due to the outbreak of COVID-19, which requires the majority of K-16 education to be temporarily taught online. While unfamiliarity with digital technologies may make the transition to online teaching difficult, the world's sudden dependence on distance learning has sparked the pressing need to implement virtual art education that is efficient and effective (Godvin, 2020). The three authors are all art educators who have been teaching virtual courses with a studio art focus in higher education for several years. In this article, based on their experiences, they share their collective insights on approaches to instruction, interaction, and assessment in virtual courses that might help other art educators avoid some of the common pitfalls of online teaching and achieve successful learning outcomes for their students. Each author describes the strategies she employed while teaching an online course and offers an analytical reflection. They end by offering the key learnings from their teaching experiences, examining how diverse students' needs could be met.},
  keywords = {Art Teachers,College Faculty,Distance Education,Feedback (Response),Peer Relationship,Student Evaluation,Teacher Student Relationship,Teaching Methods,Web Based Instruction}
}

@article{songWhatOnlineSuccess2016a,
  title = {What {{Online Success Means}} to {{Online Instructors}}: {{A Grounded Theory Investigation}}},
  author = {Song, Liyan},
  year = {2016},
  month = jan,
  journal = {International Journal of Technology in Teaching and Learning},
  volume = {12},
  number = {2},
  pages = {89--98},
  publisher = {{International Journal of Technology in Teaching and Learning}},
  issn = {1551-2576},
  abstract = {The purpose of this research was to examine online instructors' perspectives on assessment practices within online environments. Nine online instructors from seven institutions were interviewed for this grounded theory qualitative research. Three main aspects emerged from the analysis of the interviews that were involved in online assessment practices: student learning, instructional design, and interaction. The findings from this study suggested that online learning environments are uniquely different from the traditional classrooms, especially the forced nature of discussions and greater emphasis on interactions. In addition, the findings indicated that unique characteristics of online environments along with instructors' epistemic belief have an impact on course design and delivery.},
  keywords = {College Faculty,College Students,Computer Assisted Testing,Distance Education,Educational Technology,Evaluation Methods,Instructional Design,Interaction,Learning,No DOI found,Online Courses,Student Evaluation,Teacher Attitudes,Teaching Methods,Technology Uses in Education}
}

@article{sonnleitnerDifferencesStudentsTeachers2020,
  title = {Differences {{Between Students}}' and {{Teachers}}' {{Fairness Perceptions}}: {{Exploring}} the {{Potential}} of a {{Self-Administered Questionnaire}} to {{Improve Teachers}}' {{Assessment Practices}}},
  shorttitle = {Differences {{Between Students}}' and {{Teachers}}' {{Fairness Perceptions}}},
  author = {Sonnleitner, Philipp and Kovacs, Carrie},
  year = {2020},
  month = feb,
  journal = {Frontiers in Education},
  volume = {5},
  pages = {17},
  issn = {2504-284X},
  doi = {10/gg29t2},
  urldate = {2020-06-26},
  file = {/Users/colin.madland/Zotero/storage/M95DMCNI/sonnleitnerDifferencesStudentsTeachers2020.pdf}
}

@article{sozenEffectOnlineAssessments2019,
  ids = {sozenEffectOnlineAssessments2019a},
  title = {The {{Effect}} of {{Online Assessments}} on {{Students}}' {{Attitudes}} towards {{Undergraduate-Level Geography Courses}}},
  author = {S{\"o}zen, Erol and G{\"u}ven, Ufuk},
  year = {2019},
  journal = {International Education Studies},
  volume = {12},
  number = {10},
  pages = {1--8},
  publisher = {International Education Studies},
  issn = {ISSN-1913-9020},
  doi = {10/gmbv29},
  abstract = {The improvements in technology made technology tools invade almost every field, including education. Online assessment tools have various functions for students and teachers. Students are able to use their mobile devices in the classroom, while teachers are able to use the tools for formative and summative evaluation purposes and for getting to know their students. Teachers also get feedback on their instructional practices by analyzing student responses. Previous studies found that undergraduate students in Faculty of Education in Turkey do not have a very positive attitude for geography courses, because most of the students take geography courses almost every year until they enter the university. The aim of this study is to determine the effect of in-class online assessment tools on the attitudes of students at undergraduate level towards geography courses. In addition, the changes in students' attitudes are examined for various variables. The study was designed in a quasi-experimental model with experiment and control groups. The study also implemented pre-tests and post-tests. Geography Attitude Scale developed by S{\"o}zen (2019) was used as data collection tool. The study's sample consists of 70 students whose majors are Primary School Teacher in Faculty of Education. An online assessment tool was implemented for seven weeks in experiment group, while the control group did not receive the said tool. The study found that using online assessment tools significantly improved students' attitude towards geography course.},
  langid = {english},
  keywords = {Attitude Measures,Comparative Analysis,Computer Assisted Testing,Elementary School Teachers,Feedback (Response),Foreign Countries,Geography Instruction,Handheld Devices,Pretests Posttests,Schools of Education,Student Attitudes,Teacher Student Relationship,Telecommunications,Turkey,Undergraduate Students},
  file = {/Users/colin.madland/Zotero/storage/4PD3M2KV/sozenEffectOnlineAssessments2019.pdf}
}

@article{spanteDigitalCompetenceDigital2018,
  title = {Digital Competence and Digital Literacy in Higher Education Research: {{Systematic}} Review of Concept Use},
  shorttitle = {Digital Competence and Digital Literacy in Higher Education Research},
  author = {Spante, Maria and Hashemi, Sylvana Sofkova and Lundin, Mona and Algers, Anne},
  editor = {Wang, Shuyan},
  year = {2018},
  month = jan,
  journal = {Cogent Education},
  volume = {5},
  number = {1},
  pages = {1519143},
  issn = {2331-186X},
  doi = {10.1080/2331186X.2018.1519143},
  urldate = {2024-02-09},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/68C66ZE9/spanteDigitalCompetenceDigital2018.pdf}
}

@article{sparksAssessingDigitalInformation2016,
  title = {Assessing {{Digital Information Literacy}} in {{Higher Education}}: {{A Review}} of {{Existing Frameworks}} and {{Assessments}} with {{Recommendations}} for {{Next-Generation Assessment}}. {{Research Report}}. {{ETS RR-16-32}}},
  author = {Sparks, Jesse R. and Katz, Irvin R. and Beile, Penny M.},
  year = {2016},
  month = dec,
  journal = {ETS Research Report Series},
  publisher = {ETS Research Report Series},
  issn = {2330-8516},
  abstract = {Digital information literacy (DIL)--generally defined as the ability to obtain, understand, evaluate, and use information in a variety of digital technology contexts--is a critically important skill deemed necessary for success in higher education as well as in the global networked economy. To determine whether college graduates possess the requisite knowledge and skills in DIL, higher education institutions must be able to administer and use results from valid assessments of DIL. In this paper, we provide a comprehensive review of existing definitions of this construct in major frameworks from higher education and the workforce and propose an operational definition of DIL. Next, we provide a review of existing assessments of information literacy and related constructs, including features of the assessments, construct alignment, and psychometric properties (i.e., reliability and validity evidence). Finally, we discuss challenges and considerations surrounding the design, implementation, and use of next-generation assessments of DIL. We offer this review as a resource for higher education institutions in selecting among existing assessments or in designing their own measures.},
  keywords = {Definitions,Ethics,Evaluation Methods,Higher Education,Information Literacy,Information Technology,Legal Responsibility,Literature Reviews,Multiple Choice Tests,No DOI found,Performance Based Assessment,Problem Solving,Technological Literacy,Test Reliability,Test Validity}
}

@article{SpecialIssueStrengthening2018,
  title = {Special {{Issue}}: {{Strengthening}} the {{Connections Between Classroom}} and {{Large-Scale Assessments}}},
  year = {2018},
  journal = {Educational Measurement: Issues and Practice},
  volume = {37},
  number = {1},
  pages = {4--4},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {0731-1745},
  doi = {10/gjn22d},
  urldate = {2021-04-08},
  file = {/Users/colin.madland/Zotero/storage/FN5ID8EN/SpecialIssueStrengthening2018.pdf}
}

@article{spectorEthicsEducationalTechnology2016,
  title = {Ethics in Educational Technology: Towards a Framework for Ethical Decision Making in and for the Discipline},
  shorttitle = {Ethics in Educational Technology},
  author = {Spector, J. Michael},
  year = {2016},
  journal = {Educational Technology Research and Development},
  volume = {64},
  number = {5},
  pages = {1003--1011},
  issn = {1042-1629, 1556-6501},
  doi = {10.1007/s11423-016-9483-0},
  urldate = {2024-10-09},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/spectorEthicsEducationalTechnology2016.pdf}
}

@book{spectorHandbookResearchEducational2014,
  title = {Handbook of Research on Educational Communications and Technology},
  editor = {Spector, J. Michael},
  year = {2014},
  edition = {Fourth edition},
  publisher = {Springer},
  address = {New York},
  isbn = {978-1-4614-3184-8},
  lccn = {LB1028.3 .H355 2014},
  keywords = {Communication in education,Design Research,Educational technology,Handbooks manuals etc,Instructional systems,Research,Telecommunication in education}
}

@article{spectorTechnologyEnhancedFormative2016,
  title = {Technology {{Enhanced Formative Assessment}} for 21st {{Century Learning}}},
  author = {Spector, {\relax JM} and Ifenthaler, D and Sampson, D and Yang, L and Mukama, E and Warusavitarana, A and Dona, {\relax KL} and Eichhorn, K and Fluck, A and Huang, {\relax RH} and Bridges, S and Lu, {\relax JY} and Ren, {\relax YQ} and Gui, {\relax XQ} and Deneen, {\relax CC} and San Diego, J and Gibson, {\relax DC}},
  year = {2016},
  month = jul,
  journal = {Educational Technology \& Society},
  volume = {19},
  number = {3},
  pages = {58--71},
  issn = {1176-3647},
  abstract = {This paper is based on the deliberations of the Assessment Working Group at EDUsummIT 2015 in Bangkok, Thailand. All of the members of Thematic Working Group 5 (TWG5) have contributed to this synthesis of potentials, concerns and issues with regard to the role of technology in assessment as, for and of learning in the 21st century. The group decided to focus primarily on formative assessment rather than summative assessment and high stakes testing. Formative assessments and feedback provide an important opportunity to support and enhance student learning. Recognizing shifts in education towards blended and online learning with problem-based and inquiry-based approaches led to considerations of technologies that could effectively support formative assessment and informative feedback to 21st century learners. The paper concludes with a summary of conclusions and recommendations of the working group to be taken up in subsequent efforts.},
  langid = {english},
  keywords = {FEEDBACK,Formative assessment,IMPACT,Inquiry-based learning,No DOI found,PEER,Problem-based learning,Summative assessment,Technologies for assessment},
  file = {/Users/colin.madland/Zotero/storage/RTCU9KV3/spectorTechnologyEnhancedFormative2016.pdf}
}

@article{sperberPeerAIReview2025,
  title = {Peer and {{AI Review}} + {{Reflection}} ({{PAIRR}}): {{A}} Human-Centered Approach to Formative Assessment},
  shorttitle = {Peer and {{AI Review}} + {{Reflection}} ({{PAIRR}})},
  author = {Sperber, Lisa and MacArthur, Marit and Minnillo, Sophia and Stillman, Nicholas and Whithaus, Carl},
  year = {2025},
  month = jun,
  journal = {Computers and Composition},
  volume = {76},
  pages = {102921},
  issn = {8755-4615},
  doi = {10.1016/j.compcom.2025.102921},
  urldate = {2025-05-07},
  abstract = {Cycles of drafting and revising are crucial for student writers' growth, and formative assessment plays an important role. However, many teachers lack the time or resources to provide feedback on drafts. While research suggests that AI feedback is high enough quality to be used for draft feedback, especially when assignment-specific criteria are used (Steiss et al., 2024), it must be used in a human-centered process. AI has the potential to reduce educational equity gaps in writing support (Warschauer et al., 2023), but when narrowly implemented, technologies can deepen divides (Stornaiuolo, et al., 2023). Peer and AI Review + Reflection (PAIRR) combines peer review best practices with AI review in an approach that emphasizes student agency and reflection. Using a mixed methods approach, this study examined student perceptions of AI utility in the context of peer review. Results indicate that AI tools offer useful feedback when combined with peer review. Students found the similarity between AI and peer feedback reassuring, while also valuing their complementary perspectives. Moreover, by evaluating AI outputs, students developed AI literacy, gaining familiarity with AI feedback's affordances and limitations while learning ethical ways to use AI in their writing processes.},
  keywords = {Agency,AI literacy,Feedback,Formative assessment,Peer review,Reflection,Writing response},
  file = {/Users/colin.madland/Zotero/storage/AI/sperberPeerAIReview2025.pdf}
}

@phdthesis{spiethmargaretOptimizingOnlineStudent2009,
  title = {Optimizing Online Student Success: {{Strategies}} Utilized by Technical College Students},
  author = {Spieth, Margaret, M},
  year = {2009},
  abstract = {The majority of institutions of higher education consider online education to be an essential element of their long-term strategy, and online enrollments continue to grow, with almost 3.5 million students enrolled in at least one online course during the fall semester of 2006 (Sloan Consortium, 2007). Although increasing numbers of students are attracted by the flexibility of online courses, a disproportionate number are unsuccessful, with retention rates averaging 72\% for distance education courses, in comparison to 78\% for traditional courses (Instructional Technology Council, 2007). Techniques to optimize success have been shared with students to facilitate online student goal attainment, albeit these strategies have been developed by faculty and/or administration, rather than those with first-hand experience--successful online students; therefore, the purpose of this study was to draw on the experience of successful online students by answering the question, "What strategies do successful online students who have met their goals in the context of an online course utilize to optimize their success?" This descriptive research study was conducted in a technical college in Southeast Wisconsin, utilizing a three-phase data collection process. Following a preliminary focus group to establish construct validity, face validity, and content validity of a survey instrument designed to identify the dispositions of successful online students, an invitation to complete the electronic survey was extended to a census of online students at the college ( N = 1,300), with 436 students ( n = 436) completing the survey, for a 34\% response rate. The second phase of data collection consisted of interviews with a convenience sampling of participants ( n = 10). In the final phase of data collection, an invitation to complete a follow-up survey was extended to a random sampling of online students at the college ( n = 600), with a total of 137 students ( n = 137) completing the electronic survey, for a 23\% response rate. Results demonstrated successful online students utilize strategies in the areas of time management, communication, and motivation. A checklist tool of the top 10 strategies was created to share advice from students for students as a means of optimizing online student success.},
  keywords = {Education,EDUCATIONAL,technology,Vocational},
  annotation = {United States}
}

@phdthesis{spiethOptimizingOnlineStudent2009,
  title = {Optimizing Online Student Success: {{Strategies}} Utilized by Technical College Students},
  author = {Spieth, Margaret},
  year = {2009},
  abstract = {The majority of institutions of higher education consider online education to be an essential element of their long-term strategy, and online enrollments continue to grow, with almost 3.5 million students enrolled in at least one online course during the fall semester of 2006 (Sloan Consortium, 2007). Although increasing numbers of students are attracted by the flexibility of online courses, a disproportionate number are unsuccessful, with retention rates averaging 72\% for distance education courses, in comparison to 78\% for traditional courses (Instructional Technology Council, 2007). Techniques to optimize success have been shared with students to facilitate online student goal attainment, albeit these strategies have been developed by faculty and/or administration, rather than those with first-hand experience--successful online students; therefore, the purpose of this study was to draw on the experience of successful online students by answering the question, "What strategies do successful online students who have met their goals in the context of an online course utilize to optimize their success?" This descriptive research study was conducted in a technical college in Southeast Wisconsin, utilizing a three-phase data collection process. Following a preliminary focus group to establish construct validity, face validity, and content validity of a survey instrument designed to identify the dispositions of successful online students, an invitation to complete the electronic survey was extended to a census of online students at the college ( N = 1,300), with 436 students ( n = 436) completing the survey, for a 34\% response rate. The second phase of data collection consisted of interviews with a convenience sampling of participants ( n = 10). In the final phase of data collection, an invitation to complete a follow-up survey was extended to a random sampling of online students at the college ( n = 600), with a total of 137 students ( n = 137) completing the electronic survey, for a 23\% response rate. Results demonstrated successful online students utilize strategies in the areas of time management, communication, and motivation. A checklist tool of the top 10 strategies was created to share advice from students for students as a means of optimizing online student success.},
  keywords = {Education,EDUCATIONAL,technology,Vocational}
}

@article{spilkerValuingTechnologyenhancedAcademic2020,
  title = {Valuing Technology-Enhanced Academic Conferences for Continuing Professional Development. {{A}} Systematic Literature Review},
  author = {Spilker, Maria and Prinsen, Fleur and Kalz, Marco},
  year = {2020},
  journal = {Professional development in education},
  volume = {46},
  number = {3},
  pages = {482--499},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {1941-5257},
  doi = {10.1080/19415257.2019.1629614},
  abstract = {This review presents a systematic search for and analysis of the state of the art concerning research (1993-2018) on technology-enhanced conferences for academics' professional development. Fifty-nine scientific publications were included in the review which analyses them through the lens of the value creation framework. Conference formats are undergoing innovations focussed on amplifying social learning, and the role of technologies to enrich this new landscape is being explored. Initial results indicated that while new practices are emerging, a coherent perspective on technology-enhanced continuing professional development to help understand and inform the transition towards learning conferences was lacking across the literature. For instance, traditional evaluations of conferences, such as satisfaction surveys applied by the end of the conference, are not yet taking into account the full range of possible values created through participation in conferences. In addition, results about the use of social media for community building and enduring professional development remain inconclusive, and a more guided approach towards the application of social media at academic conferences is needed. The Value Creation Framework seems to be an appropriate conceptual framework for understanding the impact of conference attendance for the development of (digital) professional competences of academics.},
  keywords = {Academic conferences,College Faculty,Communities of Practice,Conferences (Gatherings),continuing professional development,Education & Educational Research,Educational Research,Influence of Technology,Innovation,Interaction,learning conferences,Participant Satisfaction,Participation,Professional Continuing Education,Research Needs,Social Media,Social Sciences,value creation framework,Value Judgment,Web 2.0 Technologies},
  file = {/Users/colin.madland/Zotero/storage/IVZ8TV44/spilkerValuingTechnologyenhancedAcademic2020.pdf}
}

@article{spiveyClassroomOnlineAssessment2014,
  title = {Classroom {{Versus Online Assessment}}},
  author = {Spivey, Michael F. and McMillan, Jeffrey J.},
  year = {2014},
  month = nov,
  journal = {Journal of Education for Business},
  volume = {89},
  number = {8},
  pages = {450--456},
  issn = {0883-2323, 1940-3356},
  doi = {10.1080/08832323.2014.937676},
  urldate = {2022-01-27},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/7AJ7RQRB/spiveyClassroomOnlineAssessment2014.pdf}
}

@inbook{spracklenIdentityMakingSocialMedia2015,
  title = {Identity-{{Making}} and {{Social Media}}},
  booktitle = {Digital {{Leisure}}, the {{Internet}} and {{Popular Culture}}},
  author = {Spracklen, Karl},
  year = {2015},
  pages = {94--112},
  publisher = {Palgrave Macmillan UK},
  address = {London},
  doi = {10.1057/9781137405876_6},
  urldate = {2021-12-23},
  collaborator = {Spracklen, Karl},
  isbn = {978-1-349-68077-1 978-1-137-40587-6},
  langid = {english}
}

@book{squireWhatNarrativeResearch2014,
  title = {What Is Narrative Research?},
  author = {Squire, Corinne and Davis, Mark and Esin, Cigdem and Andrews, Molly and Harrison, Barbara and Hyd{\'e}n, Lars-Christer and Hyd{\'e}n, Margareta},
  year = {2014},
  edition = {1},
  number = {Book, Whole},
  publisher = {Bloomsbury Academic},
  address = {London},
  doi = {10.5040/9781472545220},
  abstract = {Narrative research has become a catchword in the social sciences today, promising new fields of inquiry and creative solutions to persistent problems. This book brings together ideas about narrative from a variety of contexts across the social sciences and synthesizes understandings of the field. Rather than focusing on theory, it examines how narrative research is conducted and applied. It operates as a practical introductory guide, basic enough for first-time researchers, but also as a window onto the more complex questions and difficulties that all researchers in this area face. The authors guide readers through current debates about how to obtain and analyse narrative data, about the nature of narrative, the place of the researcher, the limits of researcher interpretations, and the significance of narrative work in applied and in broader political contexts.;This pioneering text will present cutting-edge readings of the social sciences through the lens of narrative research.;},
  isbn = {1472545222;1849669732;9781849669733;9781472545220;1780938535;9781780938530;},
  keywords = {Methodology,Narrative inquiry (Research method),Politics - Other,Politics & International Relations,Research,Social Research Methods,Social sciences,Sociology,Theory and Method - Anthropology}
}

@misc{srikanthTwitterAcknowledgesWay2020,
  type = {Text},
  title = {Twitter Acknowledges the Way It Presents Photos Is Racist},
  author = {Srikanth, Anagha},
  year = {2020},
  month = sep,
  journal = {TheHill},
  urldate = {2020-09-22},
  abstract = {The tech company has vowed to work on the problem.},
  howpublished = {https://thehill.com/changing-america/respect/diversity-inclusion/517442-twitter-acknowledges-the-way-it-presents-photos},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/ACZ9TQBK/517442-twitter-acknowledges-the-way-it-presents-photos.html}
}

@article{st-ongeCOVID19Tipping2022,
  ids = {st-ongeCOVID19Tipping2022a},
  title = {{{COVID}}-19 as the Tipping Point for Integrating E-assessment in Higher Education Practices},
  author = {St-Onge, Christina and Ouellet, Kathleen and Lakhal, Sawsen and Dub{\'e}, Tim and Marceau, M{\'e}lanie},
  year = {2022},
  journal = {British Journal of Educational Technology},
  volume = {53},
  number = {2},
  pages = {349--366},
  publisher = {Wiley},
  address = {HOBOKEN},
  issn = {0007-1013, 1467-8535},
  doi = {10.1111/bjet.13169},
  urldate = {2022-05-29},
  abstract = {The COVID-19 pandemic provoked an urgency for many educators to integrate digital information and communication technologies in their educational practices. We explored how faculty members tackled the task of adapting their assessment practices during the pandemic to identify what is required to sustain and favour future quality development and implementation of e-assessment in higher education. Employing a qualitative descriptive approach, we conducted semi-structured interviews with thirty-one individuals six months into the COVID-19 pandemic. We identified four major themes in participants' discourse about the integration of e-assessment during the COVID-19 pandemic: (a) the considerations they had for the potential consequences on students and how they considered this while deciding how to move forward, (b) the preoccupations for the potential for cheating, (c) the importance of pedagogical alignment, and (d) the affordances available to them. While the COVID-19 pandemic highlighted the fact that higher education institutions were not prepared for a pivot to- or greater integration of- e-assessment, it also provided the tipping-point to do so. In other words, it offered an unprecedented opportunity to critically appraise and change assessment practices, this opportunity was also a very challenging balancing act of considering the social consequences of assessment, and the alignment within set affordances.},
  langid = {english},
  keywords = {Alignment,Analysis,Anxiety,assessment,Communication,Communications technology,COVID-19,Education & Educational Research,Education Higher,Education parks,Educational evaluation,Epidemics,Higher education,Higher education institutions,interview,Pandemics,Professional practice,School facilities,Social Sciences,Students,Technology assessment,Workload,Workloads},
  file = {/Users/colin.madland/Zotero/storage/AGANPZ8S/st-ongeCOVID19Tipping2022.pdf}
}

@article{st-ongeCOVID19TippingPoint2022,
  title = {{{COVID-19}} as the Tipping Point for Integrating e-Assessment in Higher Education Practices},
  author = {{St-Onge}, Christina and Ouellet, Kathleen and Lakhal, Sawsen and Dub{\'e}, Tim and Marceau, M{\'e}lanie},
  year = {2022},
  journal = {British Journal of Educational Technology},
  volume = {53},
  number = {2},
  pages = {349--366},
  publisher = {Wiley Online Library},
  doi = {10.1111/bjet.13169},
  file = {/Users/colin.madland/Zotero/storage/W57MAM9Y/st-ongeCOVID19TippingPoint2022.pdf;/Users/colin.madland/Zotero/storage/9827RL8V/bjet.html}
}

@article{stabileClarifyingDifferencesTraining2013,
  title = {Clarifying the {{Differences}} between {{Training}}, {{Development}}, and {{Enrichment}}: {{The Role}} of {{Institutional Belief Constructs}} in {{Creating}} the {{Purpose}} of {{Faculty Learning Initiatives}}},
  author = {Stabile, Christopher and Ritchie, William F.},
  year = {2013},
  journal = {New Directions for Teaching and Learning},
  volume = {2013},
  number = {133},
  pages = {71--84}
}

@book{staceyCollaborativeLearningOnline2012,
  title = {Collaborative {{Learning}} in an {{Online Environment}}},
  author = {Stacey, Elizabeth},
  year = {April 8, 2012 1999},
  volume = {14},
  publisher = {AU Press}
}

@article{stackInvestigatingOnlineTests2020,
  title = {Investigating Online Tests Practices of University Staff Using Data from a Learning Management System : {{The}} Case of a Business School},
  author = {Stack, Anna and Boitshwarelo, Bopelo and Reedy, Alison and Billany, Trevor and Reedy, Hannah and Sharma, Rajeev and Vemuri, Jyoti},
  year = {2020},
  journal = {Australasian Journal of Educational Technology},
  volume = {36},
  number = {4},
  pages = {72--81},
  publisher = {Australasian Soc Computers Learning Tertiary Education-Ascilite},
  address = {TUGUN},
  issn = {1449-5554},
  doi = {10.14742/ajet.4975},
  abstract = {While research on online tests in higher education is steadily growing, there is little evidence in the literature of the use of learning management systems (LMS), such as Blackboard(TM), as rich sources of data on online tests practices. This paper reports on an investigation that used data from Blackboard(TM) LMS to gain insight into the purpose for and practice of online tests at the Charles Darwin University (CDU) Business School in Australia. Focussing on curriculum and pedagogical practices, the paper identifies indications of good practice as well as potential issues related to curriculum mapping, including possible misalignment between learning outcomes and online tests. It also affirms the versatility of using data from LMSs in the study of e-assessment in general and online tests in particular. [Author abstract]},
  keywords = {Blackboard (Learning management system),Education & Educational Research,Feedback,Higher education,Learning management systems,Online assessment,Online learning,Online teaching,Social Sciences,Student assessment,Web based courses},
  file = {/Users/colin.madland/Zotero/storage/HX6UNHZH/stackInvestigatingOnlineTests2020.pdf}
}

@article{stadlerFirstEqualsLog2020,
  title = {First among Equals: {{Log}} Data Indicates Ability Differences despite Equal Scores},
  shorttitle = {First among Equals},
  author = {Stadler, Matthias and Hofer, Sarah and Greiff, Samuel},
  year = {2020},
  month = oct,
  journal = {Computers in Human Behavior},
  volume = {111},
  pages = {106442},
  issn = {07475632},
  doi = {10.1016/j.chb.2020.106442},
  urldate = {2022-03-23},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/3YRWQH4Y/stadlerFirstEqualsLog2020.pdf}
}

@article{staggOERAdoptionContinuum2014,
  title = {{{OER}} Adoption : A Continuum for Practice},
  author = {Stagg, Adrian},
  year = {2014},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {11},
  number = {3},
  pages = {151--164},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {1698-580X},
  doi = {10.7238/rusc.v11i3.2102},
  abstract = {Whilst Open Educational Resources (OER) offer opportunities for broadening participation in higher education, reducing course development and study costs, and building open collaborative partnerships to improve teaching and learning practices, they have yet to gain significant mainstream traction. Research surrounding open education has focused on adoption at the institutional level, identifying key enablers and barriers to practice, but the practicalities of engagement with open resources are not often addressed. By reviewing existing literature, and studying prior models used to explain OER (re)use, this article proposes a continuum of use model. The proposed model seeks to acknowledge the complexity of applied knowledge required to fulsomely engage with open education by examining practitioner behaviours and the necessary supporting mechanisms. This conceptual model aims to be of use to both practitioners and also those responsible for designing professional development in an educational setting. Whilst the proposed model is designed for teaching staff use, some discussion is given as to how it could be applied to student learning using open resources as well. [Author abstract]},
  keywords = {Academic staff development,Access to information,College faculty,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Educational resources,Educational Technology,Higher Education,Humanities,Information Systems Applications (incl.Internet),Instructional design,Law,Learning,Literature reviews,Open access publishing,Open learning,Pedagogy,Postsecondary education,Special Section: Open Educational Resources Initiatives in Oceania,Statistics for Social Sciences,Teaching process,University teaching},
  file = {/Users/colin.madland/Zotero/storage/HUU847GM/staggOERAdoptionContinuum2014.pdf}
}

@article{staggOpenEducationalPractices2018,
  title = {Open {{Educational Practices}} in {{Australia}}: {{A First-phase National Audit}} of {{Higher Education}}},
  shorttitle = {Open {{Educational Practices}} in {{Australia}}},
  author = {Stagg, Adrian and Nguyen, Linh and Bossu, Carina and Partridge, Helen and Funk, Johanna and Judith, Kate},
  year = {2018},
  month = jul,
  journal = {The International Review of Research in Open and Distributed Learning},
  volume = {19},
  number = {3},
  issn = {1492-3831},
  doi = {10.19173/irrodl.v19i3.3441},
  urldate = {2019-02-13},
  file = {/Users/colin.madland/Zotero/storage/RRE6CCFR/staggOpenEducationalPractices2018.pdf}
}

@article{Stagnaro-Green_2006,
  title = {Use of Flawed Multiple Choice Items by the New England Journal of Medicine for Continuing Medical Education},
  author = {{Stagnaro-Green}, Alex and Downing, Steven M.},
  year = {2006},
  journal = {Medical Teacher},
  doi = {10/fp8x73},
  abstract = {Physicians in the United States are required to complete a minimum number of continuing medical education (CME) credits annually. The goal of CME is to ensure that physicians maintain their knowledge and skills throughout their medical career. The New England Journal of Medicine (NEJM) provides its readers with the opportunity to obtain weekly CME credits. Deviation from established item-writing principles may result in a decrease in validity evidence for tests. This study evaluated the quality of 40 NEJM MCQs using the standard evidence-based principles of effective item writing. Each multiple-choice item reviewed had at least three item flaws, with a mean of 5.1 and a range of 3 to 7. The results of this study demonstrate that the NEJM uses flawed MCQs in its weekly CME program.},
  mag_id = {2005430709},
  pmcid = {null},
  pmid = {17074708}
}

@book{stakeArtCaseStudy1995,
  title = {The {{Art}} of {{Case Study Research}}},
  author = {Stake, Robert E},
  year = {1995},
  publisher = {Sage},
  address = {Thousand Oaks, CA}
}

@techreport{stakerRise12Blended2011,
  title = {The {{Rise}} of {{K}}--12 {{Blended Learning}}},
  author = {Staker, Heather},
  year = {2011},
  pages = {184},
  institution = {Innosight Institute},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/85CAS97W/stakerRise12Blended2011.pdf}
}

@techreport{stakerRiseK12Blended2011,
  title = {The {{Rise}} of {{K-12 Blended Learning}}: {{Profiles}} of {{Emerging Models}}},
  author = {Staker, Heather and {Innosight Institute}},
  year = {2011},
  month = may,
  journal = {Innosight Institute},
  institution = {Innosight Institute},
  abstract = {Some innovations change everything. The rise of personal computers in the 1970s decimated the mini-computer industry. TurboTax forever changed tax accounting, and MP3s made libraries of compact discs obsolete. These innovations bear the traits of what Harvard Business School Professor Clayton M. Christensen terms a "disruptive innovation." Disruptive innovations fundamentally transform a sector by replacing expensive, complicated, and inaccessible products or services with much less expensive, simpler, and more convenient alternatives. Online learning appears to be a classic disruptive innovation with the potential not just to improve the current model of education delivery, but to transform it. Educators and entrepreneurs are increasingly creating blended-learning environments--where rather than doing online learning at a distance, students learn in an adult-supervised school environment for at least part of the time. This paper profiles 40 organizations that have blended or have plans to blend online learning with brick-and-mortar classrooms. These represent a range of operators, including state virtual schools, charter management organizations, individual charter schools, independent schools, districts, and private entities. The organizations profiled in this paper are not a "top 40" list. Thousands of other schools are currently participating in blended learning and may have superior programs. Furthermore, this report does not provide a comprehensive market analysis, but rather a survey that offers a more intimate look at a small sample, with the intention to identify emerging models. Appended are: (1) List of programs by model; (2) Technology wish list; and (3) Policy wish list. (Contains 12 figures.)},
  keywords = {Blended Learning,Check Lists,Definitions,Delivery Systems,Educational Development,Educational Practices,Educational Technology,Educational Trends,Influence of Technology,Institutional Characteristics,Models,Profiles,Technological Advancement,Technology Integration,Technology Uses in Education}
}

@article{stanford-bowersPersistenceOnlineClasses2008,
  title = {Persistence in Online Classes: {{A}} Study of Perceptions among Community College Stakeholders},
  author = {{Stanford-Bowers}, Denise E},
  year = {2008},
  journal = {Journal of Online Teaching and Learning},
  volume = {4},
  number = {1},
  pages = {14},
  abstract = {Because online learning presents unique challenges for not only learners but faculty and administrators as well, those involved in these cyberenvironments must think beyond the boundaries of the traditional classroom. This study examined the perceptions of online persistence factors, those characteristics which influence student retention, as seen by the three major stakeholders in community college distance education programs: administrators, faculty, and students. The purpose of the study was to determine which factors are most important among the three groups and where those perceptions converge since lack of convergence could be a factor resulting in high attrition rates of some online courses. While the results of this study indicated that the perceptions of administrators and faculty are more closely aligned than either is with the students' perceptions, they also show a recognition among all groups of stakeholders of online learning as an evolving phenomenon which requires attention to even the most minute details which are sometimes overlooked, not emphasized, or taken for granted. This recognition indicates a necessary paradigm shift, which will lead to improvements in online learning policy, design, and pedagogy, is in the making.},
  keywords = {adult learners,attrition,Online learning,online learning communities,retention}
}

@article{stanger-hallMultipleChoiceExamsObstacle2012,
  title = {Multiple-{{Choice Exams}}: {{An Obstacle}} for {{Higher-Level Thinking}} in {{Introductory Science Classes}}},
  shorttitle = {Multiple-{{Choice Exams}}: {{An Obstacle}} for {{Higher-Level Thinking}} in {{Introductory Science Classes}}},
  author = {{Stanger-Hall}, Kathrin F.},
  year = {2012},
  month = sep,
  journal = {CBE-Life Sciences Education},
  volume = {11},
  pages = {294--306},
  doi = {10.1187/cbe.11-11-0100},
  abstract = {Learning science requires higher-level (critical) thinking skills that need to be practiced in science classes. This study tested the effect of exam format on critical-thinking skills. Multiple-choice (MC) testing is common in introductory science courses, and students in these classes tend to associate memorization with MC questions and may not see the need to modify their study strategies for critical thinking, because the MC exam format has not changed. To test the effect of exam format, I used two sections of an introductory biology class. One section was assessed with exams in the traditional MC format, the other section was assessed with both MC and constructed-response (CR) questions. The mixed exam format was correlated with significantly more cognitively active study behaviors and a significantly better performance on the cumulative final exam (after accounting for grade point average and gender). There was also less gender-bias in the CR answers. This suggests that the MC-only exam format indeed hinders critical thinking in introductory science classes. Introducing CR questions encouraged students to learn more and to be better critical thinkers and reduced gender bias. However, student resistance increased as students adjusted their perceptions of their own critical-thinking abilities.},
  annotation = {3}
}

@article{stanleyStudentProducedVideosCan2018,
  title = {Student-{{Produced Videos Can Enhance Engagement}} and {{Learning}} in the {{Online Environment}}},
  author = {Stanley, Denise and Zhang, Yi},
  year = {2018},
  journal = {Online Learning},
  volume = {22},
  number = {2},
  pages = {5--26},
  issn = {ISSN-2472-5749},
  abstract = {Student engagement in online learning remains a challenge for the design of effective coursework. Additionally, few analyses have focused on student-produced activities in the online mode or upon how such class activity affects student subgroups differently. We conducted a randomized design experiment with student video production at a large public university. Student background and behavior factors were measured in two online surveys, which were combined with course assessment data. Because of the small sample size, we observed few significant differences in learning outcomes across the experimental treatment and control sections, except with regard to a value-added measure. We suggest that student learning was likely most concentrated on concepts around which students produced the videos. And when students were divided by incoming language proficiency, non-native English speakers had higher perceived learning; but when grouped by incoming GPA, those with higher previous grades actually achieved higher test scores and pass rates.},
  langid = {english},
  keywords = {College Students,Cooperative Learning,Educational Attainment,Educational Technology,English Language Learners,Gender Differences,Grade Point Average,Grants,Language Proficiency,Likert Scales,Mixed Methods Research,Mothers,No DOI found,Online Courses,Parent Background,Peer Teaching,Pretests Posttests,Randomized Controlled Trials,Readiness,Scores,Student Attitudes,Student Behavior,Student Characteristics,Student Surveys,Technological Literacy,Technology Uses in Education,Tests,Video Technology}
}

@article{stanleyStudentProducedVideosCan2018b,
  title = {Student-{{Produced Videos Can Enhance Engagement}} and {{Learning}} in the {{Online Environment}}},
  author = {Stanley, Denise and Zhang, Yi},
  year = {2018},
  month = jun,
  journal = {Online Learning},
  volume = {22},
  number = {2},
  pages = {5--26},
  publisher = {Online Learning},
  issn = {2472-5749},
  abstract = {Student engagement in online learning remains a challenge for the design of effective coursework. Additionally, few analyses have focused on student-produced activities in the online mode or upon how such class activity affects student subgroups differently. We conducted a randomized design experiment with student video production at a large public university. Student background and behavior factors were measured in two online surveys, which were combined with course assessment data. Because of the small sample size, we observed few significant differences in learning outcomes across the experimental treatment and control sections, except with regard to a value-added measure. We suggest that student learning was likely most concentrated on concepts around which students produced the videos. And when students were divided by incoming language proficiency, non-native English speakers had higher perceived learning; but when grouped by incoming GPA, those with higher previous grades actually achieved higher test scores and pass rates.},
  keywords = {College Students,Cooperative Learning,Educational Attainment,Educational Technology,English Language Learners,Gender Differences,Grade Point Average,Grants,Language Proficiency,Likert Scales,Mixed Methods Research,Mothers,No DOI found,Online Courses,Parent Background,Peer Teaching,Pretests Posttests,Randomized Controlled Trials,Readiness,Scores,Student Attitudes,Student Behavior,Student Characteristics,Student Surveys,Technological Literacy,Technology Uses in Education,Tests,Video Technology}
}

@article{starchReliabilityDistributionGrades1913,
  title = {Reliability and {{Distribution}} of {{Grades}}},
  author = {Starch, Daniel},
  year = {1913},
  journal = {Science},
  volume = {38},
  number = {983},
  pages = {630--636},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.38.983.630},
  urldate = {2024-03-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/starchReliabilityDistributionGrades1913.pdf}
}

@article{starchReliabilityGradingHighSchool1912,
  title = {Reliability of the {{Grading}} of {{High-School Work}} in {{English}}},
  author = {Starch, Daniel and Elliott, Edward C.},
  year = {1912},
  month = sep,
  journal = {The School Review},
  volume = {20},
  number = {7},
  pages = {442--457},
  issn = {0036-6773},
  doi = {10.1086/435971},
  urldate = {2024-03-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/ARYXEKYA/starchReliabilityGradingHighSchool1912.pdf}
}

@article{starchReliabilityGradingWork1913,
  title = {Reliability of {{Grading Work}} in {{Mathematics}}},
  author = {Starch, Daniel and Elliott, Edward C.},
  year = {1913},
  journal = {The School Review},
  volume = {21},
  number = {4},
  pages = {254--259},
  issn = {0036-6773},
  doi = {10.1086/436086},
  urldate = {2024-03-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/starchReliabilityGradingWork1913a.pdf}
}

@article{starchReliabilityGradingWork1913a,
  title = {Reliability of {{Grading Work}} in {{History}}},
  author = {Starch, Daniel and Elliott, Edward C.},
  year = {1913},
  journal = {The School Review},
  volume = {21},
  number = {10},
  pages = {676--681},
  issn = {0036-6773},
  doi = {10.1086/436185},
  urldate = {2024-03-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/starchReliabilityGradingWork1913.pdf}
}

@article{stathopoulouMultistakeholderViewSocial2019,
  title = {A Multi-Stakeholder View of Social Media as a Supporting Tool in Higher Education: {{An}} Educator--Student Perspective},
  author = {Stathopoulou, Anastasia and Siamagka, Nikoletta-Theofania and Christodoulides, George},
  year = {2019},
  journal = {European management journal},
  volume = {37},
  number = {4},
  pages = {421--431},
  publisher = {Elsevier Ltd},
  address = {OXFORD},
  issn = {0263-2373},
  doi = {10.1016/j.emj.2019.01.008},
  abstract = {Social media in higher education is becoming increasingly important both in courses' delivery and assessment. This research explores the adoption of social media as a supporting tool in undergraduate (UG) education using both educators' and students' perspectives. The first study involves a survey of 205 educators who reported their views on the importance and use of social media within their management courses. The second study consists of four focus groups, which provides insights into students' perspectives and attitudes toward the use of social media by their educators in higher education. Results show that both educators and students acknowledge the importance of incorporating social media in delivery and assessment of courses and highlight its positive impact on students' deep learning experience and engagement, as well as their enhancement of collaborative and organizational skills. However, faculty is advised to keep a balance in terms of relevance of social media use, control, and usage level of social media platforms.},
  keywords = {Assessment,Attitudes,Business,Business & Economics,Business schools,College students,College teachers,Delivery,Education,Faculty,Higher education,Learning,Management,Social media,Social networks,Social Sciences,Student attitudes,Students,Technology adoption}
}

@misc{statisticscanadaDataTables20162017,
  title = {Data Tables, 2016 {{Census}}},
  author = {Statistics Canada},
  year = {2017},
  month = nov,
  journal = {Statistics Canada},
  urldate = {2019-02-14},
  abstract = {This table presents Aboriginal identity, major field of study - Classification of Instructional Programs (CIP) 2016, highest certificate, diploma or degree, Registered or Treaty Indian status, residence by Aboriginal geography, age and sex for the population aged 25-64 years in private households of Canada, provinces and territories.},
  howpublished = {https://www12.statcan.gc.ca/census-recensement/2016/dp-pd/dt-td/Rp-eng.cfm?TABID=1\&LANG=E\&A=R\&APATH=3\&DETAIL=0\&DIM=0\&FL=A\&FREE=0\&GC=59\&GL=-1\&GID=1334863\&GK=1\&GRP=1\&O=D\&PID=110665\&PRID=10\&PTYPE=109445\&S=0\&SHOWALL=0\&SUB=0\&Temporal=2017\&THEME=123\&VID=0\&VNAMEE=\&VNAMEF=\&D1=0\&D2=0\&D3=0\&D4=2\&D5=0\&D6=0},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/G54Z9KQB/Rp-eng.html}
}

@article{staubStandardsAssessmentEnglish2019,
  title = {Standards {{Assessment}} in {{English Language Teacher Education}}},
  author = {Staub, Donald and Kirkg{\"o}z, Yasemin},
  year = {2019},
  journal = {Novitas-ROYAL (Research on Youth and Language)},
  volume = {13},
  number = {1},
  pages = {47--61},
  issn = {EISSN-1307-4733},
  abstract = {Instructional quality among English as a foreign language (EFL) teachers requires the identification and assessment of professional standards for the field. Although Quality Assurance, Outcomes Assessment and Accreditation may be understood within language teacher education programs, successful and sustained implementation of quality improvement processes largely remain elusive. This paper explores standards assessment in EFL teacher preparation programs in Turkey. Primary issues examined were: 1) awareness of instructors in EFL teacher preparation programs of standards assessment; 2) the degree to which the standards are assessed; and, 3) the degree to which assessment data is analyzed and acted upon. This study utilized the Instrumental Case Study combined with a mixed-method approach. Data was collected via survey and interviews. An internet-based survey was distributed to teacher preparation faculty members across Turkey. One-on-one structured interviews were conducted with instructors from EFL teacher preparation programs at public and private universities. Results indicate that despite relatively high levels of awareness among university faculty members and the standards established by the Turkish Higher Education Council, there is little evidence to suggest that assessment data is collected or acted upon.},
  langid = {english},
  keywords = {Case Studies,College Faculty,Educational Improvement,Educational Quality,English (Second Language),Foreign Countries,Knowledge Level,Language Teachers,No DOI found,Private Colleges,Quality Assurance,Second Language Instruction,Second Language Learning,Standards,State Universities,Teacher Attitudes,Teacher Education Programs,Teacher Educators}
}

@article{steeleDefiningEffectiveOnline2019,
  title = {Defining {{Effective Online Pedagogy}}},
  author = {Steele, John and Holbeck, Rick and Mandernach, Jean},
  year = {2019},
  journal = {Journal of Instructional Research},
  volume = {8},
  number = {2},
  pages = {5--8},
  issn = {ISSN-2159-0281},
  doi = {10/gmbvz2},
  abstract = {More than 5.8 million students are currently enrolled in online courses; this equates to one in four higher education students taking an online course (OLC, 2016). With so many students enrolled in online education, it is imperative that institutions examine factors that lead to their success. This article summary provides a structure to think about instructional strategies, best practices, and online pedagogy as it applies to teaching. The authors offer a brief discussion of key contextual factors that may influence the generalizability of the online teaching suggestions provided throughout this special issue. In addition, the authors offer reflective questions to guide application of the instructional approaches discussed.},
  langid = {english},
  keywords = {Best Practices,Educational Technology,Electronic Learning,Higher Education,Instruction,Online Courses,Teaching Methods,Technology Uses in Education}
}

@article{steelUseEexamsHigh2019,
  title = {Use of {{E-exams}} in {{High Stakes Law School Examinations}}: {{Student}} and {{Staff Reactions}}},
  shorttitle = {Use of {{E-exams}} in {{High Stakes Law School Examinations}}},
  author = {Steel, Alex and Moses, Lyria Bennett and Laurens, Julian and Brady, Charlotte},
  year = {2019},
  month = jun,
  journal = {Legal Education Review},
  volume = {29},
  number = {1},
  issn = {1033-2839},
  doi = {10.53300/001c.9461},
  urldate = {2022-10-31},
  abstract = {Australian law schools have just begun to move towards e-exams. There are a number of drivers encouraging Australian universities to introduce e-exams, including economic pressures, a desire to reduce administrative burdens, and changes to workplaces. Logistically, e-exams may assist with paper distribution, script legibility and shorter marking times.             Pedagogical arguments in favour of e-exams rely on the fact that students already use technology daily and complete the bulk of their university work on computers. In this context, handwriting an exam has been described as an `anachronism'. More specifically, traditional handwriting of examinations in contemporary contexts is seen as a `misalignment of assessment practice to the learning environment'. Such misalignment can result in diminished learning outcomes.             However, there is little literature addressing the adoption of e-exams for formal high stakes summative exams. Much of the research to date has focused on small scale, informal low stakes tests in non-law disciplines. Within Australia, whether e-exams are appropriate or effective has been the subject of a number of reported trials, but none have specifically reported on law students. In 2016 UNSW Law sought to rectify this and undertook such a trial.             This article provides empirical insight into the process and student perceptions for a high stakes summative e-exam. It analyses students' attitudes and concerns prior to the introduction of the e-exam platform, as well as after they had completed the exam. We also provide insights into the important procedural aspects associated with high stakes exams and staff responses to the process, issues not previously reported on.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/RTPCEME6/steelUseEexamsHigh2019.pdf}
}

@article{stefaniPeerSelfTutor1994,
  title = {Peer, Self and Tutor Assessment: {{Relative}} Reliabilities},
  shorttitle = {Peer, Self and Tutor Assessment},
  author = {Stefani, Lorraine A.J.},
  year = {1994},
  month = jan,
  journal = {Studies in Higher Education},
  volume = {19},
  number = {1},
  pages = {69--75},
  issn = {0307-5079, 1470-174X},
  doi = {10/fhb7p6},
  urldate = {2020-11-01},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/LSSWQBLL/stefaniPeerSelfTutor1994.pdf}
}

@article{steinStructuralEquationModeling2017,
  title = {Structural {{Equation Modeling}}.},
  author = {Stein, C. and Morris, N. and Hall, N. B. and Nock, N.},
  year = {2017},
  month = jan,
  journal = {Methods in molecular biology},
  doi = {10.1007/978-1-4939-7274-6_28}
}

@article{stenaltResearchingStudentAgency2021,
  title = {Researching Student Agency in Digital Education as If the Social Aspects Matter: Students' Experience of Participatory Dimensions of Online Peer Assessment},
  author = {Stenalt, Maria Hvid},
  year = {2021},
  journal = {Assessment and evaluation in higher education},
  volume = {46},
  number = {4},
  pages = {644--658},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0260-2938},
  doi = {10.1080/02602938.2020.1798355},
  abstract = {This paper focuses on the relationship between social aspects and individual agency in digital education, analysed in the context of online peer assessment in a first-semester course. Applying the adapted participation gestalt framework to identify how a particular form of participation emerges, and how it is constituted, individual interviews and focus group meetings with 13 Danish students were carried out. The analysis highlights a number of signs accumulated by students to construct their participation in the interaction. These signs argue against simplistic accounts of student agency in educational research, whereby student agency is approached as an individual and cognitive phenomenon and relationships as stable and unproblematic. The paper argues that student agency should not automatically be assumed possible as part of digital education or digital student-centred learning activities. Instead, the social aspects of educational interactions need to be taken into consideration when presenting digital education as a means to enhance student agency.},
  keywords = {College Students,Computer Mediated Communication,Danish,digital education,Education,Education & Educational Research,Educational activities,Educational Research,Electronic Learning,Foreign Countries,gestalt,higher education,Participation,peer assessment,Peer Evaluation,Peer Relationship,Personal Autonomy,Social Sciences,Student agency,Student Experience,Student Participation}
}

@phdthesis{stephenUsingAutomatedEssay2019,
  title = {Using {{Automated Essay Scoring}} to {{Assess Higher-Level Thinking Skills}} in {{Nursing Education}}},
  author = {Stephen, Tracey C.},
  year = {2019},
  urldate = {2021-05-21},
  school = {University of Alberta Libraries},
  file = {/Users/colin.madland/Zotero/storage/73BH3WUU/stephenUsingAutomatedEssay2019.pdf}
}

@inproceedings{stevensonUniversityGovernanceAutonomy,
  title = {University {{Governance}} and {{Autonomy Problems}} in {{Managing Access}}, {{Quality}} and {{Accountability}}},
  booktitle = {{{ADB Conference}} on {{University Governance}}},
  author = {Stevenson, Michael}
}

@article{stevensSeeingInfrastructureRace2021,
  title = {Seeing Infrastructure: Race, Facial Recognition and the Politics of Data},
  shorttitle = {Seeing Infrastructure},
  author = {Stevens, Nikki and Keyes, Os},
  year = {2021},
  month = sep,
  journal = {Cultural Studies},
  volume = {35},
  number = {4-5},
  pages = {833--853},
  issn = {0950-2386, 1466-4348},
  doi = {10.1080/09502386.2021.1895252},
  urldate = {2022-03-20},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/33PZU3ZD/stevensSeeingInfrastructureRace2021.pdf}
}

@article{stigginsAssessmentCrisisAbsence2002,
  title = {Assessment {{Crisis}}: {{The Absence}} of {{Assessment}} for {{Learning}}},
  author = {Stiggins, Richard J.},
  year = {2002},
  month = jun,
  journal = {Phi Delta Kappan},
  volume = {83},
  number = {10},
  pages = {758--765},
  publisher = {SAGE Publications Inc},
  issn = {0031-7217},
  doi = {10/gk5bkb},
  urldate = {2021-07-08},
  file = {/Users/colin.madland/Zotero/storage/T8G6KHMP/stigginsAssessmentCrisisAbsence2002.pdf}
}

@article{stigginsAssessmentLiteracy1991,
  ids = {stigginsAssessmentLiteracy1991a},
  title = {Assessment {{Literacy}}},
  author = {Stiggins, Richard J.},
  year = {1991},
  journal = {The Phi Delta Kappan},
  volume = {72},
  number = {7},
  pages = {534--539},
  publisher = {Phi Delta Kappa International},
  issn = {00317217},
  urldate = {2021-07-08},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/H6N3MJMY/stigginsAssessmentLiteracy1991.pdf}
}

@article{stigginsAssessmentLiteracy21st1995,
  title = {Assessment {{Literacy}} for the 21st {{Century}}},
  author = {Stiggins, Richard J.},
  year = {1995},
  journal = {The Phi Delta Kappan},
  volume = {77},
  number = {3},
  pages = {238--245},
  publisher = {Phi Delta Kappa International},
  issn = {00317217},
  urldate = {2021-07-09},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/N3IF3LPY/stigginsAssessmentLiteracy21st1995.pdf}
}

@article{stodbergResearchReviewEassessment2012,
  title = {A Research Review of E-Assessment},
  author = {St{\"o}dberg, Ulf},
  year = {2012},
  journal = {Assessment \& evaluation in higher education},
  volume = {37},
  number = {5},
  pages = {591--604},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0260-2938},
  doi = {10.1080/02602938.2011.557496},
  abstract = {The use of e-assessment in higher education is a relatively new educational practice that has been more frequently studied in recent years. This review aims to summarise some research on e-assessment, providing an overview based on articles from three well-established scientific journals. Focusing on research topics, settings for e-assessment and research methods used in the articles, the review reveals a research field with a broad spectrum of inquiries and approaches. Research of e-assessment practices is often conducted as small-scale studies in which the e-assessment task comprises closed questions such as multiple-choice questions. The article discusses the findings to guide future research and concludes that there is a need for more studies on e-assessment in online courses as well as for longitudinal studies.},
  keywords = {Cognitive Ability,Computer Assisted Testing,Curricula,e-assessment,e-learning,Education,Education & Educational Research,Educational Environment,Educational evaluation,Educational Practices,Educational Sciences,Educational Technology,Evaluation,Evaluation Methods,Formative Evaluation,higher education,Higher Education,information and communication technologies,Interviews,Journals (Academic),Literature Reviews,Longitudinal Studies,Methods,Observation,Online Courses,Online instruction,Pedagogik,Pedagogy,Periodicals,Portfolio Assessment,Program Effectiveness,Program Implementation,Qualitative Research,Questionnaires,Research Methodology,research review,Samhallsvetenskap,Social Sciences,Socialvetenskap,Statistical Analysis,Summative Evaluation,Test Reliability,Utbildningsvetenskap},
  file = {/Users/colin.madland/Zotero/storage/NUH54QYR/stodbergResearchReviewEassessment2012.pdf}
}

@incollection{stoeszAcademicIntegrityEthical2020,
  title = {Academic {{Integrity Through Ethical Teaching}} and {{Assessment}}: {{Overview}} and {{Current Trends}}},
  booktitle = {Handbook of {{Academic Integrity}}},
  author = {Stoesz, Brenda M.},
  editor = {Eaton, Sarah Elaine},
  year = {2020},
  pages = {1--14},
  publisher = {Springer Nature Singapore},
  address = {Singapore},
  doi = {10.1007/978-981-287-079-7_89-1},
  abstract = {``Teaching is an ethical undertaking,'' and those who identify as ethical educators believe and act in the best interest of their students; and it stands to reason that the activities of ethical teaching must include those that promote academic integrity and support deep learning. This section of the Handbook of Academic Integrity, 2nd Edition, aims to describe how academic integrity can be promoted through ethical teaching and assessment. The authors outlined various approaches (e.g., authentic assessment, experiential learning, program-level course design, and accommodation) and practices (e.g., duplicate and salami publication) that demonstrate ethical professional practices within higher education. This overview chapter links the authors' chapters to the existing literature describing ethical care and principles of ethical teaching and assessment. An identification of the gaps in the literature about ethical teaching and assessment in higher education, directions for future research, and considerations for changes in approaches to fostering cultures of integrity close the chapter.},
  isbn = {978-981-287-079-7},
  file = {/Users/colin.madland/Zotero/storage/stoeszAcademicIntegrityEthical2020.pdf}
}

@incollection{stoeszAcademicIntegrityEthical2024,
  title = {Academic {{Integrity Through Ethical Teaching}} and {{Assessment}}: {{Overview}} and {{Current Trends}}},
  shorttitle = {Academic {{Integrity Through Ethical Teaching}} and {{Assessment}}},
  booktitle = {Second {{Handbook}} of {{Academic Integrity}}},
  author = {Stoesz, Brenda M.},
  editor = {Eaton, Sarah Elaine},
  year = {2024},
  pages = {203--216},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-54144-5_89},
  urldate = {2024-10-24},
  isbn = {978-3-031-54143-8 978-3-031-54144-5},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/stoeszAcademicIntegrityEthical2024.pdf}
}

@misc{stommelEthicalOnlineLearning2018,
  type = {Education},
  title = {Ethical {{Online Learning}}},
  author = {Stommel, Jesse},
  year = {2018},
  urldate = {2018-06-28},
  abstract = {The first mistake~of many online programs is that they try to replicate something we do in face-to-face classes, mapping the (sometimes pedagogically-sound, sometimes bizarre) traditions of on-ground institutions onto digital space.  We need to recognize that online learning uses a different platform, builds community in different ways, demands different pedagogies, has a different economy, functions at different scales, and requires different choices regarding curriculum than does on-ground education. Even where the same goal is desired, very different methods must be used to reach that goal.},
  copyright = {License: CC Attribution-NonCommercial License},
  keywords = {turnitin}
}

@misc{stommelPlagiarismExistsNever2018,
  type = {Tweet},
  title = {Plagiarism Exists. {{I}}'d Never Begrudge Individual Teachers for Their Frustrations at This. {{The}} Work of Teaching Is Hard. {{But}} Why Do Entire Institutions Adopt and Require the Use of Tools like {{Turnitin}} That Assume from the Start That Students Are Dishonest, Plagiarists, Cheaters?},
  author = {Stommel, Jesse},
  year = {2018},
  month = jun,
  journal = {@Jessifer},
  urldate = {2018-06-28},
  langid = {english},
  keywords = {turnitin},
  file = {/Users/colin.madland/Zotero/storage/VHVK9SBT/1010442757788323840.html}
}

@misc{stommelTurnitinHelpsCreate2018,
  type = {Tweet},
  title = {Turnitin Helps Create and Feed a Culture of Suspicion around Students and Their Work. {{The}} Company Is Invested in Manufacturing a Problem They Can Solve. {{They}} Also Monetize a Database of Student Work, and Those Students Are Not Compensated and Have Little to No Ability to Consent.{{https://twitter.com/maha9313/status/1009701001832607744}}~{\dots}},
  author = {Stommel, Jesse},
  year = {2018},
  month = jun,
  journal = {@jessifer},
  urldate = {2018-06-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/4DMTN5AV/1009737552117616640.html}
}

@article{storkPrepareSuccessDesigning2022,
  title = {Prepare for {{Success}}: {{Designing}} a {{Digital Badge Program}} with a {{School-University Partnership}}},
  author = {Stork, {\relax MG} and Turcotte, N and Rizzuto, M and Wang, {\relax CX} and Meehan, {\relax MR}},
  year = {2022},
  journal = {Journal of Formative Design in Learning},
  volume = {6},
  number = {1},
  pages = {40--52},
  issn = {2509-8039},
  doi = {10.1007/s41686-022-00065-1},
  abstract = {In higher education, digital badging programs can supplement a student's degree by helping them connect their experiences on-campus to those outside of the classroom, encouraging them to think and apply the knowledge they gain from their college or university to real-world situations. This article discusses the perceptions of participants in a pilot digital badge program to identify important milestones, collaborative efforts, and barriers believed to be instrumental in designing a successful digital badge initiative through a school-university partnership. The purpose of this exploratory case study was to understand how students and members of a school-university partnership perceived the use of an earned digital badge to embrace the legitimacy of instructional technology competencies that can be used as career currency. Data collection included student and partner interviews, badge assessment results, and meeting documentation. Results of the study were framed using Rogers' (2003) innovation diffusion theory to identify the critical characteristics of the pilot digital badge initiative through a school-university partnership. Results found that relevance to professional opportunities, value to stakeholders, and sustainability plans contributed to relative advantage, compatibility, trialability, and observability. Additionally, results found communication and timing contributed to complexity barriers. Results of the current study will be used to further develop a successful digital badge initiative through an ongoing school-university partnership.},
  langid = {english},
  keywords = {Digital badge,EDUCATION,Educational technology,Instructional technology,Micro-credential,PERCEPTIONS,Professional development,School-university partnerships}
}

@misc{straumsheimTurnitinFacesNew,
  title = {Turnitin Faces New Questions about Efficacy of Plagiarism Detection Software},
  author = {Straumsheim, Carl},
  urldate = {2020-01-18},
  abstract = {Tests conducted by a writing coordinator at the U of Texas at Austin suggest that many student plagiarists could avoid being caught by Turnitin.},
  howpublished = {https://www.insidehighered.com/news/2015/07/14/turnitin-faces-new-questions-about-efficacy-plagiarism-detection-software},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/N54UNI9W/turnitin-faces-new-questions-about-efficacy-plagiarism-detection-software.html}
}

@article{straussHowardGardnerMultiple2021,
  title = {Howard {{Gardner}}: `{{Multiple}} Intelligences' Are Not `Learning Styles'},
  shorttitle = {Howard {{Gardner}}},
  author = {Strauss, Valerie},
  year = {2021},
  month = nov,
  journal = {Washington Post},
  issn = {0190-8286},
  urldate = {2022-11-16},
  abstract = {The famed psychologist explains why one is not the other though they are often confused.},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/JQMTIQ7W/howard-gardner-multiple-intelligences-are-not-learning-styles.html}
}

@article{strawserWISERAssessmentCommunication2020,
  title = {{{WISER Assessment}}: {{A Communication Program Assessment Framework}}},
  author = {Strawser, Michael G. and Neuberger, Lindsay},
  year = {2020},
  journal = {Journal of Communication Pedagogy},
  volume = {3},
  pages = {134--144},
  issn = {EISSN-2578-2568},
  doi = {10/gmbv24},
  abstract = {Learning outcome assessment is a fairly recent trend in higher education that began in the 1980s (Lubinescu et al., 2001). Today, many faculty perceive assessment reporting to be tedious, time-consuming, and irrelevant busywork (Wang \& Hurley, 2012). Unfortunately, this systematic process created to use empirical evidence to measure, document, and improve student learning has in many cases lost sight of this central goal. As a result, faculty may be justified in their opinions about it. This essay proposes a framework for addressing this thorny issue via WISER. WISER is an acronym for five content pillars of the communication discipline faculty can use to ensure their assessment efforts achieve the goal of not only documenting but also improving student learning. WISER stands for writing, immersive experiences, speaking, ethical communication, and research as programmatic assessment categories. These WISER categories extend the National Communication Association (NCA)-endorsed domains of communication learning in ways that make them functional for assessment.},
  langid = {english},
  keywords = {College Outcomes Assessment,College Programs,Communication (Thought Transfer),Communication Skills,Educational Experience,Ethics,Evaluation Criteria,Program Evaluation,Speech,Student Research,Writing (Composition)}
}

@phdthesis{streffQualitativeCaseStudy2016,
  type = {Ed.{{D}}.},
  title = {A {{Qualitative Case Study}} of {{Strategies}} for {{Choosing}} and {{Evaluating Alternative Assessments}} in {{Online Higher Education}}},
  author = {Streff, Robert James},
  year = {2016},
  journal = {ProQuest Dissertations and Theses},
  address = {Ann Arbor},
  abstract = {Studies have shown that not all students are assessed effectively using standard testing formats. However, it is unclear what alternative methodology would be useful to determine whether students have acquired the skills necessary for today's global market. This research study's purpose was to understand the processes instructors use when choosing and designing alternative assessments in higher education online courses to measure student performance. Using Gagn{\'e}'s conditions of learning and Bloom's Taxonomy as a framework to understand these processes, this qualitative case study examined 8 participants teaching online at Midwestern public universities. Interview data and course artifacts, including syllabi, rubrics, assessments, and grades, were gathered as evidence. These data were categorized by participant, interview question, and research question, and were then coded and analyzed to identify themes. The results indicated that, although objectives drive assessment indicators, they do not necessarily drive the assessment choice. They also indicated that the processes used by experienced instructors to determine assessment choices appear almost subconscious, although objectives are the major decision making point. This study impacts social change by helping identify areas where assessment selection is effective or ineffective, as well as where additional training needs to occur on alternative assessment options that accommodate changing student and workplace expectations better.},
  isbn = {978-1-339-75442-0},
  langid = {english},
  school = {Walden University},
  keywords = {0288:Educational tests & measurements,0443:Educational evaluation,0745:Higher education,Alternatve assessment,Assessment,Assessment design,Education,Educational evaluation,Educational tests & measurements,Higher education,Online assessment},
  annotation = {10112288}
}

@article{struyvenStudentsPerceptionsEvaluation2005,
  title = {Students' Perceptions about Evaluation and Assessment in Higher Education: A Review},
  shorttitle = {Students' Perceptions about Evaluation and Assessment in Higher Education},
  author = {Struyven, Katrien and Dochy, Filip and Janssens, Steven},
  year = {2005},
  month = aug,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {30},
  number = {4},
  pages = {325--341},
  issn = {0260-2938, 1469-297X},
  doi = {10/dpwf2x},
  urldate = {2021-07-04},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/J5NHUCU5/struyvenStudentsPerceptionsEvaluation2005.pdf}
}

@book{sturialeEffectsArtEducation,
  title = {The Effects of Art Education on the Development of Cognitive Skills},
  author = {Sturiale, N},
  annotation = {MDDE603 Course Readings}
}

@article{styresCommunityfirstLandcentredTheoretical2013,
  title = {The Community-First Land-Centred Theoretical Framework: {{Bringing}} a" {{Good Mind}}" to Indigenous Education Research?.},
  author = {Styres, Sandra D and Zinga, Dawn M},
  year = {2013},
  journal = {Canadian Journal of Education},
  volume = {36},
  number = {2},
  pages = {284--313},
  publisher = {JSTOR},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/BN54F7YI/styres2013community.pdf}
}

@article{subotzkyTurningTideSociocritical2011,
  title = {Turning the Tide: A Socio-Critical Model and Framework for Improving Student Success in Open Distance Learning at the {{University}} of {{South Africa}}},
  shorttitle = {Turning the Tide},
  author = {Subotzky, George and Prinsloo, Paul},
  year = {2011},
  journal = {Distance Education},
  volume = {32},
  number = {2},
  pages = {177--193},
  issn = {0158-7919, 1475-0198},
  doi = {10.1080/01587919.2011.584846},
  urldate = {2024-09-25},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/subotzkyTurningTideSociocritical2011.pdf}
}

@article{sucahyoStudentsOnlineAssessments2022,
  title = {Students' {{Online Assessments}} in {{Higher Education Context}}: {{Indonesian Teacher Educators}}' {{Voice}}},
  author = {Sucahyo, Didik and Hermagustiana, Istanti and Rusmawaty, Desy},
  year = {2022},
  journal = {Script journal},
  volume = {7},
  number = {2},
  pages = {367--379},
  issn = {2477-1880},
  doi = {10.24903/sj.v7i2.1090},
  abstract = {Background: The usage of remote learning system creates challenges in many universities, especially during COVID-19 pandemic. The utilization of remote learning system has supported many lecturers in teaching and learning process. However, making an appropriate learning assessment is still an issue. This study was aimed to investigate the types of assessment techniques, learning platforms utilized by lecturers in assessing the students' performance, and challenges in assessing students online. Methodology: This is a mixed method study. The participants were 20 lecturers from any disciplines working in one state university in East Kalimantan, Indonesia. The data were quantitatively and qualitatively analyzed. Findings: It was revealed that six assessment techniques were revealed including video projects, group presentations, essay writing, online tests, summarizing, and giving comments on online discussions. Moreover, seven learning platforms were found to be used by the participants with Zoom as the highest choice with 86.2\%. Last, three main challenges of assessing students online were uncovered through interview data which include lack of face-to-face interactions, lack of supporting teaching and learning facilities, and lack of students' integrity and honesty. Conclusion: Various techniques and platforms for students' assessments were used by lecturers. However, a number of challenges were also found to show that not only do online assessments provide positive but also negative contribution towards students' performance in assessments.},
  file = {/Users/colin.madland/Zotero/storage/AZGEL9CP/sucahyoStudentsOnlineAssessments2022.pdf}
}

@article{sudakovaOnlineFormativeAssessment2022,
  title = {Online {{Formative Assessment}} in {{Higher Education}}: {{Bibliometric Analysis}}},
  author = {Sudakova, {\relax NE} and Savina, {\relax TN} and Masalimova, {\relax AR} and Mikhaylovsky, {\relax MN} and Karandeeva, {\relax LG} and Zhdanov, {\relax SP}},
  year = {2022},
  journal = {Education Sciences},
  volume = {12},
  number = {3},
  issn = {2227-7102},
  doi = {10.3390/educsci12030209},
  abstract = {Assessment is critical in postsecondary education, as it is at all levels. Assessments are classified into four types: diagnostic, summative, evaluative, and formative. Recent trends in assessment have migrated away from summative to formative evaluations. Formative evaluations help students develop expertise and concentrate their schedules, ease student anxiety, instill a feeling of ownership in students as they go, and confirm the module's subject notion. Online formative assessment (OFA) emerged as a result of the convergence of formative and computer-assisted assessment research. Bibliometric analyses provide readers with a comprehensive understanding of a study topic across a particular time period. We used a PRISMA-compliant bibliometric method. The Scopus database was searched for BibTex-formatted publication data. In total, 898 studies were analyzed. According to the results, Assessment \& Evaluation in Higher Education and Computers \& Education are the most influential sources. RWTH Aachen University and Universitat Oberta De Catalunya are the most effective institutions. The red cluster includes terms associated with higher education and evaluation. The word "e-assessment, e-learning, assessment, moodle" appears in the green cluster. This group is quite influential yet has a low centrality. The highest percentage is 79.2 for "online assessment". The subject is comprised of three components: "distance learning", "accessibility", and "assessment design". The most important topics were "e-assessment", "higher education", and "online learning". According to the country participation network, the USA and UK were the two main centers.},
  langid = {english},
  keywords = {bibliometrics analysis,DESIGN,higher education,online formative assessment,SCIENCE,STUDENTS,TOOL},
  file = {/Users/colin.madland/Zotero/storage/KCDTTEAS/sudakovaOnlineFormativeAssessment2022.pdf}
}

@article{sugdenEvaluatingStudentEngagement2021,
  title = {Evaluating Student Engagement and Deep Learning in Interactive Online Psychology Learning Activities},
  author = {Sugden, Nicole and Brunton, Robyn and MacDonald, Jasmine and Yeo, Michelle and Hicks, Ben},
  year = {2021},
  month = may,
  journal = {Australasian Journal of Educational Technology},
  volume = {37},
  number = {2},
  pages = {45--65},
  issn = {1449-5554, 1449-3098},
  doi = {10.14742/ajet.6632},
  urldate = {2023-01-15},
  abstract = {There is growing demand for online learning activities that offer flexibility for students to study anywhere, anytime, as online students fit study around work and family commitments. We designed a series of online activities and evaluated how, where, and with what devices students used the activities, as well as their levels of engagement and deep learning with the activities. A mixed-methods design was used to explore students' interactions with the online activities. This method integrated learning analytics data with responses from 63 survey, nine interview, and 16 focus group participants. We found that students used a combination of mobile devices to access the online learning activities across a variety of locations during opportunistic study sessions in order to fit study into their daily routines. The online activities were perceived positively, facilitating affective, cognitive, and behavioural engagement as well as stimulating deep learning. Activities that were authentic, promoted problem-solving, applied theory to real-life scenarios, and increased students' feelings of being supported were perceived as most beneficial to learning. These findings have implications for the future design of online activities, where activities need to accommodate students' need for flexibility as students' study habits become more mobile.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/8V4B4Z5C/sugdenEvaluatingStudentEngagement2021.pdf}
}

@article{sugilarStudentsBarriersOnline2021,
  title = {Students' {{Barriers}} to {{Online Tutorial}}},
  author = {Sugilar},
  year = {2021},
  journal = {Turkish Online Journal of Distance Education},
  volume = {22},
  number = {1},
  pages = {170--178},
  issn = {EISSN-1302-6488},
  doi = {10/gmbv2r},
  abstract = {An online tutorial should be the core of the student learning support services in the digital era to maintain the quality of distanced higher education. However, in Universitas Terbuka with supposed to be the cyber university of Indonesia, the participation in the online tutorials was still not encouraging. For example, the average of the percentage of students' involvement in the first academic semester of 2017 to the 2nd semester 2018 for one course was 2.21\%. This study aimed to identify barriers for students to participate in the online tutorial. The method consisted of two stages. First, analyzing qualitative data that were gathered through open-ended questions to identify factors of the barriers. Second, developing 20 items' questionnaire based on the factors identified in the first stage and analyzed using Partial Least Squares Structural Equation Model (PLS-SEM). The study involved 76 students in the first stage and 237 students in the second. The results of the study revealed that the students' barriers to online tutorial reflected in four factors, i.e. (1) information, (2) motivation, (3) technical, and (4) supports; each factor confirmed significantly (p-values {$<$} 0.05) with t-values equal to 14.108, 27.875, 7.502, and 25.640, respectively. The study proposed some recommendations to improve student participation in online tutorials.},
  langid = {english},
  keywords = {Barriers,College Students,Foreign Countries,Student Attitudes,Student Motivation,Student Participation,Tutorial Programs,Web Based Instruction}
}

@book{suIntroductionAppliedStatistics2024,
  title = {Introduction to {{Applied Statistics}}},
  author = {Su, Wanhua},
  year = {2024},
  month = feb,
  publisher = {MacEwan Open Books},
  doi = {10.31542/b.gm.5},
  urldate = {2024-05-21},
  isbn = {978-1-7770611-3-5},
  langid = {canadian},
  keywords = {psyc207},
  file = {/Users/colin.madland/Zotero/storage/TG74378Y/suIntroductionAppliedStatistics2024.pdf;/Users/colin.madland/Zotero/storage/ZFCRTS6R/introstats.html}
}

@article{sulaimanUseScratchChallenge2021,
  title = {The {{Use}} of "{{Scratch}} and {{Challenge Board}}" as an {{Alternative Assessment Tool}} to {{Enhance University Students}}' {{Skills}}},
  author = {Sulaiman, Tajularipin and Rahim, Suzieleez Syrene Abdul and Wong, KaiYan and Jaafar, Wan Marzuki Wan},
  year = {2021},
  month = jul,
  journal = {Asian Journal of University Education},
  volume = {17},
  number = {3},
  pages = {85--98},
  publisher = {Asian Journal of University Education},
  issn = {1823-7797},
  doi = {10.24191/ajue.v17i3.14506},
  abstract = {In the teaching and learning process, assessment can be applied in various ways. In order to ensure the quality of education, assessment should be performed as a platform to support student learning. The role of assessment also ensures that students' learning outcomes meet the needs of the 21st century skills. "Scratch \& Challenge Board" (SCB) can be used to support the 21st century teaching and learning environment through focus group discussions. Therefore, the aim of this study was to explore the perspectives of university students on the use of "Scratch \& Challenge Board" as an alternative assessment tool in enhancing students' skills. This study applied the qualitative research approach. Data were collected through focus group interviews and related documents such as students' assignments. A total of 10 focus group were obtained, with 3-4 students in each group, and each discussion was moderated by an experienced moderator. Collected data were analysed using constant comparative data analysis methods to obtain the themes. Four (4) themes emerged in this study: (i) alternative assessment encourages active participation in learning, (ii) integrating technologies in assessment tools, (iii) relevant with 21st century skills, and (iv) improvement in learning environment. In conclusion, the "Scratch and Challenge Board" is an assessment tool that not only supports face-toface teaching and learning, but can also be integrated with technological devices and social media platforms. The "Scratch and Challenge Board" also enhances students' 21st century skills.},
  keywords = {21st Century Skills,Active Learning,Alternative Assessment,Educational Environment,Foreign Countries,Malaysia,Skill Development,Student Attitudes,Student Evaluation,Technology Integration,Undergraduate Students,Visual Aids},
  file = {/Users/colin.madland/Zotero/storage/5Z6BMP9V/sulaimanUseScratchChallenge2021.pdf}
}

@article{sultanCloudComputingEducation,
  title = {Cloud Computing for Education: {{A}} New Dawn?},
  author = {Sultan, Nabil},
  journal = {International Journal of Information Management},
  volume = {In Press, Corrected Proof},
  abstract = {Educational establishments continue to seek opportunities to rationalize the way they manage their resources. The economic crisis that befell the world following the near collapse of the global financial system and the subsequent bailouts of local banks with billions of tax payers' money will continue to affect educational establishments that are likely to discover that governments will have less money than before to invest in them. It is argued in this article that cloud computing is likely to be one of those opportunities sought by the cash-strapped educational establishments in these difficult times and could prove to be of immense benefit (and empowering in some situations) to them due to its flexibility and pay-as-you-go cost structure. Cloud computing is an emerging new computing paradigm for delivering computing services. This computing approach relies on a number of existing technologies, e.g., the Internet, virtualization, grid computing, Web services, etc. The provision of this service in a pay-as-you-go way through (largely) the popular medium of the Internet gives this service a new distinctiveness. In this article, some aspects of this distinctiveness will be highlighted and some light will be shed on the current concerns that might be preventing some organizations from adopting it.},
  keywords = {and,Cloud,computing,enterprises,Grid,medium,services,Small,SMEs,Virtualization,Web}
}

@article{sumakAcceptanceUseInteractive2016,
  title = {The Acceptance and Use of Interactive Whiteboards among Teachers: {{Differences}} in {{UTAUT}} Determinants between Pre- and Post-Adopters},
  shorttitle = {The Acceptance and Use of Interactive Whiteboards among Teachers},
  author = {{\v S}umak, Bo{\v s}tjan and {\v S}orgo, Andrej},
  year = {2016},
  month = nov,
  journal = {Computers in Human Behavior},
  volume = {64},
  pages = {602--620},
  issn = {07475632},
  doi = {10.1016/j.chb.2016.07.037},
  urldate = {2024-11-08},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/sumakAcceptanceUseInteractive2016.pdf}
}

@article{sunStudentCenteredOnlineTeaching2021,
  title = {Student-{{Centered Online Teaching Practices}} in {{Theoretical Mechanics}}},
  author = {Sun, Haibin and Liu, Tingting},
  year = {2021},
  journal = {Higher Education Studies},
  volume = {11},
  number = {2},
  pages = {233--239},
  issn = {ISSN-1925-4741},
  doi = {10/gmbvzp},
  abstract = {The COVID-19 pandemic has had a serious impact on education at all levels and types, and the education system, including colleges and universities, has been forced to respond by a sudden shift to online teaching. Successful online teaching requires careful thinking, planning, and technical and human support from teachers. Based on the reflection on the offline classroom teaching of theoretical mechanics for many years and the online teaching practice of first half of 2020, the author summarizes effective strategies for implementing online teaching of theoretical mechanics. We prepared the theoretical mechanical lessons through a "student-centered" approach, such as preparing teaching materials, students and teaching methods. These teaching strategies include (i) Adopting live-stream teaching as the main teaching method, (ii) Applying electronic blackboard to online deductions, (iii) Linking theory to practice for better understanding of knowledge, (iv) Integrating curriculum content in ideological and moral education, (v) Conducting formative assessment to supervise and motivate online learning. The implementation of these online teaching strategies has effectively promoted the development of students' independent learning ability.},
  langid = {english},
  keywords = {COVID-19,Electronic Learning,Ethical Instruction,Foreign Countries,Formative Evaluation,Ideology,Independent Study,Instructional Effectiveness,Learning Motivation,Mechanics (Physics),Pandemics,Student Centered Learning,Teaching Methods,Technology Integration,Theory Practice Relationship,Undergraduate Students}
}

@article{suttonPrincipleVicariousInteraction2001,
  title = {The Principle of Vicarious Interaction in Computer-Mediated Communications},
  author = {Sutton, Leah A.},
  year = {2001},
  journal = {International Journal of Educational Telecommunications},
  volume = {7},
  number = {3},
  pages = {223--242},
  abstract = {Prior research has identified four kinds of interaction that affect the learning process in distance education (Hillman, Willis, \& Gunawardena, 1994; Moore, 1989). This article defines, characterizes, and describes a fifth form of interaction of particular importance to certain learners, especially within the context of computer-mediated communication (CMC). This newly defined concept is referred to as "vicarious interaction." During a pilot study, the author identified students as "direct interactors," "vicarious interactors," "actors," or "non-actors" (Sutton, 1999). Within this framework, the learning psychology associated with the process of vicarious interaction is comparatively analyzed. It is generally accepted that participatory interaction by students directly affects educational success; however, social and psychological characteristics of individual students often combine to inhibit their direct interaction. This article presents the principle that direct interaction is not necessary for all students, and that those who observe and actively process interactions between others will benefit through the process of vicarious interaction.},
  keywords = {Distance,Education,Interaction,STUDENTS}
}

@article{sweeneyWhereTransformationUnlocking2017,
  title = {Where's the {{Transformation}}? {{Unlocking}} the {{Potential}} of {{Technology-Enhanced Assessment}}},
  author = {Sweeney, Trudy and West, Deborah and Groessler, Anthea and Haynie, Aeron and Higgs, Bettie Matheson and Macaulay, Janet and {Mercer-Mapstone}, Lucy and Yeo, Michelle},
  year = {2017},
  journal = {Teaching and Learning Inquiry},
  volume = {5},
  number = {1},
  pages = {1--13},
  publisher = {{International Society for the Scholarship of Teaching and Learning (ISSOTL)}},
  address = {Calgary},
  issn = {2167-4787},
  doi = {10.20343/5.1.5},
  abstract = {Effectiveness of virtual classroom training in improving the knowledge and key maternal neo-natal health skills of general nurse midwifery students in Bihar, India: A pre- and post-intervention study. First year university student engagement using digital curation and career goal setting. Piloting the feasibility of head-mounted video technology to augment student feedback during simulated clinical decision-making: an observational design pilot study. Using Simulation for clinical practice hours in nurse practitioner education in the United States: a systematic review.},
  keywords = {assessment,Collaboration,Educational technology,Empowerment,enhanced,Feedback,Higher education,Learning,Pedagogy,Quality control,R&D,Research & development,Social networks,Students,Teachers,Teaching,technology,transformed},
  file = {/Users/colin.madland/Zotero/storage/YMPV77GT/sweeneyWhereTransformationUnlocking2017.pdf}
}

@article{swellerCognitiveLoadTheory1994,
  title = {Cognitive Load Theory, Learning Difficulty, and Instructional Design},
  author = {Sweller, John},
  year = {1994},
  month = jan,
  journal = {Learning and Instruction},
  volume = {4},
  number = {4},
  pages = {295--312},
  issn = {09594752},
  doi = {10.1016/0959-4752(94)90003-5},
  urldate = {2021-12-29},
  langid = {english},
  keywords = {archived},
  annotation = {https://web.archive.org/web/20210515043639/https://www.sciencedirect.com/science/article/abs/pii/0959475294900035?via\%3Dihub},
  file = {/Users/colin.madland/Zotero/storage/8F8L5CGA/swellerCognitiveLoadTheory1994.pdf}
}

@article{swieckiAssessmentAgeArtificial2022,
  title = {Assessment in the Age of Artificial Intelligence},
  author = {Swiecki, Zachari and Khosravi, Hassan and Chen, Guanliang and {Martinez-Maldonado}, Roberto and Lodge, Jason M. and Milligan, Sandra and Selwyn, Neil and Ga{\v s}evi{\'c}, Dragan},
  year = {2022},
  journal = {Computers and Education: Artificial Intelligence},
  volume = {3},
  pages = {100075},
  issn = {2666920X},
  doi = {10.1016/j.caeai.2022.100075},
  urldate = {2023-01-30},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/FBP6WGJL/swieckiAssessmentAgeArtificial2022.pdf}
}

@article{swieckiAssessmentAgeArtificial2022a,
  title = {Assessment in the Age of Artificial Intelligence},
  author = {Swiecki, Zachari and Khosravi, Hassan and Chen, Guanliang and {Martinez-Maldonado}, Roberto and Lodge, Jason M. and Milligan, Sandra and Selwyn, Neil and Ga{\v s}evi{\'c}, Dragan},
  year = {2022},
  month = jan,
  journal = {Computers and Education: Artificial Intelligence},
  volume = {3},
  pages = {100075},
  issn = {2666-920X},
  doi = {10.1016/j.caeai.2022.100075},
  abstract = {In this paper, we argue that a particular set of issues mars traditional assessment practices. They may be difficult for educators to design and implement; only provide discrete snapshots of performance rather than nuanced views of learning; be unadapted to the particular knowledge, skills, and backgrounds of participants; be tailored to the culture of schooling rather than the cultures schooling is designed to prepare students to enter; and assess skills that humans routinely use computers to perform. We review extant artificial intelligence approaches that--at least partially--address these issues and critically discuss whether these approaches present additional challenges for assessment practice.},
  file = {/Users/colin.madland/Zotero/storage/EU699NGA/swieckiAssessmentAgeArtificial2022a.pdf}
}

@article{swieckiAssessmentAgeArtificial2022b,
  title = {Assessment in the Age of Artificial Intelligence},
  author = {Swiecki, Zachari and Khosravi, Hassan and Chen, Guanliang and {Martinez-Maldonado}, Roberto and Lodge, Jason M. and Milligan, Sandra and Selwyn, Neil and Ga{\v s}evi{\'c}, Dragan},
  year = {2022},
  journal = {Computers and Education: Artificial Intelligence},
  volume = {3},
  pages = {100075},
  issn = {2666920X},
  doi = {10.1016/j.caeai.2022.100075},
  urldate = {2023-02-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/Q7TEAHQS/Swiecki et al. - 2022 - Assessment in the age of artificial intelligence.pdf}
}

@book{SystematicPeerReviewing2019,
  title = {Systematic Peer Reviewing versus a Discussion Forum for Promoting Online Learner Success: An Evaluation of Innovative Learning Design for Postgraduate Students},
  year = {2019},
  abstract = {Designing distance learning to ensure student success is of high importance and there are well-known aspects of distance online learning that encourage retention such as regular tutor support, clear structure, student self-reflection and online discussion with peers (Doig and Hogg, 2013). A module for a new Postgraduate Certificate in Learning and Teaching in Higher Education at the University of London was recently designed using these plus innovative pedagogic features to promote student success. The design included alignment between the assessment criteria and weekly discussion forum activities. An ipsative assessment criterion indicated to students that they must demonstrate their development and progress with their learning throughout the module to encourage consistent engagement. The design also included a peer review process that was managed through the Virtual Learning Environment with student reviews that were anonymised. To identify which aspects of the design promoted success, we collected data analytics for 50 students and explored links between online discussion forum participation, peer review activities and student marks. Contrary to popular expectations, engagement with the discussion forum is not a very good predictor of completion and success. By contrast, engagement in peer review, and especially giving feedback to peers, is a good predictor of success. Furthermore, early drop out from peer review links to incomplete submission of assessments. Thus, spending time on task in the peer review links to high or moderate performance, although a few exceptions indicate that different learners might use different tools for success. This study suggests a number of avenues for tutor development in online learning to encourage retention such as using peer review activities that are time bound and well organised. Assessment could include criteria for developmental progress as well as outcomes}
}

@article{tadjerNewApproachAssessing2018,
  title = {A New Approach for Assessing Learners in an Online Problem Based Learning Environment},
  author = {Tadjer, Houda and Lafifi, Yacine and {Seridi-Bouchelaghem}, Hassina},
  year = {2018},
  month = oct,
  journal = {International Journal of Information and Communication Technology Education},
  volume = {14},
  number = {4},
  pages = {18--33},
  publisher = {IGI Global},
  issn = {1550-1876},
  doi = {10.4018/IJICTE.2018100102},
  abstract = {Problem-based learning (PBL) is an approach that improves students' skills in problem solving. The application of PBL as an approach of teaching in a class requires students' presence; such constraint cannot be fulfilled by all students. Therefore, it is important to avoid this problem by implementing an online PBL environment where students are grouped remotely and work together to solve a problem proposed by the teacher. This will guide the learning process of the learners and can evaluate their solution. In reality, we can find members who do not really contribute to solve a problem. From this point of view, the teacher's evaluation will not be adequate to estimate the contribution of the learner in the solution of a given problem. Therefore, it is important to think of another way for assessing learners' solution. So, the challenge is to implement an online PBL environment and to propose a new method for assessing students. In this paper, the authors present their system called Problearn. The developed system allows students to solve problems remotely in small groups. Furthermore, the system evaluates each student based on his behavioral profiles during the problem-solving process. To do so, the system must keep track of different actions carried out by the students. This system has been tested by students of a computer science department where they achieved very good results. (PsycINFO Database Record (c) 2020 APA, all rights reserved)},
  keywords = {Ability,computer science,Computer Science,Educational Measurement,Environment,Learning,learning environment,Learning Environment,online problem solving,Problem Based Learning,Problem Solving,Students,Teachers,teaching methods,Teaching Methods}
}

@article{taftOneSizeDoes2019,
  title = {One {{Size Does Not Fit All}}: {{Toward}} an {{Evidence-Based Framework}} for {{Determining Online Course Enrollment Sizes}} in {{Higher Education}}},
  author = {Taft, Susan H. and Kesten, Karen and {El-Banna}, Majeda M.},
  year = {2019},
  journal = {Online Learning},
  volume = {23},
  number = {3},
  pages = {188--233},
  issn = {ISSN-2472-5749},
  abstract = {Class enrollment sizes for online learning in higher education, a topic of persistent interest in the academic literature, impact student learning, pedagogical strategies, school finances, and faculty workload. Yet in the research literature, class size is addressed with insufficient specificity to provide enrollment direction. Seeking guidelines for determining online class sizes, the authors conducted a qualitative research synthesis from 43 recent higher education journals, yielding 58 evidence-based articles. It is clear that no one size fits all. Findings reflect that large classes (= 40 students) are effective for foundational and factual knowledge acquisition requiring less individualized faculty-student interaction. Small classes (= 15 students) are indicated for courses intending to develop higher order thinking, mastery of complex knowledge, and student skill development. Pedagogical intent should dictate class size. Using well-established learning theories, the authors describe current understandings of online enrollments and propose an analytical framework for pedagogically driven, numerically specific class sizes. Highlights: (1) There is academic interest in online course sizes in higher education; (2) Research indicates "no one size fits all" online classes; (3) Class sizes should be based on learning level and identified pedagogical intent; (4) Large classes are appropriate for foundation-level learning; and (5) Small classes are appropriate for learning requiring higher order thinking.},
  langid = {english},
  keywords = {Behavioral Objectives,Class Size,Educational Research,Enrollment,Higher Education,Learning Theories,No DOI found,Online Courses}
}

@article{taiAssessmentHowWell2024,
  title = {Assessment: How Well Are We Doing?},
  shorttitle = {Assessment},
  author = {Tai, J},
  year = {2024},
  month = may,
  journal = {The Bulletin of the Royal College of Surgeons of England},
  volume = {106},
  number = {3},
  pages = {158--161},
  issn = {1473-6357, 1478-7075},
  doi = {10.1308/rcsbull.2024.60},
  urldate = {2024-05-07},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/TQLWSAPT/taiAssessmentHowWell2024.pdf}
}

@article{taiAssessmentInclusionRethinking2022,
  title = {Assessment for Inclusion: Rethinking Contemporary Strategies in Assessment Design},
  shorttitle = {Assessment for Inclusion},
  author = {Tai, Joanna and Ajjawi, Rola and Bearman, Margaret and Boud, David and Dawson, Phillip and {Jorre de St Jorre}, Trina},
  year = {2022},
  month = jun,
  journal = {Higher Education Research \& Development},
  pages = {1--15},
  issn = {0729-4360, 1469-8366},
  doi = {10.1080/07294360.2022.2057451},
  urldate = {2023-02-06},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/YPP6C6LV/taiAssessmentInclusionRethinking2022.pdf}
}

@article{taiDevelopingEvaluativeJudgement2018,
  title = {Developing Evaluative Judgement: Enabling Students to Make Decisions about the Quality of Work},
  shorttitle = {Developing Evaluative Judgement},
  author = {Tai, Joanna and Ajjawi, Rola and Boud, David and Dawson, Phillip and Panadero, Ernesto},
  year = {2018},
  journal = {Higher Education},
  volume = {76},
  number = {3},
  pages = {467--481},
  issn = {0018-1560, 1573-174X},
  doi = {10.1007/s10734-017-0220-3},
  urldate = {2022-09-19},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/WF22RT9W/taiDevelopingEvaluativeJudgement2018.pdf}
}

@incollection{taiFutureSelfPeer2020,
  title = {The {{Future}} of {{Self}} and {{Peer Assessment}}: {{Are Technology}} or {{People}} the {{Key}}?},
  shorttitle = {The {{Future}} of {{Self}} and {{Peer Assessment}}},
  booktitle = {Re-Imagining {{University Assessment}} in a {{Digital World}}},
  author = {Tai, Joanna and Adachi, Chie},
  editor = {Bearman, Margaret and Dawson, Phillip and Ajjawi, Rola and Tai, Joanna and Boud, David},
  year = {2020},
  volume = {7},
  pages = {213--227},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-41956-1_15},
  urldate = {2022-03-19},
  isbn = {978-3-030-41955-4 978-3-030-41956-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/Q2FYQX6I/taiFutureSelfPeer2020.pdf}
}

@article{taiHowStudentsExperience2021,
  title = {How Do Students Experience Inclusive Assessment? {{A}} Critical Review of Contemporary Literature},
  shorttitle = {How Do Students Experience Inclusive Assessment?},
  author = {Tai, Joanna and Ajjawi, Rola and Umarova, Anastasiya},
  year = {2021},
  month = dec,
  journal = {International Journal of Inclusive Education},
  pages = {1--18},
  issn = {1360-3116, 1464-5173},
  doi = {10.1080/13603116.2021.2011441},
  urldate = {2024-05-07},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/QUZ8Z92D/taiHowStudentsExperience2021.pdf}
}

@article{tailabUseSelfAssessmentVideo2020,
  title = {Use of {{Self-Assessment}} of {{Video Recording}} to {{Raise Students}}' {{Awareness}} of {{Development}} of {{Their Oral Presentation Skills}}},
  author = {Tailab, Mohamed M. Khalifa and Marsh, Nicole Y.},
  year = {2020},
  month = jan,
  journal = {Higher Education Studies},
  volume = {10},
  number = {1},
  pages = {16--28},
  publisher = {Higher Education Studies},
  issn = {1925-4741},
  doi = {10.5539/hes.v10n1p16},
  abstract = {This paper aims to examine if using video recordings help students raise their awareness of the development of their oral presentation skills by reviewing video recordings of their presentations. For this study, all students who took a Financial Accounting class in the academic year 2018--2019 at Lincoln University (LU) were video-recorded when presenting. Participants were asked to review their video recordings, assess their performance, and record their reflections by using a Self-Assessment Questionnaire (SAQ). The results indicated that the students' attitude toward recording the presentations was highly positive. The predominant response was that this new learning activity increased students' awareness of the importance of presentation skills without provoking their anxiety. Participants were able to observe that certain delivery skills such as good preparation, self-confidence, eye contact, and voice quality needed improvement. For managerial implications, LU, through its Writing and Speaking Center (WSC), offered thirty-minute sessions with a presentation coach to improve students' communication skills and prepare them to give a more polished presentation in class. In comparing the practice presentation at the WSC with the final in-class presentation, students were observed to be more confident, better prepared, and less nervous during the final presentation. However, we observed that the practice presentation did not carry the same weight as the final presentation as the practice presentation was neither graded nor delivered in front of an instructor or a wider audience.},
  keywords = {Accounting,California (Oakland),Communication Skills,Consciousness Raising,Outcomes of Education,Public Speaking,Reflection,Self Esteem,Self Evaluation (Individuals),Self Management,Skill Development,Speech Skills,Student Attitudes,Technology Uses in Education,Undergraduate Students,Video Technology},
  file = {/Users/colin.madland/Zotero/storage/4IFGMYVE/tailabUseSelfAssessmentVideo2020.pdf}
}

@incollection{taiPromotingEquitySocial2022,
  title = {Promoting Equity and Social Justice through Assessment for Inclusion},
  booktitle = {Assessment for {{Inclusion}} in {{Higher Education}}: {{Promoting Equity}} and {{Social Justice}} in {{Assessment}}},
  author = {Tai, Joanna and Ajjawi, Rola and Boud, David and {Jorre de St Jorre}, Trina},
  editor = {Ajjawi, Rola and Tai, Joanna and Boud, David and Jorre De St Jorre, Trina},
  year = {2022},
  edition = {1},
  publisher = {Routledge},
  address = {London},
  doi = {10.4324/9781003293101},
  urldate = {2023-09-03},
  abstract = {Assessment in higher education is inescapable; it assures competence, drives learning, and shapes learners. It is something that students must undertake if they wish to succeed and graduate. While they might be able to evade other aspects of the higher education experience, they cannot escape assessment (Boud 1995). However, while all students might be required to participate in assessment, their experiences of assessment may differ significantly, particularly if they are from non-traditional backgrounds (Tai et al. 2022b).},
  isbn = {978-1-003-29310-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/7ASR3HLQ/taiPromotingEquitySocial2022.pdf}
}

@article{taiRolePeerassistedLearning2016,
  title = {The Role of Peer-Assisted Learning in Building Evaluative Judgement: Opportunities in Clinical Medical Education},
  author = {Tai, Joanna Hong-Meng and Canny, Benedict J. and Haines, Terry P. and Molloy, Elizabeth K.},
  year = {2016},
  journal = {Advances in health sciences education : theory and practice},
  volume = {21},
  number = {3},
  pages = {659--676},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  issn = {1382-4996},
  doi = {10.1007/s10459-015-9659-0},
  abstract = {This study explored the contribution of peer-assisted learning (PAL) in the development of evaluative judgement capacity; the ability to understand work quality and apply those standards to appraising performance. The study employed a mixed methods approach, collecting self-reported survey data, observations of, and reflective interviews with, the medical students observed. Participants were in their first year of clinical placements. Data were thematically analysed. Students indicated that PAL contributed to both the comprehension of notions of quality, and the practice of making comparisons between a given performance and the standards. Emergent themes included peer story-telling, direct observation of performance, and peer-based feedback, all of which helped students to define `work quality'. By participating in PAL, students were required to make comparisons, therefore using the standards of practice and gaining a deeper understanding of them. The data revealed tensions in that peers were seen as less threatening than supervisors with the advantage of increasing learners' appetites for thoughtful `intellectual risk taking'. Despite this reported advantage of peer engagement, learners still expressed a preference for feedback from senior teachers as more trusted sources of clinical knowledge. While this study suggests that PAL already contributes to the development of evaluative judgement, further steps could be taken to formalise PAL in clinical placements to improve learners' capacity to make accurate judgements on the performance of self and others. Further experimental studies are necessary to confirm the best methods of using PAL to develop evaluative judgement. This may include both students and educators as instigators of PAL in the workplace.},
  keywords = {Clinical Competence - standards,Clinical Experience,Comprehension,Computer Assisted Instruction,Cooperative Learning,Data Collection,Education,Education Medical - methods,Education Medical - standards,Educational Measurement - methods,Educational Quality,Evaluative Thinking,Feedback (Response),Female,Formative Feedback,Humans,Information Sources,Interviews,Judgment,Knowledge Level,Learning,Male,Medical Education,Medical Students,Mixed Methods Research,Observation,Peer Group,Peer Teaching,Performance Based Assessment,Preferences,Qualitative Research,Research Methodology,Story Telling,Student Placement,Students,Students Medical - psychology,Surveys,Teacher Student Relationship,Teaching Methods,Trust (Psychology)},
  file = {/Users/colin.madland/Zotero/storage/B2IT8LM6/taiRolePeerassistedLearning2016.pdf}
}

@article{taitDistanceElearningSocial2013,
  title = {Distance and E-Learning, Social Justice, and Development: {{The}} Relevance of Capability Approaches to the Mission of Open Universities},
  shorttitle = {Distance and E-Learning, Social Justice, and Development},
  author = {Tait, Alan},
  year = {2013},
  month = aug,
  journal = {The International Review of Research in Open and Distributed Learning},
  volume = {14},
  number = {4},
  issn = {1492-3831},
  doi = {10.19173/irrodl.v14i4.1526},
  urldate = {2019-02-13},
  file = {/Users/colin.madland/Zotero/storage/RLKP39IQ/taitDistanceElearningSocial2013.pdf}
}

@misc{talbertEMRNRubric2022,
  title = {The {{EMRN Rubric}}},
  author = {Talbert, Robert},
  year = {2022},
  month = apr,
  journal = {Robert Talbert, Ph.D.},
  urldate = {2022-06-24},
  abstract = {The EMRN rubric is a four-level rubric for evaluating student work. It uses a simple flowchart to categorize student work into one of four bins:  The rubric was created by Rodney Stutzman and Kim Race, where it originated as the "EMRF" rubric in a 2004 article in Mathematics Teacher magazine},
  howpublished = {http://rtalbert.org/emrn/},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/A6Q7XA9R/emrn.html}
}

@article{tamayoDesignChatbotDistance2020,
  title = {Design of a {{Chatbot}} as a {{Distance Learning Assistant}}},
  author = {Tamayo, Pedro Antonio and Herrero, Ana and Mart{\'i}n, Javier and Navarro, Carolina and Tr{\'a}nchez, Jos{\'e} Manuel},
  year = {2020},
  month = jan,
  journal = {Open Praxis},
  volume = {12},
  number = {1},
  pages = {145--153},
  publisher = {Open Praxis},
  issn = {2304-070X},
  doi = {10.5944/openpraxis.12.1.1063},
  abstract = {Within the process of progressive digitization of materials and tools for teaching and distance learning of a subject of introduction to Microeconomics (quarterly, in year three of the Degree in Social Work), taught by the authors at the National University of Distance Education (UNED), a virtual assistant in the form of "chatbot," or conversational robot, called EconBot, has been designed and made available to students from 2017. This paper presents the reasons that led to its adoption, the process of its development, differentiating two phases, its characteristics and functions, the assessment of its usefulness and the role of teachers in the implementation of this type of technological innovation.},
  keywords = {Artificial Intelligence,College Students,Computer Mediated Communication,Design,Distance Education,Economics Education,Educational Technology,Electronic Learning,Foreign Countries,Introductory Courses,Robotics,Spain,Technology Uses in Education},
  file = {/Users/colin.madland/Zotero/storage/LZKJMU62/tamayoDesignChatbotDistance2020.pdf}
}

@article{tamimWhatFortyYears2011,
  title = {What {{Forty Years}} of {{Research Says About}} the {{Impact}} of {{Technology}} on {{Learning}}: {{A Second-Order Meta-Analysis}} and {{Validation Study}}},
  author = {Tamim, Rana M. and Bernard, Robert M. and Borokhovski, Eugene and Abrami, Philip C. and Schmid, Richard F.},
  year = {2011},
  journal = {Review of educational research},
  volume = {81},
  number = {1},
  pages = {4--28},
  publisher = {SAGE Publications},
  address = {Los Angeles, CA},
  issn = {0034-6543},
  doi = {10.3102/0034654310393361},
  abstract = {This research study employs a second-order meta-analysis procedure to summarize 40 years of research activity addressing the question, does computer technology use affect student achievement in formal face-to-face classrooms as compared to classrooms that do not use technology? A study-level metaanalytic validation was also conducted for purposes of comparison. An extensive literature search and a systematic review process resulted in the inclusion of 25 meta-analyses with minimal overlap in primary literature, encompassing 1,055 primary studies. The random effects mean effect size of 0.35 was significantly different from zero. The distribution was heterogeneous under the fixed effects model. To validate the second-order metaanalysis, 574 individual independent effect sizes were extracted from 13 out of the 25 meta-analyses. The mean effect size was 0.33 under the random effects model, and the distribution was heterogeneous. Insights about the state of the field, implications for technology use, and prospects for future research are discussed.},
  keywords = {Academic Achievement,Address forms,Classroom Techniques,Comparative Analysis,Computer assisted instruction,Computer modeling and simulation,Computer technology,Computer Uses in Education,Direct instruction,Education & Educational Research,Educational Research,Effect Size,Effects,Evaluation,Evaluation Criteria,Influence,Influence of Technology,Information retrieval,Information technology,Interactive learning,Intermode Differences,Learning,Literary criticism,Literature Reviews,Meta Analysis,Social Sciences,Standard error,Systematic review,Teaching Methods,Technology,Technology Integration,Technology Uses in Education,Use Studies,Validated Programs},
  file = {/Users/colin.madland/Zotero/storage/IAFSJ4QG/tamimWhatFortyYears2011.pdf}
}

@book{tanakaLearningTeachingTogether2016,
  title = {Learning and Teaching Together: Weaving Indigenous Ways of Knowing into Education},
  author = {Tanaka, Michele T. D.},
  year = {2016},
  publisher = {UBC Press},
  address = {Vancouver, BC},
  isbn = {978-0-7748-2951-9 0-7748-2951-6},
  lccn = {E96.2 .T35 2016},
  keywords = {Canada,Critical pedagogy,Education,Indigenous peoples,Multicultural education,Teaching},
  annotation = {OCLC: ocn956556429}
}

@article{tanDevelopingInteractiveOral2022,
  title = {Developing Interactive Oral Assessments to Foster Graduate Attributes in Higher Education},
  author = {Tan, Chin Pei and Howes, Dora and Tan, Rendell K. W. and Dancza, Karina M.},
  year = {2022},
  month = nov,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {47},
  number = {8},
  pages = {1183--1199},
  publisher = {Routledge},
  issn = {0260-2938},
  doi = {10.1080/02602938.2021.2020722},
  abstract = {Interactive oral assessments demonstrate potential to develop graduate attributes such as critical thinking, professional communication and collaborative skills in students through authentic simulation of workplace scenarios. This study captured the design, delivery and evaluation of interactive oral assessments across three programmes ? occupational therapy, nursing and air transport management ? in one university. A four-step Model to Build Authentic Assessment was used to design the assessments. Quantitative and qualitative data collected from 158 students, five assessors and three module leaders were analysed for a basic evaluation of the fidelity of interactive oral assessment implementation across different contexts and to explore the experiences of faculty and students undertaking the assessments. Fidelity was considered in terms of: (i) whether students could express their individualised responses, (ii) if they perceived the assessment to be authentic, and (iii) if it helped them gain professional knowledge and skills. In all the developed assessments, each of the three aspects were somewhat evident, evident or clearly evident. Qualitative findings suggested the interactive oral assessments reflected real-world expectations, promoted deep learning and offered a quality learning experience. From these results, practical suggestions for how faculty can self-assess their readiness for implementing interactive oral assessments are offered.}
}

@article{tanDoesStudentSelf2004,
  title = {Does Student Self-assessment Empower or Discipline Students?},
  author = {Tan, Kelvin H. K.},
  year = {2004},
  month = dec,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {29},
  number = {6},
  pages = {651--662},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/0260293042000227209},
  urldate = {2022-09-18},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/GIWN59NU/tanDoesStudentSelf2004.pdf}
}

@article{tangCaseStudyTeacher2010,
  title = {A Case Study of Teacher Learning in an Assessment for Learning Project in Hong Kong},
  author = {Tang, Sylvia Yee Fan and Leung, Pamela Pui Wan and Chow, Alice Wai Kwan and Wong, Ping Man},
  year = {2010},
  journal = {Professional Development in Education},
  doi = {10/fnn3tp},
  abstract = {Changes in assessment practices in the direction of assessment for learning (AfL) can be a powerful force to enhance student learning. This article presents a case study of teacher learning in an AfL project in Hong Kong. In the Project, AfL strategies were adopted in Chinese Language and English Language classrooms at the junior secondary level. By examining subject leaders' and classroom teachers' experiences with the project reported in interviews, the paper enriches our understanding of the variations in the subject department contexts of teacher learning, the situatedness of teacher learning in terms of knowledge about student learning, understanding of AfL and curriculum leadership, as well as the relationship between teacher learning and changes in assessment practices. The article concludes with suggestions on fostering subject departments to be expansive environments for teacher professional learning and to be a vehicle of internal change, alerts the importance of integration of AfL into teachers...},
  pmcid = {null},
  pmid = {null}
}

@article{tangHaveMassiveOpen2017,
  title = {Have {{Massive Open Online Courses Disrupted Higher Education}} around the {{Globe}}? {{Exploring}} the {{Cultural Perspective}}},
  author = {Tang, Hengtao and Wang, Nicole},
  year = {2017},
  journal = {International Journal of Technology in Teaching and Learning},
  volume = {13},
  number = {1},
  pages = {45--54},
  issn = {EISSN-1551-2576},
  abstract = {Massive Open Online Courses (MOOCs) are high enrollment college-level courses that have the potential to serve learners worldwide. However, numerous questions about MOOCs are still unanswered. For example, are people enrolled in MOOCs from countries where higher educational systems are very constrained? How much does the basic infrastructure, such as Internet access, influence the awareness and acceptance of MOOCs? We believe the effectiveness and efficiency of MOOCs will be improved by understanding the answers to these questions. Our study explored the effect of cultural differences on course enrollment using power distance index, one of Hofstede's cultural dimensions. We looked into enrollment patterns and cultural beliefs of learners from 67 nations across three MOOCs offered by the Pennsylvania State University. The findings indicate that when the variable of Internet access for all countries is controlled, the PDI value of a country influences whether people from that country would register for MOOCs.},
  langid = {english},
  keywords = {Access to Computers,Barriers,Cultural Influences,Distance Education,Educational Technology,Foreign Countries,Higher Education,Internet,Large Group Instruction,No DOI found,Online Courses,Program Effectiveness,Technology Uses in Education}
}

@article{tarasAssessmentBeliefsHigher2017,
  title = {Assessment {{Beliefs}} of {{Higher Education Staff Developers}}},
  author = {Taras, Maddalena and Davies, Mark S.},
  year = {2017},
  journal = {London Review of Education},
  volume = {15},
  number = {1},
  pages = {126--140},
  issn = {EISSN-1474-8479},
  abstract = {This research focuses on the assessment literacy, that is, the understandings of assessment terminologies and how they relate to each other, in academic staff developers in the UK, collected via questionnaires and semi-structured interviews. Academic staff developers have been trained and certified to support new higher education lecturers in learning,teaching, and assessment practices, and provide continuing professional development for more experienced staff. Results showed inconsistent and differing understandings between and within individuals. These inconsistencies may reflect the lack of consistency of terminology in the literature. This lack of common understanding has far-reaching implications and needs reconciling to enhance personal and collective assessment literacies, particularly since our respondents have responsibility for training the next generation of academics.},
  langid = {english},
  keywords = {Beliefs,College Faculty,Evaluation Methods,Experienced Teachers,Familiarity,Foreign Countries,Formative Evaluation,Higher Education,Item Analysis,Knowledge Level,Mentors,No DOI found,Questionnaires,Semi Structured Interviews,Test Items,Vocabulary}
}

@article{tarasAssessmentLearningSectarian2008,
  title = {Assessment for Learning: Sectarian Divisions of Terminology and Concepts},
  author = {Taras, Maddalena},
  year = {2008},
  journal = {Journal of further and higher education},
  volume = {32},
  number = {4},
  pages = {389--397},
  publisher = {Routledge},
  issn = {0309-877X},
  doi = {10.1080/03098770802395892},
  abstract = {Assessment is critical to support and align learning and teaching within the curriculum. Yet our understanding of the many layers of assessment is still incomplete. This article examines some of the differences between critical elements of assessment terminology across the compulsory and higher education sectors in the anglophone world, more specifically in the United Kingdom. Highlighting these differences is important, so that we are able to make informed pedagogical decisions. This article signals that there is much to do in the area of assessment to arrive at a clearer understanding of recent developments within each sector. This is necessary if academics' expertise can be used across sector divides. By highlighting these differences, it is possible to address misunderstandings to fulfil the role of assessment adequately in supporting learning and teaching.},
  keywords = {assessment,Educational Change,Foreign Countries,Formative Evaluation,Higher Education,sectors,Self Evaluation (Individuals),Summative Evaluation,terminology,Theory Practice Relationship,United Kingdom},
  file = {/Users/colin.madland/Zotero/storage/tarasAssessmentLearningSectarian2008.pdf}
}

@article{tarasUsingAssessmentLearning2002,
  title = {Using {{Assessment}} for {{Learning}} and {{Learning}} from {{Assessment}}},
  author = {Taras, Maddalena},
  year = {2002},
  month = dec,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {27},
  number = {6},
  pages = {501--510},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/0260293022000020273},
  urldate = {2024-05-10},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/3596RJQ4/tarasUsingAssessmentLearning2002.pdf}
}

@article{Tarrant_2006,
  title = {The Frequency of Item Writing Flaws in Multiple Choice Questions Used in High Stakes Nursing Assessments},
  author = {Tarrant, Marie and Knierim, Aimee and Hayes, Sasha K. and Ware, James},
  year = {2006},
  journal = {Nurse Education in Practice},
  doi = {10/cm8w85},
  abstract = {Summary Multiple-choice questions are a common assessment method in nursing examinations. Few nurse educators, however, have formal preparation in constructing multiple-choice questions. Consequently, questions used in baccalaureate nursing assessments often contain item-writing flaws, or violations to accepted item-writing guidelines. In one nursing department, 2770 MCQs were collected from tests and examinations administered over a five-year period from 2001 to 2005. Questions were evaluated for 19 frequently occurring item-writing flaws, for cognitive level, for question source, and for the distribution of correct answers. Results show that almost half (46.2\%) of the questions contained violations of item-writing guidelines and over 90\% were written at low cognitive levels. Only a small proportion of questions were teacher generated (14.1\%), while 36.2\% were taken from testbanks and almost half (49.4\%) had no source identified. MCQs written at a lower cognitive level were significantly more likely to contain item-writing flaws. While there was no relationship between the source of the question and item-writing flaws, teachergenerated questions were more likely to be written at higher cognitive levels ( p},
  mag_id = {2168327886},
  pmcid = {null},
  pmid = {null}
}

@article{Tarrant_2009,
  title = {An Assessment of Functioning and Non Functioning Distractors in Multiple Choice Questions a Descriptive Analysis},
  author = {Tarrant, Marie and Ware, James and Mohammed, Ahmed M.},
  year = {2009},
  journal = {BMC Medical Education},
  doi = {10/fmt2qs},
  abstract = {Background Four- or five-option multiple choice questions (MCQs) are the standard in health-science disciplines, both on certification-level examinations and on in-house developed tests. Previous research has shown, however, that few MCQs have three or four functioning distractors. The purpose of this study was to investigate non-functioning distractors in teacher-developed tests in one nursing program in an English-language university in Hong Kong.},
  mag_id = {2135585801},
  pmcid = {2713226},
  pmid = {19580681}
}

@book{tashakkoriFoundationsMixedMethods2020,
  title = {Foundations of Mixed Methods Research: Integrating Quantitative and Qualitative Approaches in the Social and Behavioral Sciences},
  shorttitle = {Foundations of Mixed Methods Research},
  author = {Tashakkori, Abbas and Johnson, Burke and Teddlie, Charles},
  year = {2020},
  edition = {Second Edition},
  publisher = {SAGE Publications, Inc},
  address = {Thousand Oaks},
  abstract = {"The highly-anticipated second edition of the Foundations of Mixed Methods Research:Integrating Quantitative and Qualitative Approaches in the Social and Behavioral Sciences gives students a comprehensive overview of mixed methods from philosophical roots and traditions through designing, conducting, and disseminating a study. Authors Abbas Tashakkori, Burke Johnson, and Charles Teddlie have thoroughly updated the text to reflect the many advances over the last decade in mixed methods. New example studies throughout and a new appendix highlight the latest research on mixed methods and current best practices. New sections on evaluating quality in mixed methods studies and writing up research results round out the process of mixed methods research. The authors have added features like content summaries and objectives at the beginning of each chapter and chapter summaries and previews at the end of each chapter aid readers in their mixed methods journey"--},
  isbn = {978-1-5063-5030-1},
  lccn = {H62 .T294 2020},
  keywords = {Mixed methods research,Research Methodology,Social sciences}
}

@book{tashakkoriHandbookMixedMethods2003,
  title = {Handbook of Mixed Methods in Social and Behavioral Research},
  author = {Tashakkori, Abbas and Teddlie, Charles},
  year = {2003},
  publisher = {Sage Publications},
  address = {Thousand Oaks, CA}
}

@book{tashakkoriSAGEHandbookMixed2010,
  title = {{{SAGE Handbook}} of {{Mixed Methods}} in {{Social}} \& {{Behavioral Research}}},
  author = {Tashakkori, Abbas and Teddlie, Charles},
  year = {2010},
  publisher = {SAGE Publications, Inc.},
  address = {2455 Teller Road,~Thousand Oaks~California~91320~United States},
  doi = {10.4135/9781506335193},
  urldate = {2021-05-14},
  isbn = {978-1-4129-7266-6 978-1-5063-3519-3}
}

@book{tashakkoriSAGEHandbookMixed2010a,
  title = {{{SAGE Handbook}} of {{Mixed Methods}} in {{Social}} \& {{Behavioral Research}}},
  author = {Tashakkori, Abbas and Teddlie, Charles},
  year = {2010},
  publisher = {SAGE Publications, Inc.},
  address = {2455 Teller Road,~Thousand Oaks~California~91320~United States},
  doi = {10.4135/9781506335193},
  urldate = {2021-07-31},
  isbn = {978-1-4129-7266-6 978-1-5063-3519-3}
}

@article{tatsuokaRULESPACEAPPROACH1983,
  title = {{{RULE SPACE}}: {{AN APPROACH FOR DEALING WITH MISCONCEPTIONS BASED ON ITEM RESPONSE THEORY}}},
  shorttitle = {{{RULE SPACE}}},
  author = {Tatsuoka, Kikumi K.},
  year = {1983},
  month = dec,
  journal = {Journal of Educational Measurement},
  volume = {20},
  number = {4},
  pages = {345--354},
  issn = {0022-0655, 1745-3984},
  doi = {10/cbk27v},
  urldate = {2021-01-17},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/E2CL9SSN/tatsuokaRULESPACEAPPROACH1983.pdf}
}

@article{tatzlHigherEducationTeachingModule2018,
  title = {A {{Higher-Education Teaching Module}} for {{Integrating Industry Content}} and {{Language}} through {{Online Recruitment Advertisements}}},
  author = {Tatzl, Dietmar},
  year = {2018},
  journal = {Studies in Second Language Learning and Teaching},
  volume = {8},
  number = {3},
  pages = {643--672},
  issn = {ISSN-2083-5205},
  doi = {10/gmbv2m},
  abstract = {Empirical evaluations of practical teaching units integrating content and language in higher education are rare and deserve more attention. The current article aims to narrow this gap by providing an empirical study of an integrating content and language in higher education (ICLHE, Smit \& Dafouz, 2012) teaching module. It investigates the effectiveness of a content-based English for specific purposes module in tertiary aeronautical engineering education, which incorporates recruitment advertisements as online resources. The study adopted a mixed-methods approach and surveyed three aeronautical engineering student groups (N = 141) over three consecutive years on their perceptions of the module's learning outcomes. This longitudinal survey was complemented by a teacher-assessed writing task and a qualitative content analysis of online recruitment advertisements (N = 80) in a self-built corpus. All three year groups rated the 10 questionnaire statements on a 5-point Likert scale rather equally, thus suggesting a similar perception of academic achievement stemming from the module's completion. This student view was supported by the results of the writing assignment. In short, the module's effectiveness was corroborated both quantitatively and qualitatively, which identifies this teaching concept as a feasible way forward.},
  langid = {english},
  keywords = {Academic Achievement,Advertising,Aerospace Education,Computational Linguistics,Content Analysis,Course Content,Course Evaluation,Engineering Education,English for Special Purposes,Foreign Countries,Interdisciplinary Approach,Language of Instruction,Longitudinal Studies,Recruitment,Second Language Instruction,Second Language Learning,Student Attitudes,Teaching Methods,Undergraduate Students,Writing Assignments}
}

@article{tawafakElearningSystemUCOM2019,
  title = {E-Learning System of {{UCOM}} for Improving Student Assessment Feedback in {{Oman}} Higher Education},
  author = {Tawafak, Ragad M. and Romli, Awanis BT and Alsinani, Maryam},
  year = {2019},
  journal = {Education and information technologies},
  volume = {24},
  number = {2},
  pages = {1311--1335},
  publisher = {Springer US},
  address = {New York},
  issn = {1360-2357},
  doi = {10.1007/s10639-018-9833-0},
  abstract = {This paper focused on the improvement of student's assessment feedback and learning satisfaction in the higher education institutions in Oman using the E-learning system of University Communication Model (UCOM). During the study, an E-learning model was conceptualized using coursework program instruction, testing academic performance, faculty experience, and assessment method as the determinants. The aim of this work is to develop a `University Communication (UCOM) model for improving the student's assessment method and evaluating their academic performance. In the first phase of this study, a systematic review of the existing literature was carried out to determine the suitable quantitative and qualitative criteria of feature selection, like student satisfaction and degree of learning. The next phase involved the generation of an E-learning model for assessing the feedback and approval processes. The final step is the design of the evaluation forms that can measure the satisfaction of the technology and enhance the assessment method. In this study, surveys were distributed to the students of Al-Buraimi University College (BUC), Oman, to assess their level of satisfaction in using a UCOM model which served as a link between them and the University. The results were tested for accuracy, reliability, and validity using smart PLS. The findings of this paper assisted positively in four of the deployed factors and approved the capability of the developed model in improving student's assessment feedback using E-learning.},
  keywords = {Academic Achievement,Accuracy,Analysis,College Students,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Education,Education & Educational Research,Education Higher,Education parks,Educational research,Educational Technology,Electronic Learning,Equipment and supplies,Feedback,Feedback (Response),Foreign Countries,Higher education,Information Systems Applications (incl.Internet),Management Systems,Methods,Online education,Online instruction,Rating of,Reliability,Satisfaction,School facilities,Social Sciences,Student Attitudes,Student Evaluation,Student Surveys,Students,Teaching,Universities,User Interfaces and Human Computer Interaction,Validity}
}

@article{taylorConstructiveDevelopmentTheory1997,
  title = {Constructive-development {{Theory}} as a {{Framework}} for {{Assessment}} in {{Higher Education}}},
  author = {Taylor, Kathleen and Marienau, Catherine},
  year = {1997},
  month = jun,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {22},
  number = {2},
  pages = {233--243},
  issn = {0260-2938, 1469-297X},
  doi = {10/dfgcxs},
  urldate = {2021-06-30},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/JVTY5QVD/taylorConstructiveDevelopmentTheory1997.pdf}
}

@misc{TeachingAI,
  title = {Teaching with {{AI}}},
  urldate = {2023-09-22},
  abstract = {We're releasing a guide for teachers using ChatGPT in their classroom---including suggested prompts, an explanation of how ChatGPT works and its limitations, the efficacy of AI detectors, and bias.},
  howpublished = {https://openai.com/blog/teaching-with-ai},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/6TUUS3AP/TeachingAI.pdf;/Users/colin.madland/Zotero/storage/SGPVYTYF/teaching-with-ai.html}
}

@article{TeachingLearningInquiry,
  title = {Teaching and {{Learning Inquiry}}},
  urldate = {2022-10-06},
  file = {/Users/colin.madland/Zotero/storage/MY334S5J/index.html}
}

@article{TeachingQualityLearning2019,
  title = {Teaching for {{Quality Learning}} at {{Changing Universities}}. {{A}} Tour de Force of Modern Education History -- an Interview with {{Professor John Biggs}}},
  year = {2019},
  month = apr,
  journal = {Journal of Applied Learning \& Teaching},
  volume = {2},
  number = {1},
  issn = {2591-801X, 2591-801X},
  doi = {10.37074/jalt.2019.2.1.6},
  urldate = {2022-08-16},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/X9MS7CNA/TeachingQualityLearning2019.pdf}
}

@misc{TeachingTeachingUnderstanding,
  title = {"{{Teaching Teaching}} \& {{Understanding Understanding}}" (1/3) [{{English}} Subtitles]},
  urldate = {2020-05-17},
  abstract = {"Teaching Teaching \&amp; Understanding Understanding" is a 19-minute award-winning short-film about teaching at university and higher-level educational institutions.     It is based on the "Constructive Alignment" theory developed by Prof. John Biggs.     The film delivers a foundation for understanding what a teacher needs to do in order to make sure all types of students actually learn what the teacher intends.     The film is also available in high quality on DVD with subtitles in seven languages (English, French, Spanish, Portuguese, Italian, German, and Danish).    Film homepage:  - [ http://www.daimi.au.dk/{\textasciitilde}brabrand/shor... ]}
}

@article{technicaAICustomerService,
  title = {An {{AI Customer Service Chatbot Made Up}} a {{Company Policy}}---and {{Created}} a {{Mess}}},
  author = {Technica, Ars, Benj Edwards},
  journal = {Wired},
  issn = {1059-1028},
  urldate = {2025-05-08},
  abstract = {When an AI model for code-editing company Cursor hallucinated a new rule, users revolted.},
  chapter = {tags},
  langid = {american},
  keywords = {ars technica,artificial intelligence,chatbots,coding},
  file = {/Users/colin.madland/Zotero/storage/BPT2ATQL/cursor-ai-hallucination-policy-customer-service.html}
}

@article{TechTrendsOnline1985,
  title = {{{TechTrends}} ({{Online}})},
  year = {1985},
  journal = {TechTrends (Online)},
  publisher = {Association for Educational Communications \& Technology},
  address = {Washington, D.C},
  issn = {1559-7075},
  keywords = {Audio-visual education,Computer-assisted instruction,Education -- Data processing,Educational Technology,Electronic journals,Periodicals}
}

@misc{teddis.dekaStudentSuccessFacetoFace,
  title = {Student {{Success}} in {{Face-to-Face}} and {{Distance Teleclass Environments}}: {{A}} Matter of Contact?},
  author = {{Teddi S. Deka} and {Patrick McMurray}},
  journal = {International Review of Research in Open and Distributed Learning},
  urldate = {2010-04-12},
  howpublished = {http://www.irrodl.org/index.php/irrodl/article/view/251/468},
  keywords = {drop out,dropout,student retention},
  file = {/Users/colin.madland/Zotero/storage/NPCTEZBU/468.html}
}

@misc{tedHowFightingBias2017,
  title = {How {{I}}'m Fighting Bias in Algorithms {\textbar} {{Joy Buolamwini}}},
  author = {{TED}},
  year = {2017},
  month = mar,
  urldate = {2022-03-16},
  abstract = {MIT grad student Joy Buolamwini was working with facial analysis software when she noticed a problem: the software didn't detect her face -- because the people who coded the algorithm hadn't taught it to identify a broad range of skin tones and facial structures. Now she's on a mission to fight bias in machine learning, a phenomenon she calls the "coded gaze." It's an eye-opening talk about the need for accountability in coding ... as algorithms take over more and more aspects of our lives.},
  keywords = {archived},
  annotation = {https://web.archive.org/web/20220316153137/https://www.youtube.com/watch?v=UG\_X\_7g63rY}
}

@article{tejaswiProctorNetAI2023,
  title = {Proctor Net: {{An AI}} Framework for Suspicious Activity Detection in Online Proctored Examinations},
  author = {Tejaswi, P. and Venkatramaphanikumar, S. and Venkata Krishna Kishore, K.},
  year = {2023},
  journal = {Measurement : journal of the International Measurement Confederation},
  volume = {206},
  pages = {112266},
  publisher = {Elsevier Ltd},
  address = {OXFORD},
  issn = {0263-2241},
  doi = {10.1016/j.measurement.2022.112266},
  abstract = {{$\bullet$}Design and development of an end-to-end AI online proctoring application to detect the suspicious behaviour of the examinee using multi features such as eye gaze and mouth aspect ratio etc.{$\bullet$}Usage of state-of-the-art methods such as Attentive Net and Hour-glass model with Proctor-Net for analysing mischievous behaviour of the examinee.{$\bullet$}Performance evaluation of the proposed model is carried on various datasets including Labelled Faces in the Wild, Unity Eyes and Customized Proctoring Dataset under various scenarios include face recognition, Eye lid registration along with hyper parameter tuning. Due to recent pandemic and other factors, global Education System transiting from traditional paradigm to online paradigm in learning as well as assessment. Online proctored examinations have ensured continuity in assessing learners in award of various global certifications and university degrees. Traditional human proctored examination requires huge infrastructure, human resources, effort, and physical presence of examinees. To overcome these limitations, an automated AI-based proctoring system ``Proctor Net'' proposed in this work for detecting suspicious behavior of the examinee. The proposed system captures live video of the examinee and generate alerts based on three aspects, 1. Examinee Recognition, 2. Eye-gaze Tracking, and 3. Mouth Opening Detection. In first phase, Proctor Net recognizes examinee faces using inception-Resnet v1 blocks. In next phase, the Proctor Net calculates the pitch and yaw of the authenticated examinee face from the spatial landmarks extracted by hour-glass model. Further, Mouth Aspect Ratio was verified to check if examinee is speaking to others. The proposed model generate alters to proctor if found any deviation in examinee's behavior. The proposed Proctor Net is evaluated using standard data sets such as Labelled Faces in the wild Dataset (LFW), Unity Eyes Dataset and real time data - ``Proctor Dataset'' with various types of malpractices. Extensive experimentation is carried out and results demonstrate that proposed work with the combination of Inception-Resnet-v1 blocks with Hourglass modules is more accurate with an accuracy rate of 91\%, making it reliable and robust.},
  keywords = {Analysis,Biometry,Engineering,Engineering Multidisciplinary,Eye-gaze tracking,Face Recognition,Instruments & Instrumentation,Mouth Open Detection,Proctor Net Automated Online Proctoring,Science & Technology,Technology}
}

@article{tejeiroResearchBriefIndirect2019,
  title = {Research {{Brief Indirect Feedback}}: {{A Dialoguing Approach}} to {{Assessment}}},
  author = {Tejeiro, Ricardo and Vlachopoulos, Dimitrios and Edwards, Anthony and Campos, Estefania},
  year = {2019},
  journal = {Higher learning research communications},
  volume = {9},
  number = {1},
  pages = {1--8},
  publisher = {Scholarworks},
  address = {Joshua Tree},
  doi = {10.18870/hlrc.v9i1.444},
  abstract = {Although there is consensus in the current literature that feedback plays a fundamental role to student performance and learning, there is debate about what makes it effective. Particularly, some assessment instruments, like the National Student Survey in the United Kingdom, reveal that evaluation and feedback are systematically among the areas that students are less satisfied with. The aim of this article is to describe the indirect feedback technique, which was devised and used by the principle author in his previous tenure as a professor at the University of Cadiz in Spain and to reflect on how it can be applied to overcome some of the limitations presented in a different context of practice. It is argued that indirect feedback meets many of the principles of good practice (facilitation of self-assessment skills, delivery of quality information about the students' learning, encouragement of dialogue, and improvement of teaching).},
  langid = {english},
  keywords = {Essays,Feedback,Higher education,Learning,Principles,Psychology,Research methodology,Self evaluation,Students,Teachers,Teaching,Tutoring}
}

@article{tekirAlignmentIntendedEnacted2021,
  title = {Alignment of the {{Intended}}, {{Enacted}}, {{Received}} and {{Assessed Curriculum}} in {{EFL Pre-Service Measurement}} and {{Evaluation Education}}},
  author = {Tekir, Serpil},
  year = {2021},
  journal = {Education and Science},
  doi = {10/gmgbpz},
  abstract = {Recent research points out a problem regarding the pre-service assessment education given by English as a Foreign Language (EFL) programs in the national context. One factor contributing to the problem can be the poor alignment among program components as numerous teacher education researchers assert that alignment is a necessary condition for learning experiences and practices of pre-service teachers. Accordingly, in this study, the author examined the alignment among the components of the pre-service assessment course curriculum; that is, the intended, enacted, assessed, and received curricula. The study adopted a mixed-methods case study approach using both qualitative and quantitative data collection tools, and to examine the alignment among the curricula, an adaptation of Surveys of the Enacted Curriculum (SEC) alignment methodology was used. Data for the intended and assessed curricula were collected through curricular and assessment documents and analyzed through content analysis, while the data regarding the enacted and received curricula were collected through surveys with teacher educators and pre-service teachers and analyzed through descriptive statistics. In both cases, the data were transferred to matrices for further analysis. To calculate the alignment among each pair of curricula, Porter's alignment index formula was used. Results indicated that the pre-service assessment course curriculum has moderate to high alignment indices ranging from 0, 44 to 0, 78. The study found a strong alignment between the intended and enacted curricula and the assessed and received curricula but a moderate alignment between each pair of the intended and assessed; enacted and assessed; enacted and received and intended and received curricula. The results of this study serve to identify the points of misalignment within the pre-service assessment curriculum. The study concludes with implications for improving the alignment in teacher preparation and suggestions for future research on pre-service assessment education.},
  file = {/Users/colin.madland/Zotero/storage/9ISFYS3V/tekirAlignmentIntendedEnacted2021.pdf}
}

@article{tenaELearningAndalusianUniversity2016a,
  title = {E-{{Learning}} of {{Andalusian University}}'s {{Lecturers}}. {{Gender}}},
  author = {Tena, Rosal{\'i}a Romero and Almenara, Julio Cabero and Osuna, Julio Barroso},
  year = {2016},
  month = apr,
  journal = {Turkish Online Journal of Educational Technology - TOJET},
  volume = {15},
  number = {2},
  pages = {25--37},
  publisher = {Turkish Online Journal of Educational Technology - TOJET},
  issn = {1303-6521},
  abstract = {This study forms part of the research project: "Use of eLearning in Andalusian Universities: current status and analysis of good practice". Our research focuses on two fundamental areas: firstly, the Virtual Andalusian Campus (VAC) as defined in the Digital University project set up by the Andalusia's Regional Administration, and secondly an assessment of the technical and didactic potential of Learning Management Systems (LMS) for the teaching staff at these universities. The research was undertaken using a quantitative methodology which collected and analysed data through questionnaires to find out how eLearning is used by 1302 lecturers of different level of six different Andalusian{\textasciiacute}s university, and to assess their levels of satisfaction with it. The university teaching staff demonstrated positive attitudes towards the e-learning and b-learning process, the methods used, the support offered by the university, and the development programme. The research demonstrates the success of the programme, and shows that it promotes diversity within the university by making use of a variety of personal and professional factors. It also confirms that the majority of teaching staff at the universities do not consider the use of different platforms to be a problem, and that the success of the experience is dependent on the support and attitudes of the university. We found significant differences between the lecturers in terms of gender in two areas: male lecturers had more knowledge of the tools, and female lecturers made more use of them.},
  keywords = {College Faculty,Educational Technology,Electronic Learning,Foreign Countries,Gender Differences,Integrated Learning Systems,No DOI found,Questionnaires,Statistical Analysis,Teacher Attitudes,Teaching Methods,Technology Integration,Technology Uses in Education,Turkey}
}

@article{tenenbaumHowEffectivePeer2020,
  title = {How Effective Is Peer Interaction in Facilitating Learning? {{A}} Meta-Analysis.},
  shorttitle = {How Effective Is Peer Interaction in Facilitating Learning?},
  author = {Tenenbaum, Harriet R. and Winstone, Naomi E. and Leman, Patrick J. and Avery, Rachel E.},
  year = {2020},
  month = oct,
  journal = {Journal of Educational Psychology},
  volume = {112},
  number = {7},
  pages = {1303--1319},
  issn = {1939-2176, 0022-0663},
  doi = {10.1037/edu0000436},
  urldate = {2022-06-26},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/7U29QH6H/tenenbaumHowEffectivePeer2020.pdf}
}

@techreport{tennantWhatCanScholars2020,
  type = {Preprint},
  title = {What Can Scholars Learn from {{Open Source}} Software Communities during Pandemics},
  author = {Tennant, Jonathan and Crick, Tom},
  year = {2020},
  month = apr,
  institution = {SocArXiv},
  doi = {10.31235/osf.io/5kdbx},
  urldate = {2020-04-05},
  abstract = {When the SARS-CoV-2 outbreak began on January 31, 2020, no-one could have anticipated the impact that it would have on our scholarly communication and publishing systems. That is, perhaps, unless you work on open source software. Right now, global research communities are united to collaborate on solving the threat of the pandemic, sharing resources and knowledge more efficiently and effective than ever before, a process broadly described as `open scholarship' (Dunleavy, 2020). This is essentially akin to how free and open source software (FOSS) communities have been operating now for decades (Willinsky, 2005). Recently, we participated in a ``massively open online paper'', or MOOP, that explored the intersections between FOSS and open scholarship (Tennant, Agarwal, et al., 2020). Here, we want to summarise our key findings from that project, and place them in the context of the current outbreak. Critically, this pandemic shows us that many of the pervasive and systemic issues surrounding the evaluation, valuation, use and operationalisation of ``openness'' in scholarship can be extremely easily bypassed when the social demand and urgency is there, thus showing that the primary barriers towards open scholarship are inherently political and not technical.},
  file = {/Users/colin.madland/Zotero/storage/MBRBPEXR/tennantWhatCanScholars2020.pdf}
}

@incollection{teoApplyingStructuralEquation2013,
  title = {Applying {{Structural Equation Modeling}} ({{SEM}}) in {{Educational Research}}},
  booktitle = {Application of {{Structural Equation Modeling}} in {{Educational Research}} and {{Practice}}},
  author = {Teo, Timothy and Tsai, Liang Ting and Yang, Chih-Chien},
  editor = {Khine, Myint Swe},
  year = {2013},
  pages = {3--21},
  publisher = {SensePublishers},
  address = {Rotterdam},
  doi = {10.1007/978-94-6209-332-4_1},
  urldate = {2023-07-07},
  isbn = {978-94-6209-332-4},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/7P2F8ISQ/teoApplyingStructuralEquation2013.pdf}
}

@article{terasPostCovid19EducationEducation2020,
  title = {Post-{{Covid-19 Education}} and {{Education Technology}} `{{Solutionism}}': A {{Seller}}'s {{Market}}},
  shorttitle = {Post-{{Covid-19 Education}} and {{Education Technology}} `{{Solutionism}}'},
  author = {Ter{\"a}s, Marko and Suoranta, Juha and Ter{\"a}s, Hanna and Curcher, Mark},
  year = {2020},
  month = jul,
  journal = {Postdigital Science and Education},
  issn = {2524-485X, 2524-4868},
  doi = {10/gg49t7},
  urldate = {2020-07-18},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/F4WTH5JM/terasPostCovid19EducationEducation2020.pdf;/Users/colin.madland/Zotero/storage/SMIZ8YIT/terasPostCovid19EducationEducation2020.pdf}
}

@article{tessaroFiveIndigenizingOnline2018,
  title = {The {{Five R}}'s for {{Indigenizing Online Learning}}: {{A Case Study}} of the {{First Nations Schools}}' {{Principals Course}}},
  author = {Tessaro, Danielle and Restoule, Jean-Paul and Gaviria, Patricia and Flessa, Joseph and Lindeman, Carlana and {Scully-Stewart}, Coleen},
  year = {2018},
  journal = {Canadian Journal of Native Education},
  volume = {40},
  number = {1},
  pages = {125--143},
  abstract = {This article focuses on the creation, implementation, experiences, and research sur- rounding the first online professional development course for principals of First Na- tions schools across Canada, named the  First  Nations Schools' Principals Course (FNSPC). First, we describe the contexts, goals, and designing of the FNSPC. Second, we outline the complexities of bringing Indigenous values into an online educational space. Lastly, we  describe how  using  the  Five  R's (Kirkness \& Barnhardt, 2001; Restoule, 2008) of respect, relevance, reciprocity, responsibility, and relationships re- casts the challenges of Indigenizing online education into opportunities for spaces of traditional and non-traditional Indigenous learning through the FNSPC.},
  file = {/Users/colin.madland/Zotero/storage/HG97EIHK/tessaroFiveIndigenizingOnline2018.pdf}
}

@techreport{TestSpecificationsRedesigned2015,
  title = {Test {{Specifications}} for the {{Redesigned SAT}}},
  year = {2015},
  pages = {210},
  institution = {The College Board},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/KD2GST6Q/TestSpecificationsRedesigned2015.pdf}
}

@article{thakkarIntroductionStructuralEquation2020,
  title = {Introduction to {{Structural Equation Modelling}}},
  author = {Thakkar, J.},
  year = {2020},
  month = jan,
  journal = {Structural Equation Modelling},
  doi = {10.1201/B11190-9},
  abstract = {Structural equation modelling (SEM) is multivariate quantitative technique employed to describe the relationships among observed variables. The technique helps the researcher to test or validate a theoretical model for theory testing and extension. The multivariate analysis is conducted with an objective to help the researcher for an in-depth explanatory analysis with a required statistical efficiency. A researcher is interested in investigating the constructs emerging out of sets of variables and the relationships among these constructs. This can be explained with an example such as a sales manager might be interested to investigate a phenomenon that behaviour and discipline of salesperson has a direct influence on sales volume. SEM enables the researcher to indulge into a deeper inquiry through a process of scientific hypothesis testing and extend the present body of knowledge by discovering complex relationships among constructs. This book provides a comprehensive understanding on SEM with illustrative applications in two softwares -- AMOS, SPSS and R.}
}

@book{thakkarStructuralEquationModelling2020,
  title = {Structural {{Equation Modelling}}: {{Application}} for {{Research}} and {{Practice}} (with {{AMOS}} and {{R}})},
  shorttitle = {Structural {{Equation Modelling}}},
  author = {Thakkar, Jitesh},
  year = {2020},
  series = {Studies in {{Systems}}, {{Decision}} and {{Control}}},
  volume = {285},
  publisher = {Springer Singapore},
  address = {Singapore},
  doi = {10.1007/978-981-15-3793-6},
  urldate = {2023-08-17},
  isbn = {978-981-15-3792-9 978-981-15-3793-6},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/8MBS5T7P/thakkarStructuralEquationModelling2020.pdf}
}

@article{thangCreatingMaintainingOnline2011,
  title = {Creating and {{Maintaining Online Communities}} of {{Practice}} in {{Malaysian Smart Schools}}: {{Challenging Realities}}},
  author = {Thang, Siew Ming and Hall, Carol and Murugaiah, Puvaneswary and Azman, Hazita},
  year = {2011},
  journal = {Educational Action Research},
  volume = {19},
  number = {1},
  pages = {87--105},
  abstract = {Wenger describes an educational community of practice (CoP) as a group of professionals who share a passionate concern for practice-based issues and who voluntarily choose to deepen their knowledge, understanding and skills through collaborative and critical dialogue. Peer collaboration of this kind, which involves social interaction, reflection and a critical engagement with practice issues, has been widely suggested to be effective for teacher learning and professional development. The online continuing professional development for teachers (e-CPDelT) Vision 2020 model outlined here aims to bring about innovation in practice through an online or virtual CoP (VCoP). Twenty Malaysian teachers in five Smart Schools were invited to take part in a Higher Education (HE) project, funded by one of the main universities in Malaysia. By participating collaboratively in this CoP, it was anticipated that the teachers would form an active online CoP that would lead in turn to innovation in teaching and learning practices in the schools. An action research approach was used in tracing the developmental process of the three subject-based CoPs (namely, Mathematics, Science and English) and identifying challenges faced by the higher education institution (HEI) project team in fostering the active participation and commitment of the teachers. Preliminary data generated from mentor forum discussion, focus groups and blogs suggested that low levels of participation in VCoP activities were a result of low levels of trust and social affiliation, performance anxiety, time pressure and failure to see the relevance of online interaction as directly related to their individual needs as practitioners. Approaches to remediating these challenges and promoting more authentic teacher engagement are outlined. (Contains 2 tables and 1 figure.)},
  keywords = {Action,Change,Colleges,communities,Cooperation,Countries,Development,Education,EDUCATIONAL,Electronic,English,Faculty,Focus,Foreign,Groups,Higher,in,Information,Innovation,instruction,Interaction,INTERPERSONAL,LEARNING,Malaysia,Mathematics,Mentors,of,Partnerships,practice,Publishing,reflection,Relationship,Research,Science,Sites,technology,Web},
  annotation = {Routledge. Available from: Taylor \& Francis, Ltd. 325 Chestnut Street Suite 800, Philadelphia, PA 19106. Tel: 800-354-1420; Fax: 215-625-2940; Web site: http://www.tandf.co.uk/journals Accession Number: EJ915435; Acquisition Information: Routledge. Available from: Taylor \& Francis, Ltd. 325 Chestnut Street Suite 800, Philadelphia, PA 19106. Tel: 800-354-1420; Fax: 215-625-2940; Web site: http://www.tandf.co.uk/journals; Language: English; Education Level: Higher Education; Reference Count: 44; Journal Code: MAR2011; Level of Availability: Not available from ERIC; Publication Type: Journal Articles; Publication Type: Reports - Descriptive; Entry Date: 2011}
}

@misc{theriault197GreedyBosses,
  title = {197: {{Greedy}} Bosses, Game Cheats, and Virtual Beheadings},
  shorttitle = {197},
  author = {Theriault, Carole, Graham Cluley},
  journal = {Smashing Security},
  urldate = {2020-09-24},
  abstract = {Why are Zoom and Twitter making some people disappear? How are Counter-Strike: Global Offensive cheats getting their just desserts? And the founder of a anti cyber-fraud firm is charged with fraud.},
  howpublished = {http://www.smashingsecurity.com/197},
  file = {/Users/colin.madland/Zotero/storage/M5YTBQUW/197.html}
}

@misc{thetruthandreconciliationcommissionofcanadaTruthReconciliationCommission2015,
  title = {Truth and {{Reconciliation Commission}} of {{Canada}}: {{Calls}} to {{Action}}},
  author = {{The Truth {and} Reconciliation Commission of Canada}},
  year = {2015},
  publisher = {{Truth and Reconciliation Commission of Canada}},
  urldate = {2018-11-19},
  file = {/Users/colin.madland/Zotero/storage/S2G4Z38B/thetruthandreconciliationcommissionofcanadaTruthReconciliationCommission2015.pdf}
}

@techreport{theviralityprojectMemesMagnetsMicrochips2022,
  title = {Memes, {{Magnets}} and {{Microchips}}: {{Narrative}} Dynamics around {{COVID-19}} Vaccines},
  shorttitle = {Memes, {{Magnets}} and {{Microchips}}},
  author = {The Virality Project},
  year = {2022},
  institution = {Stanford Digital Repository},
  doi = {10.25740/MX395XJ8490},
  urldate = {2022-04-02},
  abstract = {The global COVID-19 pandemic and subsequent vaccine rollout created unprecedented challenges in the online information environment. Authority figures and institutions, operating with incomplete facts and emerging consensus, struggled to communicate with the public and to assess the mis- and disinformation narratives that required response. The public, looking for accurate health information, confronted a glut of claims; the narratives with the largest reach or highest engagement were not necessarily the most reliable. Rumors, misinformation, and disinformation spread rapidly. Social media companies sought to surface accurate information about the pandemic and vaccines, but faced a challenge: What should they curate or amplify in the absence of clear scientific consensus? How should they identify, and moderate, false and misleading claims? It was against this backdrop that the Virality Project was formed. Drawing on scholarship documenting the who, what, and how of the anti-vaccine movement, the Virality Project identified four categories of well-established narratives likely to emerge as key themes in the COVID-19 vaccine rollout: (1) safety, (2) efficacy and necessity, (3) development and distribution, and (4) conspiracy theory. This report details the narratives, actors, and tactics that shaped COVID-19 vaccine conversations within those themes from February to August 2021. In addition, it assesses the interplay between this content and social media platform policies, surfacing the recurring narratives that attempt to question the safety of vaccines and discourage vaccine uptake. Finally, drawing on these observations, the Virality Project team offers policy recommendations for academics, public health experts, government entities, and tech platforms with the goal of engendering a whole-of-society effort to address health misinformation.},
  collaborator = {Cryst, Elena and DiResta, Renee and Meyersohn, Lily},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
  keywords = {virality vaccine hesitancy social media covid-19 infodemic misinformation disinformation},
  file = {/Users/colin.madland/Zotero/storage/LE8QCUAI/theviralityprojectMemesMagnetsMicrochips2022.pdf}
}

@article{thibodeauxGraduateStudentsPerceptions2020,
  title = {Graduate {{Students}}' {{Perceptions}} of {{Factors That Contributed}} to {{ePortfolios Persistence}} beyond the {{Program}} of {{Study}}},
  author = {Thibodeaux, Tilisa and Harapnuik, Dwayne and Cummings, Cynthia and Dolce, Jackson},
  year = {2020},
  month = jan,
  journal = {International Journal of ePortfolio},
  volume = {10},
  number = {1},
  pages = {19--32},
  publisher = {International Journal of ePortfolio},
  issn = {2157-622X},
  abstract = {This study examined the factors that contributed to ePortfolio persistence in an online program from data collected in 2016 (Thibodeaux, Harapnuik, \& Cummings, 2017) and again in 2018. A myriad of research points to learning portfolios as having transformational power; however, many traditional instructional models that use ePortfolios in higher education downplay the significance and transformational learning that effective ePortfolios offer. To research this phenomenon, a convergent, parallel mixed-methods design was used to gather data from an online program in order to explore the learning conditions and context of ePortfolio usage over multiple years. Results indicated that real-world projects and authentic artifacts, the ePortfolio used as a career tool, and management of the ePortfolio were common factors identified in studies that contributed to continued use of the ePortfolio. Findings also revealed that learner autonomy, control, and agency, as well as continued opportunities for choice and voice, led to increased appreciation and ownership of the ePortfolio beyond the program of study.},
  keywords = {Authentic Learning,Career Development,College Graduates,Educational Technology,Electronic Learning,Graduate Students,Masters Programs,No DOI found,Persistence,Personal Autonomy,Portfolio Assessment,Portfolios (Background Materials),Student Attitudes,Transformative Learning}
}

@misc{ThisWhyTwitter,
  title = {This {{Is Why Twitter}}'s {{Algorithm Appears To Have A Race Problem}}},
  journal = {IFLScience},
  urldate = {2020-09-22},
  abstract = {As we've learned (or apparently not) time and time again, AI and machine learning technology have a racism problem. From~soap dispensers~that don't registe},
  howpublished = {https://www.iflscience.com/technology/this-is-why-twitters-algorithm-appears-to-have-a-race-problem/},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/X4MSW2QX/this-is-why-twitters-algorithm-appears-to-have-a-race-problem.html}
}

@article{thomasElaboratingFrameworkCommunicating2019,
  title = {Elaborating a Framework for Communicating Assessment Aims in Higher Education},
  author = {Thomas, Damon and Moore, Robbie and Rundle, Olivia and Emery, Sherridan and Greaves, Robyn and {\noopsort{riele}}{te Riele}, Kitty and Kowaluk, Andy},
  year = {2019},
  journal = {Assessment and evaluation in higher education},
  volume = {44},
  number = {4},
  pages = {546--564},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0260-2938},
  doi = {10/gmb8hw},
  abstract = {Assessment is a central feature of student learning in higher education and has a strong influence on the student experience. Accordingly, the appropriate communication of assessment aims is a priority for all higher education institutions. This study proposes an analytical framework for the interpretation and creation of assessments across higher education disciplines. The framework suggests that assessments can be categorised according to rhetorical purposes, formats, modes and group arrangements. Assessments from three degree programmes at one Australian university are analysed using the framework to show its usefulness in classifying and evaluating task components and generating broad images of degrees based on assessment regimes. We draw on these practical applications to explain and compare discipline-specific qualities of each degree, and argue that the framework might enhance the communication of assessment aims to benefit higher education stakeholders.},
  keywords = {Academic Achievement,Assessment design,assessment framework,College Faculty,Communication,Education & Educational Research,Educational evaluation,Evaluation Methods,Foreign Countries,higher education,Learning,Models,Social Sciences,Undergraduate Students}
}

@article{thomasYouNeedBe,
  title = {'{{You}} Need to Be Flexible Normally, and Here, Even More Flexible': Teaching Academics' Experiences and Perceptions of {{Covid-19}} Disruptions to Teaching, Learning, and Assessment},
  author = {Thomas, M and Yager, Z and Quinton, {\relax HW}},
  journal = {Journal of Further and Higher Education},
  issn = {0309-877X},
  doi = {10.1080/0309877X.2022.2102415},
  abstract = {Alongside unprecedented shifts in health care, and widespread lockdowns and stay-at-home orders, the Covid-19 pandemic brought an almost immediate shift towards digitally supported remote delivery in higher education. This paper explores the experiences and perceptions of 15 teaching academics from five universities in Victoria, Australia during this time. Semi-structured interviews were conducted with academics after they had been delivering teaching, learning and assessment remotely for a six-month period. The analysis showed that while the remote delivery environment enhanced many aspects of teaching and learning, including agile and adaptable academic skill-sets, there were challenges. The academics' sophisticated teaching skills and experience, that were intuitively relied upon in the face-to-face setting, did not always translate to the online environment. In particular, this was noticed in terms of the relational approach to teaching and learning, including relationships, rapport, and connectedness within classes, and the absence of social formative assessment cues to evaluate learners' understandings. Students were not asking questions in class and required additional support from academics, which subsequently increased already overburdened workloads. After considering the findings of our work and others, we provide recommendations to support high quality teaching and learning in digitally supported remote delivery.},
  langid = {english},
  keywords = {assessment,Covid-19,higher education,learning,online learning,SUCCESS,teaching,TECHNOLOGY,WORKLOAD}
}

@inproceedings{thompsonDistanceEducationDropout,
  title = {Distance Education Drop-out: {{What}} Can We Do?},
  booktitle = {Teaching and {{Learning Forum}} 1997},
  author = {Thompson, Eileen},
  editor = {Pospisil, Romana and Willcoxson, Lesley}
}

@article{thompsonEducationalStatisticsAuthentic2009,
  title = {Educational {{Statistics Authentic Learning CAPSULES}}: {{Community Action Projects}} for {{Students Utilizing Leadership}} and {{E-based Statistics}}},
  author = {Thompson, Carla J.},
  year = {2009},
  month = mar,
  journal = {Journal of Statistics Education},
  volume = {17},
  number = {1},
  publisher = {Taylor \& Francis},
  issn = {null},
  doi = {10.1080/10691898.2009.11889508},
  abstract = {Since educational statistics is a core or general requirement of all students enrolled in graduate education programs, the need for high quality student engagement and appropriate authentic learning experiences is critical for promoting student interest and student success in the course. Based in authentic learning theory and engagement theory graduate educational statistics CAPSULES (Community Action Projects for Students Utilizing Leadership and E-based Statistics) engage graduate students in service-learning projects involving managing, conducting, and delivering authentic data-driven research. The community action projects utilizing leadership and e-based statistics skills are spearheaded by a university-based Community Outreach Research and Authentic Learning (CORAL) Center. The graduate educational statistics CAPSULES program includes: (1) restructuring educational statistics courses to include real-world active learning and authentic assessment; (2) providing opportunities for graduate students to engage in team-driven quantitative research prior to the thesis or dissertation experience with projects generated from community agencies/educational institutions; and (3) connecting graduate students with community action projects as research managers, leaders, and presenters. Highlights of initial formative and summative student outcomes are presented relative to specific examples of student-directed CAPSULES. Student outcomes from the CAPSULES program indicate positive increases in graduate students' attitudes toward statistics and research, and students' leadership and project management skills.}
}

@article{thompsonEvaluationKnowlaOnline2016,
  title = {Evaluation of {{Knowla}}: {{An Online Assessment}} and {{Learning Tool}}},
  author = {Thompson, Meredith Myra and Braude, Eric John},
  year = {2016},
  journal = {Journal of Educational Computing Research},
  volume = {54},
  number = {4},
  pages = {483--512},
  publisher = {SAGE Publications},
  address = {Los Angeles, CA},
  issn = {0735-6331},
  doi = {10/ggrgxh},
  abstract = {The assessment of learning in large online courses requires tools that are valid, reliable, easy to administer, and can be automatically scored. We have evaluated an online assessment and learning tool called Knowledge Assembly, or Knowla. Knowla measures a student's knowledge in a particular subject by having the student assemble a set of arbitrarily sized scrambled fragments into a logical order using a web-based interface. Instructors can use Knowla to create assessments and grading criteria. Initial testing of the tool indicates that the measure is reliable and that students access critical thinking skills as they engage with the material. Additionally, testing demonstrates that Knowla can be used to assess learning gains in a subject area. Knowla also shows promise as a learning tool and has already been integrated into university courses.},
  keywords = {ABILITY,ACT Assessment,Administration,assessment,automatic scoring,College Entrance Examinations,Computer Assisted Testing,Correlation,Critical Thinking,EDUCATION & EDUCATIONAL RESEARCH,Electronic Learning,Flesch Kincaid Grade Level Formula,Flesch Reading Ease Formula,Grade Point Average,Graduate Students,Higher Education,INFORMATION,Instructional Materials,interface design,Interviews,Massachusetts,MEMORY,mixed methods,Mixed Methods Research,Multiple Regression Analysis,National Assessment of Educational Progress,National Competency Tests,online assessment,Online Courses,Online Surveys,Pretests Posttests,Readability,Readability Formulas,Reading Comprehension,RECALL,Regression (Statistics),SAT (College Admission Test),Schools of Education,scrambled text,Teaching Methods,TEXT COMPREHENSION,Thinking Skills,Undergraduate Students,VALIDITY,Writing Skills}
}

@article{thompsonMarksShouldNot2016,
  title = {Marks {{Should Not Be}} the {{Focus}} of {{Assessment}} -- {{But How Can Change Be Achieved}}?},
  author = {Thompson, Darrall G},
  year = {2016},
  month = sep,
  journal = {Journal of Learning Analytics},
  volume = {3},
  number = {2},
  pages = {193--212},
  issn = {1929-7750},
  doi = {10.18608/jla.2016.32.9},
  urldate = {2022-09-16},
  abstract = {This paper attempts to address the possibility of real change after a hundred years of exam-based assessments that produce a single mark or grade as feedback on students' progress and abilities. It uses design thinking and a reframing of the assessment space to foreground an attribute-based approach that retains the diversity of aspects of a student's performance across subject boundaries. There are a number of rationales and concepts built into this approach that aim to divert staff and student focus from marks, content delivery, and retention, towards the development of knowledge literacies, conceptual frameworks, and a broad range of personal qualities and skills. Web-based software (REVIEW) developed and refined for more than a decade to facilitate this approach retains categorised student progress data through the day-to-day criterion-referenced marking of assignments and exams. Education research cited proposes that institutions should engage students as a partner in their personal and professional development rather than as a customer buying a degree. It is suggested and illustrated in this paper that the use of self-assessment and visual feedback on different categories of progress is part of the key to forming such a partnership.},
  file = {/Users/colin.madland/Zotero/storage/C77PCD4V/thompsonMarksShouldNot2016.pdf}
}

@incollection{thompsonTeachersBeliefsConceptions1992,
  title = {Teachers' Beliefs and Conceptions: {{A}} Synthesis of the Research},
  booktitle = {Handbook of Research on Mathematics Teaching and Learning},
  author = {Thompson, A.G.},
  editor = {Grouws, Douglas A.},
  year = {1992},
  pages = {127--146},
  publisher = {Macmillan},
  address = {New York}
}

@book{thorndikeElementsPsychology1905,
  title = {The {{Elements}} of Psychology},
  author = {Thorndike, Edward Lee},
  year = {1905},
  publisher = {A.G. Seiler},
  address = {New York},
  langid = {english}
}

@misc{ThreePapersPhD,
  title = {The 'three Papers' {{PhD}} Thesis: A Guide for the Perplexed},
  journal = {Athens University of Economics and Business},
  urldate = {2022-01-20},
  howpublished = {https://www.dept.aueb.gr/sites/default/files/deos/3\_paper\_phd\_guide.pdf},
  keywords = {archived},
  annotation = {https://web.archive.org/web/20210418090608/https://www.dept.aueb.gr/sites/default/files/deos/3\_paper\_phd\_guide.pdf},
  file = {/Users/colin.madland/Zotero/storage/WHN627FI/ThreePapersPhD.pdf}
}

@article{thumvichitEnglishLanguageTeaching2021,
  title = {English {{Language Teaching}} in {{Times}} of {{Crisis}}: {{Teacher Agency}} in {{Response}} to the {{Pandemic-Forced Online Education}}},
  author = {Thumvichit, Athip},
  year = {2021},
  journal = {Teaching English with Technology},
  volume = {21},
  number = {2},
  pages = {14--37},
  issn = {EISSN-1642-1027},
  abstract = {Teacher agency occurs when teachers demonstrate a capacity to solve pedagogical and curriculum challenges. This article delves into how tertiary English teachers in Thailand practice their agency in response to the abrupt conversion to online teaching amid the COVID-19 pandemic. This study drew on teachers' responses to a questionnaire (n=162) and semi-structure interviews (n=3) to identify their positioning and agentic actions. The results suggest that teachers' positioning as being professionally responsible for students' learning outcomes remains intact, even though the situation restricted them from going beyond their fundamental responsibilities. From a pedagogical standpoint, teachers' agentic actions identified were endeavoring to create an interactive learning environment; implementing social media platforms to compensate for the loss of face-to-face communication; working with students to adjust their teaching practices; promoting autonomous learning; and incorporating formative assessment approaches. Teachers might find themselves struggling to achieve their pedagogical goals, but once they become familiar with the new learning environment and master suitable teaching methods, online learning can be a viable option for formal language education, even in the normal situation.},
  langid = {english},
  keywords = {Asynchronous Communication,COVID-19,Distance Education,Electronic Learning,Emergency Programs,English (Second Language),Foreign Countries,Formative Evaluation,Higher Education,Language Teachers,No DOI found,Pandemics,Professional Autonomy,Second Language Instruction,Summative Evaluation,Synchronous Communication,Teacher Attitudes,Teaching Methods}
}

@article{tigelaarDevelopmentValidationFramework2004,
  title = {The Development and Validation of a Framework for Teaching Competencies in Higher Education},
  author = {Tigelaar, Dineke E.H. and Dolmans, Diana H.J.M. and Wolfhagen, Ineke H.A.P. and {\noopsort{vleuten}}{van der Vleuten}, Cees P.M.},
  year = {2004},
  month = sep,
  journal = {Higher Education},
  volume = {48},
  number = {2},
  pages = {253--268},
  issn = {0018-1560},
  doi = {10.1023/B:HIGH.0000034318.74275.e4},
  urldate = {2023-03-20},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/BGCNJMX4/tigelaarDevelopmentValidationFramework2004.pdf}
}

@book{tigersAssessingOnlineFacilitationND,
  title = {Assessing {{Online Facilitation Instrument}}},
  author = {TIGERS},
  year = {ND},
  volume = {2011},
  publisher = {California State University Center for Distributed Learning}
}

@book{tigersFacilitationActivityRecordND,
  title = {Facilitation {{Activity Record}}},
  author = {TIGERS},
  year = {ND},
  volume = {2011},
  publisher = {California State University Center for Distributed Learning}
}

@article{tightPositivityBiasHigher2022,
  title = {Positivity Bias in Higher Education Research},
  author = {Tight, Malcolm},
  year = {2022},
  month = mar,
  journal = {Higher Education Quarterly},
  pages = {hequ.12388},
  issn = {0951-5224, 1468-2273},
  doi = {10.1111/hequ.12388},
  urldate = {2022-12-31},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/7VVDSIZQ/tightPositivityBiasHigher2022.pdf}
}

@article{timmisRethinkingAssessmentDigital2016,
  title = {Rethinking Assessment in a Digital Age: Opportunities, Challenges and Risks},
  shorttitle = {Rethinking Assessment in a Digital Age},
  author = {Timmis, Sue and Broadfoot, Patricia and Sutherland, Rosamund and Oldfield, Alison},
  year = {2016},
  month = jun,
  journal = {British Educational Research Journal},
  volume = {42},
  number = {3},
  pages = {454--476},
  issn = {01411926},
  doi = {10/gftz95},
  urldate = {2021-01-15},
  abstract = {Whilst it is frequently argued that assessment sits at the heart of the learning process, in practice assessment often remains narrowly focused on qualifications and reporting achievements, driven by institutional and societal aspirations and tensions such as accountability and economic well being. Yet, the need for assessment to account for the knowledge, skills, dispositions and attitudes necessary to equip young people for a changing and increasingly digital world is also increasingly acknowledged. Based on our recent research review, this article critically examines the role of technology enhanced assessment (or TEA). We argue that whilst technology offers many potentially creative opportunities for innovation and for rethinking assessment purposes, there are also numerous risks and challenges. In particular we highlight ethical concerns over social exclusion and new forms of digital dividedness and the increasing risks associated with big data and the rise of learning analytics. Finally, we note that much research and innovation happens in silos, where policy, research and practice on assessment, technology enhanced assessment and ethical and political concerns are not linked up. We conclude that there needs to be a much more wide-ranging, critical and nuanced discussion in educational and policy circles so that debates about the potential of technology can be linked to improving assessment in the light of the range of social and political challenges that such progress presents. We end with some critical questions for policy, practice and research communities which we offer as a starting point for future thinking and ways forward.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/DWBPGFZV/timmisRethinkingAssessmentDigital2016.pdf}
}

@incollection{tinocaConceptualFrameworkEassessment2014,
  title = {A Conceptual Framework for E-Assessment in Higher Education: {{Authenticity}}, Consistency, Transparency, and Practicability},
  shorttitle = {A Conceptual Framework for E-Assessment in Higher Education},
  booktitle = {Handbook of Research on Transnational Higher Education},
  author = {Tinoca, Lu{\'i}s and Pereira, Alda and Oliveira, Isolina},
  year = {2014},
  pages = {652--673},
  publisher = {IGI Global},
  file = {/Users/colin.madland/Zotero/storage/7BIVH4M2/tinocaConceptualFrameworkEassessment2014.pdf;/Users/colin.madland/Zotero/storage/3TGG7QDT/78143.html}
}

@incollection{tinocaConceptualFrameworkEAssessment2014a,
  title = {A {{Conceptual Framework}} for {{E-Assessment}} in {{Higher Education}}: {{Authenticity}}, {{Consistency}}, {{Transparency}}, and {{Practicability}}},
  booktitle = {Handbook of {{Research}} on {{Transnational Higher Education}}:},
  author = {Tinoca, Lu{\'i}s and Pereira, Alda and Oliveira, Isolina},
  editor = {Mukerji, Siran and Tripathi, Purnendu},
  year = {2014},
  series = {Advances in {{Higher Education}} and {{Professional Development}}},
  publisher = {IGI Global},
  doi = {10.4018/978-1-4666-4458-8},
  urldate = {2024-02-07},
  isbn = {978-1-4666-4458-8 978-1-4666-4459-5},
  file = {/Users/colin.madland/Zotero/storage/HYG8NC46/tinocaConceptualFrameworkEAssessment2014a.pdf}
}

@article{tinocaPromotingEassessmentQuality2012,
  title = {Promoting E-Assessment Quality in Higher Education: A Case Study in Online Professional Development},
  shorttitle = {Promoting E-Assessment Quality in Higher Education},
  author = {Tinoca, Lu{\'i}s},
  year = {2012},
  journal = {ICICTE 2012 proceedings},
  pages = {213--223},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/L9E44KFK/tinocaPromotingEassessmentQuality2012.pdf}
}

@article{tintoClassroomsCommunitiesExploring1997,
  title = {Classrooms as {{Communities}}: {{Exploring}} the {{Educational Character}} of {{Student Persistence}}},
  author = {Tinto, Vincent},
  year = {1997},
  journal = {The Journal of Higher Education},
  volume = {68},
  number = {6},
  pages = {599--623},
  abstract = {Data from a study of a learning community program in an urban community college are used to explore the educational character of student persistence. Analyses reveal that classroom activities influence student persistence by changing the way students and faculty interact within and beyond the classroom setting. Implications for current theories of persistence are discussed and a modified theory proposed.}
}

@book{tintoCollegesCommunitiesTaking2010,
  title = {Colleges as Communities: {{Taking}} Research on Student Persistence Seriously},
  author = {Tinto, Vincent},
  year = {July 21, 2010 1998},
  volume = {21},
  publisher = {Association for the Study of Higher Education},
  abstract = {Few fields in higher education have received as much attention as student persistence. Over the past twenty years, we have assembled a wide-ranging database of studies covering a variety of institutional settings and types of students. At the same time, we have developed and modified a theory of student persistence that has repeatedly been shown to help explain the causal processes that lead students to leave their institutions prior to degree completion. Though far from complete, this body of research and theory has resulted in a growing consensus among researchers and theorists alike about the major forces shaping student persistence. On a number of points, it now can be said that we do know what factors influence persistence.},
  keywords = {Collaborative Learning,College,persistence}
}

@article{tliliWhatIfDevil2023,
  title = {What If the Devil Is My Guardian Angel: {{ChatGPT}} as a Case Study of Using Chatbots in Education},
  shorttitle = {What If the Devil Is My Guardian Angel},
  author = {Tlili, Ahmed and Shehata, Boulus and Adarkwah, Michael Agyemang and Bozkurt, Aras and Hickey, Daniel T. and Huang, Ronghuai and Agyemang, Brighter},
  year = {2023},
  month = feb,
  journal = {Smart Learning Environments},
  volume = {10},
  number = {1},
  pages = {15},
  issn = {2196-7091},
  doi = {10.1186/s40561-023-00237-x},
  urldate = {2023-09-23},
  abstract = {Abstract             Artificial Intelligence (AI) technologies have been progressing constantly and being more visible in different aspects of our lives. One recent phenomenon is ChatGPT, a chatbot with a conversational artificial intelligence interface that was developed by OpenAI. As one of the most advanced artificial intelligence applications, ChatGPT has drawn much public attention across the globe. In this regard, this study examines ChatGPT in education, among early adopters, through a qualitative instrumental case study. Conducted in three stages, the first stage of the study reveals that the public discourse in social media is generally positive and there is enthusiasm regarding its use in educational settings. However, there are also voices who are approaching cautiously using ChatGPT in educational settings. The second stage of the study examines the case of ChatGPT through lenses of educational transformation, response quality, usefulness, personality and emotion, and ethics. In the third and final stage of the study, the investigation of user experiences through ten educational scenarios revealed various issues, including cheating, honesty and truthfulness of ChatGPT, privacy misleading, and manipulation. The findings of this study provide several research directions that should be considered to ensure a safe and responsible adoption of chatbots, specifically ChatGPT, in education.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/EK5Q9HXQ/tliliWhatIfDevil2023.pdf}
}

@article{todorovaCoCreatedLearningDecolonizing2016,
  title = {Co-{{Created Learning}}: {{Decolonizing Journalism Education}} in {{Canada}}},
  author = {Todorova, Miglena},
  year = {2016},
  journal = {Canadian Journal of Communication},
  volume = {41},
  number = {4},
  pages = {673},
  issn = {0705-3657},
  doi = {10.22230/cjc.2016v41n4a2970},
  abstract = {For example, Hanusch (2013) published a study titled "Charting a Theoretical Framework for Examining Indigenous Journalism Culture." The singular form of the noun "journalism" in the title obliterates the multiple and diverse philosophies and practices embodied by Indigenous media workers in countries worldwide. Despite these vast differences, Hanusch reduces Indigenous journalisms to the following shared dimensions: dedication to community service, language preservation, attachment to culture and tradition, and counter-narrative to mainstream media. Based on these characteristics, Indigenous journalisms are presented in essentialist terms as always interventionist and always culturally specific. Hanusch refers to Indigenous media and journalisms as political projects whose "core reason for existence" is "speaking back," "providing a sense of empowerment," and being a "counter-narrative" (p. 86) to mainstream media and its misrepresentations of Indigenous peoples. The underlying notion behind these essentializing characterizations is that of two separate public spheres : Indigenous and non-Indigenous, with Indigenous journalism catering only to the former. Moreover, these characterizations are tied to the dichotomies of active/neutral, objectivist/interventionist, and truth/subjectivity mentioned above. Indigenous journalism can only be considered cultural and activist when compared with the universal, neutral, and professional journalism attributed to Western cultures and liberal democracies. The act of comparison thus constitutes a process of relational self-definition of Western Self against Indigenous Other. As mentioned above, the special topic course Reporting in Indigenous Communities created by [Duncan McCue] at the University of British Columbia in Canada was inspired by similar programs in Australia. McCue explains in an interview that the course addresses two issues: 1) under-representation of Indigenous peoples in the media, and 2) stereotypes such as "Native as victim," "Native as warrior," and more recently, "Native as incompetent manager" ([McKeon], 2011, para. 5). To counter these stereotypes, McCue designed the course as a graduate, full-term, "intense study of aboriginal people in the media" and "a lot of working hands-on with aboriginal people" (paras. 2-3) on topical issues such as health, education, Indigenous youth, and water. The course also addresses the "discomfort" of non-Indigenous reporters and their concerns about how to "ask tough questions of chiefs" without "being seen as racist or having a bias" (para. 11). The empowering effects of the course on non-Indigenous students are illustrated by comments from two non-Indigenous female students, who referred to gaining the trust of Indigenous spiritual dancers and being able to access sacred locations of the St{\'o}:lo communities in the Fraser Valley (Bergen \& Kelly, 2013). The students used tactics such as transparency and perseverance to report on this "very secretive spiritual tradition" (introduction and para. 1) and presented the story on CBC Radio, thus launching their professional careers.},
  keywords = {Audiences,Canada,Colonialism,Communication,Community,Curricula,Education,Genealogy,Journalism,Journalists,Knowledge,Multiculturalism & pluralism,Native peoples,Oppression,Oral tradition,Political activism,Political power,Reporters,Scholars,Stereotypes,Traditions}
}

@article{todriPerceptionsRegardingDistance2021,
  title = {Perceptions {{Regarding Distance Learning}} in {{Higher Education}}, {{Smoothing}} the {{Transition}}},
  author = {Todri, Ardita and Papajorgji, Petraq and Moskowitz, Howard and Scalera, Francesco},
  year = {2021},
  journal = {Contemporary Educational Technology},
  volume = {13},
  number = {1},
  issn = {EISSN-1309-517X},
  doi = {10/gmbv22},
  abstract = {This paper presents the perceptions on distance learning approaches, assessed through an online survey, using experimental design of ideas (Mind Genomics). Students and professors of higher education institutions who had not yet experienced distance learning before COVID-19 pandemic period participated in the study. The participants belong to the universities located in Mediterranean basin, e.g., Albania, Italy, Morocco, Algeria and few African countries. Results suggest that distance learning will shift many of the responsibilities formerly on the professors to those of the students. The data suggests the need for emotional support during this transition, specifically to maintain interaction among students and professor as well as among students themselves in distance learning platforms as in traditional classrooms. The study shows that the effectiveness and the interactivity of this new paradigm are very important and any further developments of distance learning should provide strong support for these components. The position of the professor is indispensable as the guide to the entire process, suggesting that at least at the time of this writing (2020) distance learning approach is perceived only to be an intermittent complementary path to in-person interactions.},
  langid = {english},
  keywords = {Adjustment (to Environment),Affordances,College Faculty,COVID-19,Distance Education,Electronic Learning,Foreign Countries,Graduate Students,Instructional Effectiveness,Interaction,Pandemics,Social Support Groups,Student Attitudes,Student Role,Teacher Attitudes,Teacher Role,Undergraduate Students}
}

@book{tombroTeachingAutoethnographyPersonal2016,
  title = {Teaching Autoethnography : Personal Writing in the Classroom.},
  author = {Tombro, Melissa},
  year = {2016},
  series = {Open Textbook Library},
  publisher = {Published by Open SUNY Textbooks, Milne Library (IITG PI), State University of New York at Geneseo},
  abstract = {Summary: "Teaching Autoethnography: Personal Writing in the Classroom is dedicated to the practice of immersive ethnographic and autoethnographic writing that encourages authors to participate in the communities about which they write. This book draws not only on critical qualitative inquiry methods such as interview and observation, but also on theories and sensibilities from creative writing and performance studies, which encourage self-reflection and narrative composition. Concepts from qualitative inquiry studies, which examine everyday life, are combined with approaches to the creation of character and scene to help writers develop engaging narratives that examine chosen subcultures and the author's position in relation to her research subjects. The book brings together a brief history of first-person qualitative research and writing from the past forty years, examining the evolution of nonfiction and qualitative approaches in relation to the personal essay. A selection of recent student writing in the genre as well as reflective student essays on the experience of conducting research in the classroom is presented in the context of exercises for coursework and beyond. Also explored in detail are guidelines for interviewing and identifying subjects and techniques for creating informed sketches and images that engage the reader. This book provides approaches anyone can use to explore their communities and write about them first-hand. The methods presented can be used for a single assignment in a larger course or to guide an entire semester through many levels and varieties of informed personal writing."--Open Textbook Library.},
  isbn = {978-1-942341-28-4},
  keywords = {Academic writing,Electronic books,Ethnology -- Authorship,Ethnology -- Research,Textbooks}
}

@article{tongLinkingSummativeAssessments2011,
  title = {Linking Summative Assessments Electronic Feedback and Feedforward in Module Design},
  author = {Tong, Vincent C. H.},
  year = {2011},
  journal = {British Journal of Educational Technology},
  doi = {10/c9tg87},
  abstract = {N/A: no abstract available},
  pmcid = {null},
  pmid = {null}
}

@article{tongLinkingSummativeAssessments2011a,
  title = {Linking Summative Assessments Electronic Feedback and Feedforward in Module Design},
  author = {Tong, Vincent C. H.},
  year = {2011},
  journal = {British Journal of Educational Technology},
  doi = {10.1111/j.1467-8535.2011.01226.x},
  abstract = {N/A: no abstract available},
  pmcid = {null},
  pmid = {null}
}

@article{toppingDigitalHardwarePeer2021,
  title = {Digital {{Hardware}} for {{Peer Assessment}} in {{K-12 Schools}} and {{Universities}}},
  author = {Topping, {\relax KJ}},
  year = {2021},
  month = sep,
  journal = {Frontiers in Education},
  volume = {6},
  issn = {2504-284X},
  doi = {10.3389/feduc.2021.666538},
  abstract = {Digital peer assessment (PA) is an arrangement for learners to consider and specify the level, value, or quality of a product or the performance of other equal-status learners, using computers, tablets, mobiles or other devices, and the internet. Digital PA is of increasing relevance as more educational establishments are moving toward online or blended learning. It has been widely used for some time, not only in elementary (primary) and high (secondary) schools but also in higher education. In this article, the purposes of PA are considered. Then, questions of effectiveness are briefly discussed. Then, the majority of the article describes in general terms how to do it. A review is offered for variations in types of PA and the underpinning theory, both of which have practical implications, irrespective of whether the PA is digital or face-to-face. Then, the use of different kinds of digital hardware in different kinds of PA will be considered. After this, the social and emotional aspects of digital PA are considered. As the contexts are so different, differences between primary school, high school, and higher education are reviewed. A conclusion summarises the strengths and weaknesses of digital PA, which can certainly be effective as a teaching and learning method and enhance student communication, problem-solving, and self-confidence.{$<$}/p{$>$}},
  langid = {english},
  keywords = {digital,FEEDBACK,HIGHER-EDUCATION,IMPACT,METAANALYSIS,ONLINE,peer assessment,primary school,secondary school,university},
  file = {/Users/colin.madland/Zotero/storage/QDWFWFI8/toppingDigitalHardwarePeer2021.pdf}
}

@article{torreTrainingUniversityTeachers2019,
  title = {Training {{University Teachers}} on the {{Use}} of the {{ePortfolio}} in {{Teaching}} and {{Assessment}}},
  author = {Torre, Emanuela M.},
  year = {2019},
  month = jan,
  journal = {International Journal of ePortfolio},
  volume = {9},
  number = {2},
  pages = {97--110},
  publisher = {International Journal of ePortfolio},
  issn = {2157-622X},
  abstract = {Higher education is increasingly called upon to respond to the need for educational innovations promoting graduate employability and lifelong learning (European Higher Education Area, 2012, 2015). To achieve this, students must progressively become able to reflect both on their learning and their potential to improve and plan their own educational and professional development accordingly (D'Andrea \& Gosling, 2005). The portfolio, now used in many university courses worldwide, is a tool that contributes to responding to these needs. A study of literature on this subject indicates that the portfolio's effectiveness during the teaching-learning and assessment processes is dependent on the ability of teachers to master this tool. It follows that, in order to facilitate the effective implementation and use of the portfolio in universities, teachers need to receive suitable training. This paper presents the characteristics and results of a training course on the use of the portfolio. The course was part of an extensive training project for university teachers in the University of Turin's IRIDI program that was aimed at promoting the improvement and innovation of university teaching. The results of the training course show a higher level of competency in creating a portfolio, and a higher level of willingness to introduce it into teaching.},
  keywords = {College Faculty,Educational Technology,Electronic Publishing,Faculty Development,Foreign Countries,Higher Education,Italy,No DOI found,Portfolio Assessment,Portfolios (Background Materials),Technology Uses in Education,Training}
}

@article{torunOnlineDistanceLearning2020,
  title = {Online {{Distance Learning}} in {{Higher Education}}: {{E-Learning Readiness}} as a {{Predictor}} of {{Academic Achievement}}},
  author = {Torun, Emel Dikbas},
  year = {2020},
  journal = {Open Praxis},
  volume = {12},
  number = {2},
  pages = {191--208},
  issn = {EISSN-2304-070X},
  doi = {10/gmbvzt},
  abstract = {The purpose of this study was to examine the relationship between e-learning readiness and academic achievement in an online course in higher-level education. The survey method was employed when collecting the study data, and the data-collection instrument used was the E-Learning Readiness Scale. The scale comprises 33 items and six sub-dimensions, including (1) computer self-efficacy, (2) internet self-efficacy, (3) online self-efficacy, (4) self-directed learning, (5) learner control, (6) motivation toward e-learning. The study participants comprised 153 freshmen who were taking an online English as a Foreign Language course. A relational model is proposed in this study to measure the predicted levels of readiness on academic achievement in online learning. Reliability analysis, Pearson correlation, linear regression analysis, and structural equation modelling were used to analyze and model the study data. Results indicated that self-directed learning is the strongest predictor of academic achievement, while motivation toward e-learning was found to be another predictor of academic achievement. Internet/online/computer self-efficacy and learner control were not found to be among significant predictors of academic achievement. It is concluded that, especially with the spread of Covid-19 worldwide, education is currently switching from face-to-face to online learning in an immediate and unexpected way; therefore e-learning readiness has to be carefully taken into consideration within this new educational paradigm.},
  langid = {english},
  keywords = {Academic Achievement,College Freshmen,Computer Literacy,Distance Education,Electronic Learning,English (Second Language),Higher Education,Internet,Learning Motivation,Learning Readiness,Online Courses,Predictor Variables,Public Colleges,Second Language Learning,Self Efficacy,Self Management}
}

@misc{tourImportantThreadHere2018,
  type = {Tweet},
  title = {An Important Thread Here from @{{Jessifer}} Asking Questions of {{HE}} Use of Turnitin. {{Why}} Don't We Design Better Assessments? {{Why}} Don't We Trust Our Students to Do the Learning? {{Why}} Do We Make It All so Much about the Mark and so Little about the Learning Process?{{https://twitter.com/jessifer/status/1009737552117616640}}~{\dots}},
  author = {{\noopsort{tour}}de la Tour, Naomi},
  year = {2018},
  month = jun,
  journal = {@delatoured},
  urldate = {2018-06-28},
  langid = {english},
  keywords = {turnitin},
  file = {/Users/colin.madland/Zotero/storage/F4YVH7VE/1011256994815205377.html}
}

@misc{towardsopennessOER17ProvocationChris,
  title = {\#{{OER17 Provocation}} by {{Chris Gilliard}}},
  author = {{Towards Openness}},
  urldate = {2018-10-21},
  keywords = {OER17,open,privacy,TowardsOpenness}
}

@article{townsleyAlternativeGradingPractices2020,
  title = {Alternative Grading Practices: {{An}} Entry Point for Faculty in Competency-based Education},
  shorttitle = {Alternative Grading Practices},
  author = {Townsley, Matt and Schmid, David},
  year = {2020},
  month = sep,
  journal = {The Journal of Competency-Based Education},
  volume = {5},
  number = {3},
  issn = {2379-6154, 2379-6154},
  doi = {10/ghwpbq},
  urldate = {2021-01-30},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/WY6CZSFD/townsleyAlternativeGradingPractices2020.pdf}
}

@article{townsleyGradingPrinciplesPandemicEra,
  title = {Grading {{Principles}} in {{Pandemic-Era Learning}}: {{Recommendations}} and {{Implications}} for {{Secondary School Leaders}}},
  author = {Townsley, Matt},
  pages = {7},
  abstract = {As the COVID-19 pandemic unfolded in K-12 education, school leaders quickly pivoted from prioritizing continuous instruction and technology access to the output: grades. In response to these unprecedented times, secondary schools utilized ``do no harm'' grading methods, such as freezing previous grades and replacing letter grades with pass-fail. The purpose of this essay is to describe grading principles that secondary school leaders should consider during future pandemic era learning and to suggest implications based upon previous literature.},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/2HTYVBXP/townsleyGradingPrinciplesPandemicEra.pdf}
}

@inproceedings{toyamaTechnologyAmplifierInternational2011,
  title = {Technology as Amplifier in International Development},
  booktitle = {Proceedings of the 2011 {{iConference}}},
  author = {Toyama, Kentaro},
  year = {2011},
  month = feb,
  pages = {75--82},
  publisher = {ACM},
  address = {Seattle Washington USA},
  doi = {10/dtr4n8},
  urldate = {2021-07-14},
  isbn = {978-1-4503-0121-3},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/F5567Z28/toyamaTechnologyAmplifierInternational2011.pdf}
}

@article{toyodaVRbasedHealthSafety2022,
  title = {{{VR-based}} Health and Safety Training in Various High-Risk Engineering Industries: A Literature Review},
  author = {Toyoda, Ryo and {Russo-Abeg{\~a}o}, Fernando and Glassey, Jarka},
  year = {2022},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {19},
  number = {1},
  pages = {1--22},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-022-00349-3},
  abstract = {This article provides a critical review of the current studies in VR-based health and safety training, assessment techniques, training evaluation, and its potential to improve the training evaluation outcomes in various high-risk engineering industries. The results of this analysis indicate the breadth of VR-based applications in training users on a combination of topics including risk assessment, machinery, and/or process operation in various industries. Data showed that the use of fully immersive VR increased significantly due to the improvements in hardware, display resolution, and affordability. Most of the articles used external assessment to measure the changes in the satisfaction and the declarative knowledge of trainees as these are easier to implement, while some articles started to implement internal assessment that provides an automated assessment capable of measuring complex skills. The results of the study also suggest that it has the potential to improve the training evaluation outcomes compared to traditional training methods. The findings from this study help practitioners and safety managers by providing a training design framework that may be adopted to optimise the condition of a VR-based training.},
  keywords = {Assessment,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Educational Technology,Engineering,Health and safety training,High-risk industries,Higher Education,Humanities,Information Systems Applications (incl.Internet),Law,Literature reviews,Review Article,Risk assessment,Safety management,Safety training,Statistics for Social Sciences,Training evaluation,User training,Virtual reality},
  file = {/Users/colin.madland/Zotero/storage/3K9WHLDY/toyodaVRbasedHealthSafety2022.pdf}
}

@article{tractenbergAssessmentEvaluationRubric2021,
  title = {The {{Assessment Evaluation Rubric}}: {{Promoting Learning}} and {{Learner-Centered Teaching}} through {{Assessment}} in {{Face-to-Face}} or {{Distanced Higher Education}}},
  author = {Tractenberg, Rochelle E.},
  year = {2021},
  journal = {Education sciences},
  volume = {11},
  number = {8},
  pages = {441},
  publisher = {Mdpi},
  address = {BASEL},
  issn = {2227-7102},
  doi = {10.3390/educsci11080441},
  abstract = {It is common to create courses for the higher education context that accomplish contentdriven teaching goals and then develop assessments (quizzes and exams) based on the target content. However, content-driven assessment can tend to support teaching- or teacher-centered instruction. Adult learning and educational psychology theories suggest that instead, assessment should be aligned with learning, not teaching, objectives. To support the alignment of assessments with instruction in higher education, the Assessment Evaluation Rubric (AER) was developed. The AER can be utilized to guide the development and evaluation/revision of assessments that are already used. The AER describes, or permits the evaluation of, four features of an assessment: its general alignment with learning goal(s), whether the assessment is intended to/effective as formative or summative, whether some systematic approach to cognitive complexity is reflected, and whether the assessment (instructions as well as results) itself is clearly interpretable. Each dimension (alignment, utility, complexity, and clarity) has four questions that can be rated as present/absent. Other rating methods can also be conceptualized for the AER's 16 questions, depending on the user's intent. Any instructor can use the AER to evaluate their own assessments and ensure that they-or new assessments in development-will promote learning and learner-centered teaching. As instructors shift from face-to-face toward virtual or hybrid teaching models, or as they shift online instruction (back) to face-to-face teaching, it creates an ideal opportunity to ensure that assessment is optimizing learning and is valid for instructional decision-making.},
  keywords = {assessment,Coronaviruses,COVID-19,Curricula,Decision making,Distance learning,Education & Educational Research,Educational evaluation,Educational objectives,Higher education,instructional development,Social Sciences,Students,Teaching,validity},
  file = {/Users/colin.madland/Zotero/storage/EQXFEVRA/tractenbergAssessmentEvaluationRubric2021.pdf}
}

@techreport{tremblayAssessmentHigherEducation2014,
  title = {Assessment of Higher Education Learning Outcomes ({{AHELO}}) Feasibility Study Report: {{Design}} and Implementation},
  author = {Tremblay, Karine and Lalancette, Diane and Roseveare, Deborah},
  year = {2014},
  number = {Volume 1},
  institution = {OECD},
  urldate = {2024-04-09},
  file = {/Users/colin.madland/Zotero/storage/65X6LZRH/AHELOFSReportVolume1.pdf}
}

@article{trepuleHowIncreaseValue2021,
  ids = {trepuleHowIncreaseValue2021a,trepuleHowIncreaseValue2021b},
  title = {How to {{Increase}} the {{Value}} of {{Digital Badges}} for {{Assessment}} and {{Recognition}} in {{Higher Education}}. {{A University Case}}},
  author = {Trepule, Elena and Volungeviciene, Airina and Tereseviciene, Margarita and Greenspon, Rasa and Costa, Nilza},
  year = {2021},
  journal = {Informatics in Education},
  volume = {20},
  number = {1},
  pages = {131--152},
  publisher = {Vilnius Univ, Inst Mathematics \& Informatics},
  address = {VILNIUS},
  issn = {ISSN-1648-5831},
  doi = {10/gmbv2s},
  abstract = {The main goal of this research is to enhance the understanding of quality criteria for DB metadata for assessment and recognition as factors increasing their value in higher education (HE). To attain this goal, a case study approach centered in one HE institution was used, aiming (a) at an analysis of the "status quo" description of metadata of DBs issued by the HE institution to identify the value of DBs in terms of assessment and recognition procedures, and (b) a list of quality criteria for DB description metadata was proposed on the basis of academic research and on expert interview results. The results of the research demonstrate that in the institution under research, these criteria are not present in most cases of DB descriptions as teachers do not provide them. Distinct assessment and recognition criteria make an important quality factor for the DBs to become valid and valued digital credentials in HE.},
  langid = {english},
  keywords = {assessment,Computer Uses in Education,criteria,Criteria,digital badges,Education & Educational Research,Educational evaluation,Educational Technology,Evaluation Criteria,Foreign Countries,higher education,Higher education,Higher Education,metadata,Metadata,PERCEPTIONS,recognition,Recognition,Recognition (Achievement),Social Sciences,Student Evaluation},
  file = {/Users/colin.madland/Zotero/storage/PLK2A6PP/trepuleHowIncreaseValue2021.pdf}
}

@article{tresmanStrategyImprovedStudent2002,
  title = {Towards a {{Strategy}} for {{Improved Student Retention}} in {{Programmes}} of {{Open}}, {{Distance Education}}: {{A Case Study From}} the {{Open University UK}} {\textsubscript{ }}{{{\textsubscript{Tresman}}}}{\textsubscript{ }} {{The International Review}} of {{Research}} in {{Open}} and {{Distance Learning}}},
  author = {Tresman, Susan},
  year = {2002},
  journal = {International Review of Research in Open and Distributed Learning},
  urldate = {2010-04-12},
  keywords = {drop out,dropout,student retention}
}

@article{triceConcurrentValidityAcademic1987,
  title = {Concurrent {{Validity}} of the {{Academic Locus}} of {{Control Scale}}},
  author = {Trice, Ashton D and Ogden, Epp P and Stevens, Wayne and Booth, Jeanne},
  year = {1987},
  journal = {Educational and Psychological Measurement},
  volume = {47},
  number = {2},
  pages = {483--486},
  abstract = {In three studies of college students, significant correlations in the predicted direction were found between criterion process variables related to academic success and scores on the Academic Locus of Control (ALC) Scale. The criterion variables included verbal class participation, study time, and homework completion. Although the correlations were small, accounting for between 10\% and 21\% of the ALC variance, the validity of the scale was supported.}
}

@article{trigwellImprovingQualityStudent1991,
  title = {Improving the Quality of Student Learning: {{The}} Influence of Learning Context and Student Approaches to Learning on Learning Outcomes},
  shorttitle = {Improving the Quality of Student Learning: {{The}} Influence of Learning Context and Student Approaches to Learning on Learning Outcomes},
  author = {Trigwell, Keith and Prosser, Michael},
  year = {1991},
  journal = {Higher Education},
  volume = {22},
  pages = {251--266},
  issn = {0018-1560},
  doi = {10.1007/BF00132290},
  abstract = {Previous studies of the relationship between perceptions and/or evaluations of the learning environment and approaches to study have either not included measures of students' learning outcomes, or have included quantitative differences and not qualitative differences in learning outcomes. The studies reported in this paper focus on the relationship between qualitative differences in learning outcomes, perceptions/evaluations of the learning environment and approaches to study. The results support previous research in identifying relationships between perceptions/evaluations of the learning environment and approach to study and between approach to study and the quality of the learning outcomes. The second of the two studies reported also identifies a relationship between perceptions, approaches and the quality of the outcomes. The results suggest that perceived environments which encourage deep approaches are more likely to facilitate higher quality learning than environments designed to discourage surface approaches.},
  keywords = {Humanities,Social Sciences and Law},
  annotation = {3}
}

@incollection{trillingChapterDigitalLiteracy2013,
  title = {Chapter 4 - {{Digital Literacy Skills}}},
  booktitle = {21st Century Skills: Learning for Life in Our Times},
  author = {Trilling, Bernie and Fadel, Charles},
  year = {2013},
  publisher = {Jossey-Bass},
  address = {San Francisco, Calif.},
  urldate = {2021-12-23},
  abstract = {The new building blocks for learning in a complex worldThis important resource introduces a framework for 21st Century learning that maps out the skills needed to survive and thrive in a complex and connected world. 21st Century content includes the basic core subjects of reading, writing, and arithmetic-but also emphasizes global awareness, financial/economic literacy, and health issues. The skills fall into three categories: learning and innovations skills; digital literacy skills; and life and career skills. This book is filled with vignettes, international examples, and classroom samples that help illustrate the framework and provide an exciting view of twenty-first century teaching and learning. Explores the three main categories of 21st Century Skills: learning and innovations skills; digital literacy skills; and life and career skills Addresses timely issues such as the rapid advance of technology and increased economic competitionBased on a framework developed by the Partnership for 21st Century Skills (P21)The book contains a DVD with video clips of classroom teaching. For more information on the book visit www.21stcenturyskillsbook.com.},
  isbn = {978-0-470-55391-6},
  langid = {english},
  annotation = {OCLC: 864562139}
}

@misc{trudeauMinisterCrownIndigenousRelations2017,
  title = {Minister of {{Crown-Indigenous Relations}} and {{Northern Affairs Mandate Letter}} ({{October}} 4, 2017)},
  author = {Trudeau, Justin},
  year = {2017},
  month = aug,
  journal = {Prime Minister of Canada},
  urldate = {2019-03-25},
  abstract = {Dear Dr. Bennett:I am honoured that you have agreed to serve Canadians as Minister of Crown-Indigenous Relations and Northern Affairs.We promised Canadians real change -- in both what we do and how we do it.~ Canadians sent a clear message in the last election, and our platform offered a new, ambitious plan for a strong and growing middle class. Canadians expect us to fulfill our commitments, and it is my expectation that you will do your part in delivering on those promises to Canadians.},
  howpublished = {https://pm.gc.ca/eng/minister-crown-indigenous-relations-and-northern-affairs-mandate-letter},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/QJZB9M9V/minister-crown-indigenous-relations-and-northern-affairs-mandate-letter.html}
}

@misc{trudeauMinisterIndigenousServices2017,
  title = {Minister of {{Indigenous Services Mandate Letter}} ({{October}} 4, 2017)},
  author = {Trudeau, Justin},
  year = {2017},
  month = aug,
  journal = {Prime Minister of Canada},
  urldate = {2019-03-25},
  abstract = {Dear Minister:I am honoured that you have agreed to serve Canadians as Minister of Indigenous Services.We promised Canadians real change -- in both what we do and how we do it.~ Canadians sent a clear message in the last election, and our platform offered a new, ambitious plan for a strong and growing middle class.~ Canadians expect us to fulfill our commitments, and it is my expectation that you will do your part in delivering on those promises to Canadians.},
  howpublished = {https://pm.gc.ca/eng/minister-indigenous-services-mandate-letter-october-4-2017},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/6PHHRDKT/minister-indigenous-services-mandate-letter-october-4-2017.html}
}

@article{Trumbull_2013,
  title = {Understanding Formative Assessment Insights from Learning Theory and Measurement Theory},
  author = {Trumbull, Elise and Lash, Andrea},
  year = {2013},
  journal = {null},
  doi = {null},
  abstract = {This paper explores formative assessment, a process intended to yield information about student learning---information that teachers can use to shape instruction to meet students' needs and that students can use to better understand and advance their learning. This purpose---promoting learning by informing instruction---distinguishes it from other kinds of student assessment, such as diagnostic, which is used to identify students who have special learning needs, or sum-},
  mag_id = {2187817723},
  pmcid = {null},
  pmid = {null},
  keywords = {guskey,Invalid DOI}
}

@article{tsaiAssessmentStudentsLearning2016,
  title = {Assessment of {{Students}}' {{Learning Behavior}} and {{Academic Misconduct}} in a {{Student-Pulled Online Learning}} and {{Student-Governed Testing Environment}}: {{A Case Study}}},
  author = {Tsai, Nancy Wang},
  year = {2016},
  month = jan,
  journal = {Journal of Education for Business},
  volume = {91},
  number = {7},
  pages = {387--392},
  publisher = {Journal of Education for Business},
  issn = {0883-2323},
  doi = {10.1080/08832323.2016.1238808},
  abstract = {The development of advanced and affordable information technologies has enabled higher education institutes to instantly deliver course or training materials to its students via the Internet without any time or location limitations. At the same time, the identical technology has also empowered distance learning students with easier opportunities for academic misconduct. The purpose of this empirical study was to explore students' learning behavior changes and academic misconduct in an undergraduate computer literacy course that adopts student-pulled online learning and a student-governed online final exam.},
  keywords = {Academic Achievement,Behavior Change,Case Studies,Cheating,Computer Assisted Testing,Computer Literacy,Correlation,Distance Education,Internet,Online Courses,Statistical Significance,Student Behavior,Supervision,Testing Programs,Undergraduate Students},
  file = {/Users/colin.madland/Zotero/storage/WLX57URK/tsaiAssessmentStudentsLearning2016.pdf}
}

@article{tsaiEmpoweringLearnersPersonalised2020,
  title = {Empowering {{Learners}} with {{Personalised Learning Approaches}}? {{Agency}}, {{Equity}} and {{Transparency}} in the {{Context}} of {{Learning Analytics}}},
  author = {Tsai, Yi-Shan and Perrotta, Carlo and Ga{\v s}evic, Dragan},
  year = {2020},
  month = jan,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {45},
  number = {4},
  pages = {554--567},
  publisher = {Assessment \& Evaluation in Higher Education},
  issn = {0260-2938},
  doi = {10.1080/02602938.2019.1676396},
  abstract = {The emergence of personalised data technologies such as learning analytics is framed as a solution to manage the needs of higher education student populations that are growing ever more diverse and larger in size. However, the current approach to learning analytics presents tensions between increasing student agency in making learning-related decisions and 'datafying' students in the process of collecting, analysing and interpreting data. This article presents a study that explores staff and student experience of agency, equity and transparency in existing data practices and expectations towards learning analytics in a UK university. The results show a number of intertwined factors that have contributed to the tensions between enhancing a learner's control of their studies and, at the same time, diminishing their autonomy as an active agent in the process of learning analytics. This article argues that learner empowerment should not be automatically assumed to have taken place as part of the adoption of learning analytics. Instead, the interwoven power relationships in a complex educational system and the interactions between humans and machines need to be taken into consideration when presenting learning analytics as an equitable process to enhance student agency and educational equity.},
  keywords = {Accountability,College Faculty,College Students,Data Use,Decision Making,Equal Education,Expectation,Foreign Countries,Individualized Instruction,Learning Analytics,Personal Autonomy,Student Empowerment,United Kingdom},
  file = {/Users/colin.madland/Zotero/storage/WGTKSSWN/tsaiEmpoweringLearnersPersonalised2020.pdf}
}

@article{tseviCOVID19HigherEducation2021,
  title = {{{COVID-19}} and {{Higher Education}} in {{Ghana}}: {{The Case}} of a {{Public Higher Education Institution}}},
  author = {Tsevi, Linda},
  year = {2021},
  journal = {International Journal of Multidisciplinary Perspectives in Higher Education},
  volume = {6},
  number = {1},
  pages = {150--155},
  issn = {ISSN-2474-2546},
  abstract = {This paper examines the ability of a public higher education in Ghana to adapt to changes in teaching and learning in the midst of COVID-19 pandemic. Measures taken to ensure uninterrupted migration to online teaching and learning included a regular monthly supply of data bundle from an internet service provider to faculty members, select support staff and students in addition to regular training in the effective use of the SAKAI Learning Management System. Challenges encountered include inadequate internet access, occasional network interruptions during online classes and oversubscription of Zoom time slots at the departmental level. Despite these challenges, this public higher education institution was able to complete the 2019/2020 academic year fairly well.},
  langid = {english},
  keywords = {Access to Computers,Access to Education,Barriers,COVID-19,Distance Education,Foreign Countries,Higher Education,Internet,No DOI found,Online Courses,Pandemics,Public Colleges,School Closing,Videoconferencing}
}

@article{tuckLandEducationIndigenous2014,
  title = {Land Education: {{Indigenous}}, Post-Colonial, and Decolonizing Perspectives on Place and Environmental Education Research},
  author = {Tuck, Eve and McKenzie, Marcia and McCoy, Kate},
  year = {2014},
  journal = {Environmental Education Research},
  volume = {20},
  number = {1},
  pages = {1--23},
  issn = {1350-4622},
  doi = {10.1080/13504622.2013.877708}
}

@article{tuckRevisioningActionParticipatory2009,
  title = {Re-Visioning {{Action}}: {{Participatory Action Research}} and {{Indigenous Theories}} of {{Change}}},
  author = {Tuck, Eve},
  year = {2009},
  month = mar,
  journal = {The Urban Review},
  volume = {41},
  number = {1},
  pages = {47--65},
  issn = {1573-1960},
  doi = {10.1007/s11256-008-0094-x},
  abstract = {This article observes that participatory action research (PAR), by nature of being collaborative, necessitates making explicit theories of change that may have otherwise gone unseen or unexamined. The article explores the limits of the reform/revolution paradox on actions and theories of change in PAR. Citing examples from two recent youth PAR projects on educational issues, the author submits that when met with such a paradox, one can only move to a new vantage point. Four alternative vantage points, drawn from Indigenous epistemologies, are illustrated; they are sovereignty, contention, balance, and relationship.}
}

@article{tulgarSelfieSsessmentAlternative2017,
  title = {Selfie@ssessment as an {{Alternative Form}} of {{Self-Assessment}} at {{Undergraduate Level}} in {{Higher Education}}},
  author = {Tulgar, Ayseg{\"u}l Takka{\c c}},
  year = {2017},
  month = jan,
  journal = {Journal of Language and Linguistic Studies},
  volume = {13},
  number = {1},
  pages = {321--335},
  publisher = {{Journal of Language and Linguistic Studies}},
  issn = {1305-578X},
  abstract = {This study aimed to get ideas formed by undergraduate foreign language students about the applicability, advantages and disadvantages of "selfie@ssessment", which can be regarded as an alternative form of self-assessment utilizing modern mobile phone technologies and the available Internet facilities. Underpinning this study of "selfie@ssessment" by undergraduate students is that an increasing body of research and a good many theoretical views acknowledge the importance of self- and group assessment by students for their performances in the activities they carry out in their learning process. This study, without contrasts with the prevailing notion in the self-assessment by students in assessment acquis, offers a new perspective to the traditional approach undergraduate students assess themselves for their learning performances and presentations within the class. The unique approach in this study is that students are expected to send their selfie-recorded self- or group assessments via mobile phones or cameras enabling self-recording to their teachers through the Internet. Implemented as a research to test how undergraduate students would approach the new concept, this study is intended to bring to the fore a new dimension in self-assessment utilizing modern methods of communication and data transmission in the light of the framework of data obtained in the area self-assessment.},
  keywords = {Educational Technology,English (Second Language),Foreign Countries,Handheld Devices,No DOI found,Photography,Program Effectiveness,Qualitative Research,Second Language Instruction,Self Evaluation (Individuals),Technology Uses in Education,Telecommunications,Turkey,Undergraduate Students,Video Technology}
}

@article{tummonsItSortFeels2011,
  title = {It Sort of Feels Uncomfortable Problematising the Assessment of Reflective Practice},
  author = {Tummons, Jonathan},
  year = {2011},
  journal = {Studies in Higher Education},
  doi = {10/dsw6ck},
  abstract = {This article forms part of an exploration of assessment on one part-time higher education course: a professional qualification for teachers and trainers in the learning and skills sector, which is delivered on a franchise basis across a network of colleges in the north of England. This article proposes that the validity of the assessment of reflective practice, a key component of many higher education programmes in addition to the course being researched here, is contestable. Through an analysis informed by social practice accounts of literacy, the article suggests that the ways in which reflective practice is assessed, and the ways in which the crucial requisites of validity are assigned to it, mask complexities and contradictions in both how students write reflective assignments, and how tutors read them. This article argues for a new, critical analysis of the assessment of reflective practice and raises a number of questions about the validity of the process.},
  pmcid = {null},
  pmid = {null}
}

@article{tummonsItSortFeels2011a,
  title = {It Sort of Feels Uncomfortable Problematising the Assessment of Reflective Practice},
  author = {Tummons, Jonathan},
  year = {2011},
  journal = {Studies in Higher Education},
  doi = {10/dsw6ck},
  abstract = {This article forms part of an exploration of assessment on one part-time higher education course: a professional qualification for teachers and trainers in the learning and skills sector, which is delivered on a franchise basis across a network of colleges in the north of England. This article proposes that the validity of the assessment of reflective practice, a key component of many higher education programmes in addition to the course being researched here, is contestable. Through an analysis informed by social practice accounts of literacy, the article suggests that the ways in which reflective practice is assessed, and the ways in which the crucial requisites of validity are assigned to it, mask complexities and contradictions in both how students write reflective assignments, and how tutors read them. This article argues for a new, critical analysis of the assessment of reflective practice and raises a number of questions about the validity of the process.},
  pmcid = {null},
  pmid = {null}
}

@article{turcsanyi-szaboHandbookTeachingLearning2010,
  title = {A Handbook for Teaching and Learning in Higher Education: Enhancing Academic Practice, 3rd Ed},
  author = {{Turcsanyi-Szabo}, Marta},
  year = {2010},
  journal = {Learning, Media and Technology},
  volume = {35},
  number = {4},
  pages = {435--437}
}

@article{turnerSeeNotSee2018,
  title = {To See or Not to See? {{Comparing}} the Effectiveness of Examinations and End of Module Assessments in Online Distance Learning},
  author = {Turner, Jim and Turner, Jim and Briggs, Gemma and Briggs, Gemma},
  year = {2018},
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {43},
  number = {7},
  pages = {1048--1060},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0260-2938},
  doi = {10/ggrgxp},
  abstract = {Research comparing continuous assessment (e.g. coursework) with examinations generally reveals a student preference for the former. The perceived increased use of continuous assessment periodically captures media attention, with claims of greater numbers of higher degree classifications being awarded. This paper takes a case-study approach to investigate the extent to which different types of assessment allow students to effectively demonstrate and apply their learning. By considering data gathered from second-level, undergraduate students completing 60 point, online psychology modules, this paper investigates assessment effectiveness in terms of student satisfaction, pass rate and level of pass rate. Findings reveal that modules with an end of module assessment (EMA), rather than an examination, have higher completion and pass rates. Whilst students who took a seen examination also performed well, those who completed an unseen examination recorded the lowest overall pass and completion rates, despite high ratings of student satisfaction. Findings are discussed in terms of implications for improved pedagogy and student experience.},
  keywords = {Distance Education,EDUCATION & EDUCATIONAL RESEARCH,Evaluation Methods,examinations,Final assessment pedagogy,Foreign Countries,Grades (Scholastic),Learning Modules,Online Courses,PERFORMANCE,Progress Monitoring,Psychology,Student Evaluation,student satisfaction,Tests,Undergraduate Students}
}

@article{turnerSeeNotSee2018a,
  title = {To See or Not to See? {{Comparing}} the Effectiveness of Examinations and End of Module Assessments in Online Distance Learning},
  author = {Turner, Jim and Briggs, Gemma},
  year = {2018},
  journal = {Assessment and evaluation in higher education},
  volume = {43},
  number = {7},
  pages = {1048--1060},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0260-2938},
  doi = {10.1080/02602938.2018.1428730},
  abstract = {Research comparing continuous assessment (e.g. coursework) with examinations generally reveals a student preference for the former. The perceived increased use of continuous assessment periodically captures media attention, with claims of greater numbers of higher degree classifications being awarded. This paper takes a case-study approach to investigate the extent to which different types of assessment allow students to effectively demonstrate and apply their learning. By considering data gathered from second-level, undergraduate students completing 60 point, online psychology modules, this paper investigates assessment effectiveness in terms of student satisfaction, pass rate and level of pass rate. Findings reveal that modules with an end of module assessment (EMA), rather than an examination, have higher completion and pass rates. Whilst students who took a seen examination also performed well, those who completed an unseen examination recorded the lowest overall pass and completion rates, despite high ratings of student satisfaction. Findings are discussed in terms of implications for improved pedagogy and student experience.},
  keywords = {College students,Distance Education,Distance learning,Education & Educational Research,Educational evaluation,Evaluation Methods,examinations,Final assessment pedagogy,Foreign Countries,Grades (Scholastic),Learning Modules,Online Courses,Pedagogy,Progress Monitoring,Psychology,Social Sciences,Student Evaluation,Student Satisfaction,Tests,Undergraduate Students},
  file = {/Users/colin.madland/Zotero/storage/KSC7453B/turnerSeeNotSee2018a.pdf}
}

@misc{TwitterAccusedBakedIn2020,
  title = {Twitter {{Accused Of Baked-In Racial Bias After Users Notice Algorithm Keeps Choosing White Men}}},
  year = {2020},
  month = sep,
  journal = {Pedestrian TV},
  urldate = {2020-09-22},
  abstract = {Twitter users have accused the platform of racial and gender biases after noting the algorithm consistently chooses to highlight White men.},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/9JFRD2A8/twitter-image-algorithm-accused-racial-bias-update.html}
}

@misc{TwitterAcknowledgesIts2020,
  title = {Twitter Acknowledges Its 'racist' Photo Algorithm, Issues Lengthy Apology: '{{It}}'s 100\% Our Fault'},
  shorttitle = {Twitter Acknowledges Its 'racist' Photo Algorithm, Issues Lengthy Apology},
  year = {2020},
  month = sep,
  journal = {TheBlaze},
  urldate = {2020-09-22},
  abstract = {Loosely modeled after a human brain},
  chapter = {News},
  howpublished = {https://www.theblaze.com/news/twitter-acknowledges-its-racist-photo-algorithm-issues-lengthy-apology},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/36XZX8V9/twitter-acknowledges-its-racist-photo-algorithm-issues-lengthy-apology.html}
}

@misc{TwitterAlgorithmFailure,
  title = {Twitter's {{Algorithm Failure Shows Big Tech}}'s {{Ongoing Struggle With AI Bias}}},
  journal = {Toolbox},
  urldate = {2020-09-24},
  abstract = {Twitter's photo cropping algorithm exhibited AI bias this week, drawing severe criticism from its users. The microblogging tech giant revealed it had tested the algorithm for AI bias and conceded there is a need for continuous improvement. Let's take a look at the measures companies are taking to address this persistent issue.},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/B596R9TC/twitters-algorithm-failure-shows-big-techs-ongoing-struggle-with-ai-bias.html}
}

@misc{TwitterApologisesRacist2020,
  title = {Twitter Apologises for 'racist' Image-Cropping Algorithm},
  year = {2020},
  month = sep,
  journal = {the Guardian},
  urldate = {2020-09-22},
  abstract = {Users highlight examples of feature automatically focusing on white faces over black ones},
  chapter = {Technology},
  howpublished = {http://www.theguardian.com/technology/2020/sep/21/twitter-apologises-for-racist-image-cropping-algorithm},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/7QBZP46C/twitter-apologises-for-racist-image-cropping-algorithm.html}
}

@misc{TwitterApologizesUsers,
  title = {Twitter Apologizes after Users Notice Image-Cropping Algorithm Favours White Faces over {{Black}}},
  journal = {National Post},
  urldate = {2020-09-22},
  abstract = {PhD student Colin Madland was among the first to point out the issue after he attempted to post a two-up image of his face and that of his Black colleague's},
  howpublished = {https://nationalpost.com/news/world/twitter-apologizes-after-users-notice-image-cropping-algorithm-favours-white-faces-over-black},
  langid = {canadian},
  file = {/Users/colin.madland/Zotero/storage/4ZTKCZ86/twitter-apologizes-after-users-notice-image-cropping-algorithm-favours-white-faces-over-black.html}
}

@misc{TwitterBansConservative2021,
  title = {Twitter's {{Bans Conservative Accounts Like Project Veritas}}, {{Still Gives Whites Better Treatment Than Blacks}}},
  year = {2021},
  month = feb,
  journal = {Oakland News Now Today Blog - SF Bay Area Daily By Zennie62Media},
  urldate = {2021-02-17},
  abstract = {Twitter's Bans Conservative Accounts Like Project Veritas, Still Gives Whites Better Treatment Than Blacks {\textbar} Oakland News Now Today Blog - SF Bay Area Daily By Zennie62Media},
  howpublished = {https://oaklandnewsnow.com/twitters-bans-conservative-accounts-like-project-veritas-still-gives-whites-better-treatment-than-blacks/u-s-news/02/15/2021/09/52/11/79634/},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/WFRWLLAJ/79634.html}
}

@misc{TwitterCDOAcknowledges2020,
  title = {Twitter {{CDO}} Acknowledges "Racist" Photo Algorithm: "{{It}}'s 100 Percent Our Fault"},
  shorttitle = {Twitter {{CDO}} Acknowledges "Racist" Photo Algorithm},
  year = {2020},
  month = sep,
  journal = {Newsweek},
  urldate = {2020-09-22},
  abstract = {An algorithm used to decide which sections of an image are cropped and displayed in tweet previews will be investigated after accusations of racial bias.},
  chapter = {Tech \& Science},
  howpublished = {https://www.newsweek.com/twitter-image-preview-neural-network-racial-bias-dantley-davis-1533195},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/LBLJR4PY/twitter-image-preview-neural-network-racial-bias-dantley-davis-1533195.html}
}

@misc{TwitterHasMore,
  title = {Twitter Has 'more Analysis to Do' after Algorithm Shows Possible Racial Bias},
  journal = {Engadget},
  urldate = {2020-09-22},
  abstract = {Twitter plans to study its algorithm after an experiment showed possible signs of racial bias.},
  howpublished = {https://www.engadget.com/twitter-responds-to-algorithm-racial-bias-claims-203337604.html},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/SBQBQESD/twitter-responds-to-algorithm-racial-bias-claims-203337604.html}
}

@misc{TwitterInvestigateRacial,
  title = {Twitter to Investigate Racial Bias in Its Picture-Cropping Algorithm},
  journal = {NBC News},
  urldate = {2020-09-22},
  abstract = {Twitter says it's investigating why its picture-cropping algorithm sometimes prefers white faces to Black ones.},
  howpublished = {https://www.nbcnews.com/tech/tech-news/twitter-investigate-racial-bias-picture-cropping-algorithm-rcna130},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/L4ARSWSF/twitter-investigate-racial-bias-picture-cropping-algorithm-rcna130.html}
}

@misc{TwitterInvestigateRacial2020,
  title = {Twitter to Investigate Racial Profiling Algorithm after Users Say Auto-Feature Favours White Faces},
  year = {2020},
  month = sep,
  urldate = {2020-09-22},
  abstract = {The image preview function of Twitter's mobile app automatically crops pictures that are too big to fit on the screen and selects which parts of the image to display and cut off. Which part of the picture it features has drawn criticism.},
  howpublished = {https://www.abc.net.au/news/2020-09-22/twitter-racial-profiling-algorithm/12687796},
  langid = {australian},
  file = {/Users/colin.madland/Zotero/storage/JJVH4JIG/12687796.html}
}

@misc{TwitterInvestigateRacist,
  title = {Twitter to Investigate 'racist' Image-Cropping Function},
  journal = {SBS News},
  urldate = {2020-09-22},
  abstract = {Users of the social media site have pointed out a possible racial bias in Twitter's image cropping algorithm which relies on facial recognition.},
  howpublished = {https://www.sbs.com.au/news/twitter-to-investigate-racist-image-cropping-function},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/9T5U4UU8/twitter-to-investigate-racist-image-cropping-function.html}
}

@misc{TwitterInvestigatesApparent,
  title = {Twitter {{Investigates Apparent Racial Bias}} in {{Photo Preview Algorithm}}},
  journal = {PCMAG},
  urldate = {2020-09-22},
  abstract = {The company has 'more analysis to do' on the neural network.},
  howpublished = {https://www.pcmag.com/news/twitter-investigates-apparent-racial-bias-in-photo-preview-algorithm},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/N4RBAVPD/twitter-investigates-apparent-racial-bias-in-photo-preview-algorithm.html}
}

@article{TwitterInvestigatesRacial2020,
  title = {Twitter Investigates Racial Bias in Image Previews},
  year = {2020},
  month = sep,
  journal = {BBC News},
  urldate = {2020-09-22},
  abstract = {After users highlight problems, Twitter says more work on racial bias in algorithms is needed.},
  chapter = {Technology},
  langid = {british},
  file = {/Users/colin.madland/Zotero/storage/IAUUEZU7/technology-54234822.html}
}

@misc{TwitterInvestigateWhy,
  title = {Twitter to {{Investigate Why Its Picture Cropping Algorithm Is Apparently Racist}}},
  journal = {The Root},
  urldate = {2020-09-22},
  abstract = {Considering how little diversity is present in Silicon Valley, I'm never terribly surprised when some arbitrary feature on a tech platform turns out to have a racial bias. I mean, if white people aren't thinking about how their racial bias affects people in the real world, I doubt they're thinking about how it affects cropping a picture on Twitter.},
  howpublished = {https://www.theroot.com/twitter-to-investigate-why-its-picture-cropping-algorit-1845133273},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/LGMH9ES4/twitter-to-investigate-why-its-picture-cropping-algorit-1845133273.html}
}

@misc{TwitterInvestigatingClaims,
  title = {Twitter Is Investigating Claims That Its Picture-Cropping Tool Favours White Faces},
  journal = {BusinessInsider},
  urldate = {2020-09-22},
  abstract = {Users began to notice that the algorithm behind Twitter's automatic cropping tool appeared to be systematically favouring White faces.},
  howpublished = {https://www.businessinsider.co.za/twitter-investigating-picture-preview-algorithm-racial-bias-2020-9},
  file = {/Users/colin.madland/Zotero/storage/3LT8RXE6/twitter-investigating-picture-preview-algorithm-racial-bias-2020-9.html}
}

@misc{TwitterInvestigatingPossible2020,
  title = {Twitter Investigating Possible Racial Bias in Photo Preview Algorithm},
  year = {2020},
  month = sep,
  journal = {MobileSyrup},
  urldate = {2020-09-22},
  abstract = {Twitter is going to investigate whether its algorithm has a racial bias, after experiments have shown that it favours faces of white people over Black people.},
  chapter = {News},
  howpublished = {https://mobilesyrup.com/2020/09/21/twitter-investigating-possible-racial-bias-in-photo-preview-algorithm/},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/FZ7ET6MQ/twitter-investigating-possible-racial-bias-in-photo-preview-algorithm.html}
}

@misc{TwitterPhotoCropping,
  title = {Twitter's {{Photo Cropping Algorithm Draws Heat}} for {{Possible Racial Bias}}},
  urldate = {2020-09-22},
  howpublished = {https://petapixel.com/2020/09/21/twitter-photo-algorithm-draws-heat-for-possible-racial-bias/},
  file = {/Users/colin.madland/Zotero/storage/ASH2NWUD/twitter-photo-algorithm-draws-heat-for-possible-racial-bias.html}
}

@misc{TwitterSaysIt2020,
  title = {Twitter {{Says}} It's {{Investigating}} Its {{Algorithm After Users Claim Racial Bias}}},
  year = {2020},
  month = sep,
  journal = {Gizmodo Australia},
  urldate = {2020-09-22},
  abstract = {A Twitter spokesperson confirmed the company was looking into allegations of racial bias in how the platform chooses to preview images.},
  howpublished = {https://www.gizmodo.com.au/2020/09/twitter-says-its-investigating-its-algorithm-after-users-claim-racial-bias/},
  langid = {australian},
  file = {/Users/colin.madland/Zotero/storage/5WRCVY2W/twitter-says-its-investigating-its-algorithm-after-users-claim-racial-bias.html}
}

@misc{TwitterSaysIts,
  title = {Twitter Says Its Image-Cropping Algorithm Was Biased, so It's Ditching It}
}

@misc{TwitterScramblingFigure,
  title = {Twitter's Scrambling to Figure out Why Its Preview Tool Seems Racist},
  journal = {Gizmodo},
  urldate = {2020-09-22},
  abstract = {The neural network Twitter uses to generate photo previews is a mysterious beast. When it debuted the smart cropping tool back in 2018, Twitter said the algorithm determines the most ``salient'' part of the picture, i.e. what your eyes are drawn to first, to use as a preview image, but what exactly that entails has been the subject of frequent speculation.},
  howpublished = {https://gizmodo.com/twitters-scrambling-to-figure-out-why-its-photo-preview-1845123415},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/BYHY3E74/twitters-scrambling-to-figure-out-why-its-photo-preview-1845123415.html}
}

@misc{TwitterScramblingFigure2020,
  title = {Twitter's {{Scrambling}} to {{Figure Out Why Its Photo Preview Algorithm Seems Racist}}},
  year = {2020},
  month = sep,
  journal = {Gizmodo Australia},
  urldate = {2020-09-22},
  abstract = {The neural network Twitter uses to generate photo previews is a mysterious beast. When it debuted the smart cropping tool back in 2018, Twitter said the algorithm determines the most ``salient'' part of the picture, i.e. what your eyes are drawn to first, to use as a preview image, but...},
  howpublished = {https://www.gizmodo.com.au/2020/09/twitters-scrambling-to-figure-out-why-its-photo-preview-algorithm-seems-racist/},
  langid = {australian},
  file = {/Users/colin.madland/Zotero/storage/AUFLYPWT/twitters-scrambling-to-figure-out-why-its-photo-preview-algorithm-seems-racist.html}
}

@misc{TwitterUsersSay,
  title = {Twitter Users Say the Platform Crops out {{Black}} Faces},
  urldate = {2020-09-22},
  abstract = {Social media platform launched probe after users complained that its photo preview tool appears biased.},
  howpublished = {https://www.cbsnews.com/news/twitter-image-cropping-algorithm-racial-profiling/},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/QRXH2L6Z/twitter-image-cropping-algorithm-racial-profiling.html}
}

@misc{TwitterZoomAlgorithmic,
  title = {Twitter and {{Zoom}}'s Algorithmic Bias Issues},
  journal = {TechCrunch},
  urldate = {2020-09-22},
  abstract = {Both Zoom and Twitter found themselves under fire this weekend for their respective issues with algorithmic bias. On Zoom, it's an issue with the video conferencing service's virtual backgrounds and on Twitter, it's an issue with the site's photo cropping tool. It started wh{\dots}},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/C8MDND28/twitter-and-zoom-algorithmic-bias-issues.html}
}

@inproceedings{tynanPodcastingStudentLearning,
  title = {Podcasting, Student Learning and Expectations},
  booktitle = {The 23rd {{Annual Conference}} of the {{Australasian Society}} for {{Computers}} in {{Learning}} in {{Tertiary Education}}},
  author = {Tynan, Belinda and Colbran, Stephen},
  editor = {Markauskaite, Lina and Goodyear, Peter and Reimann, Peter},
  pages = {825--832},
  publisher = {Sydney University Press}
}

@article{tzafilkouDevelopmentValidationStudents2022,
  title = {Development and Validation of Students' Digital Competence Scale ({{SDiCoS}})},
  author = {Tzafilkou, Katerina and Perifanou, Maria and Economides, A. A.},
  year = {2022},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {19},
  number = {1},
  pages = {30},
  issn = {2365-9440},
  doi = {10.1186/s41239-022-00330-0},
  urldate = {2023-03-16},
  abstract = {Abstract             Towards the transition to blended and remote education, evaluating the levels of students' digital competence and designing educational programs to advance them is of paramount importance. Existing validated digital competence scales usually ignore either important digital skills needed or new socio-technological innovations. This study proposes and validates a comprehensive digital competence scale for students in higher education. The suggested instrument includes skills of online learning and collaboration, social media, smart and mobile devices, safety, and data protection. The scale was evaluated on a sample of 156 undergraduate and postgraduate students just before and at the beginning of the COVID-19 crisis. The final scale is composed of 28 items and six digital competence components. The evaluation study revealed valid results in terms of model fit criteria, factor loadings, internal validity, and reliability. Individual factors like the students' field of study, computer experience and age revealed significant associations to the scale components, while gender revealed no significant differences. The suggested scale can be useful to the design of new actions and policies towards remote education and the digital skills' development of adult learners.},
  langid = {english},
  keywords = {digital-competence,digital-literacy},
  file = {/Users/colin.madland/Zotero/storage/FTGPJIPY/tzafilkouDevelopmentValidationStudents2022.pdf}
}

@misc{UBC,
  title = {{{UBC}}},
  urldate = {2022-12-20},
  howpublished = {https://www.calendar.ubc.ca/okanagan/index.cfm?tree=3,41,0,0},
  file = {/Users/colin.madland/Zotero/storage/BBD7TVU4/index.html}
}

@misc{uclastatisticalconsultinggroupConfirmatoryFactorAnalysis,
  title = {Confirmatory {{Factor Analysis}} ({{CFA}}) in {{R}} with Lavaan},
  author = {UCLA: Statistical Consulting Group},
  urldate = {2022-05-09},
  howpublished = {https://stats.oarc.ucla.edu/r/seminars/rcfa/},
  file = {/Users/colin.madland/Zotero/storage/D257R7KE/rcfa.html}
}

@article{udeozorGamebasedAssessmentFramework2023,
  title = {Game-Based Assessment Framework for Virtual Reality, Augmented Reality and Digital Game-Based Learning},
  author = {Udeozor, Chioma and Chan, Philippe and Russo Abeg{\~a}o, Fernando and Glassey, Jarka},
  year = {2023},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {20},
  number = {1},
  pages = {36--22},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-023-00405-6},
  abstract = {Immersive learning technologies such as virtual reality (VR), augmented reality (AR) and educational digital games offer many benefits to teaching and learning. With their potential to immerse learners in realistic environments and facilitate higher-order cognitive learning, these technologies could be used to complement current classroom pedagogical practices. However, given that these learning environments differ from conventional classroom learning activities, current assessment practices may be insufficient for assessing learning in immersive environments. This paper develops the concept of a game-based assessment framework (GBAF) for educators interested in the assessment of learning in digital games, VR or AR. Importantly, this paper also presents the application of the framework to the design and implementation of assessments for a VR game during the game design phase. Grounded in the principles of Constructive Alignment and the Evidence-Centred Design (ECD) framework, this assessment framework describes the steps to consider for assessments and outlines the components that must be aligned for the design of assessments. To illustrate the application of the GBAF to the design of assessments for immersive learning environments, a stepwise design of assessments for a VR game is presented. The results of the outcome of the assessment of laboratory health and safety competencies of six engineering students is also presented. The GBAF offers simple and useful guidelines for the design of assessments around game tasks. It could serve as a structured basis for educators and researchers to design assessments to measure lower and higher-order cognitive learning in complex immersive environments.},
  keywords = {Assessment,Assessment design,Assessments,Augmented reality,Classrooms,Computer & video games,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Design analysis,Education & Educational Research,Educational Technology,Engineering education,Games,Higher Education,Humanities,Immersive learning,Information Systems Applications (incl.Internet),Law,Learning,Research Article,Social Sciences,Statistics for Social Sciences,Virtual reality},
  file = {/Users/colin.madland/Zotero/storage/ANPAY8BR/udeozorGamebasedAssessmentFramework2023.pdf}
}

@article{udumaHowInstructionalDesigners2007,
  title = {How Do Instructional Designers Use Automated Instructional Design Tool?},
  author = {Uduma, Letitia and Morrison, Gary R.},
  year = {2007},
  journal = {Computers in Human Behavior},
  volume = {23},
  number = {1},
  pages = {536--553},
  abstract = {The purpose of this study was to investigate the use of an automated design tool by naive, novice, and expert instructional designers. A talk-aloud protocol, attitude survey, performance assessment, and direct observation were used to gather data. While the expert designers used the tool, they used it as a word processor with a rich database of instructional strategies. The novice designers relied on the tool for advice, guidance, and assistance in completing all the design tasks. Non-designers used the tool for learning about design. The novice designer is likely to gain more benefit from using the tool than a naI{\textlnot}{\AE}ve or expert designer. Novice designers can use the tool to reinforce their prior knowledge as well as filling in any gaps in the knowledge of the design process. Based on this study, we might expect the use of an automated tool to diminish as the designer gains experience. Non-designers should probably be trained on instructional design tasks prior to exposure to automated instructional design tools.},
  keywords = {Automated,Design,Instructional}
}

@article{ugwuanyiEnhancingUniversityStudents2020,
  title = {Enhancing {{University Students}}' {{Achievement}} in {{Physics Using Computer-Assisted Instruction}}},
  author = {Ugwuanyi, Christian S. and Okeke, Chinedu I. O.},
  year = {2020},
  month = jan,
  journal = {International Journal of Higher Education},
  volume = {9},
  number = {5},
  pages = {115--124},
  publisher = {International Journal of Higher Education},
  issn = {1927-6044},
  doi = {10.5430/ijhe.v9n5p115},
  abstract = {Twenty-first century classrooms have come with a lot of changes in instructional delivery at various levels of education. However, most lecturers in Nigerian universities still adopt the traditional method of instruction not minding the demands of the twenty-first century classrooms. As a result of this, there is a dearth of empirical evidence on the impact of computer-assisted instruction on the students' achievement in physics. This study, therefore, sought the efficacy of computer-assisted instruction (CAI) on students' achievement in physics. A randomized controlled trial experimental design was adopted for the study using a sample of 120 participants. Physics Achievement Test (PAT) was used to collect data for the study. Analysis of covariance was used to analyze the data. It was found that Computer-Assisted Instruction (CAI) had a significant effect on students' achievement in physics at posttest and follow-up assessments. Thus, Physics education lecturers should be trained on how to design and use CAI package for effective twenty-first century classroom instructional delivery in a Nigerian university.},
  keywords = {College Students,Computer Assisted Instruction,Foreign Countries,Instructional Effectiveness,Nigeria,Physics,Pretests Posttests,Science Achievement},
  file = {/Users/colin.madland/Zotero/storage/9YN64PYL/ugwuanyiEnhancingUniversityStudents2020.pdf}
}

@article{ujirTeachingWorkload21st2020,
  title = {Teaching {{Workload}} in 21st {{Century Higher Education Learning Setting}}},
  author = {Ujir, Hamimah and Salleh, Shanti Faridah and Marzuki, Ade Syaheda Wani and Hashim, Hashimatul Fatma and Alias, Aidil Azli},
  year = {2020},
  journal = {International Journal of Evaluation and Research in Education},
  volume = {9},
  number = {1},
  pages = {221--227},
  issn = {ISSN-2252-8822},
  abstract = {A standard equation on teaching workload calculation in the previous academic setting only includes the contact hours with students through lecture, tutorial, laboratory and in-person consultation (i.e. one-to-one final year project consultation). This paper discusses teaching workload factors according to the current higher-education setting. Devising a teaching workload equation that includes all teaching and learning strategies in the 21st century higher education learning setting is needed. This is indeed a challenging task for the academic administrators to scrutinize every single parameter that accounted for teaching and learning. In this work, we have discussed the parameters which are significant in teaching workload calculation. For instance, the conventional in-person contact with the students, type of delivery, type of assessment, the preparation of materials for flipped classroom as well as MOOC, to name a few. Teaching workload also affects quality teaching and from the academic perception, the higher workload means lower-quality teaching.},
  langid = {english},
  keywords = {Blended Learning,College Faculty,Evaluation Methods,Foreign Countries,Material Development,No DOI found,Online Courses,Student Evaluation,Teacher Effectiveness,Teacher Student Relationship,Teaching Load}
}

@misc{UNBC,
  title = {{{UNBC}}},
  journal = {University of Northern British Columbia},
  urldate = {2022-12-20},
  abstract = {I. Formal Relationship Between the University and Students Upon registering and while registered in a for-credit course, program of study or audited course offered by or through the University of Northern British Columbia (UNBC), a Student enters a formal relationship with the University by which they},
  howpublished = {https://www2.unbc.ca/calendar/undergraduate/regulations},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/7YYLHDQB/regulations.html}
}

@incollection{underwoodDigitalTechnologiesEffective2014,
  title = {Digital {{Technologies}}: {{An Effective Educational Change Agent}}?},
  booktitle = {Research on E-{{Learning}} and {{ICT}} in {{Education}}: {{Technological}}, {{Pedagogical}} and {{Instructional Perspectives}}},
  author = {Underwood, Jean},
  editor = {Karagiannidis, Charalampos and Politis, Panagiotis and Karasavvidis, Ilias},
  year = {2014},
  pages = {3--14},
  publisher = {Springer New York},
  address = {New York, NY},
  doi = {10.1007/978-1-4614-6501-0_1},
  abstract = {This chapter questions why digital technology is a ubiquitous tool outside of the classroom but is less well received within the classroom. It addresses the questions of what happens if we, the educators, fail to embrace technology and ask could the technology take education itself out of the classroom and the hands of educators themselves.},
  isbn = {978-1-4614-6501-0},
  file = {/Users/colin.madland/Zotero/storage/I3YATRRR/underwoodDigitalTechnologiesEffective2014.pdf}
}

@article{ungererDigitalCurationCore2016,
  title = {Digital {{Curation}} as a {{Core Competency}} in {{Current Learning}} and {{Literacy}}: {{A Higher Education Perspective}}},
  shorttitle = {Digital {{Curation}} as a {{Core Competency}} in {{Current Learning}} and {{Literacy}}},
  author = {Ungerer, Leona M.},
  year = {2016},
  month = sep,
  journal = {The International Review of Research in Open and Distributed Learning},
  volume = {17},
  number = {5},
  issn = {1492-3831},
  doi = {10.19173/irrodl.v17i5.2566},
  urldate = {2024-03-19},
  abstract = {{$<$}p class="3"{$>$}Digital curation may be regarded as a core competency in higher education since it contributes to establishing a sense of metaliteracy (an essential requirement for optimally functioning in a modern media environment) among students. Digital curation is gradually finding its way into higher education curricula aimed at fostering social media literacies. Teachers are urged to blend informal and formal learning and since most people informally use curation in their daily lives for compiling relevant information, it may be fairly easy to adopt digital curation in teaching and learning. Teachers, however, require considerable insight in incorporating various informal digital curation tools in educational practices. ~The SECTIONS model may assist in guiding decisions around the suitability of digital curation tools for a higher education environment. Including digital literacy training in the professional development of academic staff members may sensitize them to the possibilities that incorporating digital approaches in curricula offer. The Five Cs of Digital Curation framework may guide academic staff members in compiling suitable digital material. There as yet appears not to be a pedagogy that fully acknowledges the various digital curation processes. A pedagogy of abundance, acknowledging that content often is freely available and abundant, may eventually prove relevant in this regard.{$<$}/p{$>$}},
  file = {/Users/colin.madland/Zotero/storage/LYVVJJMH/ungererDigitalCurationCore2016.pdf}
}

@article{UnifiedTheoryAcceptance2020,
  title = {Unified Theory of Acceptance and Use of Technology},
  year = {2020},
  month = apr,
  journal = {Wikipedia},
  urldate = {2020-04-07},
  abstract = {The unified theory of acceptance and use of technology (UTAUT) is a technology acceptance model formulated by Venkatesh and others in "User acceptance of information technology: Toward a unified view". The UTAUT aims to explain user intentions to use an information system and subsequent usage behavior. The theory holds that there are four key constructs:  1) performance expectancy,  2) effort expectancy,  3) social influence, and  4) facilitating conditions. The first three are direct determinants of usage intention and behavior, and the fourth is a direct determinant of user behavior. Gender, age, experience, and voluntariness of use are posited to moderate the impact of the four key constructs on usage intention and behavior. The theory was developed through a review and consolidation of the constructs of eight models that earlier research had employed to explain information systems usage behaviour (theory of reasoned action, technology acceptance model, motivational model, theory of planned behavior, a combined theory of planned behavior/technology acceptance model, model of personal computer use, diffusion of innovations theory, and social cognitive theory). Subsequent validation by Venkatesh et al. (2003) of UTAUT in a longitudinal study found it to account for 70\% of the variance in Behavioural Intention to Use (BI) and about 50\% in actual use.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 948658359},
  file = {/Users/colin.madland/Zotero/storage/W3EFE3IU/index.html}
}

@techreport{unitednationsUnitedNationsDeclaration2007,
  title = {United {{Nations Declaration}} on the {{Rights}} of {{Indigenous Peoples}}},
  author = {United Nations},
  year = {2007},
  institution = {United Nations},
  urldate = {2019-03-30},
  langid = {english}
}

@article{UNIVERSITYBRITISHCOLUMBIA,
  title = {{{THE UNIVERSITY OF BRITISH COLUMBIA}}},
  langid = {english}
}

@misc{universityFinalProjectsStanford,
  title = {Final {{Projects}} from the {{Stanford Internet Observatory}}'s {{Online Open Source Investigation Course}}},
  author = {University, {\copyright} Stanford and {Stanford} and California 94305},
  urldate = {2022-02-08},
  howpublished = {https://cyber.fsi.stanford.edu/io/news/final-projects-osint-course},
  langid = {english},
  keywords = {archived},
  annotation = {https://web.archive.org/web/20220208192247/https://cyber.fsi.stanford.edu/io/news/final-projects-osint-course},
  file = {/Users/colin.madland/Zotero/storage/4T27PVL4/universityFinalProjectsStanford.pdf}
}

@misc{universityFinalProjectsStanforda,
  title = {Final {{Projects}} from the {{Stanford Internet Observatory}}'s {{Online Open Source Investigation Course}}},
  author = {University, {\copyright} Stanford and {Stanford} and {California 94305}},
  urldate = {2022-02-08},
  howpublished = {https://cyber.fsi.stanford.edu/io/news/final-projects-osint-course},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/SAEGCRT7/University et al. - Final Projects from the Stanford Internet Observat.html}
}

@misc{UniversityIndigenousLeaders,
  title = {University, {{Indigenous}} Leaders Call for Collaboration at Reconciliation Forum},
  journal = {University Affairs},
  urldate = {2018-11-30},
  abstract = {Helping one another was a central theme of fourth national forum held at the University of Victoria.},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/26C2JR7F/university-indigenous-leaders-call-for-collaboration-at-reconciliation-forum.html}
}

@book{universityofalbertalibraryEducationalPsychologyLibrary2020,
  title = {Educational {{Psychology Library Lab Manual}}},
  author = {{University of Alberta Library} and Lacroix, Denis},
  year = {2020},
  month = sep,
  publisher = {University of Alberta Library},
  doi = {10.29173/oer10},
  urldate = {2020-09-14},
  isbn = {978-1-55195-450-9}
}

@article{universityofsouthaustraliaSlowmationInnovativeTwentyFirst2016,
  title = {Slowmation: {{An Innovative Twenty-First Century Teaching}} and {{Learning Tool}} for {{Science}} and {{Mathematics Pre-service Teachers}}},
  shorttitle = {Slowmation},
  author = {{University of South Australia} and Paige, Kathryn and Bentley, Brendan and {University of South Australia} and Dobson, Stephen and {University of South Australia}},
  year = {2016},
  month = feb,
  journal = {The Australian Journal of Teacher Education},
  volume = {41},
  number = {2},
  pages = {1--15},
  issn = {1835517X},
  doi = {10.14221/ajte.2016v41n2.1},
  urldate = {2022-10-31},
  file = {/Users/colin.madland/Zotero/storage/7ZETN5I9/universityofsouthaustraliaSlowmationInnovativeTwentyFirst2016.pdf}
}

@misc{universityofvictorialegacyartgalleriesCoastSalishDesign2015,
  title = {Coast {{Salish Design Elements}} {\textbar} {{Perpetual Salish}}},
  author = {{University of Victoria Legacy Art Galleries}},
  year = {2015},
  urldate = {2019-03-29},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/YY25454U/coast-salish-design-elements.html}
}

@misc{universityofvictorialegacyartgalleriesCoastSalishTerritories2015,
  title = {Coast {{Salish Territories Maps}}},
  author = {{University of Victoria Legacy Art Galleries}},
  year = {2015},
  journal = {Perpetual Salish},
  urldate = {2019-03-28},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/XDCUSI4N/coast-salish-territories-maps.html}
}

@misc{UniversityprisonPartnershipBrings,
  title = {University-Prison Partnership Brings Hope to Incarcerated Learners},
  journal = {University Affairs},
  urldate = {2018-06-12},
  abstract = {The educational initiative ``was humanizing when every aspect of imprisonment is dehumanizing,'' says a former participant.},
  howpublished = {https://www.universityaffairs.ca/news/news-article/university-prison-partnership-brings-hope-to-incarcerated-learners/},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/LB8XU5JF/university-prison-partnership-brings-hope-to-incarcerated-learners.html}
}

@misc{universitySelectionFinalProjects,
  title = {A {{Selection}} of {{Final Projects}} from the {{Stanford Internet Observatory}}'s {{Online Open Source Investigation Course}}},
  author = {University, {\copyright} Stanford and {Stanford} and California 94305},
  urldate = {2022-02-08},
  abstract = {In fall 2021, the Stanford Internet Observatory offered the fourth iteration of its Online Open Source Investigation course. The class covers strategies for investigating content on social media, c...},
  howpublished = {https://purl.stanford.edu/hy452dc9889},
  langid = {english}
}

@misc{universitySelectionFinalProjectsa,
  title = {A {{Selection}} of {{Final Projects}} from the {{Stanford Internet Observatory}}'s {{Online Open Source Investigation Course}}},
  author = {University, {\copyright} Stanford and {Stanford} and {California 94305}},
  urldate = {2022-02-08},
  abstract = {In fall 2021, the Stanford Internet Observatory offered the fourth iteration of its Online Open Source Investigation course. The class covers strategies for investigating content on social media, c...},
  howpublished = {https://purl.stanford.edu/hy452dc9889},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/P3AZJEWI/University et al. - A Selection of Final Projects from the Stanford In.html}
}

@article{urryDonDitchLaptop2021,
  title = {Don't {{Ditch}} the {{Laptop Just Yet}}: {{A Direct Replication}} of {{Mueller}} and {{Oppenheimer}}'s (2014) {{Study}} 1 {{Plus Mini Meta-Analyses Across Similar Studies}}},
  shorttitle = {Don't {{Ditch}} the {{Laptop Just Yet}}},
  author = {Urry, Heather L. and Crittle, Chelsea S. and Floerke, Victoria A. and Leonard, Michael Z. and Perry, Clinton S. and Akdilek, Naz and Albert, Erica R. and Block, Avram J. and Bollinger, Caroline Ackerley and Bowers, Emily M. and Brody, Renee S. and Burk, Kelly C. and Burnstein, Ally and Chan, Allissa K. and Chan, Petrina C. and Chang, Lena J. and Chen, Emily and Chiarawongse, Chakrapand Paul and Chin, Gregory and Chin, Kathy and Cooper, Ben G. and Corneilson, Katherine Adele and Danielson, Amanda M. and Davis, Elizabeth S. and Devis, Ycar and Dong, Melissa and Dossett, Elizabeth K. and Dulchin, Nick and Duong, Vincent N. and Ewing, Ben and Fuller, Julia Mansfield and Gartman, Thomas E. and Goldberg, Chad R. and Greenfield, Jesse and Groh, Selena and Hamilton, Ross A. and Hodge, Will and Van Hong, Dylan and Insler, Joshua E. and Jahan, Aava B. and Jimbo, Jessica Paola and Kahn, Emma M. and Knight, Daniel and Konstantin, Grace E. and Kornick, Caitlin and Kramer, Zachary J. and Lauz{\'e}, Meghan S. and Linnehan, Misha S. and Lombardi, Tommaso and Long, Hayley and Lotstein, Alec J. and Lyncee, Myrna-Nahisha A. and Lyons, Monica Gabriella and Maayan, Eli and May, Nicole Marie and McCall, Elizabeth C. and {Montgomery-Walsh}, Rhea Ann Charlotte and Morscher, Michael C. and Moser, Amelia D. and Mueller, Alexandra S. and Mujica, Christin A. and Na, Elim and Newman, Isabelle R. and O'Brien, Meghan K. and Ochoa Castillo, Katherine Alexandra and Onipede, Zaenab Ayotola and Pace, Danielle A. and Park, Jasper H. and Perdikari, Angeliki and Perloff, Catherine E. and Perry, Rachel C. and Pillai, Akash A. and Rajpal, Avni and Ranalli, Emma and Schreier, Jillian E. and Shangguan, Justin R. and Silver, Micaela Jen and Spratt, Avery Glennon and Stein, Rachel E. and Steinhauer, Grant J. and Valera, Devon K. and Vervoordt, Samantha M. and Walton, Lena and Weinflash, Noah W. and Weinstock, Karen and Yuan, Jiaqi and Zarrella, Dominique T. and Zarrow, Jonah E.},
  year = {2021},
  month = mar,
  journal = {Psychological Science},
  volume = {32},
  number = {3},
  pages = {326--339},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797620965541},
  urldate = {2024-05-06},
  abstract = {In this direct replication of Mueller and Oppenheimer's (2014) Study 1, participants watched a lecture while taking notes with a laptop ( n = 74) or longhand ( n = 68). After a brief distraction and without the opportunity to study, they took a quiz. As in the original study, laptop participants took notes containing more words spoken verbatim by the lecturer and more words overall than did longhand participants. However, laptop participants did not perform better than longhand participants on the quiz. Exploratory meta-analyses of eight similar studies echoed this pattern. In addition, in both the original study and our replication, higher word count was associated with better quiz performance, and higher verbatim overlap was associated with worse quiz performance, but the latter finding was not robust in our replication. Overall, results do not support the idea that longhand note taking improves immediate learning via better encoding of information.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/KD2NQQX2/urryDonDitchLaptop2021.pdf}
}

@misc{UsersCriticiseTwitter2020,
  title = {Users Criticise {{Twitter}} over `Racism' in Photo Previews, Company Says It Will Look into It},
  year = {2020},
  month = sep,
  journal = {The Indian Express},
  urldate = {2020-09-22},
  abstract = {Several Twitter users posted photographs that had a white and black person's face to back their claim that the preview was more likely to show the white person's face.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/598Z79UZ/twitter-algorithm-racial-bias-photo-preview-6604950.html}
}

@misc{usherDataTextbookCosts2015,
  title = {Data on {{Textbook Costs}}},
  author = {Usher, Alex},
  year = {2015},
  month = feb,
  journal = {HESA},
  urldate = {2018-05-21},
  abstract = {This data is a little old (2012), but it's interesting, so~my colleague Jacqueline Lambert and I~thought~we'd share it with you.~ Back then, when HESA was running a student panel, we asked about 1350 university students},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/9UBNRJE4/data-on-textbook-costs.html}
}

@article{usherDevelopingEvaluativeJudgement2020,
  title = {Developing Evaluative Judgement in Higher Education. {{Assessment}} for Knowing and Producing Quality Work},
  shorttitle = {Developing Evaluative Judgement in Higher Education. {{Assessment}} for Knowing and Producing Quality Work},
  author = {Usher, Natalie},
  year = {2020},
  month = nov,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {27},
  number = {6},
  pages = {707--710},
  issn = {0969-594X, 1465-329X},
  doi = {10.1080/0969594X.2020.1850419},
  urldate = {2022-05-04},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/34RTZMLE/usherDevelopingEvaluativeJudgement2020.pdf}
}

@article{usoofDesigningEassessmentHigher2012,
  title = {Designing for Eassessment of Higher Order Thinking an Undergraduate It Online Distance Education Course in Sri Lanka},
  author = {Usoof, Hakim},
  year = {2012},
  journal = {null},
  doi = {null},
  abstract = {Distance education has seen rapid growth over the recent decades. The rapid development of Information Communication Technology [ICT] has been one of the main drivers of this growth in distance edu ...},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@article{usoofDesigningEassessmentHigher2012a,
  title = {Designing for Eassessment of Higher Order Thinking an Undergraduate It Online Distance Education Course in Sri Lanka},
  author = {Usoof, Hakim},
  year = {2012},
  journal = {null},
  doi = {null},
  abstract = {Distance education has seen rapid growth over the recent decades. The rapid development of Information Communication Technology [ICT] has been one of the main drivers of this growth in distance edu ...},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@article{utoReviewDeepneuralAutomated2021,
  title = {A Review of Deep-Neural Automated Essay Scoring Models},
  author = {Uto, Masaki},
  year = {2021},
  journal = {Behaviormetrika},
  volume = {48},
  number = {2},
  pages = {459--484},
  issn = {0385-7417, 1349-6964},
  doi = {10.1007/s41237-021-00142-y},
  urldate = {2022-03-12},
  abstract = {Abstract             Automated essay scoring (AES) is the task of automatically assigning scores to essays as an alternative to grading by humans. Although traditional AES models typically rely on manually designed features, deep neural network (DNN)-based AES models that obviate the need for feature engineering have recently attracted increased attention. Various DNN-AES models with different characteristics have been proposed over the past few years. To our knowledge, however, no study has provided a comprehensive review of DNN-AES models while introducing each model in detail. Therefore, this review presents a comprehensive survey of DNN-AES models, describing the main idea and detailed architecture of each model. We classify the AES task into four types and introduce existing DNN-AES models according to this classification.},
  langid = {english},
  keywords = {archived},
  annotation = {https://web.archive.org/web/20220312235714/https://link.springer.com/article/10.1007/s41237-021-00142-y},
  file = {/Users/colin.madland/Zotero/storage/N3EASHNU/utoReviewDeepneuralAutomated2021.pdf}
}

@article{utzVoluntaryWebBasedSelfAssessment2018a,
  title = {Voluntary {{Web-Based Self-Assessment Quiz Use Is Associated}} with {{Improved Exam Performance}}, {{Especially}} for {{Learners}} with {{Low Prior Knowledge}}},
  author = {Utz, Jenifer C. and Bernacki, Matthew L.},
  year = {2018},
  month = aug,
  journal = {HAPS Educator},
  volume = {22},
  number = {2},
  pages = {129--135},
  publisher = {HAPS Educator},
  issn = {2473-3806},
  abstract = {This study examined students' voluntary use of digital self-assessment quizzes as a resource for learning in a large anatomy and physiology lecture course. Students (n = 238) could use 16 chapter quizzes and four analogous unit quizzes to rehearse and self-assess knowledge. Most students (75\%) engaged in occasional use of self-assessment quiz items; repeated use was uncommon (12\%), as was lack of use (13\%). Exam performance differed between quiz use groups. Quiz use improved exam performance more among students who entered the course with low prior knowledge of concepts from the prerequisite course. Cumulatively for all students and all exams, repeated self-assessment quiz users significantly outperformed occasional users (+7.5\%) and nonusers (+11.9\%) on course exams. Incorporation of optional learning resources can enhance the learning success of students.},
  keywords = {Anatomy,College Science,Computer Assisted Testing,Knowledge Level,Nevada (Las Vegas),No DOI found,Physiology,Prior Learning,Science Achievement,Science Tests,Self Evaluation (Individuals),Undergraduate Students}
}

@misc{UVic,
  title = {{{UVic}}},
  journal = {UVic.ca},
  urldate = {2022-12-20},
  abstract = {As of Summer Session 2014 (term 201405), grades are now being submitted as a percentage rather than a letter grade. This change, approved by Senate in May 2013, moved UVic in line with other Canadian ...},
  howpublished = {https://www.uvic.ca/registrar/faculty-staff/academics/grades/index.php},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/ABC2CWME/index.html}
}

@article{valizadehCheatingOnlineLearning2022,
  title = {Cheating in Online Learning Programs: Learners' Perceptions and Solutions},
  author = {Valizadeh, Mohammadreza},
  year = {2022},
  journal = {The Turkish online journal of distance education TOJDE},
  volume = {23},
  number = {1},
  pages = {195--209},
  issn = {1302-6488},
  doi = {10.17718/tojde.1050394},
  file = {/Users/colin.madland/Zotero/storage/8HB2IJN6/valizadehCHEATINGONLINELEARNING2022.pdf}
}

@article{valjatagaLearnerControlPersonal2010,
  title = {Learner Control and Personal Learning Environment: A Challenge for Instructional Design.},
  author = {V{\"a}ljataga, Terje and Laanpere, Mart},
  year = {/09 2010},
  journal = {Interactive Learning Environments},
  volume = {18},
  pages = {277--291},
  issn = {10494820},
  doi = {Article},
  abstract = {In an increasingly networked and technologically mediated world, people need to continuously update their knowledge and skill base, so as to be able to self-direct their intentional learning projects. In addition to teaching domain-specific knowledge and skills, the role of higher education should be reorganizing current teaching and studying practices in a way that allows students to take control over their projects and environments. Contemporary models of instructional design consider a learning environment as a predefined element in instruction created and controlled by an educational authority. On the other hand an emerging personal learning environment (PLE) discourse emphasizes learner control over an environment. However, current interpretations of PLEs leave other instructional functions unattended. The article proposes an elaborated understanding of PLE, one which integrates important instructional functions of learner control. The theoretical framework presented in this article is inspired by conceptual ideas developed within the iCamp ( www.icamp.eu) project. The article illustrates the line of argumentation with students experiences gathered from a pilot course taught at Tallinn University, Estonia. [ABSTRACT FROM AUTHOR] Copyright of Interactive Learning Environments is the property of Routledge and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
  keywords = {Educational technology,Estonia,instructional design,Instructional systems design,Intentional learning,learner control,personal learning environment,self-directing intentional learning project,Tallinn (Estonia),Tallinn University of Technology (Tallinn Estonia)}
}

@article{vanackerReturningStudentsRight2011,
  title = {Returning Students' Right to Access, Choice and Notice: A Proposed Code of Ethics for Instructors Using {{Turnitin}}},
  shorttitle = {Returning Students' Right to Access, Choice and Notice},
  author = {Vanacker, Bastiaan},
  year = {2011},
  month = dec,
  journal = {Ethics and Information Technology},
  volume = {13},
  number = {4},
  pages = {327--338},
  issn = {1388-1957, 1572-8439},
  doi = {10.1007/s10676-011-9277-3},
  urldate = {2019-08-25},
  langid = {english}
}

@article{vanderkleijEffectsFeedbackComputerBased2015,
  title = {Effects of {{Feedback}} in a {{Computer-Based Learning Environment}} on {{Students}}' {{Learning Outcomes}}: {{A Meta-Analysis}}},
  shorttitle = {Effects of {{Feedback}} in a {{Computer-Based Learning Environment}} on {{Students}}' {{Learning Outcomes}}},
  author = {{Van der Kleij}, Fabienne M. and Feskens, Remco C. W. and Eggen, Theo J. H. M.},
  year = {2015},
  month = dec,
  journal = {Review of Educational Research},
  volume = {85},
  number = {4},
  pages = {475--511},
  issn = {0034-6543, 1935-1046},
  doi = {10/gf9k5x},
  urldate = {2021-03-21},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/95YRQAQ5/vanderkleijEffectsFeedbackComputerBased2015.pdf}
}

@incollection{vanderkleijFormativeAssessmentFeedback2018,
  title = {Formative {{Assessment}} and {{Feedback Using Information Technology}}},
  booktitle = {Second {{Handbook}} of {{Information Technology}} in {{Primary}} and {{Secondary Education}}},
  author = {{\noopsort{kleij}}{van der Kleij}, Fabienne and Adie, Lenore},
  editor = {Voogt, Joke and Knezek, Gerald and Christensen, Rhonda and Lai, Kwok-Wing},
  year = {2018},
  pages = {601--615},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-71054-9_38},
  abstract = {Formative assessment including feedback to students on their learning is widely recognized as an effective means to support student learning. Research has found that the potential of formative assessment in improving student learning is often not fully realized in classroom practice. IT provides a possible solution for overcoming some of the obstacles when implementing formative assessment. This chapter reviews various ways in which IT has been used in formative assessment, focusing specifically on digital learning environments, game-based assessment, classroom response systems, Web 2.0, and video feedback. The results suggest that using IT as a platform for feedback provides opportunity to individualize feedback, increase student engagement, collect learning evidence for all students, facilitate reflective processes, and support self-regulated learning. Reported potential challenges to the utilization of IT include time restrictions, limited response formats, technical difficulties, access to evidence of student learning for teachers, and teacher knowledge and skills. One key finding is that although innovations in technology have evolved considerably, many promising possibilities are not yet being exploited for the purpose of formative assessment. Most importantly, research demonstrates that not the technologies themselves, but the ways in which they are used impact on their formative potential. Bringing together IT and formative assessment may open up the potential for moving from convergent forms of feedback to more open, divergent feedback practices.},
  isbn = {978-3-319-71054-9},
  file = {/Users/colin.madland/Zotero/storage/84CUSTFJ/vanderkleijFormativeAssessmentFeedback2018.pdf}
}

@article{vankolEffectsWebBasedFeedback2016,
  title = {Effects of {{Web-Based Feedback}} on {{Students}}' {{Learning}}},
  author = {{\noopsort{kol}}{van Kol}, Simone and Rietz, Christian},
  year = {2016},
  month = jan,
  journal = {International Journal of Teaching and Learning in Higher Education},
  volume = {28},
  number = {3},
  pages = {385--394},
  publisher = {{International Journal of Teaching and Learning in Higher Education}},
  issn = {1812-9129},
  abstract = {Feedback plays an important role in supporting students' learning process. Nonetheless, providing feedback is still rather unusual in higher education. Moreover, research on the design of ideal feedback as well as its effects is rare. In order to contribute to the development of this field, a web-based feedback system was implemented in a lecture at the University of Cologne. The effects of this feedback on the students' learning process are presented in this article. Differences in the students' learning success and motivation, as well as their assessment of competencies, are analyzed within an experimental setting. Students who received individual feedback through this system achieved higher grades and showed increased levels of motivation. Moreover, they felt more competent with regard to solving tasks related to the learning material.},
  keywords = {Academic Achievement,College Students,Competence,Control Groups,Experimental Groups,Feedback (Response),Foreign Countries,Germany,Higher Education,Internet,Lecture Method,Motivation,Multiple Choice Tests,Multivariate Analysis,No DOI found,Research Methodology,Statistical Analysis}
}

@article{vanlaarRelation21stcenturySkills2017,
  title = {The Relation between 21st-Century Skills and Digital Skills: {{A}} Systematic Literature Review},
  shorttitle = {The Relation between 21st-Century Skills and Digital Skills},
  author = {{\noopsort{laar}}{van Laar}, Ester and {\noopsort{deursen}}{van Deursen}, Alexander J.A.M. and {\noopsort{dijk}}{van Dijk}, Jan A.G.M. and {\noopsort{haan}}{de Haan}, Jos},
  year = {2017},
  month = jul,
  journal = {Computers in Human Behavior},
  volume = {72},
  pages = {577--588},
  issn = {07475632},
  doi = {10.1016/j.chb.2017.03.010},
  urldate = {2022-09-16},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/S3THUGBK/vanlaarRelation21stcenturySkills2017.pdf}
}

@book{vanmanenResearchingLivedExperience1990,
  title = {Researching Lived Experience: {{Human}} Science for an Action Sensitive Pedagogy},
  author = {{\noopsort{manen}}{van Manen}, Max},
  year = {1990},
  publisher = {State University of New York Press},
  address = {Albany, NY}
}

@article{vanslambrouckStudentsMotivationSubjective2018,
  title = {Students' Motivation and Subjective Task Value of Participating in Online and Blended Learning Environments},
  author = {Vanslambrouck, Silke and Zhu, Chang and Lombaerts, Koen and Philipsen, Brent and Tondeur, Jo},
  year = {2018},
  journal = {The Internet and Higher Education},
  volume = {36},
  pages = {33--40},
  issn = {10967516},
  doi = {10/gc5sdn},
  urldate = {2021-01-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/WH6J6NEJ/vanslambrouckStudentsMotivationSubjective2018.pdf}
}

@article{vanvughtGeneralModelQuality1994,
  title = {Towards a General Model of Quality Assessment in Higher Education},
  author = {Van Vught, Frans A. and Westerheijden, Don F.},
  year = {1994},
  month = oct,
  journal = {Higher Education},
  volume = {28},
  number = {3},
  pages = {355--371},
  issn = {0018-1560, 1573-174X},
  doi = {10.1007/BF01383722},
  urldate = {2022-12-19},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/WV8QMAI2/vanvughtGeneralModelQuality1994.pdf}
}

@misc{vartanRacialBiasFound,
  title = {Racial {{Bias Found}} in a {{Major Health Care Risk Algorithm}}},
  author = {Vartan, Starre},
  journal = {Scientific American},
  urldate = {2020-10-01},
  abstract = {Black patients lose out on critical care when systems equate health needs with costs},
  howpublished = {https://www.scientificamerican.com/article/racial-bias-found-in-a-major-health-care-risk-algorithm/},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/97GLT5YZ/racial-bias-found-in-a-major-health-care-risk-algorithm.html}
}

@article{vattoyStudentsExperiencesAssessment2022,
  title = {Students' Experiences of Assessment and Feedback Engagement in Digital Contexts: A Mixed-Methods Case Study in Upper Secondary School},
  shorttitle = {Students' Experiences of Assessment and Feedback Engagement in Digital Contexts},
  author = {Vatt{\o}y, Kim-Daniel and Gamlem, Siv M. and Kobberstad, Lina Rebekka and Rogne, Wenke Mork},
  year = {2022},
  month = sep,
  journal = {Education Inquiry},
  pages = {1--22},
  issn = {2000-4508},
  doi = {10.1080/20004508.2022.2122202},
  urldate = {2022-09-14},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/US4A7W8S/vattoyStudentsExperiencesAssessment2022.pdf}
}

@article{vaughanCommunityInquiryFramework2020,
  title = {The {{Community}} of {{Inquiry Framework}}: {{Future Practical Directions}} - {{Shared Metacognition}}},
  author = {Vaughan, Norman and Wah, Jessica Lee},
  year = {2020},
  journal = {International Journal of E-Learning \& Distance Education},
  volume = {35},
  number = {1},
  pages = {1--25},
  publisher = {Canadian Network for Innovation in Education},
  address = {Ottawa},
  abstract = {Metacognition is a required cognitive ability to achieve deep and meaningful learning that should be viewed from both an individual and social perspective. Recently, the transition from the earliest individualistic models to an acknowledgement of metacognition as socially situated and socially constructed has precipitated the study of metacognition in collaborative learning environments. This metacognitive construct was developed using the Community of Inquiry framework as a theoretical guide and tested applying qualitative research techniques by way of developing a metacognition questionnaire. The results indicate that in order to better understand the structure and dynamics of metacognition in teacher education programs; we must go beyond individual approaches to learning and consider metacognition in terms of complementary self- and co-regulation that integrates individual and shared regulation. This research study examines this shared metacognition framework and the use of digital technologies in the 3rd year of a Canadian Bachelor of Education program. Teacher candidates completed both the Shared Metacognition and Community of Inquiry surveys. The results indicate that a teacher must use digital technologies to intentionally design, facilitate, and direct a collaborative constructive learning environment in order for students to learn how to co-regulate their learning (shared metacognition).Alternate abstract:R{\'e}sum{\'e}: La m{\'e}tacognition est une capacit{\'e} cognitive requise pour r{\'e}aliser un apprentissage profond et significatif qui doit {\^e}tre consid{\'e}r{\'e} {\`a} la fois d'un point de vue individuel et social. R{\'e}cemment, le passage des premiers mod{\`e}les individualistes {\`a} une reconnaissance de la m{\'e}tacognition comme socialement situ{\'e}e et socialement construite a amen{\'e} {\`a} {\'e}tudier la m{\'e}tacognition dans les environnements d'apprentissage collaboratif. Cette construction m{\'e}tacognitive a {\'e}t{\'e} d{\'e}velopp{\'e}e en utilisant le cadre de la communaut{\'e} d'enqu{\^e}te comme guide th{\'e}orique et test{\'e}e en appliquant des techniques de recherche qualitative en d{\'e}veloppant un questionnaire sur la m{\'e}tacognition. Les r{\'e}sultats indiquent que pour mieux comprendre la structure et la dynamique de la m{\'e}tacognition dans les programmes de formation des enseignants, nous devons aller au-del{\`a} des approches individuelles de l'apprentissage et consid{\'e}rer la m{\'e}tacognition en termes d'autor{\'e}gulation compl{\'e}mentaire et de cor{\'e}gulation qui int{\`e}gre la r{\'e}gulation individuelle et partag{\'e}e. Cette {\'e}tude de recherche examine ce cadre de m{\'e}tacognition partag{\'e} et l'utilisation des technologies num{\'e}riques en 3e ann{\'e}e d'un programme canadien de baccalaur{\'e}at en {\'e}ducation. Les enseignants candidats ont r{\'e}pondu aux sondages sur la m{\'e}tacognition et la communaut{\'e} d'enqu{\^e}te. Les r{\'e}sultats indiquent qu'un enseignant doit utiliser les technologies num{\'e}riques pour concevoir, faciliter et diriger intentionnellement un environnement d'apprentissage constructif collaboratif afin que les {\'e}l{\`e}ves apprennent {\`a} cor{\'e}guler leur apprentissage (m{\'e}tacognition partag{\'e}e).},
  langid = {english},
  keywords = {Collaborative learning,Design,Education--Adult Education,Educational technology,Higher education,Metacognition,No DOI found,Qualitative research,Questionnaires,Student participation,Student retention,Teachers,Teaching},
  file = {/Users/colin.madland/Zotero/storage/DN3IMT8X/vaughanCommunityInquiryFramework2020.pdf}
}

@article{vaughanInvestigatingHowDigital2013,
  title = {Investigating {{How Digital Technologies Can Support}} a {{Triad-Approach}} for {{Student Assessment}} in {{Higher Education}} / {{{\'E}tude}} Des Technologies Num{\'e}riques Comme Appuis {\`a} l'{\'e}valuation Tripartite Des {\'E}tudiants Universitaires},
  author = {Vaughan, Norm},
  year = {2013},
  journal = {Canadian journal of learning and technology},
  volume = {39},
  number = {3},
  pages = {1},
  publisher = {{Association for Media and Technology in Education in Canada}},
  address = {Vancouver},
  issn = {1499-6677},
  doi = {10.21432/T2RG6X},
  abstract = {The purpose of this research study was to investigate if and how digital technologies could be used to support a triad-approach for student assessment in higher education. This triad-approach consisted of self-reflection, peer feedback, and instructor assessment practices in a pre-service teacher education course at a Canadian university. Through online surveys, journal postings, and post-course interviews the study participants indicated that digital technologies could be used to effectively support such a triad-approach only if students were more actively involved in the assessment process and the course instructor placed a greater emphasis on formative assessment practices. Le but de cette recherche {\'e}tait d'{\'e}tudier dans quelle mesure les technologies num{\'e}riques pouvaient {\^e}tre utilis{\'e}es pour soutenir une approche triadique de l'{\'e}valuation des {\'e}tudiants universitaires. Cette approche tripartite consistait dans l'autor{\'e}flexion, la r{\'e}troaction par les pairs et les pratiques d'{\'e}valuation de l'enseignant dans un cours de formation des futurs enseignants au sein d'une universit{\'e} canadienne. {\`A} l'aide de sondages en ligne, d'annonces de journaux et d'entrevues post-formation, les participants {\`a} l'{\'e}tude ont indiqu{\'e} que les technologies num{\'e}riques pouvaient {\^e}tre utilis{\'e}es pour soutenir efficacement une telle approche triadique, {\`a} condition que les {\'e}tudiants soient impliqu{\'e}s plus activement dans le processus d'{\'e}valuation et que l'enseignant mette davantage l'accent sur les pratiques d'{\'e}valuation formative.},
  keywords = {digital technologies,Digital transmission,Educational technology,Effectiveness studies,Higher education,Learning,self-reflection peer review instructor assessment,Teacher attitudes},
  file = {/Users/colin.madland/Zotero/storage/AWAY9AF6/vaughanInvestigatingHowDigital2013.pdf}
}

@article{vaughanPerspectivesBlendedLearning2007,
  title = {Perspectives on {{Blended Learning}} in {{Higher Education}}},
  author = {Vaughan, Norman},
  year = {2007},
  journal = {International Journal on E-Learning},
  volume = {6},
  number = {1},
  pages = {81--94},
  abstract = {This article explores the benefits and challenges of blended learning in higher education from the perspective of students, faculty, and administration that have had direct experience with this form of course delivery. Students indicate that a blended learning model provides them with greater time flexibility and improved learning outcomes but that initially they encounter issues around time management, taking greater responsibility for their own learning, and using sophisticated technologies. Faculty suggest that blended courses create enhanced opportunities for teacher-student interaction, increased student engagement in learning, added flexibility in the teaching and learning environment, and opportunities for continuous improvement. They state that the challenges faced in developing such a course include a lack of time, support and resources for course redesign, acquiring new teaching and technology skills, plus the risks associated with delivering a course in a blended format. From an administrative perspective, blended learning presents the opportunity to enhance an institution's reputation, expand access to an institution's educational offerings, and reduce operating costs. The challenges consist of aligning blended learning with institutional goals and priorities, resistance to organizational change and lack of organizational structure and experience with collaboration and partnerships. [ABSTRACT FROM AUTHOR] Copyright of International Journal on E-Learning is the property of Association for the Advancement of Computing in Education and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
  keywords = {blended,Curricula,Education,Higher,LEARNING,of,study),TEACHERS},
  annotation = {Accession Number: 23316596; Vaughan, Norman 1; Email Address: nvaughan@ucalgary.ca; Affiliations: 1 : University of Calgary, Alberta Canada; Source Info: 2007, Vol. 6 Issue 1, p81; Thesaurus Term: BLENDED learning; Thesaurus Term: LEARNING; Thesaurus Term: HIGHER education; Thesaurus Term: CURRICULA (Courses of study); Thesaurus Term: TEACHERS; Number of Pages: 14p; Illustrations: 2 Charts; Document Type: Article}
}

@book{vaughanTeachingBlendedLearning2013,
  title = {Teaching in Blended Learning Environments: Creating and Sustaining Communities of Inquiry},
  author = {Vaughan, Norman D. and Garrison, D. R. and {Cleveland-Innes}, M.},
  year = {2013},
  series = {Issues in Distance Education Serie},
  publisher = {AU Press},
  address = {Edmonton},
  isbn = {978-1-927356-48-7 978-1-927356-49-4},
  lccn = {371.3},
  keywords = {Blended learnin,Computer network resource,Computer-assisted instructio,Education Higher,Internet in higher educatio,Teaching}
}

@article{vealeConsideringImpactImageBased2022,
  title = {Considering the {{Impact}} of {{Image-Based Search Engines}} for {{Online Chemistry Assessments}}},
  author = {Veale, Clinton G. L},
  year = {2022},
  journal = {Journal of chemical education},
  volume = {99},
  number = {3},
  pages = {1497--1502},
  publisher = {{American Chemical Society and Division of Chemical Education, Inc}},
  address = {Easton},
  issn = {0021-9584},
  doi = {10.1021/acs.jchemed.1c01075},
  abstract = {The shift to online education has dealt several important pedagogical lessons in a very short time frame, none more so than approaches to assessments. This experience, coupled to improved access to education, will likely see online assessments remain as a major component of modern mainstream education. The powerful technologies that facilitate the online learning environment also provide tools to undermine the quality of assessments. While these discussions have typically focused on word-based searches using well-known search engines, very little comment has revolved around the use of image-based searches. Here, through a small sample of illustrative examples, the potential impact of image-based search technology on online chemistry assessments is discussed.},
  keywords = {CAI,Chemistry,Computer assisted instruction,Education,Higher education,Learning environment,Online instruction,Quality assessment,Search engines,Teaching methods}
}

@article{vealeDesignPrinciplesFinal2022,
  title = {Design Principles for Final Answer Assessment in Linear Algebra: Implications for Digital Testing},
  author = {Veale, {\relax AJ} and Craig, {\relax TS}},
  year = {2022},
  journal = {Teaching Mathematics and Its Applications},
  issn = {0268-3679},
  doi = {10.1093/teamat/hrac002},
  abstract = {Digital testing, such as multiple-choice questions and final answer items, offers many advantages in higher educational assessment practices. Well-designed digital grading is more reliable and faster than hand grading and is scalable to larger classes. The validity of digital grading is open to criticism, particularly in mathematics where much of mathematics is based on processes and reasoning and not on the final answer achieved. At a technical university in the Netherlands, we have been increasing our use of digital short answer testing in calculus and linear algebra for service mathematics. To assess the validity of this mode of assessment, we graded a linear algebra test in two ways: short answer grading (where answers were considered either correct or incorrect) and the so-called 'hypothetical grading', where we assigned a grade based on the fully worked solution. Certain types of items proved to be more suitable for short answer (and hence digital) testing than others. We concluded our analysis with a set of design principles for digital or short answer testing in linear algebra.},
  langid = {english},
  keywords = {COMPUTER-AIDED ASSESSMENT,MATHEMATICS},
  file = {/Users/colin.madland/Zotero/storage/3U22RSA7/vealeDesignPrinciplesFinal2022.pdf}
}

@article{veletsianosDesigningOpportunitiesTransformation2011,
  title = {Designing Opportunities for Transformation with Emerging Technologies},
  author = {Veletsianos, George},
  year = {2011},
  journal = {Educational Technology},
  volume = {51},
  number = {2},
  pages = {41--46},
  abstract = {In this article, the author argues that technology use in education has focused oncombating instructional problems and inefficiencies. While technology use for such purposes is viable and important, the author proposes that practitioners andresearchers in field utilize emerging technologies as a means to provideopportunities for personally relevant and meaningful transformation. The author discusses strategies for providing such opportunities and presents examples of potentially transformative learning activities and environments. The paper concludes with caveats regarding the pursuit of transformation in technology-enhanced learning environments.}
}

@book{veletsianosLearningOnline2020,
  title = {Learning {{Online}}},
  author = {Veletsianos, George},
  year = {2020},
  publisher = {Johns Hopkins University Press},
  address = {Baltimore},
  doi = {10.1353/book.73824},
  urldate = {2020-04-05},
  isbn = {978-1-4214-3810-8},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/Q5HKKTSL/veletsianosLearningOnline2020.pdf}
}

@misc{veletsianosRiseEducationalTechnology2017,
  title = {The {{Rise}} of {{Educational Technology}} as a {{Sociocultural}} and {{Ideological Phenomenon}}},
  author = {Veletsianos, George and Moe, Rolin},
  year = {2017},
  journal = {EDUCAUSE Review},
  urldate = {2022-05-22},
  abstract = {The push for educational technology exists within a broader political, economic, ideological, and technological context. The all-too-common ignorance},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/ZZC6939S/veletsianosRiseEducationalTechnology2017.pdf;/Users/colin.madland/Zotero/storage/ULEF5JBZ/the-rise-of-educational-technology-as-a-sociocultural-and-ideological-phenomenon.html}
}

@misc{veletsianosWeNeedGet2022,
  title = {We Need to Get Online Learning Right before the next Crisis Hits},
  author = {Veletsianos, George},
  year = {2022},
  month = oct,
  journal = {George Veletsianos, PhD},
  urldate = {2024-06-05},
  abstract = {The Globe and Mail published an op-ed I wrote. As a condition of being featured in the publication, the paper has first publication rights for the first 48 hours. Since it's been more than 48 hours, and for posterity, I'm making a copy available below.},
  chapter = {futures},
  langid = {english},
  keywords = {notion}
}

@misc{veletsianosWhyItWrong,
  title = {Why It's Wrong to Blame Online Learning for Causing Mental Health Issues during {{COVID-19}}},
  author = {Veletsianos, George and Barbour, Michael and Moore, Stephanie},
  journal = {The Conversation},
  urldate = {2022-11-08},
  abstract = {Making unsubstantiated claims that pandemic online learning caused mental health problems doesn't help us address students' current needs.},
  howpublished = {http://theconversation.com/why-its-wrong-to-blame-online-learning-for-causing-mental-health-issues-during-covid-19-191493},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/HP83WGAU/why-its-wrong-to-blame-online-learning-for-causing-mental-health-issues-during-covid-19-191493.html}
}

@article{venkateshUserAcceptanceInformation2003,
  title = {User {{Acceptance}} of {{Information Technology}}: {{Toward}} a {{Unified View}}},
  author = {Venkatesh, Viswanath and Morris, Michael G. and Davis, Gordon B. and Davis, Fred D.},
  year = {2003},
  journal = {MIS Quarterly},
  volume = {27},
  number = {3},
  pages = {425--478},
  publisher = {Management Information Systems Research Center, University of Minnesota},
  issn = {02767783},
  doi = {10/gc8zn2},
  urldate = {2020-04-18},
  abstract = {[Information technology (IT) acceptance research has yielded many competing models, each with different sets of acceptance determinants. In this paper, we (1) review user acceptance literature and discuss eight prominent models, (2) empirically compare the eight models and their extensions, (3) formulate a unified model that integrates elements across the eight models, and (4) empirically validate the unified model. The eight models reviewed are the theory of reasoned action, the technology acceptance model, the motivational model, the theory of planned behavior, a model combining the technology acceptance model and the theory of planned behavior, the model of PC utilization, the innovation diffusion theory, and the social cognitive theory. Using data from four organizations over a six-month period with three points of measurement, the eight models explained between 17 percent and 53 percent of the variance in user intentions to use information technology. Next, a unified model, called the Unified Theory of Acceptance and Use of Technology (UTAUT), was formulated, with four core determinants of intention and usage, and up to four moderators of key relationships. UTAUT was then tested using the original data and found to outperform the eight individual models (adjusted R of 69 percent). UTAUT was then confirmed with data from two new organizations with similar results (adjusted R of 70 percent). UTAUT thus provides a useful tool for managers needing to assess the likelihood of success for new technology introductions and helps them understand the drivers of acceptance in order to proactively design interventions (including training, marketing, etc.) targeted at populations of users that may be less inclined to adopt and use new systems. The paper also makes several recommendations for future research including developing a deeper understanding of the dynamic influences studied here, refining measurement of the core constructs used in UTAUT, and understanding the organizational outcomes associated with new technology use.]},
  file = {/Users/colin.madland/Zotero/storage/3TF5R9SB/venkateshUserAcceptanceInformation2003.pdf}
}

@article{venvilleExploringPotentialCollaborative2017,
  title = {Exploring the Potential of a Collaborative Web-Based e-Portfolio in Social Work Field Education},
  author = {Venville, Annie and Cleak, Helen and Bould, Emma},
  year = {2017},
  month = apr,
  journal = {Australian Social Work},
  volume = {70},
  number = {2},
  pages = {185--196},
  publisher = {Taylor \& Francis},
  issn = {0312-407X},
  doi = {10.1080/0312407X.2017.1278735},
  abstract = {In most Australian workplaces that provide placement opportunities, social workers are unlikely to receive reductions in their workload for supervising students and completing the administrative requirements of field education subjects. Associated time costs lead to reluctance to supervise social work students. This article investigates the potential for a web-based e-portfolio tool to support and streamline social work field education and assessment processes. Social work students, field educators, and university-appointed liaison staff (N = 110) from a large Australian university completed an online survey administered at the end of placement. The majority of participants reported that the e-portfolio provided a useful framework for recording evidence of student learning; was simple to use; saved time; and had the capacity to enhance the quality and immediacy of communication between parties. We argue that e-portfolios can efficiently capture evidence of student learning and provide a robust mode of supporting social work students on placement. (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
  keywords = {Curricular Field Experience,E-portfolio,Educational Placement,Field Education,Social Casework,Social Work,Social Work Education,Student Assessment}
}

@article{verbertLearningAnalyticsDashboard2013,
  title = {Learning {{Analytics Dashboard Applications}}},
  author = {Verbert, Katrien and Duval, Erik and Klerkx, Joris and Govaerts, Sten and Santos, Jos{\'e} Luis},
  year = {2013},
  month = oct,
  journal = {American Behavioral Scientist},
  volume = {57},
  number = {10},
  pages = {1500--1509},
  issn = {0002-7642, 1552-3381},
  doi = {10.1177/0002764213479363},
  urldate = {2021-12-14},
  abstract = {This article introduces learning analytics dashboards that visualize learning traces for learners and teachers. We present a conceptual framework that helps to analyze learning analytics applications for these kinds of users. We then present our own work in this area and compare with 15 related dashboard applications for learning. Most evaluations evaluate only part of our conceptual framework and do not assess whether dashboards contribute to behavior change or new understanding, probably also because such assessment requires longitudinal studies.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/6YI4NHTA/verbertLearningAnalyticsDashboard2013.pdf}
}

@article{vickVideoEssay2021,
  title = {The {{Video Essay}}},
  author = {Vick, Nicholas},
  year = {2021},
  month = jan,
  journal = {Honors in Practice},
  volume = {17},
  pages = {252--254},
  publisher = {Honors in Practice},
  issn = {1559-0143},
  abstract = {The video essay is an opportunity for students to record their words and combine other visual elements to complete the typical requirements of a standard written paper. Applicable across disciplines and pedagogically aligned with an honors ethos of self-directed learning, video essays allow for individual and collaborative forms of expression while providing unique approaches to compositional assessment on an array of subjects.},
  keywords = {Community Colleges,Essays,Florida,Honors Curriculum,Independent Study,No DOI found,Social Media,Two Year College Students,Video Technology}
}

@misc{VideoconferencingAlternativesHow,
  title = {Videoconferencing {{Alternatives}}: {{How Low-Bandwidth Teaching Will Save Us All}} {\textbar} {{IDDblog}}: {{Instructional Design Tips}}, {{Advice}}, \& {{Trends}} for {{Online}} \& {{Distance Learning}} {\textbar} {{Educational Technology}} and {{Online Course Design Help}}},
  shorttitle = {Videoconferencing {{Alternatives}}},
  urldate = {2020-05-12},
  abstract = {Daniel Stanford discusses solutions for online teaching that may help save bandwidth, be more accessible to students, and create a unified online learning environment.},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/4CQLUQPC/videoconferencing-alternatives-how-low-bandwidth-teaching-will-save-us-all.html}
}

@misc{ViewRecording,
  title = {View {{Recording}}},
  urldate = {2020-10-31},
  howpublished = {https://register.gotowebinar.com/recording/recordingView?webinarKey=7984800086379435276\&registrantEmail=colin\%40madland.ca},
  file = {/Users/colin.madland/Zotero/storage/2YAB9AJU/recordingView.html}
}

@article{villarroelUsingPrinciplesAuthentic2019,
  title = {Using Principles of Authentic Assessment to Redesign Written Examinations and Tests},
  author = {Villarroel, Ver{\'o}nica and Boud, David and Bloxham, Susan and Bruna, Daniela and Bruna, Carola},
  year = {2019},
  month = jan,
  journal = {Innovations in Education and Teaching International},
  pages = {1--12},
  issn = {1470-3297, 1470-3300},
  doi = {10.1080/14703297.2018.1564882},
  urldate = {2023-04-19},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/9YVXY563/villarroelUsingPrinciplesAuthentic2019.pdf}
}

@article{vinovskisHistoryTestingUnited2019,
  title = {History of {{Testing}} in the {{United States}}: {{PK}}--12 {{Education}}},
  shorttitle = {History of {{Testing}} in the {{United States}}},
  author = {Vinovskis, Maris A.},
  year = {2019},
  month = may,
  journal = {The ANNALS of the American Academy of Political and Social Science},
  volume = {683},
  number = {1},
  pages = {22--37},
  issn = {0002-7162, 1552-3349},
  doi = {10.1177/0002716219839682},
  urldate = {2022-11-05},
  abstract = {This article provides a brief history of K--12 education testing in the United States from colonial America to the present. In early America, students were examined orally. After the mid-nineteenth century, written tests replaced oral presentations. In the late nineteenth century, graded schools gradually replaced the single-teacher, one-room schools. In the beginning of the twentieth century, standardized intelligence tests were increasingly used to categorize and promote students. State departments of education have played a larger role in local school funding and policies in the past hundred years. Since the 1960s, the federal government has expanded its involvement in national education while also promoting the role of states. During the past three decades, the federal government and states increased the use of high-stakes national testing with initiatives such as America 2000, Goals 2000, No Child Left Behind, and Every Student Succeeds.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/7GBQW6G5/vinovskisHistoryTestingUnited2019.pdf}
}

@article{virkusUseOpenBadges2019,
  title = {The Use of {{Open Badges}} in Library and Information Science Education in {{Estonia}}},
  author = {Virkus, S},
  year = {2019},
  journal = {Education for Information},
  volume = {35},
  number = {2},
  pages = {155--172},
  issn = {0167-8329},
  doi = {10.3233/EFI-190257},
  abstract = {This paper discusses the planning and implementation of Open Badges in library and information science education at Tallinn University in order to foster and personalise student learning. The first part of the paper gives an overview of the concept and nature of Open Badges through a review of literature, the second describes the use of Open Badges in the Study Area of Information Sciences of the School of Digital Technologies at Tallinn University. The course used four types of open badges in the assessment process: basic knowledge badges, advanced knowledge badges, skill based badges and level based badges. Open Badges were directly linked to the learning outcomes and formal grading system of the course. Based on recent experience, it can be said that Open Badges are valuable tools in the assessment process which will give a more holistic picture of educational achievement of the learner. Multiple learning pathways within the course provided learners opportunities to choose their personal learning path according to their personal learning goals, learning style, interests and other preferences. Open Badges also allowed to recognize 'soft skills' or literacies. Open Badges could be also a useful tool to assess students' information literacies in different contexts.},
  langid = {english},
  keywords = {assessment,credentials,digital badges,DIGITAL BADGES,educational technology,higher education,library and information science,Open Badges}
}

@misc{VisitorsResidents,
  title = {Visitors and {{Residents}}},
  urldate = {2021-12-23},
  howpublished = {https://experimental.worldcat.org/vandrmapping/signIn},
  file = {/Users/colin.madland/Zotero/storage/6I3XD7I3/signIn.html}
}

@misc{VIU,
  title = {{{VIU}}},
  urldate = {2022-12-20},
  abstract = {VIU's policies on admissions and standards are listed below. Further information about VIU's regulations and procedures is available from the Office of the Registrar.The academic year consists of the Fall and Spring semesters, and the Summer Session. Each is approximately 15 weeks. Some university courses span both semesters. Trades and Applied Technology programs and Academic},
  howpublished = {https://www.viu.ca/registration/general-regulations},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/82NQ8N69/general-regulations.html}
}

@misc{vivienrolfeOpened16ConferencePresentation,
  type = {Education},
  title = {\#{{Opened16 Conference Presentation}}},
  author = {Vivien Rolfe},
  urldate = {2018-10-20},
  abstract = {\#Opened16 Conference Presentation},
  keywords = {history,open}
}

@article{vlachopoulosEffectGamesSimulations2017,
  title = {The Effect of Games and Simulations on Higher Education: A Systematic Literature Review},
  author = {Vlachopoulos, Dimitrios and Makri, Agoritsa},
  year = {2017},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {14},
  number = {1},
  pages = {1--33},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2365-9440},
  doi = {10.1186/s41239-017-0062-1},
  abstract = {The focus of higher education institutions is the preparation of future professionals. To achieve this aim, innovative teaching methods are often deployed, including games and simulations, which form the subject of this paper. As the field of digital games and simulations is ever maturing, this paper attempts to systematically review the literature relevant to games and simulation pedagogy in higher education. Two researchers collaborate to apply a qualitative method, coding and synthesizing the results using multiple criteria. The main objective is to study the impact of games and simulations with regard to achieving specific learning objectives. On balance, results indicate that games and/or simulations have a positive impact on learning goals. The researchers identify three learning outcomes when integrating games into the learning process: cognitive, behavioural, and affective. As a final step, the authors consolidate evidence for the benefit of academics and practitioners in higher education interested in the efficient use of games and simulations for pedagogical purposes. Such evidence also provides potential options and pathways for future research.},
  keywords = {Boolean,Computer & video games,Computer Appl. in Social and Behavioral Sciences,Computer Science,Computers and Education,Digital games,Educational Technology,Game-based learning,Games and Simulation in Higher Education,Higher Education,Higher education institutions,Humanities,Information Systems Applications (incl.Internet),Law,Learning,Learning outcomes,Literature reviews,Multiple criterion,Pedagogical use,Pedagogy,Review Article,Simulation,Simulations,Statistics for Social Sciences,Teaching methods},
  file = {/Users/colin.madland/Zotero/storage/E6DVYG7F/vlachopoulosEffectGamesSimulations2017.pdf}
}

@incollection{vogelsmeierFactorAnalysisEducation2024,
  title = {Factor {{Analysis}} in {{Education Research Using R}}},
  booktitle = {Learning {{Analytics Methods}} and {{Tutorials}}: {{A Practical Guide Using R}}},
  author = {Vogelsmeier, Leonie V. D. E. and Saqr, Mohammed and {L{\'o}pez-Pernas}, Sonsoles and Jongerling, Joran},
  editor = {Saqr, Mohammed and {L{\'o}pez-Pernas}, Sonsoles},
  year = {2024},
  pages = {673--703},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-54464-4_20},
  abstract = {Factor analysis is a method commonly employed to reduce a large number of variables into fewer numbers of factors. The method is often used to identify which observable indicators are representative of latent, not directly-observed constructs. This is a key step in developing valid instruments to assess latent constructs in educational research (e.g., student engagement or motivation). The chapter describes the two main approaches for conducting factor analysis (and how to combine them in an integrated factor analysis strategy) and provides a tutorial on implementing both techniques in the R programming language. The first is confirmatory factor analysis (CFA), a more theory-driven approach, in which a researcher actively specifies the number of underlying constructs as well as the pattern of relations between these dimensions and observed variables. The second is exploratory factor analysis (EFA), a more data-driven approach, in which the number of underlying constructs is inferred from the data, and all underlying constructs are assumed to influence all observed variables (at least to some degree).},
  isbn = {978-3-031-54464-4},
  file = {/Users/colin.madland/Zotero/storage/vogelsmeierFactorAnalysisEducation2024.pdf}
}

@article{vogtAssessmentLiteracyForeign2014,
  title = {Assessment {{Literacy}} of {{Foreign Language Teachers}}: {{Findings}} of a {{European Study}}},
  shorttitle = {Assessment {{Literacy}} of {{Foreign Language Teachers}}},
  author = {Vogt, Karin and Tsagari, Dina},
  year = {2014},
  month = oct,
  journal = {Language Assessment Quarterly},
  volume = {11},
  number = {4},
  pages = {374--402},
  issn = {1543-4303, 1543-4311},
  doi = {10/gh5k7f},
  urldate = {2021-08-03},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/MF7AUFC4/vogtAssessmentLiteracyForeign2014.pdf}
}

@article{vojtechStudentPerceptionsCollege2017,
  title = {Student {{Perceptions}} of {{College Faculty Who Use OER}}},
  author = {Vojtech, Gabrielle and Grissett, Judy},
  year = {2017},
  month = jun,
  journal = {The International Review of Research in Open and Distributed Learning},
  volume = {18},
  number = {4},
  issn = {1492-3831},
  urldate = {2018-07-07},
  copyright = {Copyright (c) 2017 Gabrielle Vojtech, Judy Grissett},
  langid = {english},
  keywords = {college students,OER,open educational resources,students' perceptions of college faculty},
  file = {/Users/colin.madland/Zotero/storage/D6M4AUZ7/vojtechStudentPerceptionsCollege2017.pdf;/Users/colin.madland/Zotero/storage/YSQ3FMY9/4215.html}
}

@article{volanteExploringTeacherCandidates2007,
  title = {Exploring Teacher Candidates' Assessment Literacy: {{Implications}} for Teacher Education Reform and Professional Development},
  author = {Volante, Louis and Fazio, Xavier},
  year = {2007},
  month = sep,
  journal = {Canadian Journal of Education/Revue canadienne de l'{\'e}ducation},
  volume = {30},
  number = {3},
  pages = {749-770},
  doi = {10/c53ntt},
  urldate = {2021-07-08},
  abstract = {This study examined the assessment literacy of primary/junior teacher candidates in all four years of their concurrent program. Candidates from each year of the program completed a survey pertaining to self-described level of assessment literacy, main purposes of assessment, utilization of different assessment methods, need for further training, and suggested methods for promoting assessment literacy in university and practice teaching settings. Levels of self-efficacy remained relatively low for teacher candidates across each of the four years of this program. Most candidates suggested summative purposes for assessment and only a minority expressed formative purposes. They favoured observational techniques and personal communication. Key words: classroom assessment; preservice education},
  chapter = {Articles},
  file = {/Users/colin.madland/Zotero/storage/NTBG93LB/volanteExploringTeacherCandidates2007.pdf}
}

@article{volanteSynergyTensionLarge2020,
  title = {Synergy and {{Tension}} between {{Large}}-{{Scale}} and {{Classroom Assessment}}: {{International Trends}}},
  shorttitle = {Synergy and {{Tension}} between {{Large}}-{{Scale}} and {{Classroom Assessment}}},
  author = {Volante, Louis and DeLuca, Christopher and Adie, Lenore and Baker, Eva and Harju-Luukkainen, Heidi and Heritage, Margaret and Schneider, Christoph and Stobart, Gordon and Tan, Kelvin and Wyatt-Smith, Claire},
  year = {2020},
  month = dec,
  journal = {Educational Measurement: Issues and Practice},
  volume = {39},
  number = {4},
  pages = {21--29},
  issn = {0731-1745, 1745-3992},
  doi = {10/ghzvvh},
  urldate = {2021-02-07},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/CBQLKQ9I/volanteSynergyTensionLarge2020.pdf}
}

@article{volungevicieneWhenOpenOnline2020,
  title = {When {{Is Open}} and {{Online Learning Relevant}} for {{Curriculum Change}} in {{Higher Education}}? {{Digital}} and {{Network Society Perspective}}},
  author = {Volungeviciene, Airina and Tereseviciene, Margarita and Ehlers, Ulf-Daniel},
  year = {2020},
  journal = {Electronic Journal of e-Learning},
  volume = {18},
  number = {1},
  pages = {88--101},
  issn = {EISSN-1479-4403},
  doi = {10/gmbvzd},
  abstract = {Digital and network society learning happens in new, timeless and borderless spaces. Such society members are always connected and online, sharing and co-creating knowledge, and their learning needs serve as the biggest driving forces for higher education curriculum change. Open online learning methodology seems to be the best-suited way to implement this change, in order to meet the needs of digital and network society. This research aims to investigate why and when open online learning is relevant for digital and network society and how open online learning supports curriculum change in higher education to meet the learning needs of digital and network society members. Theoretical research findings are discussed to: a) define the characteristics of digital and networked society, b) identify emerging ways of learning of a digital and networked society, and explain why open online learning is best suited for their needs, c) discuss the gap between the new ways of learning and higher education curricula and how open online learning is relevant for its change. Empirical research is based on global experts' semi-structured interviews. The results of the research demonstrate that open online learning should serve as a solution for curriculum change in higher education to respond to digital and network society learning needs. Higher education curricula should change to ensure better flexibility, recognition of nonformal learning in formal curricula, better collaboration and exchange of people with diverse cultural and social experiences. Assessment and recognition of prior learning in the formal curricula of universities could be one of realistic scenarios for faster adaptation and introduction of more diversified learning paths. The research findings support the need to change the pedagogical approach from teacher-centred into a learner-centred, small-group orientated, multidimensional model of teaching, which raise further challenges and research dilemmas for academic community, in order to integrate important elements of change into university practices.},
  langid = {english},
  keywords = {College Curriculum,College Role,Curriculum Development,Educational Needs,Electronic Learning,Expertise,Foreign Countries,Open Education,Relevance (Education),Social Networks,Student Centered Learning,Technology Integration}
}

@article{vonderembseHighStakesAccountabilityStudent2014,
  title = {High-{{Stakes Accountability}}: {{Student Anxiety}} and {{Large-Scale Testing}}},
  shorttitle = {High-{{Stakes Accountability}}},
  author = {{\noopsort{embse}}{von der Embse}, Nathaniel P. and Witmer, Sara E.},
  year = {2014},
  month = apr,
  journal = {Journal of Applied School Psychology},
  volume = {30},
  number = {2},
  pages = {132--156},
  issn = {1537-7903, 1537-7911},
  doi = {10/ggp725},
  urldate = {2021-01-01},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/QE4VUUQE/vonderembseHighStakesAccountabilityStudent2014.pdf}
}

@article{vonderwellAsynchronousDiscussionsAssessment2007,
  title = {Asynchronous {{Discussions}} and {{Assessment}} in {{Online Learning}}},
  author = {Vonderwell, Selma and Liang, Xin and Alderman, Kay},
  year = {2007},
  journal = {Journal of Research on Technology in Education},
  volume = {39},
  number = {3},
  pages = {309--328},
  publisher = {Routledge},
  address = {Eugene},
  issn = {1539-1523},
  doi = {10/ggrgxm},
  abstract = {This case study explored asynchronous online discussions, assessment processes, and the meaning students derived from their experiences in five online graduate courses at the Colleges of Education of two Midwestern higher education institutions. The findings suggest that asynchronous online discussions facilitate a multidimensional process of assessment demonstrated in the aspects of structure, self-regulatory activities, learner autonomy, learning community and student writing skills. The students valued the discussions as an essential component of their online learning. Further research is needed to understand the characteristics of online assessment, and what assessment strategies or criteria enhance assessment and learning. [PUBLICATION ABSTRACT];This case study explored asynchronous online discussions, assessment processes, and the meaning students derived from their experiences in five online graduate courses at the Colleges of Education of two Midwestern higher education institutions. The findings suggest that asynchronous online discussions facilitate a multidimensional process of assessment demonstrated in the aspects of structure, self-regulatory activities, learner autonomy, learning community and student writing skills. The students valued the discussions as an essential component of their online learning. Further research is needed to understand the characteristics of online assessment, and what assessment strategies or criteria enhance assessment and learning.;},
  keywords = {asynchronous online discussion,Case studies,Colleges & universities,Distance learning,Graduate studies,Higher education,learning community,online assessment,online learning}
}

@incollection{voogtDevelopingUnderstandingImpact2018,
  title = {Developing an {{Understanding}} of the {{Impact}} of {{Digital Technologies}} on {{Teaching}} and {{Learning}} in an {{Ever-Changing Landscape}}},
  booktitle = {Second {{Handbook}} of {{Information Technology}} in {{Primary}} and {{Secondary Education}}},
  author = {Voogt, Joke and Knezek, Gerald and Christensen, Rhonda and Lai, Kwok-Wing},
  editor = {Voogt, Joke and Knezek, Gerald and Christensen, Rhonda and Lai, Kwok-Wing},
  year = {2018},
  pages = {3--12},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-71054-9_113},
  abstract = {In this introduction chapter, we reflect on the contributions of research in the field of digital technologies in education during the last decade (2008--2018). The guiding questions leading these reflections are (1) what progress in understanding the role and impact of digital technologies in education has been made? and (2) what emerging themes can be observed that warrant further study? Overall, the progress made in the last decade is promising, and new research themes have emerged. This chapter highlights selected findings and issues that serve as exemplars for those addressed throughout the 2018 handbook, within the thematic strands that served as the blueprint for the reference work itself. Whenever possible, brief comparisons and contrasts are made to the evolutions over the past decade, since the first edition of the handbook was published.},
  isbn = {978-3-319-71054-9},
  file = {/Users/colin.madland/Zotero/storage/FDB3NE8N/voogtDevelopingUnderstandingImpact2018.pdf}
}

@book{voogtSecondHandbookInformation2018,
  title = {Second {{Handbook}} of {{Information Technology}} in {{Primary}} and {{Secondary Education}}},
  editor = {Voogt, Joke and Knezek, Gerald and Christensen, Rhonda and Lai, Kwok-Wing},
  year = {2018},
  series = {Springer {{International Handbooks}} of {{Education}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-71054-9},
  urldate = {2021-01-04},
  isbn = {978-3-319-71053-2 978-3-319-71054-9},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/HFWTLAU6/voogtSecondHandbookInformation2018.pdf}
}

@article{vuDesigningIntegrativeAssessment2014,
  title = {Designing Integrative Assessment to Enhance Student Learning for Their Future},
  author = {Vu, Thuy Thu},
  year = {2014},
  journal = {null},
  doi = {null},
  abstract = {As many universities have recently undergone curriculum review and renewals to better prepare students for their work and life in the changing world, renewed interests are being directed to what students should learn and how that learning can be best supported. In recent research, learning has been reconceptualised as processes where learners integrate what they know and are able to do with who they are becoming within a broad range of practices. This type of learning shifts the focus of education from the development of a particular curriculum to the development of the whole person. It plays a heightened emphasis on students developing appropriate ways of being, including being with others and things, and thus has potential in preparing them for future work and life. In line with this reconceptualisation of learning, the paper will explore ways in which assessment can be designed to promote learning to become who students endeavor to be in higher education programs. Designing assessment for this purpose underlines the need to integrate assessment with real-world practice, assessment with the learning students are engaged in, and the formative with summative purposes of assessment. Appropriate strategies for ensuring integration will also be discussed in reference with the research literature.},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@article{vuDesigningIntegrativeAssessment2014a,
  title = {Designing Integrative Assessment to Enhance Student Learning for Their Future},
  author = {Vu, Thuy Thu},
  year = {2014},
  journal = {null},
  doi = {null},
  abstract = {As many universities have recently undergone curriculum review and renewals to better prepare students for their work and life in the changing world, renewed interests are being directed to what students should learn and how that learning can be best supported. In recent research, learning has been reconceptualised as processes where learners integrate what they know and are able to do with who they are becoming within a broad range of practices. This type of learning shifts the focus of education from the development of a particular curriculum to the development of the whole person. It plays a heightened emphasis on students developing appropriate ways of being, including being with others and things, and thus has potential in preparing them for future work and life. In line with this reconceptualisation of learning, the paper will explore ways in which assessment can be designed to promote learning to become who students endeavor to be in higher education programs. Designing assessment for this purpose underlines the need to integrate assessment with real-world practice, assessment with the learning students are engaged in, and the formative with summative purposes of assessment. Appropriate strategies for ensuring integration will also be discussed in reference with the research literature.},
  pmcid = {null},
  pmid = {null},
  keywords = {Invalid DOI}
}

@article{vuralStudentIncivilityHigher2020,
  title = {Student {{Incivility}} in {{Higher Education}}},
  author = {Vural, Levent and Bacioglu, Seda Donat},
  year = {2020},
  journal = {International Journal of Progressive Education},
  volume = {16},
  number = {5},
  pages = {305--316},
  issn = {EISSN-1554-5210},
  doi = {10/gmbv36},
  abstract = {Observed frequently within higher education settings, student incivility need to be dealt with since they affect teaching-learning process adversely. The aim of this study is to determine the frequency of student incivility in higher education and coping techniques employed by academics. Both qualitative and quantitative data were collected together with a measurement tool developed by the researchers. The method of the research is a mixed method and qualitative and quantitative data were collected at the same time. A total of 250 academics working at universities in Turkey have voluntarily participated in the study. During the analysis process, construct validity concerning the quantitative data obtained from the data collection tool has been established through DFA, and parametric test statistics have been applied for data analysis. The results obtained from the study have indicated that not studying, playing with the cell phone, and not listening to the lecture are among the most frequent students' uncivil behaviors the academic witness. A significant difference has been identified between the two independent variables of the research --"seniority \& working period at the current university"-- and student incivility. The academics think that as seniority and working period at the same workplace increase, students show less of uncivil behaviors. "Verbal warning" has been noted as the most frequent method used by academics to deal with these kinds of behaviors. The implications of these findings for intervention design and development and further research are discussed.},
  langid = {english},
  keywords = {Attention,Behavior Problems,College Faculty,College Students,Foreign Countries,Gender Differences,Handheld Devices,Interpersonal Relationship,Student Behavior,Student Characteristics,Study Habits,Teacher Characteristics,Telecommunications}
}

@book{vygotskyMindSociety1978,
  title = {Mind in Society},
  shorttitle = {Mind in Society},
  author = {Vygotsky, Lev S.},
  editor = {Cole, Michael and {John-Steiner}, Vera and Scribner, Sylvia and Souberman, Ellen},
  translator = {Luria, Alexander Romanovich},
  year = {1978},
  publisher = {Harvard University Press},
  address = {Cambridge},
  keywords = {zone of proximal development,zpd}
}

@book{vygotskyThoughtLanguage1962,
  title = {Thought and Language},
  shorttitle = {Thought and Language},
  author = {Vygotsky, Lev S.},
  editor = {Vakar, Gertrude},
  translator = {Hanfmann, Eugenia},
  year = {1962},
  publisher = {Massacheusetts Institute of Technology}
}

@article{wagnerSupportFunctionalDefinition1994,
  title = {In Support of a Functional Definition of Interaction},
  author = {Wagner, E. D.},
  year = {1994},
  journal = {American Journal of Distance Education},
  volume = {8},
  number = {2},
  pages = {6--26},
  file = {/Users/colin.madland/Zotero/storage/WN8YK7FW/wagnerSupportFunctionalDefinition1994.pdf}
}

@article{wainerHowDisplayData1984,
  title = {How to {{Display Data Badly}}},
  author = {Wainer, Howard},
  year = {1984},
  journal = {The American Statistician},
  volume = {38},
  number = {2},
  pages = {137--147},
  publisher = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  issn = {00031305},
  doi = {10.2307/2683253},
  urldate = {2025-01-10},
  abstract = {[Methods for displaying data badly have been developing for many years, and a wide variety of interesting and inventive schemes have emerged. Presented here is a synthesis yielding the 12 most powerful techniques that seem to underlie many of the realizations found in practice. These 12 (the dirty dozen) are identified and illustrated.]},
  file = {/Users/colin.madland/Zotero/storage/wainerHowDisplayData1984 2.pdf}
}

@incollection{wakefieldCollaborativeActionResearch2019,
  title = {A Collaborative {{Action Research}} Project within a Data-Driven Culture : {{Improving}} Teaching and Learning through {{Social Constructivism}} in {{England}}},
  shorttitle = {A Collaborative {{Action Research}} Project within a Data-Driven Culture},
  booktitle = {Action {{Research}} for {{Inclusive Education}}: {{Participation}} and {{Democracy}} in {{Teaching}} and {{Learning}}},
  author = {Wakefield, Sarah},
  editor = {Armstrong, Felicity and Tsokova, Diana},
  year = {2019},
  month = apr,
  doi = {10.4324/9781351048361-11},
  urldate = {2019-10-13},
  abstract = {Action Research (AR), and Collaborative Action Research (CAR) in particular, has made a significant contribution to the development of inclusive},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/D5Y9ZLM3/wakefieldCollaborativeActionResearch2019.pdf;/Users/colin.madland/Zotero/storage/76LZ7W5H/9781351048361-11.html}
}

@article{walbesser1968,
  author = {Walbesser, Henry H.},
  editor = {Tyler, Ralph W. and Gagn{\'e}, Robert M. and Scriven, Michael},
  year = {1968},
  journal = {American Educational Research Journal},
  volume = {5},
  number = {1},
  pages = {120--121},
  publisher = {[American Educational Research Association, Sage Publications, Inc.]},
  issn = {00028312, 19351011},
  doi = {10/dhcw9k},
  urldate = {2021-07-07}
}

@article{walbesserPerspectivesCurriculumEvaluation1968,
  title = {Perspectives of {{Curriculum Evaluation}}},
  author = {Walbesser, Henry H. and Tyler, Ralph W. and Gagn{\'e}, Robert M. and Scriven, Michael and Gagne, Robert M.},
  year = {1968},
  month = jan,
  journal = {American Educational Research Journal},
  volume = {5},
  number = {1},
  pages = {120},
  issn = {00028312},
  doi = {10/dhcw9k},
  urldate = {2021-07-07},
  file = {/Users/colin.madland/Zotero/storage/8YDF55QI/walbesserPerspectivesCurriculumEvaluation1968.pdf}
}

@article{wallAssessmentWhomRepositioning2014,
  title = {Assessment for {{Whom}}: {{Repositioning Higher Education Assessment}} as an {{Ethical}} and {{Value-Focused Social Practice}}},
  author = {Wall, Andrew F and Hursh, David and Rodgers, Joseph W III},
  year = {2014},
  journal = {Research \& Practice in Assessment},
  volume = {9},
  pages = {5--17},
  abstract = {It is often argued that as ``consumers'' of higher education, students, parents and leaders need objective, comparative information generated through systematized assessment. In response, we critique this trend toward reductionist, comparative, and ostensibly objective assessments in the United States. We describe how management has replaced democratic selfgovernance in higher education, and connect current managerial leadership with the use of assessment as a tool in furthering market based educational aims. Lastly, we provide an alternative view of assessment as an ethical, value concerned social practice that creates space for dialogue about how higher education contributes to learning toward the public good.},
  file = {/Users/colin.madland/Zotero/storage/58E3EL9A/wallAssessmentWhomRepositioning2014.pdf}
}

@book{walterIndigenousStatisticsQuantitative2016,
  ids = {walterIndigenousStatisticsQuantitative2016a},
  title = {Indigenous {{Statistics}} : {{A Quantitative Research Methodology}}},
  author = {Walter, Maggie and Andersen, Chris},
  year = {2016},
  publisher = {Routledge},
  address = {Walnut Creek, UNITED STATES},
  isbn = {978-1-61132-294-1},
  keywords = {Indigenous peoples -- Research -- Methodology.,Indigenous peoples -- Statistics.},
  file = {/Users/colin.madland/Zotero/storage/LJNQ26Z7/walterIndigenousStatisticsQuantitative2016.pdf}
}

@article{waltonModelingOrganizationalSystems2004,
  title = {Modeling Organizational Systems: {{Banathy}}'s Three Lenses Revisited},
  author = {Walton, Douglas C},
  year = {2004},
  journal = {Systemic Practice and Action Research},
  volume = {17},
  number = {4},
  pages = {265--284},
  annotation = {MDDE603 Course Readings}
}

@article{wangExploringPerceivedIntegrations2020,
  title = {Exploring the {{Perceived Integrations Between Assessment}} and {{Metacognition}}: {{A Qualitative Inquiry}} of {{Three Award-Winning Teacher Educators}}' {{Conceptions}} of {{Assessment}} in a {{Hong Kong University Context}}},
  shorttitle = {Exploring the {{Perceived Integrations Between Assessment}} and {{Metacognition}}},
  author = {Wang, Jing},
  year = {2020},
  month = jan,
  journal = {Frontiers in Education},
  volume = {4},
  pages = {157},
  issn = {2504-284X},
  doi = {10.3389/feduc.2019.00157},
  urldate = {2022-04-07},
  file = {/Users/colin.madland/Zotero/storage/8J8JBRVH/wangExploringPerceivedIntegrations2020.pdf}
}

@article{wangListeningLearnersInvestigation2017,
  title = {Listening to Learners: {{An}} Investigation into College Students' Attitudes towards the Adoption of e-Portfolios in {{English}} Assessment and Learning},
  author = {Wang, P and Jeffrey, R},
  year = {2017},
  month = nov,
  journal = {British Journal of Educational Technology},
  volume = {48},
  number = {6},
  pages = {1451--1463},
  issn = {0007-1013},
  doi = {10.1111/bjet.12513},
  abstract = {This study discusses the possibility of e-portfolio as a central component of assessment practice in the traditionally exam-oriented context of China's tertiary education. The aim was to listen to learners, and provide them with a voice to analyse their perception of the potential advantages and challenges of introducing a learning-focused assessment tool. From five consecutive annual cohorts (2007-2011), 220 university students completed questionnaires about their attitudes and experience of using e-portfolio assessment in an English as a foreign language course, with 120 students participating in follow-up interviews and focus groups. The vast majority of learners expressed preference for e-portfolio assessment, compared to paper-based examinations. This study contributes to understanding Chinese educational ideology of assessment, so as to place emphasis on assessment for quality learning rather than on teaching to the test.},
  langid = {english},
  keywords = {CHINA,HIGHER-EDUCATION,TECHNOLOGY}
}

@article{wangPhotovoiceConceptMethodology1997,
  title = {Photovoice: {{Concept}}, {{Methodology}}, and {{Use}} for {{Participatory Needs Assessment}}},
  shorttitle = {Photovoice},
  author = {Wang, Caroline and Burris, Mary Ann},
  year = {1997},
  month = jun,
  journal = {Health Education \& Behavior},
  volume = {24},
  number = {3},
  pages = {369--387},
  issn = {1090-1981, 1552-6127},
  doi = {10/bgww5v},
  urldate = {2019-11-17},
  langid = {english}
}

@article{wangServantLeadershipCreativity2022,
  title = {Servant {{Leadership}} and {{Creativity}}: {{A Study}} of the {{Sequential Mediating Roles}} of {{Psychological Safety}} and {{Employee Well-Being}}},
  author = {Wang, Wenxian and Kang, Seung-Wan and Choi, S.},
  year = {2022},
  month = feb,
  journal = {Frontiers in Psychology},
  doi = {10.3389/FPSYG.2021.807070},
  abstract = {With today's increasingly dynamic and competitive business environment, creativity is critical for enterprises to enhance their competitiveness. Companies today invest and seek new ways to enhance creativity of employees within the organization. Our study describes the effects of servant leadership, psychological safety, and employee well-being on creativity under the conservation of resources theory. We used a sample of 252 full-time employees in the United Kingdom who had been recruited online and collected their data for analysis. We conducted confirmatory factor analyses to test the validity of the measurement model and regression to evaluate the direct effects. Subsequently, we used bootstrapping to confirm mediation and serial mediation effects. The results showed that servant leadership was positively related to creativity and that psychological safety and employee well-being were serial mediators between them.}
}

@techreport{wangTSINCPlagiarismresistantOnline2021,
  type = {Preprint},
  title = {{{TSINC}}: {{A Plagiarism-resistant Online Testing Method}}},
  shorttitle = {{{TSINC}}},
  author = {Wang, Yingwei},
  year = {2021},
  month = jan,
  institution = {SocArXiv},
  doi = {10.31235/osf.io/u4zcs},
  urldate = {2021-04-01},
  abstract = {TSINC is a new online testing method. The acronym TSINC represents its five characteristics: Time-pressed, Sequential, Individualized, Not searchable, and Calibration-bound. Its primary feature is that it can be used to organize plagiarism-resistant online testing without human monitoring. In this paper, the logical basis of this method, its implementation details, applicable areas and limitations, test cases, and so on are reported.},
  file = {/Users/colin.madland/Zotero/storage/M2A5RSAB/wangTSINCPlagiarismresistantOnline2021.pdf}
}

@book{warnerFutureEassessmentsUAE2017,
  title = {The {{Future}} of {{E-assessments}} in the {{UAE}}: {{Students}}' {{Perspectives}}},
  author = {Warner, R},
  editor = {AlMahrooqi, R and Coombe, C and AlMaamari, F and Thakur, V},
  year = {2017},
  series = {{{REVISITING EFL ASSESSMENT}}: {{CRITICAL PERSPECTIVES}}},
  pages = {358},
  doi = {10.1007/978-3-319-32601-6_19},
  abstract = {One of the core values in education is the need to align assessments with content, skills, and knowledge in order to maintain validity and reliability. There is good research evidence to show that well designed assessment systems lead to improved student performance and ensure success of students. Electronic assessment, which is regarded as the flip side of the e-learning coin, is acclaimed by some stakeholders in UAE higher education institutions as a possible magic bullet or saviour for the evaluation of learning. Others argue that e-assessment might herald the death of assessments with high levels of reliability and validity. This qualitative study investigates teachers and students' perceptions of e-assessment within a private higher education institution (HEI) in the UAE. Through the use of a questionnaire and interviews, perceptions of virtual learning environments, e-assessment methods on virtual platforms, and the process of giving feedback on performance on e-assessments are analysed. The participants offered unique insights into the conduct of e-assessment and most were concerned about the prospect of electronic feedback replacing verbal feedback and face-to-face interaction between the lecturers and students. Most participants indicated some benefits of e-assessments to the pedagogical processes in the university, but were reluctant to express wholehearted agreement with a transition to e-assessments as a sole @ method of summative evaluation. The study concludes by recommending ways of promoting the idea of e-assessment to lecturers and students including new codes of practice, training and assurances to both stakeholders that these new methods are an improvement on previous practice and that e-assessment can actually increase reliability and validity.},
  isbn = {978-3-319-32601-6},
  langid = {english},
  keywords = {Computer assisted assessments (CAA),E-assessment,Feedback}
}

@misc{warrenThatUpliftingTweet2019,
  title = {That {{Uplifting Tweet You Just Shared}}? {{A Russian Troll Sent It}}},
  shorttitle = {That {{Uplifting Tweet You Just Shared}}?},
  author = {Warren, Patrick, Darren Linvill and Linvill, Darren and Warren, Patrick},
  year = {2019},
  month = nov,
  journal = {Rolling Stone},
  urldate = {2019-12-17},
  abstract = {Here's what Russia's 2020 disinformation operations look like, according to two experts on social media and propaganda.},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/TT66YVMG/russia-troll-2020-election-interference-twitter-916482.html}
}

@article{watermeyerCOVID19DigitalDisruption2021,
  title = {{{COVID-19}} and Digital Disruption in {{UK}} Universities: Afflictions and Affordances of Emergency Online Migration},
  author = {Watermeyer, Richard and Crick, Tom and Knight, Cathryn and Goodall, Janet},
  year = {2021},
  journal = {Higher education},
  volume = {81},
  number = {3},
  pages = {623--641},
  publisher = {SPRINGER},
  address = {DORDRECHT},
  issn = {0018-1560},
  doi = {10/ghd7sm},
  abstract = {AbstractCOVID-19 has caused the closure of university campuses around the world and migration of all learning, teaching, and assessment into online domains. The impacts of this on the academic community as frontline providers of higher education are profound. In this article, we report the findings from a survey of n = 1148 academics working in universities in the United Kingdom (UK) and representing all the major disciplines and career hierarchy. Respondents report an abundance of what we call `afflictions' exacted upon their role as educators and in far fewer yet no less visible ways `affordances' derived from their rapid transition to online provision and early `entry-level' use of digital pedagogies. Overall, they suggest that online migration is engendering significant dysfunctionality and disturbance to their pedagogical roles and their personal lives. They also signpost online migration as a major challenge for student recruitment, market sustainability, an academic labour-market, and local economies.;COVID-19 has caused the closure of university campuses around the world and migration of all learning, teaching, and assessment into online domains. The impacts of this on the academic community as frontline providers of higher education are profound. In this article, we report the findings from a survey of n = 1148 academics working in universities in the United Kingdom (UK) and representing all the major disciplines and career hierarchy. Respondents report an abundance of what we call 'afflictions' exacted upon their role as educators and in far fewer yet no less visible ways 'affordances' derived from their rapid transition to online provision and early 'entry-level' use of digital pedagogies. Overall, they suggest that online migration is engendering significant dysfunctionality and disturbance to their pedagogical roles and their personal lives. They also signpost online migration as a major challenge for student recruitment, market sustainability, an academic labour-market, and local economies.;},
  keywords = {Academic staff,Affordances,Barriers,Campuses,Closure,Coronaviruses,COVID-19,Disruption,Distance learning,Education & Educational Research,Education Higher,Educational aspects,Educational Change,Educational technology,Electronic Learning,Emergency Programs,Epidemics,Forecasts and trends,Foreign Countries,Higher education,Internet,Learning,Learning outcomes,Local economy,Markets,Online education,Online instruction,Personal information,Recruitment,Respondents,School Closing,Social Sciences,Surveys,Teachers,Teaching,Technology Uses in Education,United Kingdom,Universities,Universities and colleges}
}

@article{watermeyerDigitalDisruptionTime2022,
  title = {Digital Disruption in the Time of {{COVID-19}}: Learning Technologists' Accounts of Institutional Barriers to Online Learning, Teaching and Assessment in {{UK}} Universities},
  author = {Watermeyer, Richard and Crick, Tom and Knight, Cathryn},
  year = {2022},
  journal = {The international journal for academic development},
  volume = {27},
  number = {2},
  pages = {148--162},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {1360-144X},
  doi = {10.1080/1360144X.2021.1990064},
  abstract = {This article reports on the qualitative findings of a UK-wide survey of learning technologists and their recent struggles of supporting attempts for digital resettlement of learning, teaching and assessment in response to the COVID-19 pandemic, underlining the frailties of universities in the terms of crisis management and cultural and organisational change. We find broad attitude change towards the role and contribution of learning technology and technologists by higher education staff, yet a sense that institutions are neither grasping nor pursuing the potential of digital affordances and remain focused on returning to 'pre-COVID normality'. Furthermore, despite physical campus closures increasing demand on learning technologists, we see that their attempts for institutional boundary crossing remain frustrated.},
  keywords = {boundary crossing,Colleges & universities,COVID-19,digital disruption,Distance learning,Education & Educational Research,Higher education,Learning technologists,Online instruction,Social Sciences,UK higher education}
}

@article{watermeyerEducationLimitsDigital2022,
  title = {'{{Education}} without Limits': {{The}} Digital Resettlement of Post-Secondary Education and Training in {{Singapore}} in the {{COVID-19}} Era},
  author = {Watermeyer, R and Chen, Z and Ang, {\relax BJ}},
  year = {2022},
  month = nov,
  journal = {Journal of Education Policy},
  volume = {37},
  number = {6},
  pages = {861--882},
  issn = {0268-0939},
  doi = {10.1080/02680939.2021.1933198},
  abstract = {This article reports on how those working in post-secondary education and training in Singapore perceive the professional effects of a transition to online learning, teaching and assessment (LTA) as a consequence of the COVID-19 global pandemic. It draws on a survey sample of n = 1553 educators and trainers working in Singapore and their perspectives on how a migration to online LTA is producing long-term, if not permanent, changes to the organisation and delivery of post-secondary education and training. It reveals a largely positive view of digital resettlement of education and training in Singapore as a consequence of COVID-19. Yet despite the articulation by respondents of 'paradigm change' and 'education without limits', we find that an embrace of digitalisation is mobilised (and manipulated) not so much by pedagogical concerns but by economic ambitions and a utilitarian logic common to the neoliberal incantations of a global education policy community.},
  langid = {english},
  keywords = {COMPETITION,COVID-19,digital futures,educational digitalisation,GLOBALIZATION,GOVERNANCE,market transformation,MARKETS,POLICY,POLITICS,post-compulsory education and training,STATE,TECHNOLOGY}
}

@article{watermeyerGenerativeAIAutomating2023,
  title = {Generative {{AI}} and the {{Automating}} of {{Academia}}},
  author = {Watermeyer, Richard and Phipps, Lawrie and Lanclos, Donna and Knight, Cathryn},
  year = {2023},
  month = nov,
  journal = {Postdigital Science and Education},
  issn = {2524-485X, 2524-4868},
  doi = {10.1007/s42438-023-00440-6},
  urldate = {2024-02-16},
  abstract = {Abstract                            The neoliberal transformation of higher education in the UK and an intertwined focus on the productive efficiency and prestige value of universities has led to an epidemic of overwork and precarity among academics. Many are found to be struggling with lofty performance expectations and an insistence that all dimensions of their work consistently achieve positional gains despite ferocious competition and the omnipresent threat of failure. Working under the current audit culture present across education, academics are thus found to overwork or commit to accelerated labour as pre-emptive compensation for the habitual inclemency of peer-review and vagaries of student evaluation, in accommodating the copiousness of `invisible' tasks, and in eluding the myriad crevasses of their precarious labour. The proliferation of generative artificial intelligence (GAI) tools and more specifically, large language models (LLMs) like ChatGPT, offers potential relief for academics and a means to offset intensive demands and discover more of a work-based equilibrium. Through a recent survey of               n               \,=\,284 UK academics and their use of GAI, we discover, however, that the digitalisation of higher education through GAI tools no more alleviates than extends the dysfunctions of neoliberal logic and deepens academia's malaise. Notwithstanding, we argue that the proliferating use of GAI tools by academics may be harnessed as a source of positive disruption to the industrialisation of their labour and catalyst of (re)engagement with scholarly craftsmanship.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/XFF5TS3L/watermeyerGenerativeAIAutomating2023.pdf}
}

@article{watkinsExploratoryFactorAnalysis2018,
  title = {Exploratory {{Factor Analysis}}: {{A Guide}} to {{Best Practice}}},
  shorttitle = {Exploratory {{Factor Analysis}}},
  author = {Watkins, Marley W.},
  year = {2018},
  month = apr,
  journal = {Journal of Black Psychology},
  volume = {44},
  number = {3},
  pages = {219--246},
  issn = {0095-7984, 1552-4558},
  doi = {10.1177/0095798418771807},
  urldate = {2024-02-21},
  abstract = {Exploratory factor analysis (EFA) is a multivariate statistical method that has become a fundamental tool in the development and validation of psychological theories and measurements. However, researchers must make several thoughtful and evidence-based methodological decisions while conducting an EFA, and there are a number of options available at each decision point, some better than others. Reviews of the professional literature have consistently found that many applications of EFA are marked by an injudicious choice of methods and incomplete reports. This article provides a systematic, evidence-based guide to the conduct of EFA studies that can be followed by researchers with modest statistical training, supplemented with an example to illustrate its application.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/7X422EWV/watkinsExploratoryFactorAnalysis2018.pdf}
}

@book{watkinsLearningSensemakersGuide2006,
  title = {Learning: A Sense-Makers Guide},
  shorttitle = {Learning},
  author = {Watkins, Chris and {Association of Teachers and Lecturers (Great Britain)}},
  year = {2006},
  publisher = {ATL},
  address = {London},
  isbn = {978-1-902466-27-9},
  langid = {english},
  annotation = {OCLC: 213106564},
  file = {/Users/colin.madland/Zotero/storage/P485NQDC/watkinsLearningSensemakersGuide2006.pdf}
}

@book{watkinsStepbyStepGuideExploratory2020,
  title = {A {{Step-by-Step Guide}} to {{Exploratory Factor Analysis}} with {{R}} and {{RStudio}}},
  author = {Watkins, Marley},
  year = {2020},
  month = dec,
  edition = {1},
  publisher = {Routledge},
  address = {New York},
  doi = {10.4324/9781003120001},
  urldate = {2024-02-21},
  isbn = {978-1-003-12000-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/59UHYXG7/watkinsStepbyStepGuideExploratory2020.pdf}
}

@article{watsonAssessmentConceptualKnowledge2018,
  title = {Assessment of {{Conceptual Knowledge}} Using a {{Component-Based Concept Map Scoring Program}}},
  author = {Watson, {\relax MK} and Barrella, E and Pelkey, J},
  year = {2018},
  journal = {International Journal of Engineering Education},
  volume = {34},
  number = {3},
  pages = {1025--1037},
  issn = {0949-149X},
  abstract = {Conceptual understanding is an important prerequisite for engineering competence. Concept maps, which capture the content and structure of knowledge, can be used to assess conceptual knowledge, although cumbersome scoring methods limit their use. A literature review was conducted to summarize concept map scoring methods and automated scoring programs. While quantitative, component-based methods prevailed in the literature, no program was available to automate this method. Thus, the goal of this project was to present and evaluate a component-based computer program for scoring concept maps. The program automates application of the traditional scoring method in which number of concepts, highest hierarchy, and number of cross-links are counted as indicators of knowledge breadth, depth, and connectedness, respectively. A sample of concept maps (n = 78) was scored by two judges and the computer program. High agreement (Krippendorff's alpha {$>$} 0.80) between manual and automated scores was observed for number of concepts and number of cross-links. Although less than acceptable agreement between manual and automated scores was observed for highest hierarchy, the two measures of knowledge depth were highly correlated (Spearman's rho {$>$} 0.5). Ultimately, the computer program's measure of knowledge depth was termed longest path, while judges' measure of knowledge depth was termed longest hierarchy. Overall, the computer program can be used to rapidly, precisely, and reliably score concept maps to aid in assessment of conceptual knowledge.},
  langid = {english},
  keywords = {assessment,concept maps,conceptual knowledge,educational technology,ENGINEERING-EDUCATION,No DOI found,RELIABILITY,TOOL}
}

@article{watsonSmallDataOnline2017,
  ids = {watsonSmallDataOnline2017a,watsonSmallDataOnline2017b},
  title = {Small Data, Online Learning and Assessment Practices in Higher Education: A Case Study of Failure?},
  author = {Watson, Cate and Wilson, Anna and Drew, Valerie and Thompson, Terrie Lynn},
  year = {2017},
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {42},
  number = {7},
  pages = {1030--1045},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0260-2938},
  doi = {10/ggrgxn},
  abstract = {In this paper, we present an in-depth case study of a single student who failed an online module which formed part of a master's programme in Professional Education and Leadership. We use this case study to examine assessment practices in higher education in the online environment. In taking this approach, we go against the current predilection for Big Data which has given rise to 'learning analytics', a data-intensive approach to monitoring learning. In particular, we draw attention to the model of the learner produced by learning analytics and to issues of 'dataveillance' in online learning. We also use the case to examine assessment in higher education more broadly, exploring the tensions between the requirements for certification and the need for learning. We conclude that assessment practices in higher education may have more to do with 'quality assurance' and regulatory frameworks than with 'enhancing the student experience' and inculcating the qualities that mark out higher education as an ethical project.},
  keywords = {Administrator Education,Case Studies,College Students,Cooperative Learning,CRITICALITY,Criticism,Data Analysis,Data Collection,Distance learning,Education & Educational Research,EDUCATION & EDUCATIONAL RESEARCH,Educational Technology,Ethics,Evaluation Methods,Foreign Countries,Future-oriented learning,Higher education,Leadership Training,learning analytics,Online Courses,Professional education,professional learning,Professionalism,PROFESSIONALISM,Social Sciences,Student Evaluation,teaching excellence framework (TEF),Teaching Methods,Technology Uses in Education},
  file = {/Users/colin.madland/Zotero/storage/3X23TSLB/watsonSmallDataOnline2017.pdf}
}

@book{wattersClaimYourDomain,
  title = {Claim Your Domain--and Own Your Online Presence.},
  author = {Watters, Audrey},
  publisher = {Bloomington, IN : Solution Tree Press, [2016]},
  isbn = {978-1-942496-23-6},
  keywords = {Educational technology,Internet -- Security measures,Internet in education}
}

@misc{wattersEducationTechnologyCompletely2017,
  title = {'{{Education Technology}}'s {{Completely Over}}'},
  author = {Watters, Audrey},
  year = {2017},
  month = apr,
  journal = {Hack Education},
  urldate = {2018-06-28},
  abstract = {This was the first-half of a joint presentation at Coventry University as part of my visiting fellowship at the Disruptive Media Learning Lab. The better half was delivered by Jim Groom. Our topic,...},
  howpublished = {http://hackeducation.com/2017/04/07/prince},
  langid = {american},
  keywords = {turnitin},
  file = {/Users/colin.madland/Zotero/storage/B9N7TJ5S/prince.html}
}

@misc{wattersHackEducation,
  title = {Hack {{Education}}},
  author = {Watters, Audrey},
  journal = {Hack Education},
  urldate = {2018-11-05},
  abstract = {The History of the Future of Education Technology},
  howpublished = {http://hackeducation.com/},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/2K6VYXDW/hackeducation.com.html}
}

@misc{wattersSpeakSpellHistory2015,
  title = {Speak \& {{Spell}}: {{A History}}},
  shorttitle = {Speak \& {{Spell}}},
  author = {Watters, Audrey},
  year = {2015},
  month = jan,
  journal = {Hack Education},
  urldate = {2021-07-14},
  abstract = {Toys as Teaching MachinesThe Speak \& Spell -- one of the most iconic toys of the 1980s -- is a teaching machine.},
  howpublished = {http://hackeducation.com/2015/01/13/speak-and-spell},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/Y4LQQ93Y/speak-and-spell.html}
}

@book{wattersTeachingMachinesHistory2021,
  title = {Teaching Machines: {{The}} History of Personalized Learning},
  author = {Watters, A.},
  year = {2021},
  publisher = {MIT Press},
  isbn = {978-0-262-36375-4}
}

@article{wayEmpiricalInvestigationAuthentic2021,
  title = {Empirical Investigation of Authentic Assessment Theory: {{An}} Application in Online Courses Using Mimetic Simulation Created in University Learning Management Ecosystems},
  author = {Way, K{\"i}rsten A. and Burrell, Lisa and D'Allura, Louise and {Ashford-Rowe}, Kevin},
  year = {2021},
  journal = {Assessment \& evaluation in higher education},
  volume = {46},
  number = {1},
  pages = {17--35},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0260-2938},
  doi = {10.1080/02602938.2020.1740647},
  abstract = {Authentic assessment has theorised benefits for student outcomes in higher education. More needs to be done, however, to empirically test relationships between the critical elements of authenticity and student outcomes, particularly in online learning environments. In this paper we examine whether an online simulation-based learning and assessment design, developed using the tools and functionality within the available university online ecosystem, has measurable 'authenticity' in a postgraduate course. In addition, we assess whether the simulation is associated with improvements in student learning behaviours and outcomes. We analyse qualitative data from lecturer and student interviews and student work submitted online, as well as data analytics from the learning management system in both control and experimental conditions. Seven critical elements of authentic assessment were identified including new aspects of authenticity relating to simulation-specific affordances (e.g. emotional content, temporal dimensions and unpredictability). Students watched lecture videos and participated in online discussion more frequently in the online simulation than in the control condition and indicated perceived mastery of, and confidence in, the learning outcomes. These findings make important contributions to authentic assessment theory and have practical implications for simulations built in online ecosystems available in higher education.},
  keywords = {Affordances,authentic assessment,Authenticity,Business Administration Education,College Faculty,College students,Distance learning,Education & Educational Research,Educational evaluation,Foreign Countries,Graduate Students,Higher education,Integrated Learning Systems,Learning,Learning environment,Learning management systems,Learning outcomes,mimetic,occupational safety,Online,Online Courses,Online instruction,Outcomes of Education,Performance Based Assessment,Simulation,Social Sciences,Student Behavior,Student Evaluation}
}

@techreport{webbAlignmentScienceMathematics1999,
  title = {Alignment of {{Science}} and {{Mathematics Standards}} and {{Assessments}} in {{Four States}}},
  author = {Webb, Norman L},
  year = {1999},
  number = {18},
  address = {Washington, DC},
  institution = {Council of Chief State School Officers},
  urldate = {2023-03-02},
  abstract = {Reviewers analyzed the alignment of assessments and standards in mathematics and science from four states at a four-day institute conducted June 29 through July 2, 1998. Six reviewers compared the match between assessment items and standards in mathematics and seven compared the match in science. Data from these analyses were processed and used to judge the degree of alignment on four criteria: categorical concurrence, depth-of-knowledge consistency, range-of-knowledge correspondence, and balance of representation. The analyses indicated that the standards of the four states varied in what content students were expected to know, the level of specificity at which expectations were expressed, and organization. Nearly all of the sixteen assessment instruments reviewed incorporated some constructed-response items. Only one mathematics assessment for grade 10 from one state consisted solely of multiple-choice items. The items in three science and two mathematics assessments analyzed from one state were evenly divided between multiple-choice and constructed-response items. Assessments from the other three states included from 80\% to 90\% multiple-choice items. Alignment between assessments and standards varied across grade levels, content areas, and states without any discernable pattern. Assessments and standards of three of the four states satisfied the categorical concurrence criterion. This criterion, the most common conception of alignment, required the assessment and standards to include the same content topics. Alignment was found to be the weakest on the depth-of-knowledge consistency and range-of-knowledge correspondence criteria. Generally, assessment items required a lower level of knowledge and did not span the full spectrum of knowledge as expressed in the standards. However, for the knowledge and skills identified in the standards and addressed by the assessments, generally the assessment items were evenly distributed. A major goal of this study was to develop a valid and reliable process for analyzing the alignment among standards and assessments. The process did produce credible results that distinguished among the different attributes of alignment and detected specific ways that alignment could be improved. Issues that did arise from an analysis of the process indicated that reviewers could benefit from more training at the beginning of the institute. Reviewers also needed more clarification of the four depth-of-knowledge levels and more explicit rules for assigning an assessment item to more than one statement of expectation. (Contains 15 references.) (CCM)},
  file = {/Users/colin.madland/Zotero/storage/75QK9ENK/webbAlignmentScienceMathematics1999.pdf}
}

@incollection{webbAssessmentTwentyFirstCentury2018,
  title = {Assessment as, for, and of {{Twenty-First Century Learning Using Information Technology}}: {{An Overview}}},
  booktitle = {Second {{Handbook}} of {{Information Technology}} in {{Primary}} and {{Secondary Education}}},
  author = {Webb, Mary and Ifenthaler, Dirk},
  editor = {Voogt, Joke and Knezek, Gerald and Christensen, Rhonda and Lai, Kwok-Wing},
  year = {2018},
  pages = {581--600},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-71054-9_37},
  abstract = {IT-based assessment has been advancing rapidly, and its growth is set to accelerate with emerging opportunities for automatic data collection as well as increased possibilities of communication and interaction mediated by IT. In this chapter we aim to present an overview of the range of different opportunities for IT to support assessment. We identify and discuss challenges for moving toward a situation where IT-based assessment can serve learners' needs as well as the broader needs of the educational system for evaluation. We examine theories related to assessment more generally as well as specifically to IT-enabled assessment and review recent research and development. Scenarios for IT-enabled assessments may take many different forms, some of which hold much promise for supporting learning, but there are theoretical, developmental, technical, and human challenges to be overcome. Our vision is for IT-based assessment design to move forward with designers, teachers, and learners working together to design assessments that support twenty-first-century curricula and pedagogy. In this shared endeavor, we expect that data can be collected and represented to enable learners and teachers to identify achievements; collate evidence of those achievements; diagnose needs, both cognitive and affective; and decide on suitable pedagogical approaches for enabling the next steps in learning. We argue that open assessment resources provide a vehicle for enabling the large-scale developments that are needed to support the development of IT-enabled assessment across the broad spectrum of learning. Some of the more complex twenty-first-century skills of collaboration, problem-solving, critical thinking, etc. present particular challenges. We envisage that it may take many years for our vision to be realized. In the medium term, the need is to integrate IT-enabled assessments where appropriate alongside more traditional methods including teacher assessment.},
  isbn = {978-3-319-71054-9},
  file = {/Users/colin.madland/Zotero/storage/KQEPPEDU/webbAssessmentTwentyFirstCentury2018.pdf}
}

@article{webbChallengesInformationTechnology2013,
  title = {Challenges for Information Technology Supporting Educational Assessment: {{Challenges}} for {{IT}} Supporting Assessment},
  shorttitle = {Challenges for Information Technology Supporting Educational Assessment},
  author = {Webb, M. and Gibson, D. and {Forkosh-Baruch}, A.},
  year = {2013},
  month = oct,
  journal = {Journal of Computer Assisted Learning},
  volume = {29},
  number = {5},
  pages = {451--462},
  issn = {02664909},
  doi = {10.1111/jcal.12033},
  urldate = {2023-08-08},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/GYEIGXJL/webbChallengesInformationTechnology2013.pdf}
}

@article{webbCriteriaAlignmentExpectations1997,
  title = {Criteria for {{Alignment}} of {{Expectations}} and {{Assessments}} in {{Mathematics}} and {{Science Education}}. {{Research Monograph No}}. 6.},
  author = {Webb, Norman L.},
  year = {1997},
  publisher = {ERIC},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/DYV7XYQQ/webbCriteriaAlignmentExpectations1997.pdf}
}

@article{webbIssuesRelatedJudging2007,
  title = {Issues {{Related}} to {{Judging}} the {{Alignment}} of {{Curriculum Standards}} and {{Assessments}}},
  author = {Webb, Norman L},
  year = {2007},
  month = jan,
  journal = {Applied Measurement in Education},
  volume = {20},
  number = {1},
  pages = {7--25},
  issn = {0895-7347, 1532-4818},
  doi = {10.1080/08957340709336728},
  urldate = {2023-03-01},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/KFGF73SI/webbIssuesRelatedJudging2007.pdf}
}

@article{webbTechnologyEnhancedAssessment2015,
  title = {Technology Enhanced Assessment in Complex Collaborative Settings},
  author = {Webb, Mary and Gibson, David},
  year = {2015},
  month = dec,
  journal = {Education and Information Technologies},
  volume = {20},
  number = {4},
  pages = {675--695},
  issn = {1360-2357, 1573-7608},
  doi = {10.1007/s10639-015-9413-5},
  urldate = {2023-04-18},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/BBFI5EI6/webbTechnologyEnhancedAssessment2015.pdf}
}

@incollection{weber-wulffPlagiarismDetectionSoftware2015,
  title = {Plagiarism {{Detection Software}}: {{Promises}}, {{Pitfalls}}, and {{Practices}}},
  booktitle = {Handbook of {{Academic Integrity}}},
  author = {{Weber-Wulff}, Debora},
  editor = {Bretag, Tracey Ann},
  year = {2015},
  pages = {1--10},
  publisher = {Springer Singapore},
  address = {Singapore},
  doi = {10.1007/978-981-287-079-7_19-1},
  abstract = {An increasing number of students at universities around the world seem to be submitting plagiarized texts to their instructors for credit, although no exact figures are available, either for how much was plagiarized in the past or how much is plagiarized now. Instructors, overwhelmed with an ever-increasing workload, wish for a simple method -- rather like a litmus test -- to quickly sort out the plagiarized works, so that they can concentrate their efforts on the rest of the students.},
  isbn = {978-981-287-079-7}
}

@article{weeksDevelopingIntegratingNursing2019,
  title = {Developing and Integrating Nursing Competence through Authentic Technology-Enhanced Clinical Simulation Education: {{Pedagogies}} for Reconceptualising the Theory-Practice Gap},
  author = {Weeks, Keith W. and Coben, Diana and O'Neill, David and Jones, Alan and Weeks, Alex and Brown, Matt and Pontin, David},
  year = {2019},
  month = may,
  journal = {Nurse Education in Practice},
  volume = {37},
  pages = {29--38},
  issn = {1471-5953},
  doi = {10.1016/j.nepr.2019.04.010},
  abstract = {The aim of this review and discussion paper is to advance the debate on competence in nursing, simulation education, and literacy in simulation education pedagogy. Building on our previous patient-safety critical translational research work on drug dosage calculation-competence modelling, and safeMedicate{\textregistered} virtual learning and diagnostic assessment environment design, we introduce three new concepts. First, we re-conceptualise the cognitive and physical modalities of a theory-practice gap, created by the traditional organisation of health professional education practice. Second, that simulated clinical environments occupy the liminal spaces between the ordered, symbolic and abstract world of the classroom, and the situated, messy world of clinical healthcare practice. Third, technology-enhanced boundary objects (TEBOs) function as simulation pedagogy modalities that (a) support students' transition across the liminal space and boundaries between classroom and practice setting, and (b) support competence development and integration in nursing. We use a constructivist-based clinical simulation education model as a guiding pedagogical framework for applying TEBOs and an integrated nursing competence model. The e-version of the paper has embedded animation and illustrative video content to demonstrate these constructivist principles, using technology and computer animation to make complex education ideas accessible to experienced educators and clinicians, early-stage educators, and nursing and healthcare students.},
  keywords = {Boundary-crossing,Competence,Constructivism,Simulation,Technology enhanced boundary objects (TEBO),Theory-practice gap,Translational research}
}

@techreport{wefFutureJobsReport,
  title = {The Future of Jobs Report 2016},
  author = {WEF},
  urldate = {2021-04-06},
  abstract = {The Fourth Industrial Revolution is interacting with other socio-economic and demographic factors to create a perfect storm of business model change in all industries, resulting in major disruptions to labour markets. New categories of jobs will emerge, partly or wholly displacing others.},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/BQY3QX8M/wefFutureJobsReport.pdf}
}

@techreport{wefFutureJobsReport2020,
  title = {The {{Future}} of {{Jobs Report}} 2020},
  author = {{WEF}},
  year = {2020},
  institution = {World Economic Forum},
  urldate = {2021-04-02},
  abstract = {After years of growing income inequality, concerns about technology-driven displacement of jobs, and rising societal discord globally, the combined health and economic shocks of 2020 have put economies into freefall, disrupted labour markets and fully revealed the inadequacies of our social contracts. We find ourselves at a defining moment: the decisions and choices we make today will determine the course of entire generations' lives and livelihoods.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/D2X7HKL5/wefFutureJobsReport2020.pdf}
}

@article{weinkleVoiceDigitalEducation2020,
  title = {Voice in Digital Education: {{The}} Impact of Instructor's Perceived Age and Gender on Student Learning and Evaluation},
  author = {Weinkle, Laura J. and Stratford, Jennifer M. and Lee, Lisa M. J.},
  year = {2020},
  month = jan,
  journal = {Anatomical Sciences Education},
  volume = {13},
  number = {1},
  pages = {59--70},
  publisher = {Wiley-Blackwell Publishing Ltd.},
  issn = {1935-9772},
  doi = {10.1002/ase.1865},
  abstract = {Instructor evaluations are influenced by implicit age and gender bias, with lower ratings and negative feedback given to instructors believed to stray from stereotypical age and gender norms. Female instructors exhibiting typically male-associated qualities such as leadership and authority, are often negatively impacted. Implicit bias also influences evaluation of digital resources and instructors, regardless of students' positive learning outcomes. As digital learning resources become the norm in education, it is crucial to explore the impact of implicit bias at various educational levels. In this study, undergraduate and graduate students were randomly exposed to one of five digital tutorials; four experimental tutorials presenting identical anatomy content with narrators of different gender and age, and a control tutorial featuring origami (paper folding) instructions without audio. Learning outcomes were measured by pre-quiz vs. post-quiz comparisons using repeated measures MANOVA. Implicit bias was analyzed by evaluation response comparisons using repeated measures MANOVA and three-way MANOVA. Post-quiz scores increased significantly in the four experimental groups (P {$<$} 0.05) but not in the control (P = 0.99). The increased performance was not statistically different across the four experimental groups (P {$>$} 0.26), suggesting that learning occurred irrespective of the instructor gender and age. Students' evaluations were consistently higher for the experimental resources than the control. There was no significant difference in evaluations across the four experimental groups but compared to the control, younger male and younger female narrators received significantly higher ratings for approachability, acceptance, inclusivity, and care for student learning. The study highlights important considerations for digital resources development and interpretation of student evaluations. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  keywords = {Adolescent,Adult,age bias,Age Factors,Ageism,Anatomy,Attitude of Health Personnel,College Students,College Teachers,Computer-Assisted Instruction,Curriculum,e- learning,Education Dental,educational resource design,Educational Status,Female,gender bias,graduate education digital education,gross anatomy education,Humans,Implicit Bias,Implicit Learning,Learning,learning outcome,Male,Middle Aged,Sex Factors,Sexism,Student Attitudes,student evaluation,Students Dental,Teacher Characteristics,Teacher Effectiveness Evaluation,Teaching,Teaching Methods,undergraduate education,Undergraduate Education,Video Recording,Young Adult}
}

@article{weirCaseStudyEAssessment2021,
  title = {A {{Case Study}} in the {{E-Assessment}} of {{Statistics}} for {{Non-Specialists}}},
  author = {Weir, Iain and Gwynllyw, Rhys and Henderson, Karen},
  year = {2021},
  month = jan,
  journal = {Journal of University Teaching and Learning Practice},
  volume = {18},
  number = {2},
  publisher = {{Journal of University Teaching and Learning Practice}},
  issn = {1449-9789},
  doi = {10.53761/1.18.1.5},
  abstract = {The need to be able to choose, perform and interpret the results from appropriate statistical tests is ubiquitous in many STEM disciplines and beyond. In this case study, we illustrate a learning and assessment approach that has been used successfully for first year Business School students taking a module on Business Decision Making for Marketing and Events. The objective of the module is to give students a grounding in statistics, including learning to use the SPSS package, and to apply the techniques learnt to a large real-world data set. Due to the large number of students and their diverse abilities the learning and teaching strategy is centred on using formative key skill e-assessments to encourage students to self-learn. On accessing each e-assessment, students are presented with a randomly generated data set, which they are required to import into SPSS to then appropriately analyse and report on. Marking and feedback occurs automatically on submission and repeated use ensures that a student thoroughly learns a key skill and covers various analysis outcome scenarios, for instance significant or not significant test outcomes. Each key skill e-assessment has multiple embedded links to comprehensive Help pages that provide SPSS 'how-to' information or output interpretation. Access to these means that staff in the PC sessions can concentrate on giving higher-level support as opposed to merely helping with the mechanics of producing SPSS output. The e-assessments were created using Dewis, which is a fully algorithmic open-source e-assessment system. Dewis' ability to communicate with the R programming language facilitates the creation of authentic e-assessments, generating bespoke student data and providing answers that match SPSS screen output. The assessment of students' statistical competency is by in-class e-exams, which are summative and sat under exam conditions. The fact that the formative and summative e-assessments are marked immediately by Dewis represents a huge saving in marking time compared to human marking and allows students to have instant feedback on their work. Repeated use of the formative e-assessments allows students to independently practice and check their understanding. In this case study, we find that those students that did practice achieved significantly higher marks in the e-exams. We are now in our third year of delivery and the module has developed further due to stronger connections between the business and statistics strands of the module.},
  keywords = {Case Studies,Computer Assisted Testing,Foreign Countries,Formative Evaluation,Learner Engagement,Nonmajors,Statistics Education,Student Evaluation,Test Construction,Tests,United Kingdom (Bristol)},
  file = {/Users/colin.madland/Zotero/storage/QB74DSJU/weirCaseStudyEAssessment2021.pdf}
}

@misc{WelcomeIndigenousFoundations,
  title = {Welcome to {{Indigenous Foundations}}},
  urldate = {2019-12-30},
  howpublished = {https://indigenousfoundations.arts.ubc.ca/home/},
  file = {/Users/colin.madland/Zotero/storage/UH8SABQI/home.html}
}

@misc{wellerGoodOnlineLearning2022,
  title = {Good Online Learning -- Assessment -- {{The Ed Techie}}},
  author = {Weller, Martin},
  year = {2022},
  month = may,
  journal = {The Ed Techie},
  urldate = {2022-06-02},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/7GNCZQXU/good-online-learning-assessment.html}
}

@article{wellerMappingOpenEducation2018,
  title = {Mapping the Open Education Landscape: Citation Network Analysis of Historical Open and Distance Education Research},
  shorttitle = {Mapping the Open Education Landscape},
  author = {Weller, Martin and Jordan, Katy and DeVries, Irwin and Rolfe, Viv},
  year = {2018},
  month = apr,
  journal = {Open Praxis},
  volume = {10},
  number = {2},
  pages = {109--126},
  issn = {2304-070X},
  doi = {10.5944/openpraxis.10.2.822},
  urldate = {2018-11-03},
  abstract = {The term open education has recently been used to refer to topics such as Open Educational Resources (OERs) and Massive Open Online Courses (MOOCs). Historically its roots lie in civil approaches to education and open universities, but this research is rarely referenced or acknowledged in current interpretations. In this article the antecedents of the modern open educational movement are examined, as the basis for connecting the various strands of research. Using a citation analysis method the key references are extracted and their relationships mapped. This work reveals eight distinct sub-topics within the broad open education area, with relatively little overlap. The implications for this are discussed and methods of improving inter-topic research are proposed.},
  copyright = {Copyright (c) 2018 Authors},
  langid = {english},
  keywords = {citation network analysis,distance education,history,open education,Open education,social network analysis},
  file = {/Users/colin.madland/Zotero/storage/B84VWJ66/wellerMappingOpenEducation2018.pdf;/Users/colin.madland/Zotero/storage/5ZU48BAM/822.html}
}

@article{wellerUseInnovativeTechnologies2005,
  title = {Use of Innovative Technologies on an E-Learning Course},
  author = {Weller, Martin and Pegler, Chris and Mason, Robin},
  year = {2005},
  month = jan,
  journal = {The Internet and Higher Education},
  volume = {8},
  number = {1},
  pages = {61--71},
  issn = {10967516},
  doi = {10.1016/j.iheduc.2004.10.001},
  urldate = {2022-11-27},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/DCTJ37ES/wellerUseInnovativeTechnologies2005.pdf}
}

@article{wendtStandardizedEvidenceBasedContinued2007,
  title = {Toward a {{Standardized}} and {{Evidence-Based Continued Competence Assessment}} for {{Registered Nurses}}:},
  shorttitle = {Toward a {{Standardized}} and {{Evidence-Based Continued Competence Assessment}} for {{Registered Nurses}}},
  author = {Wendt, Anne and Alexander, Maryann},
  year = {2007},
  month = jul,
  journal = {JONA's Healthcare Law, Ethics, and Regulation},
  volume = {9},
  number = {3},
  pages = {74--86},
  issn = {1520-9229},
  doi = {10/dhcs35},
  urldate = {2020-12-20},
  langid = {english}
}

@book{wengerCommunitiesPracticeBrief,
  title = {Communities of {{Practice}}: {{A}} Brief Introduction},
  author = {Wenger, Etienne},
  volume = {2011},
  abstract = {The term "community of practice" is of relatively recent coinage, even though the phenomenon it refers to is age-old. The concept has turned out to provide a useful perspective on knowing and learning. A growing number of people and organizations in various sectors are now focusing on communities of practice as a key to improving their performance. This brief and general introduction examines what communities of practice are and why researchers and practitioners in so many different contexts find them useful as an approach to knowing and learning.}
}

@book{wengerCommunitiesPracticeLearning2004,
  title = {Communities of Practice: {{Learning}}, Meaning and Identity},
  shorttitle = {Communities of Practice: {{Learning}}, Meaning and Identity},
  author = {Wenger, E.},
  year = {2004},
  publisher = {Cambridge Univeristy Press},
  address = {New York, NY}
}

@techreport{wengerFriendlyGuideStudent2024,
  title = {A {{Friendly Guide}} to {{Student Engagement}}},
  author = {Wenger, K and Russell, A and Kinzie, J},
  year = {2024},
  institution = {National Survey for Student Engagement},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/DPVJHSMK/FriendlyGuideStudent.pdf}
}

@article{wenUniversityStudentsPerceptions2006,
  title = {University {{Students}}' {{Perceptions}} of and {{Attitudes Toward}} ({{Online}}) {{Peer Assessment}}},
  author = {Wen, Meichun Lydia and Tsai, Chin-Chung},
  year = {2006},
  month = jan,
  journal = {Higher Education},
  volume = {51},
  number = {1},
  pages = {27--44},
  issn = {0018-1560, 1573-174X},
  doi = {10/cdhj3j},
  urldate = {2021-07-04},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/FNTKVGFU/wenUniversityStudentsPerceptions2006.pdf}
}

@article{wenzelAreOpenBook2022,
  title = {Are Open-book Tests Still as Effective as Closed-book Tests Even after a Delay of 2 Weeks?},
  author = {Wenzel, Kristin and Schweppe, Judith and Rummer, Ralf},
  year = {2022},
  month = apr,
  journal = {Applied Cognitive Psychology},
  pages = {acp.3943},
  issn = {0888-4080, 1099-0720},
  doi = {10.1002/acp.3943},
  urldate = {2022-05-02},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/XKB2TZ4Q/wenzelAreOpenBook2022.pdf}
}

@misc{WestbankFirstNation,
  title = {About {{Westbank First Nation}} - {{Westbank First Nation}}},
  urldate = {2022-01-14},
  howpublished = {https://www.wfn.ca/our-community/about-westbank-first-nation.htm}
}

@misc{WestbankFirstNationa,
  title = {About {{Westbank First Nation}} - {{Westbank First Nation}}},
  urldate = {2022-01-14},
  howpublished = {https://www.wfn.ca/our-community/about-westbank-first-nation.htm}
}

@article{westEnhancingAssessmentExperience2016,
  title = {Enhancing the {{Assessment Experience}}: {{Improving Student Perceptions}}, {{Engagement}} and {{Understanding Using Online Video Feedback}}},
  author = {West, John and Turner, Will},
  year = {2016},
  month = jan,
  journal = {Innovations in Education and Teaching International},
  volume = {53},
  number = {4},
  pages = {400--410},
  publisher = {{Innovations in Education and Teaching International}},
  issn = {1470-3297},
  doi = {10.1080/14703297.2014.1003954},
  abstract = {Individualised video screencasts with accompanying narration were used to provide assessment feedback to a large number (n = 299) of first-year Bachelor of Education students at Edith Cowan University in Western Australia. An anonymous online survey revealed that nearly three times as many respondents (61\%) preferred video feedback to written feedback (21\%). The results reflect a clear preference for video feedback among the research participants. Participants commented that video feedback was clearer and less ambiguous than other forms of feedback and improved both the quality and quantity of the feedback received. Participants also felt that video feedback established greater rapport with their tutor and provided them with greater insight into the assessment process.},
  keywords = {Australia,Feedback (Response),Focus Groups,Foreign Countries,Higher Education,Interviews,Learner Engagement,Likert Scales,Online Surveys,Questionnaires,Statistical Analysis,Student Attitudes,Student Surveys,Technology Uses in Education,Video Technology,Virtual Classrooms}
}

@book{westFoundationsLearningInstructional2018,
  title = {Foundations of {{Learning}} and {{Instructional Design Technology}}: {{The Past}}, {{Present}}, and {{Future}} of {{Learning}} and {{Instructional Design Technology}}},
  author = {West, Richard E.},
  year = {2018},
  edition = {1},
  publisher = {EdTech Books}
}

@misc{WhatPersonalLearning,
  title = {What Is a {{Personal Learning Network}} ({{PLN}})?},
  journal = {FutureLearn},
  urldate = {2021-12-23},
  abstract = {This animated video explains more about Personal Learning Networks and our network interactions on and offline.},
  howpublished = {https://www.futurelearn.com/info/courses/learning-network-age/0/steps/24644},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/P2H8WMRU/24644.html}
}

@misc{WhatUniversitiesCould2019,
  title = {What Universities Could Learn from an {{Indigenous}} `Way of Knowing'},
  year = {2019},
  month = jan,
  journal = {TVO},
  urldate = {2019-02-04},
  abstract = {Melanie Goodchild's research is informed by ``Anishinaabe Gikendaasowin,'' part of her First Nation's knowledge system --- she talks to TVO.org about complexity theory, two-eyed seeing, and fighting for change in academia.},
  howpublished = {https://www.tvo.org/article/current-affairs/what-universities-could-learn-from-an-indigenous-way-of-knowing},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/5RY3RXWT/what-universities-could-learn-from-an-indigenous-way-of-knowing.html}
}

@article{wheelerGoodBadWiki2008,
  title = {The Good, the Bad and the Wiki: {{Evaluating}} Student-Generated Content for Collaborative Learning},
  author = {Wheeler, Steve and Yeomans, Peter and Wheeler, Dawn},
  year = {2008},
  journal = {British Journal of Educational Technology},
  volume = {39},
  number = {6},
  pages = {987--995},
  abstract = {This paper explores the potential for wiki-type open architecture software to promote and support collaborative learning through the use of student-created content. It delineates some of the affordances and constraints of wiki software as an open architecture that has the potential to facilitate collaborative learning through community-focused enquiry. It seeks to promote debate in this key area of development, and highlights some recent key contributions to the developing discourse on social software in what has been termed `the architecture of participation'.}
}

@misc{WhiteCollarCrime,
  title = {White {{Collar Crime Risk Zones}}},
  urldate = {2020-09-26},
  abstract = {A machine learning system that predicts where white collar crimes will occur throughout the US.},
  howpublished = {https://whitecollar.thenewinquiry.com},
  file = {/Users/colin.madland/Zotero/storage/GI27BSW8/whitecollar.thenewinquiry.com.html}
}

@article{whitelockCanEAuthenticationRaise2020,
  title = {Can E-{{Authentication Raise}} the {{Confidence}} of {{Both Students}} and {{Teachers}} in {{Qualifications Granted}} through the e-{{Assessment Process}}?},
  author = {Whitelock, Denise and Edwards, Chris and Okada, Alexandra},
  year = {2020},
  month = jan,
  journal = {Journal of Learning for Development},
  volume = {7},
  number = {1},
  pages = {46--60},
  publisher = {Journal of Learning for Development},
  issn = {2311-1550},
  doi = {10.56059/jl4d.v7i1.384},
  abstract = {The EU-funded TeSLA project -- Adaptive Trust-based e-Assessment System for Learning (http://tesla-project.eu) -- has developed a suite of instruments for e-Authentication. These include face recognition, voice recognition, keystroke dynamics, forensic analysis and plagiarism detection, which were designed for integration within a university's virtual learning environment. These tools were trialed across the seven partner institutions: 4,058 participating students, including 330 students with special educational needs and disabilities (SEND); and 54 teaching staff. This paper describes the findings of this large-scale study where over 50\% of the students gave a positive response to the use of these tools. In addition, over 70\% agreed that these tools were "to ensure that my examination results are trusted" and "to prove that my essay is my own original work". Teaching staff also reported positive experiences with TeSLA: the figure reaching 100\% in one institution. We show there is evidence that a suite of e-authentication tools such as TeSLA can potentially be acceptable to students and staff and be used to increase trust in online assessment. Also, that while not yet perfected for SEND students it can still enrich their experience of assessment. We find that care is needed when introducing such technologies to ensure building the layers of trust required for their successful adoption.},
  keywords = {Bulgaria,Cheating,College Faculty,College Students,Computer Assisted Testing,Computer Security,Electronic Learning,Finland,Foreign Countries,Netherlands,Spain,Special Needs Students,Student Attitudes,Students with Disabilities,Teacher Attitudes,Trust (Psychology),Turkey,United Kingdom},
  file = {/Users/colin.madland/Zotero/storage/28UC6JW6/whitelockCanEAuthenticationRaise2020.pdf}
}

@misc{whitelockReframingEassessmentAdopting2008,
  title = {Reframing E-Assessment: Adopting New Media and Adapting Old Frameworks},
  shorttitle = {Reframing E-Assessment},
  author = {Whitelock, Denise and Watt, Stuart},
  year = {2008},
  journal = {Learning, Media and Technology},
  volume = {33},
  number = {3},
  pages = {151--154},
  publisher = {Taylor \& Francis},
  file = {/Users/colin.madland/Zotero/storage/WQKZQ5RX/17439880802447391.html}
}

@article{whiteVisitorsResidentsNew2011,
  title = {Visitors and {{Residents}}: {{A}} New Typology for Online Engagement},
  shorttitle = {Visitors and {{Residents}}},
  author = {White, David S. and Cornu, Alison Le},
  year = {2011},
  month = aug,
  journal = {First Monday},
  issn = {1396-0466},
  doi = {1633621063},
  urldate = {2022-02-01},
  abstract = {This article proposes a continuum of \&lsquo;Visitors\&rsquo; and \&lsquo;Residents\&rsquo; as a replacement for Prensky\&rsquo;s much\&dash;criticised Digital Natives and Digital Immigrants. Challenging the basic premises upon which Prensky constructed his typology, Visitors and Residents fulfil a similar purpose in mapping individuals\&rsquo; engagement with the Web. We argue that the metaphors of \&lsquo;place\&rsquo; and \&lsquo;tool\&rsquo; most appropriately represent the use of technology in contemporary society, especially given the advent of social media. The Visitors and Residents continuum accounts for people behaving in different ways when using technology, depending on their motivation and context, without categorising them according to age or background. A wider and more accurate representation of online behaviour is therefore established.},
  copyright = {Copyright (c)},
  langid = {english},
  keywords = {archived,Engagement},
  annotation = {https://web.archive.org/web/20220121041240/https://firstmonday.org/ojs/index.php/fm/article/view/3171}
}

@phdthesis{whitmellTeachersNavigatingTheir2020,
  title = {Teachers {{Navigating Their Experiences}} of "{{Going Gradeless}}" in {{Ontario}}, {{Canada}}},
  author = {Whitmell, Theresa Elizabeth},
  year = {2020},
  abstract = {The purpose of this qualitative study was to explore the experiences of Ontario secondary school teachers, navigating conceptual, pedagogical, cultural and political challenges as they shifted their practice from marks to "gradeless". Twenty-eight teachers from fifteen schools in seven school districts in the province of Ontario in Canada participated in semi-structured, face-to-face interviews. The 28 teachers in this study shared complex journeys of growth and innovation, providing feedback and supporting student learning through use of clear goals, and explicit communication of success criteria. The study provides models of gradeless classroom assessment that range from hidden or deferred marks to four-level rubrics to single-point rubrics to rich descriptive feedback, and from task criteria to curriculum expectations to overarching learning goals. The interviewees described concepts of assessment that centre on the learner, and pedagogical approaches that support student voice and choice. They experienced challenges from the cultural expectations of students, parents and colleagues, but none of the interviewees were restricted by policy requirements from making the changes in assessment practice that they identified as "gradeless", and which serve to support the learning of their students. This study suggests that teachers' conceptual understanding begins with their personal experiences of assessment, is developed through the pedagogy they employ, the cultural influences on their professional and school community, and the policy that underpins their practice. The study demonstrates that when teachers discover processes that improve the achievement of their students, they will persist with the new process even if faced with strong cultural pressure. It suggests that greater communication to, and education of, the school community, parents and students is needed to shift cultural expectations of assessment. The study reveals that given clear policy, grounded in research, teachers can develop stronger conceptual understanding of assessment, and are empowered to move forward, even in the face of strong cultural pressures. Implications for future research in classroom assessment, teacher change, and 21st century learning are further discussed.},
  langid = {english},
  school = {University of Toronto},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/U76KLNT7/whitmellTeachersNavigatingTheir2020.pdf}
}

@article{whitworthOnlineAssessmentLearning2015,
  title = {Online Assessment of Learning and Engagement in University Laboratory Practicals},
  author = {Whitworth, David E. and Wright, Kate},
  year = {2015},
  journal = {British Journal of Educational Technology},
  volume = {46},
  number = {6},
  pages = {1201--1213},
  publisher = {WILEY},
  address = {HOBOKEN},
  issn = {0007-1013},
  doi = {10/ggrgxj},
  abstract = {In science education, laboratory practicals are frequently assessed through submission of a report. A large increase in student numbers necessitated us adapting a traditional practical report into an online test with automated marking. The assessment was designed to retain positive features of the traditional laboratory report but with added pedagogic and administrative benefits made possible through the online medium. After performing their experiments, students were given idealised data, enabling immediate comparison with their own results, and asked to perform a series of calculations based on that ideal data. The two-part test asked questions about the students' calculations. Part I was formative, ensuring that the students had mastered basic concepts before advanced concepts were tested in Part II. The test rewarded correct methodology and understanding as well as the right answers and gave absolute consistency to the marking scheme. Students could submit at their convenience and received instant feedback. The assessment was met with emphatically positive feedback from students. In addition, it was possible to track submissions by students, providing insights into their behaviour. Students appeared to group into three submission styles--early submitters, considered submitters and last minute submitters--information which can be useful to guide pedagogic practice. In the latest iteration, analysis of submission behaviour gave us confidence to reduce the time before the submission deadline, which resulted in a substantial increase in student attainment.;In science education, laboratory practicals are frequently assessed through submission of a report. A large increase in student numbers necessitated us adapting a traditional practical report into an online test with automated marking. The assessment was designed to retain positive features of the traditional laboratory report but with added pedagogic and administrative benefits made possible through the online medium. After performing their experiments, students were given idealised data, enabling immediate comparison with their own results, and asked to perform a series of calculations based on that ideal data. The two-part test asked questions about the students' calculations. Part I was formative, ensuring that the students had mastered basic concepts before advanced concepts were tested in Part II. The test rewarded correct methodology and understanding as well as the right answers and gave absolute consistency to the marking scheme. Students could submit at their convenience and received instant feedback. The assessment was met with emphatically positive feedback from students. In addition, it was possible to track submissions by students, providing insights into their behaviour. Students appeared to group into three submission stylesearly submitters, considered submitters and last minute submittersinformation which can be useful to guide pedagogic practice. In the latest iteration, analysis of submission behaviour gave us confidence to reduce the time before the submission deadline, which resulted in a substantial increase in student attainment.;In science education, laboratory practicals are frequently assessed through submission of a report. A large increase in student numbers necessitated us adapting a traditional practical report into an online test with automated marking. The assessment was designed to retain positive features of the traditional laboratory report but with added pedagogic and administrative benefits made possible through the online medium. Biographical information:;},
  keywords = {Analysis,College Students,Computation,Computer Assisted Testing,EDUCATION & EDUCATIONAL RESEARCH,Educational Attainment,Feedback (Response),Grading,HIGHER-EDUCATION,Mastery Learning,Mathematics,Reports,Science Laboratories,Scientific Concepts,Student Evaluation,Universities and colleges}
}

@article{wicaksonoLanguageAssessmentEFL2023,
  title = {I like Language Assessment: {{EFL}} Learners' Voices about Self-Assessment, Self-Efficacy, Grit Tendencies, Academic Resilience, and Academic Demotivation in Online Instruction},
  author = {Wicaksono, Bayu Hendro and Ismail, Sayed M. and Sultanova, Shakhnoza Akmalovna and Abeba, Dejen},
  year = {2023},
  journal = {Language Testing in Asia},
  volume = {13},
  number = {1},
  pages = {37--18},
  publisher = {Springer International Publishing},
  address = {Cham},
  issn = {2229-0443},
  doi = {10.1186/s40468-023-00252-2},
  abstract = {Self-awareness and self-evaluation are at the heart of both core of self-assessment, self-efficacy, and grit tendencies. Although there is a lot written about self-assessment, self-efficacy, and grit tendencies, academic resilience, and motivation, very little is known about how self-assessment, self-efficacy, and grit tendencies contribute to the academic resilience and academic demotivation of the learners, especially in online English as a foreign language (EFL) assessment. Therefore, the purpose of this study was to investigate a structural model of core of self-assessment, self-efficacy, grit tendencies, academic resilience, and academic demotivation among EFL students. Consequently, 385 EFL students took surveys measuring their language-learning endeavors using the Core of Self-assessment Questionnaire (CSAQ), the Self-Efficacy Scale (S-ES), the language-domain-specific grit scale (L2-Grit S), the Academic Resilience Scale (ARS), and the Academic Demotivation Scale (ADS). Structural equation modeling (SEM) findings revealed that highly resilient and motivated EFL students had high core of self-assessment. Additionally, grit tendencies and self-efficacy displayed effectiveness in elevating academic resilience and motivation in online assessment. The results of this study may have worthwhile pedagogical implications for incorporating technologically enhanced learning and assessment into the classroom.},
  keywords = {Academic demotivation,Academic resilience,Assessment,Computer assisted language learning,Education,English as a second language,English as a second language instruction,Grit tendencies,Language assessment,Language Education,Learning oriented Assessment (LOA): A Window for Fairness in Classroom Assessment?,Motivation,Online instruction,Self evaluation,Self-assessment,Self-efficacy,Testing and Evaluation},
  file = {/Users/colin.madland/Zotero/storage/F5QJH3XH/wicaksonoLanguageAssessmentEFL2023.pdf}
}

@book{wickhamGgplot2ElegantGraphics2016,
  title = {Ggplot2: {{Elegant}} Graphics for Data Analysis},
  author = {Wickham, Hadley},
  year = {2016},
  publisher = {Springer-Verlag New York},
  isbn = {978-3-319-24277-4}
}

@incollection{wicksElectronicPortfoliosPedagogy2015,
  title = {Electronic {{Portfolios As Pedagogy}}: {{Using Bportfolios For Authentic Assessment Of Teacher Knowledge And Skills In The Us}}},
  booktitle = {International {{Teacher Education}}: {{Promising Pedagogies}}, {{Pt C}}},
  author = {Wicks, D and Lumpe, A},
  editor = {Craig, {\relax CJ} and OrlandBarak, L},
  year = {2015},
  volume = {22C},
  pages = {219--232},
  doi = {10.1108/S1479-368720150000022011},
  abstract = {Web 2.0 technologies, such as blogging, allow for locally developed, cost-effective, and holistic alternative portfolio assessment systems. By enhancing critical reflection and fostering social interaction, blogging portfolios or bPortfolios become integral formative and summative assessment tools for all teacher education students enrolled in a university program. Blogging platforms such as WordPress.com are free to use and are available worldwide allowing bPortfolios to be implemented at any institution where students have Internet access.},
  isbn = {1479-3687},
  langid = {english},
  keywords = {Access,assessment,blogging portfolios,BLOGS,bPortfolios,electronic portfolios,instructional technology,REFLECTION}
}

@misc{wileyConsensusOpen2016,
  title = {The {{Consensus Around}} ``{{Open}}''},
  author = {Wiley, David},
  year = {2016},
  month = jan,
  journal = {iterating toward openness},
  urldate = {2018-10-04},
  abstract = {Yesterday EdSurge published an opinion piece by Stephen Laster, the Chief Digital Officer at McGraw-Hill Education, titled The Future of Education Isn't Free. It's Open. The article makes a strong {\dots}},
  howpublished = {https://opencontent.org/blog/archives/4397},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/IBNYZK3Y/4397.html}
}

@article{wileyDefiningOEREnabledPedagogy2018,
  title = {Defining {{OER-Enabled Pedagogy}}},
  author = {Wiley, David and Hilton, John},
  year = {2018},
  month = sep,
  journal = {The International Review of Research in Open and Distributed Learning},
  volume = {19},
  number = {4},
  issn = {1492-3831},
  doi = {10.19173/irrodl.v19i4.3601},
  urldate = {2018-11-01},
  abstract = {The term ``open pedagogy'' has been used in a variety of different ways over the past several decades. In recent years, its use has also become associated with Open Educational Resources (OER). The wide range of competing definitions of open pedagogy, together with its semantic overlap with another underspecified term, open educational practices, makes it difficult to conduct research on the topic of open pedagogy. In making this claim we do not mean to cast doubt on the potential effectiveness of the many pedagogical approaches labeled open. In this article, rather than attempting to argue for a canonical definition of open pedagogy, we propose a new term, ``OER-enabled pedagogy,'' defined as the set of teaching and learning practices that are only possible or practical in the context of the 5R permissions that are characteristic of OER. We propose criteria used to evaluate whether a form of teaching constitutes OER-enabled pedagogy and analyze several examples of OER-enabled pedagogy with these criteria.},
  copyright = {Copyright (c) 2018 John Levi Hilton III, David Wiley, David Wiley},
  langid = {english},
  keywords = {oer-enabled pedagogy,OER-enabled pedagogy,open education,open educational practices,open learning,open pedagogy},
  file = {/Users/colin.madland/Zotero/storage/W4BGDSU7/wileyDefiningOEREnabledPedagogy2018.pdf;/Users/colin.madland/Zotero/storage/ZC62CLMA/3601.html}
}

@misc{wileyDefiningOpenOpenND,
  title = {Defining the `Open' in Open Content},
  author = {Wiley, David},
  year = {ND},
  urldate = {2018-09-23}
}

@misc{wileyOEREnabledPedagogy2017,
  title = {{{OER-Enabled Pedagogy}}},
  author = {Wiley, David},
  year = {2017},
  month = may,
  journal = {iterating toward openness},
  urldate = {2018-09-24},
  abstract = {Over the last several weeks there has been an incredible amount of writing about open pedagogy and open educational practices (samples collected here by Maha). There have been dozens of blog posts.{\dots}},
  langid = {american},
  file = {/Users/colin.madland/Zotero/storage/9B746Q9W/5009.html}
}

@article{wileyPreliminaryExplorationRelationships2017,
  title = {A {{Preliminary Exploration}} of the {{Relationships Between Student-Created OER}}, {{Sustainability}}, and {{Students}}' {{Success}}},
  author = {Wiley, David and Webb, Ashley and Weston, Sarah and Tonks, DeLaina},
  year = {2017},
  month = jun,
  journal = {The International Review of Research in Open and Distributed Learning},
  volume = {18},
  number = {4},
  issn = {1492-3831},
  urldate = {2018-07-07},
  copyright = {Copyright (c) 2017 David Wiley, Ashley Webb, Sarah Weston, DeLaina Tonks},
  langid = {english},
  keywords = {open educational resources,student-created content,sustainability},
  file = {/Users/colin.madland/Zotero/storage/P3MEDL9A/wileyPreliminaryExplorationRelationships2017.pdf;/Users/colin.madland/Zotero/storage/689HRWDW/4222.html}
}

@article{wileyRemixHypothesis2015,
  title = {The {{Remix Hypothesis}}},
  author = {Wiley, David},
  year = {2015}
}

@article{wiliamAssessmentLearningReflections2017,
  title = {Assessment and Learning: Some Reflections},
  shorttitle = {Assessment and Learning},
  author = {Wiliam, Dylan},
  year = {2017},
  month = jul,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {24},
  number = {3},
  pages = {394--403},
  issn = {0969-594X, 1465-329X},
  doi = {10/ggjrmc},
  urldate = {2021-01-29},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/BGMGMFSP/wiliamAssessmentLearningReflections2017.pdf}
}

@article{wiliamHowCanAssessment2018,
  title = {How {{Can Assessment Support Learning}}? {{A Response}} to {{Wilson}} and {{Shepard}}, {{Penuel}}, and {{Pellegrino}}},
  author = {Wiliam, Dylan},
  year = {2018},
  journal = {Educational Measurement: Issues and Practice},
  volume = {37},
  number = {1},
  pages = {42--44},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {0731-1745},
  doi = {10/gjn22h},
  urldate = {2021-04-08},
  file = {/Users/colin.madland/Zotero/storage/JN5R4WIQ/wiliamHowCanAssessment2018.pdf}
}

@incollection{wiliamIntegratingAssessmentLearning2017,
  title = {Integrating {{Assessment}} with {{Learning}}: {{What Will It Take}} to {{Make It Work}}?},
  booktitle = {The Future of Assessment: Shaping Teaching and Learning},
  author = {Wiliam, Dylan and Thompson, Marnie},
  editor = {Dwyer, Carol Anne},
  year = {2017},
  edition = {1st},
  publisher = {Routledge},
  address = {London},
  isbn = {978-1-351-54441-2},
  langid = {english},
  annotation = {OCLC: 1005608225},
  file = {/Users/colin.madland/Zotero/storage/APHV7IXP/wiliam2017.pdf}
}

@article{wiliamWhatAssessmentLearning2011,
  title = {What Is Assessment for Learning?},
  author = {Wiliam, Dylan},
  year = {2011},
  month = mar,
  journal = {Studies in Educational Evaluation},
  volume = {37},
  number = {1},
  pages = {3--14},
  issn = {0191491X},
  doi = {10.1016/j.stueduc.2011.03.001},
  urldate = {2024-04-25},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/TPF9CEBU/wiliamWhatAssessmentLearning2011.pdf}
}

@article{wilkieStudentExperiencesLive2022,
  title = {Student Experiences of Live Synchronised Video Feedback in Formative Assessment},
  author = {Wilkie, B and Liefeith, A},
  year = {2022},
  month = apr,
  journal = {Teaching in Higher Education},
  volume = {27},
  number = {3},
  pages = {403--416},
  issn = {1356-2517},
  doi = {10.1080/13562517.2020.1725879},
  abstract = {Effective student feedback is a central issue in higher education and has been closely aligned to satisfaction and overall experience. Technology-enabled models of feedback may have the capacity to overcome some of the limitations that previously made high quality feedback on formative tasks challenging or impractical. This study adopted live synchronised video feedback incorporating digital video recordings of student performance in assessment activities with real-time, synthesised, synchronous tutor audio feedback. Almost 300 unique incidences of technology-enabled feedback on formative assessment were provided during an undergraduate Physical Education and Sports Coaching module. Thematic analysis of group interviews revealed the availability of engaging feedback, the positive impact of technology, and the facilitation of reflective practice as overarching themes. Employment of this feedback strategy enabled the realisation of high quality, frequent, effective, sustainable feedback that positively impacted on students' experiences of formative assessments leading to their perceived development as learners and reflective practitioners.},
  langid = {english},
  keywords = {AUDIO FEEDBACK,formative assessment,QUALITY,reflective practice,Video feedback},
  file = {/Users/colin.madland/Zotero/storage/JKHYNKXG/wilkieStudentExperiencesLive2022.pdf}
}

@article{wilkinsonUsingLearningAnalytics2019,
  title = {Using {{Learning Analytics}} to {{Evaluate Course Design}} and {{Student Behavior}} in an {{Online Wine Business Course}}},
  author = {Wilkinson, Kerry and McNamara, Imogen and Wilson, David and Riggs, Karina},
  year = {2019},
  month = may,
  journal = {International Journal of Innovation in Science and Mathematics Education},
  volume = {27},
  number = {4},
  issn = {2200-4270},
  doi = {10.30722/IJISME.27.04.008},
  urldate = {2022-10-31},
  abstract = {This case study describes the use of learning analytics to evaluate the transition of a postgraduate wine business course from face-to-face to online delivery using e-learning course design principles. Traditionally, Foundations of Wine Science lectures were delivered face-to-face, however the decision to transition the course from semester to trimester format presented an opportunity for online delivery of lectures. This was initially achieved through audio recordings, then video lectures, supported by a range of digital learning resources intended to engage, support and enhance student learning and the student experience. Descriptive analysis of learning analytics, comprising assessment results, student evaluations of learning and teaching, and data sourced from the Learning Management System, was performed to evaluate the impact of online delivery of course content on student performance, satisfaction and engagement. The use of audio lecture recordings negatively impacted students' perception of the overall quality of the course (including course organisation, learning strategies and learning resources). The subsequent implementation of e-learning designed video lectures was considered superior to audio recordings, albeit final grades were not significantly different between the delivery modes. However, student engagement was equal to, or better than face-to-face delivery, when content was designed specifically for an e-learning environment.},
  file = {/Users/colin.madland/Zotero/storage/YZZYKBLL/wilkinsonUsingLearningAnalytics2019.pdf}
}

@article{williamsAssessingCollaborativeLearning2017,
  title = {Assessing Collaborative Learning: Big Data, Analytics and University Futures},
  author = {Williams, P},
  year = {2017},
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {42},
  number = {6},
  pages = {978--989},
  publisher = {Assessment \& Evaluation in Higher Education},
  issn = {0260-2938},
  doi = {10.1080/02602938.2016.1216084},
  abstract = {Assessment in higher education has focused on the performance of individual students. This focus has been a practical as well as an epistemic one: methods of assessment are constrained by the technology of the day, and in the past they required the completion by individuals under controlled conditions of set-piece academic exercises. Recent advances in learning analytics, drawing upon vast sets of digitally stored student activity data, open new practical and epistemic possibilities for assessment, and carry the potential to transform higher education. It is becoming practicable to assess the individual and collective performance of team members working on complex projects that closely simulate the professional contexts that graduates will encounter. In addition to academic knowledge, this authentic assessment can include a diverse range of personal qualities and dispositions that are key to the computer-supported cooperative working of professionals in the knowledge economy. This paper explores the implications of such opportunities for the purpose and practices of assessment in higher education, as universities adapt their institutional missions to address twenty-first century needs. The paper concludes with a strong recommendation for university leaders to deploy analytics to support and evaluate the collaborative learning of students working in realistic contexts.},
  langid = {english},
  keywords = {authentic assessment,collaborative learning,College Curriculum,College Students,Computer Uses in Education,Cooperative Learning,Data Analysis,Epistemology,KNOWLEDGE,Knowledge Economy,Performance Based Assessment,Professional Identity,Relevance (Education),situated learning,Social learning analytics,Student Evaluation},
  file = {/Users/colin.madland/Zotero/storage/XWUWY5XW/williamsAssessingCollaborativeLearning2017.pdf}
}

@incollection{williamsFeedbackDigitalEnvironment,
  title = {Feedback in the Digital Environment},
  booktitle = {Feedback in {{Higher}} and {{Professional Education}}: {{Understanding}} It and Doing It Well},
  author = {Williams, Brett and Brown, Ted and Benson, Robyn},
  editor = {Boud, David and Molloy, Elizabeth},
  publisher = {Routledge},
  address = {New York},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/WNU9CXRI/williamsFeedbackDigitalEnvironment.pdf}
}

@article{williamsonPandemicPoliticsPedagogies2020,
  title = {Pandemic Politics, Pedagogies and Practices: Digital Technologies and Distance Education during the Coronavirus Emergency},
  shorttitle = {Pandemic Politics, Pedagogies and Practices},
  author = {Williamson, Ben and Eynon, Rebecca and Potter, John},
  year = {2020},
  month = apr,
  journal = {Learning, Media and Technology},
  volume = {45},
  number = {2},
  pages = {107--114},
  issn = {1743-9884, 1743-9892},
  doi = {10.1080/17439884.2020.1761641},
  urldate = {2022-03-20},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/NED5RPNC/williamsonPandemicPoliticsPedagogies2020.pdf}
}

@incollection{williamsProfessionalDevelopmentWeb2012,
  title = {Professional Development through Web 2.0 Collaborative Applications},
  booktitle = {Virtual Professional Development and Informal Learning via Social Networks},
  author = {Williams, Indi M. and Olaniran, Bolanie A.},
  editor = {Dennen, Vanessa P and Myers, Jennifer B},
  year = {2012},
  pages = {1--24},
  publisher = {IGI Global},
  abstract = {This chapter presents a fresh look at collaborative applications and their use in professional development and informal learning. The chapter addresses some of the cultural challenges impacting collaborative technologies, especially given the fact that these technologies are transplanted from developed countries into regions of the world that are only beginning to understand their significance. Therefore, the chapter points to the importance of and the needs to allow cultural variation and differences in usage. The chapter acknowledges the fact that collaborative technologies possess great potential for both professional development and informal learning, but cautions that external factors, such as culture and community, be taken into account to realize potential benefits.}
}

@article{willinskyUnacknowledgedConvergenceOpen2005,
  title = {The Unacknowledged Convergence of Open Source, Open Access, and Open Science},
  author = {Willinsky, John},
  year = {2005},
  month = jan,
  journal = {First Monday},
  volume = {10},
  number = {8},
  publisher = {University of Illinois, Chicago, in cooperation with the University Library},
  issn = {1396-0466},
  doi = {10.5210/fm.v10i8.1265},
  file = {/Users/colin.madland/Zotero/storage/UV8EKMVL/willinskyUnacknowledgedConvergenceOpen2005.pdf}
}

@article{willisAffiliationAutonomyAssessment2011,
  title = {Affiliation, Autonomy and {{Assessment}} for {{Learning}}},
  author = {Willis, Jill},
  year = {2011},
  month = nov,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {18},
  number = {4},
  pages = {399--415},
  publisher = {Routledge},
  issn = {0969-594X},
  doi = {10/fbwj23},
  file = {/Users/colin.madland/Zotero/storage/HJ7QRBTZ/willisAffiliationAutonomyAssessment2011.pdf}
}

@article{willisConceptualisingTeachersAssessment2013,
  ids = {willisConceptualisingTeachersAssessment2013a},
  title = {Conceptualising Teachers' Assessment Literacies in an Era of Curriculum and Assessment Reform},
  author = {Willis, Jill and Adie, Lenore and Klenowski, Val},
  year = {2013},
  month = may,
  journal = {The Australian Educational Researcher},
  volume = {40},
  number = {2},
  pages = {241--256},
  issn = {0311-6999, 2210-5328},
  doi = {10/gh5k7d},
  urldate = {2021-07-10},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/FLB2FY79/willisConceptualisingTeachersAssessment2013.pdf}
}

@article{willisFasterFeedbackHigher2021,
  title = {Towards Faster Feedback in Higher Education through Digitally Mediated Dialogic Loops},
  author = {Willis, Jill and Gibson, Andrew and Kelly, Nick and Spina, Nerida and Azordegan, Jennifer and Crosswell, Leanne},
  year = {2021},
  month = jan,
  journal = {Australasian Journal of Educational Technology},
  pages = {22--37},
  issn = {1449-5554, 1449-3098},
  doi = {10.14742/ajet.5977},
  urldate = {2023-01-15},
  abstract = {How feedback is understood and enacted has shifted from the traditional practice of providing individual feedback on summative tasks at key points to a more ongoing series of dialogues between the teacher and students during the teaching period. This paper reports on the experiences of designing faster feedback through weekly dialogic feedback loops to enhance students' personal connection to their learning while providing teachers with faster, actionable feedback data to inform learning design. A pragmatic inquiry considered how benefits might potentially be amplified through the use of digital technologies. Data included student reflections collected via the GoingOK web application, interviews and focus groups. The findings identify and theorise four types of digitally mediated feedback loops: students in computer-mediated dialogue with themselves; students and teachers in dialogue with each other; the reflection on how feedback informed learning; and the sociotechnical dialogue informing ongoing technical design. Three design dilemmas that were experienced by teachers as they enacted digitally mediated dialogic feedback loops are articulated, alongside the principles that enabled responsive design. Understanding these design elements is fundamental if automation of some parts of the feedback loop through reflective writing analytics is to be considered both feasible and desirable.  Implications for practice or policy:    Digitally mediated feedback loops can facilitate faster feedback, enabling students to reflect on their learning and providing teachers with access to new insights about diverse learners.  Feedback technology can challenge existing ideas about feedback.  Faster feedback can save teachers time, but efficiencies are likely to depend on an increased human workload in the short term as automation technologies can be slower to develop.  Sociotechnical innovation requires collective dialogue between educators and digital developers, across asynchronous timelines.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/W6NUEUAZ/willisFasterFeedbackHigher2021.pdf}
}

@article{willMeetingMiddleFuture2019,
  title = {Meeting in the Middle: {{Future}} Directions for Researchers to Support Educators' Assessment Literacy and Data-Based Decision Making},
  author = {Will, Kelsey K. and McConnell, Scott R. and Elmquist, Marianne and Lease, Erin M. and {Wackerle-Hollman}, Alisha},
  year = {2019},
  journal = {Frontiers in Education},
  volume = {4},
  pages = {106},
  issn = {2504-284X},
  doi = {10/gk47tt},
  abstract = {Assessment is prevalent throughout all levels of education in the United States. Even though educators are familiar with the idea of assessing students, familiarity does not necessarily ensure assessment literacy, or data-based decision making (DBDM) knowledge. Assessment literacy and DBDM are critical in education, and early childhood education in particular, to identify and intervene on potential barriers to students' development. Assessment produces data and evidence educators can use to inform intervention and instructional decisions to improve student outcomes. Given this importance and educators' varying levels of assessment literacy and DBDM knowledge, researchers, and educators should be willing to meet in the middle to support these practices and improve student outcomes. We provide perspective for half of the equation-- how researchers can contribute-- by addressing important considerations for the design and development of assessment measures, implications of these considerations for future measures, and a case example describing the design, and development of an assessment tool created to support DBDM for educators in early childhood education.},
  file = {/Users/colin.madland/Zotero/storage/XDQDIIWK/willMeetingMiddleFuture2019.pdf}
}

@article{willsLearningFrameworkAssessment2009,
  title = {An E-learning Framework for Assessment ({{FREMA}})},
  author = {Wills, Gary B. and Bailey, Christopher P. and Davis, Hugh C. and Gilbert, Lester and Howard, Yvonne and Jeyes, Steve and Millard, David E. and Price, Joseph and Sclater, Niall and Sherratt, Robert and Tulloch, Iain and Young, Rowin},
  year = {2009},
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {34},
  number = {3},
  pages = {273--292},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602930802068839},
  urldate = {2024-02-07},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/2QJMK2M9/willsLearningFrameworkAssessment2009.pdf}
}

@article{wilsonClassroomAssessmentContinuing2018,
  title = {Classroom {{Assessment}}: {{Continuing}} the {{Discussion}}},
  author = {Wilson, Mark},
  year = {2018},
  journal = {Educational Measurement: Issues and Practice},
  volume = {37},
  number = {1},
  pages = {49--51},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {0731-1745},
  doi = {10/gg8f5x},
  urldate = {2021-04-08},
  file = {/Users/colin.madland/Zotero/storage/CQZT2UJY/wilsonClassroomAssessmentContinuing2018.pdf}
}

@article{wilsonDigitalEthicsUse2018,
  title = {Digital {{Ethics}} and the {{Use}} of {{ePortfolio}}: {{A Scoping Review}} of the {{Literature}}},
  author = {Wilson, Christine Brown and Slade, Christine and Kirby, Misty M. and Downer, Terri and Fisher, Marie B. and Nuessler, Shane},
  year = {2018},
  month = jan,
  journal = {International Journal of ePortfolio},
  volume = {8},
  number = {2},
  pages = {115--125},
  publisher = {International Journal of ePortfolio},
  issn = {2157-622X},
  abstract = {ePortfolios have become more than simple repositories for professional development, achievement, and assessment; they now provide opportunities for students to develop an online profile and presence. As ePortfolios become more widely implemented in higher education, some unintended consequences around privacy, consent, and confidentiality have caused ethical dilemmas, particularly with vulnerable communities such as patients and children. This systematic scoping review found a dearth of literature surrounding policies and guidelines for students. While there appears to be guidance on consent with respect to accessing information or images from vulnerable communities, there is limited guidance on how to address the ethical use of information online. When planning, reviewing, and evaluating guidelines provided for students to develop their personal ePortfolios, ethical use of online information requires careful consideration. Such guidelines will prevent negative impacts on vulnerable communities and improve the quality of work produced by students and their understanding of digital ethics when creating ePortfolios.},
  keywords = {College Students,Confidentiality,Electronic Publishing,Employment Qualifications,Ethics,Higher Education,Information Security,No DOI found,Portfolios (Background Materials),Privacy}
}

@article{wilsonEffectiveProfessionalDevelopment2012,
  title = {Effective Professional Development for E-Learning: {{What}} Do the Managers Think?},
  author = {Wilson, Amy},
  year = {2012},
  month = nov,
  journal = {British Journal of Educational Technology},
  volume = {43},
  number = {6},
  pages = {892--900},
  issn = {1467-8535},
  doi = {10.1111/j.1467-8535.2011.01248.x},
  abstract = {Abstract Introducing new methods of teaching and learning requires an institutional approach to professional development in order to cater for the different levels and requirements of staff. The increase in e-learning use has prompted many institutions to adopt a whole organisation approach to professional development for lecturers. This paper proposes to answer three related questions. How do institutions of vocational education within New Zealand structure their institutional provision of e-learning professional development? What training or other development opportunities are provided by institutions? What do e-learning managers feel are the types of e-learning professional development that work best in terms of lecturer development and support? A literature review was completed and interviews were held with e-learning managers from 13 institutions. The data collected from the interviews were then analysed using a grounded analysis approach. The analysis process yielded concepts that were related to different types of professional development training, information and support. The analysis provided a structure of professional development. Furthermore, the efficiency of the types of e-learning professional development was analysed based on e-learning managers' perception and evaluation models. Professional development with opportunities for skill acquisition and collaboration was deemed the most effective. Practitioner Notes What is already known about this topic * {$\bullet$} Academic staff need new skills to teach e-learning. * {$\bullet$} There are different levels of professional development, which vary in duration and scope. * {$\bullet$} Professional development needs to be relevant for academic staff to benefit. What this paper adds * {$\bullet$} This paper discusses the types of professional development made available at tertiary institutions for staff new to e-learning. * {$\bullet$} This paper explains what e-learning managers feel is the most effective professional development format. * {$\bullet$} This paper analyses why the e-learning managers feel this format is the most effective. Implications for practice and/or policy * {$\bullet$} Managers will be better informed why particular types of professional development for e-learning work well. * {$\bullet$} Academic staff will be better informed about what professional development might best suit them. * {$\bullet$} Academic staff will be better informed about what managers feel about effective professional development and be able to have a greater role in the evaluation feedback cycle.}
}

@article{wilsonMakingMeasurementImportant2018,
  title = {Making {{Measurement Important}} for {{Education}}: {{The Crucial Role}} of {{Classroom Assessment}}},
  author = {Wilson, Mark},
  year = {2018},
  journal = {Educational Measurement: Issues and Practice},
  volume = {37},
  number = {1},
  pages = {5--20},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {0731-1745},
  doi = {10/gfz4bf},
  urldate = {2021-04-08},
  abstract = {Abstract This article is a written version of the Presidential Address1 I gave at the annual meeting of the National Council on Measurement in Education (NCME) in April 2017. It is a call to NCME members (and others who read this, of course) to rebalance their focus so that classroom assessments are seen as being at least as important as large-scale assessments for education (in fact, in my view, they are more important). The article reviews research literature about the effects of classroom assessment to establish its importance for education. Then, the roles of large-scale assessment are reviewed, and, in particular, it is noted how these can have negative results when the large-scale assessments are not well aligned with sound curriculum and instructional and assessment practices grounded in theories of learning. In the next two sections (a) the idea of a learning progression is described as a way to facilitate the coherence between classroom and large-scale assessment and (b) the idea of a ?roadmap? is described, being the assessment components of the learning progression. This is followed by a description of an example of such a roadmap, developed for the Assessing Data Modeling and Statistical Reasoning project using the BEAR Assessment System (BAS). Finally, a concluding discussion reviews the ways that the coherence between large-scale and classroom assessments can be achieved using the BAS, and hence make measurement more important for education.},
  keywords = {assessment roadmap,BEAR assessment system,classroom assessment,large-scale assessment,learning progression},
  file = {/Users/colin.madland/Zotero/storage/WCQRCWVX/wilsonMakingMeasurementImportant2018.pdf}
}

@book{wilsonPullingTogetherFoundations2019,
  title = {Pulling {{Together}}: {{Foundations Guide}}},
  author = {Wilson, Kory},
  year = {2019},
  urldate = {2019-03-28},
  file = {/Users/colin.madland/Zotero/storage/5KRF654I/first-nations.html}
}

@book{wilsonResearchCeremonyIndigenous2008,
  title = {Research Is Ceremony: {{Indigenous}} Research Methods},
  author = {Wilson, Shawn},
  year = {2008},
  publisher = {Fernwood Pub},
  address = {Black Point, N.S},
  isbn = {978-1-55266-281-6 1-55266-281-0},
  lccn = {GN380 .W554 2008},
  keywords = {Australia,Canada,Friends and associates,Indigenous peoples,Native peoples,Research Methodolog,Research Methodology,Research Moral and ethical aspects,Rites and ceremonies,Storytelling,Wilson Shawn},
  annotation = {OCLC: 231879767}
}

@article{wilsonTobaccoTiesRelationship2010,
  title = {Tobacco {{Ties}}: {{The Relationship}} of the {{Sacred}} to {{Research}}},
  author = {Wilson, Debby D. and Restoule, Jean-Paul},
  year = {2010},
  journal = {Canadian Journal of Native Education},
  volume = {33},
  number = {1},
  pages = {29--45, 156},
  abstract = {This article aspires to raise consciousness of the spiritual power of tobacco in a modern context and the responsibility of using tobacco ties as a research methodology. An ambitious project to outline traditional ways of doing research became a humbling teaching in the necessity of honouring tobacco and the spirit connections when tobacco is involved. We recount our journey in the project and what we learned about the meaning of tobacco to various First Nations (primarily those in northeastern Turtle Island), about doing research with Indigenous Elders, and about Indigenous research methodology. We reflect on the relationships activated when tobacco is part of a research methodology and share some of the teachings Elders shared with us about research, with a focus on their thoughts about tobacco offerings. It is not this work's intention to prescribe a proper set of steps or a how-to manual for using tobacco in social research. Rather, this article is an attempt to reflect on what it really means to honour the spirit in Aboriginal research, particularly as it is embodied in tobacco. PUBLICATION ABSTRACT]},
  isbn = {07101481},
  langid = {english},
  keywords = {Cultural values,Education,Native North Americans,Research methodology,Studies,Tobacco},
  annotation = {Copyright - Copyright University of Alberta, Faculty of Education 2010; Document feature - ; Last updated - 2011-10-17}
}

@article{winbergAmTryingPractice2016,
  title = {"{{I Am Trying}} to {{Practice Good Teaching}}": {{Reconceptualizing ePortfolios}} for {{Professional Development}} in {{Vocational Higher Education}}},
  author = {Winberg, Christine and Pallitt, Nicola},
  year = {2016},
  month = may,
  journal = {British Journal of Educational Technology},
  volume = {47},
  number = {3},
  pages = {543--553},
  publisher = {British Journal of Educational Technology},
  issn = {0007-1013},
  doi = {10.1111/bjet.12440},
  abstract = {Teaching portfolios have become increasingly important to university teachers. Portfolio requirements for the appointment or promotion of academic staff recognize that the assessment of teaching practice requires more depth and detail than a candidate's academic CV generally affords. The focus of this study is the electronic teaching portfolios, developed for purposes of promotion, in a vocational higher education context. Data were obtained from candidates' eportfolios, from precourse and end-of-course surveys, as well as from eportfolio assessors' formative and summative feedback. The analysis of the data reveals tensions arising from portfolio building in the particular context of vocational higher education. The nature of the vocational field impacts not only on teaching and learning practice, but on how academic staff choose to present their practice in an eportfolio. The paper argues that the constraints and enablements of context, including the disciplinary context, as well as the possibilities and limitations of agency, will strongly influence the purposes of eportfolio development and the extent to which university teachers can exercise agency in the creation of an eportfolio in a "high stakes" context. The findings can help university appointments and promotions committees, as well as educational developers, to better understand these enablements and constraints in order to inform policy and implementation.},
  keywords = {Context Effect,Data Analysis,Educational Policy,Educational Practices,Electronic Publishing,Feedback (Response),Formative Evaluation,Higher Education,Portfolios (Background Materials),Pretests Posttests,Professional Development,Program Implementation,Student Surveys,Summative Evaluation,Vocational Education}
}

@book{windchiefApplyingIndigenousResearch2019,
  title = {Applying {{Indigenous Research Methods}} : {{Storying}} with {{Peoples}} and {{Communities}}},
  shorttitle = {Applying {{Indigenous Research Methods}}},
  author = {Windchief, Sweeney and Pedro, Timothy San},
  year = {2019},
  month = jan,
  publisher = {Routledge},
  urldate = {2019-02-11},
  abstract = {Applying Indigenous Research Methods focuseson the question of "How" Indigenous Research Methodologies (IRMs)can be used and taught across Indigenous studies},
  isbn = {978-1-351-69005-8},
  langid = {english},
  annotation = {*},
  file = {/Users/colin.madland/Zotero/storage/BDZLTR9T/windchiefApplyingIndigenousResearch2019.pdf;/Users/colin.madland/Zotero/storage/2B8ADS9E/9781315169811.html}
}

@article{winitzky-stephensOpenEducationalResources2017,
  title = {Open {{Educational Resources}} and {{Student Course Outcomes}}: {{A Multilevel Analysis}}},
  shorttitle = {Open {{Educational Resources}} and {{Student Course Outcomes}}},
  author = {{Winitzky-Stephens}, Jessie R. and Pickavance, Jason},
  year = {2017},
  month = jun,
  journal = {The International Review of Research in Open and Distributed Learning},
  volume = {18},
  number = {4},
  issn = {1492-3831},
  urldate = {2018-07-07},
  copyright = {Copyright (c) 2017 Jessie R Winitzky-Stephens, Jason Pickavance},
  langid = {english},
  keywords = {multilevel modeling,open educational resources,post-secondary education,textbooks},
  file = {/Users/colin.madland/Zotero/storage/2CAHGQJK/winitzky-stephensOpenEducationalResources2017.pdf;/Users/colin.madland/Zotero/storage/V29CVZBW/4224.html}
}

@article{winstoneCharacterisingFeedbackCultures2022,
  title = {Characterising Feedback Cultures in Higher Education: An Analysis of Strategy Documents from 134 {{UK}} Universities},
  shorttitle = {Characterising Feedback Cultures in Higher Education},
  author = {Winstone, Naomi E.},
  year = {2022},
  month = feb,
  journal = {Higher Education},
  issn = {0018-1560, 1573-174X},
  doi = {10.1007/s10734-022-00818-8},
  urldate = {2022-06-26},
  abstract = {Abstract             Feedback can be framed as a one-way transmission of information driven by educators, or as a two-way process, in which students' agentic participation is critical to its~success. Despite calls for a shift away from the former framing towards the latter, transmission-focused models of feedback continue to dominate practice internationally. Approaches to feedback in any given setting are likely influenced by the dominant feedback culture. The present study aimed to characterise `feedback cultures' within higher education by systematically examining how feedback is framed in 134 UK universities' (a) educational strategies and (b) Teaching Excellence Framework (TEF) Provider statements. These documents serve to encapsulate each institution's views of excellence and best-practice; nevertheless, analysis of the documents revealed a stronger focus on the transmission of feedback comments than on supporting students' learning through feedback processes. Linguistically, students were positioned passively within the documents, as being on the receiving end of teachers' actions, rather than actively driving their own learning through feedback. These findings inform a framework for conceptualising feedback cultures in higher education, which positions approaches to feedback design, feedback processes and the evaluation and development of feedback on a continuum from transmission-focused to learning-focused. It is argued that strategy documents shape practice in subtle ways; in order to shift towards learning-focused feedback cultures, consideration must be given to how students' roles and responsibilities are positioned in both policy and practice.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/7YY3JXLC/winstoneCharacterisingFeedbackCultures2022.pdf}
}

@article{winstoneCheckGradeLog2021,
  title = {``{{Check}} the Grade, Log out'': Students' Engagement with Feedback in Learning Management Systems},
  shorttitle = {``{{Check}} the Grade, Log Out''},
  author = {Winstone, Naomi and Bourne, Jessica and Medland, Emma and Niculescu, Irina and Rees, Roger},
  year = {2021},
  month = may,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {46},
  number = {4},
  pages = {631--643},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2020.1787331},
  urldate = {2022-06-26},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/MPKAAZLU/winstoneCheckGradeLog2021.pdf}
}

@book{winstoneDesigningEffectiveFeedback2019,
  title = {Designing {{Effective Feedback Processes}} in {{Higher Education}}: {{A Learning-Focused Approach}}},
  shorttitle = {Designing {{Effective Feedback Processes}} in {{Higher Education}}},
  author = {Winstone, Naomi and Carless, David},
  year = {2019},
  month = jun,
  edition = {1},
  publisher = {Routledge},
  doi = {10.4324/9781351115940},
  urldate = {2022-06-26},
  isbn = {978-1-351-11594-0},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/KPNLHKF3/winstoneDesigningEffectiveFeedback2019.pdf}
}

@incollection{winstoneDevelopingStudentsProactive2019,
  title = {Developing Students' Proactive Engagement with Feedback},
  booktitle = {Innovative {{Assessment}} in {{Higher Education}}},
  author = {Winstone, Naomi E. and Nash, Robert A.},
  editor = {Bryan, Cordelia and Clegg, Karen},
  year = {2019},
  month = apr,
  edition = {1},
  pages = {129--138},
  publisher = {Routledge},
  address = {Second Edition. {\textbar} New York : Routledge, 2019. {\textbar} ``[First edition published by Routledge 2006]''---T.p. verso.},
  doi = {10.4324/9780429506857-12},
  urldate = {2022-06-26},
  isbn = {978-0-429-50685-7},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/ADQ4H5NU/winstoneDevelopingStudentsProactive2019.pdf}
}

@article{winstoneExploringCulturesFeedback2019,
  title = {Exploring Cultures of Feedback Practice: The Adoption of Learning-Focused Feedback Practices in the {{UK}} and {{Australia}}},
  author = {Winstone, Naomi and Boud, David},
  year = {2019},
  journal = {Higher education research and development},
  volume = {38},
  number = {2},
  pages = {411--425},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0729-4360},
  doi = {10.1080/07294360.2018.1532985},
  abstract = {In recent years, there have been calls in the literature for the dominant model of feedback to shift away from the transmission of comments from marker to student, towards a more dialogic focus on student engagement and the impact of feedback on student learning. In the present study, we sought to gain insight into the extent to which such a shift is evident in practice, and how practice is shaped by national and disciplinary cultures. A total of 688 higher education staff from the UK and Australia completed a survey, in which we collected data pertaining to key influences on the design of feedback, and the extent to which emphasis is placed on student action following feedback. Our respondents reported that formal learning and development opportunities have less influence on feedback practice than informal learning and development, and prior experience. Australian respondents placed greater emphasis on student action following feedback than their counterparts in the UK, and were also more likely than UK respondents to judge the effectiveness of feedback by seeking evidence of its impact on student learning. We contextualise these findings within the context of disciplinary and career stage differences in our data. By demonstrating international differences in the adoption of learning-focused feedback practices, the findings indicate directions for the advancement of feedback research and practice in contemporary higher education.},
  keywords = {assessment cultures,assessment design,College Faculty,College Students,Cross Cultural Studies,cross-country comparison,Education & Educational Research,Educational practices,Feedback,Feedback (Response),Foreign Countries,Formative assessment,Formative Evaluation,Higher education,Informal Education,International comparisons,Learner Engagement,learning effects,Social Sciences,Student assessment,Student engagement,Surveys,Teacher Attitudes,Teacher Student Relationship,Teaching Methods,University students},
  file = {/Users/colin.madland/Zotero/storage/SA2NX9MU/winstoneExploringCulturesFeedback2019.pdf}
}

@article{winstoneNeedDisentangleAssessment2022,
  title = {The Need to Disentangle Assessment and Feedback in Higher Education},
  author = {Winstone, Naomi E. and Boud, David},
  year = {2022},
  month = mar,
  journal = {Studies in Higher Education},
  volume = {47},
  number = {3},
  pages = {656--667},
  issn = {0307-5079, 1470-174X},
  doi = {10.1080/03075079.2020.1779687},
  urldate = {2022-06-25},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/LZUJIBAQ/winstoneNeedDisentangleAssessment2022.pdf}
}

@article{winterBenefitUtilizingBrainBased2019,
  title = {The {{Benefit}} of {{Utilizing Brain-Based Learning}} in {{Higher Education Online Environments}}},
  author = {Winter, Renee M.},
  year = {2019},
  journal = {Journal of Instructional Research},
  volume = {8},
  number = {1},
  pages = {82--91},
  issn = {ISSN-2159-0281},
  doi = {10/gmbvz8},
  abstract = {Higher education has experienced a significant transformation from traditional face-to-face instruction to online instruction. The purpose of this quantitative causal-comparative study was to determine to what extent postsecondary online faculty utilized brain-based learning techniques as part of their academic practices in the online asynchronous learning environment and to assess differences in the use of these techniques between online full-time and online adjunct faculty employed by two public universities and one private university located in the Southwest region of the United States. The theoretical framework of Hart's (1983) brain-based learning theory (BBLT) informed this study. The sample consisted of 539 accepted and completed surveys. The participants completed 55 questions based on brain-based learning. Quantitative data were collected using Klinek's (2009) questionnaire about brain-based learning knowledge, beliefs, and practices. The data from the questionnaire measured the online faculty's knowledge, beliefs, and practices of brain-based learning techniques. The data were analyzed using descriptive information about the sample computing frequencies of the variables. Cronbach's alpha reliabilities were conducted to complete the descriptive statistics for the first research question. The statistical analysis used for research question two and three was Multivariate Analysis of Variance (MANOVA) using a 2{\texttimes}2 factorial design to test the hypotheses. The researcher found that there was a significant difference between the BBLT practices of the online faculty from public (M = 3.45) and private universities (M = 3.28), F (1, 294) = 1.62, p = 0.004, [eta]2 = 0.044. The study revealed that there is a lack of knowledge about BBLT supporting the need for professional development and training.},
  langid = {english},
  keywords = {Adjunct Faculty,Age Differences,Asynchronous Communication,Brain,Brain Hemisphere Functions,College Faculty,Comparative Analysis,Educational Benefits,Faculty Development,Institutional Characteristics,Knowledge Level,Online Courses,Private Colleges,Reliability,State Universities,Teacher Attitudes,Teacher Characteristics,Teaching Methods}
}

@article{wintersCanWeAvoid2020,
  title = {Can We Avoid Digital Structural Violence in Future Learning Systems?},
  author = {Winters, Niall and Eynon, Rebecca and Geniets, Anne and Robson, James and Kahn, Ken},
  year = {2020},
  journal = {Learning, Media and Technology},
  volume = {45},
  number = {1},
  pages = {17--30},
  publisher = {Routledge},
  issn = {1743-9884},
  doi = {10/ghqq92}
}

@article{wojtowiczDescriptiveGeometryTime2020,
  title = {Descriptive {{Geometry}} in the {{Time}} of {{COVID-19}}: {{Preliminary Assessment}} of {{Distance Education}} during {{Pandemic Social Isolation}}},
  author = {Wojtowicz, Agnieszka and Wojtowicz, Barbara and Kopec, Krzysztof},
  year = {2020},
  journal = {Advances in Engineering Education},
  volume = {8},
  number = {4},
  issn = {EISSN-1941-1766},
  abstract = {The pandemic forced a change in the teaching of descriptive geometry, a basic subject of many engineering fields. To conduct classes during COVID-19, the following resources were used: the ELF platform, MS Teams, SketchUp, AutoCAD, email. It was decided to prepare the electronic textbook along with geometric problems to be solved, supplemented by on-line consultations with students. Despite difficulties (technological, psychological), the results obtained by students during the pandemic were very good. Although the average grade during distance learning was higher than in the case of traditional education, students reported a clear need for direct contact with the teacher.},
  langid = {english},
  keywords = {College Students,Computer Assisted Design,COVID-19,Distance Education,Electronic Learning,Electronic Mail,Electronic Publishing,Engineering Education,Foreign Countries,Geometric Concepts,Grades (Scholastic),Mathematics Instruction,No DOI found,Online Courses,Outcomes of Education,Pandemics,Teacher Student Relationship,Textbooks,Videoconferencing}
}

@article{woldeab21stCenturyAssessment2019,
  title = {21st {{Century Assessment}}: {{Online Proctoring}}, {{Test Anxiety}}, and {{Student Performance}}},
  author = {Woldeab, Daniel and Brothen, Thomas},
  year = {2019},
  month = jan,
  journal = {International Journal of E-Learning \& Distance Education},
  volume = {34},
  number = {1},
  publisher = {International Journal of E-Learning \& Distance Education},
  issn = {2292-8588},
  abstract = {It is safe to say that online leaning has found a permanent place in higher education. Conventional higher education institutions are also gradually embracing it across the United States. As online learning surfaces as the new model of contemporary education both in the United States and worldwide, ensuring exam integrity in the online environment is becoming a major challenge to many higher education institutions. To meet this challenge, many of these institutions are outsourcing the examination aspect of their education to online proctoring service providers. The present study, which was conducted on a total of 631 students, assesses the effect of online proctored exams on student test anxiety and exam performance. This study shows that high trait test anxiety results in lower exam scores and that this is especially true for those students with high text anxiety taking exams in an online proctored setting.},
  keywords = {ACT Assessment,College Entrance Examinations,Computer Assisted Testing,Grade Point Average,No DOI found,Outsourcing,Performance Factors,Personality Traits,Photography,Scores,Student Attitudes,Supervision,Test Anxiety,Undergraduate Students,Video Technology},
  file = {/Users/colin.madland/Zotero/storage/M2UF7YD3/woldeab21stCenturyAssessment2019.pdf}
}

@article{wolfChapterUseTheir1991,
  title = {Chapter 2: {{To Use Their Minds Well}}: {{Investigating New Forms}} of {{Student Assessment}}},
  shorttitle = {Chapter 2},
  author = {Wolf, Dennie and Bixby, Janet and Glenn, John and Gardner, Howard},
  year = {1991},
  month = jan,
  journal = {Review of Research in Education},
  volume = {17},
  number = {1},
  pages = {31--74},
  issn = {0091-732X, 1935-1038},
  doi = {10.3102/0091732X017001031},
  urldate = {2022-07-24},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/SDN333I3/wolfChapterUseTheir1991.pdf}
}

@article{wolmingConceptValidityTheory2010,
  title = {The Concept of Validity in Theory and Practice},
  author = {Wolming, Simon and Wikstr{\"o}m, Christina},
  year = {2010},
  month = may,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {17},
  number = {2},
  pages = {117--132},
  publisher = {Routledge},
  issn = {0969-594X},
  doi = {10.1080/09695941003693856},
  abstract = {The concept of validity, as described in the literature, has changed over time to become a broad and rather complex issue. The purpose of this paper is to investigate if practice has followed theory, or if there is a gap between validity in theory and validity in practice. It compares the theoretical development of the concept of validity with the methodology adopted in validity studies over time. Important phases in the history of validity, and also common arguments for and against traditional and modern validity perspectives, are presented and discussed. Thereafter, three Swedish research projects aiming to validate instruments used for selection to higher education are described. The idea is to use these projects as examples of contemporary practice, and to compare their designs, research questions and outcomes with how validity was theoretically described during their specific period of time. The conclusions from these comparisons are that practices seem to have followed theory when it comes to how the validity research programmes have been designed, but not when it comes to how they then were carried out in practice. This gap between theory and practice seems to have increased with the introduction of broader and more modern validity perspectives. The scope of the research is more extensive but results are fragmented and there is no evidence of a ?unified? validity argument, which has been one of the central aspects in modern validity theory. This supports the arguments that validity theory is difficult to put into practice and that there is a need for guidance on how to prioritise validity questions and interpret validity evidence.},
  file = {/Users/colin.madland/Zotero/storage/IHHRCGJG/wolmingConceptValidityTheory2010a.pdf}
}

@article{wongvorachanImprovingStudentFeedback2022,
  title = {Improving {{Student Feedback Literacy}} in E-{{Assessments}}: {{A Framework}} for the {{Higher Education Context}}},
  shorttitle = {Improving {{Student Feedback Literacy}} in E-{{Assessments}}},
  author = {Wongvorachan, Tarid and Bulut, Okan and Tsai, Yi-Shan and Lindner, Marlit A.},
  year = {2022},
  month = dec,
  journal = {Trends in Higher Education},
  volume = {1},
  number = {1},
  pages = {16--29},
  issn = {2813-4346},
  doi = {10.3390/higheredu1010002},
  urldate = {2022-12-07},
  abstract = {For students, feedback received from their instructors can make a big difference in their learning by translating their assessment performance into future learning opportunities. To date, researchers have proposed various feedback literacy frameworks, which concern one's ability to interpret and use feedback for their learning, to promote students' feedback engagement by repositioning them as active participants in the learning process. However, the current feedback literacy frameworks have not been adapted to digital or e-Assessment settings despite the increasing use of e-Assessments (e.g., computer-based tests, intelligent tutoring systems) in practice. To address this gap, this conceptual paper introduces a feedback literacy model in the context of e-Assessments to present an intersection between e-Assessment features and the ecological model of feedback literacy for more effective feedback practices in digital learning environments. This paper could serve as a guideline to improve feedback effectiveness and its perceived value in e-Assessment to enhance student feedback literacy.},
  langid = {english}
}

@article{wooBiasFairnessValidity2023,
  title = {Bias, {{Fairness}}, and {{Validity}} in {{Graduate-School Admissions}}: {{A Psychometric Perspective}}},
  shorttitle = {Bias, {{Fairness}}, and {{Validity}} in {{Graduate-School Admissions}}},
  author = {Woo, Sang Eun and LeBreton, James M. and Keith, Melissa G. and Tay, Louis},
  year = {2023},
  journal = {Perspectives on Psychological Science},
  volume = {18},
  number = {1},
  pages = {3--31},
  issn = {1745-6916, 1745-6924},
  doi = {10.1177/17456916211055374},
  urldate = {2023-09-05},
  abstract = {As many schools and departments are considering the removal of the Graduate Record Examination (GRE) from their graduate-school admission processes to enhance equity and diversity in higher education, controversies arise. From a psychometric perspective, we see a critical need for clarifying the meanings of measurement ``bias'' and ``fairness'' to create common ground for constructive discussions within the field of psychology, higher education, and beyond. We critically evaluate six major sources of information that are widely used to help inform graduate-school admissions decisions: grade point average, personal statements, resumes/curriculum vitae, letters of recommendation, interviews, and GRE. We review empirical research evidence available to date on the validity, bias, and fairness issues associated with each of these admission measures and identify potential issues that have been overlooked in the literature. We conclude by suggesting several directions for practical steps to improve the current admissions decisions and highlighting areas in which future research would be beneficial.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/V69YIU5V/wooBiasFairnessValidity2023.pdf}
}

@article{woodDialogicTechnologymediatedModel2021,
  title = {A Dialogic Technology-Mediated Model of Feedback Uptake and Literacy},
  author = {Wood, James},
  year = {2021},
  journal = {Assessment and evaluation in higher education},
  volume = {46},
  number = {8},
  pages = {1173--1190},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0260-2938},
  doi = {10.1080/02602938.2020.1852174},
  abstract = {Despite the importance of feedback uptake in higher education, there is still much to be learned about supporting it. Recent perspectives hold that guiding learners through feedback uptake-oriented activities may also help them to develop feedback literacy. However, due to the acceleration of digitisation trends in higher education, there is an increasing need to explore feedback uptake and literacy development exploiting opportunities offered by digital environments. This need constitutes a significant gap that is of immediate importance to practitioners teaching online and will also be crucial in the post-COVID-19 context in which the use of blended and online learning is only expected to increase. This conceptual article draws on a synthesis of existing feedback uptake, formative assessment and technology literature to offer a technology-mediated dialogic model of feedback uptake and literacy. Focused on how technological mediation can enrich opportunities for co-regulation of the processes involved in feedback uptake, the model is intended for use in designing classroom feedback practices that can be embedded in standard curricula. The model serves to inform the discussion of feedback uptake and the nascent discussion of teacher feedback literacy in the digital settings in which feedback practices in higher education now frequently take place.},
  keywords = {Curriculum development,digital feedback literacy,Education & Educational Research,Feedback,feedback uptake,Higher education,Learning,Literacy,Mediation,Social Sciences,Technology-mediated dialogic feedback},
  file = {/Users/colin.madland/Zotero/storage/XDNXVU38/woodDialogicTechnologymediatedModel2021.pdf}
}

@article{woodsBuildingYourOwn,
  title = {Building Your Own {{PLN}}: Seeking New Insights and Ideas? {{Expand}} Your Personal Learning Network},
  author = {Woods, Bianca},
  journal = {T+D},
  volume = {67},
  number = {11},
  urldate = {2021-12-23},
  keywords = {No DOI found},
  file = {/Users/colin.madland/Zotero/storage/8YB56GUS/i.html}
}

@article{wrightFrameworkResearchEducation2018,
  title = {A {{Framework}} for {{Research}} on {{Education With Technology}}},
  author = {Wright, Daniel B.},
  year = {2018},
  month = apr,
  journal = {Frontiers in Education},
  volume = {3},
  pages = {21},
  issn = {2504-284X},
  doi = {10.3389/feduc.2018.00021},
  urldate = {2022-07-11},
  file = {/Users/colin.madland/Zotero/storage/B4QSJKRT/wrightFrameworkResearchEducation2018.pdf}
}

@book{wrightInternationalEncyclopediaSocial2015,
  title = {International Encyclopedia of the Social \& Behavioral Sciences},
  editor = {Wright, James D.},
  year = {2015},
  edition = {Second edition},
  publisher = {Elsevier},
  address = {Amsterdam, Netherlands},
  isbn = {978-0-08-097086-8 978-0-08-097087-5},
  lccn = {ELECTRONIC},
  keywords = {Electronic books,Encyclopedias,Psychology,Social sciences,Sociology}
}

@book{wyatt-smithDesigningAssessmentQuality2014,
  title = {Designing {{Assessment}} for {{Quality Learning}}},
  editor = {{Wyatt-Smith}, Claire and Klenowski, Valentina and Colbert, Peta},
  year = {2014},
  series = {The {{Enabling Power}} of {{Assessment}}},
  volume = {1},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-94-007-5902-2},
  urldate = {2022-05-07},
  isbn = {978-94-007-5901-5 978-94-007-5902-2},
  file = {/Users/colin.madland/Zotero/storage/2LZZ2VCE/wyatt-smithDesigningAssessmentQuality2014.pdf}
}

@book{wyseBERASAGEHandbook2017,
  title = {The {{BERA}}/{{SAGE Handbook}} of {{Educational Research}}: {{Two Volume Set}}},
  shorttitle = {The {{BERA}}/{{SAGE Handbook}} of {{Educational Research}}},
  author = {Wyse, Dominic and Selwyn, Neil and Smith, Emma and Suter, Larry},
  year = {2017},
  publisher = {SAGE Publications Ltd},
  address = {1 Oliver's Yard,~55 City Road~London~EC1Y 1SP},
  doi = {10.4135/9781473983953},
  urldate = {2021-07-28},
  isbn = {978-1-4739-1891-7 978-1-4739-8395-3}
}

@article{xianEffectivenessDynamicAssessment2020,
  title = {The {{Effectiveness}} of {{Dynamic Assessment}} in {{Linguistic Accuracy}} in {{EFL Writing}}: {{An Investigation Assisted}} by {{Online Scoring Systems}}},
  author = {Xian, Liuyan},
  year = {2020},
  journal = {Language Teaching Research Quarterly},
  volume = {18},
  pages = {98--114},
  issn = {EISSN-2667-6753},
  abstract = {From the perspective of Vygotsky's Sociocultural Theory and Zone of Proximal Development (ZPD), dynamic assessment (DA) highlights the role of mediation in the learning process by unveiling the distance between actual learning proficiency and potential learning development. DA is more helpful in fostering students' ability to solve problems independently and in facilitating future tutoring. However, due to its large consumption in time, a vast majority of studies on DA target at a limited scale. To remove this limitation from the implementation of DA, this paper attempts to apply interventionist DA with the support of online scoring systems in EFL writing. Targeting at 44 Chinese L2 English learners, this experimental research mainly adopts quantitative methods with qualitative methods as a supplement to explore their improvement in linguistic accuracy in English writing. It is found that both non-dynamic assessment (NDA) and DA helped participants to improve their accuracy, but only in the DA group observed a remarkable statistical significance. That is, DA is more effective in promoting learning outcomes. Besides, ZPD is predictive for future learning achievement.},
  langid = {english},
  keywords = {Accuracy,Comparative Analysis,Computer Software,English (Second Language),Evaluation Methods,Foreign Countries,Instructional Effectiveness,Intervention,Language Proficiency,Learning Processes,Learning Theories,Majors (Students),No DOI found,Online Systems,Outcomes of Education,Problem Solving,Scoring,Second Language Instruction,Second Language Learning,Sociocultural Patterns,Undergraduate Students,Writing Evaluation,Writing Instruction}
}

@article{xiaoFlippedAnatomyClassroom,
  title = {Flipped Anatomy Classroom Integrating Multimodal Digital Resources Shows Positive Influence upon Students' Experience and Learning Performance},
  author = {Xiao, {\relax JH} and Adnan, S},
  journal = {ANATOMICAL SCIENCES EDUCATION},
  issn = {1935-9772},
  doi = {10.1002/ase.2207},
  abstract = {Anatomy is shifting toward a greater focus on adopting digital delivery. To advance digital and authentic learning in anatomy, a flipped classroom model integrating multimodal digital resources and a multimedia group assignment was designed and implemented for first-year neuroanatomy and third-year regional anatomy curricula. A five-point Likert scale learning and teaching survey was conducted for a total of 145 undergraduate health science students to evaluate students' perception of the flipped classroom model and digital resources. This study revealed that over two-thirds of participants strongly agreed or agreed that the flipped classroom model helped their independent learning and understanding of difficult anatomy concepts. The response showed students consistently enjoyed their experience of using multimodal digital anatomy resources. Both first-year (75\%) and third-year (88\%) students strongly agreed or agreed that digital tools are very valuable and interactive for studying anatomy. Most students strongly agreed or agreed that digital anatomy tools increased their learning experience (similar to 80\%) and confidence ({$>$} 70\%). The third-year students rated the value of digital anatomy tools significantly higher than the first-year students (p = 0.0038). A taxonomy-based assessment strategy revealed that the third-year students, but not the first-year, demonstrated improved performance in assessments relating to clinical application (p = 0.045). In summary, a flipped anatomy classroom integrating multimodal digital approaches exerted positive impact upon learning experience of both junior and senior students, the latter of whom demonstrated improved learning performance. This study extends the pedagogy innovation of flipped classroom teaching, which will advance future anatomy curriculum development, pertinent to post-pandemic education.},
  langid = {english},
  keywords = {augmented reality,BLOOMS TAXONOMY,COVID-19,digital anatomy,flipped classroom,gross anatomy education,MEDICAL-EDUCATION,neuroanatomy,REALITY,regional anatomy,SCIENCES,taxonomy,TRANSITION,undergraduate education,videos,virtual reality},
  file = {/Users/colin.madland/Zotero/storage/46I98HW2/xiaoFlippedAnatomyClassroom.pdf}
}

@article{xiaoGuidanceConductingSystematic2019,
  title = {Guidance on {{Conducting}} a {{Systematic Literature Review}}},
  author = {Xiao, Yu and Watson, Maria},
  year = {2019},
  journal = {Journal of Planning Education and Research},
  volume = {39},
  number = {1},
  pages = {93--112},
  issn = {0739-456X, 1552-6577},
  doi = {10.1177/0739456X17723971},
  urldate = {2022-11-26},
  abstract = {Literature reviews establish the foundation of academic inquires. However, in the planning field, we lack rigorous systematic reviews. In this article, through a systematic search on the methodology of literature review, we categorize a typology of literature reviews, discuss steps in conducting a systematic literature review, and provide suggestions on how to enhance rigor in literature reviews in planning education and research.},
  langid = {english}
}

@article{xiaoLearnerAgencyLanguage2014,
  title = {Learner Agency in Language Learning: The Story of a Distance Learner of {{EFL}} in {{China}}},
  author = {Xiao, Junhong},
  year = {2014},
  journal = {Distance Education},
  volume = {35},
  pages = {4--17},
  issn = {0158-7919},
  doi = {10.1080/01587919.2014.891429},
  abstract = {Learner agency plays a key role in self-regulated learning. Yet, there is a paucity of research into its role in the distance learning context. Using reflective narratives written by a distance learner of English in China, this longitudinal case study aims to investigate the ways in which learner agency mediates the language learning in the distance mode. Findings from the study suggest that agency has a major impact on learners? self-efficacy, identity, motivation, and metacognition?four constructs which are instrumental in determining language learning success, in particular in the distance learning context. Analysis of the data indicates that positive changes in these four constructs, in turn, lead to further agentic engagement, hence forming a virtuous circle of mutual enhancement. Implications are discussed in relation to fostering distance learners? goal awareness, enhancing their self-efficacy, maintaining their motivation, and encouraging metacognitive efforts.}
}

@book{xieMarkdownCookbook,
  title = {R {{Markdown Cookbook}}},
  author = {Xie, Yihui, Michael Harper},
  urldate = {2019-11-15},
  abstract = {Examples, tips, and tricks of using R Markdown.},
  file = {/Users/colin.madland/Zotero/storage/HELRKV7H/rmarkdown-cookbook.html}
}

@article{xuAssessmentLearningFeasible2019,
  title = {Is {{Assessment}} for {{Learning Feasible}} in {{Large Classes}}? {{Challenges}} and {{Coping Strategies}} from {{Three Case Studies}}},
  author = {Xu, Yueting and Harfitt, Gary},
  year = {2019},
  month = jan,
  journal = {Asia-Pacific Journal of Teacher Education},
  volume = {47},
  number = {5},
  pages = {472--486},
  publisher = {Asia-Pacific Journal of Teacher Education},
  issn = {1359-866X},
  doi = {10.1080/1359866X.2018.1555790},
  abstract = {While assessment for learning (AfL) has been widely used in college English classrooms in China where teachers usually teach large classes, how AfL is implemented in the large-class higher education (HE) context is relatively underexplored. To address this gap, this study explores some of the challenges presented by large classes and the teachers' coping strategies through case studies of three university English teachers' AfL practices. Challenges are identified surrounding how the teachers dealt with (a) inadequate attention to individual students, (b) reduced opportunities for individualised feedback, (c) overwhelming marking responsibilities, and (d) involving students in assessment, with strategies of putting students in groups, matching names with faces, conducting teacher-student conferences, utilising technology to facilitate feedback processes, enabling peer feedback, and transforming students from assessees to assessors. Findings are framed around useful forms of AfL in large classes and the feasibility of AfL in terms of compromises between teacher agency and their temporal and contextual conditions. The paper concludes with implications for teacher assessment training, teacher education and policy-making.},
  keywords = {Case Studies,China,Class Size,College English,College Faculty,College Students,Coping,English (Second Language),English Teachers,Feedback (Response),Foreign Countries,Formative Evaluation,Large Group Instruction,Second Language Learning}
}

@article{xuInteractiveSelfReportingBehavioural2022,
  title = {Interactive {{Self-Reporting}} as {{Behavioural Cue Elicitor}} for {{Online-Classroom Assessment}}},
  author = {Xu, Hao},
  year = {2022},
  journal = {Behavioral sciences},
  volume = {12},
  number = {7},
  pages = {232},
  publisher = {Mdpi},
  address = {BASEL},
  issn = {2076-328X},
  doi = {10.3390/bs12070232},
  abstract = {How teachers should elicit and draw on behavioural cues for online-classroom assessment is of much interest to both researchers and practising teachers. Aiming to explore how to enhance interactive self-reporting as a behavioural cue elicitor for online-classroom assessment, this study adopted a large-scale questionnaire survey to investigate the effects of the intensity of interaction in interactive self-reporting and teachers' professional experience on the quality of assessment data in online teaching. Results showed that only the intensity of teacher's follow-up interaction regarding interactive self-reporting had a significant impact on the quality of the assessment data. Specifically, as a behavioural cue elicitor, interactive self-reporting may be best utilised when interaction of a moderate intensity is employed by the teacher following students' self-report. The accuracy and efficiency of interactive self-reporting as a means to obtain assessment data in online teaching can only, thus, be best synergised. Otherwise, the accuracy and efficiency may be reduced to a wax-and-wane relationship, i.e., each one increases at the expense of the other.},
  keywords = {assessment data,behavioural cues,classroom assessment,Classrooms,Communication,Design,Distance learning,English as a second language,Grammar,intensity of interaction,interactive self-reporting,Learning disabilities,Online instruction,online teaching,Psychology,Psychology Multidisciplinary,Questionnaires,Social Sciences,Students,Teaching},
  file = {/Users/colin.madland/Zotero/storage/AIXHUUMS/xuInteractiveSelfReportingBehavioural2022.pdf}
}

@article{xuMultiplechoiceQuestionsTips2016,
  title = {Multiple-Choice Questions: {{Tips}} for Optimizing Assessment in-Seat and Online},
  author = {Xu, Xiaomeng and Kauer, Sierra and Tupy, Samantha},
  year = {2016},
  month = jun,
  journal = {Scholarship of Teaching and Learning in Psychology},
  volume = {2},
  number = {2},
  pages = {147--158},
  publisher = {Educational Publishing Foundation},
  issn = {2332-2101},
  doi = {10.1037/stl0000062},
  abstract = {Multiple-choice questions are frequently used in college classrooms as part of student assessment. While multiple-choice assessments (compared to other formats such as constructed response) seem to be the preferred method of testing by instructors and students, their effectiveness in assessing comprehension in college courses is sometimes called into question. Research has shown that there are ways to optimize the construction and use of multiple-choice testing to benefit college classroom instruction and assessment, student learning, and performance, and to more efficiently utilize instructor's time and energy. This teacher-ready research review provides an overview of the research on utilizing multiple-choice questions as well as some tips on using, writing, and administering multiple-choice questions during assessments. We also summarize the benefits and potential issues with using multiple-choice questions including concerns about cheating, ways to detect and deter cheating, and testing issues and strategies unique to online formats. We hope that this short review will be helpful to instructors as they prepare courses and assessments and further encourage the use of empirical data in pedagogy related decision-making. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {assessment,Classrooms,College Environment,Distance Education,exams,Measurement,Multiple Choice (Testing Method),multiple-choice,pedagogy,testing}
}

@article{xuTeacherAssessmentLiteracy2016,
  ids = {5ece38fb684495fe674c84504413d269c420fe8e},
  title = {Teacher Assessment Literacy in Practice: {{A}} Reconceptualization},
  author = {Xu, Yueting and Brown, Gavin T.L.},
  year = {2016},
  journal = {Teaching and Teacher Education},
  volume = {58},
  pages = {149--162},
  issn = {0742-051X},
  doi = {10/f8txgm},
  abstract = {This paper aims to reconceptualize teacher assessment literacy (AL) by connecting two fields of research: educational assessment and teacher education. It begins with a scoping review of AL studies. By synthesizing and analyzing 100 studies on teacher AL, a new conceptual framework of teacher assessment literacy in practice (TALiP) is proposed. This framework is illustrated by a discussion of the various components of teacher AL and their interrelationships. This paper concludes with the theoretical contributions of the framework, a working definition of TALiP, and implications for policy and practice of assessment education.},
  keywords = {Reconceptualization,Teacher assessment literacy,Teacher education},
  file = {/Users/colin.madland/Zotero/storage/IF2SH5KA/xuTeacherAssessmentLiteracy2016.pdf}
}

@book{yanAssessmentLearningMaximising2021,
  title = {Assessment as {{Learning}}: {{Maximising Opportunities}} for {{Student Learning}} and {{Achievement}}},
  shorttitle = {Assessment as {{Learning}}},
  author = {Yan, Zi and Yang, Lan},
  year = {2021},
  month = jun,
  edition = {1},
  publisher = {Routledge},
  address = {London},
  doi = {10.4324/9781003052081},
  urldate = {2023-03-20},
  isbn = {978-1-003-05208-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/QZB59W4R/yanAssessmentLearningMaximising2021.pdf}
}

@incollection{yanConceptualisingAssessmentaslearning2021,
  title = {Conceptualising Assessment-as-Learning},
  booktitle = {Assessment as {{Learning}}},
  author = {Yan, Zi and Boud, David},
  editor = {Yan, Zi and Yang, Lan},
  year = {2021},
  month = jun,
  edition = {1},
  pages = {11--24},
  publisher = {Routledge},
  address = {London},
  doi = {10.4324/9781003052081-2},
  urldate = {2023-03-20},
  isbn = {978-1-003-05208-1},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/2TAEYDQ3/yanConceptualisingAssessmentaslearning2021.pdf}
}

@book{yanevaAdvancingNaturalLanguage2023,
  title = {Advancing {{Natural Language Processing}} in {{Educational Assessment}}},
  author = {Yaneva, Victoria and Von Davier, Matthias},
  year = {2023},
  month = may,
  edition = {1},
  publisher = {Routledge},
  address = {New York},
  doi = {10.4324/9781003278658},
  urldate = {2023-09-23},
  isbn = {978-1-003-27865-8},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/2NZV9NN2/yanevaAdvancingNaturalLanguage2023.pdf}
}

@article{yangConceptionsApproachesLearning2010,
  title = {Conceptions of and Approaches to Learning through Online Peer Assessment},
  author = {Yang, Yu-Fang and Tsai, Chin-Chung},
  year = {2010},
  journal = {Learning and Instruction},
  volume = {20},
  number = {1},
  pages = {72--83},
  publisher = {Elsevier Ltd},
  address = {OXFORD},
  issn = {0959-4752},
  doi = {10/bv256h},
  abstract = {The present study investigated junior college students' conceptions of and approaches to learning via online peer assessment (PA) using a phenomenographic approach. Participants were 163 college students. Students were asked to accomplish a given learning task via an online PA system. Of the participants, 62 were interviewed after the activity. The interviews revealed hierarchically related and qualitatively different categories of conceptions and approaches to learning via online PA. The main and achieved levels of conceptions of and approaches to learning were determined. The results showed that, within each level, conceptions emphasizing a fragmented and cohesive learning tended to be associated with approaches focusing on surface and deep learning, respectively. In addition, students with cohesive learning conceptions and deep learning approaches were likely to make greater progress in the early stages of online PA activity. The present study finally found that approaches to learning via online PA were less related to the learning outcomes than conceptions of learning. (Contains 7 tables.);The present study investigated junior college students' conceptions of and approaches to learning via online peer assessment (PA) using a phenomenographic approach. Participants were 163 college students. Students were asked to accomplish a given learning task via an online PA system. Of the participants, 62 were interviewed after the activity. The interviews revealed hierarchically related and qualitatively different categories of conceptions and approaches to learning via online PA. The main and achieved levels of conceptions of and approaches to learning were determined. The results showed that, within each level, conceptions emphasizing a fragmented and cohesive learning tended to be associated with approaches focusing on surface and deep learning, respectively. In addition, students with cohesive learning conceptions and deep learning approaches were likely to make greater progress in the early stages of online PA activity. The present study finally found that approaches to learning via online PA were less related to the learning outcomes than conceptions of learning.;The present study investigated junior college students' conceptions of and approaches to learning via online peer assessment (PA) using a phenomenographic approach. Participants were 163 college students. Students were asked to accomplish a given learning task via an online PA system. Of the participants, 62 were interviewed after the activity. The interviews revealed hierarchically related and qualitatively different categories of conceptions and approaches to learning via online PA. The main and achieved levels of conceptions of and approaches to learning were determined. The results showed that, within each level, conceptions emphasizing a fragmented and cohesive learning tended to be associated with approaches focusing on surface and deep learning, respectively. In addition, students with cohesive learning conceptions and deep learning approaches were likely to make greater progress in the early stages of online PA activity. The present study finally found that approaches to learning via online PA were less related to the learning outcomes than conceptions of learning. (C) 2009 Elsevier Ltd. All rights reserved.;},
  keywords = {Approaches to learning,ASSESSMENT SYSTEM,BELIEFS,Community colleges,Computer Assisted Testing,Conceptions of learning,EDUCATION & EDUCATIONAL RESEARCH,Electronic Learning,FACE-TO-FACE,FEEDBACK,Internet,Interviews,KNOWLEDGE,Learning Strategies,Online learning,Peer assessment,Peer Evaluation,Program Effectiveness,PSYCHOLOGY EDUCATIONAL,QUALITATIVE DIFFERENCES,SCHOOL-STUDENTS CONCEPTIONS,SCIENCE,SELF,STRATEGIES,Student Evaluation,Study and teaching,Two Year College Students,Two Year Colleges,Universities and colleges}
}

@article{yangHowTechnologyFosters2014,
  title = {How {{Technology Fosters Learning}}: {{Inspiration}} from the ``{{Media Debate}}''},
  shorttitle = {How {{Technology Fosters Learning}}},
  author = {Yang, Kai-Ti and Wang, Tzu-Hua and Chiu, Mei-Hung},
  year = {2014},
  journal = {Creative Education},
  volume = {05},
  number = {12},
  pages = {1086--1090},
  issn = {2151-4755, 2151-4771},
  doi = {10.4236/ce.2014.512123},
  urldate = {2023-08-07},
  file = {/Users/colin.madland/Zotero/storage/39VMDDAB/yangHowTechnologyFosters2014.pdf}
}

@article{yangInvestigationTwoTierTest2016,
  title = {An {{Investigation}} of a {{Two-Tier Test Strategy}} in a {{University Calculus Course}}: {{Causes}} versus {{Consequences}}},
  author = {Yang, Tzu Chi and Chen, Sherry Y. and Chen, Meng Chang},
  year = {2016},
  month = apr,
  journal = {IEEE Transactions on Learning Technologies},
  volume = {9},
  number = {2},
  pages = {146--156},
  publisher = {IEEE Transactions on Learning Technologies},
  issn = {1939-1382},
  doi = {10.1109/TLT.2015.2510003},
  abstract = {Online tests have been identified as a core learning activity in higher education. Unlike conventional online tests, which cannot completely reflect students' learning status, two-tier tests not only consider students' answers, but also take into account reasons for their answers. Due to such significance, research into the two-tier tests had mushroomed but few studies examined why the two-tier test approach was effective. To this end, we conducted an empirical study, where a lag sequential analysis was used to analyze behavior patterns while qualitative data from the questionnaire were applied to explain why these behavior patterns were happened. The results indicated students with a two-tier test tended to realize the rationale of a concept, instead of relying on their memories. In other words, the two-tier test can facilitate students to develop deep thinking skills. This may be because they considered the two-tier test as a learning tool, instead of an assessment tool only.},
  keywords = {Calculus,College Students,Computer Assisted Testing,Control Groups,Foreign Countries,Higher Education,Learning Activities,Mathematics Instruction,Mathematics Tests,Pretests Posttests,Qualitative Research,Questionnaires,Skill Development,Statistical Analysis,Student Attitudes,Taiwan,Teaching Methods,Thinking Skills,Web Based Instruction},
  file = {/Users/colin.madland/Zotero/storage/TQFKGLBZ/yangInvestigationTwoTierTest2016.pdf}
}

@article{yangRoleEPortfoliosSupporting2016,
  title = {The {{Role}} of E-{{Portfolios}} in {{Supporting Productive Learning}}},
  author = {Yang, Min and Tai, Mui and Lim, Cher Ping},
  year = {2016},
  month = nov,
  journal = {British Journal of Educational Technology},
  volume = {47},
  number = {6},
  pages = {1276--1286},
  publisher = {British Journal of Educational Technology},
  issn = {0007-1013},
  doi = {10.1111/bjet.12316},
  abstract = {e-Portfolios are a form of authentic assessment with formative functions that include showcasing and sharing learning artifacts, documenting reflective learning processes, connecting learning across various stages and enabling frequent feedback for improvements. This paper examines how e-portfolios take up these formative roles to support productive learning. Qualitative findings from interviews with selected first-year undergraduate students at a higher education institution in Hong Kong are reported concerning students' experiences of constructing e-portfolios as assessment tasks. As part of an institutional teaching and learning initiative, e-portfolios were incorporated into three core courses for first-year students. The findings reveal that several conditions necessary to foster productive learning were missing in students' experiences: strengthened formative role of e-portfolios through coherent assessment design; encouragement for students' pursuit of authentic tasks to develop learning interests; engagement of students in reflective and self-regulative learning as an essential learning process; provision of constructive feedback for sustained learning support; and support for students' autonomy through facilitation of collaborative knowledge building. By explicating how the lack of these conditions impeded students' active involvement in e-portfolio tasks and suggesting relevant strategies for teachers at the institution in question, this paper offers implications for harnessing information and communication technology (ICT) to support students' productive learning.},
  keywords = {Barriers,College Freshmen,Cooperation,Educational Technology,Electronic Publishing,Feedback (Response),Foreign Countries,Formative Evaluation,Hong Kong,Personal Autonomy,Portfolio Assessment,Reflection,Technology Uses in Education},
  file = {/Users/colin.madland/Zotero/storage/8TGWBQQV/yangRoleEPortfoliosSupporting2016.pdf}
}

@article{yangStudentResponsesOnline2019,
  title = {Student {{Responses}} to {{Online Peer Assessment}} in {{Tertiary English Language Classrooms}}},
  author = {Yang, Chi Cheung Ruby},
  year = {2019},
  journal = {TESL-EJ},
  volume = {23},
  number = {1},
  issn = {EISSN-1072-4303},
  abstract = {The use of peer assessment has been investigated for decades. However, the results of different studies are mixed. In this study, the implementation of peer assessment was attempted to assess students' reading aloud and oral presentation in two higher diploma/associate degree English language courses in Hong Kong. Students' opinions towards the implementation were obtained from the online questionnaire and follow-up interviews. In the end, 163 students from the two courses completed the questionnaire and 11 of them were involved in the interviews voluntarily. Apart from focusing on students' perceptions of peer assessment, the effects of the use of an online platform for peer assessment were explored. The results showed that more than half of the students were positive towards peer assessment because of their perceived benefits such as consolidating subject knowledge, engaging critical thinking and encouraging active student involvement in the assessment process. Regarding peer feedback, a few participants expressed that they were not confident in their abilities and English levels. Also, the majority of students interviewed commented negatively about the quality of their peers' feedback. Based on the findings, some implications for education and future studies were drawn.},
  langid = {english},
  keywords = {College Students,Computer Mediated Communication,Educational Technology,English (Second Language),Evaluation Methods,Foreign Countries,Language Proficiency,No DOI found,Oral Language,Peer Evaluation,Second Language Instruction,Student Attitudes}
}

@article{yangTheoreticalTrendsResearch2021,
  title = {Theoretical Trends of Research on Technology and {{L2}} Vocabulary Learning: {{A}} Systematic Review},
  shorttitle = {Theoretical Trends of Research on Technology and {{L2}} Vocabulary Learning},
  author = {Yang, Xinyuan and Kuo, Li-Jen and Eslami, Zohreh R. and Moody, Stephanie M.},
  year = {2021},
  journal = {Journal of Computers in Education},
  volume = {8},
  number = {4},
  pages = {465--483},
  issn = {2197-9987, 2197-9995},
  doi = {10.1007/s40692-021-00187-8},
  urldate = {2022-05-24},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/JCPFUNDJ/yangTheoreticalTrendsResearch2021.pdf}
}

@article{yanSystematicReviewFactors2021,
  title = {A Systematic Review on Factors Influencing Teachers' Intentions and Implementations Regarding Formative Assessment},
  author = {Yan, Zi and Li, Ziqi and Panadero, Ernesto and Yang, Min and Yang, Lan and Lao, Hongling},
  year = {2021},
  month = may,
  journal = {Assessment in Education: Principles, Policy \& Practice},
  volume = {28},
  number = {3},
  pages = {228--260},
  issn = {0969-594X, 1465-329X},
  doi = {10.1080/0969594X.2021.1884042},
  urldate = {2022-04-07},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/JB5DCRHK/yanSystematicReviewFactors2021.pdf}
}

@article{yaoPredictionWritingTrue2019,
  title = {Prediction of {{Writing True Scores}} in {{Automated Scoring}} of {{Essays}} by {{Best Linear Predictors}} and {{Penalized Best Linear Predictors}}. {{Research Report}}. {{ETS RR-19-13}}},
  author = {Yao, Lili and Haberman, Shelby J. and Zhang, Mo},
  year = {2019},
  month = dec,
  journal = {ETS Research Report Series},
  publisher = {ETS Research Report Series},
  issn = {2330-8516},
  abstract = {Many assessments of writing proficiency that aid in making high-stakes decisions consist of several essay tasks evaluated by a combination of human holistic scores and computer-generated scores for essay features such as the rate of grammatical errors per word. Under typical conditions, a summary writing score is provided by a linear combination of the holistic scores and the feature scores. The best linear predictor (BLP) is used to approximate the true composite writing score by a linear combination of holistic scores and scores of essay features. However, because the relationship between computer-generated feature score and human scores may depend on subgroup membership and the same scoring rules must normally be applied to all test takers, Yao, Haberman, and Zhang proposed a modified methodology of the penalized best linear predictor (PBLP) by incorporating a quadratic penalty function into the conventional BLP method. This research report contains full accounts of the BLP results as well as supplementary PBLP results to Yao et al. for three assessments of writing that aid in making high-stakes decisions: the "TOEFL iBT"{\textregistered} Writing test, the "GRE"{\textregistered} General Analytical Writing subject test, and the "Praxis"{\textregistered} Core Academic Skills for Educators: Writing assessment. Results obtained indicate the added value in using machine features for prediction of composite true scores of essay writings and effectiveness of the penalty function in suppressing the lack of population invariance.},
  keywords = {Accuracy,College Entrance Examinations,Computer Assisted Testing,English (Second Language),Essays,Graduate Record Examinations,Graduate Study,High Stakes Tests,Language Tests,No DOI found,Praxis Series,Prediction,Scoring,Second Language Learning,Test of English as a Foreign Language,True Scores,Writing Evaluation,Writing Tests}
}

@article{yazdanianRadarPredictingNearfuture2022,
  title = {On the Radar: {{Predicting}} near-Future Surges in Skills' Hiring Demand to Provide Early Warning to Educators},
  author = {Yazdanian, Ramtin and Lee Davis, Richard and Guo, Xiangcen and Lim, Fiona and Dillenbourg, Pierre and Kan, Min-Yen},
  year = {2022},
  month = jan,
  journal = {Computers and Education: Artificial Intelligence},
  volume = {3},
  pages = {100043},
  issn = {2666-920X},
  doi = {10.1016/j.caeai.2021.100043},
  abstract = {The AI-driven Fourth Industrial Revolution and the COVID-19 pandemic have one important thing in common: they both have caused significant and rapid changes to the skill set landscape of various industries. These disruptive forces mean that the early identification of the newly rising skills in a labour market --- which we call its ``emerging skills'' --- is crucial to its workforce. It is also crucial to the educators who, in order to provide lifelong training to the workforce, need to quickly adapt their curricula to the new skills. We propose a classification methodology that uses the past job ad trends of skills to predict the emerging skills of a future period, defined as the skills that have experienced a surge in hiring demand in said period. This general definition allows for freedom in specifying the criteria for a skill being emerging (through thresholds on hiring demand and its growth), which could be important to educators. Applying our methodology to the Information and Communication Technologies (ICT) labour market in Singapore, we show that we are able to predict future emerging skills with good precision and recall and beat two baseline classifiers for multiple threshold sets. Our methodology also allows us to see where job ads fail to provide sufficient predictive signals, pointing to auxiliary data sources (such as Stack Overflow for ICT) and skill ontologies as potential remedies. The success of our method shows how AI can be used to empower learners and educators in the ICT domain (and potentially other domains) with useful and well-curated insights at a moment's notice, thus helping speed up the process of curricular change.},
  keywords = {AI,Job ads,Lifelong learning,Predictive analysis,Skill needs},
  file = {/Users/colin.madland/Zotero/storage/D3GYDXKW/yazdanianRadarPredictingNearfuture2022.pdf}
}

@incollection{yeamanProfessionalEthicsEducational2013,
  title = {Professional Ethics and Educational Technology},
  booktitle = {Educational {{Technology}}},
  author = {Yeaman, RJ, Andrew and Eastman, Jr., J Nicholls and Napper, Vicki S},
  editor = {Januszewski, Al and Molenda, Michael},
  year = {2013},
  edition = {0},
  publisher = {Routledge},
  urldate = {2024-10-09},
  isbn = {978-1-136-50327-6},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/yeamanProfessionalEthicsEducational2013.pdf}
}

@article{yeoDisciplinaryApproachesAssessment2019,
  title = {Disciplinary Approaches to Assessment},
  author = {Yeo, Michelle and Boman, Jennifer},
  year = {2019},
  journal = {Journal of further and higher education},
  volume = {43},
  number = {4},
  pages = {482--493},
  publisher = {Routledge},
  address = {Abingdon},
  issn = {0309-877X},
  doi = {10.1080/0309877X.2017.1367371},
  abstract = {Change in assessment practice in higher education tends to lag behind pedagogical change. Thinking about assessment practice is, in part, related to disciplinary thinking. In this study, 27 faculty members from a broad range of disciplines were interviewed about their conceptions of assessment to help understand the distinctions and priorities of four main categories of disciplines. We uncover why university instructors may be resistant to changes in assessment practice if they perceive them not to support their disciplinary priorities.},
  langid = {english},
  keywords = {academic disciplines qualitative research,Assessment,College Faculty,Educational evaluation,Evaluation Methods,Foreign Countries,Higher Education,Intellectual Disciplines,Resistance to Change,Student Evaluation,Teacher Attitudes,Teacher evaluations,teaching practice},
  file = {/Users/colin.madland/Zotero/storage/EVUADA2T/yeoDisciplinaryApproachesAssessment2019.pdf}
}

@article{yildirim-erbasliConversationbasedAssessmentNovel2023,
  title = {Conversation-Based Assessment: {{A}} Novel Approach to Boosting Test-Taking Effort in Digital Formative Assessment},
  author = {{Yildirim-Erbasli}, Seyma N. and Bulut, Okan},
  year = {2023},
  journal = {Computers and education. Artificial intelligence},
  volume = {4},
  pages = {100135},
  publisher = {Elsevier Ltd},
  issn = {2666-920X},
  doi = {10.1016/j.caeai.2023.100135},
  abstract = {Conversational agents such as chatbots have recently gained a lot of traction in various industries, including education, marketing, and healthcare. In K--12 and higher education, conversational agents have been used to boost student learning and motivation. Recently, new applications of conversational agents, such as conversation-based assessments, have emerged in the context of educational assessments. Such applications aim to enhance students' assessment experiences through the use of conversational agents in administering items (or tasks) and providing feedback to students. To discuss the utility of conversational agents in assessments, this paper puts a special emphasis on test-taking effort in low-stakes assessments. It provides a brief introduction to educational assessments and student test-taking motivation, presents the concept of conversational agents for learning and assessment along with several examples, examines the benefits and challenges of conversational agents used for learning and assessment purposes, and discusses the concept of conversation-based assessment. This position paper contributes to the literature by discussing the utility of conversation-based assessments as a novel tool to enhance test-taking effort among students and thereby obtain a more accurate representation of students' academic performance. Specifically, we describe the advantages and disadvantages of using conversation-based assessments for addressing the lack of test-taking effort in digital formative assessments and discuss how conversation-based assessments can foster a more engaging testing experience for students.},
  keywords = {Artificial intelligence,Conversation-based assessment,Conversational agents,Formative assessment,Low-stakes assessment,Natural language processing,Test-taking effort},
  file = {/Users/colin.madland/Zotero/storage/UAF876HL/yildirim-erbasliConversationbasedAssessmentNovel2023.pdf}
}

@article{yilmazLearnerCenteredClassroom2017,
  title = {Learner {{Centered Classroom}} in {{Science Instruction}}: {{Providing Feedback}} with {{Technology Integration}}},
  author = {Yilmaz, Ozkan},
  year = {2017},
  month = jun,
  journal = {International Journal of Research in Education and Science},
  volume = {3},
  number = {2},
  pages = {604--613},
  publisher = {{International Journal of Research in Education and Science}},
  issn = {2148-9955},
  abstract = {"Learner centered" term points out environments that attention to the learners brings to the educational setting. This term includes teaching practices: effort to uncover what learners think in a specific problem on hand, talking about their misconceptions and, giving them situations to readjust their ideas. In Learner centered classrooms, teachers assess different student for feedback and revision. The two major, summative and formative, assessment reveal individual students? progress continually. Teachers, in many classrooms, provide feedbacks to students are relatively rare. Feedback is most effective in learning when students have the opportunity to use it to readjust their thinking. Technology integration, a part of learner centered classroom, is support to providing feedback in effective way. This paper explores the design of learner centered classroom in relation to the interactive technology integration which is based on using mobile technology to provide effective feedback in learning environment. Higher education students used mobile interactive technology with teacher, one term, in misconception in science course. Qualitative research design was used in this research. Focus group interview method was used to get data collecting. The study findings show that mobile technology supports feedback effectively and promote student engagement in the classroom. [This paper was presented at the International Conference on Education in Mathematics, Science \& Technology (ICEMST), May 19-22, 2016, Bodrum-TURKEY.]},
  keywords = {Classroom Techniques,Communication Strategies,Feedback (Response),Focus Groups,Foreign Countries,Handheld Devices,Instructional Effectiveness,Interviews,Misconceptions,No DOI found,Qualitative Research,Science Instruction,Student Satisfaction,Student Surveys,Teaching Methods,Technology Integration,Turkey,Undergraduate Students}
}

@article{ylonenDisciplinaryDifferencesOther2018,
  title = {Disciplinary Differences and Other Variations in Assessment Cultures in Higher Education: Exploring Variability and Inconsistencies in One University in {{England}}},
  shorttitle = {Disciplinary Differences and Other Variations in Assessment Cultures in Higher Education},
  author = {Ylonen, Annamari and Gillespie, Helena and Green, Adam},
  year = {2018},
  month = aug,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {43},
  number = {6},
  pages = {1009--1017},
  issn = {0260-2938, 1469-297X},
  doi = {10.1080/02602938.2018.1425369},
  urldate = {2022-05-29},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/JUPC3HBH/ylonenDisciplinaryDifferencesOther2018.pdf}
}

@article{yongBeginnerGuideFactor2013,
  title = {A {{Beginner}}'s {{Guide}} to {{Factor Analysis}}: {{Focusing}} on {{Exploratory Factor Analysis}}},
  shorttitle = {A {{Beginner}}'s {{Guide}} to {{Factor Analysis}}},
  author = {Yong, An Gie and Pearce, Sean},
  year = {2013},
  month = oct,
  journal = {Tutorials in Quantitative Methods for Psychology},
  volume = {9},
  number = {2},
  pages = {79--94},
  issn = {1913-4126},
  doi = {10.20982/tqmp.09.2.p079},
  urldate = {2024-06-22},
  file = {/Users/colin.madland/Zotero/storage/ADCNLFXJ/yongBeginnerGuideFactor2013.pdf}
}

@article{Yorke_2009,
  title = {Faulty Signals Inadequacies of Grading Systems and a Possible Response},
  author = {Yorke, Mantz},
  year = {2009},
  journal = {null},
  doi = {10/czdcdc},
  abstract = {Criticism of grading is not new. Milton, Pollio and Eison (1986) made a fairly forceful case that grading was suspect, but to little avail -- not surprisingly, since a long-established approach is difficult to dislodge. There is now more evidence that grading does not do what many believe it does (especially in respect of providing trustworthy indexes of student achievement), so the time may be ripe for a further challenge to existing grading practices. Grade is inherently ambiguous as a term, in that it can be used in respect of rawmarks or scores, derivatives of rawmarks (in the US, for example, the letter grades determined by conversion of raw percentages), and overall indexes of achievement. In this chapter the ambiguity is not entirely avoided: however, an appreciation of the context in which the term `grade' is used should mitigate the problem of multiple meaning. Grades are signals of achievement which serve a number of functions including the following:},
  mag_id = {1535125556},
  pmcid = {null},
  pmid = {null}
}

@incollection{yorkeFaultySignalsInadequacies2009,
  title = {Faulty {{Signals}}? {{Inadequacies}} of {{Grading Systems}} and a {{Possible Response}}},
  shorttitle = {Faulty {{Signals}}?},
  booktitle = {Assessment, {{Learning}} and {{Judgement}} in {{Higher Education}}},
  author = {Yorke, Mantz},
  editor = {Joughin, Gordon},
  year = {2009},
  pages = {1--20},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-1-4020-8905-3_5},
  urldate = {2022-04-23},
  isbn = {978-1-4020-8904-6 978-1-4020-8905-3},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/K72KWYNQ/yorkeFaultySignalsInadequacies2009.pdf}
}

@article{yorukPractitionersOpinionsStudent2021,
  title = {Practitioners' {{Opinions}} on {{Student Assessment Process}} in {{Distance Education}} in the {{Context}} of {{Educational Technologies}}},
  author = {Y{\"o}r{\"u}k, Tayfun},
  year = {2021},
  month = mar,
  journal = {Shanlax International Journal of Education},
  volume = {9},
  number = {2},
  pages = {12--17},
  issn = {2582-1334, 2320-2653},
  doi = {10.34293/education.v9i2.3552},
  urldate = {2023-01-15},
  abstract = {The aim of this study is to reveal the views of the practitioners regarding the measurement and evaluation sub-system of distance education applications in higher education. 11 faculty members working at Akdeniz University, determined with an easily accessible sampling of purposeful sampling methods, participated in this study in which qualitative research method was used. The research is in case study design, one of the qualitative research designs. Therefore, to collect data, a semi-structured interview form was prepared and an interview technique was used in the study. The data were analyzed by the content analysis technique. All the data obtained in the study were coded. Various themes and sub-themes suitable for these themes were determined by the purpose of the research, percentages and frequencies related to the sub-themes were calculated. When the findings are evaluated in the context of education management and the use of educational technologies, it was observed that the problems encountered in measurement and evaluation system in distance education in higher education are the lack of technological infrastructure, the safety of exams, failure to provide equal opportunities. As a result, opinions about an effective measurement and evaluation system have been put forward by the practitioners.},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/BRP5JLZ9/yorukPractitionersOpinionsStudent2021.pdf}
}

@inproceedings{yuenMlearningMobilityLearning,
  title = {M-Learning: {{Mobility}} in {{Learning}}},
  booktitle = {World {{Conference}} on {{E-Learning}} in {{Corporate}}, {{Government}}, {{Healthcare}}, and {{Higher Education}} 2004},
  author = {Yuen, Steve and Wang, Shuyan},
  pages = {2248--2252},
  publisher = {AACE},
  abstract = {Still in its early stages, m-learning (mobile learning) is comparable to where e-learning was a few year ago. M-learning is the point at which mobile computing and e-learning intersect to produce an anytime, anywhere learning experience. Advances in mobile technologies have enhanced m-learning tools at just the right moment to meet the need for more cost-effective just-in-time training options {\textsurd}{\textpm} Learning on the Go.}
}

@article{yufrizalSelfAssessmentCommunicativeCompetence2020,
  title = {Self-{{Assessment}} on {{Communicative Competence}} of {{Students}} of {{Higher Education}} in {{Indonesia}}},
  author = {Yufrizal, Hery and Pratiwi, Nery Eka},
  year = {2020},
  journal = {Education Quarterly Reviews},
  volume = {3},
  number = {2},
  pages = {225--236},
  issn = {ISSN-2657-215X},
  doi = {10/gmbv2g},
  abstract = {The objectives of this study are firstly to explore students' self-assessment on four language competence: linguistic, sociolinguistic competence, discourse competence, and strategic competences, secondly to find out whether there is any significant influence of students' length of language learning toward their self-assessment of communicative competences. The research was undertaken at undergraduate program at the university of Lampung. The results showed that communicative competence assessed by students has positive relationship to the score of their performance assessed by teachers. The current research succeeded in modifying students' self-assessment according to the communicative competence.},
  langid = {english},
  keywords = {Communicative Competence (Languages),Foreign Countries,Gender Differences,Performance Based Assessment,Performance Tests,Pronunciation,Second Language Learning,Self Evaluation (Individuals),Speech Communication,Undergraduate Students}
}

@article{zakariaGameBasedAssessmentAcademic2020,
  title = {Game-{{Based Assessment}} in {{Academic Writing Course}} for {{Pre-Service Teachers}}},
  author = {Zakaria, Nur Yasmin Khairani and Hashim, Harwati},
  year = {2020},
  month = jan,
  journal = {TESOL International Journal},
  volume = {15},
  number = {1},
  pages = {65--73},
  publisher = {TESOL International Journal},
  issn = {2094-3938},
  abstract = {Integration of technology in language learning has become a recommendable initiative for English as Second Language (ESL) instructors. Previous studies have noted remarkable improvement of students' learning through the integration of games in classroom teaching. However, little attention has been given to the integration of games element in language classroom that particularly aims to hone students' writing skills. In response to current language learning situation related to writing skills, this current study sought for a new method of assessment in ESL context. An online game application, Kahoot, was used as the primary tool for students' assessment in an academic writing course participated by 32 ESL students in a public university in Malaysia. Qualitative research design was conducted in this study and collection of data was conducted through focus group discussion with ESL learners and a semi-structured interview with ESL instructors. The Responses from students and instructors were recorded and transcribed in verbatim. Thematic analysis of the data revealed that ESL learners found that game-based assessment is highly engaging despite of some learners' anxiety towards the use of technology. ESL instructors also highlighted the importance of learning objectives in assessing students' performance regardless of the tools used.},
  keywords = {College Students,Educational Games,English (Second Language),Evaluation Methods,Foreign Countries,Game Based Learning,Learning Motivation,Malaysia,No DOI found,Preservice Teachers,Second Language Learning,Writing Evaluation,Writing Skills}
}

@article{zanonApplicationItemResponse2016,
  title = {An Application of Item Response Theory to Psychological Test Development},
  author = {Zanon, Cristian and Hutz, Claudio S. and Yoo, Hanwook and Hambleton, Ronald K.},
  year = {2016},
  month = dec,
  journal = {Psicologia: Reflex{\~a}o e Cr{\'i}tica},
  volume = {29},
  number = {1},
  pages = {18},
  issn = {1678-7153},
  doi = {10/ggfq5r},
  urldate = {2020-10-22},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/Q58ZCY7T/zanonApplicationItemResponse2016.pdf}
}

@article{zhaiApplyingMachineLearning2020,
  title = {Applying Machine Learning in Science Assessment: A Systematic Review},
  shorttitle = {Applying Machine Learning in Science Assessment},
  author = {Zhai, Xiaoming and Yin, Yue and Pellegrino, James W. and Haudek, Kevin C. and Shi, Lehong},
  year = {2020},
  month = jan,
  journal = {Studies in Science Education},
  volume = {56},
  number = {1},
  pages = {111--151},
  issn = {0305-7267, 1940-8412},
  doi = {10/ghv48n},
  urldate = {2021-01-27},
  langid = {english},
  keywords = {pellegrino},
  file = {/Users/colin.madland/Zotero/storage/5CX67L4M/zhaiApplyingMachineLearning2020.pdf}
}

@book{zhangAdvancedStatisticsUsing2017,
  title = {Advanced Statistics Using {{R}}},
  author = {Zhang, Zhiyong and Wang, Lijuan},
  year = {2017},
  publisher = {ISDSA Press},
  doi = {10.35566/advstats},
  urldate = {2025-03-02},
  isbn = {978-1-946728-01-2},
  file = {/Users/colin.madland/Zotero/storage/zhangAdvancedStatisticsUsing2017.pdf}
}

@article{zhanWhatMattersDesign2021,
  title = {What Matters in Design? {{Cultivating}} Undergraduates' Critical Thinking through Online Peer Assessment in a {{Confucian}} Heritage Context},
  author = {Zhan, Ying},
  year = {2021},
  month = jun,
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {46},
  number = {4},
  pages = {615--630},
  publisher = {Taylor \& Francis},
  issn = {0260-2938},
  doi = {10.1080/02602938.2020.1804826},
  abstract = {Online peer assessment has been proposed as an effective strategy for cultivating critical thinkers in higher education, but there is a dearth of relevant studies in a Confucian heritage context. This study investigated the effects of online peer assessment in a General Education course on the development of critical thinking among Hong Kong undergraduates, with a design characterised by six elements (i.e. online peer assessment training, provision of guiding questions, peer feedback requirements, anonymity, student evaluation of the usefulness of peer feedback and summative use of online peer assessment). Analysis of the participants' e-journal entries revealed a significant improvement in critical thinking in the experimental groups. Individual follow-up interviews indicated that the participants acknowledged online peer assessment design with the consideration of cultural influence and at the same time made some suggestions for refinement. This study highlights the need to adopt a culturally embedded approach to design online peer assessment to cultivate students' critical thinking in non-western contexts. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {College Students,Confucian heritage context,Confucianism,Critical thinking,Critical Thinking,Feedback,general education,journal writing,online peer assessment,Peer Evaluation}
}

@book{zhengDigitalTechnologiesInstructional2018,
  title = {Digital {{Technologies}} and {{Instructional Design}} for {{Personalized Learning}}:},
  shorttitle = {Digital {{Technologies}} and {{Instructional Design}} for {{Personalized Learning}}},
  editor = {Zheng, Robert and Tomei, Lawrence},
  year = {2018},
  series = {Advances in {{Educational Technologies}} and {{Instructional Design}}},
  publisher = {IGI Global},
  doi = {10.4018/978-1-5225-3940-7},
  urldate = {2021-08-01},
  isbn = {978-1-5225-3940-7 978-1-5225-3941-4}
}

@article{zhengRoleTechnologyfacilitatedPeer2020,
  ids = {zhengRoleTechnologyFacilitatedPeer2020},
  title = {The Role of Technology-Facilitated Peer Assessment and Supporting Strategies: A Meta-Analysis},
  author = {Zheng, Lanqin and Zhang, Xuan and Cui, Panpan},
  year = {2020},
  journal = {Assessment \& Evaluation in Higher Education},
  volume = {45},
  number = {3},
  pages = {372--386},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0260-2938},
  doi = {10.1080/02602938.2019.1644603},
  abstract = {Technology-facilitated peer assessment is gaining increasing attention. However, evidence for the contribution of technology-facilitated peer assessment to learning achievements has not been investigated. The present meta-analysis integrated findings on the effects of technology-facilitated peer assessment based on two main elements: (1) technology-facilitated peer assessment, (2) the use of extra supporting strategies in technology-facilitated peer assessment. A total of 37 empirical studies published from 1999 to 2018 were selected and analysed. Results indicated that technology-facilitated peer assessment had a significant and medium effect on learning achievements with an overall mean effect size of 0.576. The use of extra supporting strategies in technology-facilitated peer assessment also produced a positive and medium effect on students' learning achievements with an overall mean effect size of 0.543. Different moderator variables, such as task types, assessment modes, training for assessors, durations, grouping types and assessment methods were related to different effect sizes. The results together with the implications for both practice and research are discussed.},
  keywords = {Academic Achievement,Education & Educational Research,Educational Research,Educational Strategies,Educational technology,Effect Size,Elementary Secondary Education,Higher Education,Learning,learning achievement,Meta-analysis,Outcomes of Education,Peer assessment,Peer Evaluation,Peers,Social Sciences,Teacher evaluations,Technology Uses in Education},
  file = {/Users/colin.madland/Zotero/storage/8S3WANL9/The role of technology facilitated peer assessment and supporting strategies a meta analysis.pdf}
}

@article{zhengSelfassessmentFirstPeerassessment2021,
  title = {Self-Assessment First or Peer-Assessment First: Effects of Video-Based Formative Practice on Learners' {{English}} Public Speaking Anxiety and Performance},
  author = {Zheng, {\relax CP} and Wang, {\relax LL} and Chai, {\relax CS}},
  year = {2021},
  journal = {Computer Assisted Language Learning},
  issn = {0958-8221},
  doi = {10.1080/09588221.2021.1946562},
  abstract = {Although formative assessment has been recognized as an effective way for improving learning, scant attention has been paid to the specific design on the sequence of applying formative assessment practice in computer-assisted language learning (CALL). Even less emphasis has been devoted to the cognitive and affective outcomes of different orders of formative assessment strategies on building students' public speaking competence. This mixed-method research employed multi-source data to explore and explain the effects of two different ways of sequencing video-based formative assessment on English language learners' public speaking anxiety and their performance. Two intact classes in a 16-week English public speaking course were randomly assigned to two groups, 25 in the self-assessment-initiated (SAI) group and 26 in the peer-assessment-initiated (PAI) group. Following two different sequences of formative practice, both groups were required to complete three formal English public speeches. Both quantitative and qualitative findings indicated that learners in the SAI group showed significantly lower public speaking anxiety than those in the PAI group, whereas learners in the PAI group showed significantly better public speaking performance. Moreover, the findings showed that SAI formative practice helped the learners to pay more attention to their delivery and anxiety levels in public speaking, while PAI formative practice may have led the learners to improve their proper use of English language. This research indicated that the sequence of implementing different modalities of assessment matters. Supported by video technology and CALL tools, different sequences in obtaining varying sources of feedback can affect students' public speaking anxiety and competence. This study provides refined understandings about the sequences of using video technology in formative practice for alleviating the learners' public speaking anxiety and improving their performance. The findings suggest that self-assessment should be arranged first for learners with a higher-level of anxiety while peer-assessment should be conducted first for learners with a lower-level of English language proficiency. Supplemental data for this article is available online at https://doi.org/10.1080/09588221.2021.1946562 .},
  langid = {english},
  keywords = {EFFICACY,EFL LEARNERS,FEEDBACK,Foreign language anxiety,FOREIGN-LANGUAGE,formative assessment,HIGHER-EDUCATION,mixed-methods approach,ORAL PRESENTATION COMPETENCE,order of formative assessment,PERCEPTIONS,PRESENTATION SKILLS,public speaking anxiety,TEACHERS,UNIVERSITY-STUDENTS}
}

@article{zhengSystematicReviewTechnologySupported2019,
  title = {A {{Systematic Review}} of {{Technology-Supported Peer Assessment Research}}: {{An Activity Theory Approach}}},
  author = {Zheng, Lanqin and Chen, Nian-Shing and Cui, Panpan and Zhang, Xuan},
  year = {2019},
  month = dec,
  journal = {International Review of Research in Open and Distributed Learning},
  volume = {20},
  number = {5},
  pages = {168--191},
  publisher = {{International Review of Research in Open and Distributed Learning}},
  address = {ATHABASCA},
  issn = {1492-3831},
  abstract = {With the advancement of information and communication technologies, technology-supported peer assessment has been increasingly adopted in education recently. This study systematically reviewed 134 technology-supported peer assessment studies published between 2006 and 2017 using a developed analysis framework based on activity theory. The results found that most peer assessment activities were implemented in social science and higher education in the past 12 years. Acting assignments such as performance, oral presentations, or speaking were the least common type of assignments assessed across the studies reviewed. In addition, most studies conducted peer assessment anonymously and assessors and assessees were randomly assigned. However, most studies implemented only one round of peer assessment and did not provide rewards for assessors. Across studies, it was more often the case that students received unstructured feedback from their peers than structured feedback. Noticeably, collaborative peer assessment did not receive enough attention in the past 12 years. Regarding the peer assessment tools, there were more studies that adopted general learning management systems for peer assessment than studies that used dedicated peer assessment tools. However, most tools used within these studies only provide basic functionalities without scaffolding. Furthermore, the results of cross analysis reveal that there are significant relationships between learning domains and anonymity as well as learning domains and assessment durations. Significant relationships also exist between assignment types and learning domains as well as assignment types and assessment durations.},
  keywords = {Collaborative learning,Cooperative Learning,Education & Educational Research,Educational technology,Educational Technology,Elementary Secondary Education,Evaluation Methods,Feedback (Response),Higher Education,Law schools,Music teachers,No DOI found,Peer Evaluation,Peer review,Postsecondary Education,Social Sciences,Systematic review,Teacher evaluations,Technology Uses in Education},
  file = {/Users/colin.madland/Zotero/storage/C8W8KFV5/zhengSystematicReviewTechnologySupported2019.pdf}
}

@article{zhouTwoGroupsSeparated2021,
  title = {Two {{Groups Separated}} by a {{Shared Goal}}: {{How Academic Managers}} and {{Lecturers Have Embraced}} the {{Introduction}} of {{Digital Technologies}} in {{UK Higher Education}}},
  author = {Zhou, Xue and {Milecka-Forrest}, Melania},
  year = {2021},
  month = jan,
  journal = {Research in Learning Technology},
  volume = {29},
  publisher = {Research in Learning Technology},
  issn = {2156-7069},
  abstract = {Digital technologies have been widely used in higher education (HE) for years, and the benefits have been recognised by both students and academics. Although many universities have developed their own digital technology strategies, many do not share either their vision or implementation strategies with staff. This research explores differences and similarities in the perception of digital technology by lecturers and academic managers. The purpose of this paper is to compare and contrast motivations, barriers and support systems required for the use and adoption of digital strategies. Interviews were conducted with a group of 20 lecturers and academic managers in the HE sector. The results reveal that both groups shared a common view that the introduction of digital technology can have a clear set of benefits to students; however, their motivations for introducing new approaches differed significantly. Whilst it is important not to generalise too much given the lack of homogeneity in the two groups and also the crossover between managers and lecturers, managers tended to take a performance goal-based approach to its introduction whilst lecturers were more learning goal orientated. This difference can cause significant difficulties in the implementation of new approaches to learning.},
  keywords = {Administrator Attitudes,Barriers,College Administration,College Faculty,College Students,Communities of Practice,Comparative Analysis,Educational Benefits,Faculty Workload,Foreign Countries,Goal Orientation,Higher Education,Information Technology,Learning Experience,Learning Processes,No DOI found,Performance Based Assessment,Teacher Attitudes,Teaching Methods,Technological Literacy,Technology Integration,United Kingdom,Universities}
}

@article{zhuReadingConnectingUsing2020,
  title = {Reading and {{Connecting}}: {{Using Social Annotation}} in {{Online Classes}}},
  shorttitle = {Reading and {{Connecting}}},
  author = {Zhu, Xinran and Chen, Bodong and Avadhanam, Rukmini and Shui, Hong and Zhang, Raymond},
  year = {2020},
  month = may,
  doi = {10.35542/osf.io/2nmxp},
  urldate = {2020-05-11},
  abstract = {The COVID-19 pandemic has forced many instructors to rapidly shift to online/distance teaching. With a narrow preparation window, many instructors are at a loss of strategies that are both effective in responding to the crisis and compatible with their professional practices. This article presents a systematic literature review of the use of web annotation to support reading and discussion activities in formal education. As a genre of information systems, web annotation allows users to socially engage with web resources and is used in education to support social reading, argumentation, group inquiry, and community building. From this review we identified five types of social annotation activity design: processing domain-specific knowledge; supporting argumentation and inquiry; improving literacy skills; supporting instructor or peer assessment, and connecting online learning spaces. Practical recommendations for incorporating social annotation in online/distance classes are provided.},
  keywords = {No DOI found}
}

@article{zhuReviewCollaborativeAssessment2023,
  title = {A Review of Collaborative Assessment Strategies in Online Learning},
  author = {Zhu, Meina and Ergulec, Funda},
  year = {2023},
  journal = {Distance education},
  volume = {44},
  number = {3},
  pages = {522--543},
  publisher = {Routledge},
  address = {ABINGDON},
  issn = {0158-7919},
  doi = {10.1080/01587919.2022.2150127},
  abstract = {Online collaborative learning is increasingly used in online courses in higher education, but assessing student online collaborative learning presents unique challenges as well as interesting opportunities. Thus, it is critical to gain a clear picture of online group collaboration assessment strategies, including group learning assessment methods and examining the effectiveness, challenges, and opportunities in online education. The present study systematically reviewed 12 empirical studies on online collaborative learning assessment in higher education published in journals from 2011 to 2021. The results show that diverse strategies were used to facilitate group collaboration, including group agreements, project planning, role assignments, problem-based projects, and instructor feedback. The reviewed studies primarily evaluated learners through instructor evaluation, peer evaluation, and self-evaluation methods. The most common strategy was instructor assessment, while self-evaluations were used the least. The findings of this mapping review provide practical examples for future online group collaborative learning assessment research and practice.},
  keywords = {Collaborative learning,Distance learning,Education & Educational Research,Educational evaluation,group collaborative learning,Higher education,mapping review,online collaborative learning,online collaborative learning assessment,online learning,Social Sciences,Teacher evaluations}
}

@article{zhuTraditionalSystematicReview2023,
  title = {Beyond the {{Traditional}}: {{A Systematic Review}} of {{Digital Game-Based Assessment}} for {{Students}}' {{Knowledge}}, {{Skills}}, and {{Affections}}},
  author = {Zhu, Sha and Guo, Qing and Yang, Harrison Hao},
  year = {2023},
  journal = {Sustainability (Basel, Switzerland)},
  volume = {15},
  number = {5},
  pages = {4693},
  publisher = {Mdpi},
  address = {BASEL},
  issn = {2071-1050},
  doi = {10.3390/su15054693},
  abstract = {Traditional methods of student assessment (SA) include self-reported surveys, standardized tests, etc. These methods are widely regarded by researchers as inducing test anxiety. They also ignore students' thinking processes and are not applicable to the assessment of higher-order skills. Digital game-based assessment (DGBA) is thought to address the shortcomings of traditional assessment methods. Given the advantages of DGBA, an increasing number of empirical studies are working to apply digital games for SA. However, there is a lack of any systematic review of DGBA studies. In particular, very little is known about the characteristics of the games, the content of the assessment, the methods of implementation, and the distribution of the results. This study examined the characteristics of DGBA studies, and the adopted games on SA in the past decade from different perspectives. A rigorous systematic review process was adopted in this study. First, the Web of Science (WOS) database was used to search the literature on DGBA published over the last decade. Then, 50 studies on SA were selected for subsequent analysis according to the inclusion and exclusion criteria. The results of this study found that DGBA has attracted the attention of researchers around the world. The participants of the DGBA studies were distributed across different educational levels, but the number of participants was small. Among all game genres, educational games were the most frequently used. Disciplinary knowledge is the most popular SA research content. Formative assessment modeling with process data and summative assessment using final scores were the most popular assessment methods. Correlation analysis was the most popular analysis method to verify the effectiveness of games on SA. However, many DGBA studies have reported unsatisfactory data analysis results. For the above findings, this study further discussed the reasons, as well as the meanings. In conclusion, this review showed the current status and gaps of DGBA in the SA application; directional references for future research of researchers and game designers are also provided.},
  keywords = {21st century,21st century skills,Achievement tests,Analysis,Anxiety,assessment methodologies,Cognition,Computer & video games,Correlation analysis,Data analysis,digital games,Education,Educational attainment,Empirical analysis,Environmental Sciences,Environmental Sciences & Ecology,Environmental Studies,Formative assessment,Games,Green & Sustainable Science & Technology,Knowledge,Life Sciences & Biomedicine,Mathematics,media in education,Problem solving,Quantitative psychology,Reviews,Science & Technology,Science & Technology - Other Topics,Second language learning,Self evaluation,Skills,Students,Surveys,Systematic review},
  file = {/Users/colin.madland/Zotero/storage/G7RWII2Q/zhuTraditionalSystematicReview2023.pdf}
}

@article{ziegenfussFlippingFeedbackFormative2021,
  title = {Flipping the {{Feedback}}: {{Formative Assessment}} in a {{Flipped Freshman Circuits Class}}},
  author = {Ziegenfuss, Donna H. and Furse, Cynthia M.},
  year = {2021},
  month = mar,
  journal = {Practical Assessment, Research \& Evaluation},
  volume = {26},
  publisher = {Practical Assessment, Research \& Evaluation},
  issn = {1531-7714},
  abstract = {This paper describes the application of formative assessment methods in a flipped freshman engineering circuits course. This student-centered approach provided value for the instructor seeking to improve the learning environment and content in real-time, and for the students who actively participated in the process of course improvement. Three types of assessment were used in this course: online formative course feedback every three weeks; weekly 'muddiest point' content feedback; and midterm exam scores. Data were assessed using a mixed-methods approach. The formative feedback from this course provided information on how students perceived the flipped classroom and how those perceptions changed across the semester. This approach provided a low-effort strategy for incorporating the student voice for teaching and learning improvement. Although the intended assessment outcome was real-time improvement of the course, an unintended outcome of incorporating student voices and reflection during the course process was realized. Student acceptance of the flipped class increased as the semester progressed, and they placed high value on in-class active learning, the ability to re-visit the online lectures, and having a professor who valued their feedback and suggestions for course improvement. The majority of students also faced time management challenges that extended beyond this specific class.},
  keywords = {Active Learning,Class Activities,College Freshmen,Electronic Equipment,Electronic Learning,Engineering Education,Feedback (Response),Flipped Classroom,Formative Evaluation,Introductory Courses,Learner Engagement,Lecture Method,No DOI found,Questioning Techniques,Scores,Student Attitudes,Synchronous Communication,Time Management,Utah,Video Technology}
}

@article{zimmermanImplementingStandardsBasedGrading2020,
  title = {Implementing {{Standards-Based Grading}} in {{Large Courses Across Multiple Sections}}},
  author = {Zimmerman, Jane K.},
  year = {2020},
  month = nov,
  journal = {PRIMUS},
  volume = {30},
  number = {8-10},
  pages = {1040--1053},
  issn = {1051-1970, 1935-4053},
  doi = {10/gkk5t8},
  urldate = {2021-06-12},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/4FK44DWP/zimmermanImplementingStandardsBasedGrading2020.pdf}
}

@article{zlatovicUsingOnlineAssessments2015,
  title = {Using Online Assessments to Stimulate Learning Strategies and Achievement of Learning Goals},
  author = {Zlatovi{\'c}, Miran and Balaban, Igor and Kermek, Dragutin},
  year = {2015},
  journal = {Computers \& Education},
  volume = {91},
  number = {Journal Article},
  pages = {32--45},
  publisher = {Elsevier Ltd},
  address = {OXFORD},
  issn = {0360-1315},
  doi = {10/gdth39},
  abstract = {The main goals of this research are: (i) to explore the influence that announcement of certain type of online assessment has on students' learning strategies and (ii) to explore the influence of stimulated learning strategies on achievement levels that students exhibit during assessments. Research has been conducted by testing and surveying 351 students from higher education institutions. Results indicate that students' learning strategies can be influenced in a relatively short period of time by announcing various types of online assessments and that steering to more desirable deep learning strategies has positive impact on both formal and perceived levels of success in achieving the desired learning goals. These findings can be used to create a novel adaptive online assessment system that incorporates the elements of adaptivity within a series of assessments and uses postassessment feedback to steer students' learning strategies. (C) 2015 Elsevier Ltd. All rights reserved.;The main goals of this research are: (i) to explore the influence that announcement of certain type of online assessment has on students' learning strategies and (ii) to explore the influence of stimulated learning strategies on achievement levels that students exhibit during assessments. Research has been conducted by testing and surveying 351 students from higher education institutions. Results indicate that students' learning strategies can be influenced in a relatively short period of time by announcing various types of online assessments and that steering to more desirable deep learning strategies has positive impact on both formal and perceived levels of success in achieving the desired learning goals. These findings can be used to create a novel adaptive online assessment system that incorporates the elements of adaptivity within a series of assessments and uses post-assessment feedback to steer students' learning strategies. {$\bullet$}Learning strategies can be stimulated by announcing appropriate online assessments.{$\bullet$}Improvements in achieving learning goals are influenced by learning strategies.{$\bullet$}Learning strategies influence perception of ability to achieve levels of knowledge.;},
  keywords = {COMPUTER SCIENCE INTERDISCIPLINARY APPLICATIONS,Distance education and telelearning,EDUCATION & EDUCATIONAL RESEARCH,Evaluation methodologies,Improving classroom teaching,Learning strategies,Learning strategies and goals,MOTIVATION,Online knowledge assessment,Rating of,STUDENTS,Technology application}
}

@article{zongLearningImproveQuality2020,
  title = {Learning to Improve the Quality Peer Feedback through Experience with Peer Feedback},
  author = {Zong, Zheng and Schunn, Christian D. and Wang, Yanqing},
  year = {2020},
  month = oct,
  journal = {Assessment \& Evaluation in Higher Education},
  pages = {1--20},
  issn = {0260-2938, 1469-297X},
  doi = {10/ghg5nr},
  urldate = {2020-10-28},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/RYIRZF72/zongLearningImproveQuality2020.pdf}
}

@misc{ZoomTwitterHit,
  title = {Zoom, {{Twitter Hit}} by {{Allegations}} of {{Racial Bias}} in {{Their Visual Algorithms}}},
  journal = {NDTV Gadgets 360},
  urldate = {2020-09-22},
  abstract = {Several Twitter users posted photos on the microblogging platform to highlight the apparent bias.},
  howpublished = {https://gadgets.ndtv.com/social-networking/news/zoom-twitter-racial-bias-algorithms-image-cropping-virtual-background-2298787},
  langid = {english},
  file = {/Users/colin.madland/Zotero/storage/QEZC7HI4/zoom-twitter-racial-bias-algorithms-image-cropping-virtual-background-2298787.html}
}

@article{zovkoICTEnabledEducationNeed2016,
  title = {{{ICT-Enabled Education}} - {{Need}} for {{Paradigm Shift}}},
  author = {Zovko, V},
  year = {2016},
  journal = {Croatian Journal of Education-Hrvatski Casopis Za Odgoj I Obrazovanje},
  volume = {18},
  pages = {145--154},
  issn = {1848-5189},
  doi = {10.15516/cje.v18i0.2175},
  abstract = {Contemporary schools have not changed significantly since the 19th century. From primary level (elementary schools) to tertiary level of education (colleges and universities), the predominant approach to teaching is ex-cathedra teaching with assessment system based on grades. What has changed over the years are teaching and learning tools, but the methods have remained the same. In this context, information and communication technology is viewed as a tool supporting the traditional education systems. The new, hyper-digital era is based on ubiquitous computing that is radically transforming the way we live and work, and consequently, the way we teach and learn. Contemporary technologies lead to disruptive innovations in all sectors. As such, traditional education system fails to perceive the necessity to rethink the fundamental paradigms of education based on institutional framework (schools). This paper examines the evolution of education in the context of information and communication technologies and analyses the strengths and weaknesses of traditional, school-based education, as opposed to ubiquitous education based on information and communication technology, which has not been formally acknowledged within education systems, but which depends on effort invested by individuals instead. It also examines disruptive innovations in education systems that have a potential to transform formal education processes dramatically.},
  langid = {english},
  keywords = {disruptive innovation,education system,ICT}
}

@article{zuboffBigOtherSurveillance2015,
  title = {Big Other: Surveillance Capitalism and the Prospects of an Information Civilization},
  author = {Zuboff, Shoshana},
  year = {2015},
  journal = {Journal of Information Technology},
  volume = {30},
  number = {1},
  pages = {75--89},
  issn = {1466-4437},
  doi = {10.1057/jit.2015.5},
  abstract = {This article describes an emergent logic of accumulation in the networked sphere, `surveillance capitalism,' and considers its implications for `information civilization.' The institutionalizing practices and operational assumptions of Google Inc. are the primary lens for this analysis as they are rendered in two recent articles authored by Google Chief Economist Hal Varian. Varian asserts four uses that follow from computer-mediated transactions: `data extraction and analysis,' `new contractual forms due to better monitoring,' `personalization and customization,' and `continuous experiments.' An examination of the nature and consequences of these uses sheds light on the implicit logic of surveillance capitalism and the global architecture of computer mediation upon which it depends. This architecture produces a distributed and largely uncontested new expression of power that I christen: `Big Other.' It is constituted by unexpected and often illegible mechanisms of extraction, commodification, and control that effectively exile persons from their own behavior while producing new markets of behavioral prediction and modification. Surveillance capitalism challenges democratic norms and departs in key ways from the centuries-long evolution of market capitalism.},
  file = {/Users/colin.madland/Zotero/storage/YZNDJTSF/zuboffBigOtherSurveillance2015.pdf}
}

@article{zuboffShoshanaZuboffDigital2014,
  title = {{Shoshana Zuboff: A Digital Declaration}},
  shorttitle = {{Shoshana Zuboff}},
  author = {Zuboff, Shoshana},
  year = {2014},
  issn = {0174-4909},
  urldate = {2018-12-11},
  abstract = {If the digital future is to be our home, then it is we who must make it so. Against the Surveillance Capitalism of ,,Big Data``.},
  chapter = {Feuilleton},
  langid = {ngerman},
  keywords = {Ed Snowden,Edward Snowden,Frederich Hayek,John Searle,Karl Polanyi,Shoshana Zuboff,Telecom},
  file = {/Users/colin.madland/Zotero/storage/5WFV668W/shoshan-zuboff-on-big-data-as-surveillance-capitalism-13152525.html}
}

@preamble{ "\providecommand{\noopsort}[1]{} " }
