---
title: "Table of Specifications"
author: "Colin Madland"
date: "2025-06-05"
categories: [otessa25]
image: "image.jpg"
---

### Table of Specifications

| Meta-Construct | Construct | Description |
|  ---  |  ---  |  ---  |
| Assessment Purpose |   |   |
|      | Assessment *of* Learning |  Assessment *of* learning is what we typically call *summative assessment* where the intent of the assessment is to certify whether or not learners have achieved the learning outcomes. It occurs at the end of the learning experience and does not have an impact on future teaching or learning. Assessment of learning results in a symbolic representation of each learner's level of achievement. Symbols, usually letter grades or percentages, are used to communicate with learners, other institutions, regulatory agencies, and other external stakeholders, and are permanent records associated with learners. They are often used to rank learners for the purposes of scholarships and awards, entry into further education, and sometimes for employment purposes.   |
|       | Assessment *for* Learning |  Assessment *for* learning refers to activities within a learning experience that are designed to provide information on a learner's current level of achievement. This information is then used to inform future teaching and learning activities. Current levels of achievement are considered to be temporary and can be overridden by future demonstrations of achievement. Both instructors and learners benefit from the ongoing process of opening and closing feedback loops [@carlessFeedbackLoopsLongerterm2019], which require feedback to be actively used to improve learning.  |
|       | Assessment *as* Learning |  Assessment *as* learning is the process of learners developing the skill of "evaluative judgement" [@boudAssessmentaslearningDevelopmentStudents2021], which is the ability of learners to judge their own level of achievement in relation to the learning outcomes. It is a reflexive process whereby learners consider the results of their learning strategies and develop more effective strategies to enhance their performance. Assessment *as* learning allows learners to construct meaning from their experiences, identify gaps in their own knowledge, and to make meaningful decisions about their level of proficiency. Assessment *as* learning requires learners to be able to discern quality, judge learning processes, manage their biases, assess the trustworthiness of sources and seek opportunities for practice [@boudAssessmentaslearningDevelopmentStudents2021].   |
| Duty of Care |       |       |
|       | Bias |  Bias refers to the psychometric term where one group of learners is systematically advantaged or disadvantaged relative to other groups of learners (e.g., Caucasian learners as a group perform better than Asian learners as a group on an assessment due to some characteristic beyond their control) while the ability of each group is the same [@woo2023]. Bias can result from either the inclusion of construct-irrelevant content (e.g., considering learner age when assessing their ability) or the omission of construct-relevant content resulting in variance in scores.     |
|       | Inclusion |  Inclusion involves recognizing marginalized learners as having equitable agency in a learning community [@nieminen2024]. Marginalization can be based in a wide variety of factors and includes items listed in &sect; 3.1 of the *Canadian Human Rights Act* [@ministerofjusticeCanadianHumanRights1985].    |
|       | Relationships |  Relationship is intended to highlight the importance of designing assessment to foster positive relations between instructors and learners, learners and others in the class, learners and their individual communities [@tessaroFiveIndigenizingOnline2018], and learners and society as a whole [@nieminenDesigningDigitalAuthentic2022].    |
|       | Ethical EdTech | Instructors who use technologies for assessment are obligated to do so in alignment with appropriate codes of ethics. Statements of professional ethics can be related to expectations common to all instructors, such as ensuring that student data is not accessible to third party vendors or advertisers, and they can also be discipline-specific, such as ensuring that physical activity-tracking technology does not disclose learner locations inappropriately [@spectorEthicsEducationalTechnology2016]. Professional ethics involve obligations to individual learners, to society, and to the profession of teaching.    |
| Technology Acceptance |       |       |
|       | Performance Expectancy |  Performance expectancy relates to the technology user's perception that the technology will enable them to perform their job or task at a higher level, it will save them time, or it will reduce the amount of time they need to spend on some tasks [@venkatesh2003].      |
|       | Effort Expectancy |  Effort expectancy relates to the ease of use of the technology. Ease of use is most salient among older women who have less experience with the technology, and it decreases in importance as all users with sustained use [@venkatesh2003].     |
|       | Social Influence |   Social influence is the degree to which other people who are important to the user think that they should use the technology. When use of the technology is voluntary, social influence is not a significant factor in predicting acceptance, but when use is mandatory, social influences seem to increase compliance [@venkatesh2003].   |
|       | Facilitating Conditions |   Facilitating conditions are related to the user's belief that there will be sufficient institutional support in using the technology. When both performance and effort expectancy are high (the technology will improve outcomes with minimal effort), the facilitating conditions construct becomes less significant [@venkatesh2003]   |
| Assessment Design |       |       |
|       | Measurement |  Educational measurement is a quantitative approach to generating inferences about learner ability, often known as psychomterics. A foundational premiss of psychometrics is that the end result of assessment is always an *inference* or an *interpretation* about learner ability based on data collected through various tasks; it is not a direct measurement of a quantity of ability [@pellegrinoKnowingWhatStudents2001]. In order for inferences of learner ability to be accurate interpretations, they must be valid, reliable, and fair.    |
|       | Academic Integrity |  Modern conceptions of academic integrity encompass a comprehensive range of values and behaviours, including: everyday ethics, institutional ethics, ethical leadership, professional and collegial ethics, instructional ethics, student academic conduct, research integrity and ethics, and publication ethics [@eatonComprehensiveAcademicIntegrity2024]. This description goes beyond ethical learner conduct and extends to the ethical conduct of instructors in the context of instruction and assessment. Dawson [-@dawsonValidityMattersMore2024] argues that academic integrity is key to instructors being able to derive valid inferences from learner performance.      |
|       | Reciprocity | Reciprocity refers to the idea that assessment with technology should enrich both learners and instructors, as well as the learners' communities [@tessaroFiveIndigenizingOnline2018]. Reciprocity must be an intentional component of the design of assessment strategies [@rodriguez-trianaInstructionStudentEngagement2020].      |
|       | Relevance |  Assessment practice ought to be relevant to the culture of the learner. In Indigenous learning contexts, this suggests an emphasis on oral communication and learning in a community context [@tessaroFiveIndigenizingOnline2018]. We extend this argument and assert that oral communication is a key factor in ensuring ethical practice in any context.     |
:  {.striped .hover tbl-colwidths="[20,20,60]"}
